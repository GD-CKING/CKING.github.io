<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[kafka 之消费者组重平衡]]></title>
    <url>%2FCKING.github.io%2F2022%2F02%2F15%2Fkafka-%E4%B9%8B%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E9%87%8D%E5%B9%B3%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[消费者组的重平衡，它的作用就是让组内所有的消费者实例就消费哪些主题分区达成一致。重平衡需要借助 Kafka Broker 端的 Coordinator 组件，在 Coordinator 的帮助下完成整个消费者组的分区重分配。今天我们就说说这个 触发与通知重平衡的 3 个触发条件： 组成员数量发生变化 订阅主题数量发生变化 订阅主题的分区数发生变化 一般情况下，因命中第 1 个条件而引发的重平衡是最常见的。另外，消费者组中的消费者实例依次启动也属于第 1 种情况，即，每次消费者组启动时，必然会触发重平衡过程 那么，重平衡过程是如何通知到其他消费者实例的？答案就是靠消费者端的心跳线程（Heartbeat Thread） Kafka Java 消费者需要定期地发送心跳请求 到 Broker 端的协调者，以表明它还存活着。在 0.10.1.0 版本之前，发送心跳请求是在消费者主线程完成的，也就是你写代码调用 KafkaConsumer.poll 方法的那个线程 这样做最大的问题在于，消费处理逻辑也是在这个线程中完成的。因此，一旦消息处理消耗了过长的时间，心跳请求将无法及时发送到协调者那里，导致协调者「错误地」认为该消费者已「死」。自 0.10.1.0 版本开始，社区引入了一个单独的心跳线程来专门执行心跳请求发送，避免这个问题 这个重平衡有什么关系？其实，重平衡的通知机制就是通过心跳线程来完成的。当协调者决定开启新一轮重平衡后，它会将 “REBALANCE_IN_PROGRESS“ 封装进心跳的响应中，发还给消费者实例。当消费者实例发现心跳响应中包含了 “REBALANCE_IN_PROGRESS”，就能立马知道重平衡开始了，这就是重平衡的通知机制 另外，消费者端参数 heartbeat.interval.ms 参数的作用，除了设置了心跳的间隔时间外，真正的作用是控制重平衡通知的频率。如果你想要消费者实例更迅速地得到通知，那么就可以给这个参数设置一个非常小的值，这样消费者就能更快速地感知到重平衡已经开启了 消费者组状态机重平衡一旦开启，Broker 端的协调者组件就要开始忙了，主要涉及到控制消费者组的状态流转。Kafka 设计了一套消费组状态机，来帮助协调者完成整个重平衡流程 目前，Kafka 为消费者组定义了 5 种状态，分别是：Empty、Dead、PreparingRebalance、CompleingRebalance 和 Stable。如下： 接着，我们看看状态机的各个状态流转 一个消费者组最开始是 Empty 状态，当重平衡过程开启后，它会被置于 PreparingRebalance 状态下等待成员加入，之后变更到 CompletingRebalance 状态等待分配方案，最后流转到 Stable 状态完成重平衡 当有新成员加入或已有成员退出时，消费者组的状态从 Stable 直接跳到 PreparingRebalance 状态。此时，所有现存成员就必须重新申请加入组。当所有成员都退出组后，消费者组状态变更为诶 Empty。Kafka 定期自动删除过期位移的条件就是，组要处于 Empty 状态。因此，如果你的消费者组停掉了很长时间（超过 7 天），那么 Kafka 很可能就把该组的位移数据删除了。如下 Kafka 日志 1Removed XXX expired offsets in XXX milliseconds 这就是 Kafka 在尝试定期删除过期位移。只有 Empty 状态下的组，才会执行过期位移删除的操作 消费者组重平衡流程重平衡的完整流程需要消费者端和协调者组件共同参与才能完成。我们先从消费者的视角来审视一下重平衡的流程 在消费者端，重平衡分为两个步骤：分别是加入组合等待领导者消费者（Leader Consumer）分配方案。这两个步骤分别对应两类特定的请求：JoinGroup 请求和 SyncGroup 请求 当组内成员加入组时，它会向协调者发送 joinGroup 请求。在该请求中，每个成员都要将自己订阅的主题上报，这样协调者就能收集到所有成员的订阅信息。一旦收集了全部成员的 joinGroup 请求后，协调者会从这些成员中选择一个担任这个消费者组的领导者 通常情况下，第一个发送 joinGroup 请求的成员自动成为领导者。要区分这里的领导者和领导者副本，它们不是一个概念。这里的领导者是具体的消费者实例，它既不是副本，也不是协调者。领导者消费者的任务是收集所有成员的订阅信息，然后根据这些订阅信息，制定具体的分区消费分配方案 选出领导者之后，协调者会把消费者订阅信息封装到 joinGroup 请求的响应体中，然后发给领导者，由领导者统一作出分配方案后，进入到下一步：发送 SyncGroup 请求 在这一步中，领导者向协调者发送 SyncGroup 请求，将刚刚作出的分配方案发给协调者。值得注意的是，其他成员也会向协调者发送 SyncGroup 请求，只不过请求体中并没有实际的内容。这一步的主要目的是让协调者接收分配方案，然后统一以 SyncGroup 响应的方式发给所有成员，这样组内所有成员就都知道自己该消费哪些分区了 用一张图说明一下 JoinGroup 请求的处理过程 JoinGroup 请求的主要作用是将组成员订阅信息发送给领导者消费者，待领导者消费者指定好分配方案后，重平衡流程进入到 SyncGroup 请求阶段 下面这张图描述的是 SyncGroup 请求的处理流程 SyncGroup 请求的主要目的，就是让协调者把领导者指定的分配方案下发给各个组内成员。当所有成员都成功接收到分配方案后，消费者组进入到 Stable 状态，即开始正常的消费工作 到这里，消费者端的重平衡流程已经介绍完了。接下来，我们从协调者端来看一下重平衡是怎么执行的 Broker 端重平衡场景剖析要分析协调者端处理重平衡的全流程，必须要分几个场景来讨论 场景一：新成员入组新成员入组是指组处于 Stable 状态后，有新成员加入。如果是全新启动一个消费者组，Kafka 是有一些自己的小优化的，流程上会有些不同。这里讨论的是，组稳定了之后又新成员加入的情形 当协调者收到新的 JoinGroup 请求后，它会通过心跳请求响应的方法通知组内现有的所有成员，强制它们开启新一轮的重平衡。具体的过程和之前的客户端重平衡流程是一样的。我们用一张时序图来说明协调者一端是如何处理新成员入组的 场景二：组成员主动离组主动离组，就是消费者实例所在的线程或进程调用 close() 方法主动通知协调者它要退出。这个场景就涉及到了第三类请求：LeaveGroup 请求。协调者收到 LeaveGroup 请求后，依然会以心跳响应的方式通知其他成员。如下图： 场景三：组成员崩溃离组崩溃离组是指消费者实例出现严重故障，突然宕机的离组。它和主动离组是有区别的，因为后者是主动发起的离组，协调者能马上感知并处理。但崩溃离组是被动的，协调者通常需要等待一段时间才能感知到，这段时间一般是消费者端参数 session.timeout.ms 控制的。即，kafka 一般不会超过 session.timeout.ms 就能感知到这个崩溃。当然，后面处理崩溃离组的流程与之前是一样的，如下： 场景四：重平衡时协调者对组内成员提交位移的处理正常情况下，每个组内成员都会定期汇报位移给协调者。当重平衡开启时，协调者会给予成员一段缓冲时间，要求每个成员必须在这段时间内快速上报自己的位移信息，然后再开启正常的 JoinGroup / SyncGroup 请求发送。如下：]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 之循环依赖简易版]]></title>
    <url>%2FCKING.github.io%2F2022%2F02%2F09%2FSpring-%E4%B9%8B%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E7%AE%80%E6%98%93%E7%89%88%2F</url>
    <content type="text"><![CDATA[什么是循环依赖，就是 A 对象依赖了 B 对象，B 对象依赖了 A 对象。如下： 12345678// A 依赖了 Bclass A &#123; public B b;&#125;// B 依赖了 Aclass B &#123; public A a;&#125; 如上，A 类中存在一个 B 类的 b 属性，所以，当 A 类生成了一个原始对象之后，就会去给 b 属性赋值，此时就会根据 b 属性的类型和属性名去 BeanFactory 中去获取 B 类所对应的单例 bean。如果此时 BeanFactory 中存在 B 对应的 Bean，那么直接拿来赋值给 b 属性；如果此时 BeanFactory 中不存在 B 对应的 Bean，则需要生成一个 B 对应的 Bean，然后赋值给 b 属性 如果是第二种情况，如果此时 B 类在 BeanFactory 中还没有生成对应的 Bean，那么就需要去生成，就会经过 B 的 Bean 的生命周期 那么在创建 B 类的 Bean 的过程中，如果 B 类中存在一个 A 类的 a 属性，那么在创建 B 的 Bean 的过程中就需要 A 类对应的 Bean。但是，触发 B 类 Bean 的创建条件是 A 类 Bean 在创建过程中的依赖注入，所以这里就出现了循环依赖。从而导致 A Bean 创建不出来，B Bean 也创建不出来 这个循环依赖的场景。在 Spring 中，通过某些机制帮开发者解决了部分循环依赖的问题，这个机制就是三级缓存 三级缓存三级缓存是通用的叫法。一级缓存为：singletonObjects；二级缓存为：earlySingletonObjects；三级缓存为：singletonFactories singletonObjects 中缓存的是已经经历了完整生命周期的 bean 对象 earlySingletonObjects 比 singletonObjects 多了一个 early，表示缓存的是早期的 bean 对象。表示 Bean 的生命周期还没有走完就把这个 Bean 放入了 earlySingletonObjects singletonFactories 中缓存的是 ObjectFactory，表示对象工厂，表示用来创建早期 bean 对象的工厂 为什么缓存能解决循环依赖？之所以产生循环依赖，主要是：A 创建时 –&gt; 需要 B –&gt; B 去创建 –&gt; 需要 A，从而产生了循环 那么如何打破这个循环，加个中间人（缓存） A 的 Bean 在创建过程中，在进行依赖注入之前，先把 A 的原始 Bean 放入缓存（提早暴露，只要放到缓存了，其他 Bean 需要时就可以从缓存中拿了），放入缓存后，再进行依赖注入，此时 A 的 Bean 依赖了 B 的 Bean，如果 B 的 Bean 不存在，则需要创建 B 的 Bean，而创建 B 的 Bean 的过程和 A 一样，也是先创建一个 B 的原始对象，然后把 B 的原始对象暴露出来放入缓存中，然后再对 B 的原始对象依赖注入 A，此时能从缓存中拿到 A 的原始对象（只是原始对象，还不是最终的 Bean），B 的原始对象依赖注入完成了之后，B 的生命周期结束，那么 A 的生命周期也能结束 因为整个过程中，都只有一个 A 原始对象，所以对于 B 而言，就算在属性注入时，注入的是 A 原始对象，也没有关系，因为 A 原始对象在后续的生命周期中在堆中没有发生变化 从上面分析得知，只需要一个缓存就能解决循环依赖了，为什么 Spring 中还需要 singletonFactories 呢？ 如果 A 的原始对象注入给 B 的属性之后，A 的原始对象进行了 AOP 产生了一个代理对象，此时就会出现，对于 A 而言，它的 Bean 对象其实应该是 AOP 之后的代理对象，而 B 的 a 属性对应的并不是 AOP 之后的代理对象，这就产生了冲突 B 依赖的 A 和最终的 A 不是同一个对象 AOP 就是通过一个 BeanPostProcessor 来实现的，这个 BeanPostProcessor 就是 AnnotationAwareAspectJAutoProxyCreator，它的父类是 AbstractAutoProxyCreator，而在 Spring 中利用的要么是 JDK 动态代理，要么 CGLib 的动态代理，所以如果给一个类中的某个方法设置了切面，那么这个类最终就要生成一个代理对象 一般过程就是：A 类 –&gt; 生成一个普通对象 –&gt; 属性注入 –&gt; 基于切面生成一个代理对象 –&gt; 把代理对象放入 singletonObjects 单例池中 而 AOP 可以说是 Spring 中除开 IOC 的另外一大功能，而循环依赖又是属于 IOC 范畴的，所以这两大功能想要并存，Spring 需要特殊处理，就是利用了第三级缓存 singletonFactories 首先，singletonFactories 中存的是某个 beanName 对应的 ObjectFactory，在 bean 的生命周期中，生成完原始对象后，就会构造一个 ObjectFactory 存入 singletonFactories 中。这个 ObjectFactory 是一个函数式接口，所以支持 Lambda 表达式：() -&gt; getEarlyBeanReference(beanName, mbd, bean) 上面的 Lambda 表达式就是一个 ObjectFactory，执行该 Lambda 表达式就会去执行 getEarlyBeanReference 方法，如下： 123456789protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &#123; Object exposedObject = bean; if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &#123; for (SmartInstantiationAwareBeanPostProcessor bp : getBeanPostProcessorCache().smartInstantiationAware) &#123; exposedObject = bp.getEarlyBeanReference(exposedObject, beanName); &#125; &#125; return exposedObject;&#125; 该方法会去执行 SmartInstantiationAwareBeanPostProcessor 中的 getEarlyBeanReference 方法，而这个接口下的实现类中只有两个类实现了这个方法，一个是 AbstractAutoProxyCreator，一个是 InstantiationAwareBeanPostProcessorAdapter，它的实现如下： 1234567// AbstractAutoProxyCreator@Overridepublic Object getEarlyBeanReference(Object bean, String beanName) &#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); this.earlyProxyReferences.put(cacheKey, bean); return wrapIfNecessary(bean, beanName, cacheKey);&#125; 1234// InstantiationAwareBeanPostProcessorAdapterdefault Object getEarlyBeanReference(Object bean, String beanName) throws BeansException &#123; return bean;&#125; 在整个 Sprin g中，默认就只有 AbstractAutoProxyCreator 真正意义上实现了 getEarlyBeanReference 方法，而该类就是用来进行 AOP 的。上文提到的 AnnotationAwareAspectJAutoProxyCreator 的父类就 AbstractAutoProxyCreator 那么 getEarlyBeanReference 方法到底在干什么？ 首先得到一个 cachekey，cachekey 就是 beanName。 然后把 beanName 和 bean（这是原始对象）存入 earlyProxyReferences中 调用 wrapIfNecessary 进行 AOP，得到一个代理对象 那么，什么时候会调用 getEarlyBeanReference 方法呢？回到循环依赖的场景中 左边文字：这个 ObjectFactory 就是上文说的 Lambda 表达式，中间有 getEarlyBeanReference 方法，注意存入 singletonFactories 时并不会执行 Lambda 表达式，也就是不会执行 getEarlyBeanReference 方法 右边文字：从 singletonFactories 根据 beanName 得到一个 ObjectFactory，然后执行 ObjectFactory，也就是执行getEarlyBeanReference 方法，此时会得到一个 A 原始对象经过 AOP 之后的代理对象，然后把该代理对象放入 earlySingletonObjects中，注意此时并没有没有把代理对象放入 singletonObjects 中，那什么时候放入到 singletonObjects 中呢？ 我们这个时候得来理解一下 earlySingletonObjects 的作用。此时，我们只得到了 A 原始对象的代理对象，这个对象还不完整，因为 A 原始对象还没有进行属性填充，所以此时不能直接把 A 的代理对象放入 singletonObjects 中，所以只能把代理对象放入 earlySingletonObjects，假设现在有其他对象依赖了 A ，那么则可以从 earlySingletonObjects 中得到 A 原始对象的代理对象了，并且是 A 的同一个代理对象 当 B 创建完了之后，A 继续进行生命周期，而 A 在完成属性注入后，会按照它本身的逻辑去进行 AOP，而此时我们知道 A 原始对象已经经历过了 AOP，所以对于 A 本身，不会再进行 AOP 了，那么怎么判断一个对象已经经历过 AOP 呢？会利用上下文提到的earlyProxyReferences，在 AbstractAutoProxyCreator 的 postProcessAfterInitialization 方法中，会去判断当前 beanName 是否在 earlyProxyReferences，如果在则表示已经提前进行过 AOP 了，无需再次进行 AOP 对于 A 而言，进行了 AOP 的判断后，以及 BeanPostProcessor 的执行之后，就需要把 A 对应的对象放入 singletonObjects 中，但是我们知道，应该是要 A 的代理对象放入 singletonObjects 中，所以此时需要从 earlySingletonObjects 中得到代理对象，然后入singletonObjects 中 整个循环依赖解决完毕 总结 singletonObjects：缓存经过了完整生命周期的 bean earlySingletonObjects：缓存未经过完整生命周期的 bean，如果某个 bean 出现了循环依赖，就会提前把这个暂时未经过完整生命周期的 bean 放入 earlySingletonObjects 中，这个 bean 如果要经过 AOP，那么就会把代理对象放入 earlySingletonObjects 中，否则就是把原始对象放入 earlySingletonObjects，但是不管怎么样，就算是代理对象，代理对象所代理的原始对象也是没有经过完整生命周期的，所以放入 earlySingletonObjects 我们就可以统一认为是未经过完整生命周期的 bean singletonFactories：缓存的是一个 ObjectFactory，也就是一个 Lambda 表达式。在每个 Bean 的生成过程中，经过实例化得到一个原始对象后，都会提前基于原始对象暴露一个 Lambda 表达式，并保存到三级缓存中，这个 Lambda 表达式可能用到，也可能用不到，如果当前 bean 没有出现依赖循环，那么这个 Lambda 表达式没用，当前 bean 按照自己的生命周期正常执行，执行完后直接把当前 bean 放入 singletonObjects 中；如果当前 bean 在依赖注入时发现出现了依赖循环（当前正在创建的 bean 被其他 bean 依赖了），则从三级缓存中拿到 Lambda 表达式，并执行 Lambda 表达式得到一个对象，把得到的对象放入二级缓存（如果当前 Bean 需要 AOP，那么执行 Lambda 表达式，得到的就是对应的代理对象，如果无需 AOP，则直接得到一个原始对象） 其实还要一个缓存，就是 earlyProxyReferences，它用来记录某个原始对象是否进行过 AOP 的]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 之依赖注入]]></title>
    <url>%2FCKING.github.io%2F2022%2F02%2F07%2FSpring-%E4%B9%8B%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[Spring 的依赖注入方式Spring 中主要有两种注入方式： 手动注入 自动注入 手动注入在 XML 中定义 Bean 时，就是手动注入，因为是程序员手动给某个属性指定了值，如下： 12345&lt;bean name="orderService" class="com.zhouyu.service.OrderService"/&gt;&lt;bean name="userService" class="com.zhouyu.service.UserService"&gt; &lt;property name="orderService" ref="orderService"/&gt;&lt;/bean&gt; 上面是通过 set 方法进行注入的 12345&lt;bean name="orderService" class="com.zhouyu.service.OrderService"/&gt;&lt;bean name="userService" class="com.zhouyu.service.UserService"&gt; &lt;constructor-arg index="0" ref="orderService"/&gt;&lt;/bean&gt; 上面这种底层是通过构造方法进行注入 所以手动注入的底层也就是分为两种： set 方法注入 构造方法注入 自动注入自动注入又分为两种： XML 的 autowire 自动注入 @Autowired 注解的自动注入 XML 的 autowire 自动注入在 XML 中，我们可以定义一个 Bean 时去指定这个 Bean 的自动注入模式： byType byName constructor default no 比如： 12&lt;bean name="userService" class="com.zhouyu.service.UserService" autowire="byType"&gt;&lt;/bean&gt; 这么写，表示 Spring 会自动的给 userService 中所有属性自动赋值（不需要这个属性上有 @Autowired 注解，但需要这个属性有对应的 set 方法） 在创建 Bean 的过程中，在填充属性时，Spring 会去解析当前类，把当前类的所有方法都解析出来，Spring 会去解析每个方法得到对应的 PropertyDescriptor 对象，PropertyDescriptor 中有几个属性 name：这个 name 并不是方法的名字，而是哪方法名字进行处理后的名字 如果方法名字以 “get” 开头，比如 “getXXX”，那么 name = XXX 如果方法名字以 “is” 开头，比如 “isXXX”，那么 name = XXX 如果方法名字以 “set” 开头，比如 “setXXX”，那么 name = XXX readMethodRef：表示 get 方法的 Method 对象的引用 readMethodName：表示 get 方法的名字 writeMethodRef：表示 set 方法的 Method 对象的引用 writeMethodName：表示 set 方法的名字 propertyTypeRef：如果有 get 方法，那么对应的就是返回值的类型；如果是 set 方法，那么对应的就是 set 方法中唯一参数的类型 get 方法的定义是：方法参数个数为 0 个，并且方法名字以 “get” 开头或者名字以 “is” 开头并且方法的返回类型为 boolean set 方法的定义是：方法参数个数为 1 个，并且方法名字以 “set” 开头并且方法返回类型为 void 所以，Spring 通过 byName 的自动填充属性时流程是： 找到所有 set 方法所对应的 XXX 部分的名字 根据 XXX 部分的名字去获取 bean 而 Spring 通过 byType 的自动填充属性时流程是： 获取到 set 方法中的唯一参数的类型参数，并且根据该类型去容器中获取 bean 如果找到多个，会报错 constructor 表示通过构造方法注入。如果是 constructor，那么久流可以不写 set 方法，当某个 bean 是通过构造方法注入时，Spring 利用构造方法的参数信息从 Spring 容器中去找 bean，找到 bean 之后作为参数传给构造方法，从而实例化得到一个 bean 对象，并完成属性赋值（属性赋值的代码得程序员来写） 另外两个： no，表示关闭 autowire default，表示默认值。我们演示的是某个 bean 的 autowire，但是也可以直接在 &lt;beans&gt; 标签中设置 autowire。如果设置了，那么 &lt;bean&gt; 标签中设置的 autowire 如果为 default，那么则会用 &lt;beans&gt; 标签中设置的 autowire @Autowired 注解则相当于 XML 中的 autowire 属性的注解方式的替代。它提供了与 autowire 相同的功能，但是拥有更细粒度的控制和更广泛的适用性 XML 中的 autowire 控制的是整个 bean 的所有属性，而 @Autowired 注解是直接写在某个属性、某个 set 方法、某个构造方法。同时，@Autowired 注解还可以控制，哪些属性想被自动注入，哪些属性不想，这也是细粒度的控制 但是 @Autowired 无法区分 byType 和 byName，@Autowired 是先 byType，如果找到多个则 byName 所以 XML 的自动注入底层其实也就是： set 方法注入 构造方法注入 @Autowired 注解的自动注入 @Autowired 注解，是 byType 和 byName 的结合。@Autowired 注解可以写在： 属性上：先根据属性类型去找 Bean，如果找到多个再根据属性名确定一个 构造方法上：先根据方法参数类型去找 Bean，如果找到多个再根据参数名确定一个 set 方法上：先根据方法参数类型去找 Bean，如果找到多个再根据参数名确定一个 寻找注入点在创建一个 Bean 的过程中，Spring 会利用 AutowiredAnnotationBeanPostProcessor 的 postProcessMergeBeanDefinition() 找出注入点并缓存，找注入点的流程为： 遍历当前类的所有属性字段 Field 查看字段上是否存在 @Autowired、@Value、@Inject 中的其中任意一个，存在则认为该字段是一个注入点 如果字段是 static，则不进行注入 获取 @Autowired 的 required 属性的值 将字段信息构造成一个 AutowiredFieldElement 对象，作为一个注入点对象添加到 currElements 集合中 遍历当前类中所有 Method 判断当前 Method 是否是桥接方法，如果是找到原方法 查看方法上是否存在 @Autowired、@Value、@Inject 中的其中任意一个，存在则认为该字段是一个注入点 如果方法是 static，则不进行注入 获取 @Autowired 的 required 属性的值 将方法信息构造成一个 AutowiredMethodElement 对象，作为一个注入点对象添加到 currElements 集合中 遍历完当前类的字段和方法后，将遍历父类，直到没有父类 最后将 currElements 集合封装成一个 InjectMetadata 对象，作为当前 Bean 对应的注入点集合对象，并缓存 static 字段或方法为什么不支持1234@Component@Scope("prototype")public class OrderService &#123;&#125; 1234567891011@Component@Scope("prototype")public class UserService &#123; @Autowired private static OrderService orderService; public void test() &#123; System.out.println("test123"); &#125;&#125; 如上代码，UserService 和 OrderService 都是原型 Bean，假设 Spring 支持 static 字段进行自动注入，那么现在调用两次 12UserService userService1 = (UserService) applicationContext.getBean("userService");UserService userService2 = (UserService) applicationContext.getBean("userService"); 此时 userService1 的 orderService 值还是它自己注入的值吗？不是。一旦 userService2 创建好了之后，static orderService 字段的值就发生了修改，从而出现 bug 桥接方法1234public interface UserInterface &lt;T&gt;&#123; void setOrderService(T t);&#125; 123456789101112131415@Componentpublic class UserService implements UserInterface&lt;OrderService&gt; &#123; private OrderService orderService; public void test() &#123; System.out.println("test123"); &#125; @Override @Autowired public void setOrderService(OrderService orderService) &#123; this.orderService = orderService; &#125;&#125; UserService 对应的字节码为： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// class version 52.0 (52)// access flags 0x21// signature Ljava/lang/Object;Lcom/test/service/UserInterface&lt;Lcom/test/service/OrderService;&gt;;// declaration: com/test/service/UserService implements com.test.service.UserInterface&lt;com.test.service.OrderService&gt;public class com/test/service/UserService implements com/test/service/UserInterface &#123; // compiled from: UserService.java @Lorg/springframework/stereotype/Component;() // access flags 0x2 private Lcom/test/service/OrderService; orderService // access flags 0x1 public &lt;init&gt;()V L0 LINENUMBER 11 L0 ALOAD 0 INVOKESPECIAL java/lang/Object.&lt;init&gt; ()V RETURN L1 LOCALVARIABLE this Lcom/test/service/UserService; L0 L1 0 MAXSTACK = 1 MAXLOCALS = 1 // access flags 0x1 public test()V L0 LINENUMBER 16 L0 GETSTATIC java/lang/System.out : Ljava/io/PrintStream; LDC "test123" INVOKEVIRTUAL java/io/PrintStream.println (Ljava/lang/String;)V L1 LINENUMBER 17 L1 RETURN L2 LOCALVARIABLE this Lcom/test/service/UserService; L0 L2 0 MAXSTACK = 2 MAXLOCALS = 1 // access flags 0x1 public setOrderService(Lcom/test/service/OrderService;)V @Lorg/springframework/beans/factory/annotation/Autowired;() L0 LINENUMBER 22 L0 ALOAD 0 ALOAD 1 PUTFIELD com/test/service/UserService.orderService : Lcom/test/service/OrderService; L1 LINENUMBER 23 L1 RETURN L2 LOCALVARIABLE this Lcom/test/service/UserService; L0 L2 0 LOCALVARIABLE orderService Lcom/test/service/OrderService; L0 L2 1 MAXSTACK = 2 MAXLOCALS = 2 // access flags 0x1041 public synthetic bridge setOrderService(Ljava/lang/Object;)V @Lorg/springframework/beans/factory/annotation/Autowired;() L0 LINENUMBER 10 L0 ALOAD 0 ALOAD 1 CHECKCAST com/test/service/OrderService INVOKEVIRTUAL com/test/service/UserService.setOrderService (Lcom/test/service/OrderService;)V RETURN L1 LOCALVARIABLE this Lcom/test/service/UserService; L0 L1 0 MAXSTACK = 2 MAXLOCALS = 2&#125; 可以看到在 UserService 的字节码中有两个 setOrderService 方法： public setOrderService(Lcom/test/service/OrderService;)V public synthetic bridge setOrderService(Ljava/lang/Object;)V 并且都是存在 @Autowired 注解的。所以在 Spring 中需要处理这种情况，当遍历到桥接方法时，得找到原方法 注入点进行注入Spring 在 AutowiredAnnotationBeanPostProcessor 的 postProcessProperties() 方法中，会遍历所找到的注入点依次进行注入 字段注入 遍历所有的 AutowiredFieldElement 对象 将对应的字段封装为 DependencyDescriptor 对象 调用 BeanFactory 的 resolveDependency() 方法，传入 DependencyDescriptor 对象，进行依赖查找，找到当前字段所匹配的 Bean 对象 将 DependencyDescriptor 对象和所找到的结果对象 beanName 封装成一个 ShortcutDependencyDescriptor 对象作为缓存。例如如果当前 Bean 是原型 Bean，那么下次再来创建该 Bean 时，就可以直接拿缓存的结果对象 beanName 去 BeanFactory 中去拿 Bean 对象了，不用再次进行查找了 利用反射将结果对象赋值给字段 Set 方法注入 遍历所有的 AutowiredMethodElement 对象 遍历将对应的方法的参数，将每个参数都封装成 MethodParameter 对象 将 MethodParameter 对象封装为 DependencyDescriptor 对象 调用 BeanFactory 的 resolveDependency() 方法，传入 DependencyDescriptor 对象，进行依赖查找，找到当前方法参数所匹配的 Bean 对象 将 DependencyDescriptor 对象和所找到的结果对象 beanName 封装成一个 ShortcutDependencyDescriptor 对象作为缓存。例如如果当前 Bean 是原型 Bean，那么下次再来创建该 Bean 时，就可以直接拿缓存的结果对象 beanName 去 BeanFactory 中去拿 Bean 对象了，不用再次进行查找了 利用反射将找到的所有结果对象传给当前方法，并执行 resolveDependency该方法表示，传入一个依赖描述（DependencyDescriptor），该方法会根据该依赖描述从 BeanFactory 中找出对应的唯一的一个 Bean 对象。具体流程图如下： findAutowireCandidates() 实现 找出 BeanFactory 中类型为 type 的所有的 Bean 的名字，注意是名字，而不是 Bean 对象，因为我们可以根据 BeanDefinition 就能判断当前 type 是不是匹配，不用生成 Bean 对象 把 resolvableDependencies 中 key 为 type 的对象找出来并添加到 result 中。resolvableDependencies 中存放的类型是 Bean 对象。比如 &lt;BeanFactory.class : BeanFactory 对象&gt;，在 Spring 启动时设置 遍历根据 type 找出的 beanName，判断当前 beanName 对应的 Bean 是不是能够被自动注入 先判断 beanName 对应的 BeanDefinition 中的 autowireCandidate 属性，如果为 false，表示不能用来进行自动注入，如果为 true 则继续进行判断 判断当前 type 是不是泛型，如果是泛型是会把容器中所有的 beanName 找出来。如果是这种情况，那么在这一步就要获取到泛型的真正类型，然后进行匹配，如果当前 beanName 和当前泛型对应的真实类型匹配，那么则继续判断 如果当前 DependencyDescriptor 上存在 @Qualifier 注解，那么则要判断当前 beanName 上是否定义了 Qualifer，并且是否和当前 DependencyDescriptor 上的 Qualifer 相等，相等则匹配 经过上述验证之后，当前 beanName才能成为一个可注入的，添加到 result 中 底层流程图如下： 对应的执行图为：]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bean 的生命周期]]></title>
    <url>%2FCKING.github.io%2F2022%2F01%2F28%2FBean-%E7%9A%84%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%2F</url>
    <content type="text"><![CDATA[Bean 的生成过程生成 BeanDefinitionSpring 启动的时候会进行扫描，会先调用 org.springframework.context.annotation.ClasspathScaningCandidateComponentProvider#scanCandidateComponents(String basePackage) 扫描某个包路径，并得到 BeanDefinition 的 Set 集合 Spring 的扫描流程如下： 首先，通过 ResourcePatternResolver 获得指定包路径下的所有 .class 文件（Spring 源码中将此文件包装成了 Resource 对象） 遍历每个 Resource 对象 利用 MetadataReaderFactory 解析 Resource 对象得到 MetadataReader（Spring 源码中MetadataReaderFactory 具体的实现类为 CachingMetadataReaderFactory，MetadataReader 的具体实现类为 SimpleMetadataReader） 利用 MetaDataReader 进行 ExcludeFilter 和 includeFilter，以及条件注解 @Conditional 的筛选 筛选通过后，基于 MetadataReader 生成 ScannerGenericBeanDefinition 在基于 MetadataReader 判断对应的类是不是接口或抽象类 如果筛选通过，那么就表示扫描到了一个 Bean，将 ScannerGenericBeanDefinition 加入结果集 MetadataReader表示类的元数据读取器，主要包含了一个AnnotationMetadata，功能有 获取类的名字、 获取父类的名字 获取所实现的所有接口名 获取所有内部类的名字 判断是不是抽象类 判断是不是接口 判断是不是一个注解 获取拥有某个注解的方法集合 获取类上添加的所有注解信息 获取类上添加的所有注解类型集合 值得注意的是，CachingMetadataReaderFactory 解析某个 .class 文件得到 MetadataReader 对象是利用的 ASM 技术，并没有加载这个类到 JVM。并且，最终得到的 ScannerGenericBeanDefinition 对象，beanClass 属性存储的是当前类的名字，而不是 class 对象 最后，上面说的是通过扫描得到的 BeanDefinition 对象，我们还可以通过直接定义 BeanDefinition，或解析 spring.xml 文件的 ，或者 @Bean 注解的 BeanDefinition 合并 BeanDefinition通过扫描得到所有 BeanDefinition 之后，就可以根据 BeanDefinition 创建 Bean 对象了，但是 Spring 中支持父子 BeanDefinition，和 Java 父子类类似，但是完全不是一回事 父子 BeanDefinition 实际用的比较少，使用如下： 12&lt;bean id="parent" class="com.zhouyu.service.Parent" scope="prototype"/&gt;&lt;bean id="child" class="com.zhouyu.service.Child"/&gt; 上面情况下，child 是单例 Bean 12&lt;bean id="parent" class="com.zhouyu.service.Parent" scope="prototype"/&gt;&lt;bean id="child" class="com.zhouyu.service.Child" parent="parent"/&gt; 上面情况下，child 就是原型 Bean 因为 child 的父 BeanDefinition 是 parent，所以会继承 parent 上所定义的 scope 属性 而在根据 child 生成 Bean 对象之前，需要进行 BeanDefinition 的合并，得到完整的 child 的 BeanDefinition 加载类BeanDefinition 合并之后，就可以去创建 Bean 对象了，而创建 Bean 对象就必须实例化对象，而实例化就必须先加载当前 BeanDefinition 所对应的 class，在 AbstractAutowireCapableBeanFactory 类的 createBean() 方法中，一开始就会调用 1Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); 这行代码就是去加载类的，实现如下： 12345678910111213// 如果beanClass被加载了if (mbd.hasBeanClass()) &#123; return mbd.getBeanClass();&#125;// 如果beanClass没有被加载if (System.getSecurityManager() != null) &#123; return AccessController.doPrivileged((PrivilegedExceptionAction&lt;Class&lt;?&gt;&gt;) () -&gt; doResolveBeanClass(mbd, typesToMatch), getAccessControlContext());&#125;else &#123; return doResolveBeanClass(mbd, typesToMatch);&#125; 123public boolean hasBeanClass() &#123; return (this.beanClass instanceof Class);&#125; 如果 beanClass 属性的类型是 Class，那么就直接返回，如果不是，则会根据类名进行加载 ClassUtils.getDefaultClassLoader() 优先返回当前线程中的 ClassLoader 线程中类加载器为 null 的情况下，返回 ClassUtils 类的类加载器 如果 ClassUtils 类的类加载器为空，那么则表示是 Bootstrap 类加载器的 ClassUtils 类，那么则返回系统类加载器 实例化前当前 BeanDefinition 对应的类成功加载后，就可以实例化对象了。但是在 Spring 中，实例化对象之前，Spring 提供了一个扩展点，允许用户来控制是否在某个或某些 Bean 实例化之前做一些启动动作，这个扩展点叫 InstantiationAwareBeanPostProcessor.postProcessBeforeInstantiation()，比如： 1234567891011@Componentpublic class TestBeanPostProcessor implements InstantiationAwareBeanPostProcessor &#123; @Override public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; if("userService".equals(beanName)) &#123; System.out.println("实例化前"); &#125; return null; &#125;&#125; 如上代码会导致，在 UserService 这个 Bean 实例化前，会进行打印 值得注意的是，postProcessBeforeInstantiation() 是有返回值的，如果这么实现： 123456789101112@Componentpublic class TestBeanPostProcessor implements InstantiationAwareBeanPostProcessor &#123; @Override public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; if("userService".equals(beanName)) &#123; System.out.println("实例化前"); return new UserService(); &#125; return null; &#125;&#125; userService 这个 Bean，在实例化前会直接返回一个由我们所定义的 UserService 对象。如果是这样，表示不需要 Spring 来实例化了，并且后续的 Spring 依赖注入也不会进行了，会跳过一些步骤，直接执行初始化这一步 实例化这个步骤中，会根据 BeanDefinition 去创建一个对象了 Supplier 创建对象首先判断 BeanDefinition 是否设置了 Supplier，如果设置了则调用 Supplier 的 get() 得到对象。我们可以直接使用 BeanDefinition 对象来设置 Supplier，比如： 123456789AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.genericBeanDefinition().getBeanDefinition();beanDefinition.setInstanceSupplier(new Supplier&lt;Object&gt;() &#123; @Override public Object get() &#123; return new UserService(); &#125;&#125;);context.registerBeanDefinition("userService", beanDefinition); 工厂方法创建对象如果没有设置 Supplier，则检查 BeanDefinition 中是否设置了 factoryMethod，也就是工厂方法，有两种方式可以设置 factoryMethod，比如： 方式一： 1&lt;bean id="userService" class="com.test.service.UserService" factory-method="createUserService" /&gt; 对应的 UserService 类为： 12345678public class UserService &#123; public static UserService createUserService() &#123; System.out.println("执行createUserService()"); UserService userService = new UserService(); return userService; &#125;&#125; 方式二： 12&lt;bean id="commonService" class="com.test.service.CommonService"/&gt;&lt;bean id="userService1" factory-bean="commonService" factory-method="createUserService"/&gt; 对应的 CommonService 的类为： 123456public class CommonService &#123; public UserService createUserService() &#123; return new UserService(); &#125;&#125; Spring 发现当前 BeanDefinition 方法设置了工厂方法后，就会区分这两种方式，然后调用工厂方法得到对象 另外，我们通过 @Bean 所定义的 BeanDefinition，是存在 factoryMethod 和 FactoryBean 的，也就是和上面的方式二非常类似，@Bean 所注解的方法就是 factoryMethod，AppConfig 对象就是 FactoryBean。如果 @Bean 所注解的方法是 static，那么对应的就是方式一 123456789@ComponentScan("com.test")public class AppConfig &#123; @Bean public UserService userService() &#123; return new UserService(); &#125;&#125; 推断构造方法这个之前已经讲过原理了。推断完构造方法后，就会使用构造方法来进行实例化了 另外，在推断构造方法逻辑中除了会去选择构造方法以及查找入参对象外，还会判断是否在对应的类中使用 @Lookup 注解方法。如果存在则把方法封装为 LookupOverride 对象并添加到 BeanDefinition 中 在实例化时，如果判断出当前 BeanDefinition 中没有 LookupOverride，那就直接用构造方法反射得到一个实例对象。如果存在 LookupOverride 对象，即类中存在 @Lookup 注解的方法，那就会生成一个代理对象 1234567891011121314151617@Componentpublic class UserService &#123; public void test() &#123; System.out.println(createOrderService()); &#125; @Lookup public OrderService createOrderService() &#123; return null; &#125;&#125;@Componentpublic class OrderService &#123;&#125; BeanDefinition 的后置处理Bean 对象实例化出来后，接下来就要给对象的属性赋值了。在真正给属性赋值之前，Spring 又提供了一个扩展点 MergedBeanDefinitionPostProcessor.postProcessMergedBeanDefinition()，可以对此时的 BeanDefinition 进行加工，如下： 1234567891011@Componentpublic class TestMergeBeanDefinitionPostProcessor implements MergedBeanDefinitionPostProcessor &#123; @Override public void postProcessMergedBeanDefinition(RootBeanDefinition beanDefinition, Class&lt;?&gt; beanType, String beanName) &#123; if("userService".equals(beanName)) &#123; beanDefinition.getPropertyValues().add("orderService", new OrderService()); &#125; &#125;&#125; 在 Spring 源码中，AutowiredAnnotationBeanPostProcessor 就是一个 MergeBeanDefinitionProcessor，它的 postProcessorMergeBeanDefinition() 中会去查找注入点，并缓存再 AutowiredAnnotationBeanPostProcessor 对象的一个 Map 中 实例化后在处理完 BeanDefinition 后，Spring 又设计了一个扩展点：InstantiationAwareBeanPostProcessor.postProcessAfterInstantiation()，比如： 12345678910111213@Componentpublic class TestBeanPostProcessor implements InstantiationAwareBeanPostProcessor &#123; @Override public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException &#123; if("userService".equals(beanName)) &#123; System.out.println("实例化后"); UserService userService = (UserService) bean; userService.test(); &#125; return true; &#125;&#125; 上述代码就是对 userService 所实例化出来的对象进行处理。这个扩展点，在 Spring 源码中基本没怎么使用 自动注入这里就是依赖注入，自动注入 bean 中的属性 处理属性这个步骤，就会处理 @Autowired、@Resource、@Value 等注解，也是通过 InstantiationAwareBeanPostProcessor.postProcessProperties() 扩展点来实现的，比如我们可以实现一个自动注入的功能。如下 123456789101112131415161718192021@Componentpublic class TestBeanPostProcessor implements InstantiationAwareBeanPostProcessor &#123; @Override public PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) throws BeansException &#123; if("userService".equals(beanName)) &#123; for(Field field : bean.getClass().getFields()) &#123; if(field.isAnnotationPresent(TestInject.class)) &#123; field.setAccessible(true); try &#123; field.set(bean, "123"); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; return pvs; &#125;&#125; 执行 Aware完成属性赋值之后，Spring 就会执行一些回调，包括： BeanNameAware：回传 beanName 给 bean 对象 beanClassLoaderAware：回传 ClassLoader 给 bean 对象 BeanFactoryAware：回传 BeanFactory 给对象 12345678910111213141516private void invokeAwareMethods(String beanName, Object bean) &#123; if (bean instanceof Aware) &#123; if (bean instanceof BeanNameAware) &#123; ((BeanNameAware) bean).setBeanName(beanName); &#125; if (bean instanceof BeanClassLoaderAware) &#123; ClassLoader bcl = getBeanClassLoader(); if (bcl != null) &#123; ((BeanClassLoaderAware) bean).setBeanClassLoader(bcl); &#125; &#125; if (bean instanceof BeanFactoryAware) &#123; ((BeanFactoryAware) bean).setBeanFactory(AbstractAutowireCapableBeanFactory.this); &#125; &#125;&#125; 初始化前初始化前，也是 Spring 提供的一个扩展点：BeanPostProcessor.postProcessBeforeInitialization()，比如： 1234567891011@Componentpublic class TestBeanPostProcessor implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if("userService".equals(beanName)) &#123; System.out.println("初始化前"); &#125; return bean; &#125;&#125; 利用初始化前，可以对进行了依赖注入的 Bean 进行处理 在 spring 源码中，InitDestroyAnnotationBeanPostProcessor 会在初始化前这个步骤中执行 @PostConstruct 方法；而 ApplicationContextAwareProcessor 会在初始化前这个步骤中进行其他 Aware 的回调 初始化初始化主要进行以下行为： 查看当前 bean 对象是否实现了 InitializingBean 接口，如果实现了就调用其 afterPropertiesSet() 方法 执行 BeanDefinition 中指定的初始化方法 初始化后这是 Bean 创建生命周期的最后一个步骤，也是 Spring 提供的一个扩展点：BeanPostProcessor.postProcessAfterInitialization()，比如： 1234567891011@Componentpublic class TestBeanPostProcessor implements BeanPostProcessor &#123; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if("userService".equals(beanName)) &#123; System.out.println("初始化后"); &#125; return bean; &#125;&#125; 我们可以在这个步骤中，对 Bean 进行最终处理，Spring 中的 AOP 就是基于初始化后实现的，初始化后返回的对象才是最终的 Bean 对象]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka 之请求处理]]></title>
    <url>%2FCKING.github.io%2F2022%2F01%2F27%2FKafka-%E4%B9%8B%E8%AF%B7%E6%B1%82%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[无论是 Kafka 客户端还是 Broker 端，它们之间的交互都是通过「请求 / 响应」的方式完成的。比如，客户端会通过网络发送消息生产请求给 Broker，而 Broker 处理完成后，会发送对应的响应给客户端 Apache Kafka 自己定义了一组请求协议，用于实现各种各样的交互操作。比如常见的 PORDUCE 请求用于生产消息，FETCH 请求用于消费信息，METADATA 请求用于请求 KAFKA 集群元数据信息的 总之，Kafka 定义了很多类似的请求格式。所有的请求格式都是通过 TCP 网络以 Socket 的方式进行通讯的 今天，我们就来讨论一下 Kafka Broker 端处理请求的全流程 关于如何处理请求，很容易想到的方案有两个 1、顺序处理请求。如果写成伪代码，大概是这样： 1234while(true) &#123; Request request = accept(connection); handle(request)&#125; 这个方法很简单，但是有个致命的缺陷，那就是吞吐量太差。由于只能顺序处理每个请求，因此，每个请求都必须等待前一个请求处理完毕才能得到处理。这种方式只适用于请求发送非常不频繁的系统 2、每个请求使用单独线程处理。即，我们为每个入站请求都创建一个新的线程来异步处理。伪代码如下： 1234567while(true) &#123; Request request = accept(connection); Thread thread = new Thread(() -&gt; &#123; handle(request); &#125;); thread.start();&#125; 这种方式完全采用异步的方式。系统会每个入站请求都创建单独的线程来处理。这个方法的好处是，它是完全异步的，每个请求的处理都不会阻塞下一个请求。但缺陷也同样明显，为每个请求都创建线程的做法开销极大，在某些场景下甚至会压垮整个服务。因此，这个方式只适用于请求发送频率很低的业务 因为这两种方案都不好，所以 Broker 使用的是 Reactor 模式 Reactor 模式是事件驱动架构的一种实现方式，特别适合应用于处理多个客户端并发向服务器端发送请求的场景。Reactor 模式的架构如下图所示： 从上图可以知道，多个客户端会发送请求给 Reactor。Reactor 有个请求分发线程 Dispatcher，也就是图中的 Acceptor，它会将不同的请求下发到多个工作线程中处理 这个架构中，Acceptor 线程只是用于请求分发，不涉及具体的逻辑处理，非常得轻量级，因此有很高的吞吐量表现。而这些工作线程可以根据实际业务处理需要任意增减，从而动态调节系统负载能力 我们为 Kafka 画一张类似的图，如下： Kafka 的 Broker 端有个 SocketServer 组件，类似于 Reactor 模式中的 Dispatcher，它也有对应的 Acceptor 线程和一个工作线程池，只不过在 Kafka 中，这个过程线程池有个专属的名称，叫网络线程池。Kafka 提供了 Broker 端参数 num.network.threads，用于调整该网络线程池的线程数，其默认值是 3，表示每台 Broker 启动时会创建 3 个网络线程，专门处理客户端发送的请求 Acceptor 线程采用轮询的方式将入站请求公平地发到所有网络线程中，因此，在实际使用过程中，这些线程通常都有几率被分配到待处理请求，这种轮询策略编写简单，同时也避免了请求处理的倾斜，有利于实现较为公平的请求处理调度 现在，我们知道了客户端发来的请求会被 Broker 端的 Acceptor 线程分发到任意一个网络线程中，由它们来处理。那么，当网络线程接收到请求后，它是怎么处理的？实际上，Kafka 在这个环节又做了一层异步线程池的处理，如下图： 当网络线程拿到请求后，它不是自己处理，而是将请求放入到一个共享请求队列中。Broker 端还有个 IO 线程池，负责从该队列中取出请求，执行真正的处理。如果是 PRODUCE 生产请求，则将消息写入到底层的磁盘日志中；如果是 FETCH 请求，则从磁盘或页缓存中读取消息 IO 线程池中才是执行请求逻辑的线程。Broker 端参数 num.io.threads 控制了这个线程池中的线程数。目前该参数默认值是 8，表示每台 Broker 启动后自动创建 8 个 IO 线程的处理请求。你可以根据实际硬件条件设置次线程池的个数 如果你的机器上 CPU 资源非常充裕，完全可以调大该参数，允许更多的并发请求被同时处理。当 IO 线程处理完请求后，会将生成的响应发送到网络线程池的响应队列中，然后由对应的网络线程负责将 Response 返还给客户端 通过上图我们还知道了请求队列和响应队列的差别：请求队列是所有网络线程共享的。而响应队列则是每个网络线程专属的。这么设计的原因在于，Dispatcher 只是用于请求分发而不负责回传，因此只能让每个网络线程自己发送 Response 给客户端，所以这些 Response 也就没必要放在一个公共的地方 上图中还有一个叫 Purgatory 的组件，它是用来缓存延时请求的。所谓延时请求，就是那些一时未满足条件不能立刻处理的请求。比如设置了 acks = all 的 PRODUCE 请求，一旦设置了 acks = all，那么该请求就必须等待 ISR 中所有副本都接收了消息后才能返回，此时该请求的 IO 线程就必须等待其他 Broker 的写入结果。当请求不能立刻处理，它就会暂存在 Purgatory 中。稍后一旦满足了完成条件，IO 线程就会继续处理该请求，并将 Response 放入对应网络线程的响应队列中 至此，Kafka 请求流程解析其实已经讲完了。接着我们再说点其他东西 目前为止，我提及的请求处理流程对于所有请求都是适用的，即，Kafka Broker 对所有请求是一视同仁的。但是，在 Kafka 内部，除了客户端发送的 PRODUCE 请求和 FETCH 请求之外，还有很多执行其他操作的请求类型，比如负责更新 Leader 副本、Follower 副本以及 ISR 集合的 LeaderAndIsr 请求，负责勒令副本下线的 StopReplica 请求等。与 PRODUCE 和 FETCH 请求相比，这些请求有个明显的不同：它们不是数据类的请求，而是控制类的请求。也就是说，它们不是操作消息数据的，而是用来执行特定的 Kafka 内部动作的 Kafka 把 PRODUCE 和 FETCH 这类请求称为数据类请求，把 LeaderAndIsr、StopReplica 这类请求称为控制类请求。所以，当前这种一视同仁的处理方式对控制类请求是不合理的。因为控制类请求可以直接令数据类请求失效 举个例子。假设我们有个主题只有 1 个分区，改分区设置了两个副本，其中 Leader 副本保存在 Broker 0 上，Follower 副本保存在 Broker 1 上。假设 Broker 0 这台机器积压了很多的 PRODUCE 请求，此时如果你使用 Kafka 命令强制将该主题分区的 Leader、Follower 角色互换，那么 Kafka 内部的控制组件（Controller）会发送 LeaderAndIsr 请求被 Broker 0，显式告诉它，当前它不再是 Leader，而是 Follower 了，而 Broker 1 上的 Follower 副本以为被选为新的 Leader，因此停止向 Broker 0 拉取消息 这是，一个尴尬的场面就出现了，如果刚才积压的 PRODUCE 请求都设置了 acks = all，那么这些在 LeaderAndIsr 发送之前的请求都无法正常完成了。就想前面说的，它们会被暂存在 Purgatory 中不断重试，直到最终请求超时返回给客户端 设想一下，如果 Kafka 能够优先处理 LeaderAndIsr 请求，Broker 0 就会立刻抛出 NOT_LEADER_FOR_PARTITION 异常，快速地标识这些积压 PRODUCE 请求已失败，这样客户端不用等到 Purgatory 中的请求超时就能立刻感知，从而降低了请求的处理时间。即使 acks 不是 all，积压的 PRODUCE 请求能够成功写入 Leader 副本的日志，但处理 LeaderAndIsr 之后，Broker 0 上的 Leader 副本成为 Follower 副本，也要执行显式的日志截断（Log Truncation，即原 Leader 副本成为 Follower 后，会将之前写入但为提交的消息全部删除），依然做了很多无用功 再举个例子，同样是积压大量数据类请求的 Broker 上，当你删除主题时，Kafka 控制器向改 Broker 发送 StopReplica 请求。如果该请求不能及时处理，主题删除操作会一直 hang 住，从而增加了删除主题的延时 基于这些问题，社区于 2.3 版本正式实现了 数据类请求和控制类请求的分离。如何解决？很简单，社区完全拷贝了上图中的一套组件，实现了两类请求的分离。也就是说，Kafka Broker 启动后，会在后台分别创建网络线程池和 IO 线程池，它们分别处理数据类请求和控制类请求。至于所有的 Socket 端口，自然是使用不同的端口了，你需要提供不同的 listeners 配置，显式地指定哪套端口用于哪类请求]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微博的 Redis 实践]]></title>
    <url>%2FCKING.github.io%2F2022%2F01%2F25%2F%E5%BE%AE%E5%8D%9A%E7%9A%84-Redis-%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[微博的业务有很多，例如让红包飞活动、粉丝数、用户数、音乐榜单等。同时，这些业务面临的用户体量非常大，业务使用 Redis 存取的数据量经常会达到 TB 级别。作为直接面向终端用户的应用，微博用户的业务体验至关重要，这些都需要技术的支持。我们总结下微博对 Redis 的技术需求： 能够提供高性能、高并发的读写访问，保证读写延迟低 能够支持大容量存储 可以灵活扩展，对于不同业务能进行快速扩容 因此，微博对 Redis 自身做了一些改进 微博对 Redis 的基本改进微博对于 Redis 的基本改进可以分成两类：避免阻塞和节省内存 首先，针对持久化需求，他们使用了全量 RDB 加增量 AOF 复制结合的机制，这就避免了数据可靠性或性能降低的问题。当然，Redis 在官方 4.0 以后，也增加了混合使用 RDB 和 AOF 的机制 其次，在 AOF 日志写入刷盘时，用额外的 BIO 线程负责实际的刷盘工作，这可以避免 AOF 日志慢速刷盘阻塞主线程的问题 再次，增加了 aofnumber 配置项。这个配置项可以设置 AOF 文件的数量，控制 AOF 写盘时的总文件量，避免了写入过多的 AOF 日志文件导致的磁盘写满问题 最后，在主从复制机制上，使用独立的复制线程进行主从库同步，避免对主线程的阻塞影响 在节省内存方面，微博有一个典型的优化，就是定制化数据结构 在使用 Redis 缓存用户的关注列表时，针对关注列表的存储，他们定制化设计了 LongSet 数据类型。这个数据类型是一个存储 Long 类型元素的集合，它的底层数据结构是一个 Hash 数组，在设计 LongSet 类型之前，微博是用 Hash 集合类型来保存用户关注列表，但是，Hash 集合类型在保存大量数据时，内存空间消耗很大 而且，当缓存的关注列表被从 Redis 中淘汰时， 缓存实例需要从后台数据库中读取用户关注列表，在用 HMSET 写入 Hash 集合，在并发请求压力大的场景下，这个过程会降低缓存性能。跟 Hash 集合相比，LongSet 类型底层使用 Hash 数组保存数据，既避免了 Hash 表较多的指针开销，节省内存，也可以实现快速存储 对此，总结了两个经验： 第一个经验是：高性能和省内存始终都是应用 Redis 要关注的重点，这和 Redis 在整个业务系统中的位置是密切相关的 Redis 通常是作为缓存再数据库层前端部署，就需要能够快速地返回结果。另外，Redis 使用内存保存数据，一方面带来了访问速度快的优势；另一方面，也让我们在运维时需要特别关注内存优化 第二个经验是，在实际应用中需要基于 Redis 做定制化工作或二次开发，来满足一些特殊场景的需求，就像微博定制化数据结构 除了这些改进工作，为了满足大容量存储需求，他们还把 RocksDB 和 磁盘结合起来使用，以扩大单实例的容量 微博如何应对大容量数据存储需求？微博业务要保存的数据经常会达到 TB 级别，这就需要扩大 Redis 实例的存储容量了 针对这个需求，微博对数据区分冷热度，把热数据保留在 Redis 中，而把冷数据通过 RocksDB 写入底层的硬盘 在微博的业务场景中，冷热数据是比较常见的。比如，有些微博话题刚发生时，热度非常高，会有海量的用户访问这些话题，使用 Redis 服务用户请求就非常有必要 但是，等到话题热度过了以后，访问人数就会急剧下降，这些数据就变为冷数据了。这个时候，冷数据就可以从 Redis 迁移到 RocksDB，保存在硬盘中。这样一来，Redis 实例的内存就可以节省下来保存热数据，同时，单个实例能保存的数据量就由整个硬盘的大小来决定了。如下图： 从上图可以看到，Redis 是用异步线程在 RocksDB 中读写数据 读写 RocksDB 的延迟毕竟比不上 Redis 的内存访问延迟，这样做也是为了避免读写冷数据时，阻塞 Redis 主线程。至于冷数据在 SSD 上的布局和管理，都交给 RocksDB 负责 关于微博使用 RocksDB 和 SSD 进行扩容的优化工作，总结了两条经验： 首先，实现大容量的单实例在某些业务场景下还是有需求的。虽然我们可以使用切片集群的多实例分散保存数据，但是这种方法也会带来集群运维的开销，涉及到分布式系统的管理和维护。而且，切片集群的规模会受限，如果能增加单个实例的存储容量，那么，即使在使用较小规模的集群时，集群也能保存更多的数据 第二，如果想实现大容量的 Redis 实例，借助与 SSD 和 RocksDB 来实现是一个不错的方案。还有 360 开源的Pika，也是一个很好的参考 RocksDB 可以实现快读写入数据，同时使用内存缓存部分数据，也可以提供万级别的数据读取性能。而且，当前 SSD 的性能提升很快，单块 SSD 的盘级 IOPS 可以达到几十万级别。这些技术结合起来，Redis 就能够在提供大容量数据存储的同时，保持一定的读写性能]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 底层架构核心概念解析]]></title>
    <url>%2FCKING.github.io%2F2022%2F01%2F24%2FSpring-%E5%BA%95%E5%B1%82%E6%9E%B6%E6%9E%84%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[BeanDefinitionBeanDefinition 表示 Bean 定义，BeanDefinition 中存在很多属性用来描述一个 Bean 的特点，比如： class，表示 Bean 类型 scope，表示 Bean 作用域，单例或原型等 lazyInit：表示 Bean 是否是懒加载 initMethodName：表示 Bean 初始化要执行的方法 destroyMethodName：表示 Bean 销毁时要执行的方法 …… 在 Spring 中，我们经常会通过以下几种方式来定义 Bean： XML 配置 Bean @Bean @Component（@Service，@Controller） 这些，我们可以称之为声明式定义 Bean 我们还可以编程式定义 Bean，那就是直接通过 BeanDefinition，比如： 12345678AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);// 生成一个BeanDefinition 对象，并设置beanClass为User.class，并注册到ApplicationContext中AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.genericBeanDefinition().getBeanDefinition();beanDefinition.setBeanClass(User.class);context.registerBeanDefinition("user", beanDefinition);System.out.println(context.getBean("user")); 我们还可以通过 BeanDefinition 设置一个 Bean 的其他属性 123456// 设置作用域beanDefinition.setScope("prototype");// 设置初始化方法beanDefinition.setInitMethodName("init");// 设置懒加载beanDefinition.setLazyInit(true); 和声明式、编程式事务类似，通过 ，@Bean，@Component 等声明式方式所定义的 Bean，最终都会被 Spring 解析为对应的 BeanDefinition 对象，并放在 Spring 容器中 BeanDefinitionReader接着我们介绍几种在 Spring 源码中所提供的 BeanDefinition 读取器（BeanDefinitionReader），这些 BeanDefinitionReader 在我们使用 Spring 时用得少，但在 Spring 源码中用的多，相当于 Spring 源码的基础设施 AnnotatedBeanDefinitionReader可以直接把某个类转换为 BeanDefinition，并且会解析该类上的注解，比如 12345678AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);AnnotatedBeanDefinitionReader annotatedBeanDefinitionReader = new AnnotatedBeanDefinitionReader(context);// 将User.class解析为BeanDefinitionannotatedBeanDefinitionReader.register(User.class);System.out.println(context.getBean("user")); 它能解析的注解是：@Conditional、@Scope、@Lazy、@Primary、@DependsOn、@Role、@Description XMLBeanDefinitionReader可以解析 标签 123456AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);XmlBeanDefinitionReader xmlBeanDefinitionReader = new XmlBeanDefinitionReader(context);int i = xmlBeanDefinitionReader.loadBeanDefinitions("spring.xml");System.out.println(context.getBean("user")); ClassPathBeanDefinitionScannerClassPathBeanDefinitionScanner 是扫描器，但是它的作用和 BeanDefinitionReader 类似，可以进行扫描，扫描某个包路径，对扫描到的类进行解析，比如，扫描到的类上如果存在 @Component 注解，那么就会把这个类解析为一个 BeanDefinition，比如： 1234567AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext();context.refresh();ClassPathBeanDefinitionScanner scanner = new ClassPathBeanDefinitionScanner(context);scanner.scan("com.test");System.out.println(context.getBean("userService")); BeanFactoryBeanFactory 表示 Bean 工厂，所以，BeanFactory 会负责创建 Bean，并且提供获取 Bean 的 API 而 ApplicationContext 是 BeanFactory 的一种，在 Spring 源码中，是这么定义的： 12345public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver &#123; ...&#125; 首先，在 Java 中，接口是可以多继承的，我们发现 ApplicationContext 继承了 ListableBeanFactory 和 HierarchicalBeanFactory，而 ListableBeanFactory 和 HierarchicalBeanFactory 都继承至 BeanFactory，所以我们可以认为 ApplicationContext 继承了 BeanFactory，相当于苹果继承了水果，宝马继承汽车一样，ApplicationContext 也是 BeanFactory 的一种，拥有 BeanFactory 支持的所有功能，不过 ApplicationContext 比 BeanFactory 更加强大，因为 ApplicationContext 还继承了其他接口，拥有其他功能 在 Spring 的源码实现中，当我们 new 一个 ApplicationContext 时，其底层会 new 一个 BeanFactory 出来，当使用 ApplicationContext 的某些方法时，比如 getBean()，底层调用的是 BeanFactory 的 getBean() 方法 在 Spring 源码中，BeanFactory 接口存在一个非常重要的实现类：DefaultListableBeanFactory，也是非常核心的。所以，我们可以直接来使用 DefaultListableBeanFactory，而不用使用 ApplicationContext 的某个实现类，比如 12345678DefaultListableBeanFactory beanFactory = new DefaultListableBeanFactory();AbstractBeanDefinition beanDefinition = BeanDefinitionBuilder.genericBeanDefinition().getBeanDefinition();beanDefinition.setBeanClass(User.class);beanFactory.registerBeanDefinition("user", beanDefinition);System.out.println(beanFactory.getBean("user")); DefaultListableBeanFactory 是非常强大的，支持很多功能，可以通过查看 DefaultListableBeanFactory 的类继承实现结构来看 它实现了很多接口，表示它拥有很多功能： AliasRegistry：支持别名功能，一个名字可以对应多个别名 BeanDefinitionRegistry：可以注册、保存、移除、获取某个 BeanDefinition BeanFactory：Bean 工厂，可以根据某个 bean 的名字、或类型、或别名获取某个 Bean 对象 SingletonBeanRegistry：可以直接注册、获取某个单例 Bean SimpleAliasRegistry：它是一个类，实现了 AliasRegistry 接口中所定义的功能，支持别名功能 ListableBeanFactory：在 BeanFactory 的基础上，增加了其他功能，可以获取所有 BeanDefinition 的 beanNames，可以根据某个类型获取对应的 beanNames，可以根据某个类型获取 {类型 : 对应的 Bean} 的映射关系 HierarchicalBeanFactory：在 BeanFactory 的基础上，添加了获取父 BeanFactory 的功能 DefaultSingletonBeanRegistry：它是一个类，实现了 SingletonBeanRegistry 接口，拥有了直接注册、获取某个单例 Bean 的功能 ConfigurableBeanFactory：在 HierarchicalBeanFactory 和 SingletonBeanRegistry 的基础上，添加了设置父 BeanFactory、类加载器（表示可以指定某个类加载器进行类的加载）、设置 Spring EL 表达式解析器（表示改 BeanFactory 可以解析 EL 表达式）、设置类型转化服务（表示该 BeanFactory 可以进行类型转化）、可以添加 BeanPostProcessor（表示改 BeanFactory 支持 Bean 的后置处理器），可以合并 BeanDefinition，可以销毁某个 Bean 等等功能 FactoryBeanRegistrySupport：支持了 FactoryBean 的功能 AutowireCapableBeanFactory：是直接继承了 BeanFactory，在 BeanFactory 的基础上，支持在创建 Bean 的过程中能对 Bean 进行自动装配 AbstractBeanFactory：实现了 ConfigurableBeanFactory 接口，继承了 FactoryBeanRegistrySupport，这个 BeanFactory 的功能已经很全面了，但是不能自动装配和获取 beanNames ConfigurableListableBeanFactory：继承了 ListableBeanFactory、AutowireCapableBeanFactory、ConfigurableBeanFactory AbstractAutowireCapableBeanFactory：继承了 AbstractBeanFactory，实现了 AutowireCapableBeanFactory，拥有了自动装配的功能 DefaultListableBeanFactory：继承了 AbstractAutowireCapableBeanFactory，实现了 ConfigurableListableBeanFactory 接口和 BeanDefinitionRegistry 接口，所以 DEfaultListableBeanFactory 的功能很强大 ApplicationContextApplicationContext 是一个接口，实际上也是一个 BeanFactory，不过比 BeanFactory 更加强大，比如： HierarchicalBeanFactory：拥有获取父 BeanFactory 的功能 ListableBeanFactory：拥有获取 beanNames 的功能 ResourcePatternResolver：资源加载器，可以一次性获取多个资源（文件资源等） EnvironmentCapable：可以获取运行时环境（没有设置运行时环境功能） ApplicationEventPublisher：拥有广播事件的功能（没有添加事件监听器的功能） MessageSource：拥有国际化功能 我们先看看 ApplicationContext 两个比较重要的实现类：AnnotationConfigApplicationContext、ClassPathXMLApplicationContext AnnotationConfigApplicationContext ConfigurableApplicationContext：继承了 ApplicationContext 接口，增加了，添加事件监听器、添加 BeanFactoryPostProcessor、设置 Environment、获取 ConfigurableListableBeanFactory 等功能 AbstractApplicationContext：实现了 ConfigurableApplicationContext 接口 GenericApplicationContext：继承了 AbstractApplicationContext，实现了 BeanDefinitionRegistry 接口，拥有了所有 ApplicationContext 的功能，并且可以注册 BeanDefinition AnnotationConfigRegistry：可以单独注册为某个类为 BeanDefinition（可以处理该类上的 @Configuration 注解，已经可以处理 @Bean 注解），同时可以扫描 AnnotationConfigApplicationContext：继承了 GenericApplicationContext，实现了 AnnotationConfigRegistry 接口，拥有了以上所有的功能 ClassPathXMLApplicationContext 它也是继承了 AbstractApplicationContext，但是相对于 AnnotationConfigApplicationContext 而言，功能没有 AnnotationConfigApplicationContext 强大，比如不能注册 BeanDefinition 资源加载ApplicationContext 还拥有资源加载的功能，比如，可以直接利用 ApplicationContext 获取某个文件的内容： 123456AnnotationConfigApplicationContext context = newAnnotationConfigApplicationContext(AppConfig.class);Resource resource = context.getResource("file://D:\\IdeaProjects\\spring‐framework\\luban\\src\\main\\java\\com\\luban\\entity\\User.java");System.out.println(resource.contentLength()); 你还可以： 123456789101112131415AnnotationConfigApplicationContext context = newAnnotationConfigApplicationContext(AppConfig.class);Resource resource = context.getResource("file://D:\\IdeaProjects\\spring‐framework‐5.3.10\\tuling\\src\\main\\java\\com\\zhouyu\\service\\UserService.java");System.out.println(resource.contentLength());System.out.println(resource.getFilename());Resource resource1 = context.getResource("https://www.baidu.com");System.out.println(resource1.contentLength());System.out.println(resource1.getURL());Resource resource2 = context.getResource("classpath:spring.xml");System.out.println(resource2.contentLength());System.out.println(resource2.getURL()); 还可以一次性获取多个： 12345Resource[] resources = context.getResources("classpath:com/zhouyu/*.class");for (Resource resource : resources) &#123; System.out.println(resource.contentLength()); System.out.println(resource.getFilename());&#125; 获取运行时环境123456789101112131415161718192021AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class);Map&lt;String, Object&gt; systemEnvironment = context.getEnvironment().getSystemEnvironment();System.out.println(systemEnvironment);System.out.println("=======");Map&lt;String, Object&gt; systemProperties = context.getEnvironment().getSystemProperties();System.out.println(systemProperties);System.out.println("=======");MutablePropertySources propertySources = context.getEnvironment().getPropertySources();System.out.println(propertySources);System.out.println("=======");System.out.println(context.getEnvironment().getProperty("NO_PROXY"));System.out.println(context.getEnvironment().getProperty("sun.jnu.encoding"));System.out.println(context.getEnvironment().getProperty("luban")); 注意，可以利用 @PropertySource(&quot;classpath:spring.properties&quot;) 来使得某个 properties 文件中的参数添加到运行时环境中 类型转化在 Spring 源码中，有可能需要把 String 转换成其他类型，所以在 Spring 源码中提供了 一些技术来更方便的做对象的类型转换 PropertyEditor这其实是 JDK 中提供的类型转化工具类 123456789public class StringToUserPropertyEditor extends PropertyEditorSupport implements PropertyEditor &#123; @Override public void setAsText(String text) throws IllegalArgumentException &#123; User user = new User(); user.setName(text); this.setValue(user); &#125;&#125; 1234StringToUserPropertyEditor propertyEditor = new StringToUserPropertyEditor();propertyEditor.setAsText("1");User value = (User) propertyEditor.getValue();System.out.println(value); 如何向 Spring 中注册 PropertyEditor： 1234567891011@Beanpublic CustomEditorConfigurer customEditorConfigurer() &#123; CustomEditorConfigurer customEditorConfigurer = new CustomEditorConfigurer(); Map&lt;Class&lt;?&gt;, Class&lt;? extends PropertyEditor&gt;&gt; propertyEditorMap = new HashMap&lt;&gt;(); // 表示StringToUserPropertyEditor可以将String转化为User类型，在Spring源码中，如果发现当前 // 对象是String，而需要的类型是User，就会使用该PropertyEditor来做类型转化 propertyEditorMap.put(User.class, StringToUserPropertyEditor.class); customEditorConfigurer.setCustomEditors(propertyEditorMap); return customEditorConfigurer;&#125; 假设现在有如下 Bean： 1234567891011@Componentpublic class UserService &#123; @Value("123") private User user; public void test() &#123; System.out.println(user.getName()); &#125;&#125; 那么 test 属性就能正常地完成赋值 ConversionServiceSpring 中提供的类型转化服务，它比 PropertyEditor 更强大 123456789101112131415161718public class StringToUserConvert implements ConditionalGenericConverter &#123; @Override public boolean matches(TypeDescriptor sourceType, TypeDescriptor targetType) &#123; return sourceType.getType().equals(String.class) &amp;&amp; targetType.getType().equals(User.class); &#125; @Override public Set&lt;ConvertiblePair&gt; getConvertibleTypes() &#123; return Collections.singleton(new ConvertiblePair(String.class, User.class)); &#125; @Override public Object convert(Object source, TypeDescriptor sourceType, TypeDescriptor targetType) &#123; User user = new User(); user.setName((String) source); return user; &#125;&#125; 1234DefaultConversionService conversionService = new DefaultConversionService();conversionService.addConverter(new StringToUserConvert());User valut = conversionService.convert("12", User.class);System.out.println(valut.getName()); 如何向 Spring 中注册 ConversionService 1234567@Beanpublic ConversionServiceFactoryBean conversionService() &#123; ConversionServiceFactoryBean conversionServiceFactoryBean = new ConversionServiceFactoryBean(); conversionServiceFactoryBean.setConverters(Collections.singleton(new StringToUserConvert())); return conversionServiceFactoryBean;&#125; TypeConverter整合了 PropertyEditor 和 ConversionService 的功能，是 Spring 内部用的 12345SimpleTypeConverter typeConverter = new SimpleTypeConverter();typeConverter.registerCustomEditor(User.class, new StringToUserPropertyEditor());// typeConverter.setConversionService(conversionService);User value = typeConverter.convertIfNecessary("1", User.class);System.out.println(value.getName()); BeanPostProcessorBeanPostProcessor 表示 Bean 的后置处理器，我们可以定义一个或多个 BeanPostProcessor，比如通过一点代码定义一个 BeanPostProcessor 123456789101112131415161718192021@Componentpublic class TestPostProcessor implements BeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; if("userService".equals(beanName)) &#123; System.out.println("初始化前"); &#125; return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; if("userService".equals(beanName)) &#123; System.out.println("初始化后"); &#125; return bean; &#125;&#125; 一个 BeanPostProcessor 可以在任意一个 Bean 的初始化之前和初始化之后去额外的做一些用户自定义的逻辑。当然，我们可以通过判断 beanName 来进行针对性处理（针对某个 bean，或某部分 Bean） 我们可以通过定义 BeanPostProcessor 来干涉 Spring 创建 Bean 的过程 BeanFactoryPostProcessorBeanFactoryPostProcessor 表示 Bean 工厂的后置处理器，其实和 BeanPostProcessor 类似，BeanPostProcessor 是干涉 Bean 的创建过程，BeanFactoryPostProcessor 是干涉 BeanFactory 的创建过程。比如，我们可以这样定义一个 BeanFactoryPostProcessor： 1234567@Componentpublic class TestBeanFactoryPostProcessor implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println("加工BeanFactory"); &#125;&#125; 我们可以在 postProcessBeanFactory() 方法中对 BeanFactory 进行加工 FactoryBean上面提到，可以通过 BeanPostProcessor 来干涉 Spring 创建 Bean 的过程，但是如果我们想一个 Bean 完全由我们来创造，也是可以的，比如通过 FactoryBean 1234567891011121314@Componentpublic class TestFactoryBean implements FactoryBean&lt;Object&gt; &#123; @Override public Object getObject() throws Exception &#123; UserService userService = new UserService(); return userService; &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return UserService.class; &#125;&#125; 通过上面的代码，我们创建了一个 UserService 对象，并且它将成为 Bean。但是通过这种方式创建出来的 UserService 的 Bean，只会经历初始化后，其他 Spring 的生命周期步骤是不会经过的，比如依赖注入 通过 Bean 也可以自己生成一个对象作为 Bean，那么和 FactoryBean 的区别是什么呢？区别很明显，@Bean 定义的 Bean 是会经过完整的 Bean 生命周期的 ExcludeFilter 和 InCludeFilter这两个 Filter 是 Spring 扫描过程中用来过滤的。ExcludeFilter 表示排除过滤器，IncludeFilter 表示包含过滤器 比如下面的配置，表示扫描 com.test.app 这个包下面的所有类，但是排除 UserService 类，也就是就算它上面有 @Component 注解也不会成为 Bean 1234567@ComponentScan(value = "com.test.app", excludeFilters = &#123;@ComponentScan.Filter( type = FilterType.ASSIGNABLE_TYPE, classes = UserService.class )&#125;)public class AppConfig &#123;&#125; 再比如下面的配置，就算 UserService 类上没有 @Component 注解，它也会被扫描成一个 Bean 1234567@ComponentScan(value = "com.test.app", includeFilters = &#123;@ComponentScan.Filter( type = FilterType.ASSIGNABLE_TYPE, classes = UserService.class )&#125;)public class AppConfig &#123;&#125; FilterType 分为： ANNOTATION：表示是否包含某个注解 ASSIGNABLE_TYPE：表示是否是某个类 ASPECTJ：表示是否是符合某个 Aspectj 表达式 REGEX：表示是否符合某个正则表达式 CUSTOM：自定义 在 Spring 的扫描逻辑中，默认会添加一个 AnnotationTypeFilter 给 includeFilters，表示默认情况下 Spring 扫描过程中会认为类上有 @Component 注解的就是 Bean MetadataReader、ClassMetadata、AnnotationMetadata在 Spring 中需要去解析类的信息，比如类名、类中的方法、类上的注解，这些都可以称为类的元数据，所以 Spring 中对类的元数据做了抽象，并提供了一些工具类 MetadataReader 表示类的元数据读取器，默认实现类为 SimpleMetadataReader，比如： 123456789101112131415161718public static void main(String[] args) throws IOException &#123; SimpleMetadataReaderFactory simpleMetadataReaderFactory = new SimpleMetadataReaderFactory(); // 构造一个MetadataReader MetadataReader metadataReader = simpleMetadataReaderFactory.getMetadataReader("com.luban.app.UserService"); // 得到一个ClassMetadata，并获取了类名 ClassMetadata classMetadata = metadataReader.getClassMetadata(); System.out.println(classMetadata.getClassName()); // 获取annotationMetadata，并获取类上的注解信息 AnnotationMetadata annotationMetadata = metadataReader.getAnnotationMetadata(); for (String annotationType : annotationMetadata.getAnnotationTypes()) &#123; System.out.println(annotationType); &#125;&#125; 需要注意的是，SimpleMetadataReader 去解析类时，使用的 ASM 技术 为什么要使用 ASM 技术，Spring 启动的时候需要去扫描，如果指定的包路径比较宽泛，那么扫描的类是非常多的，那如果在 Spring 启动时就把这些类全部加载进 JVM 了，这样不好，所以使用了 ASM 技术]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 之数据分布优化]]></title>
    <url>%2FCKING.github.io%2F2022%2F01%2F20%2FRedis-%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[在切片集群中，数据会按照一定的分布规则分散到不同的实例上保存。比如，使用 Redis Cluster 时，数据都会先按照 CRC 算法的计算值对 Slot（逻辑槽）取模，同时，所有的 Slot 又会由运维管理员分配到不同的额实例上。这样，数据就被保存到相应的实例上了 虽然这种实现方法很简单，但是容易导致一个问题：数据倾斜 数据倾斜有两类： 数据量倾斜：在某些情况下，实例上的数据分布不平衡，某个实例上的数据特别多 数据访问倾斜：虽然每个集群实例上的数据量相差不大，但是某个实例上的数据是热点数据，被访问得非常频繁 如果发生了数据倾斜，那么保存了大量数据，或者是保存了热点数据的实例的处理压力就会增大，速度变慢，甚至还可能引起这个实例的内存资源耗尽，从而崩溃。这是我们在应用切片集群时要避免的 数据量倾斜的成因和应对方法当数据量倾斜发生时，数据在切片集群的多个实例上分布不均衡，大量数据集中到了一个或几个实例上。如下： 数据量倾斜主要有三个原因：分别是某个实例上保存了 bigkey、Slot 分配不均衡以及 Hash Tag bigkey 导致倾斜第一个原因是，某个实例上保存了 bigkey。bigkey 的 value 值很大（String 类型），或者是 bigkey 保存了大量集合元素（集合类型），会导致这个实例的数据量增加，内存资源消耗也相应增加 而且，bigkey 的操作一般都会造成实例 IO 线程阻塞，如果 bigkey 的访问量比较大，就会影响到这个实例上的其他请求被处理的速度 为了避免 bigkey 造成的数据倾斜，根本的对应方法是：我们在业务层生成数据时，要尽量避免把过多的数据保存在同一个键值对中 此外，如果 bigkey 正好是集合类型，可以把 bigkey 拆分成很多个小的集合类型数据，分散保存在不同实例上 例如，假设 Hash 类型集合 user:info 保存了 100 万个用户的信息，是一个 bigkey。那么，我们可以按照用户 ID 的范围，把这个集合拆分为 10 个小集合，每个小集合只保存 10 万个用户的信息。这样，我们就可以把一个 bigkey 分散保存了，避免了 bigkey 给单个切片实例带来的访问压力 Slot 分配不均衡导致倾斜如果集群运维人员没有均衡地分配 Slot，就会有大量的数据被分配同一个 Slot 中，而同一个 Slot 只会在一个实例上分布，这就会导致，大量数据被集中到一个实例上，造成数据倾斜 以 Redis Cluster 为例，介绍下 Slot 分配不均衡的情况 Redis Cluster 一共有 16384 个 Slot，假设集群一共有 5 个实例，其中，实例 1 的硬件配置较高，运维人员在给实例分配 Slot 时，就可能会给实例 1 多分配些 Slot，把实例 1 的资源充分利用起来 但是，我们并不知道数据和 Slot 的对应关系，这种做法就可能会导致大量数据正好被映射到实例 1 上的 Slot，造成数据倾斜，给实例 1 带来访问压力 为了应对这个问题，可以通过运维规范，在分配之前，就要避免把过多的 Slot 分配到同一个实例。如果是已经分配好 Slot 的集群，可以先看 Slot 和实例的具体分配关系，从而判断是否有过多的 Slot 集中到了同一个实例。如果有的话，就将部分 Slot 迁移到其他实例，从而避免数据倾斜 我们执行 CLUSTER SLOTS 命令查看 Slot 分配情况。命令返回结果显示，Slot 0 到 Slot 4095 被分配到了实例 192.168.10.3 上，而 Slot 12288 到 Slot 16383 被分配到了实例 192.168.10.5 上 123456789127.0.0.1:6379&gt; cluster slots1) 1) (integer) 0 2) (integer) 4095 3) 1) "192.168.10.3" 2) (integer) 63792) 1) (integer) 12288 2) (integer) 16383 3) 1) "192.168.10.5" 2) (integer) 6379 如果某一个实例上有太多的 Slot，我们就可以使用迁移命令把这些 Slot 迁移到其他实例上。在 Redis Cluster 中，我们可以使用 3 个命令完成 Slot 迁移 CLUSTER SETSLOT：使用不同的选项进行三种设置，分别是设置 Slot 要迁入的目标实例，Slot 要迁出的源实例，以及 Slot 所属的实例 CLUSTER GETKEYSINSLOT：获取某个 Slot 中一定数量的 key MIGRATE：把一个 key 从源实例实际迁移到目标实例 假设我们要把 Slot 300 从源实例（ID 为 3）迁移到目标实例（ID 为 5），可以分为 5 步 第一步，先在目标实例 5 上执行下面的命令，将 Slot 300 的源实例设置为实例 3，表示要从实例 3 上迁入 Slot 300 1CLUSTER SETSLOT 300 IMPORTING 3 第二步，在源实例 3 上，我们把 Slot 300 的目标实例设置为 5，表示 Slot 300 要迁出到实例 5 上 1CLUSTER SETSLOT 300 MIGRATING 5 第三步，从 Slot 300 中获取 100 个 key，因为 Slot 中的 key 数量可能很多，所以我们需要在客户端上多次执行下面的这条命令，分批次获得并迁移 key 1CLUSTER GETKEYSINSLOT 300 100 第四步，把刚才获取的 100 个 key 中的 key1 迁移到目标实例 5 上（IP 为 192.168.10.5），同时把要迁入的数据库设置为 0 好数据库，把迁移的超时时间设置为 timeout。重复执行 MIGRATE 命令，把 100 个 key 都迁移完 1MIGRATE 192.168.10.5 6379 key1 0 timeout 最后，重复执行第三步和第四步，知道 Slot 中的所有 key 都迁移完成 从 Redis 3.0.6 开始，可以使用 KEYS 选项，一次迁移多个 key，这样可以提升迁移效率 1MIGRATE 192.168.10.5 6379 "" 0 timeout KEYS key1 key2 key3 Hash Tag 导致倾斜Hash Tag 是指加在键值对 key 中的一对花括号 {}。这对花括号会把 key 的一部分括起来，客户单在计算 key 的 CRC16 值时，只对 Hash Tag 话括号中的 key 内容进行计算。如果没用 Hash Tag 的话，客户端计算整个 key 的 CRC16 的值 例如，假设 key 是 user:profile:3231，我们把其中的 3231 作为 Hash Tag，此时，key 就变成了 user:profile:{3231}。当客户端计算这个 key 的 CRC16 值时，就只会计算 3231 的 CRC16 值。否则，客户端会计算整个 user:profile:3231 的 CRC16 值 使用 Hash Tag 的好处是，如果不同 key 的 Hash Tag 内容是一样的，那么，这些 key 对应的数据会被映射到同一个 Slot 中，同时会被分配同一个实例上 下面就显示了使用 Hash Tag 后，数据被映射到相同 Slot 的情况 那么，Hash Tag 一般用在什么场景呢？它主要是用在 Redis Cluster 中，支持事务操作和范围查询。因为 Redis Cluster 并不支持跨实例的事务操作和范围操作，当业务应用有这些需求时，就只能先把这些数据读取到业务层进行事务处理，或者是逐个查询每个实例，得到范围查询的结果 这样操作起来非常麻烦，所以，我们可以使用 Hash Tag 把要执行事务操作或者范围查询的数据映射到同一个实例上，这样就能实现事务或范围查询了 但是，使用 Hash Tag 的潜在问题，就是大量的数据可能被集中到一个实例上，导致数据倾斜，集群中的负载不均衡。这是时候，我们就需要进行取舍了 我们建议，如果使用 Hash Tag 进行切片的数据会带来较大的访问压力，就优先避免考虑数据倾斜，最好不要使用 Hash Tag 进行数据切片。因为事务和范围查询还可以放在客户端来执行，而数据倾斜会导致实例不稳定，造成服务不可用 数据访问倾斜的成因和应对方法发生数据访问倾斜的根本原因，就是实例上存在热点数据。一旦热点数据被存在了某个实例上，这个实例的请求访问量就会远高于其他实例，面临巨大的访问压力，如下： 和数据量倾斜不同，热点数据通常是一个或几个数据，所以，直接重新分配 Slot 并不能解决热点数据问题 通常来说，热点数据以服务读操作为主，在这种情况下，我们可以采用热点数据多副本的方法来应对 这个方法的具体做法是，我们把热点数据复制多份，在每一个数据副本的 key 中增加一个随机前缀，让它和其他副本数据不会被映射到同一个 Slot 中。这样，热点数据既有多个副本可以同时服务请求，同时，这些副本数据的 key 又不一样，会被映射到不同的 Slot 中。在给这些 Slot 分配实例时，我们也要注意把他们分配到不同的实例上，那么，热点数据的访问压力就被分散到不同的实例上了 注意，热点数据多副本方法只能针对只读的热点数据。如果热点数据是有读有写的话，就不适合采用多副本方法了，因为要保证多副本间的数据一致性，会带来额外的开销 对于有读有写的热点数据，就需要给实例本身增加资源了，例如使用配置更高的机器，来应对大量的访问压力]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 主从同步与故障切换可能产生的问题]]></title>
    <url>%2FCKING.github.io%2F2022%2F01%2F20%2FRedis-%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E4%B8%8E%E6%95%85%E9%9A%9C%E5%88%87%E6%8D%A2%E5%8F%AF%E8%83%BD%E4%BA%A7%E7%94%9F%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Redis 的主从同步机制不仅可以让从库服务更多的读请求，分担主库的压力，而且还能在主库发生故障时，进行主从库切换，提供高可靠服务 不过，在实际使用主从机制的时候，还是容易踩到一些坑。我们先看第一个坑：主从数据不一致 主从数据不一致主从数据不一致，就是指客户端从从库中读取到的值和主库中的最新值并不一致。为什么会出现这个坑？这是因为主从库间的命令复制是异步进行的 具体来说，在主从库命令传播阶段，主库收到新的写命令之后，会发送从库。但是，主库并不会等到从库实际执行完命令后，再把结果返回给客户端。而是主库自己在本地执行完命令后，就会向客户端返回结果了。如果从库还没有执行主库同步过来的命令，主从库间的数据就不一致了 从库滞后执行同步命令，主要有两个原因 一方面，主从库间的网络可能会有传输延迟，所以从库不能及时收到主库发送的命令，从库上执行同步命令的时间就会被延后 另一方面，即使从库及时收到了主库的命令，但是，也可能会因为正在处理其它复杂度高的命令（例如集合操作命令）而阻塞。此时，从库需要处理完当前的命令，才能执行主库发送的命令操作，这样就会造成主从数据不一致。而在主库命令被滞后处理的这段时间内，主库本身可能又执行了新的写操作。这样，主从库间的数据不一致程度又会进一步加剧 首先，在硬件环境配置方面，要尽量保证主从库间的网络连接状态良好。例如，避免把主从库部署在不同的机房，或者是避免把网络通信密集的应用（例如数据分析应用）和 Redis 主从库部署在一起 另外，还可以开发一个外部程序来监控主从库间的复制进度 因为 Redis 的 INFO replication 命令可以查看主库接收写命令的进度信息（master_repl_offset）和从库复制写命令的进度信息（slave_repl_offset）。所以，我们可以开发一个监控程序，先用 INFO replication 命令查到主、从库的进度，然后，用 master_repl_offset 减去 slave_repl_offset，这样就能得到从库和主库间的复制进度差值了 如果某个从库的进度差值大于我们预设的阈值，可以让客户端不再和这个从库进行数据读取，这样就可以减少读到不一致数据的情况。不过，为了避免出现客户端和所有从库都不能连接的情况，需要把复制进度差值的阈值设置得大一些 我们在应用 Redis 时，可以周期性地运行这个流程来监控主从库间的不一致情况。如下： 当前，监控程序可以一直监控着从库的复制进度，当从库的复制进度又赶上主库时，我们就允许客户端再次跟这些从库连接 读取过期数据在使用 Redis 主从集群时，有时会读到过期数据。例如，数据 X 的过期时间是 202010240900，但是客户端在 202010240910 时，仍然可以从从库中读到数据 X。一个数据过期后，应该是被删除的，客户端不能再读取到该数据。但是，Redis 为什么还能在从库中读到过期的数据呢 其实，这是由 Redis 的过期数据删除策略引起的。Redis 同时使用了两种策略来删除过期的数据，分别是惰性删除和定期删除策略 惰性删除策略，是指一个数据的过期时间到了以后，并不会立即删除数据，而是等到再有请求来读写这个数据时，对数据进行检查，如果发现数据已经过期了，再删除这个数据 这个策略的好处是尽量减少删除操作对 CPU 资源的使用，对于用不到的数据，就不再浪费时间进行检查和删除了。但是，这个策略会导致大量已经过期的数据留存在内存中，占用较多的内存资源。所以，Redis 在使用这个策略的同时，还使用了定期删除策略 定期删除策略是指，Redis 每隔一段时间（默认 100ms），就会随机选出一定数量的数据，检查它们是否过期，并把其中过期的数据删除，这样就可以及时释放一些内存 清楚了这两个策略，我们再看为什么会导致读取到过期的数据 首先，虽然定期删除策略可以释放一些内存，但是，Redis 为了避免过多删除操作对性能产生影响，每次随机检查数据的数量并不多。如果过期数据很多，并且一直没有再被访问的话，这些数据就要留存在 Redis 实例中。业务应用之所以会读到过期数据，这些留存数据就是一个重要因素 其次，惰性删除策略实现后，数据只有被再次访问时，才会被实际删除。如果客户端从主库上读取留存的过期数据，主库会触发删除操作，此时，客户端并不会读到过期数据。但是，从库本身不会执行删除操作，如果客户端在从库中访问留存的过期数据，从库并不会触发数据删除。那么，从库会给客户端返回过期数据吗？ 这就和 Redis 版本有关了。如果使用的是 Redis 3.2 之前的版本，那么从库在服务读请求时，并不会判断数据是否过期，而是会返回过期数据。在 3.2 版本后，Redis 做了改进，如果读取的数据已经过期了，从库虽然不会删除，但是会返回空值，这就避免了客户端读到过期数据。所以，在应用主从集群时，尽量使用 Redis 3.2 及以上版本 但是，使用了 Redis 3.2 后的版本，就不会读到过期数据吗？还是会的 我们先介绍一些命令。设置过期时间的命令一共有 4 个，我们可以分成两类： EXPIRE 和 PEXPIRE：它们给数据设置的是从命令执行时开始计算的存活时间 EXPIREAT 和 PEXPIREAT：它们会直接把数据的过期时间设置为具体的一个时间点 如下： 举个例子。第一个例子，使用 EXPIRE 命令，执行下面的命令时，我们就把 testkey 的过期时间设置为 60s 后 1EXPIRE testkey 60 第二个例子，使用 EXPIREAT 命令，如下命令，可以让 testkey 在 2020 年 10 月 24 日上午 9 点过期，命令中的 1603501200 就是以秒数时间戳表示的 10 月 24 日上午 9 点 1EXPIREAT testkey 1603501200 接着我们看这些命令如何导致读到过期数据 当主从库全量同步时，如果主库接收到了一条 EXPIRE 命令，那么，主库会直接执行这条命令。这条命令会在全量同步完成后，发给从库执行。而从库在执行时，就会在当前时间的基础上加上数据的存活时间，这样，从库上数据的过期时间就会比主库上延后 假设当前时间是 2020 年 10 月 24 日上午 9 点，主从库正在同步，主库收到了一条命令：EXPIRE testkey 60，这就表示，testkey 的过期时间就是 24 日 上午 9 点 1 分，主库直接执行了这条命令 但是，主从库同步花费了 2 分钟才完成。等从库开始执行这条命令时，时间已经是 9 点 2 分了。而 EXPIRE 命令是把 testkey 的过期时间设置为当前时间的 60s 后，也就是 9 点 3 分。如果客户端在 9 点 2 分 30 秒时在从库上读取 testkey，仍然可以读到 testkey 的值。但是，testkey 实际上已经过期了 为了避免这种情况，我们建议，在业务应用中使用 EXPIREAT / PEXPIREAT 命令，把数据的过期时间设置为具体的时间点，避免读到过期数据 不合理配置项导致的服务挂掉这里涉及到的配置项有两个，分别是 protected - mode 和 cluster - mode - timeout protected - mode 配置项这个配置项的作用是限定哨兵实例能否被其他服务器访问。当这个配置项设置为 yes 时，哨兵实例只能在部署的服务器本地进行访问。当设置为 no 时，其他服务器也可以访问这个哨兵实例 因此，当 protected - mode 设置为 yes，而其他哨兵实例部署在其他服务器，那么，这些哨兵实例间就无法通信。当主库故障时，哨兵无法判断主库下线，也无法进行主从切换，最终 Redis 服务不可用 所以，在应用主从集群时，要将 protected - mode 配置项设置为 no，并且将 bind 配置项设置为其他哨兵实例的 IP 地址。这样，只有在 bind 中设置了 IP 地址的哨兵，才可以访问当前实例，既保证了实例间能够通信进行主从切换，也保证了哨兵的安全性 12protected - mode nobind 192.168.0.3 192.168.0.4 192.168.0.5 cluster - node - timeout 配置项这个配置项设置了 Redis Cluster 中实例响应心跳消息的超时时间 当我们在 Redis Cluster 集群中为每个实例配置了「一主一从」模式时，如果主实例发生故障，从实例会切换为主实例，受网络延迟和切换操作执行的影响，切换时间可能较长，就会导致实例的心跳超时（超过 cluster - node - timeout）。实例超时后，就会被 Redis Cluster 判断为异常。而 Redis Cluster 正常运行的条件就是，有半数以上的实例能够正常运行 所以，如果执行主从切换的实例超过半数，而主从切换时间又过长的话，就可能有半数以上的实例心跳超时，从而可能导致整个集群挂掉。所以，建议你将 cluster - node - timeout 调大些（例如 10 到 20 秒）]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 的事务机制]]></title>
    <url>%2FCKING.github.io%2F2022%2F01%2F18%2FRedis-%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Redis 如何实现事务事务的执行过程包含了三个步骤，Redis 提供了 MULTI、EXEC 两个命令来完成这三个步骤 第一步，客户端要使用一个命令显示地表示一个事务的开启。在 Redis 中，这个命令就是 MULTI 第二步，客户端把事务中本身要执行的具体操作（例如增删改数据）发送给服务器端。这些操作就是 Redis 本身提供的数据读写命令，例如 GET、SET 等。不过，这些命令虽然被客户端发送到了服务器端，但 Redis 实例只是把这些命令暂存到一个命令队列中，并不会立即执行 第三步，客户端向服务器端发送提交事务的命令，让数据库实际执行第二步中发送的具体操作。Redis 提供的 EXEC 命令就是执行事务提交的。当服务器端收到 EXEC 命令后，才会实际执行命令队列中的所有命令 如下代码： 12345678910111213#开启事务127.0.0.1:6379&gt; MULTIOK#将a:stock减1127.0.0.1:6379&gt; DECR a:stockQUEUED#将b:stock减1127.0.0.1:6379&gt; DECR b:stockQUEUED#实际执行事务127.0.0.1:6379&gt; EXEC1) (integer) 41) (integer) 9 假设 a:stock、b:stock 两个键的初始值是 5 和 10.在 MULTI 命令后执行的两个 DECR 命令，是把 a:stock、b:stock 两个键的值分别减 1，它们执行后的返回结果都是 QUEUED，这就表示，这些操作都被暂存到了命令队列，还没有实际执行。等执行了 EXEC 命令后，可以看到返回了 4、9.说明两个 DECR 命令已经成功执行了 通过 MULTI 和 EXEC 命令，可以实现多个操作的共同执行，但是这符合事务要求的 ACID 属性吗？ Redis 的事务机制能保证哪些属性？原子性如果事务正常执行，没有发生任何错误，那么，MULTI 和 EXEC 配合使用，就可以保证多个操作都完成。但是，如果事务执行发生错误了，原子性还能保证吗？我们需要分三种情况来看 第一种情况是，在执行 EXEC 命令之前，客户端发送的操作命令本身就有错误（比如语法错误，使用了不存在的命令），在命令入队时就被 Redis 实例判断出来了 对于这种情况，在命令入队时，Redis 就会报错并且记录这个错误。此时，我们还能继续提交命令操作。等到执行了 EXEC 命令之后，Redis 就会拒绝执行所有提交的命令操作，返回事务失败的结果。这样，事务中所有命令都不会再被执行，保证了原子性。如下： 123456789101112#开启事务127.0.0.1:6379&gt; MULTIOK#发送事务中的第一个操作，但是 Redis 不支持该命令，返回报错信息127.0.0.1:6379&gt; PUT a:stock 5(error) ERR unknown command `PUT`, with args beginning with: `a:stock`, `5`#发送事务中的第二个操作，这个操作是正确的命令，Redis 把该命令入队127.0.0.1:6379&gt; DECR b:stockQUEUED#实际执行事务，但是之前命令有错误，所以 Redis 拒绝执行127.0.0.1:6379&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors 这个例子中，事务里包含了一个 Redis 本身就不支持的 PUT 命令，所以，在 PUT 命令入队时，Redis 就报错了。虽然事务里还有一个正确的 DECR 命令，但是，在最后执行 EXEC 命令后，这个事务被放弃执行了 接着是第二种情况。事务操作入队时，命令和操作的数据类型不匹配，但 Redis 实例没有检查出错误。但是，在执行完 EXEC 命令以后，Redis 实际执行这些事务操作时，就会报错。不过，需要注意的是，虽然 Redis 会对错误命令报错，但还是会把正确的命令执行完。这种情况下，事务的原子性就无法得到保证了 例如，事务中的 LPOP 命令对 String l类型数据进行操作，入队时没有报错，但是，在 EXEC 执行时报错了。LPOP 命令本身没有执行成功，但是事务中的 DECR 命令却成功执行了 12345678910111213#开启事务127.0.0.1:6379&gt; MULTIOK#发送事务中的第一个操作，LPOP 命令操作的数据类型不匹配，此时不报错127.0.0.1:6379&gt; LPOP a:stockQUEUED#发送事务中的第二个操作，这个操作是正确的命令，Redis 把该命令入队127.0.0.1:6379&gt; DECR b:stockQUEUED#实际执行事务，事务第一个操作执行报错127.0.0.1:6379&gt; EXEC(error) WRONGTYPE Operation against a key holding the wrong kind of value(integer) 8 我们知道，传统数据库在执行事务时，会提供回滚机制，当事务执行发生错误时，事务中的所有操作都会撤销，已经修改的数据也会被恢复到事务执行前的状态。那么，刚才的例子中，如果命令实际执行时报错了，是不是可以用回滚机制恢复原来的数据呢？ 其实，Redis 中并没有提供回滚机制。虽然 Redis 提供了 DISCARD 命令，但是，这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。具体使用如下代码 123456789101112131415#读取a:stock的值4127.0.0.1:6379&gt; GET a:stock"4"#开启事务127.0.0.1:6379&gt; MULTIOK#发送事务的第一个操作，将a:stock减1127.0.0.1:6379&gt; DECR a:stockQUEUED#执行DISCARD命令，主动放弃事务127.0.0.1:6379&gt; DISCARDOK#再次读取a:stock的值，值没有被修改127.0.0.1:6379&gt; GET a:stock"4" 这个例子中，a:stock 键的值一开始为 4，然后，我们执行一个事务，想对 a:stock 的值减 1。但是，在事务的最后，我们执行的是 DISCARD 命令，所以事务就被放弃了。再次查看 a:stock 的值，会发现仍然为 4 最后看第三种情况：在执行事务的 EXEC 命令时，Redis 实例发生了故障，导致事务执行失败 这种情况下，如果 Redis 开启了 AOF 日志，那么，只会有部分的事务操作被记录到 AOF 日志中。我们需要使用 redis-check-aof 工具检查 AOF 日志文件，这个工具可以把已完成的事务操作从 AOF 文件中去除。这样一来，我们使用 AOF 恢复实例后，事务操作不会再被执行，从而保证了原子性 如果 AOF 日志没有开启，那么实例重启后，数据也都没法去恢复了，此时就谈不上原子性了 到此，我们总结一下 Redis 的原子性： 命令入队时就报错，会放弃事务执行，保证原子性 命令入队时没报错，实际执行时报错，不保证原子性 EXEC 命令执行时实例故障，如果开启了 AOF 日志，可以保证原子性 一致性事务的一致性保证会受到错误命令、实例故障的影响。所以，我们按照命令出错和实例故障的发生时机，分成三种情况来看 情况一：命令入队时就报错 这种情况下，事务本身就会被放弃执行，所以可以保证数据库的一致性 情况二：命令入队时没报错，实际执行时报错 这种情况下，有错误的命令不会被执行，正确的命令可以正常执行，也不会改变数据库的一致性 情况三：EXEC 命令执行时实例发生故障 这种情况下，实例故障后会进行重启，这就和数据恢复的方式有关了，我们要根据实例是否开启了 RDB 或 AOF 来分情况讨论 如果我们没有开启 RDB 或 AOF ，那么实例故障重启后，数据都没有了，数据库是一致的 如果我们使用了 RDB 快照，因为 RDB 快照不会在事务执行时执行，所以，事务命令操作的结果不会被保存到 RDB 快照中，使用 RDB 快照进行恢复时，数据库里的数据也是一致的 如果我们使用了 AOF 日志，而事务操作还没有被记录到 AOF 日志时，实例就发生了故障，那么，使用 AOF 日志恢复的数据库数据是一致的。如果只有部分操作被记录到了 AOF 日志，我们可以使用 redis-check-aof 清除事务中已经发生的操作，数据库恢复后也是一致的 所以，总结来说，在命令执行错误或 Redis 发生故障的情况下，Redis 事务机制对一致性属性是有保证的 隔离性事务的隔离性保证，会受到和事务一起执行的并发操作的影响。而事务执行又可以分为命令入队（EXEC 命令执行前）和命令实际执行（EXEC 命令执行后）两个阶段，所以，针对这两个阶段，分成两种情况来分析： 并发操作在 EXEC 命令前执行，此时，隔离性的保证要使用 WATCH 机制来实现，否则隔离性无法保证 并发操作在 EXEC 命令后执行，此时，隔离性可以保证 第一种情况，一个事务的 EXEC 命令还没有执行时，事务的命令操作是暂存在命令队列中的。此时，如果有其他的并发操作，我们就需要看事务是否使用了 WATCH 机制 WATCH 机制的作用是，在事务执行前，监控一个或多个键的值变化情况，当事务调用 EXEC 命令执行时，WATCH 机制会先检查监控的键是否被其他客户端修改了。如果修改了，就放弃事务执行，避免事务的隔离性被破坏。然后，客户端可以再次执行事务，此时，如果没有并发修改事务数据的操作了，事务就能正常执行，隔离性也得到了保证 WATCH 机制的具体实现是有 WATCH 命令实现的。如下图： 我们具体解释一下上图的内容： 在 t1 时，客户端 X 向实例发生了 WATCH 命令。实例收到 WATCH 命令后，开始检测 a:stock 的值的变化情况 在 t2 时，客户端 X 把 MULTI 命令和 DECR 命令发送给实例，实例把 DECR 命令暂存入命令队列 在 t3 时，客户端 Y 也给实例发送了一个 DECR 命令，要修改 a:stock 的值，实例收到命令后就直接执行了 在 t4 时，实例收到客户端 X 发送的 EXEC 命令，但是，实现的 WATCH 机制发现 a:stock 已经被修改了，就会放弃事务执行。这样一来，事务的隔离性就可以得到保证 当然，如果没有使用 WATCH 机制，在 EXEC 命令钱执行的并发操作是会对数据进行读写的。而且，在执行 EXEC 命令的时候，事务要操作的数据已经变了，在这种情况下，Redis 并没有做到让其他事务对其他操作隔离，隔离性也就没有得到保障 上面说的是并发操作在 EXEC 命令前执行的情况。接着看第二种情况：并发操作在 EXEC 命令之后被服务器端接收并执行 因为 Redis 是用单线程执行命令，而且，EXEC 命令执行后，Redis 会保证先把命令队列中的所有命令执行完。所以，这种情况下，并发操作不会破坏事务的隔离性。如下图： 持久性因为 Redis 是内存数据库，所以，数据是否持久化保存完全取决于 Redis 的持久化配置模式 如果 Redis 没有使用 RDB 或 AOF，那么事务的持久化属性肯定得不到保证。如果 Redis 使用了 RDB 模式，那么，在一个事务执行后，而下一次的 RDB 快照还未执行前，如果发生了实例宕机，这种情况下，事务修改的数据也是不能保证持久化的 如果 Redis 使用了 AOF 模式，因为 AOF 模式的三种配置选项 no、everysec 和 always 都会存在数据丢失的情况，所以，事务的持久性属性也还是得不到保证 所以，不管 Redis 采用什么持久化模式，事务的持久性是得不到保证的 小结]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 实现分布式锁]]></title>
    <url>%2FCKING.github.io%2F2022%2F01%2F17%2FRedis-%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[单机上的锁和分布式锁的联系与区别对于在单机上运行的多线程程序来说，锁本身可以用一个变量来表示： 变量值为 0 时，表示没有线程获取锁 变量值为 1 时，表示已经没有线程获取到锁了 一个线程调用加锁操作，其实就是检查锁变量是否为 0。如果为 0，就把锁的变量值设置为 1，表示获取到锁，如果不是 0，就返回错误信息，表示加锁失败，已经有别的线程获取到锁了。而一个线程调用释放锁操作，其实就是将锁变量的值置为 0，以便其他线程可以来获取锁 用一段伪代码表示加锁和释放锁，其中，lock 为锁变量，如下： 123456789101112acquire_lock() &#123; if lock == 0 lock = 1 return 1 else return 0&#125;release_lock() &#123; lock = 0 return 1&#125; 和单机上的锁类似，分布式锁同样可以用一个变量来实现。客户端加锁和释放锁的操作逻辑，也和单机上的加锁和释放锁操作逻辑一致：加锁时同样需要判断锁变量的值，根据锁变量值来判断是否加锁成功；释放锁时需要把锁变量值设置为 0，表明客户端不再持有锁 但是，和线程在单机上操作锁不同的是，在分布式场景下，锁变量需要由一个共享存储系统来维护，只有这样，多个客户端才可以通过访问共享存储系统来访问锁变量。相应的，加锁和释放锁的操作就变成了读取、判断和设置共享存储系统中的锁变量值 这样，我们就可以得出实现分布式锁的两个要求： 要求一：分布式锁的加锁和释放锁的过程，涉及多个操作。所以，在实现分布式锁时，我们需要保证这些锁操作的原子性 要求二：共享存储系统保存了锁变量，如果共享存储系统发生故障，那么客户端也就无法进行锁操作了。在实现分布式锁时，我们需要考虑保证共享存储系统的可靠性，进而保证锁的可靠性 实际上，我们可以基于单个 Redis 节点来实现，也可以使用多个 Redis 节点实现。这两种情况下，锁的可靠性是不一样的。我们先看基于单个 Redis 节点的实现方法 基于单个 Redis 节点实现分布式锁作为分布式锁实现过程中的共享存储系统，Redis 可以使用键值对来保存锁变量，再接收和处理不同客户端发送的加锁和释放锁的操作请求。那么，键值对的键和值具体是怎么定的呢？ 我们要赋予锁变量一个变量名，把这个变量名作为键值对的键，而锁变量的值，则是键值对的值，这样一来，Redis 就能保存锁变量了，客户端也就可以通过 Redis 的命令操作来实现锁操作 因为加锁包含了三个操作（读取锁变量、判断锁变量以及把锁变量值设置为 1），而这三个操作在执行时需要保证原子性，那怎么保证原子性？ 要想保证操作的原子性，有两种通用的方法，分别是使用 Redis 的单命令操作和使用 Lua 脚本。那么，在分布式加锁场景下，该怎么应用这两个方法呢 那么，Redis 有哪些单命令操作实现加锁操作呢 首先是 SETNX 命令，它用于设置键值对的值。这个命令在执行时会判断键值对是否存在，如果不存在，就设置键值对的值，如果存在，就不做任何修改 例如，执行下面的命令，key 不存在，那么 key 会被创建，并且值会被设置为 value；如果 key 已经存在，SETNX 不做任何赋值操作 1SETNX key value 对于释放锁操作来说，我们可以在执行完业务逻辑后，使用 DEL 命令删除锁变量。不过，你不用担心锁变量被删除后，其他客户端无法请求加锁了。因为 SETNX 命令在执行时，如果要设置键值对（也就是锁变量）不存在，SETNX 命令会先去创建键值对，然后设置它的值。所以，释放锁之后，再有客户端请求加锁时，SETNX 命令会创建保存锁变量的键值对，并设置锁变量的值，完成加锁 总结来说，我们可以用 SETNX 和 DEL 命令组合来实现加锁和释放锁操作。如下 12345678// 加锁SETNX lock_key 1// 业务逻辑DO THINGS// 释放锁DEL lock_key 不过，使用 SETNX 和 DEL 命令组合实现分布锁，存在两个潜在的风险 第一个风险是，客户端在执行了 SETNX 命令、加锁之后，紧接着却在操作共享数据时发生了异常，结果一直没有执行最后的 DEL 命令释放锁。因此，锁就一直被这个客户端持有，其他客户端无法拿到锁，也无法访问共享数据和执行后续操作，这会给业务应用带来影响 针对这个问题，一个有效的解决方式是，给锁变量设置一个过期时间。这样一来，即使持有锁的客户端发生了异常，无法主动地释放锁，Redis 也会根据锁变量的过期时间，在锁变量过期后，把它删除。其他客户端在锁变量过期后，就可以重新请求加锁，这就不会出现无法加锁的问题了 然后是第二个风险。如果客户端 A 执行了 SETNX 命令加锁后，假设客户端 B 执行了 DEL 命令释放锁，此时，客户端 A 的锁就被释放了。如果客户端 C 正好也在申请加锁，就可以成功获得锁，进而开始操作共享数据。这样一来，客户端 A 和 C 同时在对共享数据进行操作，数据就会被修改错误，这也是业务层不能接受的 因此，我们需要能区分来自不同客户端的锁操作，具体咋做？我们可以在锁变量的值上想想办法 在使用 SETNX 命令进行加锁的方法中，我们通过把锁变量设置为 1 或 0，表示是否加锁成功。1 和 0 只有两种状态，无法表示究竟是哪个客户端进行的锁操作。所以，我们在加锁操作时，可以让每个客户端给锁变量设置一个唯一值，这里的唯一值就可以用来标识当前操作的客户端。在释放锁操作时，客户端需要判断，当前锁变量的值是否和自己的唯一标识相等，只有在相等的情况下，才能释放锁。这样一来，就不会出现误释放锁的问题了 那么该如何实现呢？可以通过 Redis 的 SET 命令 SETNX 命令是，对于不存在的键值对，它会先创建再设置（也就是「不存在即设置」），为了能达到和 SETNX 命令一样的效果，Redis 给 SET 命令提供了类似的选项 NX，用来实现「不存在即设置」。如果使用了 NX 选项，SET 命令只有在键值对不存在时，才会进行设置，否则不做复制操作。此外，SET 命令在执行时还可以带上 EX 或 PX 选项，用来设置键值对的过期时间 如下命令，只有 key 不存在时，SET 才会创建 key，并对 key 进行赋值。另外，key 的存活时间由 seconds 或者 milliseconds 选项值来决定 1SET key value [EX seconds | PX milliseconds] [NX] 有了 SET 命令的 NX 和 EX / PX 选项后，我们就可以用下面的命令来实现加锁操作了 12// 加锁，unique_value 作为客户端唯一性的标识SET lock_key unique_value NX PX 10000 其中，unique_value 是客户端的唯一标识，可以用一个随机生成的字符串来表示，PX 10000 则表示 lock_key 会在 10s 后过期，以免客户端在这期间发生异常而无法释放锁 因为在加锁操作中，每个客户端都使用了一个唯一标识，所有在释放锁操作时，我们需要判断锁变量的值，是否等于释放锁操作的客户端的唯一标识，如下： 123456// 释放锁，比较 unique_value 是否相等，避免误释放if redis.call("get", KEYS[1]) == ARGV[1] then return redis.call("del", KEYS[1])else return 0end 这是使用 Lua 脚本（unlock.script）实现的释放锁操作的伪代码，其中，KEYS[1] 表示 lock_key，ARGV[1] 是当前客户端的唯一标识，这两个值都是我们在执行 Lua 脚本作为参数传入的 最后，我们执行下面的命令，就可以完成释放锁操作了 1redis-cli --eval unlock.script lock_key, unique_value 在释放锁的过程中，我们使用了 Lua 脚本。这是因为，释放锁操作的逻辑也包含了读取锁变量、判断值、删除锁变量的多个操作，而在 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，从而保证了锁释放操作的原子性 至此，我们了解了如何使用 SET 命令和 Lua 脚本在 Reds 单节点上实现分布式锁。但是，我们现在只用了一个 Redis 实例来保存锁变量，如果这个 Redis 实例发生故障宕机了，那么锁变量就没有了。此时，客户端也无法进行锁操作了，这就会影响到业务的正常执行。所以，我们在实现分布式锁时，还需要保证锁的可靠性，怎么提高呢？这就要提到基于多个 Redis 节点实现分布式锁的方式了 基于多个 Redis 节点实现高可靠的分布式锁当我们要实现高可靠的分布式锁时，就不能只依赖单个的命令操作了，我们需要按照一定的步骤和规则进行加解锁操作，否则，就可能会出现锁无法工作的情况。「一定的步骤和规则」说的就是分布式锁的算法 为了避免 Redis 实例故障而导致的锁无法工作的问题，Redis 的开发者提出了分布式锁算法 Redlock Redlock 算法的基本思路，是让客户端和多个独立的 Redis 实例依次请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么就认为客户端成功地获得分布式锁了，否则加锁失败。这样一来，即使有单个 Redis 实例发生故障，因为锁变量在其他实例上也有保存，所以，客户端仍然可以正常地进行锁操作，锁变量并不会丢失 我们看 Redlock 算法的执行步骤。Redlock 算法的实现需要有 N 个独立的 Redis 实例，我们可以分成 3 步来完成加锁操作 第一步是，客户端获取当前时间 第二步是，客户端按顺序依次向 N 个 Redis 实例执行加锁操作 这里的加锁操作和在单实例上执行的加锁操作一样，使用 SET 命令，带上 NX，EX / PX 选项，以及带上客户端的唯一标识。当然，如果某个 Redis 实例发生故障了，为了保证在这种情况下，Redlock 算法能够继续运行，我们需要给加锁操作设置一个超时时间 如果客户端在和一个 Redis 实例请求加锁时，一直到超时都没有成功，那么此时，客户端会和下一个 Redis 实例继续请求加锁。加锁操作的超时时间需要远远地小于锁的有效时间，一般也就是设置为几十毫秒 第三步是，一旦客户端完成了和所有 Redis 实例的加锁操作，客户端就要计算整个加锁过程的总耗时 客户端只有在满足下面的两个条件时，才能认为是加锁成功 条件一：客户端从超过半数（大于等于 N / 2 + 1）的 Redis 实例上成功获取到了锁 条件二：客户端获取锁的总耗时没有超过锁的有效时间 在满足了这两个条件以后，我们需要重新计算这把锁的有效时间，计算的结果是锁的最初有效时间减去客户端为获取锁的总耗时。如果锁的有效时间已经来不及完成共享数据的操作了，我们可以释放锁，以免出现还没完成数据操作，锁就过期了的情况 如果客户端在和所有实例执行完加锁操作后，没能同时满足这两个条件，那么，客户端向所有 Redis 节点发起释放锁的操作 在 Redlock 算法中，释放锁的操作和在单实例上释放锁的操作一样，只要执行释放锁的 Lua 脚本就可以了。这样一来，只要 N 个 Redis 实例中的半数以上实例能正常工作，就能保证分布式锁的正常工作了 所以，在实际的业务应用中，如果想提升分布式锁的可靠性，可以通过 Redlock 算法来实现]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 之无锁的原子操作]]></title>
    <url>%2FCKING.github.io%2F2022%2F01%2F12%2FRedis-%E4%B9%8B%E6%97%A0%E9%94%81%E7%9A%84%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[为了保证并发访问的正确性，Redis 提供了两种方法，分别是加锁和原子操作 加锁是一种常用的方法，在读取数据前，客户端需要先获得锁，否则就无法进行操作。当一个客户端获得锁后，就会一直持有这把锁，知道客户端完成数据更新，才释放这把锁 加锁会有两个问题，一个是，如果加锁操作多，会降低系统的并发访问性能；第二个是，Redis 客户单要加锁时，需要用到分布式锁，而分布式锁实现复杂，需要用额外的存储系统来提供加解锁操作 原子操作是另一种提供并发访问控制的方法。原子操作是指执行过程中保持原子性的操作，而且原子操作执行时并不需要加锁，实现了无锁操作。这样一来，既能保证并发控制，还能减少对系统并发性能的影响 并发访问中需要对什么进行控制我们说的并发访问控制，是指多个客户端访问操作同一份数的过程进行控制，以保证任何一个客户端发送的操作在 Redis 实例上执行时具有互斥性。例如，客户端 A 的访问操作在执行时，客户端 B 的操作不能执行，需要等到 A 的操作结束后，才能执行 并发访问控制对应的操作主要是数据修改操作。当客户端需要修改数据时，基本流程分成两步： 客户端先把数据读取到本地，在本地进行修改 客户端修改完数据后，再写回 Redis 我们把这个流程叫做「读取 - 修改 - 写回」操作（Read - Modify - Write，简称为 RMW 操作）。当有多个客户端对同一份数据执行 RMW 操作的话，我们就需要让 RMW 操作涉及的代码以原子性方式执行。访问同一份数据的 RMW 操作代码，就叫做临界区代码 不过，当有多个客户端并发执行临界区代码时，就会存在一些潜在问题。我们用一个多客户端更新商品库存的例子来解释一下 我们先看临界区代码。假设客户端要对商品库存执行扣减 1 的操作，伪代码如下： 123current = GET(id)current--SET(id, current) 如果我们对临界区代码的执行没有控制机制，就会出现数据更新的操作。假设现在有两个客户端 A 和 B，同时执行刚才的临界区代码，就会出现错误，如下 可以看到，客户端 A 在 t1 时读取库存值 10 并扣减 1，在 t2 时，客户端 A 还没有把扣减后的库存值 9 写回 Redis，而在此时，客户端 B 读到库存值 10，也扣减了 1，B 记录的库存值也为 9 了。等到 t3 时，A 往 Redis 写回了库存值 9，而到 t4 时，B 也写回了库存值 9 如果按正确的逻辑处理，客户单 A 和 B 对库存值各做了一次扣减，库存值应该为 8。所以，这里的库存值明显更新错了 出现了这个的原因是，临界区的代码中的客户端读取数据、更新数据、再写回数据涉及了三个操作，而这三个操作在执行时并不具有互斥性，多个客户端基于相同的初始值进行修改，而不是基于前一个客户端修改后的值再修改 为了保证数据并发修改的正确性，我们可以用锁把并行操作变成串行操作，串行操作就是具有互斥性。一个客户端持有锁后，其他客户端只能等到锁释放，才能拿到锁再进行修改。如下伪代码 12345LOCK()current = GET(id)current--SET(id, current)UNLOCK() 虽然加锁保证了互斥性，但是加锁也会导致系统并发性能降低 和加锁类似，原子操作也能实现并发控制，但是原子操作对系统并发性能影响较小，接着我们看看 Redis 中的原子操作 Redis 的两种原子操作方法为了实现并发控制要求的临界区代码互斥执行，Redis 的原子操作采用了两种方法： 把多个操作在 Redis 中实现成一个操作，也就是单命令操作 把多个操作写到一个 Lua 脚本中，以原子性方式执行单个 Lua 脚本 我们先看下 Redis 本身的单命令操作 Redis 是使用单线程来串行处理客户端的请求操作命令的，所以，当 Redis 执行某个命令操作时，其他命令是无法执行的，这相当于命令操作是互斥执行的。当然，Redis 的快照生成、AOF 重写这些操作，可以使用后台线程或者是子进程执行，也就是和主线程的操作并行执行。不过这些只是读取数据，不会修改数据，所以，我们并不需要对它们做并发控制 虽然 Redis 的单个命令可以原子性地执行，但是数据修改时，可能包含多个动作，至少包括读数据、数据增减、写回数据三个操作，这显然不是单个命令操作了 别担心，Redis 提供了 INCR / DECR 命令，把这三个操作转变为一个原子操作了。INCR / DECR 命令可以对数据进行增值 / 减值操作，而且它们本身就是单个命令操作，Redis 在执行它们时，本身就具有互斥性 所以，如果我们执行的 RMW 操作是对数据进行增减值的话，Redis 提供的原子操作 INCR 和 DECR 可以直接帮助我们进行并发控制 但是，如果我们要执行的操作不是简单地增减数据，而是有更加复杂的判断逻辑或者是其他操作，那么，Redis 的单命令操作已经无法保证多个操作的互斥执行了。这个时候，我们修使用第二个方法，也就是 Lua 脚本 Redis 会把整个 Lua 脚本作为一个整体执行，在执行的过程中不会被其他命令打断，从而保证了 Lua 脚本中操作的原子性。如果我们有多个操作要执行，但是又无法用 INCR / DECR 这种命令操作来实现，就可以把这些要执行的操作编写到一个 Lua 脚本中。然后，我们可以使用 Redis 的 EVAL 命令来执行脚本，这样，这些操作在执行时就具有了互斥性 举个例子，当一个业务应用的访问用户增加时，我们需要限制某个客户端在一定时间范围内的访问次数，比如爆款商品的购买限流，社交网络中的每分钟点赞次数限制等 怎么限制呢？我们可以把客户端 IP 作为 key，把客户端的访问次数作为 value，保存到 Redis 中。客户端没访问一次，我们就用 INCR 增加访问次数 不过，这种场景下，客户端限流其实同时包含了对访问次数和时间范围的限制，例如每分钟的访问次数不能超过 20。所以，我们可以在客户端第一次访问时，给对应键值设置过期时间，例如设置为 60s 后过期。同时，在客户端每次访问时，我们读取客户端当前的访问次数，如果次数超过了阈值，就报错，限制客户端再次访问。如下 123456789101112131415// 获取IP对应的访问次数current = GET(ip)// 如果访问次数超过 20 次，报错IF current != NULL AND current &gt; 20 THEN ERROR "exceed 20 accesses per second"ELSE // 如果访问次数不足 20 次，增加一次访问计数 value = INCR(ip) // 如果是第一次访问，将键值对的过期时间设置为 60s 后 IF value == 1 THEN EXPIRE(ip, 60) END // 执行其他操作 DO THINGSEND 这个例子中，我们使用了 INCR 来原子性地增加计数。但是，客户端限流的逻辑不只有计数，还包括访问次数判断和过期时间设置 对于这些操作，我们同样需要保证它们的原子性。所以，这个例子中的操作无法用 Redis 单个命令来实现，此时，我们就可以使用 Lua 脚本来保证并发控制。我们可以把访问次数加 1、判断访问次数是否为 1，以及设置过期时间这三个操作写入一个 Lua 脚本，如下： 12345local currentcurrent = redis.call("incr", KEYS[1])if tonumber(current) == 1 then redis.call("expire", KEYS[1], 60)end 假设我们编写的脚本名称为 lua.script，我们就可以使用 Redis 客户单，带上 eval 选项，来执行该脚本。脚本所需的参数将通过以下命令中的 keys 和 args 进行传递 1redis-cli --eval lua.script keys, args 这样一来，访问次数加 1、判断访问此时是否为 1，以及设置过期时间这三个操作就可以原子性地执行了。即使客户端有多个线程同时执行这个脚本，Redis 也会依次串行执行脚本代码，避免了并发操作带来的数据错误]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 缓存污染]]></title>
    <url>%2FCKING.github.io%2F2022%2F01%2F10%2FRedis-%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93%2F</url>
    <content type="text"><![CDATA[什么是缓存污染？在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中，就只会白白占用缓存空间。这就是缓存污染 解决缓存污染要解决缓存污染，就要把不会再被访问的数据筛选出来并淘汰掉。这样就不用等到缓存被写满以后，再逐一淘汰旧数据之后，才能写入新数据。而哪些数据能留存在缓存中，是由缓存的淘汰策略决定的 Redis 一共有 8 中数据淘汰策略。分别是 noeviction、volatile-random、volatile-ttl、volatile-lru、volatile-lfu、allkeys-lru、allkeys-random 和 allkeys-lfu 策略 其中，noeviction 策略是不会进行数据淘汰的，所以它不能用来解决缓存污染问题。而 volatile-random 和 allkeys-random 这两种策略，都是采用随机挑选数据的方式，来筛选即将被淘汰的数据 既然是随机挑选，那么 Redis 就不会根据数据的访问情况来筛选数据。如果淘汰的数据又被访问了，就会发生缓存缺失。即，应用需要到后端数据库访问这些数据，降低了应用的请求响应速度。所以，volatile-random 和 allkeys-random 在避免缓存污染的问题上效果非常有限 而 volatile-ttl 针对是是设置了过期时间的数据，把这些数据中剩余存活时间最短的筛选出来并淘汰掉。虽然 volatile-ttl 策略不再是随机淘汰数据了，但是剩余存活时间并不能直接反映数据再次访问的情况。所以，按照 volatile-ttl 策略淘汰数据，也可能出现数据被淘汰后，被再次访问导致的缓存缺失问题 LRU 缓存策略LRU 策略的核心思想：如果一个数据刚刚被访问，那么这个数据肯定是热数据，还会被再次访问 按照这个核心思想，Redis 中的 LRU 策略，会在每个数据对应的 RedisObject 结构体中设置一个 lru 字段，用来记录数据的访问时间戳。在进行数据淘汰时，LRU 策略会在候选数据集中淘汰掉 lru 字段值最小的数据（也就是访问时间最久的数据） 所以，在数据被频繁访问的业务场景中，LRU 策略的确能有效留存访问时间最近的数据。而且，因为留存的这些数据还会被再次访问，所以可以提升业务应用的访问速度 但是，也正是因为只看数据的访问时间，使用 LRU 策略在处理扫描式单次查询操作时，无法解决缓存污染。所谓的扫描式查询操作，就是指应用对大量的数据进行一次全体读取，每个数据都会被读取，而且只会被读取一次。此时，因为这些被查询的数据刚刚被访问过，所以 lru 字段值都很大 在使用 LRU 策略淘汰数据时，这些数据会留存在缓存中很长一段时间，造成缓存污染。如果查询的数据量很大，这些数据占满了缓存空间，却有不会服务新的缓存请求，此时，再有新数据要写入缓存的话，还是需要先把这些旧数据替换出缓存才行，这会影响缓存的性能 所以，对于采用了 LRU 策略的 Redis 缓存来说，扫描式单词查询会造成换粗污染。为了应对这类缓存污染问题，Redis 从 4.0 版本开始增加了 LFU 淘汰策略 与 LRU 策略相比，LFU 策略中会从两个维度来筛选并淘汰数据：一是，数据访问的时效性；二是，数据的被访问次数 LFU 缓存策略的优化LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存 和那些被频繁访问的数据相比，扫描式单次查询的数据因为不会被再次访问，所以它们的访问次数不会再增加。因此，LFU 策略会优先把这些访问次数低的数据淘汰出来缓存。这样，LFU 策略就可以避免这些数据对缓存造成污染了 那么，LFU 策略具体是如何实现的呢？既然 LFU 策略是在 LRU 策略上做的优化，那它们的实现必然有些关系。我们先看看 LRU 策略的实现 为了避免操作链表的开销，Redis 在实现 LRU 策略时使用了两个近似方法： Redis 是用 RedisObject 结构来保存数据的，RedisObject 结构中设置了一个 lru 字段，用来记录数据的访问时间戳 Redis 并没有为所有的数据都维护一个全局链表，而是通过随机采样方式，选取一定数量（例如 10 个）的数据放入候选集合，后续在候选集合中根据 lru 字段值的大小进行筛选 在此基础上，Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分： ldt 值：lru 字段的前 16bit，表示数据的访问时间戳 counter 值：lru 字段的后 8bit，表示数据的访问次数 总结一下：当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰 但是，Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255，这可以吗？在实际应用中，一个数据可能会被访问成千上万次，如果每被访问一次，counter 值就加 1 的话，那么，只要访问次数超过了 255，数据的 counter 值就一样了。在进行数据淘汰时，LFU 策略就无法很好地区分并筛选这些数据，反而还可能把不怎么访问的数据留存在缓存中 所以，在实现 LFU 策略时，Redis 并没有采用数据每被访问一次，就给对应的 counter 值加 1 的计数规则，而是采用了更优化的计数规则 LFU 策略实现的计数规则是：每当数据被访问一次时，首先，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，在取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在 (0, 1) 间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器再加 1 如下，显示了 LFU 策略增加计数器值的计算逻辑。其中，baseval 是计数器当前的值。计数器的初始值默认是 5（由代码中的 LFU_INIT_VAL 常量设置），而不是 0，这样可以避免数据刚被写入缓存，就因为访问次数太少而被立即淘汰 1234double r = (double) rand() / RAND_MAX;...double p = 1.0 / (baseval * server.lfu_log_factoer + 1);if(r &lt; p) counter++; 使用了这种计算规则后，我们可以通过设置不同的 lfu_log_factor 配置项，来控制计数器增加的速度，避免 counter 值很快就到 255 了 为了更进一步说明 LFU 策略计数器递增的效果，可以看下面这张表，这是 Redis 官网提供的一张表，记录了当 lfu_log_factor 取不同值时，在不同的实际访问次数情况下，计数器的值是如何变化的 因为使用了非线性递增的计数器方法，即使缓存数据的访问次数成千上万，LFU 策略也可以有效地区分不同的访问次数，从而进行合理的筛选。上图中可以看到，当 lfu_log_factor 取值为 10 时，百、千、十万级别的访问次数对应的 counter 值已经有明显的区分了，所以，我们在应用 LFU 策略时，一般可以将 lfu_log_factor 取值为 10 在一些场景下，有些数据在短时间内被大量访问后就不会再被访问了。那么再按照访问次数来筛选的话，这些数据会被留存在缓存中，但不会提升缓存命中率。为此，Redis 在实现 LFU 策略时，还设计了一个 counter 值的衰减机制 简单来说，LFU 策略使用衰减因子配置项 lfu_decay_time 来控制访问次数的衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，得到的结果就是数据 counter 要衰减的值 例如，假设 lfu_decay_time 取值为 1，如果数据在 N 分钟内没有被访问，那么它的访问次数就要减 N。如果 lfu_decay_time 取值更大，那么相应的衰减值会变小，衰减效果也会减弱。所以，如果业务应用中有短时高频访问的数据的话，建议把 lfu_decay_time 值设置为 1，这样一来，LFU 策略在它们不再被访问后，会较快地衰减它们的访问次数，尽早把它们从缓存中淘汰出去，避免缓存污染]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 之 GEO]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F26%2FRedis-%E4%B9%8B-GEO%2F</url>
    <content type="text"><![CDATA[面向 LBS 应用的 GEO 数据类型日常生活中，搜索附近的人，打车软件上叫车，这些都离不开基于位置信息服务（Location-Based Service，LBS）的应用。LBS 应用访问的数据是和人或无关联的一组经纬度信息，而且要能查询相邻的经纬度范围，GEO 就非常适合应用在 LBS 服务的场景中 GEO 的底层结构我们以叫车服务为例，分析下 LBS 应用中经纬度的存取特点 每一辆网约车都有一个编号（例如 33），网约车需要将自己的经度信息（例如 116.034579）和纬度信息（例如 39.000452）发给叫车应用 用户在叫车的时候，叫车应用会根据用户的经纬度位置（例如经度 116.054579，纬度 39.030452），查找用户的附近车辆，并进行匹配 等把位置相近的用户和车辆匹配上以后，叫车应用就会根据车辆的编号，获取车辆的信息，并返回给用户 可以看到，一辆车（或一个用户）对应一组经纬度，并且随着车（或用户）的位置移动，相应的经纬度也会变化 这种数据记录模式属于一个 key（例如车 ID）对应一个 value（一组经纬度）。当有很多车辆信息要保存时，就需要有一个集合来保存一系列的 key 和 value。Hash 集合类型可以快速存取一系列的 key 和 value，正好可以用来记录一系列车辆 ID 和经纬度的对应关系。所以，我们可以把不同车辆的 ID 和它们对应的经纬度信息存在 Hash 集合中，如下： 同时，Hash 类型的 HSET 操作命令，会根据 key 来设置相应的 value 值，所以，我们可以用它来快速地更新车辆变化的经纬度信息 但是，对于一个 LBS 应用来说，除了记录经纬度消息，还需要根据用户的经纬度信息在车辆的 Hash 集合中进行范围查询。一旦涉及到范围查询，就意味着集合中的元素需要有序，但 Hash 类型的元素是无序的，显然不能满足需求 接着我们看 Sorted Set 类型是否合适。Sorted Set 也支持一个 key 对应一个 value 的记录模式，其中，key 就是 Sorted Set 中的元素，value 则是元素的权重分数。更重要的是，Sorted Set 可以根据元素的权重分数排序，支持范围查询。这就能满足 LBS 服务中查找相邻位置的需求了 用 Sorted Set 来保存车辆的经纬度信息时，Sorted Set 的元素是车辆 ID，元素的权重分数是经纬度信息，如下： 其实，GEO 类型的底层数据结构就是用 Sorted Set 来实现的。但是 Sorted Set 元素的权重分数是一个浮点数（float 类型），而一组经纬度包含的是经度和纬度两个值，是没法直接保存为一个浮点数的，那要怎么保存？ 这就要用到 GEO 类型的 GeoHash 编码了 GeoHash 的编码方法为了高效地对经纬度进行比较，Redis 采用了业务广泛使用的 GeoHash 编码方法，这个方法的基本原理就是「二分区间，区间编码」 当我们要对一组经纬度进行 GeoHash 编码时，我们先要对经度和纬度分别编码，然后再把经纬度各自的编码合成一个最终编码 首先，我们看经度和纬度的单独编码过程 对于一个地理位置信息来说，它的经度范围是 [-180, 180]。GeoHash 编码会把一个经度值编码成一个 N 位的二进制值，我们来对经度范围 [-180, 180] 做 N 次的二分区操作，其中 N 可以自定义 在进行第一次二分区时，经度范围 [-180, 180] 会被分成两个子区间： [-180, 0) 和 [0, 180]（称之为左、右分区）。此时，我们可以查看一下要编码的经度值落在了左分区还是右分区。如果落在左分区，就用 0 表示；如果在右分区，就用 1 表示。这样一来，每做完一次二分区，我们就可以得到 1 位编码值 然后，我们再对经度值所属的分区再做一次二分区，同时再次查看经度值落在了二分区后的左分区还是右分区，按照刚才的规则再做 1 位编码。当做完 N 次的二分区后，经度值就可以用一个 N bit 的数来表示了 举个例子，我们要编码的经度值是 116.37，我们用 5 位编码值（即 N = 5，做 5 次分区） 我们先做第一次二分区操作，把经度区间 [-180, 180] 分成了左分区 [-180, 0) 和 右分区 [0, 180]。此时，经度值 116.37 是属于右分区 [0, 180]。所以，我们用 1 表示第一次二分区后的编码值 接下来，我们做第二次二分区，把经度值 116.37 所属的 [0, 180]，分成 [0, 90) 和 [90, 180]。此时，经度值 116.37 还是属于右分区 [90, 180]。所以，第二次分区后的编码值仍然为 1 按照这种方法，做完 5 次分区后，我们把经度值 116.37 定位在 [112.5, 123.75] 这个区间，并且得到了经度值的 5 位编码值，即 11010。编码过程如下： 对纬度的编码方式也是一样，只是纬度的范围是 [-90, 90]，下图显示了对纬度值 39.86 的编码过程 当一组经纬度值都编完码后，再把它们的各自编码值组合在一起，组合的规则是：最终编码值的偶数位上依次是经度的编码值，奇数位上依次是纬度的编码值。其中，偶数位从 0 开始，奇数位从 1 开始 刚刚计算的经纬度（116.37, 39.86）的各自编码值是 11010 和 10111，按照上面的规则，就能得到最终编码值 1110011101，如下： 用了 GeoHash 编码后，原来无法用一个权重分数表示的一组经纬度（116.37, 39.86）就可以了用 1110011101 这一个值来表示了，就可以保存为 Sorted Set 的权重分数了 当然，使用 GeoHash 编码后，我们相当于把这个地理空间划分成了一个个方格，每个方格对应了 GeoHash 中的一个分区 例如，我们把经度区间 [-180, 180] 做一次二分区，把纬度区间 [-90, 90] 做一次二分区，就会得到 4 个分区。它们的经度和纬度范围以及对应的 GeoHash 组合编码如下： 分区一：[-180, 0) 和 [-90, 0)，编码 00 分区二：[-180, 0) 和 [0, 90]，编码 01 分区三：[0, 180] 和 [-90, 0)，编码 10 分区四：[0, 180] 和 [0, 90]，编码 11 这 4 个分区对应了 4 个方格，每个方格覆盖了一定范围内的经纬度值，分区越多，每个方格能覆盖到的地理空间就越小，也就越精准。我们把所有方格的编码值映射到一维空间时，相邻方格的 GeoHash 编码值基本也是接近的，如下： 所以，我们使用 Sorted Set 范围查询得到的相近编码值，在实际的地理空间上，也是相邻的方格，这就可以实现 LBS 应用「搜索附近的人或物」的功能了 不过，有的编码值虽然在大小上接近，但实际对应的方格却距离比较远。例如，我们用 4 位来做 GeoHash 编码，把经度区间 [-180, 180] 和纬度区间 [-90, 90] 各分成了 4 个分区，一共 16 个分区，对应了 16 个方格。编码值为 0111 和 1000 的两个方格就离得比较远，如下： 所以，为了避免查询不准确问题，我们可以同时查询给定经纬度所在的方格周围的 4 个或 8 个方格 如何操作 GEO 类型在使用 GEO 类型时，我们经常会用到两个命令，分别是 GEOADD 和 GEORADIUS GEOADD 命令：用于把一组经纬度信息和相对应的一个 ID 记录到 GEO 类型集合中 GEORADIUS 命令：会根据输入的经纬度位置，查找以这个经纬度为中心的一定范围内的其他元素。当然，我们可以自己定义这个范围 举个例子。假设车辆 ID 是 33，经纬度位置是 (116.034579, 39.030452)，我们可以用一个 GEO 集合保存所有车辆的经纬度，集合 key 是 cars:locations。执行下面的命令，就可以把 ID 号为 33 的车辆的当前经纬度位置存入 GEO 集合中 1GEOADD cars:locations 116.034579 39.030452 33 当用户想要寻找自己附近的网约车时，LBS 应用就可以使用 GEORADIUS 命令 例如，执行下面命令时，Redis 会根据输入的用户的经纬度信息 (116.034579, 39.030452)，查找以这个经纬度为中心的 5 公里内的车辆信息。当然，你可以修改 “5” 这个参数，来返回更大或更小范围内的车辆信息 1GEORADIUS cars:locations 116.034579 39.030452 5 km ASC COUNT 10 上面命令中，使用 ASC 选项，让返回的车辆信息按照距离这个中心位置从近到远的方式来排序，以方便选择最近的车辆；还可以使用 COUNT 选项，指定返回的车辆信息的数量]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 之集合使用场景]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F17%2FRedis-%E4%B9%8B%E9%9B%86%E5%90%88%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[聚合统计所谓的聚合统计，就是指统计多个元素的聚合结果，包括：统计多个集合的共有元素（交集统计）；把两个元素相比，统计其中一个集合独有的元素（差集统计）；统计多个集合的所有元素（并集统计） 例如，统计手机 APP 每天的新增用户数和第二天的留存用户数，正好对应了聚合统计。要完成这个统计任务，我们可以用一个集合记录所有登录过 APP 的用户 ID，同时，用另一个集合记录每一天登录过 APP 的用户 ID。然后，在对这两个集合做聚合统计。我们看看具体的操作 记录所有登录过 APP 的用户 ID 比较简单，我们可以直接使用 Set 类型，把 key 设置为 user:id，表示记录的是用户 ID，value 就是一个 Set 集合，里面是所有登录过 APP 的用户 ID，我们可以把这个 Set 叫做累计用户 Set 需要注意的是，累积用户 Set 中没有日期信息，我们是不能直接统计每天的新增用户的。所以，我们还需要把每一天登录的用户 ID，记录到一个新集合中，我们把这个集合叫做每日用户 Set，它有两个特点： key 是 user:id 以及当天日期，例如 user:id:20200803 value 是 Set 集合，记录当天登录的用户 ID 在统计每天的新增用户时，我们只用计算每日用户 Set 和累计用户 Set 的差集就行 假设我们手机 APP 在 2020 年 8 月 3 日上线，那么 8 月 3 日前是没有用户的。此时，累计用户 Set 是空集，当天登录的用户 ID 会被记录到 key 为 user:id:20200803 的 Set 中。所以，user:id:20200803 这个 Set 中的用户就是当天的新增用户 然后，我们计算累计累计用户 Set 和 user:id:20200803 Set 的并集结果，结果保存在 user:id 这个累计用户 Set 中 1SUNIONSTORE user:id user:id user:id:20200803 此时，user:id 累计用户 Set 就有了 8 月 3 日的用户 ID。等到 8 月 4 日再统计时，我们把 8 月 4 日登录的用户 ID 记录到 user:id:20200804 的 Set 中。接着，我们执行 SDIFFSTORE 命令计算累计用户 Set 和 user:id:20200804 Set 的差集，结果保存在 key 为 user:new 的 Set 中 1SDIFFSTORE user:new user:id:20200804 user:id 这个差集中的用户 ID 在 user:id:20200804 的 Set 中存在，但是不在累计用户 Set 中。所以，user:new 这个 Set 中记录的就是 8 月 4 日的新增用户 当要计算 8 月 4 日的留存用户时，我们只需要计算 user:id:20200803 和 user:id:20200804 两个 Set 的交集，就可以得到同时在这两个集合中的用户 ID 了，这些就是在 8 月 3 日登录，并且在 8 月 4 日留存的用户 1SINTERSTORE user:id:rem user:id:20200803 user:id:20200804 当你需要对多个集合进行聚合计算时，Set 类型是一个非常不错的选择，但是，它有一个潜在风险 Set 的差集、并集和交集的计算复杂度较高，在数据量较大的情况下，如果直接执行这些计算，会导致 Redis 实例阻塞。所以，你可以从主从集群中选择一个从库，让它专门负责聚合计算，或者是把数据读取到客户端，在客户端来完成聚合统计。这样就可以规避阻塞主库实例和其他从库实例的风险了 排序统计接着我们看看对集合元素排序需求的方法，以电商网站上提供最新评论列表的场景为例。最新评论列表包含了所有评论中的最新留言，这就要求集合类型能对元素保序，即集合中的元素可以按序排列，这种对元素保底的集合类型叫做有序集合 在 Redis 常用的 4 个集合类型中，List 和 Sorted Set 就属于有序集合 List 是按照元素进入 List 的顺序进行排序的，而 Sorted Set 可以根据元素的权重来排序，我们可以自己来决定每个元素的权重值。比如，我们可以根据元素插入 Sorted Set 的时间确定权重值，先插入的元素权重小，后插入的元素权重大 我们先看 List 的情况。每个商品对应一个 List，这个 List 包含了对这个商品的所有评论，而且会按照评论时间保存这些评论，没来一个新评论，就用 LPUSH 命令把它插入 List 的队头 在只有一页评论的时候，我们可以很清晰地看到最新的评论。但是，网站一般会分页显示最新的评论列表，一旦涉及到分页操作，List 就可能出现问题 假设当前的评论 List 是 {A, B, C, D, E, F}，其中，A 是最新的评论，以此类推，F 是最早的评论。在展示第一页的 3 个评论时，我们可以用下面的指令，得到最新三条评论 A、B、C 1234LRANGE product1 0 21) "A"2) "B"3) "C" 然后，再用下面的命令获取第二页的 3 个评论，也就是 D、E、F 1234LRANGE product1 3 51) "D"2) "E"3) "F" 但是，在展示第二页前，又产生了一个新评论 G，评论 G 就会被 LPUSH 命令插入到评论 List 的队头，List 就变成了 {G, A, B, C, D, E, F}。此时，再用刚才的命令获取第二页评论时，评论 C 又被展示出来了 1234LRANGE product1 3 51) "C"2) "D"3) "E" 之所以会这样，关键原因在于 List 是通过元素在 List 中的位置来排序的，当有一个新元素插入时，原先的元素在 List 中的位置都后移了一位。所以，对比新元素插入前后，List 相同位置上的元素就会发生变化，用 LRANGE 读取时，就会读到旧元素 和 List 相比，Sorted Set 就不存在这个问题，因为它是根据元素的实际权重来排序和获取数据的 我们可以按评论时间的先后给每条评论设置一个权重值，然后再把评论保存到 Sorted Set 中。Sorted Set 的 ZRANGEBYSCORE 命令就可以按权重排序后返回元素。这样，即使集合的元素频繁更新，Sorted Set 也能通过 ZRANGEBYSCORE 命令准确获取到按排序排列的数据 假设越新的评论权重越大，目前最新评论的权重是 N，我们执行下面的命令时，就可以获得最新的 10 条评论 1ZRANGEBYSCORE comments N-9 N 所以，在面对需要展示最新列表、排行榜等场景时，如果数据更新频繁或者需要分页显示，建议优先考虑用 Sorted Set 二值状态统计这里的二值状态是指集合元素的取值就只有 0 和 1 两种。在签到打卡的场景中，我们只用记录签到（1）或未签到（0），这就是典型的二值状态 在签到统计时，每个用户一天的签到用 1 个 bit 位就能表示，一个月（假设是 31 天）的签到情况用 31 个 bit 位，而一年的签到值需要用到 365 个 bit 位，根本不用太复杂的集合类型。这个时候，我们就可以选择 Bitmap Bitmap 本身是用 String 类型作为底层数据结构实现的一种统计二值状态的数据类型。String 类型是会保存为二进制的字节数组，所以，Redis 就把字节数组的每个 bit 位利用起来，用来表示一个元素的二值状态。你可以把 Bitmap 看做是一个 bit 数组 Bitmap 提供了 GETBIT / SETBIT 操作，使用一个偏移量 offset 对 bit 数组的某一个 bit 位进行读和写。不过，Bitmap 的偏移量是从 0 开始算的，即 offset 的最小值是 0.当使用 SETBIT 对一个 bit 位进行写操作时，这个 bit 位被被设置为 1。Bitmap 还提供了 BITCOUNT 操作，用来统计这个 bit 数组所有「1」的个数 假设我们要统计 ID 3000 的用户在 2020 年 8 月份的签到情况，就可以按照下面的步骤进行操作 第一，执行下面的命令，记录用户 8 月 3 号已签到 1SETBIT uid:sigin:3000:202008 2 1 第二，检查该用户 8 月 3 日是否签到 1GETBIT uid:sigin:3000:202008 2 第三，统计该用户在 8 月份的签到次数 1BITCOUNT uid:sigin:3000:202008 如果记录了 1 亿个用户 10 天的签到情况，有办法统计处这 10 天连续签到的用户总数吗？ 其实，Bitmap 支持用 BITOP 命令对多个 Bitmap 按位做「与」「或」「异或」的操作，操作的结果会保存到一个新的 Bitmap 中 如下，三个 Bitmap bm1、bm2 和 bm3，对应 bit 位做「与」操作，结果保存到了一个新的 Bitmap 中 因此，在统计 1 亿个用户连续 10 天的签到情况时，可以把每天的日期作为 key，每个 key 对应 1 亿 位的 Bitmap，每一个 bit 对应一个用户当天的签到情况 接着，我们对 10 个 Bitmap 做「与」操作，得到的结果也是一个 Bitmap。在这个 Bitmap 中，只有 10 天都签到的用户对应的 bit 位上的值才会是 1。最后，我们可以用 BITCOUNT 统计下 Bitmap 中的 1 的个数，这就是连续签到 10 天的用户总数了 我们计算一下 10 天签到后的内存开销。每天使用 1 个 1 亿位的 Bitmap，大约站 12MB 的内存（10 ^ 8 / 8 / 1024 / 1024），10 天的 Bitmap 的内存开销大约为 120MB，内存压力不算太大。不过在实际应用时，最好对 Bitmap 设置过期时间，让 Redis 自动删除不再需要的签到记录，以节省内存开销 所以，如果只需要统计数据的二值状态。例如商品有没有、用户在不在等，就可以使用 Bitmap。在记录海量数据时，Bitmap 能够有效地节省内存空间 基数统计基数统计就是统计一个集合中不重复的元素个数。例如统计网页 UV，就需要去重，一个用户一天内的多次访问只能算一次。在 Redis 的集合类型中，Set 类型集合默认支持去重，所以看到有去重需求时，第一时间就会想到用 Set 类型 我们用一个例子来看一看用 Set 的情况。有一个用户 user1 访问 page1 时，你把这个信息加到 Set 中： 1SADD page1:uv user1 用户 1 再来访问时，Set 的去重功能就保证了不会重复记录用户 1 的访问次数，这样，用户 1 就算是一个独立访客。当你需要统计 UV 时，可以直接使用 SCARD 命令，这个命令会返回一个集合中的元素个数 但是，如果 page1 非常火爆，UV 达到了千万，这个时候，一个 Set 就要记录千万个用户 ID。对于一个搞大促的电商网站而言，这样的页面可能有成千上万个，如果每个页面都用这样的一个 Set，就会消耗很大的内存空间 当然，你也可以使用 Hash 类型记录 UV 例如，你可以把用户 ID 作为 Hash 集合的 Key ，当用户访问页面时，就用 HSET 命令（用于设置 Hash 集合元素的值），对这个用户 ID 记录一个值「1」，表示一个独立访客，用户 1 访问 page1 后，我们就记录为 1 个独立访客，如下： 1HSET page1:uv user1 1 即使用户 1 多次访问页面，重复执行这个 HSET 命令，也只会把 user1 的值设置为 1，仍然只记录为 1 个独立访客。当要统计 UV 时，我们可以用 HLEN 命令统计 Hash 集合中的所有元素个数 但是，和 Set 类型相似，当页面很多时，Hash 类型也会消耗很大的内存空间。有什么办法可以既能完成统计，还能节省内存吗？ 这个就要用到 Redis 提供的 HyperLogLog 了 HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小 在 Redis 中，每个 HyperLogLog 只需要花费 12KB 内存，就可以计算接近 2 ^ 64 个元素的基数。在统计 UV 时，可以用 PFADD 命令（用于向 HyperLogLog 中添加元素）把访问页面的每个用户都添加到 HyperLogLog 中 1PFADD page1:uv user1 user2 user3 user4 user5 接着，就可以用 PFCOUNT 命令直接获得 page1 的 UV 值了，这个命令的作用就是返回 HyperLogLog 的统计结果 1PFCOUNT page:uv 不过，HyperLogLog 的统计规则是基于概率完成的，所以它给出的统计结果是有一定误差的，标准误差率是 0.81%。这就是说，你使用 HyperLogLog 统计的 UV 是 100 万，但实际的 UV 可能是 101 万。虽然误差率不算大，但如果你要精确统计的话，最好还是继续用 Set 或 Hash 类型 小结]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka 之副本机制]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F16%2FKafka-%E4%B9%8B%E5%89%AF%E6%9C%AC%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Kafka 是有主题概念的，而每个主题又进一步分成若干个分区。副本的概念实际上是在分区层架下定义的，每个分区配置有若干个副本。所谓副本，本质就是一个只能追加消息的提交日志。同一个分区下的所有副本保存有相同的消息序列，这些副本分散保存在不同的 Broker 上，从而能够对抗部分 Broker 宕机带来的数据不可用 如下图，展示的是一个有 3 台 Broker 的 Kafka 集群上的副本分布情况。我们可以看到，主题 1 分区 0 的 3 个副本分散在 3 台 Broker 上，其他主题分区的副本也都散落在不同的 Broker 上，从而实现数据冗余 副本角色当生产者发送消息到某个主题后，消息是如何同步到对应的所有副本中的呢？针对这个问题，最常见的解决方案就是采用基于领导者（Leader - based）的副本机制 第一，在 Kafka 中，副本分成两类：领导者副本（Leader Replica）和追随者副本（Follower Replica）。每个分区在创建时都要选举一个副本，成为领导者副本，其余的副本自动称为追随者副本 第二，在 Kafka 中，Follower Replica 是不对外提供服务的。即，所有的读写请求都必须发往 Leader Replica 所在的 Broker 处理。Follower Replica 不处理客户端请求，它唯一的任务就是从 Leader Replica 异步拉取消息，并写入到自己的提交日志中，从而实现与 Leader Replica 的同步 第三，当 Leader Replica 所在的 Broker 宕机时，Kafka 依托与 ZooKeeper 提供的监控功能能够实时感知到，并开启新一轮的 Leader 选举，从 Follower Replica 中选一个作为新的 Leader。老 Leader Replica 重启回来后，只能作为 Follower 加入到集群中 对于客户端而言，Kafka 的 Follower Replica 没有任何作用，它既不能像 MySQL 那样帮助 Leader Replica 「扛读」，也不能实现将某些副本放到离客户端近的地方来改善数据局部性 那 Kafka 为什么要这么设计？其实有两个方面的好处： 1、方便实现「Read - your - writes」 所谓「Read - your - writes」，就是当你使用生产者 API 向 Kafka 成功写入消息后，马上使用消费者 API 去读刚才生产的消息 例如，你平时发微博时，刚发完一条，肯定是希望能立即看到的，这就是典型的 Read - your - writes 场景。如果允许 Follower Replica 对外提供服务，由于副本同步是异步的，所以有可能出现 Follower Replica 还没有从 Leader Replica 那里拉取到最新的消息，从而使得客户端看不到最新写入的消息 2、方便实现单调读 单调读就是，对于一个消费者用户而言，在多次消费消息时，它不会看到某条消息一会存在一会不存在 如果允许 Follower Replica 提供读服务，假设当前有 2 个 Follower Replica，分别是 F1 和 F2，它们异步地拉取 Leader Replica 数据。如果 F1 拉取了 Leader 的最新消息而 F2 还没有及时拉取，那么，此时如果有一个消费者从 F1 读取消息之后又从 F2 拉取消息，它可能会遇到：第一次消费时看到的最新消息在第二次消费时不见了，这就不是单调读一致性了 但是，如果所有的读请求都是由 Leader 来处理，那么 Kafka 就很容易实现单调读一致性 In - sync Replica（ISR）上面说过，Follower 不提供服务，只是定期地异步拉取 Leader 中的数据而已。既然是异步，就存在这不可能与 Leader 实时同步的风险。那么，Follower 到底在什么条件下才算可以与 Leader 同步？ 基于这个想法，Kafka 引入了 In- sync Replica，即 ISR 副本集合。ISR 中的副本都是与 Leader 同步的副本，相反，不在 ISR 中的 Follower 就被认为是与 Leader 不同步的。那么，什么副本能进入 ISR 中呢？ 首先要明确的是，Leader 副本天然就在 ISR 中。即，ISR 不只是 Follower 副本集合，它必然包含 Leader 副本。甚至在某些情况下，ISR 只有 Leader 这一个副本 Follower 是否与 Leader 同步，主要看 Broker 端参数 replica.lag.time.max.ms 的值。这个参数的含义是 Follower 副本能够落后 Leader 副本的最长时间间隔，当前默认值是 10 秒。即，只要一个 Follower 落后 Leader 的时间不连续超过 10 秒，那么 Kafka 就认为该 Follower 与 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的 上面说过，Follower 副本唯一的工作就是不断地从 Leader 副本拉取消息，然后写入到自己的提交日志中。如果这个同步过程的速度连续慢于 Leader 副本的消息写入速度，那么在 replica.lag.time.max.ms 时间后，此 Follower 副本就会被认为是与 Leader 副本不同步的。此时，Kafka 会自动收缩 ISR 集合，将该副本剔除 ISR 如果该副本后面慢慢地追上 Leader 的进度，那么它是能够重新被加回 ISR 的。这也说明，ISR 是一个动态的集合，而非静态不变的 Unclean 领导者选举（Unclean Leader Election）既然 ISR 是可以动态调整的，那么就可能出现ISR 为空的情况。因为 Leader 副本天然就在 ISR 中，如果 ISR 为空，说明 Leader 副本也挂掉了。Kafka 需要重新选举一个新的 Leader。可是此时 ISR 为空，该怎么选举新 Leader 呢？ Kafka 把所有不在 ISR 中的存活副本都称为非同步副本。一般来说，非同步副本落后 Leader 太多，因此，如果选举这些副本作为新 Leader，就可能出现数据的丢失。毕竟这些副本中保存的消息远远落后于老 Leader 中的消息 在 Kafka 中，选举这种副本的过程称为 Unclean 领导者选举。Broker 端参数 unclean.leader.election.enable 控制是否允许 Unclean 领导者选举 开启 Unclean 领导者选举可能会造成数据丢失，但好处是，它使得分区 Leader 副本一直存在，不至于停止对外提供服务，因此提升了高可用性。反之，禁止 Unclean 领导者选举的好处在于维护了数据的一致性，避免了消息丢失，但牺牲了高可用性 你可以根据记得实际场景决定是否开启 Unclean 领导者选举。不过，我强烈建议不要开启，毕竟我们可以通过其他方式来提升高可用性。如果为了这点高可用性的改善，牺牲了数据一致性，就很不值当了]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka 之位移主题]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F12%2FKafka-%E4%B9%8B%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98%2F</url>
    <content type="text"><![CDATA[Kafka 内部有一个位移主题：__consumer_offsets，它的主要作用就是用来保存 Kafka 消费者的位移信息 位移主题可以看做是一个普通的 Kafka 主题，但它的消息格式却是 Kafka 自己定义的，用户不能修改，即你不能随意地向这个主题写消息，因为一旦你写入的消息不满足 Kafka 规定的格式，那么 Kafka 内部就无法解析成功 那这个主题存的到底是什么格式的消息呢？你可以简单地理解为是一个 KV 对。其中，位移主题的 Key 中保存 3 部分内容：&lt;Group ID，主题名，分区号&gt;。那么它的消息体呢？消息体除了保存一个位移值外，还保存了位移提交的一些其他元数据，诸如时间戳和用户自定义的数据等。保存这些元数据是为了帮助 Kafka 执行各种各样后续的操作，比如删除过期位移信息等。但总体来说，我们还是可以简单地认为消息体就是保存了位移值 事实上，除了上面说的那种格式，消息格式还有 2 种： 用于保存 Consumer Group 信息的消息 用于删除 Group 过期位移甚至是删除 Group 的消息 第一种比较神秘，你只需要记住它是用来注册 Consumer Group 的就可以了 第二种相对有名一些，有个专属的名字：tombstone 消息，即墓碑消息。这些消息只出现在源码中而不暴露给你，它的主要特点是它的消息体是 null，即空消息体 那么，何时会写入这类消息呢？一旦某个 Consumer Group 下的所有 Consumer 实例都停止了，而且它们的位移数据都已被删除了，Kafka 会向位移主题的对应分区写入 tombstone 消息，表名要彻底删除这个 Group 的信息 接着说说位移主题是怎么被创建的。一般来说，当 Kafka 集群中的第一个 Consumer 程序启动时，Kafka 就会自动创建位移主题。位移主题就是普通的 Kafka 主题，那么它自然也有对应的分区数。但如果是 Kafka 自动创建的，分区数是怎么设置呢？这就要看 Broker 端参数 offsets.topic.num.partitions 的取值了。它的默认值是 50，因此 kafka 会自动创建一个 50 分区的位移主题 除了分区数，副本数或者备份因子是怎么控制的？这就是 Broker 端另一个参数 offsets.topic.replication.factor 要做的事情了，它的默认值是 3 总结一下，如果位移主题是Kafka 自动创建的，那么该主题的分区数是 50，副本数是 3 当然，你也可以选择手动创建位移主题，具体方法是，在 kafka 主题尚未启动任何 Consumer 之前，使用 kafka API 创建它。手动创建的好处在于，你可以创建满足你实际场景需要的位移主题。比如 50 个分区太多了，那么你就可以手动创建，不用理会 offsets.topic.num.partitions 的值 不过我给你的建议是，还是让 Kafka 自动创建比较好。目前 Kafka 源码中有一些地方硬编码了 50 分区数，因此如果你自行创建了一个不同于默认分区数的位移主题，可能会碰到各种各种奇怪的问题 创建主题当然是为了用的，那么什么地方会用到位移主题呢？前面一直在说 Kafka Consumer 提交位移时会写入该主题，那 Consumer 是怎么提交位移的？目前 Kafka Consumer 提交位移的方式有两种：自动提交位移和手动提交位移 Consumer 端有个参数 enabled.auto.commit，如果值是 true，则 Consumer 在后台默默地为你定期提交位移，提交间隔由一个专属的参数 auto.commit.interval.ms 来控制。自动提交位移有一个显著的特点，就是省事，你不用操心位移提交的事情，就能保证消息消息不会丢失。但是，自动提交会丧失很大的灵活性和可控性，你完全没法把控 Consumer 端的位移管理 事实上，很多与 Kafka 集成的大数据框架都是禁用自动提交位移的，如 Spark、Flink 等。这就引出了另一种位移提交方式：手动提交位移，即设置 enable.auto.commit = false。一旦设置了 false，作为 Consumer 应用开发的你就要承担起位移提交的责任。Kafka Consumer API 为你提供了位移提交的方法，如 consumer.commitSync 等。当调用这些方法时，Kafka 会向位移主题写入相应的消息 如果你选择的是自动提交位移，那么就可能存在一个问题：只要 Consumer 一直启动着，它就会无限期地向位移主题写入消息 举个极端的例子。假设 Consumer 当前消费到了某个主题的最新一条消息，位移是 100，之后该主题没有任何新消息产生，故 Consumer 无消息可消费了，所以位移永远保持在 100。由于是自动提交位移，位移主题中会不停地写入位移 = 100 的消息。显然 Kafka 只需要保留这类消息中的最新一条就可以了，之前的消息都是可以删除的。这就要求 Kafka 要有针对位移主题消息特点的消息删除策略 Kafka 使用 Compact 策略来删除位移主题中的过期消息。那么如何定义 Compact 策略中的过期呢？对于同一个 Key 的两条消息 M1 和 M2，如果 M1 的发送时间早于 M2，那么 M1 就是过期消息。Compact 的过程就是扫描日志的所有消息，剔除那些过期的消息，然后把剩下的消息整理在一起 图中位移为 0、2、3 的消息的 key 都是 K1。Compact 之后，分区只需要保存位移为 3 的消息，因为它是最新发送的 Kafka 提供了专门的后台线程定期地巡检待 Compact 的主题，看看是否存在满足条件的可删除数据。这个线程叫 Log Cleaner。很多实际生产环境中都出现过位移主题无线膨胀占用过多磁盘空间的问题，这是可以去检查一下 Log Cleaner 线程的状态，通常都是这个线程挂掉导致的]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka 之消费者组]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F12%2FKafka-%E4%B9%8B%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%2F</url>
    <content type="text"><![CDATA[Consumer Group 是 Kafka 提供的可扩展且具有容错性的消费者实例。组内有多个消费者或消费者实例，他们共享一个公共的 ID，这个 ID 被称为 Group ID。组内的所有消费者协调在一起来消费订阅主题（Subscribed Topics）的所有分区（Partition）。当然，每个分区只能由同一个消费组内的一个 Consumer 实例来消费 理解 Consumer Group，记住下面三个特性就行 Consumer Group 下可以有一个或多个 Consumer 实例。这里的实例可以是一个单独的进程，也可以是统一进程下的线程。在实际场景中，使用进程更为常见一些 Group ID 是一个字符串，在一个 Kafka 集群中，它标识唯一的一个 Consumer Group Consumer Group 下所有实例订阅的主题的单个分区，只能分配给组内的某个 Consumer 实例消费。这个分区当然也可以被其他的 Group 消费 Consumer Group 之间彼此独立，互不影响，它们能够订阅相同的一组主题而互不干涉。再加上 Broker 端的消息留存机制，Kafka 的 Consumer Group 完美地规避了伸缩性差的问题。Kafka 仅仅使用 Consumer Group 这一种机制，就同时是吸纳了 传统消息引擎系统的两大模型：如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型；如果所有实例分别属于不同的 Group，那么它实现的就是发布 / 订阅模型 那么，在实际场景中，怎么知道一个 Group 下该有多少个 Consumer 实例呢？理想情况下，Consumer 实例的数量应该等于该 Group 订阅主题的分区总数 例如，一个 Consumer Group 订阅了 3 个主题，分别是 A、B、C，他们的分区数依次是 1、2、3，那么通常情况下，为该 Group 设置 6 个 Consumer 实例是比较理想的情形，它能最大限度地实现高伸缩性 接着，针对 Consumer Group，Kafka 是怎么管理位移的呢？消费者在消费的过程中需要记录自己消费了多少数据，即消费位置信息。在 Kafka 中，这个位置信息有个专门的术语：位移（Offset） 看上去 Offset 就是一个数值而已，其实对于 Consumer Group 而言，它是一组 KV 对，Key 是分区，V 对应 Consumer 消费该分区的最新位移。当然 Kafka 源码中并不是这样简单的数据结构，而是要复杂得多，不过不妨碍我们对 Group 位移的理解 老版本的 Consumer Group 把位移保存在 ZooKeeper 中。将位移保存 ZooKeeper 外部系统的做法，最显而易见的好处就是减少了 Kafka Broker 端的状态保存开销。现在比较流行的做法是将服务器节点做成无状态的，这样可以自由地扩缩容，实现超强的伸缩性。Kafka 最开始也是基于这样的考虑，才将 Consumer Group 位移保存在独立于 Kafka 集群之外的框架中 但是，Kafka 这类元框架其实并不适合进行频繁的写更新，而 Consumer Group 的位移更新确实一个非常频繁的操作。这种大吞吐量的写操作会极大拖慢 ZooKeeper 集群的性能，因此 Kafka 社区意识到，将 Consumer 位移保存在 ZooKeeper 中是不合适的 于是，在新版本的 Consumer Group 中，采用了将位移保存在 Kafka 内部主题的方法。这个内部主题就是 __consumer_offsets 最后，我们再说说 Consumer Group 端的重平衡，也就是所谓的 Rebalance Rebalance 本质上是一种协议，规定了一个 Consumer Group 下所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。比如某个 Group 下有 20 个 Consumer 实例，它订阅了一个具有 100 个分区的 Topic。正常情况下，Kafka 平均会为每个 Consumer 分配 5 个分区。这个分配的过程就叫 Rebalance 那么 Consumer Group 何时进行 Rebalance 呢？Rebalance 的触发条件有 3 个 组成员数发生变更。比如有新的 Consumer 实例加入组或者离开组，抑或是有 Consumer 实例崩溃被「踢出」组 订阅主题数发生变更。Consumer Group 可以使用正则表达式的方式订阅主题，比如 consumer.subscribe(Pattern.compile(“t.*c”)) 就表明该 Group 订阅所有以字母 t 开头、字母 c 结尾的主题。在 Consumer Group 的运行过程中，你新创建了一个满足这样条件的主题，那么该 Group 就会发生 Rebalance 订阅主题的分区数发生变更。Kafka 当前只能允许增加一个主题的分区数。当分区数增加时，就会触发该订阅主题的所有 Group 开启 Rebalance 接着，我们说说 Rebalance 不好的地方 首先，Rebalance 过程对 Consumer Group 消费过程有极大的影响。如果你了解 JVM 的垃圾回收机制，一定听过 stop the world，简称 STW。在 STW 期间，所有应用线程都会停止工作，表现为整个应用程序僵在那一动不动。Rebalance 过程也和这个类似，在 Rebalance 过程中，所有 Consumer 实例都会停止消费，等待 Rebalance 完成。这个 Rebalance 为人诟病的一个方面 其次，目前 Rebalance 的设计是所有 Consumer 实例共同参与，全部重新分配所有分区。其实更高效的做法是尽量减少分配方案的变动。例如实例 A 之前负责消费分区 1、2、3，那么 Rebalance 之后，如果可能的话，最好还是让实例 A 继续消费分区 1、2、3，而不是重新分配其他分区。这样，实例 A 连接这些分区所在 Broker 的 TCP 连接就可以继续用，不用重新创建连接其他 Broker 的 Socket 资源 最后，Rebalance 实在是太慢了。有个国外用于的 Group 内有几百个 Consumer 实例，成功 Rebalance 一次要几个小时。这完全是不能忍受的。目前社区还没有特别好的解决方案，也许最好的方案就是避免 Rebalance 的发生吧]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 之 String]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F11%2FRedis-%E4%B9%8B-String%2F</url>
    <content type="text"><![CDATA[我们要开发一个图片存储系统，要求这个系统能快速地记录图片 ID 和图片再存储系统中保存的 ID。同时，还要能够根据图片 ID 快速查找到图片存储对象 ID 因为图片数量巨大，所以我们用 10 位数来表示图片 ID 和图片存储对象 ID。例如，图片 ID 为 1101000051，它在存储系统中对应的 ID 号是 3301000051 12photo_id: 1101000051photo_obj_id: 3301000051 我们的第一个方案就是用 String 保存数据。String 类型可以保存二进制字节流，只要把数据转成二进制字节数组，就可以保存了 刚开始，我们保存了 1 亿张图片，大约用了 6.4 GB 的内存。但是，随着图片数据量的不断增加，我们的 Redis 内存使用量也在增加，结果就遇到了大内存 Redis 实例因为生成 RDB 而响应变慢的问题。显然，String 类型并不是一种好的选择，我们需要进一步寻找能节省内存开销的数据类型方案 为什么 String 类型内存开销大上面的案例中，一个图片 ID 和图片存储对象 ID 的记录平均使用了 64 字节。但是，一组图片 ID 及其存储对象 ID 的记录，实际只需要 16 字节就可以了 其实，图片 ID 和图片存储对象 ID 都是 10 位数，我们可以用两个 8 字节的 Long 类型表示这两个 ID。因为 8 字节的 Long 类型最大可以表示 2 的 64 次方的数组，肯定可以表示 10 位数字。但是，为什么 String 类型却用了 64 字节呢？ 那么，String 类型具体是怎么保存数据的呢？ 当你保存 64 位有符号整数时，String 类型会把它保存为一个 8 字节的 Long 类型整数，这种保存方式通常也叫做 int 编码方式 但是，当你保存的数据中包含字符串时，String 类型就会用简单动态字符串（SDS ）结构体来保存，如下： buf：字符数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个 “\0”，这就会额外占用 1 个字节的开销 len：占 4 个字节，表示 buf 的已用长度 alloc：占 4 个字节，表示 buf 的实际分配长度，一般大于 len 可以看到，SDS 中，buf 保存实际数据，而 len 和 alloc 本身其实是 SDS 结构体的额外开销 另外，对于 String 类型来说，除了 SDS 的额外开销，还有一个来自于 RedisObject 结构体的开销 以为 Redis 的数据类型有很多，而且不同数据类型都有些相同的元数据要记录（比如最后一次访问的时间，被引用的次数等），所以，Redis 会用一个 RedisObject 结构体来统一记录这些元数据，同时指向实际数据 一个 RedisObject 包含了 8 字节的元数据和一个 8 字节指针，这个指针再进一步指向具体数据类型的实际数据所在，例如指向 String 类型的 SDS 结构所在的内存地址。如下： 为了节省内存，Redis 还对 Long 类型整数和 SDS 的内存布局做了专门的设计 一方面，当保存的是 Long 类型整数时，RedisObject 中的指针就直接赋值为整数数据了，这样就不用额外的指针再指向整数了，节省了指针的空间开销 另一方面，当保存的是字符串数据，并且字符串小于等于 44 字节时，RedisObject 中的元数据、指针和 SDS 是一块连续的内存区域，这样就可以避免内存碎片。这种布局方式也被称为 embstr 编码方式 当字符数大于 44 字节时，SDS 的数据量就开始变多了，Redis 就不再把 SDS 和 RedisObject 布局在一起了，而是会给 SDS 分配独立的空间，并用指针指向 SDS 结构。这种布局方式被称为 raw 编码模式 因为 10 位数的图片 ID 和图片存储对象 ID 是 Long 类型整数，所以可以直接用 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 保存。每个 int 编码的 RedisObject 元数据部分占 8 字节，指针部分被直接赋值为 8 字节的整数了。此时，每个 ID 会使用 16 字节，加起来一共是 32 字节。那么，另外的 32 字节去哪了？ 之前说过，Redis 是使用一个全局哈希表保存所有键值对，哈希表的每一项是一个 dictEntry 的结构体，用来指向一个键值对。dictEntry 结构体中有三个 8 字节的指针，分别指向 key、value 以及下一个 dictEntry，三个指针共 24 字节 但是这三个指针只有 24 个字节，怎么会占用 32 字节呢？这就要提到 Redis 使用的内存分配库 jemalloc了 jemalloc 在分配内存时，会根据我们申请的字节数 N，找一个比 N 大，但是最接近 N 的 2 的幂次数作为分配的空间，这样可以减少频繁分配的次数 例如，如果你申请 6 字节空间，jemalloc 实际会分配 8 字节空间；如果你申请 24 字节空间，jemalloc 则会分配 32 字节。所以，上面的场景里，dictEntry 结构就占用了 32 字节 你看，明明有效信息只有 16 字节，使用 String 类型保存，却需要 64 字节的内存空间，有 48 字节都没有用于保存实际的数据。那么，有没有更加节省内存的方法呢？ 用什么数据结构可以节省内存Redis 有一种底层数据结构，叫压缩列表（ziplist），这是一种非常节省内存的结构。 压缩列表表头有三个字段 zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量，以及列表中的 entry 个数。压缩列表尾还有一个 zlend，表示列表结束 压缩列表之所以能节省内存，就在于它是用一系列连续的 entry 保存数据。每个 entry 的元数据包括下面几部分： prev_len：表示前一个 entry 的长度。prev_len 有两种取值情况：1 字节或 5 字节。取值 1 字节时，表示上一个 entry 的长度小于 254 字节。否则就取值为 5 字节 len：表示自身长度，4 字节 encoding：表示编码方式，1 字节 content：保存实际数据 这些 entry 会挨个放置在内存中。不需要再用额外的指针进行连接，就可以节省指针所占用的空间 我们以保存图片存储对象 ID 为例。每个 entry 保存一个图片存储对象 ID（8 字节），此时每个 entry 的 prev_len 只需要 1 个字节就行，因为每个 entry 的前一个 entry 长度都只有 8 字节，小于 254 字节。这样一来，一个图片的存储对象 ID 所占用的内存大小是 14 字节（1 + 4 +1 + 8 = 14），实际分配 16 字节 Redis 基于压缩列表实现了 List、Hash 和 SortSet 这样的集合类型，最大的好处就是节省了 dictEntry 的开销。当你用 String 类型时，一个键值对就有一个 dictEntry，要用 32 字节空间。但采用集合类型时，一个 key 对应一个集合的数据，能保存的数据多了很多，但也只用了一个 dictEntry，这样就节省了内存 如果用集合类型保存单值的键值对在保存单值的键值对，可以采用基于 Hash 类型的二级编码方法。这里的二级编码，就是把一个单值的数据拆分为两部分，前一部分作为 Hash 集合的 key，后一部分作为 Hash 集合的 value。这样一来，我们就可以把单值数据保存到 Hash 集合中了 以图片 ID 1101000060 和图片存储对象 ID 3302000080 为例，我们可以把图片 ID 的前 7 位（1101000）作为 Hash 类型的键，把图片 ID 的最后 3 位（060）和图片存储对象 ID 分别作为 Hash 类型值中的 key 和 value 按照这种设计方法，在 Redis 中插入一组图片 ID 及其存储对象 ID 的记录，并且用 info 命令查看了内存开销。发现增加一条记录后，内存占用只增加了 16 字节 12345678127.0.0.1:6379&gt; info memory# Memoryused_memory:1039120127.0.0.1:6379&gt; hset 1101000 060 3302000080(integer) 1127.0.0.1:6379&gt; info memory# Memoryused_memory:1039136 在用 String类型时，每个记录需要消耗 64 字节，这种方式却只用了 16 字节，所使用的内存空间是原来的 1/4，满足了我们节省内存空间的需求 但是，二级编码一定要把图片 ID 的前 7 位作为 Hash 类型的键，把最后 3 位作为 Hash 类型值中的 key 吗？其实，二级编码方法中采用的 ID 长度是有讲究的 Redis Hash 类型耳朵两种底层实现结构，分别是压缩列表和哈希表。那么，Hash 类型底层什么时候使用压缩列表，什么时候使用哈希表呢？其实，Hash 类型设置了用压缩列表保存数据时的两个阈值，一旦超过了阈值，Hash 类型就会用哈希表来保存数据了 这两个阈值分别对应一下两个配置项： hash-max-ziplist-entries：表示用压缩列表保存时哈希集合中的最大元素个数 hash_max_ziplist-value：表示用压缩列表保存时哈希集合中单个元素的最大长度 如果我们往 Hash 集合中写入元素的个数超过了 hash-max-ziplist-entries，或者写入的单个元素大小超过了 hash-max-ziplist-value，Redis 就会自动把 Hash 类型的实现结构由压缩列表转为哈希表 一旦从压缩列表转为了哈希表，Hash 类型就会一直用哈希表进行保存，而不会再转回压缩列表了。在节省内存空间方面，哈希表就没有压缩列表那么高效了 为了能充分使用压缩列表的精简内存布局，我们一般要控制保存在 Hash 集合中的元素个数。所以，在刚才的二级编码中，我们只用图片 ID 最后 3 位作为 Hash 集合的 key，也就保证了 Hash 集合的元素个数不超过 1000，同时，我们把 Hash-max-ziplist-entries 设置为 1000，这样，Hash 集合就可以一直使用压缩列表来节省内存空间了]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 之切片集群]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F11%2FRedis-%E4%B9%8B%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据分成多份，每一份用一个实例来保存。在实际应用 Redis 时，随着用户或业务规模的扩展，保存大量数据的情况通常是无法避免的。而切片集群，就是一个非常好的解决方案 数据切片和实例的对应分布关系在切片集群中，数据需要分布在不同实例上，那么，数据和实例之间如何对应呢？这就和 Redis Cluster 方案有关了 实际上，切片集群是一种保存大量数据的通用方案，这个机制可以有不同的实现方案。从 Redis 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则 Redis Cluster 方案采用哈希槽（Hash Slot）来处理数据和实例之间的关系。在 Redis Cluster 方案中，一个切片集群有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中 具体的映射过程分为两大步：首先根据键值对的 key，按照 CRC16 算法计算一个 16 bit 耳朵值；然后，用这个 16 bit 值对 16384 取模，得到 0 ~ 16383 范围内的模数，每个模数代表一个相应编号的哈希槽 那么，这些哈希槽又是如何被映射到具体的 Redis 实例上的呢？ 在不熟 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。例如，如果集群上有 N 个实例，那么每个实例上的槽的个数为 16384 / N 个 当然，我们也可以使用 cluster meet 命令手动建立实例间的连接，形成集群，再使用 cluster addslots 命令，指定每个实例上的哈希槽个数 假设集群中一共有 3 个实例，同时有 5 个哈希槽，我们可以通过下面的命令手动分配哈希槽 123redis-cli -h 172.16.19.3 -p 6379 cluster addslots 0,1redis-cli -h 172.16.19.4 -p 6379 cluster addslots 2,3redis-cli -h 172.16.19.5 -p 6379 cluster addslots 4 另外，在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作 客户端如何定位数据在定位键值对数据时，它所处的哈希槽时可以通过计算得到的，这个计算可以在客户端发送请求时来执行。但是，要进一步定位到实例，还需要知道哈希槽分布在哪个实例上 一般来说，客户端和集群实例建立连接后，实例就会把哈希槽的分配信息发给客户端。但是，在集群刚刚创建的时候，每个实例只知道自己被分配了哪些哈希槽，是不知道其他实例拥有的哈希槽信息的 那么，客户端为什么可以在访问一个实例时，能获得所有的哈希槽信息呢？这是因为，Redis 实例会把自己的哈希槽信息发给和它相连接的其他实例，来完成哈希槽分配信息的扩散。当实例之间相互连接后，每个实例就有所有哈希槽的映射关系了 客户端收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会先计算键值对所对应的哈希槽，然后就可以给相应的实例发送请求了 但是，在集群中，实例和哈希槽的对应关系并不是一成不变的，最常见的变化有两个： 在集群中，实例有新增或删除，Redis 需要重新分配哈希槽 为了负载均衡，Redis 需要把哈希槽在所有实例上重新分布一遍 此时，实例之间还可以通过相互传递信息，获得最新的哈希槽分配信息。但是，客户端是无法主动去感知这些变化的。这就会导致，它缓存的分配信息和最新的分配就不一致了，怎么办呢？ Redis Cluster 方案提供了 一种重定向机制。指客户端给一个实例发送数据读写操作时，这个实例上并没有相应的数据，客户端要再给一个新实例发送操作命令 当客户端把一个键值对的操作请求发送给一个实例时，如果这个实例上并没有这个键值对映射的哈希槽，那么，这个实例就会给客户端返回下面的 MOVED 命令响应结果，这个结果中就包含了新实例的访问地址 12GET hello:key(error) MOVED 13320 172.16.19.5:6379 其中 MOVED 命令表示，客户端请求的键值对所在的哈希槽 13320，实际是在 172.16.19.5 这个实例上。通过返回 MOVED 命令，把新实例的信息告诉给客户端了。这样一来，客户端就可以直接和 172.16.19.5 连接，并发送操作请求了 如下，由于负载均衡，Slot 2 中的数据已经从实例 2 迁移到实例 3，但是，客户端缓存仍然记录着「Slot 2 在实例 2」的信息，所以会给实例 2 发送命令。 实例 2 给客户端返回一条 MOVED 命令，把 Slot 2 的最新位置（也就是在实例 3上），返回给客户端，客户端就会再次向实例 3 发送请求，同时还会更新本地缓存，把 Slot 2 与实例的对应关系更新过来 需要注意的是，上图中，当客户端给实例 2 发送命令时，Slot 2 中的数据已经全部迁移到了实例 3。在实际应用中，如果 Slot 2 中的数据比较多，就可以会出现一种情况：客户端向实例 2 发送请求，但此时，Slot 2 中的数据只有一部分迁移到了实例 3，还有部分数据没有迁移。在这种迁移部分完成的情况下，客户端就会收到一条 ASK 报错信息，如下： 12GET hello:key(error) ASK 13320 172.16.19.5:6379 这个结果中的 ASK 命令就表示，客户端请求的键值对所在的哈希槽 13320，在 172.16.19.5 这个实例上，但是这个哈希槽正在迁移。此时，客户端需要先给 172.16.19.5 这个实例发送一个 ASKING 命令。这个命令的意思是，让这个实例允许执行客户端接下来发送的命令。然后，客户端再向这个实例发送 GET 命令，去读取数据 如下图，Slot 2 正在从实例 2 往实例 3 迁移，key 1 和 key 2 已经迁移过去，key 3 和 key 4 还在实例 2。客户端向实例 2 请求 key 2 后，就会收到实例 2 返回的 ASK 命令 ASK 命令表示两层含义：第一，表名 Slot 数据还在迁移中；第二，ASK 命令把客户端所请求数据的最新实例地址返回给客户端，此时，客户端需要给实例 3 发送 ASKING 命令，然后再发送操作命令 和 MOVED 命令不同，ASK 命令并不会更新客户端缓存的哈希槽分配信息。所以，上图中，如果客户端再次请求 Slot 2 中的数据，它还是会给实例 2 发送请求。即，ASK 命令的作用只是让客户端能给新实例发送一次请求，而不像 MOVED 命令那样，会更改本地缓存，让后续所有命令都发往新实例]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 之 RDB 快照]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F09%2FRedis-%E4%B9%8B-RDB-%E5%BF%AB%E7%85%A7%2F</url>
    <content type="text"><![CDATA[Redis 持久化除了 AOF 之外，还有另外一种方式：内存快照。对 Redis 来说，它实现类似于照片记录效果的方式，就是把某一时刻的状态以文件的形式写到磁盘上，也就是快照。这样一来，即使宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。这个快照文件被称为 RDB 文件。其中，RDB 就是 Redis DataBase 的缩写 和 AOF 相比，RDB 记录的是某一时刻的记录，并不是操作，所以，在做数据恢复时，我们可以直接把 RDB 文件读入内存，很快地完成恢复 给哪些内存数据做快照Redis 的数据都在内存中，为了提供所有数据的可靠性保证，它执行的是全量快照，也就是把内存中的所有记录都记录到磁盘中。这样的好处是，一次性记录了所有数据，一个都不少 对于 Redis 而言。它的单线程模型就决定了，我们要尽量避免所有会阻塞主线程的操作，所以，RDB 文件的生成是否会阻塞主线程，这关系到是否会降低 Redis 的性能 Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave save：在主线程中执行，会导致阻塞 bgsave：创建一个子线程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是 Redis RDB 文件生成的默认配置 这个时候，我们就可以通过 bgsave 命令来执行全量快照，这既提供了数据的可靠性保证，也避免了对 Redis 的性能影响 快照时数据能修改吗例如，我们在时刻 t 给内存做快照，假设内存数据量是 4GB，磁盘的写入带宽是 0.2 GB/s，即至少需要 20S（4 / 0.2 = 20）才能做完。如果在 t + 5s 时，一个还没有被写入磁盘的内存数据 A，被修改成了 A’，那么就会破坏快照的完整性 但是，如果快照执行期间数据不能被修改，是会有潜在问题的。在做快照的 20s 的时间里，如果这 4GB 的数据都不能被修改，Redis 就不能处理这些数据的写操作，那无疑会给业务造成巨大的影响 为了快照而暂停写操作，肯定是不能接受的。所以，Redis 会借助操作系统提供的写时复制技术，在执行快照的同时，正常处理写操作 简单来说，bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件 此时，如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和 bgsave 子进程互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 C），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而这个过程中，主线程仍然可以直接修改原来的数 这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响 可以每秒做一次快照吗如下图，我们先在 T0 时刻做了一次快照，然后有在T0 + t 时刻做了一次快照，在这期间，数据块 5 和 9 被修改了。如果在 t 这段时间内，机器宕机了，那么，只能按照 T0 时刻的快照进行恢复。此时，数据块 5 和 9 的修改值因为没有快照记录，就无法恢复 所以，要想尽可能恢复数据，t 值就要尽可能小。那么，t 值可以小到什么程度呢？例如每秒一次？毕竟每次快照都是有 bgsave 子进程在后台执行，也不会阻塞主线程 这种想法其实是错误的。虽然 bgsave 执行时不阻塞主线程，但是，如果频繁地执行全量快照，也会带来两方面的开销 一方面，频繁将全量数据写入磁盘，会给磁盘带来很大压力，多个快照竞争有限的磁盘宽带，前一个快照还没有做完，后一个又开始做了，容易造成恶性循环 另一方面，bgsave 子进程需要通过 fork 操作从主线程创建出来。虽然，子进程在创建后不会再阻塞主线程，但是，fork 这个创建过程本身会阻塞主线程，而且主线程的内存越大，阻塞时间越长。如果频繁 fork 出 bgsave 子进程，这就会频繁阻塞主线程了 那么，有什么其他好方法吗？ Redis 4.0 中提出了一个混合使用 AOF 日志和内存快照的方法。简单说，内存快照以一定的频率执行，在两次快照之间，使用 AOF 日志记录这期间的所有命令操作 这样一来，快照不用很频率地执行，这就避免了频繁 fork 对主线程的影响。而且，AOF 日志也只用记录两次快照间的操作，即不需要记录所有操作了，因此，就不会出现文件过大的情况，也可以避免重写开销 如下，T1 和 T2 时刻的修改，用 AOF 日志记录，等到第二次做全量快照时，就可以清空 AOF 日志，因为此时的修改都已经记录到快照中了，恢复时就不用再用日志了]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kafka 之幂等生产者和事务生产者]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F06%2FKafka-%E4%B9%8B%E5%B9%82%E7%AD%89%E7%94%9F%E4%BA%A7%E8%80%85%E5%92%8C%E4%BA%8B%E5%8A%A1%E7%94%9F%E4%BA%A7%E8%80%85%2F</url>
    <content type="text"><![CDATA[幂等性 Producer在 Kafka 中，Producer 默认不是幂等的，但我们可以创建幂等性 Producer。它是 0.11.0.0 版本引入的新功能。指定 Producer 幂等性的方法很简单，仅需要设置一个参数即可，即 props.put(“enable.idempotence”, true) 或 props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true) enable.idempotence 被设置成 true 后，Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要改变，Kafka 自动帮你做消息的重复去重。底层具体的原理很简单，就是经典的用空间去换时间的优化思路，即在 Broker 端多保存一些字段。当 Producer 发送了具有相同字段值的消息后，Broker 能够自动知晓这些消息已经重复了，于是可以在后台默默丢弃掉。当然，实际的实现原理并没有那么简单，你可以大致这么理解 但是，幂等性的 Producer 也是有局限性的。首先，它只能保证单分区上的幂等性，即一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，它无法实现多个分区的幂等性。其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。这里的会话，你可以理解为 Producer 进程的一次运行。当你重启了 Producer 进程之后，这种幂等性保证就丧失了 那如果要实现多分区以及多会话上的消息无重复，应该怎么做？答案就是事务或者依赖事务型 Producer。这也是幂等性 Producer 和事务型 Producer 的最大区别 事务型 Producer事务型 Producer 能够保证将消息原子性地写入到多个分区中。这批消息要么全部写入成功，要么全部失败。另外，事务型 Producer 也不惧进程的重启。Producer 重启回来后，kafka 依然保证它们发送消息的精确一次处理 设置事务型 Producer 的方法也很简单，满足两个条件即可： 和幂等性 Producer 一样，开启 enable.idempotence = true 设置 Producer 端参数 transactional.id。最好设置一个有意义的名字 此外，你还需要在 Producer 代码中做一些调整，如下： 123456789producer.initTransactions();try &#123; producer.beginTransaction(); producer.send(record1); producer.send(record2); producer.commitTransaction();&#125; catch (KafkaException e) &#123; producer.abortTransaction();&#125; 和普通 Producer 代码相比，事务型 Producer 的显著特点是调用了一些事务 API，如 initTransaction、beginTransaction、commitTransaction 和 abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止 这段代码能够保证 Record1 和 Record2 被当做一个事务统一提交到 Kafka，要么它们全部提交成功，要么全部写入失败。实际上即使写入失败，Kafka 也会把他们写入到底层的日志中，也就是说 Consumer 还是会看到这些消息。因此在 Consumer 端，读取事务型 Producer 发送的消息也是需要一些变更的。修改起来也简单，设置 isolation.level 参数的值即可。当前这个参数有两个取值： read_uncommitted：这是默认值，表明 Consumer 能够读取到 Kafka 写入的任何消息，不论事务型 Producer 提交事务还是终止事务，其写入的消息都可以读取。显然，如果你使用了事务型 Producer，那么对应的 Consumer 就不要使用这个值 read_committed：表明 Consumer 只会读取事务型 Producer 成功提交事务写入的消息。当然，它也能看到非事务型 Producer 写入的所有消息 相比较幂等性 Producer，事务型 Producer 的性能要更差，在实际使用过程中，我们需要仔细评估引入事务的开销，不可无脑地启用事务]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka 之无消息丢失配置]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F05%2Fkafka-%E4%B9%8B%E6%97%A0%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Kafka 什么情况下能保证消息不丢失呢？ 一句话概括，Kafka 只对「已提交」的消息做有限度的持久化保证 第一个核心要素是「已提交的消息」。什么是已提交的消息？当 Kafka 的若干个 Broker 成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在 Kafka 看来就正式变成了「已提交」消息了 那为什么是若干个 Broker 呢？这取决于你对「已提交」的定义。你可以选择只要有一个 Broker 成功保存该消息就算是已提交，也可以是令所有 Broker 都成功保存该消息才算是已提交。不论哪种情况，Kafka 只对已提交的消息做持久化保证这件事是不变的 第二个核心要素是「有限度的持久化保证」。这里的有限度，是说 Kafka 不丢消息是有前提条件的。假如你的消息保存在 N 个 Kafka Broker 上，那么这个前提条件就是这 N 个 Broker 中至少有 1 个存活。只要这个条件成了，Kafka 就能保证你的这条消息永远不会丢失 总结一下，Kafka 是能做到不丢失消息的，只不过这些消息必须是已提交的消息，而且还要满足一定的条件 消息丢失案例生产者程序丢失数据目前，Kafka Producer 是异步发送消息的，也就是说如果你调用的是 producer.send(msg) 这个 API，那么它通常会立即返回，但此时你不能认为消息发送已完成 如果用这个方式，可能会有哪些因素导致消息没有发送成功呢？原因有很多，例如网络抖动，导致消息压根就没有发送到 Broker 端；或者消息本身不合格导致 Broker 拒绝接收（比如消息太大，超过了 Broker 的承受能力）等 实际上，解决此问题的方法非常简单：Producer 永远要使用带有回调通知的发送 API，也就是说不要使用 producer.send(msg)，而是使用 producer.send(msg, callback)。通过回调函数，就可以在提交失败的情况下，进行针对性的处理了 消费者程序丢失案例Consumer 端丢失数据主要体现在 Consumer 端要消费的消息不见了。Consumer 程序有个「位移」的概念，表示的是这个 Consumer 当前消费到的 Topic 分区的位置。如下图 比如对于 Consumer A 而言，它当前的位移值就是 9；Consumer B 的位移值是 11 这里的「位移」类似于我们看书时使用的书签，它会记录我们当前阅读了多少页，下次翻书的时候我们就能直接跳到书签页继续阅读 正确使用书签有两个步骤：第一步是读书，第二步是更新书签页。如果这两步的顺序颠倒了，就可能出现这样的场景：当前的书签页是第 90 页，我先将书签放到第 100 页上，之后开始读书。当阅读到第 95 页时，我临时有事中止了阅读。那么问题来了，当我下次直接跳到书签页阅读时，我就丢失了第 96～99 页的内容，即这些消息就丢失了 同理，Kafka 中 Consumer 端的消息丢失就是这么一回事。要对抗这种消息丢失，办法就是：维持先消费消息（阅读），再更新位移（书签）的顺序即可。这样就能最大限度保证消息不丢失 当然，这种处理方式可能带来的问题是消息重复处理，类似于同一页书被读了很多遍，但这不属于消息丢失的情形 除此之外，还有一种情况。Consumer 程序从 Kafka 获取到消息之后开启了多个线程异步处理消息，而 Consumer 程序自动地向前更新位移。假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于 Consumer 而言实际上是丢失了 这个问题的解决也很简单：如果是多线程异步处理消费消息，Consumer 程序不要开启自动提交位移，而是要应用程序手动提交位移。这里注意一下，单个 Consumer 程序使用多线程来消费消息说起来容易，写成代码却很困难，因为你很难正确地处理位移的更新，也就是说避免无消息消费很简单，但极易出现消息被消费了多次的情况 最佳实现这里，我们分享一下 Kafka 无消息丢失的配置 不要使用 producer.send(msg)，而要使用 producer.send(msg, callback)。一定要使用带有回调通知的 send 方法 设置 acks = all。acks 是 Producer 的一个参数，代表了你对「已提交」消息的定义。如果设置成 all，则表名所有副本 Broker 都要接收到消息，该消息才算是已提交。这是最高等级的「已提交」定义 设置 retries 为一个较大的值。这个 retries 同样是 Producer 的参数，对应前面提到的 Producer 自动重试。当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 retires &gt; 0 的 Producer 能够自动重试消息发送，避免消息丢失 设置 unclean.leader.election.enable = false。这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader。如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失。故一般都要将该参数设置成 false，即不允许这种情况的发生 设置 replication.factor &gt;= 3。这也是 Broker 端的参数。这里想表述的是，最好将消息多保存几份，毕竟目前防止消息丢失的主要机制就是冗余 设置 min.insync.replicas &gt; 1。这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是「已提交」。设置成大于 1 可以提升消息持久性。在实际环境中千万不要使用默认值 1 确保 replication.factor &gt; min.insync.replicas。如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了。我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成。推荐设置成 replication.facotr = min.insync.replicas + 1 确保消息消费完成再提交。Consumer 端有个参数 enable.auto.commit，最好把它设置成 false，并采用手动提交位移的方式。这对于单 Consumer 多线程处理的场景而言是很重要的]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 之 AOF 日志]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F05%2FRedis-%E4%B9%8B-AOF-%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[目前，Redis 的持久化主要有两大机制：AOF 日志和 RDB 快照。我们先看一下 AOF 日志 AOF 日志是怎么实现的说到日志，我们比较熟悉的是数据库的写前日志（Write Ahead Log，WAL），即，在实际写日志前，先把修改的数据记到日志文件中，以便故障时进行恢复。不过，AOF 日志正好相反，它是写后日志。「写后」的意思是 Redis 先执行命令，把数据写入内存，然后才记录日志。如下： 为什么 AOF 是这么个顺序呢？首先，我们也好知道 AOF 里记录了什么内容 传统数据库的日志，例如 redo log（重做日志），记录的是修改后的数据，而 AOF 里记录的是 Redis 收到的每一条命令，这些命令是以文本形式保存的 以 Redis 收到「set testkey testvalue」命令后记录的日志为例，看看 AOF 日志的内容。其中，「*3」表示当前命令有三个部分，每个部分都是由「$ + 数字」开头，后面紧跟着具体的命令、键或值。这里，「数字」表示这部分中的命令、键或值一共有多少字节。例如，「$3 set」表示这部分有 3 个字节，也就是「set」命令 但是，为了避免额外的检查开销，Redis 在向 AOF 里面记录日志的时候，并不会先对这些命令进行语法检查。所以，如果先记日志再执行命令的话，日志中就有可能记录了错误的命令，Redis 在使用日志恢复数据时，就可能会出错 而写后日志这种方式，就是先让系统执行命令，只有命令能执行成功，才会被记录到日志中，否则，系统就会直接向客户端报错。所以，Redis 使用写后日志的一个好处是，可以避免出现记录错误命令的情况 另外，AOF 还有一个好处：它是在命令执行后才记录日志，所以不会阻塞当前的写操作 不过，AOF 也有两个潜在风险 首先，如果刚执行完一个命令，还没来得及记录日志就宕机了，那么这个命令就和相应的数据就有丢失的风险。 其次，AOF 虽然避免了对当前命令的阻塞，但是会给下一个操作带来阻塞风险。这是因为，AOF 日志也是在主线程中执行的，如果在把日志文件写入磁盘时，磁盘压力过大，就会导致写盘很慢，进而导致后续的操作也无法执行了 其实，这两个风险都是和 AOF 写回磁盘的时机相关的。这意味着，如果我们能够控制一个写命令执行完后 AOF 日志写回磁盘的时机，这两个风险就接触了 三种写回策略其实，AOF 机制给我们提供了三个选择，也就是 AOF 配置项 appendfsync 的三个可选值 Always，同步写回：每个命令执行完，立马同步地将日志写回磁盘 Everysec，每秒写回：每个命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区的内容写入磁盘 No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘 针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。原因如下： 「同步写回」可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的罗盘操作，不可避免地会影响主线程性能 虽然「操作系统控制的写回」在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了 「每秒写回」采用一秒写回一次的频率，避免了「同步写回」的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失 三种策略的写回时机，优缺点如下： 配置项 写回时机 优点 缺点 Always 同步写回 可靠性高，数据基本不丢失 每个写命令都要落盘，性能影响较大 Everysec 每秒写回 性能适中 宕机时丢失 1 秒内的数据 No 操作系统控制的写回 性能好 宕机时丢失数据较多 但是，按照系统的性能需求选定了写回策略，并不是就没问题了。毕竟，AOF 是以文件的形式在记录收到的所有写命令。随着接收的写命令越来越多，AOF 文件会越来越大。这就意味着，我们要小心 AOF 文件过大带来的性能问题 性能问题主要包括三个方面：一是，文件系统本身对文件大小有限制，无法保存过大的文件；二是，如果文件太大，之后往里面追加命令记录的话，效率会变低；三是，如果发生宕机，AOF 中记录的命令要一个个被重新执行，用于故障恢复，如果日志文件太大，整个恢复过程就会非常缓慢，就会影响到 Redis 的正常使用 这个时候，AOF 重写机制就登场了 AOF 重写机制AOF 重写机制就是在重写时，Redis 根据数据库的现状创建一个新的 AOF 文件，也就是说，读取数据库中的所有键值对，然后对每一个键值对用一条命令记录它的写入。比如说，当读取了键值对「”testkey” : “testvalue”」之后，重写机制会记录「set testkey testvalue」这条命令。这样，当需要恢复时，就可以重新执行该命令，实现「”testkey” : “testvalue”」的写入 为什么重写机制可以把日志文件变小呢？实际上，重写机制具有「多变一」功能。所谓的「多变一」，即旧日志文件中的多条命令，在重写后的新日志中变成了一条命令 我们知道，AOF 文件是以追加的方式，逐一记录收到的写命令。当一个键值对被多条写命令反复修改时，AOF 文件会记录想赢的多条命令。但是，在重写的时候，是根据这个键值对当前的最新状态，为它生成对应的写入命令。这样一来，一个键值对在重写日志中只用了一条命令就行。而且，在日志恢复时，只用执行这条命令，就可以直接完成这个键值对的写入了。如下图 当我们对一个列表先后做了 6 次修改操作后，列表最后的状态是「”D”, “C”, “N”」，此时，只用 LPUSH u:list &quot;N&quot;, &quot;C&quot;, &quot;D&quot; 这一条命令就能实现该数据的恢复，这就节省了五条命令的空间。对于被修改过成百上千次的键值对来说，重写能节省的空间就更大了 不过，虽然 AOF 重写后，日志文件会缩小，但是，要把整个数据库的最新数据的操作日志都写回磁盘，仍然是一个非常耗时的操作。那么，重写会不会阻塞主线程 AOF 重写会阻塞吗和 AOF 日志由主线程写回不同，重写过程是有后台线程 bgrewriteaof 完成的，也是为了避免阻塞主线程，导致数据库性能下降 这里把重写的过程总结为「一个拷贝，两处日志」 「一个拷贝」是指，每次执行重写时，主线程 fork 出后台的 bgrewriteaof 子进程。此时，fork 会把主进程的内存拷贝一份给 bgrewriteaof 子进程，这里面就包含了数据库的最新数据。然后，bgrewriteaof 子进程就可以在不影响主线程的情况下，逐一把拷贝的数据写成操作，记入重写日志 「两处日志」是什么呢？ 因为主线程未阻塞，仍然可以处理新来的操作。此时，如果有写操作，第一处日志就是指正在使用的 AOF 日志，Redis 会把这个操作写到它的缓冲区。这样一来，即使宕机了，这个 AOF 日志的操作仍然是齐全的，可以用于恢复 而第二处日志，就是指新的 AOF 重写日志。这个操作也会被写到重写日志的缓冲区。这样，重写日志也不会丢失最新的操作。等到拷贝数据的所有操作记录重写完成后，重写日志记录的这些最新操作也会写入新的 AOF 文件，以保证数据库的最新状态的记录。此时，我们就可以用新的 AOF 文件替代旧文件了 总结来说，每次 AOF重写时，Redis 会先执行一个内存拷贝，用于重写；然后，使用两个日志保证在重写过程中，新写入的数据不会丢失。而且，因为 Redis 采用额外的线程进行数据重写，所以，这个过程不会阻塞主线程 补充AOF 日志重写的时候，是由 bgrewriteaof 子进程来完成的，不用主线程参与，我们今天说的非阻塞也是指子进程的执行不阻塞主线程。但是，你觉得，这个重写过程有没有其他潜在的阻塞风险呢？如果有的话，会在哪里阻塞？ Redis 采用 fork 子进程重写 AOF 文件时，潜在的阻塞风险包括：fork 子进程 和 AOF 重写过程中父进程产生写入的场景，下面依次介绍 fork 子进程，fork 这个瞬间一定是会阻塞主线程的（注意，fork 时并不会一次性拷贝所有内存数据给子进程，上面文章写的是拷贝所有内存数据给子进程，是有歧义的），fork 采用操作系统提供的写时复制（Copy On Write）机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但 fork 子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量 CPU 资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork 阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？「写时复制」顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景 fork 出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行 AOF 重写，把内存中的所有数据写入到 AOF 文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的 key，那么这个时候父进程就会真正拷贝这个 key 对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认 4k，如果父进程此时操作的是一个 bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制（Huge Page，页面大小2M），那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭 Huge Page 机制。Redis 每次 fork 生成 RDB 或 AOF 重写完成后，都可以在 Redis log 中看到父进程重新申请了多大的内存空间 AOF 重写也有一个重写日志，为什么它不共享使用 AOF 本身的日志呢？ AOF 重写不复用 AOF 本身的日志，一个原因是父子进程写同一个文件必然会产生竞争问题，控制竞争就意味着会影响父进程的性能。二是如果 AOF 重写过程中失败了，那么原本的 AOF 文件相当于被污染了，无法做恢复使用。所以 Redis AOF 重写一个新文件，重写失败的话，直接删除这个文件就好了，不会对原先的 AOF 文件产生影响。等重写完成之后，直接替换旧文件即可。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 单线程为什么这么快]]></title>
    <url>%2FCKING.github.io%2F2021%2F12%2F05%2FRedis-%E5%8D%95%E7%BA%BF%E7%A8%8B%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%99%E4%B9%88%E5%BF%AB%2F</url>
    <content type="text"><![CDATA[我们通常说，Redis 是单线程，主要是值 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，是由额外的线程执行的 多线程的开销在我们平时使用的系统中，会存在被多线程同时访问的共享资源，比如一个共享的数据结构。当有多个线程要修改这个共享资源时，为了保证共享资源的正确性，就需要有额外的机制进行保证，而这个额外的机制，就会带来额外的开销 并发访问控制一直是多线程开发中的一个难点问题，如果没有精细的设计，例如只是简单地采用一个粗粒度互斥锁，就会出现不理想的结果；即使增加了线程，大部分线程也在等待获取访问共享资源的互斥锁，并行变串行，系统吞吐率并没有随着线程的增加而增加 而且，采用多线程开发一般会引入同步原语来保护共享资源的并发访问，这也会降低系统代码的易调试性和可维护性。为了避免这些问题，Redis 直接采用了单线程模式 单线程 Redis 为什么那么快？单线程的处理能力要比多线程差很多，但是 Redis 却能使用单线程模型达到每秒数十万级别的处理能力，这是为什么？其实，这是 Redis 多方面设计选择的一个综合结果 一方面，Redis 的大部分操作在内存上完成，再加上它采用了高效的数据结构，例如哈希表和跳表，这是它实现高性能的一个重要原因。另一方面，就是 Redis 采用了多路复用机制，使其在网络 IO 操作中能并发处理大量的客户端请求，实现高吞吐率 首先，我们要弄明白网络操作的基本 IO 模型和潜在的阻塞点 基本 IO 模型和阻塞点假设 Redis 要处理一个 Get 请求，如果是基本的 IO 模型，一般流程是这样子的。先监听客户端请求（bind / listen），和客户端建立连接（accept），从 socket 中读取请求（recv），解析客户端发送请求（parse），根据请求类型读取键值数据（get），最后给客户端返回结果，即向 socket 中写回数据（send） 如下图，其中，bind / listen、accept、recv、parse 和 send 属于网络 IO 处理，而 get 属于键值数据操作。既然 Redis 是单线程，那么，最基本的一种实现就是在一个线程中依次执行上面的这些操作 但是，这里的网络 IO 模型中，有潜在的阻塞点，分别是 accept() 和 recv()。当 Redis 监听到一个客户端有连接请求，但一直未能成功建立起连接时，会阻塞在 accept 函数这里，导致气他客户端无法和 Redis 建立连接。类似的，当 Redis 通过 recv() 从一个客户端读取数据时，如果数据未到达，Redis 也会一直阻塞在 recv() 这就导致了 Redis 整个线程阻塞，无法处理其它客户端请求，效率很低 非阻塞模型Socket 网络模型的非阻塞模式设置，主要体现在三个关键的函数调用上 在 socket 模型中，不同操作调用后会返回不同的套接字类型。socket() 方法会方位主动套接字，然后调用 listen() 方法，将主动套接字转化为监听套接字，此时，可以监听来自客户端的连接请求。最后，调用 accept() 方法接收到达的客户端连接，并返回已连接套接字 调用方法 返回套接字类型 非阻塞模式 效果 socket() 主动套接字 listen() 监听套接字 可设置 accept() 非阻塞 accept() 已连接套接字 可设置 send() / recv() 非阻塞 针对监听套接字，我们可以设置非阻塞模式：当 Redis 调用 accept() 但一直未有连接请求到达时，Redis 线程可以返回处理其它操作，而不用一直等待。但是，需要注意的是，调用 accept() 时，已经存在监听套接字了 虽然 Redis 线程可以不用继续等待了，但是总得有机制继续在监听套接字上等待后续连接请求，并在有请求时通知 Redis。recv() 也是类似 这样才能保证 Redis 线程，既不会像基本 IO模型中一直在阻塞点等待，也不会导致 Redis 无法处理实际到达的连接请求或数据 基于多路复用的高性能 I/O 模型Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select / epoll 机制。简单说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求，一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果 下图就是基于多路复用的 Redis IO 模型。图中的多个 FD 就是刚才所说的多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，即，不会阻塞在某一个特定的客户端请求处理上。因此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性 为了在请求到达时能通知到 Redis 线程，select / epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的处理函数 那么，回调机制是怎么工作的呢？其实，select / epoll 一旦监测到 FD 上有请求到达时，就会触发相应的事件 这些事件会被放进一个事件队列，Redis 单线程对该事件队列不断进行处理。这样一来。Redis 无需一直轮询是否有请求实际发生，这就可以避免造成 CPU 浪费资源。同时，Redis 在对事件队列中的事件进行处理时，会调用相应的处理函数，这就实现了基于事件的回调。因为 Redis 一直在对事件队列进行处理，所以能及时相应客户端请求，提升 Redis 的响应性能 例如，有两个请求分别对应 Accept 事件和 Read 事件，Redis 分别对这两个时间注册 accept 和 get 回调函数。当 Linux 内核监听到有连接或读数据请求时，就会触发 Accept 事件和 Read 事件，此时，内核就会回调 Redis 相应的 accept 和 get 函数进行处理 补充Redis 单线程处理 IO 请求性能瓶颈主要包括两个方面： 任意一个请求在 server 中一旦发生耗时时，都会影响整个 server 的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能白处理到。还是的操作包括以下几种： 操作 bigkey：写入一个 bigkey 在分配内存时需要耗费更多的时间。同样，删除 bigkey 释放内存同样会产生耗时 使用复杂度过高的命令：例如 SORT / SUNION / ZUNIONSTORE，或者 O(N) 命令，但是 N 很大，例如 lrange key 0 -1 一次查询全量数据 大量 key 集中过期：Redis 的过期机制也是在主线程中执行的，大量 key 集中过期会导致处理一个请求时，耗时都在删除过期 key，耗时变长 淘汰策略：淘汰策略也是在主线程执行的，当内存超过 Redis 内存上限后，每次写入到需要淘汰一些 key，也会造成耗时变成 AOF 刷盘开启 always 机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度比写内存慢，会拖慢 Redis 的性能 主从全量同步生成 RDB：虽然采用 fork 子进程生成数据快照，但 fork 这一瞬间也是会阻塞整个线程的。实例越大，阻塞时间越久 并发量非常大时，单线程读写客户端 IO 数据存在性能瓶颈，虽然采用 IO 多路复用机制，但是读写客户端数据依旧是同步 IO，只能单线程一次读取客户端的数据，无法利用到 CPU 的多核 针对问题 1，一方面需要业务人员去规避，一方面 Redis 在 4.0 推出了 lazy-free 机制，把 bigkey 释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响 针对问题2，Redis 在 6.0 推出了多线程，可以在高并发场景下利用 CPU 多核多线程读写客户端数据，进一步提升 server 性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis 数据结构]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F30%2FRedis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Redis 为什么能那么快？一方面是因为它是内存数据库，所有操作都在内存上完成，内存的访问速度本身就很快。另一方面，这要归功于它的数据结构。这是因为，键值对是按一定的数据结构来组织的，操作键值对最终就是对数据结构进行增删改查操作，所以高效的数据结构是 Redis 快速处理数据的基础 Redis 的数据结构有哪些呢？你可能会说，是 String、List、Hash、Set 和 Sorted Set 吗？其实，这些知识 Redis 键值对中值的数据类型，也就是数据的保存形式。而这里，我们说的数据结构，是要去看看它们的底层实现 简单来说，底层数据结构一共有 6 种，分别是简单动态字符串、双向链表、压缩链表、哈希表、跳表和整数数组。它们和数据类型的对应关系如下： 可以看到，String 类型的底层实现只有一种数据结构，也就是简单动态字符串。而 List、Hash、Set 和 Sorted Set 这四种数据类型，都有两种底层实现结构。通常情况下，我们会把这四种类型称为集合类型，它们的特点是一个键对应了一个集合的数据 键和值用什么结构组织为了实现从键到值的快速访问，Redis 使用了一个哈希表来保存所有键值对 一个哈希表，其实就是一个数组，数组的每个元素成为一个哈希桶。所以，一个哈希表由多个哈希桶组成，每个哈希桶中保存了键值对数据 如果值是集合类型的话，作为数组元素的哈希桶怎么来保存呢？其实，哈希桶中的元素保存的并不是值本身，而是指向具体值的指针。即，不管值是 String，还是集合类型，哈希桶中的元素都是指向它们的指针 下图中，哈希桶中的 entry 元素中保存了 *key 和 *value 指针，分别指向了实际的键和值，这样一来，即使值是一个集合，也可以通过 *value 指针查找到 因为这个哈希表保存了所有的键值对，所以，我也把它成为全局哈希表。哈希表的最大好处，就是让我们可以用 O(1) 的时间复杂度来快速查找到键值对。我们只要计算键的哈希值，就可以知道它所对应的哈希桶位置，然后就可以访问相应的 entry 元素 虽然我们知道了哈希表的 O(1) 复杂度和快速查找特性，那么，你往 Redis 中写入大量数据后，就可能发现操作有时候会突然变慢了。这其实是因为你忽略了一个潜在的风险点，那就是哈希表的冲突问题和 rehash 可能带来的操作阻塞 为什么哈希表操作变慢了？当你往哈希表中写入更多数据时，哈希冲突是不可避免的问题。这里的哈希冲突，是指两个 key 的哈希值和哈希桶计算对应关系时，正好落在了同一个哈希桶中 Redis 解决哈希冲突的方式，就是链式哈希。链式哈希，是指同一个哈希桶中的多个元素用一个链表来保存，它们之间依次用指针连接 但是，这里依然存在一个问题，哈希冲突链上的元素只能通过指针逐一查找再操作。如果哈希表里写入的数据越来越多，哈希冲突可能也会越来越多，这就会导致某些哈希冲突链过长，进而导致这个链上的元素查找耗时长，效率变低 所以，Redis 会对哈希表做 rehash 操作。rehash 也就是增加现有的哈希桶数量，让主键增多的 entry 元素能在更多的桶之间分散保存，减少单个桶中的元素数量，从而减少单个桶中的冲突。具体怎么做呢？ 其实，为了 rehash 操作更高效，Redis 默认使用了两个全局哈希表：哈希表 1 和哈希表 2.一开始，当你刚插入数据时，默认使用哈希表 1，此时的哈希表 2 并没有被分配空间。随着数据逐步增多，Redis 开始执行 rehash，这个过程分为三步： 给哈希表 2 分配更大的空间，例如是当前哈希表 1 大小的两倍 把哈希表 1 中的数据重新映射并拷贝到哈希表 2 中 释放哈希表 1 的空间 到此，我们就可以从哈希表 1 切换到哈希表 2，用增大的哈希表 2 保存更多数据，而原来的哈希表 1 留作下一次 rehash 扩容备用 这个过程看似简单，但是第二次涉及大量的数据拷贝，如果一次性把哈希表 1 中的数据都迁移完，会造成 Redis 线程阻塞，无法服务其他请求。此时，Redis 就无法快速访问数据了 为了解决这个问题，Redis 采用了渐进式 rehash 简单说就是在第二步拷贝数据时，Redis 仍然正常处理客户端请求，每处理一个请求时，从哈希表 1 中的第一个索引位置开始，顺带着将这个索引位置上的所有 entries 拷贝到哈希表 2 中；等处理下一个请求时，再顺带拷贝哈希表 1 中的下一个索引位置的 entries。如图： 这样就巧妙地把一次性大量拷贝的开销，分摊到了多次处理请求的过程中，避免了耗时操作，保证了数据的快速访问 集合数据操作效率和 String 类型不同，一个集合类型的值，第一步是通过全局哈希表找到对应的哈希桶位置，第二步是在集合中再增删改查。那么，集合的操作效率和哪些因素相关呢？ 首先，与集合的底层数据结构有关。例如，使用哈希表实现的集合，要比使用链表实现的集合访问效率更高。其次，操作效率和这些操作本身的执行特定有关，比如读写一个元素的操作要比读写所有元素的效率高 有哪些底层数据结构上面说过，集合类型的底层数据结构主要有 5 种：整数数组、双向链表、哈希表、压缩列表和跳表 其中，哈希表的操作特点上面已经说过了；整数数组和双向链表也很常见，它们的操作特征都是顺序读写，也就是通过数组下标或者链表的指针逐个元素访问，操作复杂度基本是 O(N)，操作效率比较低；压缩列表和跳表我们平时接触得不多，但他们也是 Redis 重要的数据结构 压缩列表类似于一个数组，数组中的每一个元素都对用保存一个数据。和数组不同的是，压缩列表在表头有三个字段：zlbytes、zltail 和 zllen，分别表示列表长度、列表尾的偏移量和列表中的 entry 个数；压缩列表在表尾还有一个 zlend，表示列表结束 在压缩列表中，如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段的长度直接定位，复杂度是 O(1)。而查找其他元素时，就没有那么高效了，只能逐个查找，此时的复杂度就是 O(N) 了 接着看看跳表 有序链表只能逐一查找元素，导致操作起来非常缓慢，于是就出现了跳表。具体来说，跳表在链表的基础上，增加了多级索引，通过索引位置的几个跳转，实现数据的快速定位。如下： 如果我们要在链表查找 33 这个元素，只能从头开始遍历链表，查找 6 次，直到找到 33 为止。此时，复杂度是 O(N)，查找效率很低 为了提高查找速度，我们增加了多级索引。可以看到，这个查找过程就是在多级索引上跳来跳去，最后定位到元素。当数据量很大时，跳表的复杂度就是 O(logN) 我们总结一下各个数据结构的时间复杂度 不同操作的复杂度集合类型的操作类型很多，有读写单个集合元素的，例如 HGET、HSET，也有操作多个元素的，比如 SADD，还有对整个集合进行遍历操作的，例如 SMEMBERS。这么多操作，它们的复杂度也各不相同。而复杂度高低又是我们选择集合类型的重要依据 这里有一个口诀： 单元操作是基础 范围操作非常耗时 统计操作通常高效 例外情况只有几个 第一，单元素操作，是指每一种集合类型对单个数据实现的增删改查操作。例如，Hash 类型的 HGET、HSET 和 HDEL，Set 类型的 SADD、SREM、SRANDMEMBER 等。这些操作的复杂度由集合采用的数据结构决定。 例如，HGET、HSET 和 HDEL 是对哈希表做操作，所以他们的复杂度都是 O(1)；Set 类型用哈希表作为底层数据结构时，它的 SADD、SREM、SRANDMEMBER 复杂度也是 O(1) 第二，范围操作，是指集合类型中的遍历操作，可以返回集合中的所有数据，比如 Hash 类型的 HGETALL 和 Set 类的 SMEMBERS，或者返回一个范围内的部分数据，比如 List 类型的 LRANGE 和 ZSet 类型的 ZRANGE。这类操作的复杂度一般是 O(N)，比较耗时，我们应该尽量避免 不过，Redis 从 2.8 版本开始提供了 SCAN 系统操作（包含 HSCAN，SSCAN 和 ZSCAN），这类操作实现了渐进式遍历，每次只返回有限数量的数据。这样一来，相比于 HGETALL、SMEMBERS 这类操作来说，就避免了一次性返回所有元素而导致的 Redis 阻塞 第三，统计操作，是指集合类型对集合中所有元素个数的记录。例如 LLEN 和 SCARD。这类操作复杂度只有 O(1)，这是因为当集合类型采用压缩列表、双向链表、整数数组这些数据结构时，这些结构中专门记录了元素的个数统计，因此可以高效地完成相关操作 第四，例外情况，是指某些数据结构的特殊记录，例如压缩列表和双向链表都会记录表头和表尾的偏移量。这样一来，对于 List 类型的 LPOP、RPOP、LPUSH、RPUSH 这四个操作来说，它们是在列表的头尾增删元素，这就可以通过偏移量直接定位，所以它们的复杂度也只有 O(1)，可以实现快速操作 总结]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产者压缩算法]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F30%2F%E7%94%9F%E4%BA%A7%E8%80%85%E5%8E%8B%E7%BC%A9%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[Kafka 是如何压缩算法的？目前 Kafka 共有两大类消息格式，社区分别称之为 V1 版本和 V2 版本。V2 版本是 Kafka 0.11.0.0 中正式引入的 无论是哪个版本，Kafka 的消息层次都分为两层：消息集合（message set）和消息（message）。一个消息集合中包含若干条日志项，而日志项才是真正封装消息的地方。Kafka 底层的消息日志由一系列消息集合日志项组成。Kafka 通常不会直接操作具体的一条条消息，而是在消息集合这个层面上进行写入操作 其中，V2 版本针对 V1 版本的一些弊端做了修正。例如，把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了 举个例子，在原来 V1 版本中，每条消息都需要执行 CRC 校验，但有些情况下消息的 CRC 值是会发生变化的。比如在 Broker 端可能会对消息时间戳字段进行更新，那么重新计算之后的 CRC 值也会相应更新；再比如 Broker 端在执行消息格式转换时（主要是为了兼容老版本客户端程序），也会带来 CRC 值的变化。鉴于这些情况，再对每条消息都执行 CRC 校验就有点没必要了，不仅浪费空间还耽误 CPU 时间。因此在 V2 版本中，消息的 CRC 校验工作就被移到了消息集合这一层 V2 版本还有一个和压缩息息相关的改进，就是保存压缩消息的方法发生了变化。之前 V1 版本中保存压缩信息的方法是把多条消息进行压缩然后保存到外层消息的消息体字段中；而 V2 版本的做法是对整个消息集合进行压缩。显然后者比前者有更好的压缩效果 何时压缩在 Kafka 中，压缩可能发生在两个地方：生产者端和 Broker 端 生产者程序中配置 compression.type 参数即表示启用指定类型的压缩算法。如下： 123456789Properties props = new Properties();props.put("bootstrap.servers", "localhost:9092");props.put("acks", "all");props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer"); props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");// 开启 GZIP 压缩props.put("compression.type", "gzip"); Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props); 在生产者端启用压缩是很自然的想法，那为什么 Broker 端也可能进行压缩呢？其实大部分情况下 Broker 从 Producer 端接收到消息后仅仅是原封不动地保存而不会对其进行任何修改。但有两种例外情况就可能让 Broker 重新压缩消息 情况一：Broker 端指定了和 Producer 端不同的压缩算法 先看一个例子。 Producer 说：“ 我要使用 GZIP 进行压缩 ” Broker 说：“ 不好意思，我这边接收的消息必须使用 Snappy 算法进行压缩。” 这种情况下 Broker 接收到 GZIP 压缩消息后，只能解压缩然后使用 Snappy 重新压缩一遍。Broker 端也有一个参数叫 compression.type，和上面的那个例子中的同名。但是这个参数的默认值是 producer，这表示 Broker 端会尊重 Producer 端使用的压缩算法。可一旦你在 Broker 端设置了不同的 compression.type 值，就要小心了，因为可能会发生预料之外的 压缩 / 解压缩操作，通常表现为 Broker 端 CPU 使用率飙升 情况二：Broker 端发生了消息格式转换 所谓的消息格式转换主要是为了兼容老版本的消费者程序。上面说过 V1、V2 版本，在一个生产环境中，kafka 集群中同时保存多种版本的消息格式非常常见。为了兼容老版本的格式，Broker 端会对新版本消息执行向老版本格式的转换。这个过程会涉及消息的解压缩和重新压缩 何时解压缩通常来说解压缩发生在消费者程序中，也就是说 Producer 发送压缩消息到 Broker 后，Broker 照单全收并保存起来。当 Consumer 程序请求这部分消息时，Broker 依然原样发送出去，当消息到达 Consumer 端后，由 Consumer 自行解压缩还原之前的消息 那么 Consumer 怎么知道这些消息是用何种压缩算法压缩的呢？答案就在消息中。kafka 会将启用了哪种压缩算法封装进消息集合中，这样当 Consumer 读取到消息集合时，它自然就知道了这些消息使用的是哪种压缩算法。如果用一句话总结一下压缩和解压缩，那就是：Producer 端压缩、Broker 端保持、Consumer 端解压缩 除了在 Consumer 端解压缩，Broker 也会进行解压缩。注意，这和前面提到的消息格式转换时发生的解压缩是不同的场景。每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。我们必须承认这种解压缩对 Broker 端性能是有一定影响的，特别是对 CPU 的使用率而言 各种压缩算法对比在 Kafka 2.1.0 版本之前，Kafka 支持 3 种压缩算法：GZIP、Snappy 和 LZ4。从 2.1.0 开始，kafka 正式支持 Zstandard 算法（简写为 zstd）。它是 Facebook 开源的一个压缩算法，能够提供超高的压缩比 在实际使用中，GZIP、Snappy、LZ4 甚至是 zstd 的表现更有千秋。但对于 Kafka 而言，它们的性能测试结果缺出奇得一致，即在吞吐量方面：LZ4 &gt; Snappy &gt; zstd 和 GZIP；而在压缩比方面，zstd &gt; LZ4 &gt; GZIP &gt; Snappy。具体到物理资源，使用 Snappy 算法占用的网络带宽最多，zstd 最少，这是合理的，毕竟 zstd 就是要提供超高的压缩比；在 CPU 使用率方面，各个算法表现得差不多，只是在压缩时 Snappy 算是使用的 CPU 较多一些，而在解压缩时 GZIP 算法则可能使用更多的 CPU]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产者消息分区机制原理]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F30%2F%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E6%81%AF%E5%88%86%E5%8C%BA%E6%9C%BA%E5%88%B6%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[![Kafka 分区机制](生产者消息分区机制原理/Kafka 分区机制.png) 为什么分区kafka 有主题（Topic）的概念，它是承载真实数据的逻辑容器，而在主题之下还分为若干个分区，也就是说 Kafka 的消息组织方式实际上是三级结构：主题 - 分区 - 消息。主题下的每条消息只会保存在某一个分区中，而不会在多个分区中被保存多份。如图： 为什么使用分区的概念而不是直接使用多个主题呢？ 其实分区的作用就是提供负载均衡的能力，或者说对数据进行分区的主要原因，就是为了实现系统的高伸缩性（Scalability）。不同的分区都能独立地执行各自分区的读写请求处理。并且，我们还可以通过新的节点机器来增加整体系统的吞吐量 除了提供负载均衡这种最核心的功能之外，利用分区也可以实现其他一些业务级别的需求，比如实现业务级别的消息顺序的问题 分区策略所谓分区策略，是决定生产者将消息发送到哪个分区的算法。Kafka 为我们提供了默认的分区策略，同时它也支持你自定义分区策略。 如果要自定义分区策略，你需要显式地配置生产者端的参数 partitioner.class。你可以编写一个具体的类实现 org.apache.kafka.clients.producer.Partitioner 接口。这个接口定义了两个方法：partition() 和 close()，通常你只需要实现最重要的 partition 方法。 1int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster); 这里的 topic、key、keyBytes、value 和 valueBytes 都属于消息数据，cluster 则是集群信息（比如当前 Kafka 集群共有多少主题，多个 Broker 等） Kafka 给你这么多信息，就是希望让你能够充分地利用这些信息对消息进行分区，计算出它要被发送到哪个分区中。只要你自己实现类定义好了 partition 方法，同时设置 partitioner.class 参数为你自己实现类的 Full Qualified Name，那么生产者程序就会按照你的代码逻辑对消息进行分区 虽说可以有无数中分区的可能，但比较常见的分区策略也就那么几种 轮询策略也成 Round - robin 策略，即顺序分配。比如一个主题下有 3 个分区，那么第一条消息被发送到分区 0，第二条被发送到分区 1，第三条被发送到分区 2，以此类推。如下： 这就是所谓的轮询策略。轮询策略是 Kafka Java 生产组 API 默认提供的分区策略。如果你未指定 partitioner.class 参数，那么你的生产者程序就会按照轮询的方式在主题的所有分区均匀地放消息 轮询策略有非常优秀的负载均衡表现，它总是能保证消息最大限度地被平均分配到所有分区上，故默认情况下它是最合理的分区策略，也是我们最常用的分区策略之一 随机策略也成 Randomness 策略。所谓随机就是我们随意地将消息放置到任意一个分区上，如下： 如果要实现随机策略版的 partition 方法，只需要两行代码即可： 12List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);return ThreadLocalRandom.current().nextInt(partitions.size()); 本质上随机策略也是力求将数据均匀地打散到各个分区，但从表现上看，它要逊于轮询策略，所以如果追求数据的均匀分布，还是使用轮询策略比较好。 按消息键保序策略也成 Key - ordering 策略。这个名词其实是瞎编的，Kafka 官网上并无这样的提法 Kafka 允许为每条消息定义消息键，简称为 Key。这个 Key 的作用非常大，它可以是一个有着明确业务含义的字符串，比如客户代码、部门编号或是业务 ID 等；也可以直接用来表征元数据。特别是在 Kafka 不支持时间戳的年代，在一些场景中，工程师们都是直接将消息创建时间封装进 Key 里面的 一旦消息被定义了 Key，那么你就可以保证同一个 Key 的所有消息都进入到相同的分区里面，由于每个分区下的消息处理都是有顺序的，故这个策略被称为按消息键保序策略，如图： 实现这个策略的 partition 方法同样简单，只需要下面两行代码即可： 12List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);return Math.abs(key.hashCode()) % partitions.size(); 前面提到的 Kafka 默认分区策略实际上同时实现了两种策略：如果指定了 Key，那么默认实现按消息键保序策略；如果没有指定 Key，则使用轮询策略 其他分区策略除了上面几种比较基础的策略，其实还有一种比较常见的，即所谓的基于地理位置的分区策略。当然这种策略一般只针对于那些大规模的 Kafka 集群，特别是跨城市、跨国家甚至是跨大洲的集群 假设所有系统的一个服务都部署在北京的一个机房，现在考虑在南方找个城市（比如广州）再创建一个机房；另外从两个机房中选取一部分机器共同组成一个大的 Kafka 集群。显然，这个集群中必然有一部分机器在北京，另外一部分机器在广州 假设系统计划为每个新注册用户提供一份注册礼品，比如南方的用户注册可以免费得到一碗「甜豆腐脑」，而北方的新注册用户可以得到一碗「咸豆腐脑」。如果用 Kafka 来实现很简单，只需要创建一个双分区的主题，然后再创建两个消费者程序分别处理南北方注册用户逻辑即可 但问题是你需要把南北方注册用户的注册消息正确地发送到位于南北方的不同机房中，因为处理这些信息的消费者程序只可能在某一个机房中启动着。换句话说，送甜豆腐脑的消费者程序只在广州机房启动着，而送咸豆腐脑的程序只在北京的机房中，如果你向广州机房中的 Broker 发送北方注册用户的消息，那么这个用户就无法得到礼品 此时我们就可以根据 Broker 所在的 IP 地址实现定制化的分区策略。如下： 12List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);return partitions.stream().filter(p -&gt; isSouth(p.leader().host())).map(PartitionInfo::partition).findAny().get(); 我们可以从所有分区中找出那些 Leader 副本在南方的所有分区，然后随机挑选一个进行消息发送]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之说说 join 连接]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F25%2FMySQL-%E4%B9%8B%E8%AF%B4%E8%AF%B4-join-%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[今天我们说说 join 语句是怎么执行的。为了方便分析，我们先创建两个表 t1 和 t2 1234567891011121314151617181920212223CREATE TABLE `t2` ( `id` int(11) NOT NULL, `a` int(11) DEFAULT NULL, `b` int(11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `a` (`a`)) ENGINE=InnoDB;delimiter ;;create procedure idata()begin declare i int; set i=1; while(i&lt;=1000)do insert into t2 values(i, i, i); set i=i+1; end while;end;;delimiter ;call idata();create table t1 like t2;insert into t1 (select * from t2 where id&lt;=100) 可以看到，这两个表都有一个主键索引 id 和一个索引 a，字段 b 上无索引。存储过程 idata() 往表里 t2 里插入了 1000 行数据吗，在表 t1 里插入的是 100 行数据 Index Nested-Loop Join先看一条 SQL 语句： 1select * from t1 straight_join t2 on (t1.a = t2.a) 如果直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，这样会影响我们分析 SQL 语句的执行过程。所以，为了便于分析执行过程中的性能问题，用 straight_join 让 MySQL 使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去 join 这个语句中，t1 是驱动表，t2 是被驱动表。我们看一下这条语句的 explain 结果 在这条语句里，被驱动表 t2 的字段 a 上有索引，join 过程用上这个索引，因此这个语句的执行流程是这样的： 从表 t1 中读入一行数据 R 从数据行 R 中，取出 a 字段到表 t2 里去查找 取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分 重复执行步骤 1 到 3，直到表 t1 的末尾循环结束 这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为 Index Nested - Loop Join，简称 NLJ。流程图如下： 这个流程里： 对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行 而对于每一行的 R，根据 a 字段去表 t2 查找，走的是树搜索过程。由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行 所以，整个执行流程，总扫描行数是 200 那么，怎么选择驱动表？ 在这个 join 语句执行过程中，驱动表是走全表扫描，而被驱动表是走树搜索 假设被驱动表的行数是 M。每次在被驱动表查一行数据，要先搜索索引 a，再搜索主键索引。每次搜索一棵树近视复杂度是以 2 为底的 M 的对数，记为 log₂M，所以在被驱动表上差一行的时间复杂度是 2 * log₂M 假设驱动表的行数是 N，执行过程就要扫描驱动表 N 行，然后对于每一行，到被驱动表上匹配一次。因此整个执行过程，近似复杂度是 N + N * 2 * log₂M 显然，N 对扫描行数的影响更大，因此应该让小表来做驱动表 接着我们看看驱动表用不上索引的情况 Simple Nested - Loop Join我们把 SQL 改成这样： 1select * from t1 straight_join t2 on (t1.a = t2.b) 由于表 t2 的字段 b 上没有索引，因此再用图 2 的执行流程时，每次到 t2 去匹配的时候，就要做一次全表扫描 如果继续使用图 2 的算法，是不是可以得到正确的结果呢？如果只看结果的话，这个算法是正确的，而且这个算法也有一个名字，叫 Simple Nested - Loop Join 但是，这样算来，这个 SQL 请求就要扫描表 t2 多达 100 次，总共扫描 100 * 1000 = 10 万行 当然，MySQL 也没有使用这个 Simple Nested - Loop Join 算法，而是使用了另一个叫做 Block Nested - Loop Join 的算法，简称 BNL Block Nested - Loop Join这时候，被驱动表上没有可用的索引，算法的流程是这样的： 把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的 select *，因此是把整个表 t1 放入了内存 扫描表 t2，把表 t2 中的每一行取出来，跟 join buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回 这个过程的流程图如下： 对应地，这条 SQL 语句的 explain 结果如下所示： 可以看到，这个过程，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是 1100.由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100 * 1000 = 10 万次 相比较于 Simple Nested - Loop Join 算法进行查询，扫描行数也是 10 万行，时间复杂度是一样的。但是，Block Nested - Loop Join 算法的 10 万次判断是内存操作，速度上会快很多，性能也很好 接着，这种情况下，应该选择哪个表做驱动表 假设小表的行数是 N，大表的行数是 M，那么在这个算法里： 两个表都做一次全表扫描，所以总的扫描行数是 M + N 内存中的判断次数是 M * N 可以看到，这时候选择大表还是小表做驱动表，执行耗时是一样的 如果，表 t1 是一个大表，join_buffer 放不下怎么办呢？ join_buffer 的大小是由参数 join_buffer_size 设定的，默认是 256K。如果放不下表 t1 的所有数据，策略很简单，就是分段放。 我们把 join_buffer_size 调小，那么执行过程就变成： 扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步 扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回 清空 join_buffer 继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步 执行流程图也变成这样： 图中的步骤 4 和 5，表示清空 join_buffer 再复用。这个流程才体现出这个算法中「Block」的由来，表示「分块去 join」 可以看到，由于表 t1 被分为了两次放入 join_buffer 中，导致表 t2 会被扫描两次。虽然分成两次 放入 join_buffer，但是判断等值条件的次数还是不变的，依然是 (88 + 12) * 1000 = 10 万次 那么，这种情况下驱动表的选择问题是怎样的 假设，驱动表的数据行数是 N，需要分 K 段才能完成算法流程，被驱动表的数据行数是 M。注意，这里的 K 不是常数，N 越大 K 就会越大，因此把 K 表示为 λ * N，显然 λ 的取值范围是 (0, 1) 所以，这个算法的执行过程中： 扫描行数是 N + λ * N * M 内存判断 N * M 次 显然，内存判断次数是不受选择哪个表作为驱动表影响的。而考虑到扫描行数，在 M 和 N 大小确定的情况下，N 小一些，整个算式的结果会更小 所以结论是，应该让小表当驱动表 当然，你会发现，在 N + λ * N * M 这个式子里，λ 才是影响扫描行数的关键因素，这个值越小越好 N 越大，分段数 K 越大。那么，N 固定的时候，什么参数会影响 K 的大小呢？（也就是 λ 的大小）答案是 join_buffer_size。join_buffer_size 越大，一次可以放入的行越多，分成的段数也就越少，对被驱动表的全表扫描次数就越少 这就是为什么，网上会有一些建议，如果你的 join 语句很慢，就把 join_buffer_size 改大 所以，能不能使用 join 语句？ 如果可以使用 Index Nested - Loop Join 算法，也就是说可以用上被驱动表上的索引，其实是没问题的 如果使用 Block Nested - Loop Join 算法，扫描次数就会过多。尤其是在大表上的 join 操作，这样可能要扫描被驱动表很多次，会占用大量的系统资源。所以这种 join 尽量不要用 所以在判断要不要使用 join 语句时，就看 explain 结果里面，Extra 字段里面有没有出现 Block Nested Loop 字样 那么，如果要使用 join，应该选择大表做驱动表还是小表做驱动表？ 如果是 Index Nested- Loop Join 算法，应该选择小表做驱动表 如果是 Block Nested Join 算法： 在 join_buffer_size 足够大的时候，是一样的 在 join_buffer_size 不够大的时候，应该选择小表做驱动表 所以，在决定哪个表做驱动表的时候，应该是两个表按照各自的条件过滤，过滤完成之后，计算参与 join 的各个字段的总数据量，数据量小的那个表，就是「小表」，应该作为驱动表]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之怎么保证高可用]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F23%2FMySQL-%E4%B9%8B%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[主备延迟主备延迟可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动操作，比如主库所在机器掉电 在介绍主动切换流程的详细步骤之前，要先跟你说明一个概念，即「同步延迟」。与数据同步有关的时间点主要包括以下三个： 主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1 之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2 备库 B 执行完成这个事务，我们把这个时刻记为 T3 所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3 - T1 你可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒 seconds_behind_master 的计算方法是这样的： 每个事务的 binlog 里面都有一个时间段，用于记录主库上写入的时间 备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master 所以，seconds_behind_master 这个参数计算的就是 T3 - T1。因此，我们可以用这个来作为主备延迟的值，这个值的时间精度是秒 如果主备库机器的系统时间设置不一致，会不会导致主库延迟的值不准？不会的，因为备库连接到主库的时候，会通过执行 SELECT UNIX TIMESTAMP() 函数来获得当前主库的系统时间。如果发现主库的系统时间与自己不一致，备库在执行 seconds_behind_master 计算的时候会自动扣掉这个差值 在网络正常的时候，日志从主库传到备库所需的时间时很短的，即 T2 - T1 的值是非常小的。即，在网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差 所以，主备延迟最直接的表现是，备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢。 主备延迟的来源首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差 另外一个可能是，备库的压力大了。一般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑 这种情况，我们一般可以这么处理： 一主多从。除了备库外，可以多连接几个从库，让这些从库来分担读的压力 通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力 其中，一主多从大都会被采用。因为作为数据库系统，还必须保证有定期全量备份的能力，而从库，就很适合用来做备份 还有第三种可能，即大事务 大事务这种情况很好理解。因为主库上必须等待事务执行完才会写入 binlog，再传给备库。所以，如果一个主库上的语句执行 10 分钟，那这个事务很可能就会导致从库延迟 10 分钟 例如，不要一次性地用 delete 语句删除太多数据。这就是一个典型的大事务场景 比如，一些归档类的数据，平时没有注意删除历史数据，等到空间快满了，开发人员要一次性删掉大量历史数据。结果，DBA 可能就会收到延迟报警，然后会要求你后续删除数据的时候，要控制每个事务删除的数据量，分成多次删除 另一个典型的大事务场景，就是大表 DDL 造成主备延迟还有一个大方向原因，就是备库的并行复制能力。这个后续再说 由于主备延迟的存在，所以在主备切换的时候，就有相应的不同策略 可靠性优先策略如图，是之前讲过的双 M 结构 在双 M 结构下，从状态 1 到状态 2 切换的详细过程如下： 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步 把主库 A 改成只读状态，即把 readonly 设置为 true 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止 把备库 B 改成可读写状态，也就是把 readonly 设置为 false 把业务请求到切换备库 B 这个切换流程，一般是由专门的 HA 系统来完成的，我们暂时称之为可靠性优先流程 可以知道，这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，知道步骤 5 完成后才能恢复 在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。这也是为什么需要在步骤 1 先做判断，确保 seconds_behind_master 的值足够小 如果一开始主备延迟就长达 30 分钟，而不先做判断直接切换的话，系统的不可用时间就会长达 30 分钟，这种情况一般业务都是不可接受的 当然，系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的策略，来把这个不可用时间几乎降为 0 可用性优先策略如果强行把步骤 4、5 调整到最开始执行，也就是不等主备数据同步，直接把连接切换到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了 这个切换流程，暂时成为可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况 举个例子。有一个表 t: 1234567CREATE TABLE `t` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `c` int(11) unsigned DEFAULT NULL, PRIMARY KEY (`id`)) ENGINE=InnoDB;insert into t(c) values(1),(2),(3); 这个表自定义了一个自增主键 id，初始化数据后，主库和备库上都是 3 行数据。接下来，业务人员要继续在 表 t 上执行两条插入语句的命令，依次是： 12insert into t(c) values(4);insert into t(c) values(5); 假设，现在主库上其他的数据表有大量的更新，导致主备延迟达到 5 秒。在插入一条 c = 4 的语句后，发起了主备切换。 下图是可用性优先策略，且 binlog_format= mixed 时的流程切换和数据结果 我们分析下这个切换流程： 步骤 2 中，主库 A 执行完 insert 语句，插入了一行数据 (4, 4)，之后开始进行主备切换 步骤 3 中，由于主备之间有 5 秒的延迟，所以备库 B 还没来得及应用「插入 c = 4」这个中转日志，就开始接收客户端「插入 c = 5」的命令 步骤 4 中，备库 B 插入了一行数据 (4, 5)，并且把这个 binlog 发给主库 A 步骤 5 中，备库 B 执行「插入 c = 4」这个中转日志，插入了一行数据 (5, 4)。而直接在备库 B 执行的「插入 c = 5」这个语句，传到主库 A，就插入了一行新数据 (5, 5) 最后的结果是，主库 A 和备库 B 上出现了两行不一致的数据。可以看到，这个数据不一致，是由可用性优先流程导致的 那么，如果我还是用可用性优先策略，但设置 binlog_format = row，情况又会怎样呢？ 因为 row 格式记录在 binlog 的时候，会记录新插入的行的所有字段值，所以最后只会有一行不一致，而且，两边的主备同步的应用线程会报错 duplicate key error 并停止。即，这种情况下，备库 B 的 (5, 4) 和 主库 A 的 (5, 5) 这两行数据，都不会被对方执行。如下： 从上图可以得出一些结论： 使用 row 格式的 binlog，数据不一致的问题更容易被发现。而使用 mixed 或者 statement 格式的 binlog 时，数据很可能悄悄地不一致了，如果你过了很久才发现数据不一致的问题，很可能这时的数据不一致已经不可查，或者连带造成了更多的数据逻辑不一致 主备切换的可用性优先策略会导致数据不一致。因此，大多数情况下，我都建议使用可靠性优先策略。毕竟对数据服务来说的话，数据的可靠性一般还是要优于可用性的 那么，按照可靠性优先的思路，异常切换会是什么效果？ 假设，主库 A 和备库 B 间的主备延迟是 30 分钟，这时候主库 A 掉电了，HA 系统要切换 B 作为主库。我们在主动切换的时候，可以等到主备延迟小于 5 秒的时候再启动切换，但这时候已经别无选择了 采用可靠性优先策略的话，就必须得等到备库 B 的 seconds_behind_master = 0 之后，才能切换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用的状态。因为，主库 A 掉电后，我们的连接还没有切换到备库 B 那能不能直接切换到备库 B，但是保持 B 只读呢？ 不行。因为这段时间内，中转日志还没有应用完成，如果直接发起主备切换，客户端查询看不到之前执行完成的事务，会认为有「数据丢之」 虽然随着中转日志的继续应用，这些数据会恢复回来，但是对于一些业务来说，查询到「暂时丢失数据的状态」也是不能被接受的 到这就会知道，在满足数据可靠性的前提下，MySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之主备如何保证一致]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F22%2FMySQL-%E4%B9%8B%E4%B8%BB%E5%A4%87%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E4%B8%80%E8%87%B4%2F</url>
    <content type="text"><![CDATA[MySQL 主备的基本原理下图是基本的主备切换流程 在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据都是相同的 当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库 在状态 1 中，虽然节点 B 没有被直接访问，但是依然建议把节点 B（也就是备库）设置成只读（readonly）模式。因为： 有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作 防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致 可以用 readonly 状态，来判断节点的角色 把主库设置成只读，还怎么跟主库保持同步更新？不用担心。readonly 设置对超级（super）权限用户是无效的，而用于同步更新的线程，就拥有超级权限 接着，看看节点 A 到节点 B 这条线的内部流程是怎样的。如下图，就是一个 update 语句在节点 A 执行，然后同步到节点 B 的完整流程图 上图可以看到：主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog 备库 B 和主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的： 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log） sql_thread 读取中转日志，解析出日志里的命令，并执行 需要说明的是，后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程，跟我们今天要介绍的原理没有直接关系，暂不展开 分析完了这个长连接的额逻辑，我们再看一个问题：binlog 里面是什么内容，为什么备库拿过去可以直接执行 binlog 的三种格式对比binlog 有两种格式，一种是 statement，一种是 row，还有 mixed，mixed 其实是前两种格式的混合 为了方便描述 binlog 的这三种格式间的区别，我们创建了一个表，并初始化几行数据 1234567891011121314CREATE TABLE `t` ( `id` int(11) NOT NULL, `a` int(11) DEFAULT NULL, `t_modified` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (`id`), KEY `a` (`a`), KEY `t_modified`(`t_modified`)) ENGINE=InnoDB;insert into t values(1,1,&apos;2018-11-13&apos;);insert into t values(2,2,&apos;2018-11-12&apos;);insert into t values(3,3,&apos;2018-11-11&apos;);insert into t values(4,4,&apos;2018-11-10&apos;);insert into t values(5,5,&apos;2018-11-09&apos;); 如果要在表中删除一行数据的话，我们看看 delete 语句的 binlog 是怎么记录的 下面的这个语句包含注释，如果你用 MySQL 客户端来做这个实验，要加 -c 参数，否则客户端会自动去掉注释 1delete from t /*comment*/ where a &gt;= 4 and t_modified &lt;= &apos;2018-11-10&apos; limit 1; 当 binlog_format = statement 时，binlog 里面记录的就是 SQL 语句的原文，可以如下命令查看 binlog 的内容 1show binlog events in &apos;master.000001&apos; 我们看一下上图的输出结果： 第一行 SET @@SESSION.GTID_NEXT=&#39;ANONYMOUS&#39; 可以先忽略 第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务 第三行就是真实执行的语句了。在真实执行 delete 命令之前，还有一个 use test 命令，这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能正确地更新到 test 库的表 tuser ‘test’ 命令之后是 delete 语句，就是我们输入的 SQL 原文了。可以看到，binlog 记录了 SQL 命令，甚至连注释也一并记录了 最后一行是一个 COMMIT，可以看到里面写着 xid = 61 为了说明 statement 和 row 格式的区别，我们看一下这条 delete 命令的执行效果图： 可以看到，运行这条命令产生了一个 warning，原因是当前 binlog 设置的是 statement 格式，并且语句中有 limit，所以这个命令可能是 unsafe 的。为什么？ 因为 delete 带 limit，很可能会出现主备数据不一致的情况，比如上面这个例子： 如果 delete 语句使用的是索引 a，那么会根据索引 a 找到第一个满足条件的行，即删除的是 a = 4 这一行 如果使用的是索引 t_modified，那么删除的就是 t_modified = ‘2018-11-09’ ，也就是 a = 5 这一行 由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的 如果把 binlog 的格式改为 binlog_format = ‘row’ 是不是就好了呢？我们看 binlog 中的内容吧 可以看到，与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里面没有 SQL 语句的原文，而是替换了两个 event：Table_map 和 Delete_rows Table_map event，用于说明接下来要操作的表是 test 库的表 t Delete_rows event，用于定义删除的行为 上图其实是看不到详细信息的，还需要借助 binlog 工具。用下面这个命令解析和查看 binlog 中的内容。从上图可以知道，这个事务的 binlog 是从 8900 这个位置开始的，所以可以用 start-position 参数来指定从这个位置的日志开始解析 1mysqlbinlog -vv data/master.000001 --start-position=8900; 从上图可以看出几个信息： service id 1，表示这个事务是在 server_id = 1 的这个库上执行的 每个 event 都有 CRC32 的值，这是因为把参数 binlog_checksum 设置成了 CRC32 Table_map event 显示了接下来要打开的表，map 到数字 226。现在我们这条 SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 Table_map event，都会 map 到一个单独的数字，用于区分不同表的操作 我们在 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1=4、@2=4 这些值） binlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把 binlog_row_image 设置为 MINMAL，则只会记录必要的信息。这个例子里，就是只会记录 id = 4 这个信息 最后的 XID event，用于表示事务被正确地提交了 可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id = 4 的行，不会有主备删除不同行的问题 mixed 格式的 binlog那么，为什么会有 mixed 这种 binlog 格式的存在场景？推论过程是这样子的： 因为有些 statement 格式的 binlog 会导致主备不一致，所以要使用 row 格式 但 row 格式的缺点是，很占空间。比如你用 delete 语句删除 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但使用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也会耗费 IO 资源，影响执行速度 所以，MySQL 就取了个折中方案，就有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式 即，mixed 格式可以利用 statement 格式的优点，同时又避免了数据不一致的风险 因此，如果你的线上 MySQL 设置的 binlog 格式是 statement 的话，那基本上就可以认为这是一个不合理的设置。你至少应该把 binlog 的格式设置为 mixed。 比如我们这个例子，设置为 mixed 后，就会记录为 row 格式；而如果执行的语句去掉 limit 1，就会记录为 statement 格式 当然，现在越来越多的场景都是把 MySQL 的 binlog 格式设置成 row。这么做的理由有很多，一个可以直接看出来的好处就是：恢复数据 我们分别从 delete、insert 和 update 这三种 SQL 语句的角度，来看看数据恢复的问题 从上图可以看出，即使执行了 delete 语句，row 格式的 binlog 也会被删掉的行的整行信息保存起来。所以，如果你在执行一条 delete 语句以后，发现删错数据了，可以直接把 binlog 中记录的 delete 语句转成 insert，把被错删的数据插入回去就可以恢复了 如果执行错了 insert 语句呢？row 格式下，insert 语句的 binlog 里会记录所有的字段信息，这些信息可以用来精确定位刚刚被插入的那一行。这时，直接把 insert 语句转成 delete 语句，删除掉这被误插入的一行数据就可以了 如果执行的是 update 语句的话，binlog 里会记录修改前整行的数据和修改后的整行数据。所以，如果你误执行了 update 语句的话，只需要把这个 event 前后的两行信息对调一下，再去数据库里面执行，就能恢复这个更新操作了 我们用 mixed 格式来说明一个问题，看一下这条 SQL 语句： 1insert into t values(10, 10, now()) 如果我们把 binlog 设置为 mixed，MySQL 会把它记录为 row 格式还是 statement 格式呢？如下： 可以看到，用的是 statement 格式。如果这个 binlog 过了一分钟才传给备库的话，那主备的数据不就不一致了吗？ 我们用 mysqlbinlog 工具来看看： 由上图可以看到，binlog 在记录 event 的时候，多了一条命令：SET TIMESTAMP = 1546103491。他用 SET TIMESTAMP 命令约定了接下来的 now() 函数的返回时间 所以，这个 binlog 不管是 1 分钟后被执行，还是 3 天后被执行，这个 insert 语句插入的行，值都是固定的。即，通过这条 SET TIMESTAMP 命令，MySQL 就确保了主备数据的一致性 如果你用 mysqlbinlog 解析出日志，然后把里面的 statement 语句直接拷贝出来执行。那么是有风险的，因为有些语句的执行结果是依赖于上下文命令的，直接执行的结果很可能是错误的 所以，用 binlog 来恢复数据的标准做法是，用 mysqlbinlog 工具解析出来，然后把解析结果整个发给 MySQL 执行。类似下面的命令： 1mysqlbinlog master.000001 --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -p13000 -u$user -p$pwd 这个命令的意思是，将 master.000001 文件里面从第 2738 字节到第 2973 字节中间这段内容解析出来，放到 MySQL 去执行 循环复制问题通过上面的讲述，我们知道，binlog 的特性确保了在备库执行相同的 binlog，可以得到与主库相同的状态 因此，我们可以认为正常情况下主备的数据是一致的。即，第一张图中的 A B 两个节点的内容是一直的。其实，第一张图画的是 M - S 结构，但实际生产上使用较多的是双 M 结构，也就是下图所示的主备切换流程 相比于第一张图，上图就只是多了一条线，意思是：节点 A 和节点 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系 但是，双 M 结构还有一个问题 业务逻辑在节点 A 上更新一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog（建议把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog） 那么，节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 之间，会不断地循环执行这个更新语句，也就是循环复制了。怎么解决？ 从上面我们知道，MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制问题： 规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系 一个备库接到 binlog 并在重放的过程中，生产与原 binlog 的 server id 相同的新的 binlog 每个库在收到自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志 按照这个逻辑，如果我们设置了双 M 结构，日志的执行就会变成这样： 从节点 A 更新的事务，binlog 里面记的都是 A 的 server id 传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之怎么保证数据不丢]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F15%2FMySQL-%E4%B9%8B%E6%80%8E%E4%B9%88%E4%BF%9D%E8%AF%81%E6%95%B0%E6%8D%AE%E4%B8%8D%E4%B8%A2%2F</url>
    <content type="text"><![CDATA[MySQL 的 WAL 机制，全程是 Write-Ahead Logging，预写日志系统。指的是 MySQL 的写操作并不是立刻更新到磁盘上，而是先记录在日志上，然后在合适的时间更新到磁盘上。日志主要分为 undo log、redo log 和 binlog，作用分别是「完成 MVCC 从而实现 MySQL 的隔离级别」「降低随机写的性能消耗（转成顺序写），同时防止写操作因为宕机而丢失」「写操作的备份，保证主从一致」 其实，只要 redo log 和 binlog 保证持久化到磁盘，就能确保 MySQL 异常重启后，数据可以恢复。那么，MySQL 写入 binlog 和 redo log 的流程是怎样的呢 binlog 的写入机制binlog 的写入逻辑比较简答：事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中 一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入。这就涉及到了 binlog cache 的保存问题 系统给 binlog cache 分配了一片内存，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘 事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。状态如图 1 所示： 可以看到，每个线程都有自己 binlog cache，但是共用同一份 binlog 文件 图中的 write，指的就是把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快 图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS write 和 fsync 的时机，是由参数 sync_binlog 控制的： sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync sync_binlog = 1 的时候，表示每次提交事务都会执行 fsync sync_binlog = N（N &gt; 1）的时候，表示每次提交事务都 write，但累积 N个事务后才 fsync 因此，在出现 IO 瓶颈的场景里，将 sync_binlog 设置成一个比较大的值，可以提升性能。在实际的业务场景中，考虑到丢失日志量的可控性，一般不建议将这个参数设置成 0，比较常见的是将其设置为 100 ~ 1000 中的某个数值 但是，将 sync_binlog 设置为 N，对应的风险是：如果主机发生异常重启，会丢失最近 N 个事务的 binlog 日志 redo log 的写入机制之前说过，事务在执行过程中，生成的 redo log 是要先写到 redo log buffer 的。那么，redo log buffer 里面的内容，是不是每次生成后都要直接持久化到磁盘呢？答案是，不需要 如果事务执行期间 MySQL 发生异常重启，那这部分日志就丢了。由于事务并没有提交，所以这时日志丢了也不会有损失 那么，另一个问题是，事务还没提交的时候，redo log buffer 中的部分日志有没有可能被持久化到磁盘呢？答案是，确实会有 这个问题，要从 redo log 可能存在的三种状态说起。这三种状态，对应的就是图 2 中的三个颜色块 这三种状态分别是： 存在 redo log buffer 中，物理上是在 MySQL 进程内存中 写到磁盘（write），但是并没有持久化（fsync），物理上是在文件系统的 page cache 里面 持久化到磁盘，对应的是 hard disk 日志写到 redo log buffer 是很快的，write 到 page cache 也差不多，但是持久到磁盘的速度的慢多了 为了控制 redo log 的写入策略，InnoDB 提供了 innodb_flush_log_at_trx_commit 参数，它有三种可能取值： 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久到磁盘 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘 注意，事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些 redo log 也会被后台线程一起持久化到磁盘。即，一个没有提交的事务的 redo log，也是可能已经持久化到磁盘的 实际上，除了后台线程每秒一次的轮询操作外，还有两种场景会让一个没有提交的事务的 redo log 写入到磁盘中 一种是，redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动写盘。注意，由于这个事务并没有提交，所以这个写盘动作只是 write，而没有调用 fsync，也就是只留在了文件系统柜的 page cache 另一种是，并行的事务提交的时候，顺带将这个事务的 redo log buffer 持久化到磁盘。假设一个事务 A 执行到一半，已经写了一些 redo log 到 buffer 中，这时候有另外一个线程的事务 B 提交。如果 innodb_flush_log_at_trx_commit 设置的是 1，那么按照这个参数的逻辑，事务 B 要把 redo log buffer 里的日志全部持久化到磁盘。这时候，就会带上事务 A 在 redo log buffer 里的日志一起持久化到磁盘 这里需要说明的是，我们介绍两阶段提交的时候说过，时序上 redo log 先 prepare，再写 binlog，最后再把 redo log commit 如果把 innodb_flush_log_at_trx_commit 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的 每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了 通常我们说 MySQL 的「双 1」配置，指的就是 sync_binlog 和 innodb_flush_log_at_trx_commit 都设置成 1.也就是说，一个事务完成提交前，需要等待两次刷盘，一次是 redo log（prepare 阶段），一次是 binlog 这时候，可能会有一个疑问？这意味着我从 MySQL 看到的 TPS 是每秒两万的话，每秒就会写四万次磁盘。如果磁盘能力也就两万左右，怎么能实现两万的 TPS？ 这里，就要用到组提交（group commit）机制了 这里，需要先介绍日志逻辑序列号（log sequence number，LSN）的概念。LSN 是单调递增的，用来对应 redo log 的一个个写入点。每次写入长度为 length 的 redo log，LSN 的值就会加上 length LSN 也会写到 InnoDB 的数据页中，来确保数据页不会被多次执行重复的 redo log 如下图，是三个并发事务（trx1, trx2, trx3）在 prepare 阶段，都写完 redo log buffer，持久化到磁盘的过程，对应的 LSN 分别是 50、120 和 160 从图中可以看到： trx1 是第一个到达的，会被选为这组的 leader 等 trx1 要开始写盘的时候，这个组里面已经有了三个事务，这时候 LSN 也变成了 160 trx1 去写盘的时候，带的就是 LSN = 160，因此等 trx1 返回时，所有 LSN 小于等于 160 的 redo log，都已经被持久化到磁盘 这时候 trx2 和 trx3 就可以直接返回了 所以，一次组提交里面，组员越多，节约磁盘 IOPS 的效果就越好。但如果只有单线程压测，那就只能老老实实地一个事务对应一次持久化操作了 在并发更新场景下，第一个事务写完 redo log buffer 以后，接下来这个 fsync 越晚调用，组员可能越多，节约 IOPS 的效果就越好 为了让一次 fsync 带的组员更多，MySQL 有一个很有趣的优化：拖时间。redo 两阶段提交的时候，流程图如下 图中，把「写 binlog」当成一个动作。但实际上，写 binlog 是分成两步的： 先把 binlog 从 binlog cache 中写到磁盘上的 binlog 文件 调用 fsync 持久化 MySQL 为了让组提交的效果更好，把 redo log 做 fsync 的时间拖到了步骤 1 之后。即，上面的图变成了这样： 这么一来，binlog 也可以组提交了。在执行图中第 4 步把 binlog fsync 到磁盘时，如果有多个事务的 binlog 已经写完了，也是一起持久化的，这样也可以减少 IOPS 的消耗 不过通常情况下第 3 步执行得很快，所以 binlog 的 write 和 fsync 间的间隔时间很短，导致能集合到一起持久化的 binlog 比较少，因此 binlog 的组提交的效果通常不如 redo log 的效果好 如果想提升 binlog 组提交的效果，可以通过设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no delay_count 来实现 binlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync binlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync 这两个条件是或的关系，也就是说只要有一个满足条件就会调用 fsync。所以，当 binlog_group_commit_sync_delay 设置为 0 的时候，binlog_group_commit_sync_no_delay_count 也无效了 WAL 机制是减少磁盘写，可是每次提交事务都要写 redo log 和 binlog，这磁盘读写次数也没变少啊 其实，WAL 机制主要得益于两个方面： redo log 和 binlog 都是顺序写，磁盘的顺序写比随机写速度要快 组提交机制，可以大幅度降低磁盘的 IOPS 消耗 到这里，如果你的 MySQL 现在出现了性能瓶颈，而且瓶颈在 IO 上，可以通过哪些方法来提升性能呢？ 针对这个问题，可以考虑一下三种方法： 设置 binlog_group_commit_sync_delay 和 binlog_group_commit_sync_no_delay_count 参数，减少 binlog 的写盘次数。这个方式是基于「额外的故意等待」来实现的，因此可能会增加语句的响应时间，但没有丢失数据的风险 将 sync_binlog 设置为大于 1 的值（比较常见是 100 ~ 1000）。这样的风险是，主机掉电时会丢 binlog 日志 不建议把 innodb_flush_log_at_trx_commit 设置为 0。因为把这个参数设置成 0，表示 redo log 只保存在内存中，这样的话 MySQL 本身异常重启也会丢数据，风险太大。而 redo log 写到文件系统的 page cache 的速度也是很快的，所以将这个参数设置成 2 跟设置成 0 其实性能差不多，但这样 MySQL 异常重启时就不会丢数据了，相比之下风险会更小]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之全局锁和表锁]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F12%2FMySQL-%E4%B9%8B%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81%2F</url>
    <content type="text"><![CDATA[数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则，而锁就是用来实现这些访问规则的重要数据结构。而根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类 全局锁全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句 全局锁的典型使用场景是，做全库逻辑备份。就是把整库每个表都 select 出来存成文本 但是，让整库都只读，听上去就很危险： 如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆 如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟 看起来加全局锁并不好，但为什么备份要加锁呢？我们看一下不加锁会有什么问题 假设你要维护「极客时间」的购买系统，关注的是用户账户余额表和用户课程表 现在发起一个逻辑备份。假设备份期间，有个用户购买了一门课程，业务逻辑里就要扣掉他的余额，然后往已购课程里面加上一门课 如果时间顺序上是先备份账户余额表（u_account），然后用户购买，然后备份用户课程表（u_cource），会发生什么？如下： 可以看到，这个备份结果里，用户 A 的数据状态是「账户余额没扣，但是用户课程表里面已经多了一门课」。如果后面用这个备份来恢复数据的话，用户 A 就会发现自己赚了 所以，不加锁的话，备份系统备份得到的库不是一个逻辑时间点，这个视图是逻辑不一致的 其实，是有一个方法能够拿到一致性视图的，就是在可重复读隔离级别下开启一个事务。 官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数 -single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的 有了这个功能，为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了 所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是使用 InnoDB 替代 MyISAM 的原因之一 既然要全库只读，为什么不使用 set global readonly = true 的方式呢？readonly 方式也可以让全库进入只读状态，但还是建议你用 FTWRL 方式，原因如下： 在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，不建议使用 在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高 业务的更新不只是增删改数据（DML），还有可能是加字段等修改表结构的操作（DDL）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的 但是，即使没有被全局锁住，加字段也不是就能很顺利，因为还有表级锁 表锁MySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL） 表锁的语法是 lock tables … read / write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限制了本线程接下来的操作对象 例如，如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1,、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表 在还没有出现更细粒度的锁的时候，表锁时最常用的处理并发的方式。而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大 另一类表级的锁时 MDL（metadata lock）。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上 ，肯定是不行的 因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁 读锁之间不互斥，因此你可以有多个线程同事对一张表增删改查 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行 虽然 MDL 锁时系统默认会加的，但是不能忽略这么一个机制。举个例子，给一个小表加个字段，导致整个库挂了 给一个表加字段，或者修改字段，或者加索引，需要扫描全表的数据。在对大表操作的时候，你肯定会特别小心，以免对线上服务造成影响。而实际上，即使是小表，操作不慎也会出问题。如下，假设表 t 是一个小表 我们看到 session A 先启动，这时候会对表 t 加一个 MDL 读锁。由于 session B 需要的也是 MDL 读锁，因此可以正常执行 之后 session C 会被 blocked，是因为 session A 的 MDL 读锁还没有释放，而 session C 需要 MDL 写锁，因此只能被阻塞 如果只有 session C 自己被阻塞还没啥，但是之后所有要在表 t 上新申请 MDL 读锁的请求也会被 session C 阻塞。前面说过，所有对表的增删改查操作都需要先申请 MDL 读锁，就都被锁住，等于这个表现在完全不可读写了 如果某个表上的查询语句频繁，而且客户端有重试机制，也就是说超时会再起一个新 session 再请求的话，这个库的线程很快就会爆满 现在应该清楚，事务中的 MDL 锁，在语句执行开始时申请，但是语句结束后并不会马上释放，而会等到整个事务提交后再释放 那么，如何安全地给小表加字段？ 首先我们要解决长事务，事务不提交，就会一直占着 MDL 锁。在 MySQL 的 information_schema 库的 innodb_trx 表中，你可以查到当前执行中的事务。如果你要做的 DDL 变更的表刚好有长事务在执行，要考虑先暂停 DDL，或者 kill 掉这个长事务 但考虑一个场景。如果你要变更的表是一个热点表，虽然数据量不大，但是上面的请求很频繁，而你不得不加个字段，要怎么处理？ 这时候 kill 可能未必管用，因为新的请求马上就来了。比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程 MariaDB 已经合并了 AliSQL 的这个功能，所以这两个开源项目分支目前都支持 DDL NOWAIT / WAIT n 这个语句 123ALTER TABLE tbl_name NOWAIT add column ...ALTER TABLE tbl_name WAIT N add column ... 小结全局锁主要用于在逻辑备份过程中。对于全部是 InnoDB 引擎的库，建议使用 single-transaction 参数，对应用会更好 表锁一般是在数据库引擎不支持行锁的时候才会被用到的。如果你发现你的应用程序你有 lock tables 这样的语句，你需要追查一下，比较可能的情况是： 要么是你的系统现在还在用 MyISAM 这类不支持事务的引擎，那需要升级换引擎 要么是你的引擎升级了，但是代码还没升级、 MDL 会直到事务提交才释放，在做表结构变更的时候， 你一定要小心不要导致锁住线上查询和更新]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之 order by 是怎么工作的]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F08%2FMySQL-%E4%B9%8B-order-by-%E6%98%AF%E6%80%8E%E4%B9%88%E5%B7%A5%E4%BD%9C%E7%9A%84%2F</url>
    <content type="text"><![CDATA[开发应用的时候，会遇到需要根据指定的字段排序来显示结果的需求。举个例子，假设有个表的定义是这样子的 123456789CREATE TABLE `t` ( `id` int(11) NOT NULL, `city` varchar(16) NOT NULL, `name` varchar(16) NOT NULL, `age` int(11) NOT NULL, `addr` varchar(128) DEFAULT NULL, PRIMARY KEY (`id`), KEY `city` (`city`)) ENGINE=InnoDB; 这时候你的 SQL 可以这么写： 1SELECT city, name, age FROM t where city = &apos;杭州&apos; ORDER BY name LIMIT 1000 这个语句很简单，但是你了解它的执行流程吗？ 全字段排序上面的 SQL 语句中，我们为了避免全表扫描，需要在 city 字段加上索引。在 city 字段上创建索引后，我们用 explain 命令看看看这个语句的执行情况 Extra 这个字段中的 Using filesort 表示的就是需要排序，MySQL 会给每个线程分配一块内存用于排序，成为 sort_buffer 为了说明这个 SQL 查询语句的执行过程，我们先来看一下 city 这个索引的示意图 从图中可以看到，满足 city = ‘杭州’ 条件的行，是从 ID_X 到 ID_(X + N) 的这些记录 通常情况下，这个过程执行流程如下： 初始化 sort_buffer，确定放入 name、city、age 这三个字段 从索引 city 找到第一个满足 city = ‘杭州’ 条件的主键 id，也就是图中的 ID_X 到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中 从索引 city 去下一个记录的主键 id 重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y 对 sort_buffer 中的数据按照字段name 做快速排序 按照排序结果取前 1000 行返回给客户端 我们暂且把这个排序过程，成为全字段排序，执行流程的示意图如下： 图中 「按 name 排序」这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size sort_buffer_size，就是 MySQL 为排序开辟的内存（sort_buffer）的大小。如果要排序的数据量小于 sort_buffer_size，排序就在内存中完成。但如果排序数据量太大，内存放不下，则不得不利用磁盘临时文件辅助排序 你可以用下面介绍的方法，来确定一个排序语句是否使用了临时文件 1234567891011121314151617/* 打开 optimizer_trace，只对本线程有效 */SET optimizer_trace=&apos;enabled=on&apos;;/* @a保存Innodb_rows_read的初始值 */select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name = &apos;Innodb_rows_read&apos;;/* 执行语句 */select city, name,age from t where city=&apos;杭州&apos; order by name limit 1000; /* 查看 OPTIMIZER_TRACE 输出 */SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`\G/* @b保存Innodb_rows_read的当前值 */select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name = &apos;Innodb_rows_read&apos;;/* 计算Innodb_rows_read差值 */select @b-@a; 这个方法是通过 OPTIMIZER_TRACE 的结果来确认的，可以从 number_of_tmp_files 中看到是否使用了临时文件 number_of_tmp_files 表示的是，排序过程中使用的临时文件数。为什么需要 12 个文件？内存放不下时，就需要使用外部排序，外部排序一般使用归并排序算法。可以这么简单理解，MySQL 将需要排序的数据分成 12 份，每一份单独排序后存在这些临时文件中。然后把这 12 个有序文件再合并成一个有序的大文件 如果 sort_buffer_size 超过了需要排序的数据量的大小，number_of_tmp_files 就是 0，表示排序可以直接在内存中完成。否则就需要放在临时文件中排序，sort_buffer_size 越小，需要分成的份数越多，number_of_tmp_files 的值就越大 我们示例表中有 4000 条满足 city = ‘杭州’ 的记录，所以你可以看到 examined_rows = 4000，表示参与排序的行数是 4000 行 sort_mode 里面的 packed_additional_fields 的意思是，排序过程对字符串做了「紧凑」处理。即使 name 字段的含义是 varcahr(16)，在排序过程中还是要按照实际长度来分配空间的 同时，最后一个查询语句 select @b - @a 的返回结果是 4000，表示整个执行过程只扫描了 4000 行 这里需要注意的是，为了避免对结论造成干扰，把 internal_tmp_disk_storage_engine 设置成 MyISAM，否则，select @b - @a 的结果会显示为 4001 这是因为查询 OPTIMIZER_TRACE 这个表时，需要用到临时表，而 interanl_tmp_disk_storage_engine 的默认值是 InnoDB。如果使用的是 InnoDB 引擎的话，把数据从临时表取出来的时候，会让 InnoDB_rows_read 的值加 1 rowid 排序上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差 所以如果单行很大，这个方法效率不够好 那么，如果 MySQL 认为排序的单行长度太大会怎么做呢？我们修改一个参数，让 MySQL 采用另外一种算法 1SET max_length_for_sort_data = 16 max_length_for_sort_data 是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法 city、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，我们在看看计算过程有什么改变 新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id 但这时，排序的结果就因为少了 city 和 age 字段的值，不能直接返回了，整个执行流程就变成如下： 初始化 sort_buffer，确定放入两个字段，即 name 和 id 从索引 city 找到另一个满足 city = ‘杭州’ 条件的主键 id，也就是图中的 ID_X 到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中 从索引 city 去下一个记录的主键 id 重复步骤 3、4 直到不满足 city = ‘杭州’ 条件为止，也就是图中的 ID_Y 对 sort_buffer 中数据按照字段 name 进行排序 遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端 这个执行流程的示意图如下，我们称为 rowid 排序 对比全字段排序流程图你会发现，rowid 排序多访问了一次表 t 的主键索引 需要说明的是，最后的「结果集」是一个逻辑概念，实际上 MySQL 服务端从排序后的 sort_buffer 中依次取出 id，然后到原表查到 city、name 和 age 这三个字段的结果，不需要再服务端再耗费内存存储结果，是直接返回给客户端的 根据这个说明过程和图示，你可以想一下，这个时候执行 select @b - @a，结果会是多少？ 首先，图中的 examined_rows 的值还是 4000，表示用于排序的数据是 4000 行。但是 select @b - @a 这个语句的值变成 5000 了 因为这时候除了排序过程外，在排序完成后，还要根据 id 去原表取值。由于语句是 limit 1000，因此会多读 1000 行 从 OPTIMIZER_TRACE 的结果中，你还能看到另外两个信息也变了 sort_mode 变成了 &lt;sort_key, rowid&gt;，表示参与排序的只有 name 和 id 这两个字段 number_of_tmp_files 变成 10 了，是因为这时候参与排序的行数虽然仍为 4000 行，但是每一行都变小了，因此需要排序的总数据量就变小了，需要的临时文件也相应地变小了 全字段排序 VS rowid 排序我们来分析一下，从这两个执行流程，还能得出什么结论 如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据 如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据 这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问 对于 InnoDB 表来说，rowid 排序会要求回表造成磁盘读，因此不会被优先选择 看到这，你就了解了，MySQL 做排序时一个成本比较高的操作。那么，是不是所有的 order by 都需要排序操作呢？如果不排序就能得到正确的结果，那对系统的消耗会小很多，语句的执行时间也会变得更短 其实，并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的 所以，如果能够保证从 city 这个索引上取出来的行，天然就是按照 name 递增排序的话，是不是就可以不用再排序了呢？ 确实是这样。所以，我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是： 1alter table t add index ciyt_user(city, name) 作为与索引 city 索引的对比，我们看看这个索引的示意图 在这个索引里，我们依然可以用树搜索的方式定位到第一个满足 city = ‘杭州’ 的记录，并且额外确保了，接下来按顺序取「下一条记录」的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的 这样整个查询过程的流程就变成了： 从索引 (city, name) 找打第一个满足 city = ‘杭州’ 条件的主键 id 到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回 从索引 (city, name) 取下一个记录主键 id 重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city = ‘杭州’ 条件时循环结束 可以看到，这个查询过程不需要临时表，也不需要排序。explain 的结果如下： 从图中可以看到，Extra 字段中没有 Using filesort 了，也就是不需要排序了。而且由于 (city, name) 这个联合索引本身有序，所以这个查询也不用把 4000 行全都读一遍，只要找到满足条件的前 1000 条记录就可以退出了。即，在我们这个例子里，只需要扫描 1000 次 到这里，这个语句的执行流程有没有可能进一步简化呢？我们可以利用覆盖索引。覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据 按照覆盖索引的概念，我们可以在优化一下这个查询语句的执行流程。我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是 1alter table t add index city_user_age(city, name, age) 此时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了： 从索引 (city, name, age) 找到第一个满足 city = ‘杭州’ 条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回 从索引 (city, name, age) 去下一个解读那，同样取出这三个字段的值，作为结果集一部分直接返回 重复执行步骤 2，知道查到第 1000 条记录，或者是不满足 city = ‘杭州’ 条件时循环结束 然后，我们来看看 explain 的结果 可以看到，Extra 字段里面多了「Using index」，表示的就是使用了覆盖索引，性能上会快很多 当然，这里并不是说要为了么个查询能用上覆盖索引，就要把语句中涉及的字段都建上联合索引，毕竟索引还是有维护代价的。这是一个需要权衡的决定]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 变慢的一些场景]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F05%2FSQL-%E5%8F%98%E6%85%A2%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[在 MySQL 中，有很多看上去逻辑相同，但性能确差异巨大的 SQL 语句。对这些语句使用不当的话，就会导致这个数据库的压力变大 条件字段函数操作假设你维护了一个交易系统，其中交易记录表 tradelog 包含交易流水号（tradeid）、交易员 id（opeartor）、交易时间（t_modified）等字段。为了方便描述，我们先忽略其他字段 123456789CREATE TABLE `tradelog` ( `id` int(11) NOT NULL, `tradeid` varchar(32) DEFAULT NULL, `operator` int(11) DEFAULT NULL, `t_modified` datetime DEFAULT NULL, PRIMARY KEY (`id`), KEY `tradeid` (`tradeid`), KEY `t_modified` (`t_modified`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4; 假设，现在已经记录了从 2016 年初到 2018 年底的所有数据，有一个需求时，要统计发生在所有年份中的交易记录总数。你的 SQL 语句可能会这么写： 1select count(*) from tradelog where month(t_modified) = 7 由于 t_modified 字段上有索引，于是你就很放心地在生产库中执行了这条语句，但却发现了执行了特别久才返回结果。网上可能说：如果对字段做了函数计算，就用不了索引了 为什么条件是 where t_modified = ‘2018-7-1’ 的时候可以用上索引，而改成 where month(t_modified) = 7 的时候就不行了？ 先看一下 t_modified 索引的示意图，方框上面的数字就是 month() 函数对应的值 如果你的 SQL 语句用的是 where t_modified = &#39;2018-7-1&#39; 的话，引擎就会按照上面的红色箭头的路线，快速定位到 t_modified = ‘2018-7-1’ 需要的结果 实际上，B+ 树提供的这个快速定位能力，来源于同一层兄弟节点的有序性 但是，如果计算 month() 函数的话，你会看到传入 7 的时候，在数的第一层就不知道该怎么办了。也就是说，对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃做数搜索功能 需要注意的是，优化器并不是要放弃使用这个索引 在这里例子里，放弃了树搜索功能，优化器可以选择遍历主键索引，也可以选择遍历索引 t_modified，优化器对比索引大小后，索引 t_modified 更小，遍历这个索引比遍历主键索引来得更快。因此还是最终选择索引 t_modified 我们使用 explain 命令，看一下这条 SQL 语句的执行结果 key = ‘t_modified’ 表示的是，使用了 t_modified 这个索引；我在测试表数据中插入了 10 万行数据，rows = 100335，说明这条语句扫描了整个索引的所有值；Extra 字段的 Using index，表示的是使用了覆盖索引 即，由于在 t_modified 字段加了 month() 函数操作，导致了全索引扫描。为了能够用上索引的快速定位能力，我们就要把 SQL 语句改成基于字段本身的范围查询。如下，优化器就能用上 t_modified 索引的快速定位能力了 1234select count(*) from tradelog where (t_modified &gt;= &apos;2016-7-1&apos; and t_modified&lt;&apos;2016-8-1&apos;) or (t_modified &gt;= &apos;2017-7-1&apos; and t_modified&lt;&apos;2017-8-1&apos;) or (t_modified &gt;= &apos;2018-7-1&apos; and t_modified&lt;&apos;2018-8-1&apos;); 到这我们就清楚了，由于加了 month() 函数操作，MySQL 无法再使用索引快速定位功能，而只能使用全索引扫描 不过优化器在这个问题上确实有「偷懒」行为，即使是对于不改变有序性的函数，也不会考虑使用索引。比如，对于 select * from tradelog where id + 1 = 10000 这个 SQL 语句，这个加 1 操作并不会改变有序性，但是 MySQL 优化器还是不能用 id 索引快速定位到 9999 这一行。所以，需要你在写 SQL 语句的时候，手动改写成 where id = 10000 - 1 才可以 隐式类型转换先看下面这条 SQL： 1select * from tradelog where tradeid = 110717 交易编号 tradeid 这个字段上，本来就有索引，但是 explain 的结果缺显示，这条语句需要全表扫描。我们发现，tradeid 的字段类型是 varchar(32)，而输入的参数却是整型，所以需要做类型转换 那么，这里就有两个问题： 数据类型转换的规则是什么？ 为什么有数据类型转换，就需要走全索引扫描 先看第一个问题，数据库里面类型那么多，这种数据类型转换规则更多，我记不住，怎么办？ 这里有一个简单的方法，看 select &#39;10&#39; &gt; 9 的结果： 如果规则是「将字符串转成数字」，那么就是做数字比较，结果应该是 1 如果规则是「将数字转成字符串」，那么就是做字符串比较，结果应该是 0 如下图： 从上图我们知道 MySQL 里的转换规则了：在 MySQL 中，字符串和数字作比较的话，是将字符串转换成数字 这时，再看看这个全表扫描的语句： 1select * from tradelog where tradeid = 110717 就知道对于优化器来说，这个语句相当于 1select * from tradelog where CAST(tradeid AS signed int) = 110717 即，这条语句触发了我们上面说到的规则：对索引字段做函数操作，优化器会放弃走树搜索功能 隐式字符编码转换假设系统你还有另外一个表 trade_detail，用于记录交易的操作细节。为了便于量化分析和复现，我往交易日志表 tradelog 和交易详情表 trade_detail 这两个表里插入一些数据 123456789101112131415161718192021222324CREATE TABLE `trade_detail` ( `id` int(11) NOT NULL, `tradeid` varchar(32) DEFAULT NULL, `trade_step` int(11) DEFAULT NULL, /*操作步骤*/ `step_info` varchar(32) DEFAULT NULL, /*步骤信息*/ PRIMARY KEY (`id`), KEY `tradeid` (`tradeid`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into tradelog values(1, &apos;aaaaaaaa&apos;, 1000, now());insert into tradelog values(2, &apos;aaaaaaab&apos;, 1000, now());insert into tradelog values(3, &apos;aaaaaaac&apos;, 1000, now());insert into trade_detail values(1, &apos;aaaaaaaa&apos;, 1, &apos;add&apos;);insert into trade_detail values(2, &apos;aaaaaaaa&apos;, 2, &apos;update&apos;);insert into trade_detail values(3, &apos;aaaaaaaa&apos;, 3, &apos;commit&apos;);insert into trade_detail values(4, &apos;aaaaaaab&apos;, 1, &apos;add&apos;);insert into trade_detail values(5, &apos;aaaaaaab&apos;, 2, &apos;update&apos;);insert into trade_detail values(6, &apos;aaaaaaab&apos;, 3, &apos;update again&apos;);insert into trade_detail values(7, &apos;aaaaaaab&apos;, 4, &apos;commit&apos;);insert into trade_detail values(8, &apos;aaaaaaac&apos;, 1, &apos;add&apos;);insert into trade_detail values(9, &apos;aaaaaaac&apos;, 2, &apos;update&apos;);insert into trade_detail values(10, &apos;aaaaaaac&apos;, 3, &apos;update again&apos;);insert into trade_detail values(11, &apos;aaaaaaac&apos;, 4, &apos;commit&apos;); 这时候，如果要查询 id = 2 的交易的所有操作步骤信息，SQL 语句可以这么写： 1select d.* from tradelog l,trade_detail d where d.tradeid = l.tradelog and l.id = 2 我们一起来看下这个结果： 第一行显示优化器会现在交易记录表 tradelog 上查到 id = 2 的行，这个步骤用上了主键索引。rows = 1 表示只扫描一行 第二行 key = NULL，表示没有用上交易详情表 trade_detail 上的 tradeid 索引，进行了全表扫描 着这个执行计划里，是从 tradelog 表中取 tradeid 字段，再去 trade_detail 表里查询匹配字段。因此，我们把 tradelog 称为驱动表，把 trade_detail 称为被驱动表，把 tradeid 成为关联字段 explain 结果的执行流程如下： . 图中： 第 1 步，是根据 id 在 tradelog 表里找到 L2 这一行 第 2 步，是从 L2 中取出 tradeid 字段的值 第 3 步，是根据 tradeid 值到 trade_detail 表中查找条件匹配的行。explain 的结果里面第二行的 key = NULL 表示的是，这个过程是通过遍历主键索引的方式，一个一个地判断 tradeid 的值是否匹配 到这里，你会发现第 3 步不符合我们的预期。因为表 trade_detail 你 tradeid 字段是有索引的，我们本来是希望通过 tradeid 索引能够快速定位到等值的行。但，这里并没有 这里直接告诉你答案，因为这个表的字符集不同，一个是 UTF8，一个是 utf8mb4，所以做表连接查询的时候用不上关联字段的索引。 但，为什么字符集不同就用不上索引呢？ 我们说问题是出在执行步骤的第 3 步，如果单独把这一步改成 SQL 语句的话，那就是： 1select * from trade_detail where tradeid = $L2.tradeid.value 其中，$L2.tradeid.value 的字符集是 utf8mb4 参照前面的而两个例子，你肯定就想到，字符集 utf8mb4 是 utf8 的超集，所以当这两个类型的字符串在做比较的时候，MySQL 内部操作是，先把 utf8 字符串转成 utf8mb4 字符集，再做比较 这个设定很好理解，utf8mb4 是 utf8 的超集。类似地，在程序设计语言里面，做自动类型转换的时候，为了避免数据在转换过程中由于截断导致数据错误，也都是「按数据长度增加的方向进行转换的」 因此，在执行上面这个语句的时候，需要将被驱动数据表里的字段一个个地转换成 utf8mb4，再跟 L2 做比较。即，实际上这个语句等同下面的写法： 1select * from trade_detail where CONVERT(tradeid USING utf8mb4) = $L2.tradeid.value 这就触发了我们上面说到的原则：对索引字段做函数操作，优化器会放弃走索引的功能 这里我们明确了，字符集不同只是条件之一，连接过程中要求在被驱动表的索引字段加上函数操作，是直接导致对被驱动表做全表扫描的原因 作为对比验证，我们「查找 trade_detail 表里 id = 4 的操作，对应的操作者是谁」，再来看下这个语句和它的执行计划 1SELECT l.operator FROM tradelog l,trade_detail d WHERE d.tradeid = l.tradeid AND d.id = 4 这个语句里 trade_detail 表成了驱动表，但是 explain 结果的第二行显示，这次的查询操作用上了被驱动表 tradelog 里的索引 (tradeid)，扫描行数是 1 这也是两个 tradeid 字段的 join 操作，为什么这次能用上被驱动表的 tradeid 索引呢？ 假设驱动表 trade_detail 里 id = 4 的行记为 R4，那么在连接的时候（上面执行流程图的第 3 步），被驱动表 tradelog 上执行的就是类似这样的 SQL 语句 1SELECT operator FROM tradelog WHERE tradeid = $R4.tradeid.value 这时候 $R4.tradeid.value 的字符集是 utf8，按照字符集转换规则，要转成 utf8mb4，所以这个过程就被改写成： 1SELECT operator FROM tradelog WHERE tradeid = CONVERT(R4.tradeid.value USING utf8mb4) 你看，这里的 CONVERT 函数是加在输入参数上的，这样就可以用上被驱动表的 tradeid 索引 理解了原理，就可以用来指导操作了。如果要优化语句 1SELECT d.* FROM tradelog l, trade_detail d WEHRE d.tradeid = l.tradeid AND l.id = 2 的执行过程，有两种做法： 1、比较常见的优化方法是，把 trade_detail 表上的 tradeid 字段的字符集也改成 utf8mb4，这样就没有字符集转换的问题了 1alter table trade_detail modify tradeid varchar(32) CHARACTER SET utf8mb4 default null 2、如果能够修改字段的字符集的话，是最好不过的。但如果数据量比较大，或者业务上暂时不能做这个 DDL 的话，那就只能采用修改 SQL 语句的方法了 1SELECT d.* FROM tradelog l, trade_detail d WHERE d.tradeid = CONVERT(l.tradeid USING utf8) AND l.id = 2 这里，主动把 l.tradeid 转成 utf8，就避免了被驱动表上的字符编码转换，从 explain 结果可以看到，这次索引走对了 小结上面举的三个例子，其实是在说同一件事儿，即：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之 count(*)]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F04%2FMySQL-%E4%B9%8B-count%2F</url>
    <content type="text"><![CDATA[Count(*) 的实现方式首先，在不同的 MySQL 引擎中，count(*) 有不同的实现方式 MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高 而 InnoDB 引擎，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数 注意，我们讨论的是没有过滤条件的 count(*)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的 那为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？ 因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表「应该返回多少行」也是不确定的。这里，用一个算 count(*) 的例子解释一下 假设表 t 中现在有 10000 条数据，我们设计了三个用户并行的会话 会话 A 先启动事务并查询一次表的总行数 会话 B 启动事务，插入一行后记录后，查询表的总行数 会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数 假设从上到下是按照时间顺序执行的，同一行语句是在同一时刻执行的 你会发现，在最后一个时刻，三个会话 A B C 会同时查询表 t 的总行数，但拿到的结果却不同 这个 InnoDB 的事务设计有关系，可重复读是它默认的隔离级别，在代码上就是通过多版本并发控制，即 MVCC 来实现的。每一行记录都要判断自己是否对这个会话可见，因此对 count(*) 请求来说，InnoDB 只好把数据一行一行地读出依次判断，可见的行才能够用于计算「基于这个查询」的表的总行数 当然，MySQL 在执行 count(*) 操作的时候还是做了优化的 InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count() 这样的操作，遍历那颗索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。*在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一** 不同的 count 用法在 select count(?) from t 这样的查询语句里面，count(*)、count(主键 id)、count(字段) 和 count(1) 等不同用法的性能，有哪些差别？我们基于 InnoDB 引擎讨论一下 首先要弄清楚 count() 的语义，count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值 所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段) 则表示返回满足条件的数据行你，参数「字段」不为 NULL 的总个数 至于分析性能差别的时候，可以记住这么几个原则： server 层要什么就给什么 InnoDB 只给必要的值 现在的优化器值优化了 count(*) 的语义为 「取行数」，其他显而易见的优化并没有做 这是什么意思呢？ 对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加 对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字 「1」进去，判断是不可能为空的，按行累加 单看这两个用法的差别的话，能对比出来，count(1) 执行得要比 count(主键 id) 块，因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作 对于 count(字段) 来说： 如果这个「字段」是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加 如果这个「字段」定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加 也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段 但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。 count(*) 肯定不是 null，按行累加 所以结论是：按照效率排序的话，count(字段) &lt; count(主键 id) &lt; count(1) ≈ count(*)]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之普通索引和唯一索引]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F02%2FMySQL-%E4%B9%8B%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[假设你在维护一个市民系统，每个人都有一个唯一的身份证号，而且业务代码已经保证不会写入两个重复的身份证号。如果市民系统需要按照身份证号查姓名，就会执行类似下面的语句： 1select name from CUser where id_card = &apos;xxxxyyyzzz&apos; 所以，一般都要在 id_card 字段上建索引 由于身份证号字段比较大，所以不建议把身份证号当做主键。那么现在有两个选择，要么给 id_card 字段创建一个唯一索引，要么创建一个普通索引。如果业务代码已经保证了不会写入重复的身份证号，那么这两个选择逻辑上都是正确的 那么，从性能的角度考虑，你选择唯一索引还是普通索引？选择的依据是什么呢？ 举个例子，假设我们有一个主键为 ID 的表，表中有字段 k，并且在 k 上有索引。表的建表语句是： 12345create table T(id int primary key,k int not null,name varchar(16),index (k)) engine = InnoDB; 表中 R1 ~ R5 的 (ID, k) 值分别为 (100, 1)、(200, 2)、(300, 3)、(500, 5) 和 (600, 6)，两棵树的示例示意图如下： 接着，我们就从这两种索引对查询语句和更新语句的性能影响来进行分析 查询过程假设，执行查询的语句是 select id from T where k = 5。这个查询语句在索引树上查找的过程，先是通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页，然后可以认为数据页内部通过二分法来定位记录 对于普通索引来说，查找到满足条件的第一个记录 (5, 500) 后，需要查找下一个记录，知道碰到第一个不满足 k = 5 条件的记录 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索 那么，这个不同带来的性能差距会有多少呢？答案是，微乎其微 其实，InnoDB 的数据是按数据页为单位来读写的。即，当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB 因为引擎是按页读写的，所以，当找到 k = 5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次「查找和判断下一条记录」的操作，就只需要一次指针寻找和一次计算 当然，如果 k = 5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些 但是，我们之前计算过，对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，我们计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计 更新过程为了说明普通索引和唯一索引对更新语句性能的影响，需要先介绍一下 change buffer 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这个更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性 另外，虽然名字叫 change buffer，实际上它是可以持久化的数据。即，change buffer 在内存中有拷贝，也会被写入到磁盘中 将 change buffer 中的操作应用到原数据页，得到最新结果的过程成为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭的过程中，也会执行 merge 操作 显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能避免占用内存，提高内存利用率 那么，什么条件下可以使用 change buffer 呢？ 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4, 400) 这个记录，就要先判断现在表中是否已经存在 k = 4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了 因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用 change buffer 用的是 buffer pool 里的内存，因此不能无线增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50% 理解了 change buffer 的机制，我们看看如果要在这张表中插入一个新纪录 (4, 400) 的话，InnoDB 的处理流程是怎样的 第一种情况是，这个记录要更新的目录页在内存中。这时，InnoDB 的处理流程如下： 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束 这样看来，普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间 第二种情况是，这个记录更新的目标页不在内存中。这是，InnoDB 的处理流程如下： 对于唯一索引，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束 对于普通索引，则是将更新记录在 change buffer，语句执行就结束了 将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的 例如，负责的某个业务的库内存命中率突然从 99% 降低到了 75%，整个系统处于阻塞状态，更新语句全部堵住。而探究其原因后，发现这个业务有大量插入数据的操作，而他在前一天把其中的某个普通索引改成了唯一索引 change buffer 的使用场景现在，我们知道了使用 change buffer 对更新过程的加速作用，也清楚了 change buffer 只限于用在普通索引的场景下，而不适用于唯一索引。那么，现在一个问题是：普通索引的所有场景，使用 change buffer 都可以起到加速作用吗 因为 merge 的时候是真正进行数据更新的时候，而 change buffer 的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge 之前，change buffer 记录的变更越多（也就是这个页面上要更新的次数越多），收益就越大 因此，对于写多读少的业务来说，页面在写完以后马上被访问的概率比较小，此时 change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统 反过来，假设一个业务的更新模式是写入之后马上做查询，那么即使满足了条件，将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 merge 过程。这样随机访问 IO 的次数不会减少，反而增加了 change buffer 的维护代价。所以，对于这种模式来说，change buffer 反而起到了副作用 索引选择和实践那么，普通索引和唯一索引应该怎么选择？其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，建议尽量选择普通索引 如果所有的更新后面，都马上伴随着对这个记录的查询，那么你应该关闭 change buffer。而其他情况，change buffer 都能提升更新性能 在实际使用中，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的 change buffer 和 redo log假设我们要在表上执行这个插入语句 1insert into t(id, k) values(id1, k1), (id2, k2) 这里，我们假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存（InnoDB buffer pool）中，k2 所在的数据页不在内存中，如下： 分析这条更新语句，你会发现它涉及了四个部分：内存、redo log（ib_log_fileX）、数据表空间（t.ibd）、系统空间（ibdata1） 这条更新语句做了如下的操作（按照图中的数字顺序）： Page 1 在内存中，直接更新内存 Page 2 没有在内存中，就在内存的 change buffer 区域，记录下「我要往 Page 2 插入一行」这个信息 将上述两个动作记入 redo log 中（图中 3 和 4） 做完上面这些，事务就可以完成了。所以，你会看到，执行这条更新语句的成本很低，就是写了两条内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的 同时，图中的两个虚线箭头，是后台操作，不影响更新的响应时间 那在之后的读请求，要怎么处理呢？ 比如，我们现在要执行 select * from t where k in (k1, k2) 如果读语句发生在更新语句后不久，内存中的数据都还在，那么此时的两个读操作就与系统表空间（ibdata1）和 redo log（ib_log_fileX）无关了，所以，下图中没画出这两部分 从图中可以看到： 读 Page1 的时候，直接从内存返回。WAL 之后如果要读数据，是不是一定要读盘，是不是一定要从 redo log 里面把数据更新以后才可以返回？其实是不用的。如上图，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的 要读 Page2 的时候，需要把 Page2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果 可以看到，直到需要读 Page2 的时候，这个数据页才会被读入内存 所以，如果要简单地对比两个机制在提升更新性能上的收益的话，redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的是随机读磁盘的 IO 消耗]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 更新语句是如何执行的]]></title>
    <url>%2FCKING.github.io%2F2021%2F11%2F01%2FSQL-%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84%2F</url>
    <content type="text"><![CDATA[MySQL 可以恢复到半个月内任何一秒的状态，这是怎么做到的？ 我们从一个表的一条更新语句说起，下面是这个表的创建语句，这个表有一个主键 ID 和一个整型字段 c 1create table T(ID int primary key, c int); 如果要将 ID = 2 这一行的值加 1，SQL 语句就会这么写： 1update T set c = c + 1 where ID = 2; 我们看一下 SQL 语句的基本的执行路径。可以确定的说，查询语句和更新语句都会走一遍下面的路径 你执行语句要先连接数据库，这是连接器的工作 在一个表上有更新的时候，跟这个表有关的查询缓存会失效，所以这条语句就会把表 T 上所有缓存都清空。这也是我们一般不建议使用查询缓存的原因 接着，分析器会通过词法和语法解析知道这是一条更新语句。优化器决定要使用 ID 这个索引。然后，执行器负责具体执行，找到这一行，然后更新 与查询流程不一样的是，更新流程还涉及两个重要的日志模块：redo log（重做日志）和 binlog（归档日志）。 重要的日志模块：redo log说一个场景，酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本 如果有人要赊账或者还账的话，掌柜一般有两种做法： 一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉 另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算 在生意红火柜台很忙时，掌柜一定会选择后者，因为前者操作实在是太麻烦了。首先，你得找到这个人的赊账总额那条记录。密密麻麻几十页，掌柜要找到那个名字，可能还得带上老花镜慢慢找，找到之后再拿出算盘计算，最后将结果写回到账本上 这整个过程想想都麻烦。相比之下，还是现在粉板上记一下方便。试想一下，如果掌柜没有粉板的帮助，每次记账都得翻账本，效率是不是低得让人难以忍受？ 同样，在 MySQL 你也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了类似掌柜粉板的思路来提升更新效率 而粉板的账本配合的整个过程，其实就是 MySQL 你经常说到的 WAL 技术。WAL 的全程是 Write-Ahead Logging，它的关键点就是写日志，再写磁盘，也就是先写粉板，等不忙的时候再写账本 具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做，这就像打烊以后掌柜做的事 InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块「粉板」总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下： write_pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件 write_pos 和 checkpoint 之间的「粉板」上还空着的部分，可以用来记录新的操作。如果 write_pos 追上 checkpoint，表示「粉板」满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力成为 crash-safe 要理解 crash-safe 这个概念，可以想想我们前面赊账记录的例子。只要赊账记录记在粉板上或者写在账本上，之后即使掌柜忘了，比如突然停业几天，恢复生意后依然可以通过账本和粉板上的数据明确赊账账目 重要的日志模块：binlogMySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的粉板 redo log 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，成为 binlog（归档日志） 为什么会有两份日志？ 因为最开始 MySQL 里并没有 InnoDB 引擎。MySQL 自带的引擎是 MyISAM，但是 MyISAM 没有 crash-safe 的能力，binlog 日志只能用于归档。而 InnoDB 是另一个公司以插件形式引入 MySQL 的，既然只依靠 binlog 是没有 crash-safe 能力的，所以 InnoDB 使用另外一套日志系统 — 也就是 redo log 来实现 crash-safe 能力 这两种日志有以下三点不同： redo log 是 InnoDB 引擎持有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用 redo log 是物理日志，记录的是「在某个数据页上做了什么修改」；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如「给 ID = 2 这一行的 c 字段加 1」 redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。「追加写」是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志 有了对这两个日志的概念性理解，我们再来看执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程 执行器先找引擎取 ID = 2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID = 2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N + 1，得到新的一行数据，再调用引擎接口写入这行新数据 引擎将这行数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务 执行器生成这个操作的 binlog，并把 binlog 写入磁盘 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成 这里给出这个 update 语句的执行流程图，图中绿色框表示是在 InnoDB 内部执行的，蓝色框表示是在执行器中执行的 最后三步看上去有点绕，将 redo log 的写入拆成了两个步骤：prepare 和 commint，这就是「两阶段提交」 两阶段提交为什么要有两阶段提交？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：怎样让数据库恢复到半个月内任意一秒的状态？ 上面说过，binlog 会记录所有的逻辑操作，并且是采用「追加写」的形式。如果你的 DBA 承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有 binlog，同时系统会定期做整库备份。这里的「定期」取决于系统的重要性，可以是一天一备，也可以是一周一备 当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做： 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库 然后，从备份的时间点开始，将备份的 binlog 依次取出来，重放到中午误删表之前的那个时刻 这样你的临时表就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去 说完了数据恢复过程，我们再看看，为什么日志需要「两阶段」提交。这里不妨用反证法来进行解释 由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者采用反过来的顺序，看看这两种方式会有什么问题： 仍然用 update 语句来做例子。假设当前 ID = 2 的行，字段 c 的值是 0，再假设执行 update 语句过程中再写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况？ 先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1 但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句 然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同 先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了「把 c 从 0 改成 1」这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同 可以看到，如果不使用「两阶段提交」，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。 你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？ 其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个「不一致」就会导致你的线上出现主从数据库不一致的情况。 简单说，redo log 和 binlog 都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Synchronized 锁升级优化的全流程]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F30%2FSynchronized-%E9%94%81%E5%8D%87%E7%BA%A7%E4%BC%98%E5%8C%96%E7%9A%84%E5%85%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[本文主要谈一下 Synchronized 锁的各种优化：包括偏向锁、轻量级锁、重量级锁，以及它们之间是如何获取和释放锁、锁之间是如何进行升级和膨胀的 偏向锁从 JDK 1.6 开始，JVM 对比较重的 Synchronized 就引入了各种锁优化的机制，偏向锁算是最轻的一种锁，应用的场景也是最简单的，即偏向锁是专门为了优化线程多次获取同一把锁的场景量身打造的 比如说方式 A 是被 Synchronized 修饰的，线程 1 可能会多次调用方法 A，这样每次都要加锁和释放锁，而获取锁和释放锁是切切实实伴随着性能的损耗的 因为我们现在已经知道当前场景，即一个线程多次来获取一把锁，能不能说第一次获取锁成功之后，后面要是同一个线程再来获取锁时，就可以快点获取锁。根据这个想法，偏向锁机制被提出来了 偏向锁的获取Synchronized 加锁时，肯定是要加锁的，对谁加锁呢？ 访问 Synchronized 修饰的实例方法，锁对象就是方法对应的实例对象 访问 Synchronized 修饰的静态方法，锁对象就是方法所在的类，即类的字节码对象 访问 Synchronized 代码块，那锁对象就是 Synchronized 当前指定的对象 而偏向锁的具体实现细节，得要从锁对象的结构中进一步寻找答案 首先锁对象包含对象头以及其他的一些成员变量，包括成员变量、实例方法等，重点我们关注对象头 对象头里面包含的内容比较多，比如 Mark Work、ClassMetadata Address（就是当前锁对象的类在方法区中的地址）等，如下图： 而偏向锁实现的关键主要依附于 Mark Word 来实现：Mark Word 中有一个标志位用来记录当前锁的状态，比如当前是无锁状态还是偏向锁状态呢？ 另外当一个线程获取锁成功后，Mark Word 中还有一个指向那个获取锁成功的线程指针；一开始获取锁的线程的指针当然为空，并且锁的状态为无锁状态，如下图： 此时线程 1 过来获取 Synchronized 锁，线程 1 先看下锁的状态，如果为无锁状态，就直接将偏向锁的线程指针 CAS 改为指向线程 1，然后将锁标记 CAS 为偏向锁标记，标志这线程 1 获取偏向锁成功，如下所示： 如果说线程 1 以后再要对同一个 Synchronized 加锁，此时就到锁对象头中的 Mark Word 中看一下，发现当前已经是偏向锁标记了，并且当前偏向锁线程指针也是指向自己，此时就可以几乎零性能损耗获取锁成功了。如下： 现在应该能感受到偏向锁的好处了吧。偏向锁，偏的是同一个线程，一个线程只在第一次获取锁时，需要 CAS 修改下锁的的标记以及线程指针，耗费一点性能，而往后的重复加锁都是以极低的代价直接获取锁成功的 竞争释放偏向锁偏向锁的使用场景我们提到过一点，它是适合线程多次获取同一把锁而做的优化措施，适用于竞争不是很激烈的场景，一旦多线程竞争激烈了，此时就会导致偏向锁的释放和锁的升级 此时，如果线程 2 也过来对同一个 Synchronized 加锁会怎样？那就要看下之前的线程 1 是否还存活： 如果线程 1 已经执行结束了，那么此时线程 2 过来一看锁标记依然为偏向锁，但是线程指针指向的线程 1 已经没了，此时就将偏向锁的指针指向线程 2，线程 2 获取偏向锁成功，偏向锁后续就偏向线程 2 了 如果当前锁标记为偏向锁，并且当前线程 1 依然是存活的，此时线程 2 过来要对同一个 Synchronized 获取锁，此时就构成竞争，也就不符合偏向锁的适用的场景了。此时就会释放线程 1 获取的偏向锁，并且就锁标记 CAS 改为轻量级锁 从这里我们可以感受到，偏向锁的使用场景并不是很狭义的只有一个线程工作的场景，而不是竞争非常小，小道不足以发生竞争，这样对单个线程的多次获取同一个锁优化效率就可以充分发挥出来了 此时释放偏向锁的场景如下图所示： 轻量级锁轻量级锁的获取前面我们分析到线程 2 过来加锁时，和线程 1 产生冲突，线程 1 的偏向锁释放并被迫升级为了轻量级锁，那此时线程 1 和线程 2 都没有获取到锁，线程 1 和线程 2 都会同时 CAS 去获取轻量级锁 偏向锁的加锁机制为修改 Mark Word 中锁标记位为偏向锁，并且线程指针指向当前线程，那么轻量级锁的加锁机制是怎样的呢？我们继续看下 比如现在是线程 2 过来加锁，此时就会在线程 2 对应栈帧中开辟一块所记录的内存空间，然后将锁对象中的 Mark Word 复制一份到栈帧的锁记录中，并且将锁对象中的线程指针指向栈帧中的锁记录空间，这样轻量级锁算是加成功了。如下： 轻量级锁释放锁当线程 2 的轻量级锁释放时，此时就会逆向操作，将线程 2 栈帧锁记录中的 Mark Word CAS 替换回锁对象中的 Mark Word，如果替换成功，就表示释放轻量级锁成功 到这里我们发现，之所以轻量级锁比偏向锁稍微重那么一点，就是下你比较于偏向锁而言，轻量级锁每次都要先加锁，然后还需要再释放锁。不想偏向锁，只要不产生竞争，那么第一次加锁一次即可，后续再次获取锁的性能耗费极低，并且也不需要释放锁，自然也就不用承担释放锁性能损耗了 重量级锁什么时候会膨胀为重量级锁情况 1：其他线程 CAS 自旋失败导致膨胀为重量级锁假设线程 2 还没有释放轻量级锁，此时线程 3 过来加锁，线程 3 和线程 2 一样，先把 Mark Word 复制一份到自己线程栈帧中的锁记录空间，然后在修改锁记录的指针时，因为锁记录的指针已经指向了线程 2，所以此时线程 3 的 CAS 修改锁记录指针就会失败 此时线程 3 的 CAS 操作失败并不会像偏向锁一样直接导致锁升级，而是会先 CAS 自旋一会，如果自旋获取锁失败的次数过多，此时才会升级为重量级锁 情况 2：三个线程竞争导致直接膨胀为重量级锁假设此时也是线程 2 获取了轻量级锁，线程 3 过来 CAS 加锁，修改锁记录指针时失败了，然后线程 3 正在自旋获取锁，这时正好线程 4 也来获取锁了，此时 JVM 会毫不犹豫地将锁膨胀为重量级锁 毕竟线程 3 在那自旋时，要是线程 2 能快点释放锁，那么线程 3 还是有机会在最大允许自旋次数内获取到轻量级锁的，这下倒好，线程 4 直接掺和进来，JVM 会认为现在线程 3 获取锁的希望不大，竞争太激烈了，所以就直接膨胀为重量级锁了 以下两种膨胀情况如下所示： 重量级锁的获取现在由于锁膨胀为重量级锁，原本的锁记录的指针将会变为指向重量级锁 Monitor 对象的指针了，并且当前所有没获取到锁的线程优先进入到 Monitor 对象中 entrylist 中获取等待锁，如下： 然后多线程依次去获取锁，比如现在线程 3 开始获取锁，此时底层会执行 monitorenter 指令，然后在 Object Monitor 中锁的计数器加 1，并且记录当前持有锁的线程为线程 3，后面如果线程 3 再次过来加锁时发现当前持有锁的线程正是线程 3，直接将计数器加 1，表示又重入了一次锁，如下： 重量级锁的释放重量级锁的释放比较简单，直接递减加锁次数 count： 递减后如果 count 为 0，表示当前线程该释放的都释放完了，此时直接将线程指针 owner 置空，释放锁完毕 如果递减后 count 还不为 0，那就表示线程之前对这个锁重入过好几次，那还得线程再次执行释放锁操作，直到 count 为 0 才算释放彻底了，才能将线程指针置空 JIT 编译器的优化Java 代码编译生成 class 字节码文件是静态编译过程，那么 class 字节码文件编译成计算机能执行的机器指令，这个阶段就包含了 JIT 编译 Synchronized 加锁时，除了对不同竞争程度做的各种锁优化之外，在最开始的 JIT 编译阶段也会 Synchronized 也做了一定程度的优化 锁消除优化点之一就是锁消除，锁消除顾名思义就是不要你加的锁，把你加的 Synchronized 锁删除掉，免得加锁还要浪费性能，那什么场景下要锁消除呢？、 一般是在不需要加 Synchronized 锁的地方加锁。比如一个方法内，涉及到的变量都是局部变量，并且要是根据逃逸分析技术分析，发现完全没有将当前线程资源暴露给其他线程看见的可能，既然其他线程没有任何看见当前线程的资源，也就不会出现并发的问题，既然没有并发的问题，那你还莫名加个锁岂不是浪费性能了 所以 JIT 底层默默为该现象把了倒关，即锁消除的优化，要是在没有多线程并发冲突的地方还加 Synchronized 锁，底层就不会执行 monitorenter 和 monitorexit 相关的指定了 锁粗化我们知道 Synchronized 锁比较重，也是比较消费性能的。比如有个场景，你在一个方法内，对同一个对象加了多次 Synchronized 锁，此时可能就对应有多个 Synchronized 代码块。正常我们看到这种情况，都会优化成：将多个 Synchronized 代码块合并在一个 Synchronized 代码块中，否则你就要先加锁在释放锁，重复多次这种耗费性能的操作 确实 JIT 编译时也是这样设计的，底层不会多次执行 monitorenter 和 monitorexit 指令，如果发现居然是对同一个对象多次加 Synchronized 锁，底层将会把他们合并成一个 Synchronized 代码块，然后只会执行一次 monitorenter 和 monitorexit，达到了优化的目的，底层这里又对代码的性能把了道关 现在我们可以知道，锁粗化，顾名思义就是多个 Synchronized 代码块在底层 JIT 编译时合并成一个，好似一个锁变粗了一样，尽可能地避免了不必要的。多次加锁和释放锁带来的性能损耗 自适应加锁我们前面看到了，在前面多个线程获取锁的时候，如果获取锁失败，都会自旋一会，然后再去尝试获取锁，也就是自旋加锁 其实这个做法已经比较先进了，相比于一旦获取锁失败就阻塞，然后线程上下文切换执行其他线程而言，确实已经很好了，毕竟线程上下文切换时很耗费性能的，如果说你能够自旋一会，等到其他线程释放锁之后就能获取到锁，虽然自旋一会耗费了点 CPU，但是相比于线程上下文切换的代价，自旋一会就可以获取到锁还是更好的 但是问题来了，要是当前的环境竞争非常激烈，我一直自旋都获取锁失败，可能都超过了线程上下文切换带来的性能损耗，那自旋获取锁岂不是性能更差？面对这个问题，提出了自适应加锁的概念 即根据最近几次线程自旋获取锁成功的概率，来决定当前线程是自旋一会来获取锁，还是直接阻塞切换线程上下文让其他线程执行 如果最近一段时间线程竞争程度比较激烈，那就不适合一直自旋等待；如果最近几次线程竞争很小，自旋获取锁的成功率比较高，那可以自旋等待一会来获取锁，通过这样比较智能的自适应过程，来权衡自旋加锁和线程上下文切换带来的性能损耗 题目剖析偏向锁的加锁流程能简单说下吗？一般适用于什么场景？偏向锁加锁时，首先会在 Synchronized 对应锁对象的对象头中的 Work Mark 中，先看一下锁的标记： 如果是无锁状态，CAS 修改为偏向锁标记，然后将 Mark Word 中的线程指针指向当前线程，表示当前线程已经获取到了一个偏向锁；那么后续该线程再来加锁时，发现自己已经获取偏向锁了，那么此时几乎零成本获取偏向锁成功 如果已经是偏向锁状态，那就看下当前的 Mark Word 中，线程指针指向的线程是不是自己，如果是自己，当然直接获取偏向锁成功了如果指针指向的线程不是当前线程，但恰好该指向的线程已经结束了，那么直接将 Mark Word 中，线程指针指向当前线程自己，表示现在改为偏向当前新来的线程了 从偏向锁的加锁流程我们可以看到，偏向锁只适合于竞争不激烈的场景，主要是优化同一个线程多次获取同一个锁的性能，如果说线程 1 已经获取偏向锁成功，并且在线程 1 还没有结束时，紧接着线程 2 又过来获取锁，这下一看锁标记为偏向锁，还被线程 1 持有，那就直接发生竞争了 轻量级锁时如何加锁的？为什么说轻量级锁会比偏向锁更重一点呢？首先线程会在自己线程的栈帧中创建一个锁记录空间，然后将 Mark Word 复制一份到这个锁记录空间中，然后将锁对象中的 Mark Word 指向这个锁记录空间，轻量级锁就算获取成功了 因为轻量级锁相比较于偏向锁而言，每次加锁使用完毕后都需要释放锁，也就是说每次都需要老老实实地执行加锁和释放锁。而偏向锁只有在线程第一次过来加锁时，]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 事务失效情况]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F26%2FSpring-%E4%BA%8B%E5%8A%A1%E5%A4%B1%E6%95%88%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[没有被 Spring 管理没有被 Spring 管理的 Bean，如果其中出现了方法需要进行事务处理的情况，此时的事务不会执行。如下，在 OrderServiceImpl 类中如果将 @Service 注释掉，那么此类对应的 bean 也就不会被 Spring IOC 容器管理。即使 updateOrder 上面注释了 @Transactional，这个方法也不会执行事务 12345678//@Servicepublic class OrderServiceImpl &#123; @Transactional public void updateOrder(Order order) &#123; // update order &#125;&#125; 方法不是 public@Transactional 只能用于 public 方法上，否则事务会失效。如果要用在非 public 方法上，可以开启 AspectJ 代理模式。如下，saveAll 方法上面标注了 @Transactional 的注释，由于 saveAll 方法没有标注 public，因此 saveAll 的内容是不会执行事务的 12345678910@Servicepublic class DemoServiceImpl implements DemoService&#123; @Transactional(rollbackFor = Exception.class) @Override int saveAll() &#123; // do something return 1; &#125;&#125; 自身调用问题当一个服务存在多个方法，都标注了事务 @Transactional，当其中一个方法调用另外一个方法的时候，被调用方法中的事务是不会执行的。 如下，在 ServiceA 中存在 doSomething 有 @Transactional 的标注，在方法体内会调用 insert 方法，insert 方法上面也有 @Transactional 的标注。此时 doSomething 中的事务可以执行，但是 insert 方法的事务就无法执行 12345678910111213141516@Servicepublic class ServiceA &#123; @Transactional public void doSomething() &#123; insert(); // 调用其他系统 &#125; @Transactional(propagation = Propagation.REQUIRES_NEW) public void insert() &#123; // 向数据库中添加数据 &#125;&#125; 为了解决这个问题，可以将 insert 方法放到另外一个类中进行调用，如下，将 doSomething 和 insert 方法分别放到 ServiceA 和 ServiceB 两个类中，然后再通过 doSomething 调用 insert。此时两个方法中的事务都会执行 1234567891011121314151617181920212223@Servicepublic class ServiceA &#123; @Autowired private ServiceB serviceB; @Transactional public void doSomething() &#123; serviceB.insert(); // 调用其他系统 &#125;&#125;@Servicepublic class ServiceB &#123; @Transactional(propagation = Propagation.REQUIRES_NEW) public void insert() &#123; // 向数据库中添加数据 &#125;&#125; 数据源没有配置事务管理器如下，数据源没有配置事务管理器，那么下面的方法 TransactionManager 是无法实现事务的 1234@Beanpublic PlatformTransactionManager transactionManager(DataSource dataSource) &#123; return new DataSourceTransactionManager(dataSource);&#125; 事务传播级别选择如果在嵌套调用时存在事务传播的场景，在定义事务级别的时候是用来 NOT_SUPPORTED，那么对应的方法就不会执行事务。如下，在 OrderServiceImpl 中执行的 update 方法执行了事务，同时该方法调用 updateOrder 方法。由于 updateOrder 方法的 @Transactional 注释中标注 了 Propagation.NOT_SUPPORTED，因此 updateOrder 方法的事务是不执行的 123456789101112@Servicepublic class OrderServiceImpl &#123; @Transactional public void update(Order order) &#123; updateOrder(); &#125; @Transactional(propagation = Propagation.NOT_SUPPORTED) public void updateOrder(Order order) &#123; // update order &#125;&#125; 事务中出现异常如果在执行方法中执行的事务，由于异常退出的情况，那么这个事务是无法完成的。如下，在 updateOrder 方法使用了 try catch，一旦方法体中出现异常，此时事务会中断无法执行 1234567891011121314@Servicepublic class OrderServiceImpl implements OrderService &#123; @Transactional public void updateOrder(Order order) &#123;] try &#123; // update order &#125; catch (Exception e) &#123; // do something &#125; &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 事务框架源码初探]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F26%2FSpring-%E4%BA%8B%E5%8A%A1%E6%A1%86%E6%9E%B6%E6%BA%90%E7%A0%81%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[事务开启分析Spring声明式事务是通过 AOP 增强实现的，所以现在分析 Spring 事务执行过程的时候离不开 AOP 拦截器执行链的描述，其中比较重要的拦截器就是 TransactionInterceptor 了 如下，在 TransactionInterceptor 中有一个重要的方法 invoke，其中会获取带来对象的类型，同时会调用父类 TransactionAspectSupport 的 invokeWithintransaction 方法传入拦截器执行的方法和目标类，从而返回连接点的执行结果 1234567891011121314/** * @param invocation 拦截器链的执行器，用于执行下一个拦截器 * @return 返回连接点的执行结果 * @throws Throwable */@Nullablepublic Object invoke(MethodInvocation invocation) throws Throwable &#123; // 获取被代理对象的类类型 Class&lt;?&gt; targetClass = invocation.getThis() != null ? AopUtils.getTargetClass(invocation.getThis()) : null; // 调用父类 TransactionAspectSupport 方法 // 传入连接点对象，代理对象类类型，拦截器执行器 MethodInvocation 的 proceed() 方法引用 return this.invokeWithinTransaction(invocation.getMethod(), targetClass, invocation::proceed);&#125; 接着到 TransactionAspectSupport 的 invokeWithintransaction 方法中去看看，如下，该方法传入连接点的方法对象，被代理的对象（用于执行方法）以及执行下一个的拦截器。 在方法体里面通过 getTransactionAttributeSource 方法获取事务注解属性源，再通过它获取事务注解属性对象，由事务注解属性对象产生事务管理器，最后的目的是为了生成 TransactionInfo 的事务信息对象，通过这个对象执行并提交事务。需要注意的是，生成对象的方法是 createTransactionIfNecessary 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 执行事务逻辑 * * @param method 连接点的方法对象 * @param targetClass 被代理的对象，用于执行 method * @param invocation 用于执行下一个拦截器 * @return * @throws Throwable */@Nullableprotected Object invokeWithinTransaction(Method method, @Nullable Class&lt;?&gt; targetClass, TransactionAspectSupport.InvocationCallback invocation) throws Throwable &#123; // 事务注解属性源，包含了保存 事务注解属性的缓存 如果为空不执行事务 TransactionAttributeSource tas = this.getTransactionAttributeSource(); // 事务注解属性对象 TransactionAttribute txAttr = tas != null ? tas.getTransactionAttribute(method, targetClass) : null; // 事务管理器 TransactionManager tm = this.determineTransactionManager(txAttr); PlatformTransactionManager ptm = this.asPlatformTransactionManager(tm); //获取连接点唯一标识字符串 com.example.UserService.insertUser String joinpointIdentification = this.methodIdentification(method, targetClass, txAttr); Object retVal; // 如果是本地事务执行逻辑 if (txAttr == null || ptm instanceof CallbackPreferringPlatformTransactionManager) &#123; // 创建事务对象并返回事务信息 // TransactionInfo 事务信息对象 主要包含 TransactionStatus、TransactionAttribute、PlatformTransactionManager TransactionInfo txInfo = this.createTransactionIfNecessary(ptm, txAttr, joinpointIdentification); try &#123; // 执行下一个拦截器，如果只有一个拦截器，那么下一个会执行连接点的方法 retVal = invocation.proceedWithInvocation(); &#125; catch (Throwable ex) &#123; // 事务回滚 this.completeTransactionAfterThrowing(txInfo, var18); throw ex; &#125; finally &#123; // 清除事务信息 this.cleanupTransactionInfo(txInfo); &#125; // 提交事务 this.commitTransactionAfterReturning(txInfo); return retVal; &#125;&#125; 上面 invokeWithintransaction 方法中会将事务信息对象执行并提交，其中通过 createTransactionIfNecessary 产生这个事务信息对象，接下来看看这个对象的产生方法的代码。如下，该方法中通过传入的 PlatformTransactionManager 获取事务管理器，然后调用其中的 getTransaction 方法获取事务 123456789101112131415161718192021222324protected TransactionAspectSupport.TransactionInfo createTransactionIfNecessary(@Nullable PlatformTransactionManager tm, @Nullable TransactionAttribute txAttr, final String joinpointIdentification) &#123; // 如果没有执行名称，则使用 joinpointIdentification，并且返回代理对象 if (txAttr != null &amp;&amp; ((TransactionAttribute)txAttr).getName() == null) &#123; txAttr = new DelegatingTransactionAttribute((TransactionAttribute)txAttr) &#123; public String getName() &#123; return joinpointIdentification; &#125; &#125;; &#125; TransactionStatus status = null; // 事务属性不为 null if (txAttr != null) &#123; // 事务管理器不为 null if (tm != null) &#123; // 获取事务 status = tm.getTransaction((TransactionDefinition)txAttr); &#125; else if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Skipping transactional joinpoint [" + joinpointIdentification + "] because no transaction manager has been configured"); &#125; &#125; // 创建并初始化 TransactionInfo return this.prepareTransactionInfo(tm, (TransactionAttribute)txAttr, joinpointIdentification, status);&#125; getTransaction 的方法比较长，主要是根据事务的传播级别对事务进行处理，我们截取其中一段代码。如下，首先调用 doGetTransaction 方法获取 transaction 对象。然后，经过事务传播级别判断以后，生产 DefaultTransactionStatus 类型，同时 doBegin 方法开启事务、获取链接、设置数据库事务隔离级别等操作。最后，通过运行 prepareSynchronization 方法初始化事务同步器 TransactionSynchronizationManager doBegin 的代码如下所示，它主要做了一下几个操作 通过 obtainDataSource 中的 getConnection 方法，从数据源获取新的连接 通过 prepareConnectionForTransaction 方法设置数据库事务隔离级别 通过 prepareTransactionConnection 设置只读事务 通过 getConnectionHolder 中的 setTransactionActive 方法设置事务为生效状态 通过 determineTimeout 方法设置连接超时时间 事务开启大图总结上面通过对主要源码的分析了解了 Spring 事务开启的整个过程，这里通过一张大图梳理一下。如下图，我们从上往下看，TransactionInterceptor 作为事务拦截器，是本次课程的核心，通过其中的 invoke 方法开启事务。其中会调用父类 TransactionAspectSupport 中的 invokeWithinTransaction 方法 invokeWithinTransaction 这个方法有两个分支，左边是执行业务逻辑的方法，调用的是 invocation 中的processedWithinInvocation 完成的。右边的分支用来开启事务，会调用 TransactionAspectSupport 的 createTransactionIfNecessary 方法，其中会使用到事务管理器 PlatformTransactionManager 中的 getTransaction 方法获取事务 此时获取事务的操作有两个部分，第一步通过调用 JpaTransactionManager 中的 doGetTransaction 方法返回 JpaTransactionObject，第二步通过 JpaTransactionManager 中的 doBegin 方法调用 HibernateJpaDialect 中的beingTransaction 完成事务的开启 事务提交和回滚代码我们启动了 Spring 的事务之后，如果事务顺利执行就会提交事务，否则会对事务进行回滚。在 invokeWithinTransaction 方法中 try catch 语句定义了执行拦截器和事务回滚的代码。其中事务回滚会调用 completeTransactionAfterthrowing，如果事务执行顺利就会调用 commitTransactionAfterReturning方法 在 completeTransactionAfterThrowing 方法内部主要处理异常情况下是否需要回滚。注意，方法内部会向上递归查找父类是否和 Exception 相同，如果相同进行回滚。其中下面的 rollback 方法，该方法是从事务消息对象中的 getTransactionManager 中获取的，传入了事务状态对象（getTransactionStatus 获取状态） 123456789101112131415161718192021222324252627282930313233343536protected void completeTransactionAfterThrowing(@Nullable TransactionAspectSupport.TransactionInfo txInfo, Throwable ex) &#123; if (txInfo != null &amp;&amp; txInfo.getTransactionStatus() != null) &#123; if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Completing transaction for [" + txInfo.getJoinpointIdentification() + "] after exception: " + ex); &#125; // 使用 RuleBasedTransactionAttribute 判断当前异常是否需要回滚 - 如果注解上定义了 @Transactional(rollbackFor = Exception.class) // 这里会使用 ex 向上递归查找父类是否和 Exception 是否相同，如果相同则进行回滚 if (txInfo.transactionAttribute != null &amp;&amp; txInfo.transactionAttribute.rollbackOn(ex)) &#123; try &#123; txInfo.getTransactionManager().rollback(txInfo.getTransactionStatus()); &#125; catch (TransactionSystemException var6) &#123; this.logger.error("Application exception overridden by rollback exception", ex); var6.initApplicationException(ex); throw var6; &#125; catch (Error | RuntimeException var7) &#123; this.logger.error("Application exception overridden by rollback exception", ex); throw var7; &#125; &#125; // 否则执行提交 else &#123; // commit() 会判断通过手动设置回滚的操作，然后也会进行回滚 try &#123; txInfo.getTransactionManager().commit(txInfo.getTransactionStatus()); &#125; catch (TransactionSystemException var4) &#123; this.logger.error("Application exception overridden by commit exception", ex); var4.initApplicationException(ex); throw var4; &#125; catch (Error | RuntimeException var5) &#123; this.logger.error("Application exception overridden by commit exception", ex); throw var5; &#125; &#125; &#125;&#125; 由于此处使用了 TransactionManager，这里提一下，PlatformTransactionManager 继承自 TransactionManager 接口，AbstractPlatformTransactionManager 对 PlatformTransactionManager 进行了抽象，对方法进行了具体的实现。 如下，PlatformTransactionManager 继承了 TransactionManager 接口，其中也继承了创建事务并开启事务的方法 getTransaction、提交事务的方法 commit 以及回滚事务的方法 rollback 12345678910public interface PlatformTransactionManager extends TransactionManager &#123; // 创建一个事务并开启事务 TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException; // 提交事务 void commit(TransactionStatus definition) throws TransactionException; // 回滚事务 void rollback(TransactionStatus definition) throws TransactionException;&#125; 看完了 Rollback 相关的方法再来看看 commitTransactionAfterReturning，如下，在方法体中通过 getTransactionManager 调用 commit 方法传入事务状态 12345678910protected void commitTransactionAfterReturning(@Nullable TransactionAspectSupport.TransactionInfo txInfo) &#123; if (txInfo != null &amp;&amp; txInfo.getTransactionStatus() != null) &#123; if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Completing transaction for [" + txInfo.getJoinpointIdentification() + "]"); &#125; txInfo.getTransactionManager().commit(txInfo.getTransactionStatus()); &#125;&#125; 如下，需要注意的是，在 commit 方法中会针对 isLocalRollbackOnly 进行判断，如果为 true 会执行 processRollback 方法进行手动回滚。同时还会通过 shouldCommitOnGlobalRollbackOnly 和 isGlobalRollbackOnly 判断进行 processRollback 的手动回滚 123456789101112131415161718192021222324252627public final void commit(TransactionStatus status) throws TransactionException &#123; if (status.isCompleted()) &#123; throw new IllegalTransactionStateException("Transaction is already completed - do not call commit or rollback more than once per transaction"); &#125; else &#123; DefaultTransactionStatus defStatus = (DefaultTransactionStatus)status; // 如果这里执行了 TransactionInterceptor.currentTransactionStatus().setRollbackOnly(); // 这里会判断为 true 并且进行回滚操作 if (defStatus.isLocalRollbackOnly()) &#123; if (defStatus.isDebug()) &#123; this.logger.debug("Transactional code has requested rollback"); &#125; this.processRollback(defStatus, false); &#125; // 通过 ConnectionHolder setRollbackOnly() 设置的回滚 else if (!this.shouldCommitOnGlobalRollbackOnly() &amp;&amp; defStatus.isGlobalRollbackOnly()) &#123; if (defStatus.isDebug()) &#123; this.logger.debug("Global transaction is marked as rollback-only but transactional code requested commit"); &#125; this.processRollback(defStatus, true); &#125; else &#123; // 执行提交 this.processCommit(defStatus); &#125; &#125;&#125; 总结提交回滚流程我们用一张图梳理一下事务的提交和回滚流程。流程图从 TransactionInterceptor 开始，调用父类的 invokeWithinTransaction 方法业务逻辑，如果报错，走左边的逻辑调用 TransactionAspectSupport 中的 completeTransactionAfterThrowing，继续通过 AbstractPlatformTransactionManager 的 rollback 方法执行回滚操作 如果没有报错，调用 commitTransactionAfterReturning 方法，使用 AbstractPlatformTransactionManager 的 commit 方法进行提交操作。Rollback 和 commit 的后续操作会涉及到 JpaTransactionManager 类，这里不展开描述]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 同步和异步事件的使用场景]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F25%2FSpring-%E5%90%8C%E6%AD%A5%E5%92%8C%E5%BC%82%E6%AD%A5%E4%BA%8B%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[Spring 事件的监听机制可以理解为是一种观察者模式，有数据发布者（事件源）和数据接受者（监听器）。在 Java 中，事件对象都是继承 java.util.EventObject 对象，事件监听器都是 java.util.EventListener 实例 其中，java.util.EventObject 是事件状态对象的基类，它封装了事件源对象以及和事件相关的信息。所有 java 的事件类都需要继承该类 而 java.util.EventListener 是一个接口，所有事件监听器都需要实现该接口。事件监听器注册在事件源上，当事件源的属性或状态改变的时候，调用相应监听器内的回调方法 Source 作为事件源不需要实现或继承任何接口或类，它是事件最初发生的地方。因为事件源需要注册事件监听器，所以事件源内需要存放事件监听器的容器 例如，我们需要将 User 信息保存到数据库中，然后发送一条 User 的消息，然后由对应的监听器来处理 如下代码，UserEvent 作为需要发送的消息继承于 ApplicationEvent，同时提供了 getData 和 setData 的方法来存放需要处理的数据 12345678910111213141516public class UserEvent &lt;T&gt; extends ApplicationEvent &#123; private T data; public UserEvent(T source) &#123; super(source); this.data = source; &#125; public T getData() &#123; return data; &#125; public void setData(T data) &#123; this.data = data; &#125;&#125; 接着就是发送 UserEvent 消息的 sendInsertUser 方法，如下，该方法创建 User 的实例以后填写对应的属性，然后通过 ApplicationEventPublisher 类型的 publisher 变量执行 publishEvent 方法进行发送消息 1234567891011@Autowiredprivate ApplicationEventPublisher publisher;private void sendInsertUser() &#123; User user = new User(); user.setId(1); user.setUsername("李四"); UserEvent&lt;User&gt; userEvent = new UserEvent&lt;&gt;(user); // 发布事件 publisher.publishEvent(userEvent);&#125; 有了发送消息的代码就有监听消息的代码。insertUserListener 方法在 @EventListener 的修饰下就成为消息监听器。它会接收 UserEvent 消息，并且对消息进行处理，最后把处理的结果 message 记录到日志中 123456@EventListenerpublic void insertUserListener(UserEvent&lt;User&gt; userEvent) &#123; User data = userEvent.getData(); String message = String.format("get user message: %s", JSON.toJSONString(data)); log.info(message);&#125; 接着测试代码，如下，在测试方法中先执行 insertUsers 方法用来往 User 表中插入数据，然后再执行 sendInsertUser 方法来发送消息 1234567891011121314151617public BackResult testEvent() &#123; BackResult backResult = new BackResult(); try&#123; // 向 user 表插入数据 insertUsers(); // 添加 user 插入对象操作 sendInsertUser(); backResult.setSuccess(true); backResult.setMessage("操作成功"); &#125; catch(Exception e) &#123; backResult.setMessage(e.getMessage()); backResult.setSuccess(false); &#125; return backResult;&#125; Spring 消息的同步处理假设上面的例子中两个方法 insertUsers 和 sendInsertUser 需要同步执行，也就是 insertUsers 方法会先执行，完成数据库的提交以后再 执行 sendInsertUser 方法发送消息。如果 insertUsers 数据库提交一直没有返回成功的结果，sendInsertUser 就需要一直等待 也就是说 insertUsers 会阻塞 sendInsertUser 方法，这就是我们常说的同步执行。为了做到同步执行，就需要将监听器加入到主线程的事务中，让这两个方法顺序执行 如下，首先在 insertUsers 方法上面打了 @Transactional 的注释，标注它是一个事务操作 1234@Transactional(rollbackFor = Exception.class)public void insertUsers() &#123; // insert data into database&#125; 然后修改 insertUserListener 方法，在上面加 @TransactionalEventListener的注释，并且通过 phase 属性标注 TransactionPhase.AFTER_COMMIT，意思是在事务提交以后，再执行方法内容。 也就是在 insert user 数据库事务提交以后，再处理监听到的 UserEvent 消息，从而保证事务的一致性 123456@TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT, fallbackExecution = true)public void insertUserListener(UserEvent&lt;User&gt; userEvent) &#123; User data = userEvent.getData(); String message = String.format("get user message: %s", JSON.toJSONString(data)); log.info(message);&#125; 从这个例子可以发现，如果执行的操作和发送消息以后对应的操作业务上有较高的关联性，可以作为一个事务的两个操作来处理，要么一起完成要么都不完成的话，那么就需要进行同步处理。 常见的业务场景有，下单操作和通知减扣库存，下单以后商品别售出，库存随之扣减，如果下单失败扣减库存的操作也不能执行 Spring 消息的异步处理上面说的是同步处理的业务场景，还是这个例子，假设 insertUsers 和 sendInsertUser 这两个操作的业务关联性并不大，那么如何处理？例如，insertUsers 之后只是发一个通知给用户，说数据入库了。就算是入库不成功，消息发送也不用撤回 这种场景业务就可以用异步处理来做，也就是说 snedInserUser 不用等待 insertUsers 方法数据库条件完成就可以处理发送的消息了。即这两个方法不是串行执行而是并行执行，两个操作的执行时互相不干扰的 如下，异步处理只需要在原方法上加上 @Async 的注解，同时需要注意的是，需要使用 EnableAsync 开启 Spring 异步模式 1234567@Async@TransactionalEventListener(phase = TransactionPhase.AFTER_COMMIT, fallbackExecution = true)public void insertUserListener(UserEvent&lt;User&gt; userEvent) &#123; User data = userEvent.getData(); String message = String.format(&quot;get user message: %s&quot;, JSON.toJSONString(data)); log.info(message);&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP 源码分析 2]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F18%2FSpring-AOP-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-2%2F</url>
    <content type="text"><![CDATA[JDK 动态代理源码分析接着我们通过源码分析介绍 Spring AOP JDK 动态代理实现的原理。内容包括： invoke：实现 AOP 中具体的逻辑 getProxy：获取产生的代理类 invoke：实现 AOP 中具体的逻辑JDK 中的 AOP 的实现是基于 java.lang.reflect 包中 Proxy 和 InvocationHandler 两个接口来实现的。对于 InvocationHandler 的创建，需要我们重写三个方法： 构造函数：将目标代理对象传入 invoke：实现 AOP 中具体的逻辑 getProxy：获取产生的代理类 而在 Spring 框架中，JDK 方式的代理也是实现了上述过程 JDK 动态代理时通过 proxyFactory.getProxy 获取代理的，如下，通过 createAopProxy() 生成对应的 ProxyFactory，然后在调用其中的 getProxy 方法 123public Object getProxy() &#123; return this.createAopProxy().getProxy();&#125; createAopProxy 中决定的实现类为 JdkDynamicAopProxy，如下面代码所示，它实现了 AopProxy 和 InvocationHandler 1final class JdkDynamicAopProxy implements AopProxy, InvocationHandler, Serializable 由于我们会调用 InvocationHandler，并且 override 其中的 invoke 方法，然后通过 InvocationHandler 中的 getProxy 方法获取代理类，通过对代理类调用 process 方法执行 AOP 的相关操作 我们先来看看 override 的 invoke 方法的源码，如下图所示，在 invoke 方法中我们需要关注红框标注的部分： 在获取目标类以后，通过目标类获取要执行方法的拦截器链，这里的变量为 chain 如果 chain 为空，说明没有在方法上进行拦截，那么直接调用切点方法就行了 如果 chain 不为空，说明在方法上有拦截，于是将拦截器封装在 ReflectiveMethodInvocation，并执行，这部分也是 AOP 需要关注的 上面通过了 getInterceptorsAndDynamicInterceptionAdvice 获取目标类执行方法的拦截器链 chain，这里对 getInterceptorsAndDynamicInterceptionAdvice 进行解析，如下图，依旧关注红框的部分： 收到获取此方法的拦截器链，依然将 Advisor 分为三种类型： PointcutAdvisor：当前 class、method 与 Pointcut 匹配时，才获取并保存 MethodInterceptor 的 List IntroductionAdvisor：当前 class 与 Pointcut 匹配时，获取并保存 MethodInterceptor 的 List 其他类型：直接获取并保存 MethodInterceptor 的 List 从上图可以知道，处理 PointcutAdvisor 类型的时候会用到 getInterceptors 方法获取 MethodInterceptor 的数组类型，这里看看 getInterceptors 内部的实现是如何的 如下，使用 advisor.getAdvice() 获取 Advice。假设注解 Advisor 以 @Before 注解形式存在，那么此时得到的 Advice 应该是 AspectJMethodBeforeAdvice，进入的是 interceptors.add(adapter.getInterceptor(advisor)) 这行代码，将 AspectJMethodBeforeAdvice 包装成 MethodInterceptor 类型，并返回 12345678910111213141516171819202122public MethodInterceptor[] getInterceptors(Advisor advisor) throws UnknownAdviceTypeException &#123; List&lt;MethodInterceptor&gt; interceptors = new ArrayList(3); Advice advice = advisor.getAdvice(); if (advice instanceof MethodInterceptor) &#123; interceptors.add((MethodInterceptor)advice); &#125; Iterator var4 = this.adapters.iterator(); while(var4.hasNext()) &#123; AdvisorAdapter adapter = (AdvisorAdapter)var4.next(); if (adapter.supportsAdvice(advice)) &#123; interceptors.add(adapter.getInterceptor(advisor)); &#125; &#125; if (interceptors.isEmpty()) &#123; throw new UnknownAdviceTypeException(advisor.getAdvice()); &#125; else &#123; return (MethodInterceptor[])interceptors.toArray(new MethodInterceptor[0]); &#125;&#125; 上面说的是如何获取方法拦截链 chain，接下来看看拦截链为空和不为空的情况。拦截链为空，如下代码所示，表示当前的 Method 并没有 Advice 逻辑需要增强 12Object[] argsToUse = AopProxyUtils.adaptArgumentsIfNecessary(method, args);retVal = AopUtils.invokeJoinpointUsingReflection(target, method, argsToUse); 拦截链不为空，如图 4 所示，需要创建 ReflectiveMethodInvocation 对象。如下： 12345678protected ReflectiveMethodInvocation(Object proxy, @Nullable Object target, Method method, @Nullable Object[] arguments, @Nullable Class&lt;?&gt; targetClass, List&lt;Object&gt; interceptorsAndDynamicMethodMatchers) &#123; this.proxy = proxy; this.target = target; this.targetClass = targetClass; this.method = BridgeMethodResolver.findBridgedMethod(method); this.arguments = AopProxyUtils.adaptArgumentsIfNecessary(method, arguments); this.interceptorsAndDynamicMethodMatchers = interceptorsAndDynamicMethodMatchers;&#125; 有了 ReflectiveMethodInvocation 对象就要通过 proceed 方法对拦截链上的拦截器进行递归执行，也是一种对当前 Method 的链式增强。如下，proceed 方法中会在拦截链上通过 currentInterceptorIndex 获取一个拦截器，然后对其进行动态代理方法的匹配，如果匹配通过了，执行拦截器中的方法，否则跳过该拦截器，执行拦截器链上的下一个拦截器 如果是一个拦截器，就通过静态的方式执行，不用执行其中的嵌入方法 123456789101112131415161718public Object proceed() throws Throwable &#123; if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123; return this.invokeJoinpoint(); &#125; else &#123; // currentInterceptorIndex 用来递归执行 MethodInvocation.proceed，从而进入到下一个拦截器 Object interceptorOrInterceptionAdvice = this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex); if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123; // 进行动态代理方法的匹配，如果匹配上了执行加入拦截器以后的方法，否则跳过拦截器执行下一个拦截器链的拦截器 InterceptorAndDynamicMethodMatcher dm = (InterceptorAndDynamicMethodMatcher)interceptorOrInterceptionAdvice; Class&lt;?&gt; targetClass = this.targetClass != null ? this.targetClass : this.method.getDeclaringClass(); // 如果动态匹配失败，跳过拦截器到拦截链的下一个拦截器 return dm.methodMatcher.matches(this.method, targetClass, this.arguments) ? dm.interceptor.invoke(this) : this.proceed(); &#125; else &#123; // 只是一个拦截器就通过静态的方式执行，不用执行其中嵌入的方法 return ((MethodInterceptor)interceptorOrInterceptionAdvice).invoke(this); &#125; &#125;&#125; 在 proceed 方法中无论是否匹配上动态代理方法都会运行 invoke。这里以前置增强为例，实现类为 MethodBeforeAdviceInterceptor。如下，在 invoke 方法中执行 advice 的 before 方法实现增强内容 12345678910111213public class MethodBeforeAdviceInterceptor implements MethodInterceptor, BeforeAdvice, Serializable &#123; private final MethodBeforeAdvice advice; public MethodBeforeAdviceInterceptor(MethodBeforeAdvice advice) &#123; Assert.notNull(advice, "Advice must not be null"); this.advice = advice; &#125; public Object invoke(MethodInvocation mi) throws Throwable &#123; this.advice.before(mi.getMethod(), mi.getArguments(), mi.getThis()); return mi.proceed(); &#125;&#125; 这里把 JDK 的链式增强做一个总结。如下图，首先根据 Advisor 中的 Advice 创建 MethodInterceptor 拦截器链，这个链中保存对目标类对应方法的所有增强，这些增强以拦截器链的方式放到拦截器链中。然后创建 MethodInvocation 用来保存上述的 MethodInterceptor 拦截器链 接着执行 MethodInvocation.proceed 的递归方法，在方法中通过 IterceptorIndex 对拦截器链上的拦截器进行遍历。在拦截器链中的逻辑都执行完毕了，通过 invoke 执行目标类的原方法 getProxy：获取产生的代理类接着我们看通过 getProxy 获取代理对原方法和增强方法执行的过程。如下所示，getProxy 接收 ClassLoader 作为参数，方法体中调用了 AopProxyUtils 的 completeProxiedInterfaces 生成代理接口，然后通过 Proxy 中的 newProxyInstance 方法将代理实例化 123456789public Object getProxy(@Nullable ClassLoader classLoader) &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Creating JDK dynamic proxy: " + this.advised.getTargetSource()); &#125; Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); this.findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);&#125; 我们看看 getProxy 中调用的 completeProxiedInterfaces 方法，该方法体中获取 AdvisedSupport 代理配置中目标类中需要被代理的接口 在当前目标类中，如果需要被代理的接口数为0 的情况下，做如下处理： 如果目标类它自身就是个接口，将其加到目标 Interface 如果目标类本身已经是一个代理类（根据 Proxy.isProxyClass 判断），是 JDK 动态代理创建的代理对象，那么将其所有的接口都加到目标 Interface 重新获取目标接口 addSpringProxy、addAdvised 用于判断目标类是否是特殊接口：SpringProxy、Advised。一般情况下两个 boolean 都是 true 将目标代理类、SpringProxy、Advised 三个接口填入 proxiedInterfaces 中，返回此数组 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950static Class&lt;?&gt;[] completeProxiedInterfaces(AdvisedSupport advised, boolean decoratingProxy) &#123; Class&lt;?&gt;[] specifiedInterfaces = advised.getProxiedInterfaces(); if (specifiedInterfaces.length == 0) &#123; Class&lt;?&gt; targetClass = advised.getTargetClass(); if (targetClass != null) &#123; if (targetClass.isInterface()) &#123; advised.setInterfaces(new Class[]&#123;targetClass&#125;); &#125; else if (Proxy.isProxyClass(targetClass)) &#123; advised.setInterfaces(targetClass.getInterfaces()); &#125; specifiedInterfaces = advised.getProxiedInterfaces(); &#125; &#125; boolean addSpringProxy = !advised.isInterfaceProxied(SpringProxy.class); boolean addAdvised = !advised.isOpaque() &amp;&amp; !advised.isInterfaceProxied(Advised.class); boolean addDecoratingProxy = decoratingProxy &amp;&amp; !advised.isInterfaceProxied(DecoratingProxy.class); int nonUserIfcCount = 0; if (addSpringProxy) &#123; ++nonUserIfcCount; &#125; if (addAdvised) &#123; ++nonUserIfcCount; &#125; if (addDecoratingProxy) &#123; ++nonUserIfcCount; &#125; Class&lt;?&gt;[] proxiedInterfaces = new Class[specifiedInterfaces.length + nonUserIfcCount]; System.arraycopy(specifiedInterfaces, 0, proxiedInterfaces, 0, specifiedInterfaces.length); int index = specifiedInterfaces.length; if (addSpringProxy) &#123; proxiedInterfaces[index] = SpringProxy.class; ++index; &#125; if (addAdvised) &#123; proxiedInterfaces[index] = Advised.class; ++index; &#125; if (addDecoratingProxy) &#123; proxiedInterfaces[index] = DecoratingProxy.class; &#125; return proxiedInterfaces;&#125; 总结 CGLIB 动态代理源码分析CGLIB 是通过字节码增强处理器框架 ASM，来生成字节码并装载到 JVM。和 JDK 代理基于接口实现方式不同，CGLIB 没有局限于接口，采用的是生成子类的方式。这个子类本质上就是一个 Class 对象，即，原来是执行原有的 Class，CGLIB 会通过字节码增强的方式，在字节码的层面生成一个子类去继承需要增强的类，在子类中加入需要增强的方法，让这个子类代替原有的类，完成增强的操作 我们将 CGLIB 生成 Class 对象分为三个步骤： 生成指定类的 Class 对象字节数组 将 Class 对象字节数组转换为 Class 对象 通过 Class.forName 方法将 Class 对象装载到 JVM 生成指定类的 Class 对象字节数组如下，在创建 Enhance 对象会调用 create 方法从而生成超类的子类。深入到 create 方法内部可以看到，先通过 getClassLoader 获取当前类加载器，通过 AbstractClassGenerator 中的 ClassLoaderData 方法传入到加载器，获取加载类的内容 data。并且将其放到缓存中，接下来利用 data 中的 get 方法获取字节码信息并且返回 12345678910111213141516171819202122232425262728293031protected Object create(Object key) &#123; try &#123; // 获取当前类加载器，应用类加载器 ClassLoader loader = this.getClassLoader(); Map&lt;ClassLoader, AbstractClassGenerator.ClassLoaderData&gt; cache = CACHE; AbstractClassGenerator.ClassLoaderData data = (AbstractClassGenerator.ClassLoaderData)cache.get(loader); if (data == null) &#123; Class var5 = AbstractClassGenerator.class; synchronized(AbstractClassGenerator.class) &#123; cache = CACHE; data = (AbstractClassGenerator.ClassLoaderData)cache.get(loader); if (data == null) &#123; Map&lt;ClassLoader, AbstractClassGenerator.ClassLoaderData&gt; newCache = new WeakHashMap(cache); // 创建 AbstractClassGenerator data = new AbstractClassGenerator.ClassLoaderData(loader); newCache.put(loader, data); CACHE = newCache; &#125; &#125; &#125; this.key = key; // 调用 get 方法获取字节码，如果没有字节码，则会创建字节码 Object obj = data.get(this, this.getUseCache()); return obj instanceof Class ? this.firstInstance((Class)obj) : this.nextInstance(obj); &#125; catch (Error | RuntimeException var9) &#123; throw var9; &#125; catch (Exception var10) &#123; throw new CodeGenerationException(var10); &#125;&#125; 顺着 data 中的 get 方法查看代码，get 中会判断是否开启缓存，如果没有使用缓存就调用 generate 方法，否则直接从缓存中获取对象。这里的缓存可以通过 enhancer.setUserCache 方法设置，默认为 true 123456789public Object get(AbstractClassGenerator gen, boolean useCache) &#123; // 判断是否开启缓存，可直接设置：enhancer.setUserCache(false); 默认为 true if (!useCache) &#123; return gen.generate(this); &#125; else &#123; Object cachedValue = this.generatedClasses.get(gen); return gen.unwrapCachedValue(cachedValue); &#125;&#125; 继续跟进 generate方法中传入 data 作为参数，生成对应的代理类名称，然后通过类加载器和类名称尝试加载类。如果之前没有生成对应的字节码，那么创建字节码。接着通过生成字节码的策略生成字节码，当前对象即为 Enhancer 对象，字节数组的形式 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849protected Class generate(AbstractClassGenerator.ClassLoaderData data) &#123; Object save = CURRENT.get(); CURRENT.set(this); Class var8; try &#123; ClassLoader classLoader = data.getClassLoader(); if (classLoader == null) &#123; throw new IllegalStateException("ClassLoader is null while trying to define class " + this.getClassName() + ". It seems that the loader has been expired from a weak reference somehow. Please file an issue at cglib's issue tracker."); &#125; String className; // 生成代理类名称 synchronized(classLoader) &#123; className = this.generateClassName(data.getUniqueNamePredicate()); data.reserveName(className); this.setClassName(className); &#125; Class gen; // 这里通过应用类加载器和类名称尝试加载，如果加载不到，才开始创建字节码 if (this.attemptLoad) &#123; try &#123; gen = classLoader.loadClass(this.getClassName()); Class var23 = gen; return var23; &#125; catch (ClassNotFoundException var19) &#123; &#125; &#125; // 通过生成策略创建字节码，当前对象即为 Enhancer 对象，字节数组形式 byte[] b = this.strategy.generate(this); className = ClassNameReader.getClassName(new ClassReader(b)); ProtectionDomain protectionDomain = this.getProtectionDomain(); synchronized(classLoader) &#123; // 将字节码加载到 JVM 内存，同时会触发代理对象初始化 gen = ReflectUtils.defineClass(className, b, classLoader, protectionDomain, this.contextClass); &#125; var8 = gen; &#125; catch (Error | RuntimeException var20) &#123; throw var20; &#125; catch (Exception var21) &#123; throw new CodeGenerationException(var21); &#125; finally &#123; CURRENT.set(save); &#125; return var8;&#125; 我们看 getClassName 方法中时如何生成代理类名称的。由下可以看出，生成字节码文件的规则：真实类路径 + 来源（EnhancerByCGLIB）+ key 的 hash 值的 16 进制 123456789101112131415public String getClassName(String prefix, String source, Object key, Predicate names) &#123; if (prefix == null) &#123; prefix = "org.springframework.cglib.empty.Object"; &#125; else if (prefix.startsWith("java")) &#123; prefix = "$" + prefix; &#125; // 拼接类路径 String base = prefix + "$$" + source.substring(source.lastIndexOf(46) + 1) + this.getTag() + "$$" + Integer.toHexString(STRESS_HASH_CODE ? 0 : key.hashCode()); String attempt = base; for(int var7 = 2; names.evaluate(attempt); attempt = base + "_" + var7++) &#123; &#125; return attempt;&#125; 生成文件的结果入好像如下所示： com.example.cglib.RealService$$EnhancerByCGLIB$$a9ba5c5e 具体生成的字节码的方式就是和通过 asm 的工具类 DefaultGeneratorStrategy 来生成，另外提供了一个 DebuggingClassWriter 来写入到指定目录，默认的目录为空，所以生成的代理类只存在于内存中 将 Class 对象字节数组转换为 Class 对象通过上面的源代码分析已经生成了 Class 对象字节数组，接下来就要将这个字节数组转换成 Class 对象。跟进 ReflectUtils.defineClass 继续看，如下，方法 defineClass 传入了 byte[] b，这个 b 的数组中存放的就是字节数组。通过 new object 将字节数组赋值给 args，然后通过 DEFINE_CLASS.invoke 方法将字节数组转化为 Class 对象 12345678910111213141516171819202122232425262728293031323334public static Class defineClass(String className, byte[] b, ClassLoader loader, ProtectionDomain protectionDomain, Class&lt;?&gt; contextClass) throws Exception &#123; Class c = null; Lookup lookup; if (c == null &amp;&amp; classLoaderDefineClassMethod != null) &#123; if (protectionDomain == null) &#123; protectionDomain = PROTECTION_DOMAIN; &#125; // 其中 b 为 cglib 生成的字节数组 Object[] args = new Object[]&#123;className, b, 0, b.length, protectionDomain&#125;; try &#123; if (!classLoaderDefineClassMethod.isAccessible()) &#123; classLoaderDefineClassMethod.setAccessible(true); &#125; c = (Class)classLoaderDefineClassMethod.invoke(loader, args); &#125; catch (InvocationTargetException var10) &#123; throw new CodeGenerationException(var10.getTargetException()); &#125; catch (Throwable var11) &#123; if (!var11.getClass().getName().endsWith("InaccessibleObjectException")) &#123; throw new CodeGenerationException(var11); &#125; &#125; &#125; if (c == null) &#123; throw new CodeGenerationException(THROWABLE); &#125; else &#123; // 正式加载到 JVM 内存 Class.forName(className, true, loader); return c; &#125;&#125; 通过 Class.forName 方法将 Class 对象装载到 JVM 从上面的代码可以知道，在 defineClass 的最后调用了 Class.forName 方法传入 className 以及加载器，将 Class 对象装载到 JVM 中以供使用。以后这个 Class 对象就代替了源 Class 对象，完成 AOP 增强的操作 总结]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP 源码分析]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F17%2FSpring-AOP-%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[AOP 框架有很多种，Spring 中的 AOP 是通过动态代理实现的。JDK 动态代理只在运行期，目标类加载后，为借口动态生成代理类，将切面织入代理类中 这里通过一个例子来讲解 JDK 动态代理的原理。如下，定义一个 Service 接口，其中有一个 help 方法。用 ServiceImpl 去实现 Service 借口，在 help 方法中实现「打印买书」的输出。这个 ServiceImpl 就是我们要代理的目标类 12345678910public interface Service &#123; public void help();&#125;public class ServiceImpl implements Service &#123; @Override public void help() &#123; System.out.println("买书"); &#125;&#125; 接下来实现代理类，如下，DynamicProxy 作为动态代理类实现了 InvocationHandler 接口。其中定义了 Service 的接口作为代理类 DynamicProxy 构造方法的输入参数。在 Override 的 invoke 方法中通过参数 Method 来代理要执行的代理类中的方法。method.invoke 的输入参数为目标类 Service method.invoke 是用来执行代理类中的 help 方法，如果这个假设成立的话，在这个方法前面执行的 System.out.println(&quot;买书之前&quot;)，会在「买书」方法之前执行；同理，System.out.println(&quot;买书之后&quot;) 会在「买书」方法之后执行 123456789101112131415161718192021public class DynamicProxy implements InvocationHandler &#123; // 代理的真是对象 private Object service; // 构造方法，给代理的真是对象复制 public DynamicProxy(Object service) &#123; this.service = service; &#125; @Override public Object invoke(Object object, Method method, Object[] args) throws Throwable&#123; // 真实方法之前执行 System.out.println("买书之前"); // 调用真实方法 method.invoke(service, args); // 真实方法之后执行 System.out.println("买书之后"); return null; &#125;&#125; 接着我们测试一下 JDK 的代理类是否工作，如下，在 main 方法中通过 Proxy 的 newProxyInstance 方法传入 ClassLoader 的类加载器，同时传入 Service 的接口，以及代理类 DynamicProxy（以 InvocationHandler 的形式）。然后执行代理类的 help 方法 12345678910111213public class Client &#123; public static void main(String[] args) &#123; // 要代理的真实对象 Service service = new ServiceImpl(); // 要代理哪个真实对象，就将该对象传进去，最后是通过该真实对象来调用其方法 InvocationHandler handler = new DynamicProxy(service); // 添加以下几段代码，就可以将代理生成的字节码保存起来 Service serviceProxy = (Service) Proxy.newProxyInstance(service.getClass().getClassLoader(), service.getClass().getInterfaces(), handler); serviceProxy.help(); &#125;&#125; 执行上图代码之后，会发现如下输出，表明在调用 ServiceImpl 类的时候，虽然只执行了其中的 help 方法，该方法输出为「买书」。但同时通过代理类 DynamicProxy 的织入方式，把「买书之前」和「买书之后」两端代码放在了 help 方法的前后，完成面线切面的织入。 CGLIB（Code Generation Library）是一个开源项目，是一个强大的，高性能，高质量的 Code 生成类库，它可以在运行期扩展 Java 类与实现 Java 接口。其原理是在运行期间，通过「字节码的方式在目标类生成的子类中织入对应的代码完成代理」 如下代码，定义一个 Biz 的目标类，里面有一个 help 方法打印「买书」。接着定义一个 BizInterceptor 作为代理类，实现了 MethodInterceptor 的接口，并且 Override intercept 方法 介绍一下 intercept 方法的参数，Object 是生成的子类对象，Method 是要代理目标类的方法，Object[] 是参数，MethodProxy 子类生成的代理方法。通过 methodProxy.invokeSuper 方法执行生成子类的代理方法，第一个输入是目标类生成的子类，第二个输入是参数，该方法就是调用目标类 biz 中的 help方法 最后就是执行测试类的方法了，在 main 函数中 new 一个 enhancer，通过 setSuperclass 指定目标类，通过 setCallback 方法指定代理类，最后使用通过 create 方法生成 Biz 类的实例，并且执行对应的 help 方法 12345678910111213141516171819202122232425262728293031323334353637public class Biz &#123; public void help() &#123; System.out.println("买书"); &#125;&#125;public class BizInterceptor implements MethodInterceptor &#123; /** * * @param o 生成的子类对象 * @param method 要代理目标类的方法 * @param objects 参数 * @param methodProxy 子类生成的代理方法 * @return * @throws Throwable */ @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("买书之前"); methodProxy.invokeSuper(o, objects); System.out.println("买书之后"); return null; &#125;&#125;public class BizCglibClient &#123; public static void main(String[] args) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Biz.class); enhancer.setCallback(new BizInterceptor()); Biz biz = (Biz) enhancer.create(); biz.help(); &#125;&#125; 执行结果如下： Aspect、Join Points、Pointcuts 和 Advice 语法Aspect、Join Points、Pointcuts 以及 Advice，这些都属于 Spring AOP 的核心概念，Spring AOP 是通过这些概念的组合完成代码的织入工作的 如下图，这张图将 Spring AOP 的概念进行了整体描述。先从向右的箭头说起，这个箭头包含了一些小方块，我们称之为 Join Points，它是可以用来进行增强的方法点。例如上面 Service 类中的 help 方法，说白了就是对什么方法进行增强 Join Points 往上看，有一个向下的箭头，上面标注这 Pointcut，我们称之为切入点。切入点是告诉我们在方法的什么位置进行增强，比如在方法执行之强增强，还是执行之后增强。Advice 是最上面的方块，它表示需要增强的功能。例如上面例子中在「买书」的前面和后面都加入了「买书之前」和「买书之后」的打印语句 这里的「买书之前」和「买书之后」就是增强功能，例如我们如果需要编写日志也可以放在这个增强方法里面完成。最后，Advice 和 Pointcut 的组合就是切面 Aspect Spring AOP 举例上面那个图对于那几个概念还是有点抽象，我们通过一个例子来说明 如下代码，Biz 类作为需要增强的目标类，其中包括 help 方法打印出 「买书」，service 方法打印出「提供买书服务」。假设对这两个方法进行增强，那么这两个方法就是 Join Points 12345678910public class Biz &#123; public void help() &#123; System.out.println("买书"); &#125; public void service() &#123; System.out.println("提供买书服务"); &#125;&#125; 上面描述了目标类和 Pointcuts 也就是需要增强的方法，接着我们看具体的增强内容，也就是 Advice。如下，这里定义了两个类 BeforeAdvice、ArroundAdvice 分别实现 MethodBeforeAdvice 和 MethodInterceptor 其中 BeforeAdvice 类中 Override 了 before 方法，就是在方法执行之前运行 before 方法中的内容。再看 ArroundAdvice 类实现了 MethodInterceptor 类并且 Override 了 invoke 方法。通过 invocation.proceed() 调用代理的方法，并且在该方法执行的前后加上了「方法执行之前增强」和「方法执行之后增强」的打印语句 12345678910111213141516public class BeforeAdvice implements MethodBeforeAdvice &#123; @Override public void before(Method method, Object[] objects, Object o) throws Throwable &#123; System.out.println("方法执行执行增强"); &#125;&#125;public class ArroundAdvice implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation invocation) throws Throwable &#123; System.out.println("方法执行之前增强"); Object ret = invocation.proceed(); System.out.println("方法执行之后增强"); return ret; &#125;&#125; 有了 Join points 和 advice 的定义，再来看在什么地方进行增强。我们在 advice 的定义中包含了方法执行之前和前后皆有的 advice，这里通过配置文件看看他们是如何与目标类以及 Advice 进行关联的 如下图，在 bean 的定义中，定义目标类 Biz，同时也定义了对应 advice 类，包括：BeforeAdvice 好 arroundAdvice。在 aop:config 节点中定义了第一个 Pointcut，id 为 doMethods，在 expression 中定义了这个 Pointcut 的执行范围，显示是可以用于对应 namespace 中的 help 方法的 在 advisor 节点中定义了 BeforeAdvice，在 pointcut-ref 中引用了 doMethod 的 pointcut，也就是说对于所有 namespace 在 com.aop.* 的类中使用 help 方法的时候，会使用 beforeAdvice 的增强方法，也就是在 help 方法之前加入增强代码。 同理，定义另一个 advisor 节点，使用了 arroundAdvice 增强方法，针对所有的 namespace 为 com.aop.* 的类中方法为 service 进行增强，增强的方法遵循 arroundAdvice 中描述的：在方法执行执行和之后都插入打印语句 完成配置以后，再看测试代码，如下，首先引入配置的 xml 文件，如果获取 Biz 类的实例，并且调用 help 和 service 方法 12345678public static void main(String[] args) &#123; ApplicationContext context = new GenericXmlApplicationContext( "classpath:com/aop/application.xml"); Biz biz = context.getBean(Biz.class); biz.help(); biz.service();&#125; 执行测试代码之后显示如下内容，由于「买书」使用了 BeforeAdvice 的增强方法，因此在执行help方法打印出「买书」之前会先打印出「方法执行之前增强」。同样，「提供买书服务」使用了 ArroundAdvice 的环绕增强方法，因此在执行 service 方法的时候，会在「提供买书服务」前面和后面分别加入「方法执行之前增强」和「方法执行之后增强」的打印语句。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 动态代理时是如何解决依赖循环的]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F10%2FSpring-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E6%97%B6%E6%98%AF%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E4%BE%9D%E8%B5%96%E5%BE%AA%E7%8E%AF%E7%9A%84%2F</url>
    <content type="text"><![CDATA[什么是依赖循环我们先回顾一下 Bean 的创建过程，在此之前，先看一下三级缓存的概念： singletonObjects：一级缓存。存储单例对象，Bean 已经实例化，初始化完成 earlySingletonObjects：二级缓存。存储 singletonObject，这个 Bean 已经实例化，还没有初始化 singletonFactories：三级缓存。存储 singletonFactory Bean 的创建过程先看下面一段代码 1234@Servicepublic class CircularServiceA &#123; private String fieldA = "字段 A";&#125; 通过上面的流程，可以看出 Spring 在创建 Bean 的过程中重点是 AbstractAutowireCapableBeanFactory 中的以下三个步骤： 实例化 createBeanInstance：其中实例化 Bean并对 Bean 进行赋值，像例子中的 fieldA 字段在这里就会赋值 属性注入 populateBean：可以理解为对 Bean 里面的属性进行赋值（会依赖其他 Bean） 初始化 initializeBean：执行初始化和 Bean 的后置处理器 实例化赋值依赖源码可以阅读： BeanUtils.instantiateClass(constructorToUse) 如果要依赖其他 Bean 呢？那如果 CircularServiceA 依赖了其他 Bean 呢？ 12345678910111213@Servicepublic class CircularServiceA &#123; private String fieldA = "字段 A"; @Autowired private CircularServiceB circularServiceB;&#125;@Servicepublic class CircularServiceB &#123;&#125; 当 A 依赖了 B 的时候，在 createBeanInstance 这一步，并不会对 B 进行属性赋值。而是在 populateBean 这里查找依赖项，并创建 B 依赖循环下的创建过程循环依赖的场景如下： 1234567891011121314@Servicepublic class CircularServiceA &#123; private String fieldA = "字段 A"; @Autowired private CircularServiceB circularServiceB;&#125;@Servicepublic class CircularServiceB &#123; @Autowired private CircularServiceA circularServiceA;&#125; 在 A 和 B 循环依赖的场景中： B populateBean 查找依赖项 A 的时候，从一级缓存中虽然未获取到 A，但是发现 A 在创建中。 此时，从三家缓存中获取 A 的 singletonFactory 调用工厂方法，创建 getEarlyBeanReference A 的早起引用并返回 B 引用到 A，B 就可以初始化完毕，然后 A 同样也可以初始化完毕了 二级缓存能否解决依赖循环通过上面的图，仔细分析一下，其实把二级缓存拿掉，在 B 尝试获取 A 的时候直接返回 A 的实例，是不是也是可以的？ 答案是：可以的 但是为什么还是用三级缓存呢？ 网上的很多资料说是和动态代理有关系，那就从动态代理的方面继续往下分析 动态代理在 JavaConfig（配置类）上添加 EnableAspectJAutoProxy 注解，开启 AOP，通过 Debug 循序渐进看一看动态代理对循环依赖的影响 动态代理下，Bean 的创建过程12345678910111213141516171819@Servicepublic class CircularServiceA &#123; private String fieldA = "字段 A"; public void methodA() &#123; System.out.println("方法 A 执行"); &#125;&#125;@Aspect@Componentpublic class AspectA &#123; @Before("execution(public void com.liuzhihang.circular.CircularServiceA.methodA())") public void beforeA() &#123; System.out.println("beforeA 执行"); &#125;&#125; 只有 A 的情况下，给 A 添加切面，开始 Debug 前面的流程都相同，在 initializeBean 开始出现差异，这一步需要初始化 Bean 并执行 Bean 的后置处理器 其中有一个处理器为：AnnotationAwareAspectJAutoProxyCreator，其实就是加的注解切面，会跳转到 AbstractAutoProxyCreator 类的 postProcessAfterInitialization 方法 如图所示，wrapIfNecessary 方法会判断是否满足代理条件，是的话返回一个代理对象，否则返回当前 Bean 后续调用 getProxy、createAopProxy 等等，最终执行到下面一部分 最终会执行到这里，AOP 代理相关的就不细看了 一路放行，知道 initializeBean 执行结束 此时发现：A 被替换为代理对象 所以 doCreateBean 返回，以及后面放到一级缓存中的都是代理对象 有循环依赖的动态代理这一次把循环依赖打开： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Servicepublic class CircularServiceA &#123; private String fieldA = "字段 A"; @Autowired private CircularServiceB circularServiceB; public void methodA() &#123; System.out.println("方法 A 执行"); &#125;&#125;@Aspect@Componentpublic class AspectA &#123; @Before("execution(public void com.liuzhihang.circular.CircularServiceA.methodA())") public void beforeA() &#123; System.out.println("beforeA 执行"); &#125;&#125;@Servicepublic class CircularServiceB &#123; @Autowired private CircularServiceA circularServiceA; public void methodB() &#123; &#125;&#125;@Aspect@Componentpublic class AspectB &#123; @Before("execution(public void com.liuzhihang.circular.CircularServiceB.methodB())") public void beforeB() &#123; System.out.println("beforeB 执行"); &#125;&#125; 开始 Debug，前面的一些流程，都和正常的没有什么区别。而唯一的区别在于，创建 B 的时候。需要从三级缓存获取 A 此时 getSingleton 方法中会调用：singletonObject = singletonFactory.getoObject() 有时会比较疑惑 singletonFactory.getObject() 调用是哪里？ 所以这一块调用的是 getEarlyBeanReference，开始遍历 BeanPostProcess 看到 wrapIfNecessary 就明白了，这块会获取一个代理对象 也就是说此时返回，并放到二级缓存的是一个 A 的代理对象 这样 B 就创建完毕了。 到 A 开始初始化并执行后置处理器了。因为 A 有代理，所以 A 也会执行到 postProcessAfterInitialization 这一部分 但是在执行 wrapIfNecessary 之前，会先判断代理对象缓存是否有 A 了 this.earlyProxyReferences.remove(cacheKey) != bean 但是这块获取到的是 A 的代理对象，肯定是 false。所以不会再生成一次 A 的代理对象 总结可以看到，依赖循环下，有没有代理情况下的区别就在：singletonObject = singletonFactory.getObject() 在依赖循环发生的情况下 B 中的 A 复制时： 无代理：getObject 直接返回原来的 Bean 有代理：getObject 返回的是代理对象 为什么要三级缓存？ 假设去掉三级缓存去掉三级缓存之后，Bean 直接创建 earlySingletonObjects，看着好像也可以。如果有代理的时候，在 earlySingletonObjects 直接放代理对象就行了 但是会导致一个问题：在实例化阶段旧的执行后置处理器，判断有 AnnotationAwareAspectJAutoProxyCreator 并创建代理对象。这么一想，是不是会对 Bean 的生命周期有影响？ 同样，先创建 singletonFactory 的好处就是：在真是需要实例化的时候，再使用 singletonFactory.getObject() 获取 Bean 或者 Bean 的代理。相当于是延迟实例化 假设去掉二级缓存如果去掉了二级缓存，则需要在 singletonFactory.getObject() 阶段初始化完毕，并放到一级缓存中 那么有一种场景，B 和 C 都依赖了 A 要知道在有代理的情况下，singletonFactory.getObject() 获取的是代理对象 而多次调用 singletonFactory.getObject 返回的代理对象时不同的，就会导致 B 和 C 依赖了不同的 A 那如果 A 获取到 B 之后直接放到一级缓存，然后 C 再获取呢？一级缓存存放的是已经初始化完毕的 Bean，要知道 A 依赖了 B 和 C，A 这时候还没初始化完毕呢]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 依赖循环]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F09%2FSpring-%E4%BE%9D%E8%B5%96%E5%BE%AA%E7%8E%AF%2F</url>
    <content type="text"><![CDATA[什么是依赖循环 Spring IoC 容器会在运行时检测到「构造函数注入」循环依赖，并抛出 BeanCurrentlyInCreationException。所有要避免构造函数注入，可以使用 setter 注入替代 根据官方文档说明，Spring 会自动解决基于 setter 注入的依赖循环，当然我们工作中现在都使用 @Autowired 注解来注入属性。@Autowired 是通过反射进行赋值 我们通过常用的场景切入，看 Spring 是如何解决循环依赖的 123456789101112131415161718192021@Servicepublic class CircularServiceA &#123; @Autowired private CircularServiceB circularServiceB;&#125;@Servicepublic class CircularServiceB &#123; @Autowired private CircularServiceC circularServiceC;&#125;@Servicepublic class CircularServiceC &#123; @Autowired private CircularServiceA circularServiceA;&#125; 这里有 A、B、C 三个类，可以看到发生了循环依赖： 即使是发生了循环依赖，依然可以启动 OK，使用并没有任何影响 Spring 是如何解决循环依赖的在 Spring 的 Bean 的创建中，使用了三级缓存： singletonObjects：一级缓存。存储单例对象，Bean 已经实例化，初始化 earlySingletonObjects：二级缓存。存储 singletonObject，这个 Bean 实例化了，还没有初始化 singletonFactories：三级缓存。存储 singletonFactory 上面的图比较长，我们可以简化一下： 通过 Debug 来说明生成过程从 preInstantiateSingletons 方法开始：添加断点 beanName.equals(&quot;circularServiceA&quot;)。启动 Debug 会从缓存中获取单例 Bean 这里显然获取不到，继续执行，创建单例实例 发现是单例再次获取 这里还会从一级缓存获取一次 circularServiceA，没有获取到，将 circularServiceA 添加到在创建的池子里面（singletonsCurrentlyInCreation 是一个 set 集合） 然后会调用工厂方法 createBean(beanName, mbd, args) 创建对象 在 createBean 中去实例化 Bean 判断是否是循环引用，是的话需要添加到三级缓存中 circularServiceA 不在一级缓存中，则将 circularServiceA 的 singletonFactory 添加到三级缓存（singletonFactories）中，同时从二级缓存中移除 到这一步为止，circularServiceA 已经在三级缓存中了 开始对 Bean 的属性进行赋值 在 populateBean 方法中执行到 1PropertyValues pvsToUse = bp.postProcessProperties(pvs, bw.getWrappedInstance(), beanName); 就会对属性进行赋值 在 inject 方法中，回去解决相关依赖 继续 Debug，发现解决依赖，最后发现其实又调用会 beanFactory.getBean(beanName)。不过这次创建的是 circularServiceB circularServiceB 的过程和 circularServiceA 的一样，也是创建了三级缓存，然后去创建 circularServiceC 这时候三级缓存里面有他们三个的 singetonFactory circularServiceC 也调用到 doCreateBean 方法去获取 circularServiceA，不过这次调用到 Object sharedInstance = getSingleton(beanName) 的时候，circularServiceA 已经存在了 这次调用虽然没有从一级缓存（singletonObjects）中获取到 circularServiceA，但是 circularServiceA 在创建中，所以进入判断 在这里执行后，circularServiceA 从三级缓存升级到二级缓存 使用反射对 circularServiceC 中的 circularServiceA 进行赋值，此时 circularServiceA 是在耳机缓存中 那就比较好奇了，这时候 circularServiceC 里面的 circularServiceA 已经通过反射赋值，这个赋值给的是什么值？ 看代码： 这块是从三级缓存（singletonFactories）中获取的 singletonObject，然后调用 singletonObject = singletonFactory.getObject() 获取的一个对象 这里获取到的是 circularServiceA 的引用，注意，circularServiceA 这时候还没创建完成，只是引用，所以这里赋值的是 circularServiceA 的引用 到这里 circularServiceC 就创建完了 然后会将 C 添加到一级缓存和已注册列表中，同时从二级三级缓存中删除 C 继续执行 B 和 A 的属性赋值以及后续的初始化流程 至此，循环依赖解决完毕 总结Spring 使用三级缓存来解决循环依赖的问题，三级缓存分别是： singletonObjects：一级缓存。存储单例对象，Bean 已经实例化，初始化完成 earlySingletonObjects：二级缓存。存储 singletonObject，这个 Bean 实例化了，还没有初始化 singletonFactories：三级缓存，存储 singletonFactory 转载Spring 是如何解决循环依赖的？]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 单例 Bean 创建]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F08%2FSpring-%E5%8D%95%E4%BE%8B-Bean-%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[本文主要讲解单例 Bean 的创建过程。这里主要分为三个部分创建单例 Bean： getSingleton createBean getObjectForBeanInstance getSingleton我们先看一下 getSingleton的源码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public Object getSingleton(String beanName, ObjectFactory&lt;?&gt; singletonFactory) &#123; Assert.notNull(beanName, "Bean name must not be null"); // 加锁 synchronized (this.singletonObjects) &#123; // 检查 singletonObjects 缓存中是否有 Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; // 检查是否在执行销毁 if (this.singletonsCurrentlyInDestruction) &#123; throw new BeanCreationNotAllowedException(beanName, "Singleton bean creation not allowed while singletons of this factory are in destruction " + "(Do not request a bean from a BeanFactory in a destroy method implementation!)"); &#125; if (logger.isDebugEnabled()) &#123; logger.debug("Creating shared instance of singleton bean '" + beanName + "'"); &#125; // 将 Bean 添加到 singletonsCurrentlyInCreation 集合中, 表示正在创建 beforeSingletonCreation(beanName); boolean newSingleton = false; boolean recordSuppressedExceptions = (this.suppressedExceptions == null); if (recordSuppressedExceptions) &#123; this.suppressedExceptions = new LinkedHashSet&lt;&gt;(); &#125; try &#123; // 调用工厂方法 // 也就是调用 createBean(beanName, mbd, args) singletonObject = singletonFactory.getObject(); newSingleton = true; &#125; catch (IllegalStateException ex) &#123; // Has the singleton object implicitly appeared in the meantime -&gt; // if yes, proceed with it since the exception indicates that state. singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &#123; throw ex; &#125; &#125; catch (BeanCreationException ex) &#123; if (recordSuppressedExceptions) &#123; for (Exception suppressedException : this.suppressedExceptions) &#123; ex.addRelatedCause(suppressedException); &#125; &#125; throw ex; &#125; finally &#123; if (recordSuppressedExceptions) &#123; this.suppressedExceptions = null; &#125; // 创建成功, 从 singletonsCurrentlyInCreation 移除 afterSingletonCreation(beanName); &#125; if (newSingleton) &#123; // 将给定的单例对象添加到该工厂的单例缓存中 // this.singletonObjects.put(beanName, singletonObject); // this.singletonFactories.remove(beanName); // this.earlySingletonObjects.remove(beanName); // this.registeredSingletons.add(beanName); addSingleton(beanName, singletonObject); &#125; &#125; return singletonObject; &#125;&#125; 上面的大概意思是：返回以给定名称注册的（原始）单例对象，如果尚未注册，则创建并注册一个新对象 这一块一共可以拆分为三部分来理解： 1、从 singletonObjects 缓存中获取singletonOjbects 是什么？ 12/** Cache of singleton objects: bean name to bean instance. */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256); singletonObjects 是一个 ConcurrentHashMap，用来缓存单例对象的实例 2、创建 singletonObject如果从缓存中没有获取到 singletonObject，则创建新的对象 1singletonObject = singletonObjects.getOjbect(); 这一步其实是调用外边的 createBean(beanName, mbd, args) 方法，这是一个工厂方法。通过 createBean 方法，会创建一个新的 singletonObject 3、将创建的 singletonObject 添加到缓存中123456789protected void addSingleton(String beanName, Object singletonObject) &#123; synchronized (this.singletonObjects) &#123; this.singletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); this.earlySingletonObjects.remove(beanName); // 已经成功创建的单例 this.registeredSingletons.add(beanName); &#125;&#125; 这一步涉及到三个缓存，以及一个成功创建的单例列表 123456789101112131415/** Cache of singleton objects: bean name to bean instance. *//** 缓存单例对象， K-V -&gt; BeanName - Bean 实例 */private final Map&lt;String, Object&gt; singletonObjects = new ConcurrentHashMap&lt;&gt;(256);/** Cache of singleton factories: bean name to ObjectFactory. *//** 缓存 Bean 工厂 */private final Map&lt;String, ObjectFactory&lt;?&gt;&gt; singletonFactories = new HashMap&lt;&gt;(16);/** Cache of early singleton objects: bean name to bean instance. *//** 缓存早期单例对象 */private final Map&lt;String, Object&gt; earlySingletonObjects = new ConcurrentHashMap&lt;&gt;(16);/** Set of registered singletons, containing the bean names in registration order. *//** 已注册的单例列表，按注册顺序保存 BeanName。 */private final Set&lt;String&gt; registeredSingletons = new LinkedHashSet&lt;&gt;(256); 将创建的单例对象，添加到单例缓存中，同事将工厂缓存以及早期单例对象缓存中的对应对象删除 createBean我们看一下 creaetBean 的源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162protected Object createBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Creating instance of bean '" + beanName + "'"); &#125; RootBeanDefinition mbdToUse = mbd; // Make sure bean class is actually resolved at this point, and // clone the bean definition in case of a dynamically resolved Class // which cannot be stored in the shared merged bean definition. // 获取真实的类型 Class&lt;?&gt; resolvedClass = resolveBeanClass(mbd, beanName); if (resolvedClass != null &amp;&amp; !mbd.hasBeanClass() &amp;&amp; mbd.getBeanClassName() != null) &#123; // 创建新的 mbd 防止 其他线程修改 mbdToUse = new RootBeanDefinition(mbd); mbdToUse.setBeanClass(resolvedClass); &#125; // Prepare method overrides. try &#123; // 验证并准备为此bean定义的方法替代。 检查是否存在具有指定名称的方法。 mbdToUse.prepareMethodOverrides(); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanDefinitionStoreException(mbdToUse.getResourceDescription(), beanName, "Validation of method overrides failed", ex); &#125; try &#123; // Give BeanPostProcessors a chance to return a proxy instead of the target bean instance. // 应用实例化之前的后处理器，以解决指定的bean是否存在实例化快捷方式。 // InstantiationAwareBeanPostProcessor 后置处理器 // postProcessBeforeInstantiation 方法可能会已经实例化 Bean Object bean = resolveBeforeInstantiation(beanName, mbdToUse); if (bean != null) &#123; return bean; &#125; &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbdToUse.getResourceDescription(), beanName, "BeanPostProcessor before instantiation of bean failed", ex); &#125; try &#123; // 实例化 Bean Object beanInstance = doCreateBean(beanName, mbdToUse, args); if (logger.isTraceEnabled()) &#123; logger.trace("Finished creating instance of bean '" + beanName + "'"); &#125; return beanInstance; &#125; catch (BeanCreationException | ImplicitlyAppearedSingletonException ex) &#123; // A previously detected exception with proper bean creation context already, // or illegal singleton state to be communicated up to DefaultSingletonBeanRegistry. throw ex; &#125; catch (Throwable ex) &#123; throw new BeanCreationException( mbdToUse.getResourceDescription(), beanName, "Unexpected exception during bean creation", ex); &#125;&#125; 这个方法涉及到：创建 Bean 实例、填充 Bean、应用 PostProcessor 其中实例化 Bean 是在 doCreateBean 中。现在重点看一下 doCreateBean 方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116protected Object doCreateBean(String beanName, RootBeanDefinition mbd, @Nullable Object[] args) throws BeanCreationException &#123; // Instantiate the bean. // Bean 的 对象包装 BeanWrapper instanceWrapper = null; if (mbd.isSingleton()) &#123; // 从缓存中获取 instanceWrapper = this.factoryBeanInstanceCache.remove(beanName); &#125; if (instanceWrapper == null) &#123; // 缓存中获取不到则直接创建, 这里创建的 BeanInstance !!! instanceWrapper = createBeanInstance(beanName, mbd, args); &#125; // 获取 Bean 实例以及类型 Object bean = instanceWrapper.getWrappedInstance(); Class&lt;?&gt; beanType = instanceWrapper.getWrappedClass(); if (beanType != NullBean.class) &#123; mbd.resolvedTargetType = beanType; &#125; // Allow post-processors to modify the merged bean definition. synchronized (mbd.postProcessingLock) &#123; if (!mbd.postProcessed) &#123; try &#123; // 如果允许修改 mbd // 调用 MergedBeanDefinitionPostProcessor 后置处理器的 // postProcessMergedBeanDefinition(mbd, beanType, beanName); applyMergedBeanDefinitionPostProcessors(mbd, beanType, beanName); &#125; catch (Throwable ex) &#123; throw new BeanCreationException(mbd.getResourceDescription(), beanName, "Post-processing of merged bean definition failed", ex); &#125; mbd.postProcessed = true; &#125; &#125; // Eagerly cache singletons to be able to resolve circular references // even when triggered by lifecycle interfaces like BeanFactoryAware. // mbd 是单例 且 允许循环引用, (默认 true) 且在创建 boolean earlySingletonExposure = (mbd.isSingleton() &amp;&amp; this.allowCircularReferences &amp;&amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) &#123; if (logger.isTraceEnabled()) &#123; logger.trace("Eagerly caching bean '" + beanName + "' to allow for resolving potential circular references"); &#125; // 先获取 之前的 Bean 的引用, 从 beanPostProcessorCache 中 获取 SmartInstantiationAwareBeanPostProcessor // 然后从 SmartInstantiationAwareBeanPostProcessor#getEarlyBeanReference 获取之前的引用 addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); &#125; // Initialize the bean instance. Object exposedObject = bean; try &#123; // 属性赋值 populateBean(beanName, mbd, instanceWrapper); // 执行 init 方法 exposedObject = initializeBean(beanName, exposedObject, mbd); &#125; catch (Throwable ex) &#123; if (ex instanceof BeanCreationException &amp;&amp; beanName.equals(((BeanCreationException) ex).getBeanName())) &#123; throw (BeanCreationException) ex; &#125; else &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Initialization of bean failed", ex); &#125; &#125; // 这里允许循环依赖 if (earlySingletonExposure) &#123; // 获取早期的 Bean, 如果没有循环依赖 则获取不到 Object earlySingletonReference = getSingleton(beanName, false); // 有循环依赖 if (earlySingletonReference != null) &#123; // 创建的是不是同一个，可能会有代理对象 if (exposedObject == bean) &#123; exposedObject = earlySingletonReference; &#125; else if (!this.allowRawInjectionDespiteWrapping &amp;&amp; hasDependentBean(beanName)) &#123; // 获取依赖的 Bean 并 循环放入到 actualDependentBeans String[] dependentBeans = getDependentBeans(beanName); Set&lt;String&gt; actualDependentBeans = new LinkedHashSet&lt;&gt;(dependentBeans.length); for (String dependentBean : dependentBeans) &#123; if (!removeSingletonIfCreatedForTypeCheckOnly(dependentBean)) &#123; actualDependentBeans.add(dependentBean); &#125; &#125; if (!actualDependentBeans.isEmpty()) &#123; throw new BeanCurrentlyInCreationException(beanName, "Bean with name '" + beanName + "' has been injected into other beans [" + StringUtils.collectionToCommaDelimitedString(actualDependentBeans) + "] in its raw version as part of a circular reference, but has eventually been " + "wrapped. This means that said other beans do not use the final version of the " + "bean. This is often the result of over-eager type matching - consider using " + "'getBeanNamesForType' with the 'allowEagerInit' flag turned off, for example."); &#125; &#125; &#125; &#125; // Register bean as disposable. try &#123; // 注册销毁方法 registerDisposableBeanIfNecessary(beanName, bean, mbd); &#125; catch (BeanDefinitionValidationException ex) &#123; throw new BeanCreationException( mbd.getResourceDescription(), beanName, "Invalid destruction signature", ex); &#125; return exposedObject;&#125; 同样是代码很长，分步骤阅读： 如果这个 Bean 是单例 Bean 且允许循环使用且在创建中，则说明有循环引用。则调用： 1addSingletonFactory(beanName, () -&gt; getEarlyBeanReference(beanName, mbd, bean)); 这一行代码涉及到两个方法，分别是 getEarlyBeanReference 和 addSingletonFactory。源码如下： • getEarlyBeanReference • addSingletonFactory 这一块可以看到将创建的一个单例对象的 singletonFactory 添加到了 singletonFactories 缓存中，同时将 earlySingletonObjects 缓存中的单例对象移除 那什么时候添加到 earlySingletonObjects 缓存中呢？ 在这里将缓存从 singletonFactories 移到了 earlySingletonObjects Spring 的 Bean 实例化的时候用到的三级缓存是： singletonObjects：一级缓存，存储单例对象。Bean 已经实例化，初始化完成 earlySingletonObjects：二级缓存，存储 singletonObject，这个 Bean 实例化了，还没有初始化 singletonFactories：三级缓存，存储 singletonFactory 接着会初始化 Bean。重点关注下面一部分： • populateBean 对 Bean 的属性进行赋值 这块需要注意的是，在对属性进行赋值，发现依赖了其他 Bean，就会去先创建其他 Bean。我这边使用的注解 @Autowired 就会执行下面一部分： 在这里解析属性的时候，就会去创建内部依赖的 Bean getObjectForBeanInstance获取给定的 bean 实例对象，如果是 FactoryBean，则为 bean 实例本身或其创建的对象 这一块逻辑相对比较简单，就是根据前面你创建的 beanInstance，判断其类型，从而创建 Bean 实例 总结]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前缀和技巧]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F08%2F%E5%89%8D%E7%BC%80%E5%92%8C%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[前缀和技巧适用于快速计算一个索引区间内的元素之和 这道题 303.区域和检索 - 数组不可变 就是前缀和的基本使用场景： 题目要求你实现这样一个类： 12345678910class NumArray &#123; public NumArray(int[] nums) &#123; &#125; public int sumRange(int left, int right) &#123; &#125;&#125; sumRange 函数需要计算并返回一个索引区间之内的元素和，没学过前缀和的人可能写出如下代码： 12345678910111213141516class NumArray &#123; private int[] nums; public NumArray(int[] nums) &#123; this.nums = nums; &#125; public int sumRange(int left, int right) &#123; int res = 0; for (int i = left; i &lt;= right; i++) &#123; res += nums[i]; &#125; return res; &#125;&#125; 这样可以达到效果，但是效率很差，因为 sumRange 的时间负责度是 O(N)，其中 N 代表 nums 数组的长度 这道题的最优解法是使用前缀和技巧，将 sumRange 函数的时间复杂度降为 O(1) 前缀和技巧如何运用前缀和技巧？我们说要将 sumRange 函数的时间复杂度降为 O(1)，说白了就是不要在 sumRange 里面用 for 循环，如何实现？直接看代码，如下： 12345678910111213141516171819class NumArray &#123; // 前缀和数组 private int[] preSum; /* 输入一个数组，构造前缀和 */ public NumArray(int[] nums) &#123; preSum = new int[nums.length + 1]; // 计算 nums 的累加和 for (int i = 1; i &lt; preSum.length; i++) &#123; preSum[i] = preSum[i - 1] + nums[i - 1]; &#125; &#125; /* 查询闭区间 [left, right] 的累加和 */ public int sumRange(int left, int right) &#123; return preSum[right + 1] - preSum[left]; &#125;&#125; 核心思路是 new 一个新的数组 preSum 出来，preSum[i] 记录 nums[0...i-1] 的累加和，如下图：10 = 5 + 3 + 2 看到这个 preSum 数组，如果我想求索引区间 [1, 4] 内的所有元素之和，就可以通过 preSum[5] - preSum[1] 得出。这样，sumRange 函数仅仅需要做一次减法运算，避免了每次进行 for 循环调用，最坏时间复杂度为常数 O(1) 这个技巧用在 生活中运用也挺广泛的，比如说，你们班上有若干个同学，每个同学有一个期末考试的成绩（满分 100 分），那么请实现一个 API，输入任意一个分数段，返回有多少同学的成绩在这个分数内 那么，你可以先通过技术排序的方式计算每个分数具体有多少个同学，然后利用前缀和技巧来实现分数查询的 API： 1234567891011int[] scores; // 存储着所有同学的分数// 试卷满分 100 分int[] count = new int[100 + 1]// 记录每个分数有几个同学for (int score : scores) count[score]++// 构造前缀和for (int i = 1; i &lt; count.length; i++) count[i] = count[i] + count[i-1];// 利用 count 这个前缀和数组进行分数段查询 相关题目560. 和为 K 的子数组 304. 二维区域和检索 - 矩阵不可变 304 这道题，题目给的是一个二维数组 matrix，那么你可以构造一个二维的前缀和数组 preSum，然后 preSum[i][j] 就记录 matrix[0..i][0..j] 的和 题目让你算 (x1, y1, x2, y2) 这个的矩形的和，相当于图中红色矩形之和减去绿色矩形减去蓝色矩形最后加上黄色矩形的和，而红绿蓝黄这几个矩形的和都是在你的 preSum 里面记录着的。 参考资料公众号 ：labuladong]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[差分数组技巧]]></title>
    <url>%2FCKING.github.io%2F2021%2F09%2F08%2F%E5%B7%AE%E5%88%86%E6%95%B0%E7%BB%84%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[本文将一个和前缀和思想非常类似的算法技巧：差分数组。前缀和主要适用的场景是原始数组不会被修改的情况下，频繁查询某个区间的累加和；而差分数组主要适用场景是频繁对原始数组的某个区间的元素进行增减 比如，我给你输入一个数组 nums，然后要求给区间 nums[2..6] 全部加 1，再给 nums[3..9] 全部减 3，再给 nums[0..4] 全部加 2，再给.. 一通操作之后，然后问你，最后 nums 数组的值是什么？ 常规的思路很简单，你让我给区间 nums[i..j] 加上 val，那我就一个 for 循环给它们都加上呗 12345void increment(int[] nums, int i, int j, int val) &#123; for (int k = i; k &lt;= j; k++) &#123; nums[k] += val; &#125;&#125; 这种思路的时间复杂度是 O(N)，由于这个场景下对 nums 的修改非常频繁，所以效率会很低下，而我们差分数组技巧可以一个差分数组，使得这个操作的时间复杂度为 O(1) 差分数组的实现这里就需要差分数组的技巧，类似前缀和技巧构造的 preSume 数组，我们先对 nums 数组构造一个 diff 差分数组，diff[i] 就是 nums[i] 和 nums[i - 1] 之差 123456int[] diff = new int[nums.length];// 构造差分数组diff[0] = nums[0];for (int i = 1; i &lt; nums.length; i++) &#123; diff[i] = nums[i] - nums[i - 1];&#125; 通过这个 diff 差分数组是可以反推出原始数组 nums 的，代码逻辑如下： 123456int[] res = new int[diff.length];// 根据差分数组构造结果数组res[0] = diff[0];for(int i = 1; i &lt; diff.length; i++) &#123; res[i] = res[i - 1] + diff[i];&#125; 这样构造差分数组 diff，就可以快速进行区间增减的操作。如果你想对区间 nums[i..j] 的元素全部加 3，那么只需要让 diff[i] += 3，然后再让 diff[j + 1] -= 3 即可 原理很简单，回想 diff 数组反推 nums 数组的过程，diff[i] += 3 以为这给 nums[i..] 所有的元素都加了 3，然后 diff[j + 1] -= 3 又意味着对于 nums[j + 1..] 所有元素再减 3，那综合起来，是不是就是对 nums[i, j] 中的所有元素都加 3 了？ 只要花费 O(1) 的时间修改 diff 数组，就相当于给 nums 整个区间做了修改，多次修改 diff，然后通过 diff 数组反推，即可得到 nums 修改后的结果 我们现在把差分数组抽象成一个类，包含 increment 方法和 result 方法： 1234567891011121314151617181920212223242526272829303132class Difference &#123; // 差分数组 private int[] diff; public Difference(int[] nums) &#123; assert nums.length &gt; 0; diff = new int[nums.length]; // 构造差分数组 diff[0] = nums[0]; for (int i = 1; i &lt; nums.length; i++) &#123; diff[i] = nums[i] - nums[i - 1]; &#125; &#125; /* 给闭区间 [i,j] 增加 val 或减少 val（val 是负数） */ public void increment(int i, int j, int val) &#123; diff[i] += val; if (j + 1 &lt; diff.length) &#123; diff[j + 1] -= val; &#125; &#125; public int[] result() &#123; int[] res = new int[diff.length]; // 根据差分数组构造结果数组 res[0] = diff[0]; for (int i = 1; i &lt; diff.length; i++) &#123; res[i] = res[i - 1] + diff[i]; &#125; return res; &#125;&#125; 这里注意一下 increment 方法中的 if 语句： 123456public void increment(int i, int j, int val) &#123; diff[i] += val; if (j + 1 &lt; diff.length) &#123; diff[j + 1] -= val; &#125;&#125; 当 j + 1 &gt;= diff.length 时，说明是对 nums[i] 及以后的整个数组都进行修改，那么就不需要再给 diff 数组减 val 了 差分数组的应用我们看一到力扣 1094. 拼车 说白了，题目就是让你对一个初始全为 0 的数组进行区间操作嘛，可以利用差分数组技巧解决这个问题 还有一道力扣第 1109 题 航班预定统计 这个题目就在那绕弯弯，其实它就是个差分数组的题，翻译一下就是： 给你输入一个长度为 n 的数组 nums，其中所有元素都是 0.再给你输入一个 bookings，里面都是若干三元组 (i, j, k)，每个三元组的含义就是要求你给 nums 数组的闭区间 [i - 1, j - 1] 中所有元素都加上 k，请你返回最后的 nums 数组是多少 PS：因为题目说的 n 是从 1 开始计数的，而数组索引是从 0 开始，所以对于输入的三元组 (i, j, k)，数组区间应该对应 [i - 1, j - 1] 这一看，不就是一道标准的差分数组提吗？ 参考资料公众号 ：labuladong]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Ioc 容器初始化]]></title>
    <url>%2FCKING.github.io%2F2021%2F08%2F11%2FSpring-Ioc-%E5%AE%B9%E5%99%A8%E5%88%9D%E5%A7%8B%E5%8C%96%2F</url>
    <content type="text"><![CDATA[思维导图![Spring Ioc 容器初始化](Spring-Ioc-容器初始化/Spring Ioc 容器初始化.png) Ioc 是如何工作的如下代码所示，通过 ApplicationContext 创建 Spring 容器，该容器会读取配置文件 /beans.xml，并统一管理由该文件中定义好的 bean 实例对象，如果要获取某个 bean 实例，使用 getBean 方法就行。假设将 User 配置在 beans.xml 文件中，之后不需要使用 new User() 的方式创建实例，而是通过 ApplicationContext 容器来获取 User 的实例 12ApplicationContext appContext = new ClassPathXmlApplicationContext("/beans.xml");User p = (User) appContext.getBean("user"); 下面就来看一下创建 IoC 容器经历的几个阶段：Resource 定位、载入 BeanDefinition、将 BeanDefinition 注册到容器 Resource 定位Resource 是 Spring 用于封装 I/O 操作的接口。在创建 Spring 容器时，回去访问 XML 配置文件，还可以通过文件类型、二进制流、URL 等方式访问资源。这些都可以理解为 Resource FileSystemResource：以文件绝对路径进行资源访问 ClassPathResource：以类路径的方式访问资源 ServletContextResource：web 应用根目录的方式访问资源 URLResource：访问网络资源的实现类 ByteArrayResource：访问字节数组资源的实现类 那么这些类型在 Spring 中时如何访问的呢？Spring 提供了 ResourceLoader 接口用于实现不同的 Resource 加载策略，该接口的实例对象中可以获取一个 resource 对象。如下所示，在 ResourceLoader 接口中只定义了两个方法： 12345678public interface ResourceLoader &#123; // 通过提供的资源 location 参数获取 Resource 实例 Resource getResource(String location); // 获取 ClassLoader，通过 ClassLoader 可将资源载入 JVM @Nullable ClassLoader getClassLoader();&#125; 注意，ApplicationContext 的所有实现类都实现 ResourceLoader 接口，因此可以直接调用 getResource（参数）获取 Resource 对象。不同的 ApplicationContext 实现类使用 getResource 方法取得的资源类型不同。例如： FileSystemXMLApplicationContext.getResource 获取的就是 FileSystemResource 实例 ClassPathXMLApplicationContext.getResource 获取的就是 ClassPathResource 实例 XmlWebApplicationContext.getResource 获取的就是 ClassPathResource 实例 另外像不需要通过 xml 直接使用注解 @Configuration 方式加载资源的 AnnotationConfigApplicationContext 等等 在资源定位过程完成以后，就为资源文件中的 bean 的载入创造了 I/O 操作的条件，如何读取资源中的数据将会在下一步介绍的 BeanDefinition 的载入过程中描述 载入 BeanDefinitionBeanDefinition 是一个数据结构，BeanDefinition 的根据 resource 对象中的 bean 来生成的。bean 会在 Spring IoC 容器内部以 BeanDefinition 的形式存在，IoC 容器对 bean 的管理和依赖注入的实现是通过操作 BeanDefinition 来完成的。BeanDefinition 就是 Bean 在 IoC 容器中的存在形式 由于 Spring 的配置文件主要是 XML 格式，一般而言会使用到 AbstractXMLApplicationContext 类进行文件的读取。如下所示，该类定义了一个名为 loadBeanDefitions(DefaultListableBeanFactory beanFactory) 的方法用于获取 BeanDefinition 12345678910// 该方法属于 AbstractXMLApplicationContext 类protected void loadBeanDefinitions(DefaultListableBeanFactory beanFactory) throws BeansException, IOException &#123; XmlBeanDefinitionReader beanDefinitionReader = new XmlBeanDefinitionReader(beanFactory); beanDefinitionReader.setEnvironment(this.getEnvironment()); beanDefinitionReader.setResourceLoader(this); beanDefinitionReader.setEntityResolver(new ResourceEntityResolver(this)); this.initBeanDefinitionReader(beanDefinitionReader); // 用于获取 BeanDefinition this.loadBeanDefinitions(beanDefinitionReader);&#125; 接下来以 XMLBeanDefinitionReader 对象载入 BeanDefinition 为例。如下代码，调用 loadBeanDefinitions 方法传入对象，分别加载 configResources（定位到的资源位置）和 configLocation（本地配置文件的位置），也就是将用户定义的资源以及容器本身需要的资源全部加载到 reader 中 1234567891011121314151617// 该方法属于 AbstractXMLApplicationContext 类protected void loadBeanDefinitions(XmlBeanDefinitionReader reader) throws BeansException, IOException &#123; // 获取所有定位到的 resource 资源位置（用户定义） Resource[] configResources = this.getConfigResources(); if (configResources != null) &#123; // 载入 resources reader.loadBeanDefinitions(configResources); &#125; // 获取所有本地配置文件的位置（容易自身） String[] configLocations = this.getConfigLocations(); if (configLocations != null) &#123; // 载入 resources reader.loadBeanDefinitions(configLocations); &#125;&#125; 顺着看 reader 中的 loadBeanDefinitions 方法，该方法 override 了 AbstractBeanDefinitionReader 类，父接口的 BeanDefinitionReader。方法体中，将所有资源全部加载，并且交给 AbstractBeanDefinitionReader 的实现子类处理这些 resource 123456789101112131415// 该方法属于 AbstractBeanDefinitionReader 类，父接口 BeanDefinitionReaderpublic int loadBeanDefinitions(Resource... resources) throws BeanDefinitionStoreException &#123; Assert.notNull(resources, "Resource array must not be null"); int count = 0; Resource[] var3 = resources; int var4 = resources.length; for(int var5 = 0; var5 &lt; var4; ++var5) &#123; Resource resource = var3[var5]; // 将所有资源全部加载，交给 AbstractBeanDefinitionReader 的实现子类处理这些 resource count += this.loadBeanDefinitions((Resource)resource); &#125; return count;&#125; 如下所示，BeanDefinitionReader 接口定义了 int loadBeanDefinitions(Resource resource) 方法 123int loadBeanDefinitions(Resource var1) throws BeanDefinitionStoreException;int loadBeanDefinitions(Resource... var1) throws BeanDefinitionStoreException; 此时回到 XMLBeanDefinitionReader 上来，它主要针对 XML 方式的 Bean 进行读取，XMLBeanDefinitionReader 主要是实现了 AbstractBeanDefinitionReader 抽象类，而该类继承于 BeanDefinitionReader，主要实现的方法也是来自于 BeanDefinitionReader 的 loadBeanDefinitions(Resource) 方法 如下代码所示，读取 Bean 之后就是加载 Bean 的过程，XMLBeanDefinitionReader 中的 doLoadBeanDefinitions 方法主要来处理加载 Bean 的工作。首先对资源进行验证，然后从资源对象中加载了 Document 对象，使用了 documentLoader 中的 loadDocument 方法，然后跟上 registerBeanDefinitions 对文档对应的 resource 进行注册，也就是将 XML 文件中的 Bean 转换成容器中的 BeanDefinition 1234567891011121314151617protected int doLoadBeanDefinitions(InputSource inputSource, Resource resource) throws BeanDefinitionStoreException &#123; try &#123; // 从资源对象中加载 Document 对象。大致过程为：将 resource 资源文件的内容读入到 document 中 // DocumentLoader 在容器读取 XML 文件过程中有着举足轻重的作用 // XMLBeanDefinitionReader 实例化会创建一个 DefaultDocumentLoader 型的私有属性，继而调用 loadDocument 方法 // inputSource -- 要加载的文档的输入源 Document doc = this.doLoadDocument(inputSource, resource); // 将 document 文件的 bean 封装成 BeanDefinition，并注册到容器 int count = this.registerBeanDefinitions(doc, resource); if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Loaded " + count + " bean definitions from " + resource); &#125; return count; &#125; catch ...(略) &#123;&#125; 接着就是 registerBeanDefinitions方法了，它主要对 Spring Bean 语义进行转化，变成 BeanDefinition 类型。首先获取 DefaultBeanDefinitionDocumentReader 实例，然后获取容器中的 bean 数量，通过 documentReader 中的 registerBeanDefinitions 方法进行注册和转化工作 123456789// 属于 XMLBeanDefinitionReader 类public int registerBeanDefinitions(Document doc, Resource resource) throws BeanDefinitionStoreException &#123; // 获取到 DefaultBeanDefinitionDocumentReader 实例 BeanDefinitionDocumentReader documentReader = this.createBeanDefinitionDocumentReader(); // 获取容器中 bean 的数量 int countBefore = this.getRegistry().getBeanDefinitionCount(); documentReader.registerBeanDefinitions(doc, this.createReaderContext(resource)); return this.getRegistry().getBeanDefinitionCount() - countBefore;&#125; 顺着上面的思路往下，在 DefaultBeanDefinitionDocumentReader 中的 registerBeanDefinitions 方法如下代码所示，其中获取 document 的根节点然后顺势访问所有的子节点。同时把处理 BeanDefinition 的过程委托给 BeanDefinitionParserDelegate 对象来完成 123456789101112131415161718192021222324protected void doRegisterBeanDefinitions(Element root) &#123; BeanDefinitionParserDelegate parent = this.delegate; // 处理 BeanDefinition 的过程委托给 BeanDefinitionParserDelegate 实例对象来完成 this.delegate = this.createDelegate(this.getReaderContext(), root, parent); if (this.delegate.isDefaultNamespace(root)) &#123; String profileSpec = root.getAttribute("profile"); if (StringUtils.hasText(profileSpec)) &#123; String[] specifiedProfiles = StringUtils.tokenizeToStringArray(profileSpec, ",; "); if (!this.getReaderContext().getEnvironment().acceptsProfiles(specifiedProfiles)) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Skipped XML bean definition file due to specified profiles [" + profileSpec + "] not matching: " + this.getReaderContext().getResource()); &#125; return; &#125; &#125; &#125; this.preProcessXml(root); // 核心方法，代理 this.parseBeanDefinitions(root, this.delegate); this.postProcessXml(root); this.delegate = parent;&#125; BeanDefinitionParserDelegate 类主要负责 BeanDefinition 的解析。BeanDefinitionParserDelegate 代理类会完成对符合 Spring Bean 语义规则的处理，比如 、、 等的监测。如下，就是 BeanDefinitionParserDelegate 代理类中的 parseBeanDefinitions 方法，用来对 XML 文件中的节点进行解析。通过遍历 import 标签节点调用 importBeanDefinitionResource 方法对其进行处理，然后接着对 Bean 节点调用 processBeanDefinition 对其处理 1234567891011121314151617181920212223protected void parseBeanDefinitions(Element root, BeanDefinitionParserDelegate delegate) &#123; if (delegate.isDefaultNamespace(root)) &#123; NodeList nl = root.getChildNodes(); // 遍历所有节点，做对应解析工作 // 如遍历到&lt;import&gt;标签节点就调用 importBeanDefinitionResource(ele)方法对其处理 // 遍历到 &lt;bean&gt; 标签就调用 processBeanDefinition(ele, delegate) 方法对应处理 for(int i = 0; i &lt; nl.getLength(); ++i) &#123; Node node = nl.item(i); if (node instanceof Element) &#123; Element ele = (Element)node; if (delegate.isDefaultNamespace(ele)) &#123; this.parseDefaultElement(ele, delegate); &#125; else &#123; // 对应用户自定义节点处理方法 delegate.parseCustomElement(ele); &#125; &#125; &#125; &#125; else &#123; delegate.parseCustomElement(root); &#125;&#125; 再看 parseBeanDefinitions 方法中调用的 parseDefaultElement 方法，顾名思义它是对节点元素进行处理的，从方法体的语句可以看出它对 import 标签、alias 便签、bean 标签进行了处理。每类便签对应不同的 BeanDefinition 的处理方法 12345678910111213141516private void parseDefaultElement(Element ele, BeanDefinitionParserDelegate delegate) &#123; // 解析 &lt;import&gt; 标签 if (delegate.nodeNameEquals(ele, "import")) &#123; this.importBeanDefinitionResource(ele); // 解析 &lt;alias&gt; 标签 &#125; else if (delegate.nodeNameEquals(ele, "alias")) &#123; this.processAliasRegistration(ele); // 解析 &lt;bean&gt; 标签 &#125; else if (delegate.nodeNameEquals(ele, "bean")) &#123; this.processBeanDefinition(ele, delegate); // 解析 &lt;beans&gt; 标签 &#125; else if (delegate.nodeNameEquals(ele, "beans")) &#123; this.doRegisterBeanDefinitions(ele); &#125;&#125; 在 parseDefaultElement 调用的众多方法中，我们选取 processBeanDefinition 方法给大家讲解。如下代码所示，该方法是用来处理 Bean 的。首先通过 delegate 的 parseBeanDefinitionElement 方法传入节点信息，获取该 Bean 对应的 name 和 alias。然后通过 BeanDefinitionReaderUtils 中的 registerBeanDefinition 方法对其进行容器注册，也就是将 Bean 实例注册到容器中进行管理。最后，发送注册事件 1234567891011121314151617protected void processBeanDefinition(Element ele, BeanDefinitionParserDelegate delegate) &#123; // 该对象持有 BeanDefinition 的 name 和 alias，可以使用该对象完成 BeanDefinition 向容器的注册 BeanDefinitionHolder bdHolder = delegate.parseBeanDefinitionElement(ele); if (bdHolder != null) &#123; bdHolder = delegate.decorateBeanDefinitionIfRequired(ele, bdHolder); try &#123; // 注册最终被修饰的 bean 实例，下文注册 BeanDefinition 到容器会讲解该方法 BeanDefinitionReaderUtils.registerBeanDefinition(bdHolder, this.getReaderContext().getRegistry()); &#125; catch (BeanDefinitionStoreException var5) &#123; this.getReaderContext().error("Failed to register bean definition with name '" + bdHolder.getBeanName() + "'", ele, var5); &#125; this.getReaderContext().fireComponentRegistered(new BeanComponentDefinition(bdHolder)); &#125;&#125; 至此完成 BeanDefinition 的加载工作 将 BeanDefinition 注册到容器在加载了 Bean 之后，就需要将其注册到容器中用心管理。如下代码，Bean 会被解析成 BeanDefinition 并与 BeanName、Alias 一同封装到 BeanDefinitionHolder 类中，之后 beanFactory.registerBeanDefinition(beanName, bdHolder.getBeanDefinition())，注册到 DefaultListableBeanFactory.BeanDefinitionMap 中。如果客户端需要获取 Bean 对象，Spring 容器会根据注册的 BeanDefinition 信息进行实例化 123456789101112131415161718public static void registerBeanDefinition(BeanDefinitionHolder definitionHolder, BeanDefinitionRegistry registry) throws BeanDefinitionStoreException &#123; String beanName = definitionHolder.getBeanName(); // 注册 BeanDefinition registry.registerBeanDefinition(beanName, definitionHolder.getBeanDefinition()); // 如果有别名的话也注册进去 String[] aliases = definitionHolder.getAliases(); if (aliases != null) &#123; String[] var4 = aliases; int var5 = aliases.length; for(int var6 = 0; var6 &lt; var5; ++var6) &#123; String alias = var4[var6]; registry.registerAlias(beanName, alias); &#125; &#125;&#125; DefaultListableBeanFactory 实现了上面调用 BeanDefaultRegistry 接口的 registerBeanDefinition(beanName, bdHolder.getBeanDefinition()) 方法。如下所示，这一部分的逻辑是向 DefaultListableBeanFactory 对象的 BeanDefinitionMap 中存放 beanDefinition，也就是说 BeanDefinition 都放在 BeanDefinitionMap 中进行管理。当初始化容器进行 bean 初始化时，在 bean 的生命周期分析里必然会在这个 beanDefinitionMap 中获取 beanDefinition 实例 1234567891011121314151617181920212223242526272829303132333435public void registerBeanDefinition(String beanName, BeanDefinition beanDefinition) throws BeanDefinitionStoreException &#123; Assert.hasText(beanName, "Bean name must not be empty"); Assert.notNull(beanDefinition, "BeanDefinition must not be null"); if (beanDefinition instanceof AbstractBeanDefinition) &#123; try &#123; ((AbstractBeanDefinition)beanDefinition).validate(); &#125; catch (BeanDefinitionValidationException var8) &#123; throw new BeanDefinitionStoreException(beanDefinition.getResourceDescription(), beanName, "Validation of bean definition failed", var8); &#125; &#125; // beanDefinitionMap 是个 ConcurrentHashMap 类型数据，用于存放 beanDefinition，它的 key 值是 beanName BeanDefinition existingDefinition = (BeanDefinition)this.beanDefinitionMap.get(beanName); if (existingDefinition != null) &#123; if (!this.isAllowBeanDefinitionOverriding()) &#123; throw new BeanDefinitionOverrideException(beanName, beanDefinition, existingDefinition); &#125; if (existingDefinition.getRole() &lt; beanDefinition.getRole()) &#123; if (this.logger.isInfoEnabled()) &#123; this.logger.info("Overriding user-defined bean definition for bean '" + beanName + "' with a framework-generated bean definition: replacing [" + existingDefinition + "] with [" + beanDefinition + "]"); &#125; &#125; else if (!beanDefinition.equals(existingDefinition)) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("Overriding bean definition for bean '" + beanName + "' with a different definition: replacing [" + existingDefinition + "] with [" + beanDefinition + "]"); &#125; &#125; else if (this.logger.isTraceEnabled()) &#123; this.logger.trace("Overriding bean definition for bean '" + beanName + "' with an equivalent definition: replacing [" + existingDefinition + "] with [" + beanDefinition + "]"); &#125; // 将获取到的 BeanDefinition 放入 Map 中，容器操作使用 bean 时通过这个 HashMap 找到具体的 BeanDefinition this.beanDefinitionMap.put(beanName, beanDefinition); &#125; &#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 事务同步机制]]></title>
    <url>%2FCKING.github.io%2F2021%2F04%2F08%2FSpring-%E4%BA%8B%E5%8A%A1%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[Spring 事务极简介绍Spring 有「声明式事务」和「编程式事务」： 声明式事务只需要提供 Transactional 的注解，然后事务的开启和提交 / 回滚、资源的清理就都由 Spring 来管控，我们只需要关注业务代码即可 编程式事务则需要使用 Spring 提供的模板，如 TransactionTemplate，或者直接使用底层的 PlatformTransactionManager 手动控制提交、回滚 声明式事务最大的优点就是对代码的侵入性小，只需要在方法上加 @Transcational的注解就可以实现事务；编程式事务的最大优点是对事务的管控粒度较细，可以实现代码块级别的事务 前提介绍Spring 把 JDBC 的 Connection 或者 Hibernate 的 Session 等数据库的链接（会话）都统一称为资源。我们知道 Connection 是线程不安全的，同一时刻是不能被多个线程共享的 同一时刻，我们每个线程持有的 Connection 应该是独立的，且都是互不干扰和互不相同的 但是 Spring 管理的 Service、Dao 等都是无状态的单例 Bean，如何保证单例 Bean 里面使用的 Connection 都能够独立？Spring 引入一个类：事务同步管理器 TransactionSynchronizationManager 来解决这个问题。它的做法是内部使用了很多的 ThreadLocal 为不同的事务线程提供了独立的资源副本，并同时维护这些事务的配置属性和运行状态信息（比如强大的事务嵌套、传播属性等） 同步管理器 TransactionSynchronizationManager 是掌管这一切的大脑，它管理的 TransactionSynchronization 是开放给调用者一个非常重要的扩展点 TransactionSynchronizationManager 将 Dao、Service 中影响线程安全的所有 “状态” 都统一抽取到该类中，并用 ThreadLocal 进行封装，这样一来，Dao（基于模板类或资源获取工具类创建的 Dao）和 Service（采用 Spring 事务管理机制）就不用自己来保存一些事务状态了，从而就变成了线程安全的单例对象了 DataSourceUtils在这里我们先介绍一下 DataSourceUtils 这个工具类。在一些场景里，比如使用 Mybatis 的时候，可能无法使用 Spring 提供的模板来达到效果，而是需要直接操作原生 API Connection 那如何拿到这个链接 Connection 呢（这里有个前提：必须保证和当前 Mybatis 线程使用的是同一个链接，这样才接收本事务的控制）。这个事务 DataSourceUtils 这个工具类就闪亮登场了，它提供了这个能力： 1234567891011121314151617181920212223242526272829public abstract class DataSourceUtils &#123; ... public static Connection getConnection(DataSource dataSource) throws CannotGetJdbcConnectionException &#123; ... &#125; ... // 把definition和connection进行一些准备工作~ public static Integer prepareConnectionForTransaction(Connection con, @Nullable TransactionDefinition definition) throws SQLException &#123; ...&#125; // Reset the given Connection after a transaction, // con.setTransactionIsolation(previousIsolationLevel);和con.setReadOnly(false);等等 public static void resetConnectionAfterTransaction(Connection con, @Nullable Integer previousIsolationLevel) &#123; ... &#125; // 该JDBC Connection 是否是当前事务内的链接~ public static boolean isConnectionTransactional(Connection con, @Nullable DataSource dataSource) &#123; ... &#125; // Statement 给他设置超时时间 不传timeout表示不超时 public static void applyTransactionTimeout(Statement stmt, @Nullable DataSource dataSource) throws SQLException &#123; ... &#125; public static void applyTimeout(Statement stmt, @Nullable DataSource dataSource, int timeout) throws SQLException &#123; ... &#125; // 此处可能是归还给连接池，也有可能是close~（和连接池参数有关） public static void releaseConnection(@Nullable Connection con, @Nullable DataSource dataSource) &#123; ... &#125; public static void doReleaseConnection(@Nullable Connection con, @Nullable DataSource dataSource) throws SQLException &#123; ... &#125; // 这个是真close public static void doCloseConnection(Connection con, @Nullable DataSource dataSource) throws SQLException &#123; ... &#125; // 如果链接是代理，会拿到最底层的connection public static Connection getTargetConnection(Connection con) &#123; ... &#125;&#125; getConnection() 这个方法就是从 TransactionSynchronizationManager 里拿到一个现成的 Connection，若没有现成的，会用 DataSource 创建一个链接然后放进去 其实 Spring 不就为 JDBC 提供了这个工具类，还有 Hibernate、JPA、JDO 等提供了类似的工具类 org.springframework.orm.hibernate.SessionFactoryUtils.getSession() org.springframework.orm.jpa.EntityManagerFactoryUtils.getTransactionalEntityManager() org.springframework.orm.jdo.PersistenceManagerFactoryUtils.getPersistenceManager() 问题场景模拟为了更好地解释和说明，此处模拟出这样的一个场景： 12345678910111213141516171819@Slf4j@Servicepublic class HelloServiceImpl implements HelloService &#123; @Autowired private JdbcTemplate jdbcTemplates; @Transactional @Override public Object hello(Integer id) &#123; // 向数据库插入一条记录 String sql = "insert into user(id, name, age) values(" + id + ", 'fsx', 21)"; jdbcTemplate.update(sql); // 做其余的事情，可能抛出异常 System.out.println(1 / 0); return "service hello"; &#125;&#125; 如上 Demo，因为 1 / 0 会报错，因为有事务，所以最终这个插入是不会成功的 1234567891011121314@Transactional@Overridepublic Ojbect hello(Integer id) &#123; // 向数据库插入一条记录 String sql = "insert into user(id, name, age) values(" + id + ", 'fsx', 21)"; jdbcTemplage.update(sql); // 根据id去查询获取总数（若查询到了肯定是 count = 1） String query = "select count(1) from user where id = " + id; Integer count = jdbcTemplate.queryForObject(query, Integer.class); log.info(count.toString()); return "service hello";&#125; 稍微改造一下，按照上面那么写，count 永远是返回 1 的。前面 insert 一条记录，下面是可以立马去查询出来的 下面把它改造如下： 1234567891011121314151617181920212223@Transactional@Overridepublic Ojbect hello(Integer id) &#123; // 向数据库插入一条记录 String sql = "insert into user(id, name, age) values(" + id + ", 'fsx', 21)"; jdbcTemplage.update(sql); // 生产环境，一般会把这些操作交给线程池，这里只是模拟一下效果 new Thread(() -&gt; &#123; String query = "select count(1) from user where id = " + id; Integer count = jdbcTemplate.queryForObject(query, Integer.class); log.info(count.toString()); &#125;).start(); // 把问题放大 try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; return "service hello";&#125; 经过上面的改造，这样我们的 count 的值就永远是 0 了 这个现象是一个非常严重的问题。他可能会出现：刚插入的数据竟然查不到的诡异现象。 解决方案在互联网中，我们经常为了提高吞吐量、程序性能，会使用到异步的方式进行优化、削峰等。因此连接池、线程池得到了大量的应用。比如一个业务处理中，发短信、发微信通知、记录操作日志等这些非主干需求，我们一般都希望都交给线程池去处理而不要干扰主要业务流程，所以上面模拟的现象出现问题的可能性还是蛮高的 上面出现的问题中，我们先给解决方案。我们的诉求是：我们的异步线程执行时，必须确保记录已经持久化到数据库了。因此可以这么处理： 123456789101112131415161718192021222324252627282930@Transactional@Overridepublic Ojbect hello(Integer id) &#123; // 向数据库插入一条记录 String sql = "insert into user(id, name, age) values(" + id + ", 'fsx', 21)"; jdbcTemplage.update(sql); TransactionSynchronizationManager.registerSynchronization(new TransactionSynchronizationAdapter() &#123; // 在事务提交之后执行的代码块（方法），此处使用 TransactionSynchronizationAdapter // 其实在 Spring5 后直接使用接口也很方便 @Override public void afterCommit() &#123; new Thread(() -&gt; &#123; String query = "select count(1) from user where id = " + id; Integer count = jdbcTemplate.queryForObject(query, Integer.class); log.info(count.toString()); &#125;).start(); &#125; &#125;); // 把问题放大 try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; return "service hello";&#125; 我们使用 TransactionSynchronizationManager 注册一个 TransactionSynchronization，然后在 afterCommit 里执行我们的后续代码，这样就能 100% 确保我们的后续逻辑是在当前事务被 commit 后才执行的 TransactionSynchronizationManagerTransactionSynchronizationManager 使用 ThreadLocal 记录事务的一些属性，用于应用扩展同步器的使用，在事务的开启、挂起、提交等各个点上回调应用的逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123public abstract class TransactionSynchronizationManager &#123; // ======保存着一大堆的ThreadLocal 这里就是它的核心存储====== // 应用代码随事务的声明周期绑定的对象 比如：DataSourceTransactionManager有这么做： //TransactionSynchronizationManager.bindResource(obtainDataSource(), txObject.getConnectionHolder()); // TransactionSynchronizationManager.bindResource(obtainDataSource(), suspendedResources); // 简单理解为当前线程的数据存储中心~~~~ private static final ThreadLocal&lt;Map&lt;Object, Object&gt;&gt; resources = new NamedThreadLocal&lt;&gt;("Transactional resources"); // 使用的同步器，用于应用扩展 // TransactionSynchronization同步器是最为重要的一个扩展点~~~ 这里是个set 所以每个线程都可以注册N多个同步器 private static final ThreadLocal&lt;Set&lt;TransactionSynchronization&gt;&gt; synchronizations = new NamedThreadLocal&lt;&gt;("Transaction synchronizations"); // 事务的名称 private static final ThreadLocal&lt;String&gt; currentTransactionName = new NamedThreadLocal&lt;&gt;("Current transaction name"); // 事务是否是只读 private static final ThreadLocal&lt;Boolean&gt; currentTransactionReadOnly = new NamedThreadLocal&lt;&gt;("Current transaction read-only status"); // 事务的隔离级别 private static final ThreadLocal&lt;Integer&gt; currentTransactionIsolationLevel = new NamedThreadLocal&lt;&gt;("Current transaction isolation level"); // 事务是否开启 actual：真实的 private static final ThreadLocal&lt;Boolean&gt; actualTransactionActive = new NamedThreadLocal&lt;&gt;("Actual transaction active"); // 返回的是个只读视图 public static Map&lt;Object, Object&gt; getResourceMap() &#123; Map&lt;Object, Object&gt; map = resources.get(); return (map != null ? Collections.unmodifiableMap(map) : Collections.emptyMap()); &#125; public static boolean hasResource(Object key) &#123; ... &#125; public static Object getResource(Object key) &#123; ... &#125; // actualKey：确定的key 拆包后的 @Nullable private static Object doGetResource(Object actualKey) &#123; Map&lt;Object, Object&gt; map = resources.get(); if (map == null) &#123; return null; &#125; Object value = map.get(actualKey); // Transparently remove ResourceHolder that was marked as void... // 如果ResourceHolder 被标记为了void空白了。此处直接从map里移除掉对应的key // ~~~~~~~并且返回null~~~~~~~~~~~ if (value instanceof ResourceHolder &amp;&amp; ((ResourceHolder) value).isVoid()) &#123; map.remove(actualKey); // Remove entire ThreadLocal if empty... if (map.isEmpty()) &#123; resources.remove(); &#125; value = null; &#125; return value; &#125; // 逻辑很简单，就是和当前线程绑定一个Map，并且处理ResourceHolder 如果isVoid就抛错 public static void bindResource(Object key, Object value) throws IllegalStateException &#123; Object actualKey = TransactionSynchronizationUtils.unwrapResourceIfNecessary(key); Assert.notNull(value, "Value must not be null"); Map&lt;Object, Object&gt; map = resources.get(); // set ThreadLocal Map if none found if (map == null) &#123; map = new HashMap&lt;&gt;(); resources.set(map); &#125; Object oldValue = map.put(actualKey, value); // Transparently suppress a ResourceHolder that was marked as void... if (oldValue instanceof ResourceHolder &amp;&amp; ((ResourceHolder) oldValue).isVoid()) &#123; oldValue = null; &#125; if (oldValue != null) &#123; throw new IllegalStateException("Already value [" + oldValue + "] for key [" + actualKey + "] bound to thread [" + Thread.currentThread().getName() + "]"); &#125; &#125; public static Object unbindResource(Object key) throws IllegalStateException &#123; ... &#125; public static Object unbindResourceIfPossible(Object key) &#123; ... &#125; // 同步器是否是激活状态~~~ 若是激活状态就可以执行同步器里的相关回调方法了 public static boolean isSynchronizationActive() &#123; return (synchronizations.get() != null); &#125; // 如果事务已经开启了，就不能再初始化同步器了 而是直接注册 public static void initSynchronization() throws IllegalStateException &#123; if (isSynchronizationActive()) &#123; throw new IllegalStateException("Cannot activate transaction synchronization - already active"); &#125; logger.trace("Initializing transaction synchronization"); synchronizations.set(new LinkedHashSet&lt;&gt;()); &#125; // 注册同步器TransactionSynchronization 这个非常重要 下面有详细介绍这个接口 // 注册的时候要求当前线程的事务已经是激活状态的 而不是随便就可以调用的哦~~~ public static void registerSynchronization(TransactionSynchronization synchronization) throws IllegalStateException &#123; Assert.notNull(synchronization, "TransactionSynchronization must not be null"); if (!isSynchronizationActive()) &#123; throw new IllegalStateException("Transaction synchronization is not active"); &#125; synchronizations.get().add(synchronization); &#125; // 返回的是只读视图 并且，并且支持AnnotationAwareOrderComparator.sort(sortedSynchs); 这样排序~~ public static List&lt;TransactionSynchronization&gt; getSynchronizations() throws IllegalStateException &#123; ... &#125; public static void clearSynchronization() throws IllegalStateException &#123; ... &#125; ... // 省略name等其余几个属性的get/set方法 因为没有任何逻辑 // 这个方法列出来，应该下面会解释 public static void setActualTransactionActive(boolean active) &#123; actualTransactionActive.set(active ? Boolean.TRUE : null); &#125; // 清楚所有和当前线程相关的（注意：此处只是clear清除，和当前线程的绑定而已~~~） public static void clear() &#123; synchronizations.remove(); currentTransactionName.remove(); currentTransactionReadOnly.remove(); currentTransactionIsolationLevel.remove(); actualTransactionActive.remove(); &#125;&#125; 这里把 setActualTransactionActive 单独拿出来看一下。在 AbstractPlatformTransactionManager.getTransaction() 的时候会调用此方法： 12// 相当于表示事务为开启了TransactionSynchronizationManager.setActualTransactionActive(status.hasTransacation()); 而且该类的 handleExistingTransaction、prepareTransactionStatus 等方法都会调用上面的方法，也就是说它会参与到事务的声明周期里面去 备注：以上方法他们统一的判断条件有：TransactionStatus.isNewTransaction() 是新事务的时候才会调用这个方法进行标记 另外，AbstractPlatformTransactionManager 的 suspend 暂停的时候会直接这么调用： 12TransactionSynchronizationManager.setCurrentTransactionReadOnly(false);TransactionSynchronizationManager.setActualTransactionActive(false); resume 恢复的时候： 12TransactionSynchronizationManager.setCurrentTransactionReadOnly(resourcesHolder.readOnly);TransactionSynchronizationManager.setActualTransactionActive(resourcesHolder.wasActive); 大体可以得出这样的一个处理步骤： 开启新的事务时初始化。第一次开启事务分为：real 首次或已存在事务但是 REQUIRES_NEW 在事务的嵌套过程中，TransactionSynchronizationManager 属性不断更新最终清除。即外层事务挂起、事务提交，这两个点需要更新 TransactionSynchronizationManager 属性 这里面有个内部类 ：AbstractPlatformTransactionManager.SuspendedResourcesHolder。它是负责事务挂起的时候，保存事务属性的对象，用于恢复外层事务。当恢复外层事务时，根据 SuspendedResourcesHolder 对象，调用底层事务框架恢复事务属性，并恢复 TransactionSynchronizationManager DefaultTransactionStatus它实现了 TransactionStatus 接口，这个是整个事务框架最重要的状态对象，它贯穿于事务拦截器，Spring 抽象框架和底层具体事务实现框架之间 它的重要任务就是在新建、挂起、提交事务的过程中保存对应事务的属性，在 AbstractPlatformTransactionManager 中，每个事务流程都会 new 创建这个对象 TransactionSynchronizationUtils这个工具类比较简单，主要是处理 TransactionSynchronizationManager 和执行 TransactionSynchronization 对应的方法们 TransactionSynchronization这个类非常重要，它是我们对事务同步的扩展点，用于事务同步回调的接口，AbstractPlatformTransactionManager 支持它 注意：自定义的同步器可以通过实现 Ordered 接口来自己定制化顺序，若没实现接口就按照添加的顺序执行]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[I/0 多路复用]]></title>
    <url>%2FCKING.github.io%2F2021%2F03%2F29%2FI-0-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%2F</url>
    <content type="text"><![CDATA[最基本的 Socket 模型要想客户端和服务器能在网络中通信，必须要使用 Socket 编程，它是进程间通信里比较特别的方式，特别之处在于它是可以跨主机间通信 Socket 的中文名叫「插口」。事实上，双方要进行网络通信前，各自得创建一个 Socket，这相当于客户端和服务器都开了一个「口子」，双方读取和发送数据的时候，都通过这个口子。这样，是不是觉得很像弄了一根网线，一头插在客户端，一头插在服务器，然后进行通信 创建 Socket 的时候，可以指定网络层使用的是 IPV4 还是 IPV6，传输层使用的是 TCP 还是 UDP。UDP 的 Socket 编程相对简单一些，这里我们只介绍基于 TCP 的 Socket 编程 服务器的程序要先跑起来，然后等待客户端的连接和数据，我们先看服务端的 Socket 编程过程是怎样的 服务端首先调用 socket() 函数，创建网络协议为 IPV4 以及传输协议为 TCP 的 Socket，接着调用 bind() 函数，给这个 Socket 绑定一个 IP 地址和端口，绑定这两个的目的是什么？ 绑定端口的目的：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们 绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们 绑定完 IP 地址和端口后，就可以调用 listen() 函数进行监听，此时对应下面 TCP 状态图中的 listen，如果我们要判定服务器中一个网络程序有没有启动，可以通过 netstat 命令查看对应的端口号是否有被监听 服务端进入监听状态后，通过调用 accept() 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来 那客户端是怎么发起连接的呢？客户端在创建好 Socket 后，调用 connect() 函数发起连接，该函数的参数要指明服务器的 IP 地址和端口号，然后 TCP 三次握手就开始了 在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列： 一个是还没完全建立连接的队列，称为 TCP 半连接队列。这个队列都是没有完成三次握手的连接，此时服务端处于 sync_rcvd 的状态 一个是已经建立连接的队列，称为 TCP 全连接队列。这个队列都是完成了三次握手的连接，此时服务端处于 established 装填 当 TCP 全连接队列不为空后，服务端的 accept() 函数，就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket 注意，监听的 Socket 和真正用来传数据的 Socket 是两个： 一个叫做监听 Socket 一个叫做已连接 Socket 连接建立后，客户端和服务端就开始相互传输数据了，双方都可以通过 read() 和 write() 函数来读写数据 至此，TCP 协议的 Socket 程序的调用过程就结束了，整个过程如下图： 看到这，是不是觉得读写 Socket 的方式，有点像读写文件。是的，基于 Linux 一切皆文件的理念，在内核中 Socket 也是以「文件」的形式存在的，也是有对应的文件描述符 文件描述符的作用是什么？每一个进程都有一个数据结构：task_struct，该结构体里有一个指向「文件描述符数组」的成员指针。该数组里列出这个进程打开的所有文件的文件描述符。数组的下标是文件描述符，是一个整数，而数组的内容是一个指针，指向内核中所有打开的文件的列表，也就是说内核可以通过文件描述符找到对应打开的文件 然后每个文件都有一个 inode，Socket 文件的 inode 指向了内核中的 Socket 结构，在这个结构体里有两个队列，分别是发送队列和接收队列，这两个队列里面保存的是一个个 struct sk_buff，用链表的组织形式串起来 sk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 package，在数据链路层称为 frame 为什么全部数据包只用一个结构体来描述呢？协议栈采用的是分层结构，上层向下层传递数据时需要增加包头，下层向上层传递数据时又需要去掉包头，如果每一层都用一个结构体，那在层之间传递数据的时候，就要发生多次拷贝，这将大大降低 CPU 效率 因此，为了在层级之间传递数据时，不发生拷贝，只用 sk_buff 一个结构体来描述所有的网络包，那它是如果做到的呢？是通过调整 sk_buff 中 data 的指针。比如： 当接收报文时，从网卡驱动开始，通过协议栈层层往上传送数据包，通过增加 skb -&gt; data 的值，来逐步剥离协议首部 当要发送报文的时，创建 sk_buff 结构体，数据缓存区的头部预留足够的空间，用来填充各层首部，在经过各下层协议时，通过减少 skb -&gt; data 的值来增加协议首部 如下图，当发送报文时，data 指针的移动过程 如何服务更多的用户前面提到的 TCP Socket 调用流程是最简单、最基本的，它基本只能一对一通信，因为使用的是同步阻塞的方式，当服务端还没处理完一个客户端的网络 I/O 时，其他客户端是无法与服务端连接的 可如果我们服务器只能服务一个客户，是很浪费资源的，于是我们要改进这个网络 I/O 模型，以支持更多的客户端 在改进网络 I/O 模型前，你知道服务器单机理论最大能连接多少个客户端？其实，TCP 连接是由四元组唯一确认的，这个四元组就是：本机 IP、本地端口、对端 IP、对端端口 服务器作为服务方，通常会在本地固定监听一个端口，等待客户端的连接，因此服务器的本地 IP 和端口是固定的，于是对于服务端 TCP 连接的四元组只有对端 IP 和端口是会变化的，所以最大 TCP 连接数 = 客户端 IP 数 * 客户端端口数 对于 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数约为 2 的 48 次方 这个理论值很丰满，但是服务器肯定承载不了那么大的连接数，主要会受两个方面的限制： 文件描述符。Socket 实际上是一个文件，也就会对应一个文件描述符。在 Linux 下，单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024，不过我们可以通过 ulimit 增大文件描述符的数目 系统内存。每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占用一定内存的 如果服务器的内存只有 2GB，网卡时千兆的，能支持并发 1 万请求吗？并发 1 万请求，也就是经典的 C10K 问题，C 是 Client 单词首字母缩写，C10K 就是单机同时处理 1 万个请求的问题 从硬件资源看，对于 2GB 内存千兆网卡的服务器，如果每个请求处理占用不到 200KB 的内存和 100Kbit 的网络带宽就可以满足并发 1 万个请求 不过，要想真正实现 C10K 的服务器，要考虑的地方在于服务器的网络 I/O 模型，效率低的模型，会加重系统开销，从而会离 C10K 的目标越来越远 多进程模型基于最原始的阻塞网络 I/O，如果服务器要支持多个客户端，其中比较传统的方式，就是使用多进程模型，也就是为每个客户端分配一个进程来处理请求 服务器的主进程负责监听客户的连接，一旦与客户端连接完成，accpet() 函数就会返回一个「已连接 Socket」，这时就通过 fork() 函数创建一个子进程，实际上就把父进程所有相关的东西都复制一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等 这两个进程刚复制完的时候，几乎一模一样。不过，会根据返回值来区分是父进程还是子进程，如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程 正因为子进程会复制父进程的文件描述符，于是就可以直接使用「已连接 Socket」和客户端通信了 可以发现，子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户端交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要个关心「监听 Socket」 如下图，描述了从连接请求到连接建立，父进程创建子进程为客户服 另外，当子进程退出时，实际上内核里还会保留该进程的一些信息，也是会占用内存的，如果不做好「回收」工作，就会变成僵尸进程。随着僵尸进程越来越多，会慢慢耗尽我们的系统资源 因此，父进程要 “善后” 好自己的孩子？怎么善后呢？有两种方式可以在子进程退出后回收资源，分别是调用 wait() 和 waitpid() 函数 这种用多个进程来应付多个客户端的方式，在应对 100 个客户端还是可行的，但是当客户端数量高达一万时，肯定是扛不住的，因为没产生一个进程，必会占据一定的系统资源，而且进程间上下文切换的 “包袱” 是很重的，性能会大打折扣 进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源 多线程模型既然进程间上下文切换的 “包袱“ 很重，那我们就搞个比较轻量级的模型来应对多用户的请求 — 多线程模型 线程是运行在进程中的一个 “逻辑流”，单进程中可以运行多个线程，同进程里的线程可以共享进程的部分资源，比如文件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享资源在上下文切换时是不需要切换，而只需要切换线程的私有数据、寄存器等不共享的数据，因此同一个进程下的线程上下文切换的开销要比进程小得多 当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的 如果每来一个连接就创建一个线程，线程运行完后，操作系统还得销毁线程，虽然线程切换的上下文开销不大，但是频繁创建和销毁线程，系统开销也是不小的 因此，我们卡伊使用「线程池」的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当有新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出已连接 Socket 进程处理 需要注意的是，这个队列是全局的，每个线程都会操作，为了避免多线程竞争，线程在操作这个队列前要加锁 上面基于进程或者线程模型的，其实还有有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程，那么如果要达到 C10K，意味着一台机器要维护 1 万个连接，相当于要维护 1 万个进程 / 线程，操作系统就算死扛也是扛不住的 I/O 多路复用既然为每个请求分配一个进程 / 线程的方式不合适，那有没有可能只使用一个进程来维护多个 Socket 呢？？？答案是有的，那就是 I/O 多路复用技术 一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把这个事件拉长来看，多个请求复用了一个进程，这就是多路复用。这种思想很类似一个 CPU 并发多个进程，所以也就分时多路复用 我们熟悉的 select / poll / epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件 select / poll / epoll 是如何获取网络时间的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可 select / poll / epoll 这三个多路复用接口，都能实现 C10K 吗？我们分别讨论一下 select / pollselect 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件发生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将次 Socket 标记为可读或可写，接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理 所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一次是在用户态里，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出于用户空间中 select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的。在 Linux 系统中，由内核中的 FD_SETSIZE 限制，默认最大值为 1024，只能监听 0 ~ 1023 的文件描述符 poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表的形式来组织，突破了 select 的文件描述符限制个数限制，当然还会受到系统文件描述符限制 但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长 epollepoll 通过两个方面，很好地解决了 select / poll 的问题 第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述符，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树，红黑树是个高效的数据结构，增删查一般时间复杂度是 O(logn)，通过对这棵红黑树进行操作，这样就不需要像 select / poll 每次操作时都传入整个 socket 集合，只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配 第二点，epoll 使用事件驱动的机制，内核了维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪时间列表中，当用户调用 epoll_wait() 函数时，智慧返回有事件发生的文件描述符个数，不需要像 select / poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率 下图你可以看到 epoll 相关的接口作用： epoll 的方式即使监听的 socket 数量越多的时候，效率也不会大幅度降低，能过同时监听的 socket 的数目也非常多，上线就为系统定义的进程打开的最大文件描述符个数。因为，epoll 被称为解决 C10K 问题的利器 插个题外话，网上不少文章说，epoll_wait 返回时，对于就绪的事件，epoll 使用的是共享内存的方式，即用户态和内核态都指向了就绪链表，所以就避免了内存拷贝消耗 这是错的，看过 epoll 内核源码的都知道，压根就没有使用共享内存这个玩意。你可以从下面这份代码看到，epoll_wait 实现的内核代码中调用了 __put_user 函数，这个函数就是将数据从内核拷贝到用户空间 好了，题外话就到这，我们继续 epoll 支持两种时间触发模式，分别是边缘模式（edge-triggered，ET）和水平触发（level-triggered，LT）。它们的区别如下： 使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完 使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们又数据需要读取 举个例子，你的快递被放到了一个快递箱里，如果快递箱只会通过短信通知你一次，即使你一直没有去取，它也不会再发送第二条短信提醒你，这个方式就是边缘触发；如果快递箱发现你的快递没有被取出，它就会不停地发短信通知你，知道你取出了快递，它才消停，这个就是水平触发的方式 这就是两者的区别，水平触发的意思是只要满足事件的条件，比如内核中有数据需要读，就一直不断地把这个事件传递给用户；而边缘触发的意思是只有第一次满足条件的时候才触发，之后就不会再传递同样的事件了 如果使用水平触发 模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写，所以在收到通知后，没必要一次执行尽可能多的读写操作 如果使用边缘触发模式，I/O 事件发生时只会通知一次，而且我们不知道到底能不能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读可写，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I/O 搭配使用，程序会一直执行 I/O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK 一般来说，边缘触发的效率比水平触发的效率要高，以为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的，毕竟也存在上下文的切换 select / poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式 另外，使用 I/O 多路复用时，最好搭配非阻塞 I/O 一起使用，Linux 书册关于 select 的内容中有如下说明： 在 Linux 下，select() 可能会将一个 socket 文件描述符报告为 “准备读取”，而后续的读取块却没有。例如，当数据已经到达，但经检查后发现有错误的校验和而被丢弃时，就会发生这种情况。也有可能在其他情况下，文件描述符被错误地报告为就绪。因此，在不应该阻塞的 socket 上使用 O_NONBLOCK 可能更安全 简单点理解，就是多路复用 API 返回的事件并不一定可读写的，如果使用阻塞 I/O，那么在调用 read / write 时则会发生程序阻塞，因此最好搭配非阻塞 I/O，以便应对极少数的特殊情况 总结最基础的 TCP 的 Socket 编程，它是阻塞 I/O 模型，基本上只能一对一通信，为了服务更多的客户端，我们需要改进网络 I/O 模型 比较传统的方式是使用多进程 / 线程模型，每来一个客户端连接，就分配一个进程 / 线程，然后后续的读写都在对应的进程 / 线程，这种方式处理 100 个客户端没问题，但是当客户端增大到 10000 个时，10000 个进程 / 线程的调度、上下文切换以及它们占用的内存，都会成为瓶颈 为了解决上面的问题，就出现了 I/O 的多路复用，可以只在一个进程里处理多个文件的 I/O，Linux 下提供了三种 I/O 多路复用的 API，分别是：select、poll、epoll select 和 poll 并没有本质区别，它们内部都是使用「线性结构」来存储进程关注的 socket 集合 在使用的时候，首先需要把关注的 socket 集合通过 select / poll 系统调用从用户态拷贝到内核态，然后由内核检测事件，当有网络事件产生时，内核需要遍历进程关注 socket 集合，找到对应的 socket，并设置其状态为可读 / 可写，然后把整个 socket 集合从内核态拷贝到用户态，用户态还要继续遍历整个 socket 集合找到可读 / 可写的 socket，然后对其处理 很明显发现，select 和 poll 的缺陷在于，当客户端越多，也就是 socket 集合越大，socket 集合的遍历和拷贝会带来很大的开销，因此也很难应对 C10K epoll 是解决 C10K 问题的利器，通过两个方面解决了 select / poll 的问题： epoll 在内核里使用「红黑树」来关注进程所有待检测的 socket，红黑树是个高效的数据结构，增删查一般时间复杂度是 O(logn)，通过对这棵红黑树的管理，不需要像 select / poll 在每次操作时都传入整个 socket 集合，减少了内核和用户空间大量的数据拷贝和内存分配 epoll 使用事件驱动的机制，内核里维护了一个「链表」来记录就绪事件，只将有事件发生的 socket 集合传递给应用程序，不需要像 select / poll 那样轮询扫描整个集合（包含有和无事件的 socket），大大提高了检测的效率 而且，epoll 支持边缘触发和水平触发的方式，而 select / poll 只支持水平触发。一般而言，边缘触发的方式会比水平触发的效率高 转载一举拿下 I/O 多路复用]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大规模集群下 Hadoop NameNode 如何承受每秒上千万的高并发访问]]></title>
    <url>%2FCKING.github.io%2F2021%2F02%2F10%2F%E5%A4%A7%E8%A7%84%E6%A8%A1%E9%9B%86%E7%BE%A4%E4%B8%8B-Hadoop-NameNode-%E5%A6%82%E4%BD%95%E6%89%BF%E5%8F%97%E6%AF%8F%E7%A7%92%E4%B8%8A%E5%8D%83%E4%B8%87%E7%9A%84%E9%AB%98%E5%B9%B6%E5%8F%91%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[我们分析一下，高并发请求 NameNode 会遇到什么问题 我们知道，每次请求 NameNode 修改一条元数据（比如说申请上传一个文件，那么就需要在内存目录树种加入一个文件），都要写一条 edits log，包括两个步骤： 写入本地磁盘 通过网络传输给 JournalNodes 集群 但是这存在多线程并发安全问题。NameNode 在写 edits log 时的第一条原则： 必须保证每条 edits log 都有一个全局顺序递增的 transactionId（简称为 txid），这样才可以标识出来一条一条的 edits log 的先后顺序 那么如果要保证每条 edits log 的 txid 都是递增的，就必须要加锁 每个线程修改了元数据，要写一条 edits log 的时候，都必须按顺序排队获取锁后，才能生成一个递增的额 txid，代表了这次要写的 edits log 的序号 如上图，如果每次都是在一个加锁的代码块里，生成 txid，然后写磁盘文件 edits log，网络请求写入 JournalNodes 一条 edits log。这样子是绝对不行的，NameNode 本身用多线程接收多个客户端发送过来的并发请求，结果多个线程居然修改完内存中的元数据之后，排着队写 edits log 而且，写本地磁盘 + 网络传输 JournalNodes 集群，都是很耗时的。性能两大杀手：磁盘写 + 网络写 如果 HDFS 的架构这么设计的话，基本上 NameNode 能承载的每秒的并发数就很少了，可能就每秒处理几十个并发请求处理就撑死了 HDFS 的解决方案针对上述问题，HDFS 是做了不少优化的 首先，既然我们不希望每个线程写 edits log 的时候，串行化排队生成 txid + 写磁盘 + 写 JournalNodes，那么是不是可以搞一个内存缓冲。即，多个线程可以快速地获取锁，生成 txid，然后快速地将 edits log 写入内存缓冲。接着就快速地释放锁，让下一个线程获取锁后，生成 id + 写 edits log 进入内存缓冲 然后接下来有一个线程可以将内存中的 edits log 刷入磁盘，但是在这个过程中，还是继续允许其他线程将 edits log 写入内存缓冲中 但是这里就有一个问题了，如果针对同一块内存缓冲，同时有人写入，还同时有人读取后写磁盘，那也有问题，因为不能并发读写一块共享内存数据 所以 HDFS 在这里采取了 double - buffer 双缓冲机制来处理，将一块内存缓冲分为两个部分： 其中一个部分可以写入 另外一个部分用于读取后写入磁盘和 JournalNodes 如下图： 分段加锁机制 + 内存双缓冲机制首先各个线程依次第一次获取锁，生成顺序递增的 txid，然后将 edits log 写入内存双缓冲的区域 1，接着就立马第一次释放锁了 趁着这个空隙，后面的线程就可以再次第一次获取锁，然后立即写自己的 edits log 到内存缓冲 写内存那么快，可能才耗时即使微秒，接着就立马第一次释放锁了。所以这个并发优化是有效果的 接着各个线程竞争第二次获取锁，有线程获取到锁之后，就看看，有没有谁在写磁盘和网络？如果没有，那么这个线程就是个幸运儿，直接交换双缓冲的区域 1 和 区域 2，接着第二次释放锁。这个过程相当快速，内存里判断几个条件，耗时不了几微秒 到这一步，内存缓冲已经被交换了，后面的线程可以立马快速地依次获取锁，然后将 edits log 写入内存缓冲的区域 2，区域 1 中的数据被锁定了，不能写 多线程并发吞吐量的百倍优化接着，之前那个幸运儿，将内存缓冲区的区域 1 中的数据读取出来（此时没人写区域 1 了，都在写区域 2），将里面的 edits log 都写入磁盘文件，以及通过网络写入 JournalNodes 集群 这个过程是很耗时的，但是没关系，人家做过优化了，在写磁盘和网络的过程中，是不具有锁的 因此后面的线程可以快速地第一次获取锁之后，立马写入内存缓冲的区域 2，然后释放锁。这个时候大量的线程都可以快速地写入内存，没有阻塞和卡顿 缓冲数据批量刷磁盘 + 网络的优化那么在幸运儿线程把数据写磁盘和网络的过程中，排在后面的大量线程，快速地第一次获取锁，写内存缓冲区域 2，释放锁，之后，这些线程第二次获取到锁后会干嘛？ 它们会发现有人在写磁盘，所以会立即休眠 1 秒，释放锁 此时大量的线程并发过来，都会在这里快速地第二次获取锁，然后发现有人在写磁盘和网络，快速地释放锁，休眠 这样，这个过程没有长时间地阻塞其他人，因为都会快速地释放锁，所以后面的线程还是可以迅速地第一次获取锁后写内存缓冲 而且这时，一定会有很多线程发现，好像之前的那个幸运儿的 txid 是排在自己之后的，那么肯定就把自己的 edits log 从缓冲里写入磁盘和网络了。这些线程甚至都不会休眠等待，直接返回后去干别的事情，不会卡在这里 然后按个幸运儿线程写完磁盘和网络之后，就会唤醒之前休眠的那些线程 那些线程会依次排队再第二次获取锁后进入判断，发现没有人在写磁盘和网络了。然后就会判断，有没有排在自己之后的线程已经将自己的 edits log 写入磁盘了。如果有，就直返返回；没有的话，那么就成为第二个幸运儿线程，交换两块缓冲区，区域 1 和区域 2 交换一下，然后释放锁，自己将区域 2 的数据写入磁盘和网络 这个时候，后面的线程如果要写 edits log 的，还是可以第一次获取锁后立马写内存缓冲再释放锁，以此类推 总结这套机制还是挺复杂的，涉及到了分段加锁以及内存双缓冲两个机制 通过这套机制，NameNode 保证了多个线程在高并发的修改元数据之后写 edits log 的时候，不会说一个线程一个线程地写磁盘和网络，那样性能很差，并发能力太弱 通过上述那套复杂的机制，尽量保证，一个线程可以批量地将一个缓冲中的多条 edits log 刷入磁盘和网络。在这个漫长的过程中，其他线程可以快速地高并发写入 edits log 到内存缓冲里，不会阻塞其他线程写 edits log 正是依靠以上机制，最大限度优化了 NameNode 处理高并发访问修改元数据的能力 参考资料大规模集群下Hadoop NameNode如何承载每秒上千次的高并发访问]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 基本架构原理]]></title>
    <url>%2FCKING.github.io%2F2021%2F02%2F09%2FHadoop-%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Hadoop 是目前大数据领域最主流的一套技术体系，包含了多种技术。包括 HDFS（分布式文件系统）、YARN（分布式资源调度系统）、MapReduce（分布式计算系统）等等 我们用一个简单的场景来阐述一下 Hadoop。假如你现在公司里的数据都是放在 MySQL 里的，并且全部放在一台数据库服务器上，假设这台服务器的磁盘空间有 2T ，如下： 如果你不停地往这台服务器的 MySQL 里放数据，结果数据量越来越大，超过了 2T 的大小，怎么办？我们可以搞多台 MySQL 服务器，分库分表，每台放一部分数据，就如上图所示，我们搞 3 台数据库服务器，3 个 MySQL 案例，然后每台服务器都可以放 2T 的数据 那么，所谓的大数据是在干什么？假设你有一个电商网站，现在要把这个电商网站里所有的用户在页面和 APP 上的点击、购买、浏览的行为日志都存放起来分析。你现在把这些数据全都放在了 3 台 MySQL 服务器，数据量很大，但还是勉强可以放得下 某天，你的 boss 要看一张报表，比如要看某天网站的 X 指标、Y 指标、Z 指标等等二三十数据指标。好，现在你尝试去从那些点击、购买、浏览的日志里，通过写一个 SQL 来分析出那二三十个指标试试看？ 你可能会写出来一个几百行起步，甚至上千行的复制大 SQL。这个 SQL，你觉得能运行在分表分库后的 3 台 MySQL 服务器上么？这不现实，几百行的大 SQL 跨库 join，各种复杂计算 因此，大数据的存储和计算压根不是靠 MySQL 来搞的，Hadoop、Spark 等大数据技术体系才应运而生。本质上，Hadoop、Spark 等大数据技术，其实就是一系列的分布式系统 比如 Hadoop 中的 HDFS，就是大数据技术体系中的核心基石，负责分布式存储数据。HDFS 全程是 Hadoop Distribute File System，是 Hadoop 的分布式文件系统 它由很多机器组成，每台机器上运行一个 DataNode 进程，负责管理一部分数据。然后有一台机器运行了 NameNode 进程，NameNode 大致可以认为是负责管理整个 HDFS 集群的这么一个进程，它里面存储了 HDFS 集群的所有元数据 然后有很多台机器，每台机器存储一部分数据。所以，HDFS 现在可以很好地存储和管理大量的数据了 有人会问：MySQL 服务器不也是这样的吗？这个事情不是你想的那么简单，HDFS 天然就是分布式的技术，所以你上传大量数据，存储数据，管理数据，天然就可以用 HDFS 来做。如果你硬要基于 MySQL 分库分表来做这个事，会痛苦很多，因为 MySQL 并不是设计为分布式系统架构的，它在分布式数据存储这块缺乏很多数据保障的机制 至此，你现在用 HDFS 存储了数据，接着就是要分布式来计算这些数据了。对于分布式计算： 用 Hive 写几百行的大 SQL（底层基于 MapReduce） 用 Spark 写几百行的大 SQL（底层是 Spark Core 引擎） 总之就是写一个大 SQL，人家会拆分为很多的计算任务，放到各个机器上去，每个计算任务就负责计算一笑部分，这就是所谓的分布式计算。这个，绝对比你针对分库分表的 MySQL 来跑几百行大 SQL 要靠谱得多 整个过程如下图所示： HDFS 的 NameNode 架构原理接着我们讨论一下 HDFS 集群中的 NameNode 核心架构原理 NameNode 有一个很核心的功能：管理整个 HDFS 集群的元数据，比如说文件目录树、权限的设置、副本数的设置等等 下面就用最典型的文件目录树的维护，来个大家举例。如下图，现在有一个客户端系统要上传一个 1TB 的大文件的 HDFS 集群里 此时它会先跟 NameNode 通信，说：大哥，我想创建一个新的文件，它的名字叫 /usr/hive/warehouse/access_20180101.log，大小是 1TB 然后 NameNode 就会在自己内存的文件目录树里，在指定的目录下搞一个新的文件对象，名字是 access_20180101.log 这个文件目录树不就是 HDFS 非常核心的一块元数据，维护了 HDFS 这个分布式文件系统中，有哪些目录，有哪些文件 但是有个问题，这个文件目录树是在 NameNode 的内存里的，你把重要的元数据都放在内存里，万一 NameNode 不小心宕机了，元数据不就全部丢失了？ 可你要是每次都频繁地修改磁盘文件里的元数据，性能肯定是极地的，毕竟这是大量的磁盘随机读写。我们看看 HDFS 是如何优雅地解决的 每次内存里改完，写一条 edits log，元数据修改的操作日志到磁盘文件里，不修改磁盘文件内容，就是顺序追加，这个性能就高很多。每次 NameNode 重启的时候，把 edits log 里的操作日志读到内存里回放一下，就可以恢复元数据了。如下： 但是，如果 edits log 越来越大的话，岂不是每次重启都会很慢？因为要读取大量的 edits log 回放恢复数据 所以 HDFS 引入了一个新的磁盘文件叫 fsimage，然后再引入一个 JournalNodes 集群，以及一个 Standby NameNode（备节点） 每次 Active NameNode（主节点）修改一次元数据都会生成一条 edits log，除了写入本地磁盘文件外，还会写入 JournalNodes 集群 然后 Standby NameNode 就可以从 JournalNodes 集群拉取 edits log，应用到自己内存的文件目录树里，跟 Active NameNode 保持一致 然后每隔一段时间，Standby NameNode 都把自己内存里的文件目录树写一份到磁盘上的 fsimage。这可不是日志，这是完整的一份元数据。这个操作就是所谓的 checkpoint 检查点操作 然后把这个 fsimage 上传到 Active NameNode，接着清空掉 Active NameNode 的旧的 edits log 文件，这里可能都有 100 万行修改日志了 然后 Active NameNode 继续修改接收元数据的请求，再写入 edits log，写了一小会，这里可能就几十行修改日志而已 如果此时 Active NameNode 重启了，没关系，只要把 Standby NameNode 传过来的 fsimage 直接读到内存里，这个 fsimage 直接就是元数据，不需要做任何额外操作，纯读取，效率很高 然后把新的 edits log 里少量的几十行的修改日志回放到内存里就 OK 了 这个过程的启动速度就快很多了，因为不需要回放大量上百万行的 edits log 来恢复元数据。如下图： 另外，我们看上面这张图，现在我们又两个 NameNode了 一个是主节点对外提供服务接收请求 另外一个就是接收和同步主节点的 edits log 以及执行定期 checkpoint 的备节点 他们俩内存里的元数据几乎是一模一样的。所以，如果 Active NameNode 挂了，是不是可以立马切换成 Standby NameNode 对外提供服务？这不就是所谓的 NameNode 主备高可用故障转移机制么 接着，HDFS 客户端在 NameNode 内存里的文件目录树，增加了一个文件。这个时候，人家要把数据上传到多台 DataNode 机器上去，这可是一个 1TB 的大文件，咋传？ 很简单，把 1TB 的大文件拆成 N 个 block，每个 block 是 128MB，1TB = 1024GB = 1048576MB，一个 block 是 128MB，那么就对应着 8192 个 block 这些 block 会分布式在不同的机器上管理者，比如说一共有 100 台机器组成的集群，那么每天机器放 80 个左右的 block 就可以了 但是，如果这个时候 1 台机器宕机了，不就导致 80 个 block 丢失了？也就是说上传上去的 1TB 的大文件，会丢失一小部分数据。没关系，HDFS 都考虑好了 它会默认给每个 block 搞 3 个副本，一模一样的副本，分别放在不同的机器上，如果一台机器宕机了，同一个 block 还有另外两个副本在其他机器上 如下图，每个 block 都在不同的机器上有 3 个副本，任何一台机器上宕机都没事，还可以从其他的机器上拿到那个 block 这样，上面就是 Hadoop 的基本架构原理 参考资料兄弟，用大白话告诉你小白都能看懂的Hadoop架构原理]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务 -- TCC Saga 入门级理解]]></title>
    <url>%2FCKING.github.io%2F2021%2F02%2F05%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1-TCC-Saga-%E5%85%A5%E9%97%A8%E7%BA%A7%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[业务理解简单描述下业务场景：有四个模块 A、B、C、D，其中 B、C、D 是下游服务，A 是上游服务调用方。从前端进来一个请求进入 A，A 需要对这一个请求进行记录落库，之后串行地调用 B、C 服务，并且异步地调用 D 服务，调用结束后再对数据库里这批请求进行更新操作 用电商场景来说就是以下几个步骤： 用户在订单平台操作下单 占库存 占钱款 生成一笔订单 如图所示： 分布式系统上图是一个分布式应用的简单呈现，将电商的业务拆分成了多个服务。在分布式应用的场景中，往往会遇到「网络通信异常」、「服务器节点异常」甚至「服务器宕机」等场景。其实，在分布式应用中遇到的各种异常场景一定会比想的还要多，发生也更频繁 既然分布式应用需要考虑那么多的异常场景，为什么还要使用分布式的方式部署服务呢？以前，流量还没那么大的时候，一个网站靠单机是可以撑住的。但随着互联网业务的快速发展，我们开始追求网站的高可用、高性能、易扩展、伸缩性强且安全的系统。这也是分布式系统存在的意义 分布式系统有一下特点： 高可用：在出现一台或多台服务器节点异常甚至宕机的情况下，系统仍然可用，采用分布式冗余部署多节点来保证高可用 高性能：在单机的情况下一台机器的 CPU、内存等因素容易成为性能的瓶颈，在在分布式多机部署的情况下，通过拆分业务多机部署达到高性能 伸缩性强：在访问量增大和存储需求提高的时候，一台或几台服务器就显得势单力薄，此时可以通过向服务器集群中添加服务器来应付 扩展性强：需要将扩展性和伸缩性区分开来看待，伸缩性是基于底层硬件来说的，而扩展性则是针对业务来说的，也就是说便于新业务的扩展或者是业务的拆分。一般采用模块化，所以更便于扩展，也便于模块重用。业务被拆分，开发效率也会随之提升 另外，分布式需要重点考虑在服务调用「成功、失败、超时异常」三种场景下，如何保证「数据一致性」的问题 数据一致性我们经常听到「一致性」这个名词。在使用数据库的时候提到的「ACID」里的 C 是一致性，分布式系统「CAP 理论」里面的 C 也是一致性，这两个有什么区别呢？ ACIDACID 指的是在数据库写入或更新时为了保证实物正确可靠而必须满足的四个特性，分别是「A（Atomicity 原子性）、C（Consistency 一致性）、I（Isolation 隔离性）、D（Durability 持久性）」。其它三个特性我们先不谈，这里的一致性指的是事务上的一致性。我理解的其它三个特性最终都是为了这个一致性而服务。这里的一致性指的是在事务发生的前后，系统从一个正确的状态，转移到另一个正确的状态 什么叫「正确的状态」呢？举个例子，A B 账号各有 100 元，A 向 B 转账 50 元，转账后的 A 的账户变成 了 50 元，B 账户变成了 150 元，这是正确的状态。如果此时 A 又向 B 转账了 100元，之后 A 的账户变成了 -50 元，B 的账户变成了 250 元，那么这就是错误的状态。在这个例子里，如果变成了错误的状态，事务是需要回滚的，这就是事务上的一致性。一般来说这个一致性可以是数据库做约束去保证，但更多时候业务逻辑更为复杂，需要代码层面去约束保证 CAPCAP 理论通常用于分布式系统中，CAP 分别指「C（Consistency 一致性）、A（Availability 可用性）、P（Partition tolerance 分区容错性）」，CAP 理论认为在分布式系统中这三个特性只能同时满足两个。而我们所说的数据一致性也是指的这个一致性，这个一致性和 ACID 中的事务一致性完全不是同一个东西，切记不要搞混了 一致性：在分布式系统中所有的数据副本，在同一个时刻有同样的值 可用性：在分布式系统的集群中某个或多个节点故障了，客户端的读写请求仍然会有响应 分区容错性：当集群中的节点与节点之间无法通信时，或者系统在一定时限内无法达到数据一致性，就意味着产生了分区，而分区产生后仍然可用，即分区容错性 为什么只能同时满足两个？首先考虑要满足分区容忍性的情况下，就要做多个副本，但是一旦副本多起来，一致性就会收到影响，数据同步需要花更多时间，数据同步花的时间多了，就会对可用性造成影响，有可能有段时间无法使用，同时分区容错性由于达到一致性的时间变长了，则无法很好地满足。归纳起来就是： 满足 C / A 不满足 P：即不要求分区，则节点受限，也就是放弃了系统的伸缩性，这跟分布式的特性是想违背的。通常采用这种方案的是传统的数据库，如 Oracle 满足 C / P 不满足 A：则不要求可用性，要求一致性即所有副本的数据都要保持一致，而分区则有可能导致数据同步的时间大大地延长，这种场景下就牺牲了用户的体验，等数据全部一致了用户才可以用户。Zookeeper 就是采用了这种方式 满足 A / P 不满足 C：则不要求一致性。一旦分区发生，又要保持可用，每个节点就会用本地缓存的数据来提供服务，这样用户就可能访问到过期的数据。服务发现组件 Eureka 就是采用了这种方式 前后的矛盾冲突导致无法同时满足三者，因此我们一般在实现中会采用一些折中的方案，这就要提到在一致性上根据实际需求而产生的集中不同的一致性： 强一致性：系统中某个数据被更新了，那么后续对于该数据的读取都将得到更新后的值，也就是说所有副本上数据都要保持严格的一致，副本是同步更新的 弱一致性：相对强一致性而言，数据更新后，对该数据的读取并不能保证总是读取到更新后的值，也就是副本的数据无法保持一致，副本是异步更新的 最终一致性：属于一种特殊的弱一致性，系统中多有的副本在经过一个短暂的数据不一致后通过同步最终达到一致 在我们这次的业务场景中，上游服务 A 对于服务 B、C、D 的调用都要保证数据最终一致性。对于服务 B、C 是同步调用，在服务调用过程中如果失败则事务直接进行回滚；对于服务 D 异步调用可以容忍较长时间的数据不一致，在最终一致性之前引入「软状态（中间状态）」作为临时状态，当异步调用结果还没有返回时，可以设置一个「订单生成中」的状态 容错机制对于跟钱打交道的业务，我们考虑的重点首先肯定是不能错（数据一致性），错了之后怎么解决或者系统如何自动处理是我们接下来考虑的（容错机制） 容错的话需要考虑多种场景，流程顺利的话自不必说，失败的话就要考虑实现自动回滚系统，而像因为网络或服务器节点原因而导致的超时则是需要特殊考虑的异常场景 业务成功场景 成功场景表示同步调用成功以及异步发起请求这个动作成功，这个时候会返回给用户表示请求成功。但是有一点需要注意的是异步请求后不代表订单就生成成功了，此时返回给用户的只是给用户一个响应而不至于流程阻塞。所以此时我们会进入软状态，也就是中间状态类似于「订单生成中」的状态来表示。订单生成有可能成功也有可能失败，如果订单生成失败则同样要做回滚的处理 业务场景失败业务失败场景 1 业务失败场景 2 业务失败场景 3 这里展示了三种失败的场景，对于前两种，失败了就需要做回滚处理： 当调用服务 B 冻结库存失败则终止并回滚数据库 当调用服务 C 冻结钱款失败则终止并回滚服务 B 解除库存以及回滚数据库 对于第三种失败场景则多了几种选择： 可以同前两种一样直接做回滚的处理 可以选择提供给用户「手动重试」的机会，因为一般成功冻结仓库和冻结钱款后，这笔订单已经大概率下达成功了，异步发起请求失败是极小概率的事情，通过提供重试机制来提升用户的体验 可以将异步请求写入数据库扩展消息队列，另起一个线程去处理异步请求以及后续的操作，包括可以设定「自动重试」以及受到异步返回结果后成功和失败的处理。这样的好处在于可以很好地将代码解耦开，业务流程较为清晰 超时 / 异常处理超时的原因多种多样，网络抖动、服务器节点不通、服务器节点崩溃，而且超时还有一个难点在于特别容易导致状态的不一致。当服务 A 调用服务 B 超时了，此时无法得知 B 是否有接收到请求，在这种情况下有两种解决方案：一种是要求 B 要实现「幂等」或者提供「状态查询接口」，服务 A 通过重试来处理超时情景；另外一种是采用「强制回滚」来处理超时，但是当这两种方法都再次超时的时候就不得不人工介入处理，此时则还需要预留好后续的提供给运维人员的人工处理手段 宕机处理突然的停电、插头被人拔了或者有人恶意杀进程，一旦出现那么保存在内存中的状态和数据就全部没了。假如此时服务 A 已经成功调用服务 B 冻结库存成功了，还没有调用服务 C 就突然断电了，那么势必会造成各个服务上的数据不一致，库存都已经扣了，钱没有扣，订单也没有生成，这不就莫名多扣了库存吗。所以在调用服务前一定要将现场的数据保存下来，方便宕机重启后进行回滚状态 在宕机重启系统后，会启动一个线程去读取保存的现场数据，基于现场数据去做回滚，因此现场数据应该包含有几个信息：被调用模块、传递参数、状态。判断该数据是否已经用于回滚处理，如果已经进行回滚则为已处理，否则为待处理 TCC什么是 TCC 框架？TCC 其实是三个单词的首字母，分别是：try、confirm、cancel。try 就是尝试一下，confirm 就是确认，cancel 就是取消。例如你晚上约几个朋友去吃宵夜，然后就约了几个朋友预定了座位，这就是 try；朋友约到了座位预约到了，准时六点下班去吃饭，这就是 confirm；因为你要修 bug 不得不加班，或者朋友都在加班，或者没有预约到座位，那就没有宵夜了，这就是 cancel 让我们结合业务场景来讲一下 正常逻辑 阶段一：try在 try 阶段，「调用方」会分别调用多个「被调用方」，只有当多个被调用方都返回成功的时候，才会进行 confirm，否则就会进行 cancel。也就是说 try 阶段是一个预备类的操作，锁定某个资源、冻结部分数据，是在真正的扣除之前进行一个预占、冻结的动作 阶段二：confirm在该阶段，confirm 就是对 try 成功了之后的一个后续处理，将冻结、预占的数据进行真正的扣除（该业务场景是扣除，当然其他场景也可能是增加），这里就要考虑两种场景： confirm 都成功了，那么对服务 B、C 的调用就此完成，在数据上服务也都是一致的 个别或者全部的 confirm 失败了或者调用超时了，和 try 阶段不一样的是，这种场景不做 cancel 回滚处理，而是将所有的 confirm 进行重试。需要注意的是，被调用方一定要实现「幂等机制」，否则是无法进行重试的。另外，需要设定重试次数，如果重试还是失败或超时并且已经超过了重试次数，则必须告警通知人工进行处理 阶段三：cancel只有在 try 阶段失败或异常超时的情况下才会进行 cancel 处理，并且 cancel 处理并不是对所有的调用方进行 cancel，而是对已经 try 成功的被调用方进行 cancel 处理。另外，和 confirm 阶段一样，cancel 阶段也需要提供重试机制和重试超过一定次数的情况下告警通知人工处理 进一步思考到这，基本就能知道 TCC 框架大概是怎么回事。在具体实现中，可以选用开源的 TCC 框架：ByteTCC、Himly、TCC - transaction、Seata 等等。或者自己手写，不过手写这么个框架内部的实现细节还是很复杂的，各个阶段的执行情况怎么感知，如何推动到下一步阶段，如何实现重试机制、告警系统、人工菌介入、宕机回滚等等都要考虑清楚 SagaSaga 框架，感觉是一个没有 confirm 的 TCC 框架，但这么说也不太准确，因为 Saga 的 try 不再是尝试一下，没有了预占和冻结数据，而是直接对数据进行了扣除 / 增加 Saga 理论来自 Hector &amp; Kenneth 1987 发表的论文 Sagas，其中最主要的思想就是补偿协议： 补偿协议：在 Saga 模式下，分布式事务内有多个参与者，每个参与者都是正向补偿服务。上图中的 T1 ~ Tn 就是「正向调用」，C1 ~ Cn 是「补偿调用」，正向调用和补偿调用是一一对应的关系。假设有 n 个被调用方服务，T1 就是对服务方一的调用，T2 就是服务方二的调用，T3 就是服务方三的调用。如果这时候返回了失败，那么就需要进行回滚，此时就会调用 T2 的对应补偿 C2，调用 T1 的对应补偿 C1，使得分布式事务回到初始状态 Saga 适用场景 Saga 是一种「长事务的解决方案」，更适合于业务流程长、业务流程多的场景 如果服务参与者包含其他公司或遗留系统服务，此时无法提供 TCC 模式下的三个接口，那么就需要采用 Saga 典型的业务系统：金融机构对接系统（需要对接外部系统）、渠道整合（流程长）、分布式架构服务 银行金融机构使用更为广泛 Saga 模式的优势是： 一阶段提交本地数据库事务，无所，高性能； 参与者可以采用事务驱动异步执行，高吞吐 补偿服务即正向服务的「方向」，易于理解，易于实现 缺点：Saga 模式由于一阶段已经提交本地数据库事务，且没有进行「预留」动作，所以不能保证隔离性 Saga 和 TCC 的异同TCC 和 Saga 的不同之处，主要体现在应用场景上的不同 数据隔离性回到我们的业务场景，服务 A 调用了服务 B、C，如果发生了以下的情况： 对服务 B try 成功了，但是服务 C try 失败了 此时有用户来读取服务 B 和服务 C 的数据 A、B、C 进行回滚 那么对于 TCC 和 Saga 来说，try 失败了都会进入 cancel阶段，但是刚好在还没有来得及进行 cancel 回滚处理的时候，有用户来读取 B、C 的数据。这种情况下 TCC 和 Saga 就会返回不一样的结果 对于 TCC 来说，try 只是一个冻结的操作，所以它操作的也只是一个冻结字段，这并不会影响用户查询的实际数据，所以是可以返回正确的结果的 对于 Saga 来说，try 则是对数据的一个直接操作，会更改用户想要访问的数据，那么这个时候就会返回给用户脏数据。会有脏读说明 Saga 框架下数据时有隔离性的问题的 对于 Saga 来说，隔离问题本质上是要控制并发，因此还是要回到业务上来，从业务逻辑层去实现并发控制。可以是在应用层枷锁的机制去处理，也可以是 Session 层面保证串行化，但这些多多少少对性能和吞吐量有所影响 两阶段与一阶段从上面的叙述中，Saga 相对于TCC主要在隔离性上的缺失，究其原因，是因为 TCC 是两阶段提交事务而 Saga 是一阶段提交事务。 对于 TCC，一阶段会将资源进行预占，对资源进行锁定；二阶段才会使用资源或释放资源 对于 Saga，则是一阶段直接进行事务提交。相比 TCC 二阶段的提交事务，一阶段提交事务「无锁」，且可以采用「事件驱动异步执行」，适合长流程的业务，另外异步执行也意味着更高的吞吐量 但是一阶段提交导致 Saga 有隔离性问题，那么在 cancel（补偿）失败的时候，TCC 可以采用重试机制去处理，而 Saga 需要提供额外的人工介入处理 参考资料分布式事务实践——TCC、Saga入门级理解 分布式事务 Seata Saga 模式首秀以及三种模式详解]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[公司的分布式缓存架构]]></title>
    <url>%2FCKING.github.io%2F2021%2F02%2F03%2F%E5%85%AC%E5%8F%B8%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[Spring Cache在讨论公司的分布式缓存架构之前，我们先拿 Spring Cache 缓存作为一个参考系。简单来说，Spring Cache 有两个优点： 基于 Spring AOP 注解 上手简单 对业务侵入性低 提供标准的 Cache 抽象（JSR 107），具体的 Cache、CacheManager 依赖各自实现 SpaceStation 实践在 Spring Cache 的基础上，我们进行了一些简单的优化。包括以下两点： 实现了两级缓存（堆内内存 + Redis） 自定义 EnhanceCacheManager，定义了 CacheConfig 结构，可以定义 Cache 的 TTL、Size 等属性 Spring Cache 初体验在使用 Spring Cache 的过程中，发现了以下缺点： 接口简单。没有 TTL，而且也没有缓存批量操作。例如批量增加、批量删除等等 注解简单。注解的属性太少，缓存配置和缓存声明式分开的 扩展困难。所有功能需要自己实现 Cache Manager，而且切面固定，但不是所有功能都是放在 CacheManager 里面 对缓存穿透、缓存雪崩缺乏支持 公司的分布式缓存架构 - SCache为了解决 Spring Cache 上述问题，满足公司项目的使用。公司架构组决定自研一个分布式缓存架构。其设计目标如下： 开箱即用，声明式（注解）和编程式的使用方式 更丰富的 API 和注解 原生支持多级缓存 支持批量缓存存取 更好预防缓存雪崩和缓存穿透场景 做一个透明的、可监控的缓存层 为此，该架构吸收了 Spring Cache 的优点，有标准化的 Cache API；并且基于 AOP，降低侵入性；同时支持 SPEL，以及灵活的 key 生成和条件匹配 多级缓存SCache 本地使用 Caffeine Cache，远程缓存则适配 Redis，并且多级缓存之间 TTL 等属性会作出区分。支持可配置的序列化、压缩等存储方式，另外，提供了统一的 Redis 操作客户端 Eadis 批量缓存操作Spring Cache 的批量缓存操作，其实并不是真正意义上的批量，而是多个 key hash 成一个，仍是单个缓存。这样如果其中一个 key 发生变化，整个缓存就都无法命中了 而 SCache 则是拆分请求，分成独立的缓存，批量查询。如果命中缓存，则从 Cache 中获取，未命中的缓存则走业务逻辑回源，然后将回源到的数据回写到缓存，最终结果是有 Cache 和 DB 数据两者结合而成。如下图： 缓存场景缓存穿透缓存穿透是指大量请求请求不存在的数据，穿透缓存，请求到了数据库那里。SCache 的解决方案是缓存 Null Value，并为 Null Value 提供专门的 TTL 缓存击穿缓存击穿是指某缓存 key 失效，大量并发请求同时抵达数据库。SCache 的解决方案是控制缓存回源的并发数，并且提供可选的 Cache Policy，直接返回过期缓存，并异步回源。此外再上 Lock，Lock 范围可以在 JVM，也可以在整个系统 缓存雪崩缓存雪崩是缓存采用了相同的过期时间，导致大量缓存同时失效，请求全部落到了 DB 上。SCache 采取的解决方案是采用多级缓存，并在缓存有限期附加随机时间，同时控制缓存回源的并发 可监控的缓存缓存的监控，主要是分为以下几个维度去监控： 分 Cache 监控：每个缓存都有自己的命名 分 Type 监控：有两个类型，本地缓存和远程缓存 而我们监控的指标主要是：缓存的 QPS、相应时间以及命中率等 其他特性SCache 除了上述的功能外，还有其他特性。包括缓存与源的一致性、缓存自动刷新和缓存压缩等 缓存与源的一致性 与事务的协调处理 数据库主从同步延迟的处理 缓存自动刷新 定时自动刷新缓存 冷数据，自动停止刷新 缓存压缩 节约 Redis 内存 存入缓存时自动压缩 读取缓存时自动解压缩 一级缓存失灵一般情况下，为了保证系统的高可用，我们都是集群部署系统，那么这样就会出现一个问题。假设有两台机器都部署了系统，其中两个系统本地缓存数据 X = 1。接着 JVM1 更改了数据 X = 2，并修改了本地换粗和 Redis 缓存，但此时 JVM2 的 X 还是为 1。这就是一级缓存失灵，如下图 网上的解决方案如何保证多个系统之间的本地缓存数据保持一致性呢？常规的解决方法有两种，一是 JVM 之间直接同步；二是引入中间件，例如 MQ 「JVM 之间直接同步」大体上有两种方案，一个是使用 RPC，但这个依赖于服务发现的实时性，而且有可能造成通知方压力过大；另一个是使用一致性协议，如 Gossip 等，但这个实现复杂度较高，并且不可控，消息过大，容易造成网络风暴 SCache 的解决方案初级方案因为我们的远程缓存时采用 Redis，因此架构组经过讨论后，采用 Redis 的 pubSub 机制来解决一致性问题。PubSub 消息包含发生变更的 key 以及对应的编号，并且通知的时候，删除过期的 key 而不是更新 value 进阶方案随着系统有并发量的提升，刚开始那一套方案开始出现了问题。Redis 的 PubSub 是有一定延迟的，平时可能感觉不出来，但有了一定并发量的时候，就会有问题。例如一个数据，x = 1,被修改了两次，x = 2, x = 3，通过 Redis 的 pubSub 广播出去，但由于延迟，有可能另一台JVM 先修改了 x =3，再修改了 x = 2。这时候就出现问题了。因此，就有了这个进阶方案。 进阶方案包含两个维度。首先是「发起方」，发起方要修改数据的时候，先双写变更 key，然后定时心跳通知当前最大的消息 id 接着是「接收方」，先比对心跳通知，检查自身消息 id 是否遗漏。如果遗留，则 get 备份消息，进行一致性恢复；无法恢复一致性，则清空该 name 下本地缓存 方案补充基本上述方案就能抗住高并发，实现数据的一致性。接着就是一些网络问题的补充方案。因为 Redis 的不稳定，尤其是集群的网络抖动，双写 set、publish、subscribe 等都可能失败。因此 Eadis 提供高可靠的 Set / Get、Publish / Subscribe 命令，自动计算合适的 hashtag，将数据发送到可用的 Redis 节点上 出现的问题这套缓存框架使用一段时间后，慢慢也开始显露出一个问题。那就是本地缓存时存储在 JVM 堆内存中的，很多缓存数据会逃过 Young GC，躲入老年代。缓存虽然会不断淘汰，但是之前的数据仍然占用老年代空间，并造成老年代的碎片 这个时候，虽然有 JVM 的 GC 垃圾回收机制，回收掉老年代的数据，但这套缓存框架仍然受限于 JVM 的堆内存，大量系统剩余的内存无法利用 解决方案为了解决上述问题，我们就需要搞定「大内存」，而最有效的方法就是使用堆外内存。经过调研，主要有一下三种方法使用堆外内存： 使用直接内存 性能好 需要配置 JVM 参数进行控制 MaxDirectMemorySize 有 OOM Full GC 风险 使用本地服务 提升架构复杂度，降低了系统稳定性 进程间通信，性能相对较低 PAAS 外存在数据一致性无问题 使用本地动态链接库 进程内通信，与 Java 进程工存亡 缺乏合适的技术解决方案 最终架构组采用了第三个方案，选择 Rust 实现动态链接库。理由如下： 可提供 FFI 接口的功能 C 语言级别的性能 内存安全，自动回收，无 GC 并发安全 纯粹的缓存 Lib 复杂度可控 在使用 Rust 的过程中，发现 Rust 现有的 HashMap 容器并不好用，跟 JDK1.7 的 ConcurrentHashMap 类似，有如下问题： 采用分段锁，锁的粒度太大，高并发下锁竞争激烈 数据越多，Put、扩缩容等对锁造成的影响越大 数据结构内部封装，外部不可见 为此，架构组参考 JDK1.8 的 ConcurrentHashMap，用 Rust 自定义了 hashMap，有如下特点： 线程安全 最小粒度的锁，支持高并发 渐进式 rehash，扩缩容无阻塞 可自由访问任意 entry 进行遍历 SCache 就用这一套解决了大内存问题 内存控制内存控制主要分为三个方面：整体限制、独立控制以及数据淘汰 整体限制主要分为以下两点： 可定义最少需要保留的主机空闲内存 可定义堆外缓存最大使用的主机内存 独立控制主要体现在：每个命名 Cache 可以单独配置可使用的堆外内存大小，使用 localMaxWeight 属性去配置 数据淘汰主要有以下三点： 后台线程定期淘汰过期数据 惰性删除。Get 数据时，如果该 Key 已经过期，则删除该数据 强制剔除。Insert 数据时，如果使用内存已经达到所配置的 localMaxWeight，则将先淘汰部分数据，释放足够的内存来完成本次 Insert]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cache]]></title>
    <url>%2FCKING.github.io%2F2021%2F02%2F01%2FSpring-Cache%2F</url>
    <content type="text"><![CDATA[Spring Cache 简介在 Spring 3.1 中引入了多 Cache 的支持，在 spring - context 包中定义了 org.springframework.cache.Cache 和 org.springframework.cache.CacheManager 两个接口来统一不同的缓存技术。Cache 接口包含缓存的常用操作：增加、删除、读取等。CacheManager 是 Spring 各种缓存的抽象接口。Spring 支持的常用 CacheManager 如下： CacheManager 描述 SimpleCacheManager 使用简单的 Collection 来存储缓存 ConcurrentMapCacheManager 使用 java.util.ConcurrentHashMap 来实现缓存 NoOpCacheManager 仅测试用，不会实际存储缓存 EhCacheCacheManager 使用 EhCache 作为缓存技术。EhCache 是一个纯 Java 的进程内缓存框架，特点是快速、精干，是 Hibernate 中默认的 CacheProvider，也是 Java 领域应用最为广泛的缓存 JCacheCacheManager 支持 JCache（JSR - 107）标准的实现作为缓存技术 CaffeineCacheManager 使用 Caffeine 作为缓存技术。用于取代 Guava 缓存技术 RedisCacheManager 使用 Redis 作为缓存技术 HazelcastCacheManager 使用 Hazelcast 作为缓存技术 CompositeCacheManager 用于组合 CacheManager，可以从多个 CacheManager 中轮询得到相应的缓存 Spring Cache 提供了 @Cacheable、@CachePut、@CacheEvict、@Caching 等注解，在方法上使用。通过注解 Cache 可以实现类似事务一样，缓存逻辑透明地应用到我们的业务代码上，且只需要更少的代码。核心思想：当我们调用一个方法时会把该方法的参数和返回结果作为一个键值对放在缓存中，等下次利用同样的参数来调用该方法时就不会再执行，而是直接从缓存中获取结果进行返回 Cache 注解@EnableCaching开启缓存功能，一般放在启动类上 @CacheConfig当我们需要缓存的地方越来越多，你可以使用 @CacheConfig(cacheNames = {&quot;cacheName&quot;}) 注解在 class 之上来统一制定 value 的值，这时可省略 value。如果你在你的方法依旧写上了 value，那么依然以方法的 value 值为准 @Cacheable根据方法对其返回结果进行缓存，下次请求时，如果缓存存在，则直接读取缓存数据返回；如果缓存不存在，则执行方法，并把返回的结果存入缓存中。一般用在查询方法上。有以下属性值： 属性/方法值 解释 value 缓存名，必填，它指定了你的缓存放在哪块命名空间 CacheNames 与 value 差不多，二选一即可 key 可选属性，可以使用 SpEL 标签自定义缓存的 key keyGenerator key 的生成器。key / keyGenerator 二选一使用 cacheManager 指定缓存管理器 cacheResolver 指定获取解析器 condition 条件符合则缓存 unless 条件符合则不缓存 sync 是否使用异步模式。默认为 false @CachePut使用该注解标志的方法，每次都会执行，并将结果存入指定的缓存中。其它方法可以直接从响应的缓存中读取缓存数据，而不需要再去查询数据库。一般用在新增方法上。属性值如下： 属性/方法值 解释 value 缓存名，必填，它指定了你的缓存放在哪块命名空间 CacheNames 与 value 差不多，二选一即可 key 可选属性，可以使用 SpEL 标签自定义缓存的 key keyGenerator key 的生成器。key / keyGenerator 二选一使用 cacheManager 指定缓存管理器 cacheResolver 指定获取解析器 condition 条件符合则缓存 unless 条件符合则不缓存 @CacheEvict使用该注解标志的方法，会清空指定的缓存，一般用在更新或者删除方法上。属性值如下： 属性/方法值 解释 value 缓存名，必填，它指定了你的缓存放在哪块命名空间 CacheNames 与 value 差不多，二选一即可 key 可选属性，可以使用 SpEL 标签自定义缓存的 key keyGenerator key 的生成器。key / keyGenerator 二选一使用 cacheManager 指定缓存管理器 cacheResolver 指定获取解析器 condition 条件符合则缓存 allEntries 是否清空所有缓存，默认为 false。如果为 true，则方法调用后将立即清空所有缓存 beforeInvocation 是否在方式执行前就清空，默认为 false。如果为 true，则在方法执行后就清空缓存 @Caching该注解可以实现同一个方法上同时使用多种注解。从其源码可以看出： 1234567891011@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Inherited@Documentedpublic @interface Caching &#123; Cacheable[] cacheable() default &#123;&#125;; CachePut[] put() default &#123;&#125;; CacheEvict[] evict() default &#123;&#125;;&#125; Spring Cache 使用接着我们用一个 demo 来看一下 Spring Cache 如何使用 构件项目，添加依赖12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.4.2&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;spring-cache&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-cache&lt;/name&gt; &lt;description&gt;Demo project for Spring Cache&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- spring cache --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- mybatis-plus --&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.4.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- jdbc --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.20&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.properties 配置文件123456spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driverspring.datasource.url=jdbc:mysql://127.0.0.1:3306/db_test?useUnicode=true&amp;characterEncoding=UTF-8&amp;useSSL=true&amp;serverTimezone=UTCspring.datasource.username=rootspring.datasource.password=123456mybatis-plus.mapper-locations=classpath:/mapper/*Mapper.xml 实体类123456789101112131415package com.example.springcache.entity;import lombok.Data;import lombok.ToString;@Data@ToStringpublic class UserEntity &#123; private Long id; private String userName; private String userSex;&#125; 数据层 dao 和 mapper.xml12345678910111213141516171819202122232425262728293031323334@Mapperpublic interface UserDao &#123; /** * 获取所有用户 * @return */ List&lt;UserEntity&gt; getAll(); /** * 根据id获取用户 * @param id * @return */ UserEntity getOne(Long id); /** * 新增用户 * @param user */ void insertUser(UserEntity user); /** * 修改用户 * @param user */ void updateUser(UserEntity user); /** * 删除用户 * @param id */ void deleteUser(Long id);&#125; 123456789101112131415161718192021222324252627282930&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.4//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.example.springcache.dao.UserDao"&gt; &lt;resultMap type="com.example.springcache.entity.UserEntity" id="user"&gt; &lt;id property="id" column="id"/&gt; &lt;result property="userName" column="user_name"/&gt; &lt;result property="userSex" column="user_sex"/&gt; &lt;/resultMap&gt; &lt;!-- 获取所有用户 --&gt; &lt;select id="getAll" resultMap="user"&gt; select * from t_user &lt;/select&gt; &lt;!-- 根据用户ID获取用户 --&gt; &lt;select id="getOne" resultMap="user"&gt; select * from t_user where id=#&#123;id&#125; &lt;/select&gt; &lt;!-- 新增用户 --&gt; &lt;insert id="insertUser" parameterType="com.example.springcache.entity.UserEntity"&gt; insert into t_user (id, user_name,user_sex) values(#&#123;id&#125;,#&#123;userName&#125;,#&#123;userSex&#125;) &lt;/insert&gt; &lt;!-- 修改用户 --&gt; &lt;update id="updateUser" parameterType="com.example.springcache.entity.UserEntity"&gt; update t_user set user_name=#&#123;userName&#125;,user_sex=#&#123;userSex&#125; where id=#&#123;id&#125; &lt;/update&gt; &lt;!-- 删除用户 --&gt; &lt;delete id="deleteUser" parameterType="Long"&gt; delete from t_user where id=#&#123;id&#125; &lt;/delete&gt;&lt;/mapper&gt; 业务代码层接口 Service 和实现类 ServiceImpl1234567891011121314151617181920212223242526272829303132public interface UserService &#123; /** * 获取所有用户 * @return */ List&lt;UserEntity&gt; getAll(); /** * 根据id获取用户 * @param id * @return */ UserEntity getOne(Long id); /** * 新增用户 * @param user */ void insertUser(UserEntity user); /** * 修改用户 * @param user */ void updateUser(UserEntity user); void deleteAll1(); void deleteAll2();&#125; 1234567public interface UserService2 &#123; /** * 删除用户列表 */ void deleteUserList();&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Service@CacheConfig(cacheNames = &#123;"userCache"&#125;)public class UserServiceImpl implements UserService &#123; @Resource private UserDao userDao; @Autowired private UserService2 userService2; @Override @Cacheable("userList") // 标志读取缓存操作，如果缓存不存在，则调用目标方法，并将结果放入缓存 public List&lt;UserEntity&gt; getAll() &#123; System.out.println("缓存不存在，执行方法"); return userDao.getAll(); &#125; @Override @Cacheable(cacheNames = &#123;"user"&#125;, key = "#id") // 如果缓存存在，直接读取缓存值；如果不存在，则调用目标方法，并将结果缓存缓存 public UserEntity getOne(Long id) &#123; System.out.println("缓存不存在，执行方法"); return userDao.getOne(id); &#125; @Override @CachePut(cacheNames = &#123;"user"&#125;, key = "#user.id") // 写入缓存，key 为 user.id，一般该注解标注在新增方法上 public void insertUser(UserEntity user) &#123; System.out.println("写入缓存"); userDao.insertUser(user); &#125; @Override @CacheEvict(cacheNames = &#123;"user"&#125;, key = "#user.id") // 根据 key 清除缓存，一般该注解标注在修改和删除方法上 public void updateUser(UserEntity user) &#123; System.out.println("清除缓存"); userDao.updateUser(user); userService2.deleteUserList(); &#125; @Override @CacheEvict(value = "userCache", allEntries = true) // 方法调用后清空所有缓存 public void deleteAll1() &#123; &#125; @Override @CacheEvict(value = "userCache", beforeInvocation = true) // 方法调用前清空所有缓存 public void deleteAll2() &#123; &#125;&#125; 12345678910@Service@CacheConfig(cacheNames = &#123;"userCache"&#125;)public class UserService2Impl implements UserService2 &#123; @Override @CacheEvict("userList") public void deleteUserList() &#123; &#125;&#125; 测试 Controller12345678910111213141516171819202122232425262728293031@RestController@RequestMapping("/user")public class UserController &#123; @Autowired private UserService userService; @RequestMapping("/getAll") public List&lt;UserEntity&gt; getAll() &#123; return userService.getAll(); &#125; @RequestMapping("/getOne") public UserEntity getOne(Long id) &#123; UserEntity user = userService.getOne(id); System.out.println(user); return user; &#125; @RequestMapping("insertUser") public String insertUser(UserEntity user) &#123; userService.insertUser(user); return "insert success"; &#125; @RequestMapping("updateUser") public String updateUser(UserEntity user) &#123; userService.updateUser(user); return "update success"; &#125;&#125; 启动 Cache 功能123456789@SpringBootApplication@EnableCachingpublic class SpringCacheApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCacheApplication.class, args); &#125;&#125; Spring Cache 整合 Caffeine在不做任何配置的情况下，默认使用的是 SimpleCacheConfiguration，即使用 ConcurrentMapCacheManager。如果要使用其它的缓存框架，要怎么做？我们只需重新定义好 CacheManager 即可。我们在上面的例子中，将默认的缓存框架切换为 Caffeine EhCache、Guava、Caffeine 对比这三个都是作为进程缓存（本地缓存）的优秀开源产品，如果我们要使用本地缓存来加速访问，选择哪种？下面做一个简单的对比： EhCache：是一个纯 Java 的进程内存缓存框架，具有快速、精干等特点，是 Hibernate、Mybatis 默认的缓存提供（虽然 EhCache3 支持到了分布式，但它还是基于 Java 进程的缓存） Guava：它是 Google Guava 工具包中一个非常方便易用的本地化缓存实现，基于 LRU 算法实现，支持多种缓存过期策略 Caffeine：它是使用 Java8 对 Guava 缓存的重写版本，在 Spring5 中取代了 Guava，支持多种缓存过期策略 Caffeine 在性能上碾压其余两者。它可以完全地替代 Guava，因为 API 上都差不多一致，并且它还提供了 Adapter 让 Guava 过度到 Caffeine 上来。Caffeine 被称为进程缓存之王 引入 jar 包想要整合 Caffeine，首先先在 pom 文件引入 Caffeine 的 jar 包 1234&lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;caffeine&lt;/artifactId&gt;&lt;/dependency&gt; 配置缓存配置类1234567891011121314151617@Configurationpublic class CacheConfig &#123; @Bean public CacheManager cacheManager() &#123; CaffeineCacheManager cacheManager = new CaffeineCacheManager(); cacheManager.setCaffeine(Caffeine.newBuilder() // 设置最后一次写入或访问后经过固定时间过期 .expireAfterAccess(60, TimeUnit.SECONDS) // 初始的缓存空间大小 .initialCapacity(100) // 缓存的最大条数 .maximumSize(1000)); return cacheManager; &#125;&#125; 这样，Spring Cache 默认的缓存框架就切换成 Caffeine 了 参考资料Spring Cache 使用]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java 内部类]]></title>
    <url>%2FCKING.github.io%2F2020%2F12%2F25%2FJava-%E5%86%85%E9%83%A8%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[内部类的作用首先我们要知道什么事内部类 内部类（inner class）：定义在另一个类中的类 内部类有什么作用： 内部类方法可以访问该类定义所在作用域中的数据，包括 private 修饰的私有数据 内部类可以对同一包中的其他类隐藏起来 内部类可以实现 Java 单继承的缺陷 内部类方法可以访问该类定义所在作用域中的数据我们看下面的代码 123456789101112131415161718192021222324252627public class TestExample &#123; private List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); private class InnerClass &#123; public Integer get(int poi) &#123; return list.get(poi); &#125; &#125; public void init() &#123; this.list.add(1); this.list.add(2); &#125; public Integer get(int poi) &#123; InnerClass innerClass = new InnerClass(); return innerClass.get(poi); &#125; public static void main(String[] args) &#123; TestExample testExample = new TestExample(); testExample.init(); System.out.println(testExample.get(1)); &#125;&#125; 上面代码中，InnerClass 就是 TestExample 的一个内部类。可以看出 InnerClass 可以直接访问 TestExample 中定义的 list 私有变量。如果不将 InnerClass 定义为内部类，想要访问 list 私有变量，没有 public getXXX 方式是不行的。 为什么内部类可以随意访问外部类的成员呢？ 当外部类的对象创建一个内部类的对象时，内部类对象必定会秘密捕获一个指向外部类对象的引用，然后访问外部类成员时，就是用那个引用来选择外围类的成员的。这些编译器已经帮我们处理了 另外注意内部类只是一种编译器现象，与虚拟机无关。编译器会将内部类编译成「外部类名$内部类名」的常规文件，虚拟机对此一无所知 内部类可以对同一包中的其他类隐藏起来我们知道，普通的类不能使用 private protected 访问权限符来修饰，而内部类则可以使用 private 和 protected 来修饰。当我们使用 private 来修饰内部类的时候，这个类就对外隐藏了。这有什么用？当内部类失信案例 某个接口的时候，再进行向上转型，对外部来说，就完全实现了接口的实现。如下： 1234567891011121314151617181920212223242526272829public interface InterfaceTest &#123; void test();&#125;public class Example &#123; // 内部类实现 InterfaceTest 接口 private class InsideClass implements InterfaceTest &#123; public void test() &#123; System.out.println("这是一个测试"); &#125; &#125; // 返回一个 InterfaceTest 实例 public InterfaceTest getIn() &#123; return new InsideClass(); &#125;&#125;public class TestExample &#123; public static void main(String[] args) &#123; Example example = new Example(); InterfaceTest in = example.getIn(); in.test(); &#125;&#125; 上面的代码我们只知道 Example 的 getIn() 方法能返回一个 InterfaceTest 实例但并不知道这个实例是怎么实现的。而且由于 InnerClass 是 private 的，所以我们如果不看代码的话根本看不到这个具体类的名字，所以说它可以很好的实现隐藏 内部类可以实现 Java 单继承的缺陷Java 是不允许使用 extends 去继承多个类的，但内部类的引入可以很好地解决这个事情。 每个内部类都可以继承自一个（接口的）实现，所以无论外围类是否已经继承了某个（接口的）实现，对于内部类没有影响。如果没有内部类提供的，可以继承多个具体的或抽象的类的能力，一些设计与编程问题就难以解决。接口解决了部分问题，一个类可以实现多个接口，内部类允许继承多个非接口类型（类或抽象类） Java 只能继承一个类这个大家都知道，而在有内部类之前它的多重继承方式是用接口来实现的。但使用接口有时候有很多不方便 的地方。比如我们实现一个接口就必须实现它里面的多有方法。而有了内部类就不一样了，它可以使我们的类继承多个具体类或抽象类。如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 抽象类 Apublic abstract class ClassA &#123; public String name() &#123; return "liuyifei"; &#125; public abstract void doSomething();&#125;// 具体类 Bpublic class ClassB &#123; public int age() &#123; return 25; &#125;&#125;public class MainExample &#123; private class Test1 extends ClassA &#123; public String name() &#123; return super.name(); &#125; @Override public void doSomething() &#123; System.out.println("测试doSomething"); &#125; &#125; private class Test2 extends ClassB &#123; public int age() &#123; return super.age(); &#125; &#125; public String name() &#123; return new Test1().name(); &#125; public int age() &#123; return new Test2().age(); &#125; public void doSomething() &#123; new Test1().doSomething(); &#125; public static void main(String[] args) &#123; MainExample mi = new MainExample(); System.out.println("姓名" + mi.name()); System.out.println("年龄" + mi.age()); mi.doSomething(); &#125;&#125; 上面这个例子可以看出来，MainExample 类通过内部类拥有了 ClassA 和 ClassB 的两个类的继承关系。 内部类与外部类的关系对于非静态内部类，内部类的创建依赖外部类的实例对象，在没有外部类实例之前是无法创建内部类的 内部类是一个相对独立的实体，与外部类不是 is - a 关系 创建内部类的时刻并不依赖于外部类的创建 创建内部类的时刻并不依赖于外部类的创建这是《Thinking In Java》中的一句话，大部分人看到这里会断章取义的认为，内部类的创建不依赖于类的创建，这种理解是错误的，去掉「时刻」二字就会变了一个味道 事实上静态内部类「嵌套类」的确不依赖于外部类的创建，因为 static 并不依赖于实例，而依赖于 Class本身 但是对于普通的内部类，其必须依赖于外部类实例的创建。正如上面第一条关系所说：对于非静态内部类，内部类的创建依赖于外部类的实例对象，在没有外部类实例之前是没办法创建内部类的 对于普通内部类创建方法有两种： 12345678910111213141516171819202122public class ClassOuter &#123; public void fun() &#123; System.out.println("外部类方法"); &#125; public class InnerClass &#123; &#125;&#125;public class TestInnerClass &#123; public static void main(String[] args) &#123; // 创建方式 1 ClassOuter.InnerClass innerClass = new ClassOuter().new InnerClass(); // 创建方式 2 ClassOuter outer = new ClassOuter(); ClassOuter.InnerClass inner = outer.new InnerClass(); &#125;&#125; 需要注意的是，正是由于这种依赖关系，所以普通内部类中不允许有 static 成员，包括嵌套类（内部类的静态内部类）。因为 static 本身是针对类本身来说的，又由于非 static 内部类总是由一个外部的对象生成，既然与对象相关，就没有静态的字段和方法。当然静态内部类不依赖于外部类，所以其允许有 static 成员 内部类是一个相对独立的实体，与外部类不是 is - a 关系首先什么是「is - a 关系」。is - a 关系是指继承关系。知道什么是 is - a 关系后，内部类与外部类不是 is - a 关系就很容易理解了 对于内部类是一个相对独立的实体，我们可以从两个方面来理解这句话： 一个外部类可以拥有多个内部类对象，而它们之间没有任何关系，是独立的个体 从编译结果来看，内部类被表现为「外部类$内部类.class」，所以对于虚拟机来说它与一个单独的类来说没什么区别。但是我们知道它们是有关系的，因为内部类默认持有一个外部类的引用 内部类的分类内部类可以分为：静态内部类（嵌套类）和非静态内部类。非静态内部类有可以分为：成员内部类、方法内部类匿名内部类。 静态内部类和非静态内部类的区别： 静态内部类可以有静态成员，而非静态内部类不能有静态成员 静态内部类可以访问外部类的静态变量，而不可访问外部类的非静态变量 非静态内部类的非静态成员可以访问外部类的非静态变量 静态内部类的创建不依赖于外部类，而非静态内部类必须依赖于外部类的创建而创建 我们通过一个例子来加深一下理解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class ClassOuter &#123; private int noStaticInt = 1; private static int STATIC_INT = 2; public void fun() &#123; System.out.println("外部类方法"); &#125; public class InnerClass &#123; // 下面那句代码编译器会报错，非静态内部类不能有静态成员 // static int num = 1; public void fun() &#123; // 非静态内部类的非静态成员可以访问外部类的非静态变量 System.out.println(STATIC_INT); System.out.println(noStaticInt); &#125; &#125; public static class StaticInnerClass &#123; // 静态内部类可以有静态成员 static int NUM = 1; public void fun() &#123; System.out.println(STATIC_INT); // 下面那句代码会报错，不可访问外部类的非静态变量 // System.out.println(noStaticInt); &#125; &#125;&#125;public class TestInnerClass &#123; public static void main(String[] args) &#123; // 非静态内部类 创建方式 1 ClassOuter.InnerClass innerClass = new ClassOuter().new InnerClass(); // 非静态内部类 创建方式 2 ClassOuter outer = new ClassOuter(); ClassOuter.InnerClass inner = outer.new InnerClass(); // 静态内部类的创建方式 ClassOuter.StaticInnerClass staticInnerClass = new ClassOuter.StaticInnerClass(); &#125;&#125; 局部内部类 如果一个内部类只在一个方法中使用到了，那么我们可以将这个类定义在方法内部，这种内部类成为局部内部类。其作用域仅限于该方法 局部内部类有几点值得我们注意的地方： 局部内部类不允许使用访问权限修饰符。private public protected 都不允许 局部内部类对外完全隐藏，除了创建这个类的方法可以访问它，其它的地方都是不允许访问的 局部内部类与成员内部类不同之处就是它可以引用方法的局部变量，但是该局部变量必须声明为 final，而且内部不允许修改该变量的值。如果不加 final，编译器会自动加上 final 123456789101112131415161718192021222324252627282930public class ClassOuter &#123; private int noStaticInt = 1; private static int STATIC_INT = 2; private Integer params; public void fun() &#123; System.out.println("外部类方法"); &#125; public void testFunctionClass() &#123; Integer params = 0; class FunctionClass &#123; private void fun() &#123; System.out.println("局部内部类的输出"); System.out.println(STATIC_INT); System.out.println(noStaticInt); System.out.println(params); // params 不可变所以这句话编译错误 // params++; &#125; &#125; FunctionClass functionClass = new FunctionClass(); functionClass.fun(); &#125;&#125; 匿名内部类 匿名内部类是没有访问修饰符的 匿名内部类必须继承一个抽象类或者接口 匿名内部类中不能存在任何静态成员或方法 匿名内部类是没有构造方法的，因为它没有类名 与局部内部类相同，匿名内部类也可以引用局部变量，此变量也必须声明为 final 1234567891011121314151617181920public class Button &#123; public void click(final int params) &#123; new ActionListener() &#123; @Override public void onAction() &#123; System.out.println("click action..." + params); &#125; &#125;.onAction(); &#125; public interface ActionListener &#123; void onAction(); &#125; public static void main(String[] args) &#123; Button button = new Button(); button.click(2); &#125;&#125; 为什么局部变量需要 final 修饰因为局部变量和匿名内部类的生命周期不同 匿名内部类是创建后存储在堆中的，而方法中的局部变量是存储在 Java 栈中。当方法执行完毕后，就进行退栈，同时局部变量也会消失。那么此时匿名内部类还有可能在堆中存储着，那么匿名内部类要到哪里去找这个局部变量呢？ 为了解决这个问题，编译器自动帮我们在匿名内部类中创建了一个局部变量的备份，就是说即使方法执行结束，匿名内部类中还有一个备份，自然就不怕找不到了 但是，如果局部变量中的 a 不停的在变化，那么岂不是也要让备份 a 的变量无时无刻地变化。为了保持局部变量与匿名内部类中备份域保持一致，编译器不得不规定死这些局部域必须是常量，一旦赋值不能再发生变化。这就是为什么匿名内部类应用外部方法的域必须是常量域的原因了 特别注意：在 Java 8 中已经去掉对 final 的修饰限制，但其实只要在匿名内部类使用了，该变量还是会自动变成 final 类型（只能使用，不能赋值） 实际开发中内部类有可能会引起的问题内部类会造成程序的内存泄露要想了解为啥内部类会造成内存泄露，我们需要了解 Java 虚拟机的回收机制。Java 的内存回收机制通过「可达性分析」来实现。即 Java 虚拟机会通过内存回收机制来判定引用是否可达，如果不可达就会在某些时刻去回收这些引用 那么内部类在什么情况下会造成内存泄露的可能呢 如果一个匿名内部类没有被任何引用持有，那么匿名内部类对象用完就有机会被回收 如果内部类仅仅只是在外部类中被引用，当外部类不再被引用时，外部类和内部类就可以被 GC 回收 如果当内部类的引用被外部类以外的其他类引用时，就会造成内部类和外部类无法被 GC 回收的情况，即使外部类没有被引用，因为内部类持有指向外部类的引用 ‘ 参考资料搞懂 Java 内部类]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 零拷贝原理]]></title>
    <url>%2FCKING.github.io%2F2020%2F12%2F21%2FLinux-%E9%9B%B6%E6%8B%B7%E8%B4%9D%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[零拷贝就是没有把数据从一个存储区域拷贝到另一个存储区域，但是没有数据的复制，怎么可能实现数据的传输呢？其实我们在 Java NIO、netty、kafka 遇到的零拷贝，并不是不复制数据，而是减少不必要的数据拷贝次数，从而提升代码的性能 零拷贝的好处 减少或避免不必要的 CPU 数据拷贝，从而释放 CPU 去执行其他任务 零拷贝机制能减少用户空间和操作系统内核空间的上下文切换 减少内存的占用 内核空间和用户空间 内核空间：Linux 自身使用的空间。主要提供进程调度、内存分配、连接硬件资源等功能 用户空间：提供给各个程序进程的空间。用户空间不具有访问内核空间资源的权限，如果应用程序需要使用到内核空间的资源，则需要通过系统调用来完成：从用户空间切换到内核空间，完成相关操作后再从内核空间切换回用户空间 缓冲区和虚拟内存直接内存访问直接内存访问（Direct Memory Access）（DMA）：DMA 允许外设设备和内存存储器之间直接进行 IO 数据传输，其过程不需要 CPU 的参与 缓冲区缓冲区是所有 I/O 的基础，I/O 无非就是把数据移进或移出缓冲区 进程发起 read 请求，内核先检查内核空间缓冲区是否存在进程所需数据，如果已经存在，则直接 copy 数据到进程的内存区。如果没有，系统则向磁盘请求数据，通过 DMA 写入内核的 read 缓冲区，接着再将内核缓冲区数据 copy 到进程的内存区 进程发起 write 请求，则是把进程的内存区数据 copy 到内核的 write 缓冲区，然后再通过 DMA 把内核缓冲区数据刷回磁盘或者网卡中 虚拟内存现代操作系统都使用虚拟内存，有如下两个好处： 一个以上的虚拟地址可以指向同一个物理内存地址 虚拟内存空间可大于实际可用的物理地址 利用第一点特性可以把内核空间地址和用户空间的虚拟地址映射到同一个物理地址，这样 DMA 就可以填充（读写）对内核和用户空间进程同时可见的缓冲区了。大致如下： 传统的 I/O123#include &lt;unistd&gt;ssize_t write(int filedes, void *buf, size_t nbytes);ssize_t read(int filedes, void *buf, size_t nbytes); 如 Java 在 Linux 系统上，读取一个磁盘文件，并发送到远程端的服务 发出 read 系统调用，会导致用户空间到内核空间的上下文切换，然后再通过 DMA 将文件中的数据从磁盘上读取到内核空间缓冲区 接着将内核空间缓冲区的数据拷贝到用户空间进程内存，然后 read 系统调用返回。而系统调用的返回又会导致一次内核空间到用户空间的上下文切换 wirte 系统调用，则再次导致用户空间到内核空间的上下文切换，将用户空间的进程里的内存数据复制到内核空间的 socket 缓冲区（也是内核缓冲区，不过是给 socket 使用的），然后 write 系统调用返回，再次出发上下文切换 至于 socket 缓冲区到网卡的数据传输则是独立异步的过程，也就是说 write 系统调用的返回并不保证数据被传输到网卡 一共有四次用户空间和内核空间的上下文切换。四次数据的 copy，分别是两次 CPU 数据复制，两次 DMA 数据复制 mmap + write 实现的零拷贝12#include &lt;sys/mman.h&gt;void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset) mmap + write 实现的零拷贝流程大概如下： 发出 mmap 系统调用，导致用户空间到内核空间的上下文切换。然后通过 DMA 引擎将磁盘文件中的数据复制到内核空间缓冲区 mmap 系统调用返回，导致内核空间到用户空间的上下文切换 这里不需要将数据从内核空间复制到用户空间，因为用户空间和内核空间共享了这个缓冲区 发出 write 系统调用，导致用户空间到内核空间的上下文切换。将数据从内核空间缓冲区复制到内核空间 socket 缓冲区。write 系统调用返回，导致内核空间到用户空间的上下文切换 异步，DMA 引擎将 socket 缓冲区中的数据 copy 到网卡 通过 mmap 实现的零拷贝 I/O 进行了 4 次用户空间与内核空间的上下文切换，以及 3 次数据拷贝；其中 3 次数据拷贝包含了 2 次 DMA 拷贝和 1 次 CPU 拷贝 sendfile 实现的零拷贝12#include &lt;sys/sendfile.h&gt;ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); sendfile 实现的零拷贝流程如下： 发出 sendfile 系统调用，导致用户空间到内核空间的上下文切换，然后通过 DMA 引擎将磁盘文件中的内容复制到内核空间缓冲区中，接着再将数据从内核空间复制到 socket 相关的缓冲区 sendfile 系统调用返回，导致内核空间到用户空间的上下文切换。DMA 异步将内核空间 socket 缓冲区中的数据传递到网卡 通过 sendfile 实现的零拷贝 I/O 使用了 2 次用户空间与内核空间的上下文切换，以及 3 次数据的拷贝。其中 3 次数据拷贝包括了 2 次 DMA 拷贝和 1 次 CPU 拷贝 带有 DMA 收集拷贝功能的 sendfile 实现的零拷贝从 Linux 2.4 版本开始，操作系统提供 scatter 和 gather 的 SG - DMA 方式，直接从内核空间缓冲区中将数据读取到网卡，无需将内核空间缓冲区的数据再复制一份到 socket 缓冲区。大概流程如下： 发出 sendfile 系统调用，导致用户空间到内核空间的上下文切换。通过 DMA 引擎将磁盘文件中的内容复制到内核空间缓冲区 这里没把数据复制到 socket 缓冲区，取而代之的是，相应的描述符信息被复制到 socket 缓冲区。该描述符包含了两种信息：1、内核缓冲区的内存地址；2、内核缓冲区的偏移量 sendfile 系统调用返回，导致内核空间到用户空间的上下文切换。DMA 根据 socket 缓冲区的描述符提供的地址和偏移量直接将内核缓冲区中的数据复制到网卡 带有 DMA 手机拷贝功能的 sendfile 实现的 I/O 使用了 2 次用户空间与内核空间的上下文切换，以及 2 次数据的拷贝，而且这 2 次的数据拷贝都是非 CPU 拷贝。这样一来就实现了最理想的零拷贝 I/O 传输了，不需要任何一次的 CPU 拷贝，以及最少的上下文切换 Java 提供的零拷贝方式Java NIO 的零拷贝实现是基于 mmap + write 方式 FileChannel 的 map 方法产生的 MappedByteBuffer FileChannle 提供了 map() 方法，该方法可以在一个打开的文件和 MappedByteBuffer 之间建立一个虚拟内存映射，MappedByteBuffer 继承于 ByteBuffer map 方法底层是通过 mmap 实现的，因此将文件内存从磁盘读取到内核缓冲区后，用户空间和内核空间共享该缓冲区 12345678910111213public static void main(String[] args) throws IOException &#123; FileChannel readChannel = FileChannel.open(Paths.get("D:\\test\\read.txt"), StandardOpenOption.READ); FileChannel writeChannel = FileChannel.open(Paths.get("D:\\test\\write.txt"), StandardOpenOption.WRITE, StandardOpenOption.CREATE); long size = readChannel.size(); MappedByteBuffer data = readChannel.map(FileChannel.MapMode.READ_ONLY, 0, size); //数据传输 writeChannel.write(data); readChannel.close(); writeChannel.close(); &#125; FileChannel 的 transferTo、transferFrom 如果操作系统底层支持的话，transferTo、transferFrom 也会使用相关的零拷贝技术来实现数据的传输。用法如下： 12345678910111213141516public static void main(String[] args) throws IOException &#123; FileChannel readChannel = FileChannel.open(Paths.get("D:\\test\\read.txt"), StandardOpenOption.READ); FileChannel writeChannel = FileChannel.open(Paths.get("D:\\test\\write.txt"), StandardOpenOption.WRITE, StandardOpenOption.CREATE); long size = readChannel.size(); long position = readChannel.position(); // 数据传输 readChannel.transferTo(position, size, writeChannel); // 效果和 transferTo 一样 writeChannel.transferFrom(readChannel, position, size); readChannel.close(); writeChannel.close();&#125; 参考资料Linux 零拷贝原理]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>杂记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态规划解题框架]]></title>
    <url>%2FCKING.github.io%2F2020%2F12%2F14%2F%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E8%A7%A3%E9%A2%98%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[动态规划问题一般形式就是求最值。既然要求最值，核心问题是什么？求解动态规划的核心问题就是穷举。因为要求最值吗，肯定要把所有可行的答案穷举出来，然后在其中找最值 但是，动态规划的穷举有点特别，因为这类问题存在「重叠子问题」，如果暴力穷举的话效率会很低，所以需要「备忘录」来优化穷举过程，避免不必要的计算。而且，动态规划问题一定会具备「最优子结构」，才能通过子问题的最值得到原问题的最值 另外，虽然动态规划的核心思想是穷举求最值，但是问题可以千变万化，穷举所有可行解并不是一件容易的事，只有列出正确的「状态转移方程」才能正确地穷举 以上提到的重叠子问题，最优子结构、状态转移方程就是动态规划三要素。具体什么意思待会会举例详解，但是在实际的算法问题中，写出状态转移方程式最困难的。我们用一个思维框架，辅助你思考状态转移方程： 明确 base case -&gt; 明确「状态」-&gt; 明确「选择」-&gt; 定义 dp 数组 / 函数的含义 按上面的套路走，最后的结果就可以套这个框架： 1234567891011// 初始化 base casedp[0][0][...] = base// 进行状态转移for(状态 1 : 状态 1 的所有取值) &#123; for(状态 2 : 状态 2 的所有取值) &#123; for ... &#123; dp[状态 1][状态 2][...] = 求最值(选择 1, 选择 2 ...) &#125; &#125;&#125; 下面通过斐波那契数列问题和凑零钱问题来详解动态规划的基本原理 斐波那契数列暴力递归斐波那契数列的数学形式就是递归的，写成代码如下所示： 123456int fib(int N) &#123; if(N == 1 || N == 2) &#123; return 1; &#125; return fib(N - 1) + fib(N - 2);&#125; 这样写代码虽然简洁易懂，但是十分低效。假设 N = 20，画出的递归树如下： 怎么理解这棵递归树？就是说想要计算原问题 f(20)，我们就要先计算出子问题 f(19) 和 f(18)，然后要计算 f(19)，就要先算出子问题 f(18) 和 f(17)，以此类推。最后遇到 f(1) 或 f(2) 的时候，结果已知，就能直接返回结果，递归树不再向下生长了 递归算法的时间复杂度怎么计算？就是用子问题个数乘以解决一个子问题需要的时间 首先计算子问题的个数，即递归树种节点的总数。显然二叉树节点总数为指数级别，所以子问题个数为 O(2^n)。然后计算解决一个子问题的时间。在本算法中，没有循环，只有 f(n - 1) + f(n - 2) 一个加法操作，时间为 O(1)。所以这个算法的时间复杂度为二者相乘，即 O(2^n) 观察递归树，可以发现算法低效的原因：存在大量重复计算，比如 f(18) 被计算了两次，而且以 f(18) 为根的递归树体量巨大，多算一遍，会耗费巨大的时间。更何况，还不止 f(18) 这一个节点被重复计算，所以这个算法很低效 这就是动态规划问题的第一个性质：重叠子问题。 带备忘录的递归解法既然耗时的原因是重复计算，那么我们可以造一个「备忘录」，每次算出某个子问题的答案后别急着返回，先记到「备忘录」里再返回；每次遇到一个子问题先去「备忘录」里查一查，如果发现之前已经解决过这个问题了，直接把答案拿出来用，不用再耗时去计算了 一般使用一个数组充当这个「备忘录」，当然也可以使用哈希表，思想都是一样的 1234567891011121314151617public int fib(int n) &#123; Map&lt;Integer, Integer&gt; memo = new HashMap&lt;&gt;(n); return helper(memo, n);&#125;public int helper(Map&lt;Integer, Integer&gt; memo, int n) &#123; if (n == 0 || n == 1) &#123; return n; &#125; if (memo.get(n) != null) &#123; return memo.get(n); &#125; int res = helper(memo, n - 1) + helper(memo, n - 2); memo.put(n, res); return res;&#125; 画出递归树，看一下「备忘录」做了什么 实际上，带「备忘录」的递归算法，把一棵存在巨量冗余的递归树通过「剪枝」，改造成了一幅不存在冗余的递归图，极大减少了子问题（即递归图中节点）的个数 上面说过递归问题的复杂度计算，就是用子问题个数乘以解决一个子问题需要的时间。而子问题个数，即图中节点的总数，由于本算法不存在冗余计算，子问题就是 f(1), f(2), f(3) ... f(20)，数量和输入规模 n = 20 成正比，所以子问题个数为 O(n) 解决一个子问题的时间，同上，没有循环，时间为 O(1)。所以本算法时间复杂度为 O(n)，比起暴力算法，是降维打击 dp 数组的迭代解法有了上一步「备忘录」的启发，我们可以把这个「备忘录」独立出来成为一张表，就叫做 DP table 吧，在这张表完成「自底向上」的推算 12345678public int fib(int n) &#123; int[] dp = new int[n + 1]; dp[1] = dp[2] = 1; for(int i = 3; i &lt;= n; i++) &#123; dp[i] = dp[i - 1] + dp[i - 2]; &#125; return dp[n];&#125; 从上图可以知道，这个 DP table 很像之前那个「剪枝」后的结果，只是反过来算而已。实际上，带备忘录的递归解法中的「备忘录」，最终完成后就是这个 DP table，所以这两种解法是差不多的，大部分情况下，效率也基本相同 这里，引出「状态转移方程」这个名词，实际上就是描述问题结构的数学形式 为啥叫「状态转移方程」？你把 f(n) 想做一个状态 n，这个状态 n 是由状态 n - 1 和状态 n - 2 相加转移而来，这就叫状态转移 你会发现，上面的几种解法中的所有操作，例如 return f(n - 1) + f(n - 2)，dp[i] = dp[i - 1] + dp[i - 2]，以及对备忘录或 DP table 的初始化操作，都是围绕这个方程式的不同表现形式。可见列出「状态转移方程」的重要性，它是解决问题的核心。而且，其实状态转移方程直接代表着暴力解法 不要看不起暴力解，动态规划问题最困难的就是写出这个暴力解，即状态转移方程。只要写出暴力解，优化方法无非是用备忘录或者 DP table，再无奥妙可言 这个例子的最后，将一个细节优化。细心的读者会发现，根据斐波那契数列的状态转移方程，当前状态只和之前的两个状态有关，并不需要那么长的一个 DP table 来存储所有的状态，只要想办法存储之前的两个状态即可。所以，可以进一步优化，把空间复杂度降为 O(1)： 12345678910111213public int fib(int n) &#123; if (n == 2 || n == 1) &#123; return 1; &#125; int sum = 0; int prev = 1, curr = 1; for(int i = 3; i &lt;= n; i++) &#123; sum = prev + curr; prev = curr; curr = sum; &#125; return sum;&#125; 这个技巧就是所谓的「状态压缩」，如果我们发现每次转移状态只需要 DP table 中的一部分，那么可以尝试用状态压缩来缩小 DP table 的大小，只记录必要的数据。上述例子就相当于把 DP table 的大小从 n 缩小到 2。 凑零钱问题先看下题目：给你 k 种面值的硬币，面值分别为 c1, c2 ... ck，每种硬币的数量无限，再给一个总金额 amount，问你最少需要几枚硬币凑出这个金额，如果不可能凑出，返回 -1。对应的 LeetCode 链接为 零钱兑换 你觉得计算机该如何解决这个问题？显然，就是把所有可能的凑硬币方法都穷举出来，然后找找看最少需要多少枚硬币 暴力递归首先，这个问题是动态规划问题，因为它具有「最优子结构」。要符合「最优子结构」，子问题间必须互相独立。 比如说，你考试，没门科目的成绩都是互相独立的。你的原问题是考出最高的总成绩，那么你的子问题就是要把语文考到最高，数学考到最高 …… 为了每门课考到最高，你要把每门课相应的选择题分数拿到最高，填空题分数拿到最高。当然，最终就是你每门课都是满分，这就是最高的总成绩 得到了正确的结果：最高的总成绩就是总分。因为这个过程符合最优子结构，「没门科目考到最高」这些子问题是互相独立，互不干扰的 但是，如果加一个条件：你的语文成绩和数学成绩会互相制约，数学分数高，语文分数就会降低，反之亦然。这样，你能考到的最高成绩就达不到总分了，按刚才的思路就会得到错误的结果。因为子问题并不独立，语文数学成绩无法同时最优，所以最优子结构被破坏 回到凑零钱问题，为什么它符合最优子结构？比如你想求 amount = 11 时的最少硬币数，如果你知道凑出 amout = 10 的最少硬币数（子问题），你只需要把子问题的答案加一（再选一枚面值为 1 的硬币）就是原问题的答案。因为硬币的数量是没有限制的，所以子问题之间没有相互制约，是互相独立的 那么，既然知道了这是个动态规划问题，就要思考如何列出正确的状态转移方程 确定 base case，这个很简单。显然目标金额 amount 为 0 时算法返回 0，因为不需要任何硬币就已经凑出目标金额了 确定「状态」，也就是原问题和子问题中会变化的变量。由于硬币数量无限，硬币的面额也是题目中给定的，只有目标金额会不断地向 base case 靠近，所以唯一的「状态」就是目标金额 amount 确定「选择」，也就是导致「状态」产生变化的行为。目标金额为什么变化呢？因为你在选择硬币，你每选择一枚硬币，就相当于减少目标金额。所以说所有硬币的面值，就是你的「选择」 明确 dp 函数 / 数组的定义。我们这里讲的是自顶向下的解法，所以会有一个递归的 dp 函数，一般来说函数的参数就是状态转移中会变化的量，也就是上面说到的「状态」；函数的返回值就是题目要求我们计算的量。就本题来说，状态只有一个，即「目标金额」，题目要求我们计算凑出目标金额所需的最少硬币数量。 所以我们可以这样定义 dp 函数： dp(n) 的定义：输入一个目标金额 n，返回凑出目标金额 n 的最少硬币数量 接着我们看代码实现 12345678910111213141516171819202122public int coinChange(int[] coins, int amount) &#123; // base case if (amount == 0) &#123; return 0; &#125; if (amount &lt; 0) &#123; return -1; &#125; // 求最小值，所以初始化为正无穷 int res = Integer.MAX_VALUE; // 做选择，选择需要硬币最少的那个结果 for(int coin : coins) &#123; int subProblem = coinChange(coins, amount - coin); // 子问题无解，跳过 if(subProblem == -1) &#123; continue; &#125; res = Math.min(res, 1 + subProblem); &#125; return res == Integer.MAX_VALUE ? -1 : res;&#125; 至此，状态转移方程其实已经完成了，以上算法已经是暴力破解法了，以上代码的数学形式就是状态代码方程： 至此，这个问题就解决了，只不过需要消除一下重叠子问题，比如 amount = 11, coins = {1, 2, 5} 时画出递归树如下： 子问题总数为递归树节点个数，这个比较难看出来，是 O(n^k)，总之是指数级别的。每个子问题中含有一个 for 循环，复杂度为 O(k)，所以总时间复杂度为 O(k * n^k)，指数级别 带备忘录的递归类似斐波那契数列，只需要稍加修改，就可以通过备忘录消除子问题 12345678910111213141516171819202122232425262728293031Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;();public int coinChange(int[] coins, int amount) &#123; // base case if (amount == 0) &#123; return 0; &#125; if (amount &lt; 0) &#123; return -1; &#125; // 查备忘录，避免重复计算 if(map.get(amount) != null) &#123; return map.get(amount); &#125; // 求最小值，所以初始朱为正无穷 int res = Integer.MAX_VALUE; for(int coin : coins) &#123; int subProblem = coinChange(coins, amount - coin); // 子问题无解，跳过 if(subProblem == -1) &#123; continue; &#125; res = Math.min(res, 1 + subProblem); &#125; res = res == Integer.MAX_VALUE ? -1 : res; map.put(amount, res); return res;&#125; 很显然，「备忘录」大大减小了子问题数目，完全消除子问题的冗余，所以子问题总数不会超过金额数 n，即子问题数目为 O(n)。处理一个子问题的时间不变，仍是 O(k)，所以总的时间复杂度是 O(kn) dp 数组的迭代解法我们也可以自底向上使用 dp table 来消除重叠子问题，关于「状态」「选择」和 base case 与之前没有区别，dp 数组的定义和刚才 dp 函数类似，就是把「状态」，也就是目标金额作为变量。不过，dp 函数体现在函数参数，而 dp 数组体现在数组索引： dp 数组的定义：当目标金额为 i 时，至少需要 dp[i] 枚硬币凑出 根据开头给出的动态规划代码框架可以写出如下解法： 12345678910111213141516171819202122232425public int coinChange(int[] coins, int amount) &#123; // 数组大小为 amount + 1，初始值为 amount + 1 int[] dp = new int[amount + 1]; for(int i = 0; i &lt; dp.length; i++) &#123; dp[i] = amount + 1; &#125; // base case dp[0] = 0; // 外层 for 循环在遍历所有状态的取值 for(int i = 0; i &lt; dp.length; i++) &#123; // 内层 for 循环在求所有选择的最小值 for(int coin : coins) &#123; // 子问题无解，跳过 if(i - coin &lt; 0) &#123; continue; &#125; dp[i] = Math.min(dp[i], 1 + dp[i - coin]); &#125; &#125; return (dp[amount] == amount + 1) ? -1 : dp[amount]; &#125; 总结斐波那契数列的问题，解释了如何通过「备忘录」或者「dp table」的方法来优化递归树，并且明确了这两种方法本质上是一样的，只是自顶向下和自底向上的区别而已 凑零钱问题，展示了如何流程化确定「状态转移方程」，只要通过状态转移方程写出暴力递归解，剩下的就是优化递归树，消除重叠子问题而已 计算机解决问题其实没有任何奇技淫巧，它唯一的解决办法就是穷举，穷举所有可能性。算法设计无非就是先思考“如何穷举”，然后再追求“如何聪明地穷举”。 列出动态转移方程，就是在解决“如何穷举”的问题。之所以说它难，一是因为很多穷举需要递归实现，二是因为有的问题本身的解空间复杂，不那么容易穷举完整。 备忘录、DP table 就是在追求“如何聪明地穷举”。用空间换时间的思路，是降低时间复杂度的不二法门，除此之外，试问，还能玩出啥花活？ 参考资料动态规划解题套路框架]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分库分表案例]]></title>
    <url>%2FCKING.github.io%2F2020%2F11%2F30%2F%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[假设有这么一个订单系统，每天新增数据大概是 1W 左右，每个月是新增 30W 数据，每年是新增 360W 数据，那么最多 3 年就到千万级大表了，这个就会导致你涉及订单的操作，速度挺慢的。 所以要做分库分表。订单表在拆分的时候，往往要考虑三个维度。一个是要按照订单 id 为粒度去分库分表，也就是把订单 id 进行 hash 之后，对表数量进行取模然后把订单数据均匀分散到 100 ~ 1000 个表里，再把这些表分散在多台服务器上 另外两个维度是用户端和运营端。用户端，就是用户可能要查自己的订单，运营端就是公司可能要查所有订单，如何解决这类问题？基本上针对用户端，需要按照（userid, orderid）这个表结构，去做一个索引映射表。userid 和 orderid 的一一对应关系要放在这个表里，然后针对 userid 为粒度去进行分库分表，也就是对 userid 进行 hash 后取模，然后把数据均匀分散在很多索引映射表里，再把表放在很多数据库里 然后每次客户端拿出 APP 查询自己的订单，直接根据 userid 去 hash 然后取模路由到一个索引映射表，找到这个用户的 orderid，这里可以做一个分页，因为一般订单都是支持分页的，此时可以允许用户分页查询 orderid，然后拿到一堆 orderid，再根据 orderid 去按照 orderid 粒度分库分表的表里提取订单完整数据 至于运营端，一般都是要根据 N 多条件对订单进行搜索的，此时根上次讲的一样，可以把订单数据的搜索条件都同步到 ES 里，然后用 ES 来进行复杂搜索，找出来一波 orderid，再根据 orderid 去分库分表里找订单完整数据 基本分库分表的玩法都是这套思路，按业务 id 分库分表，建立索引映射表同时进行分库分表，数据同步到 ES 做复杂搜索，基本这套玩法就可以保证你的分库分表场景下，各种业务功能都可以支撑 跨库的分页操作接着是关于分库分表后的跨库 / 跨表的分页问题，例如之前的那个订单场景，假设用户现在要查询自己的订单，同时订单要求要支持分页，怎么实现？ 其实按我们之前说的，基本上你只要按照 userid 先去分库分表的（userid, orderid）索引映射表里查找到你的那些 orderid，然后搞一个分页就可以了。对分页内的 orderid，每个 orderid 都得去按 orderid 分库分表的数据里查找完整的订单数据，这就可以搞定分库分表环境下的分页问题 这仅仅只是一个例子，告诉你的是，如果要在分库分表下搞分页，最好是保证你的一个主数据粒度（比如 userid）是你的分库分表的粒度，你可以根据一个业务 id 路由到一个表找到他的全部数据，这就可以做分页了 如果我想对用户下的订单做分页，同时还能指定一些查询条件呢？这其实也是很多 APP 都支持的，就是对自己的订单查询，有的 APP 是支持指定一些条件的，例如订单名称模糊搜索。例如，在我的订单界面，可以按照订单状态来搜索，分别是全部、代付款、待收货、已完成、已取消几个状态，同时就是对订单购买的商品标题进行模糊搜索 此时怎么分页？你的索引映射表里，只有（userid, orderid）。但这又怎样，你完全可以在这个索引映射表里加入更多的数据，比如（userid, orderid, order_status, product_description），加上订单所处的状态，以及商品的标题。副标题等文本 然后你在对「我的订单」进行分页的时候，直接就可以根据 userid 去索引映射表里找到用户的所有订单，然后按照订单状态、商品描述文本模糊匹配去搜索，完了再分页，分页拿到的 orderid，再去获取订单需要展示的数据。 如果是针对运营端的分页查询需求呢？数据直接进入 ES 里，通过 ES 就可以对多条进行搜索同时再进行分页 当然，也有人说过一些跨库的分页方案。比如说要针对跨多个库和多个表的数据搞查询和分页，基本上只能是自己从各个库表拉数据到内存，自己内存里做筛选和分页了。或者是基于数据库中间件去做，数据库中间件本质也是干这个，把各个库表的数据拉到内存做筛选和分页 实际上这种方案的效率和性能都是极差的，基本都是几秒级别的速度。所以当你觉得似乎要跨库和表查询分页的时候，建议，第一，是不是可以把你查询里按照某个主要的业务 id 进行分库分表建立一个索引映射表；第二，是不是可以把这个查询里要的条件都放到索引映射表里去；第三，是不是可以通过 ES 来搞定这个需求 分库分表的扩容假设分库分表了，比如搞了几个数据库服务器，每个服务器上部署了一个数据库实例，然后你的业务库拆分在各个服务器上，你的业务表拆分为几百上千个，每个服务器上都有一部分。 此时过了几年后，你每个表的数据量都增长到了一定水准。比如刚拆分的时候每个表才 100W 数据，结果过了几年，每个表都增长到了几百万数据，此时怎么办？只能是把表进一步拆分，增加更多的表了。完了增加更多的表后还得把数据做迁移，更改系统的路由规则，极为的麻烦 大家觉得真的应该出现这种情况吗？其实不是，我们应该一开始，就完全可以多分一些表，比如你数据量只有 10 亿级，那么你可以分为 10000 个表，每个表才 10W 数据，而且后续你计算好增量，可能 10 年，20 年过后，单表数据百万级。此时就不会出现上述情况了 所以，从一开始，你的表数量宁愿多一些，也别太少，最好是计算一下数据增量，让自己永远不用增加更多的表 另外，如果过了几年后，你的每一台服务器上的存储空间要耗尽了，或者是写并发压力太大，每个服务器的并发压力都到瓶颈了呢？此时就要增加更多的数据库服务器。增加服务器之后，还要把你的表均匀分散迁移到新增加的数据库服务器上去，然后修改一些系统里的路由规则，用新的路由规则保证你能正确的把数据路由到指定表以及指定库上去就行 因此关于数据库扩容这块，网上虽然有很多方案，但是我们建议及时，刚开始拆分，表数据可以多一些，避免后续要增加表。然后数据库服务器扩容是没问题，直接把表做一下迁移就行了，然后修改路由规则]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[上亿数据量的用户表如何进行水平拆分]]></title>
    <url>%2FCKING.github.io%2F2020%2F11%2F24%2F%E4%B8%8A%E4%BA%BF%E6%95%B0%E6%8D%AE%E9%87%8F%E7%9A%84%E7%94%A8%E6%88%B7%E8%A1%A8%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E6%B0%B4%E5%B9%B3%E6%8B%86%E5%88%86%2F</url>
    <content type="text"><![CDATA[今天我们只讲解分库分表的整体方案设计，但是在进行具体的方案落地的时候，是需要数据库中间件技术的支持的，业内常用的一般有 Sharding - Sphere 以及 MyCat 两种，各自用的公司也很多，你们可以自行选择一个数据库中间件技术，熟悉一下它们的用法 今天要说的是海量用户数据的分库分表的方案。一般公司都会有个用户中心，而且用户中心就是负责所有用户的数据管理，包括了用户的数据存储，用户信息的增删改查，用户注册登录等等。我们的背景就是这么一个亿级数据量的用户表 首先，一般面对这么一个几千万级的数据，刚开始可能都是把数据库放在 MySQL 的一个单库单表里的，但是这么大量级的数据到了后期，会搞的数据库查询速度很慢。因为数据量级太大，会导致表的索引很大，树的层级很高，进而导致搜索性能下降，而且能放内存缓存的数据页是比较少的 因此，我们都建议 MySQL 单表数据量不要超过 1000 万，最好是在 500 万以内，如果能控制在 100 万以内，那是最佳的选择。基本单表 100 万以内的数据，性能上不会有太大的问题，前提是，只要你建好索引就行。其实保证 MySQL 高性能通常没什么特别高深的技巧，就是控制数据量不要太大，还有就是保证你的查询用上了索引，一般就没问题 针对这个问题，我们就可以进行分库分表了，可以选择把这个用户大表拆分为 100 张表，此时几千万数据瞬间分散到 100 个表里去，类似 user_001、user_002、user_100 这样的 100 个表，每个表也就几十万数据而已 其次，可以把这 100 个表分散到多台数据库服务器上去，那么要分散到几台服务器呢？要考虑两个点，一个是数据量有多少个 GB/TB，一个是针对用户中心的并发压力有多高。实际上用户中心的压力不会高的太离谱，因为一般不会有很多人同时登陆 / 注册，或者同时修改自己的个人信息，所以并发这块不是太大问题 数据量层面，给大家一个经验值，一般 1 亿行数据，大致在 1GB 到几个 GB 之间的范围，具体跟你一行数据有多少字段也有关系，大致就是这个范围，所以你几千万的用户数据，往多了说也就几个 GB 而已，这点数据量，对于服务器的存储空间来说，完全没压力 综上，你完全可以给他分配两台数据库服务器，放两个库，然后 100 张表均匀分散在 2 台服务器上就可以了。分的时候要指定一个字段来分，一般会指定 userId，根据用户 id 进行 hash 之后，对表进行取模，路由到一个表里去，这样可以让数据均匀分散 到此就搞定了用户表的分库分表，只要给系统加上数据库中间件技术，设置好路由规则，就可以轻松地对 2 个分库上的 100 张表进行增删改查的操作了。平时针对某个用户增删改查，直接对他的 userId 进行 hash，然后对表取模，做一个路由，就知道到哪个表里去找这个用户的数据了 但是，会出现一些问题。例如，用户在登陆的时候，可能不是根据哪个 userId 登陆的，可能是根据 username 之类的用户名、手机号之类的来登陆的，此时你又没有 userId，怎么知道去哪个表里找这个用户的数据判断是否能登陆？ 对于这个问题，一般来说就是建立一个索引映射表。就是搞一个表结构为（username, userId）的索引映射表，把 username 和 userId 一一映射，然后针对 username 再做一次分库分表，把这个索引映射表拆分为比如 100 个表分散在两台服务器里 接着用户登陆的时候，就可以根据 username 先去索引映射表里查找对应的 userId，比如对 username 进行 hash 然后取模到一个表里，找到 username 对应的 userId，接着根据 userId 进行 hash 再取模，然后路由到按照 userId分库分表里的一个表里去，找到用户的完整数据即可 但是这种方式会把一次查询转化为两个表的两次查询，先查索引映射表，再根据 userId 去查具体的数据，性能上是有一定的损耗的，不过有时候为了解决分库分表的问题，也只用用这种类似的方法 另外就是如果在公司运营团队里，有一个用户管理模块，需要对公司的用户按照手机号、地址、年龄、性别、职业等各种条件进行极为复杂的搜索，怎么处理？其实没太多的好办法，基本上就是要你对你的用户数据表进行 binlog 监听，把你要搜索的所有字段同步到 Elasticsearch 里去，建立好搜索的索引，然后你的运营系统就可以通过 Elasticsearch 去进行复杂的多条件搜索。ES 是适合干这个事情的，然后定位到一批 userId，通过 userId 回到分库分表环境里去找出具体的用户数据，在页面上展示出来即可]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 主从复制原理]]></title>
    <url>%2FCKING.github.io%2F2020%2F11%2F02%2FMySQL-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[MySQL 的主从复制架构，就是部署两台服务器，每台服务器上都有一个 MySQL，其中一个 MySQL 是 master（主节点），另一个 MySQL 是 slave（从节点）。然后我们的系统平时连接到 master 节点写入数据，当然也可以从里面查询，跟你用一个单机版的 MySQL 是一样的。但是 master 节点会把写入的数据自动复制到 slave 节点去，让 slave 节点可以跟 master 节点有一模一样的数据。如图： 这种架构的意义在哪？如果你的 MySQL 是单机部署的，一旦它宕机了，你的数据库就挂了，那么你的 Java 业务员系统也就挂了。所以在真正的生产架构里，MySQL 要做高可用架构 那高可用架构怎么做？一个先决条件就是主从复制架构。主节点可以复制数据到从节点，保证主从数据是一致的，接着万一你的主节点宕机了，此时可以让你的 Java 业务系统连接到从节点上去执行 SQL 语句。因为主从数据是一致的，所以这是没问题的 但即使生产环境使用这套架构，也还有大量的问题需要解决。例如主从进行数据复制的时候，其实从节点通常都会落后一些，所以数据不完全一致。另外，主节点宕机后，要能自动切换从节点对外提供服务，这也需要一些中间件的支持 读写分离MySQL 主从复制架构，除了实现高可用之外，其实读写分离架构，也是依赖于 MySQL 的主从复制架构的。读写分离的意思是，你的 Java 业务系统可以往主节点写入数据，但是从从节点去查询数据，把读写操作做一个分离，分离到两台 MySQL 服务器上去，一台服务器专门让你写入数据，然后复制数据到从节点，另外一台服务器专门让你查询数据。如图： 读写分离的作用是什么？假设我们的 MySQL 单机服务器配置是 8 核 16GB，每秒最多能抗 4000 读写请求。现在假设你真实的业务负载已经达到了每秒 2500 写请求 + 2500 读请求，即每秒 5000 读写请求了，此时一台 MySQL 服务器是扛不住的 此时你可以利用主从复制架构，搭建起来读写分离架构，就可以让每秒 2500 写请求落到主节点那台服务器，2500 读请求落到从节点那台服务器，用 2 台服务器来抗下每秒 5000 的读写请求。 其实，大部分 Java 系统都是读多写少，读请求远远多于写请求。那么随着系统的发展，读请求越来越多，每秒可能有 6000 读请求了，此时一个节点服务器也扛不住。此时，因为 MySQL 的主从复制架构，是支持一主多从的，所以此时可以再在一台服务器上部署一个从节点，去主节点复制数据过来，此时你就有 2 个从节点了，然后你每秒 6000 读请求就可以落到 2 个从节点上去， 每台服务器主要接受处理每秒 3000 的读请求。如图： Java 业务系统以每秒 2500 的 TPS 写入主库，然后主库会复制数据到两个从库，接着你每秒 6000 QPS 的读请求分散在两个从库上。这就是主从复制的另外一个经典的应用场景，就是读写分离。通过读写分离，可以抗下很高的读请求 在上述架构下，还可以融合高可用架构进去。因为你有多个从库，所以当你主库宕机的时候，可以通过中间件把一个从库切换为主库，此时你的 Java 业务系统可以继续运行，在实现读写分离的场景下，同时实现高可用架构 主从复制架构的工作原理MySQL 在执行增删改的时候会记录 binlog 日志，所以这个 binlog 日志就记录了所有数据的增删改的操作。然后从库上有一个 IO 线程，这个 IO 线程会复制跟主库建立一个 TCP 连接，接着请求主库传输 binlog 日志给自己。这个时候主库上有一个 IO dump 线程，就会负责通过这个 TCP 连接把 binlog 日志传输给从库的 IO 线程。如图： 接着从库的 IO 线程会把读取到的 binlog 日志数据写入到自己本地的 relay 日志文件中，然后从库上另外一个 SQL 线程会读取 relay 日志里的内容，进行日志重做，把所有在主库执行过的增删改操作，在从库上做一遍，达到一个还原数据的过程。如图： 总结起来就是，你只要给主节点挂上一个从节点，从节点的 IO 线程就会跟主节点建立网络连接，然后请求主节点传输 binlog 日志，主节点的 IO dump 线程就会负责传输 binlog 日志给从节点，从节点收到日志后就可以回访增删改操作恢复数据。在这个基础上，就可以实现 MySQL 主从节点的数据复制以及基本一致，进而可以实现高可用以及读写分离架构]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 调优案例四]]></title>
    <url>%2FCKING.github.io%2F2020%2F10%2F20%2FSQL-%E8%B0%83%E4%BC%98%E6%A1%88%E4%BE%8B%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[这个案例的背景是，有人删除了千万级的数据，结果导致了频繁的慢查询，接下来说一下这个案例排查、定位以及解决的一个过程。当时是从线上收到大量的慢查询告警开始的，当我们收到大量的慢查询告警之后，就去检查慢查询的 SQL，结果不是什么特别的 SQL，这些 SQL 语句主要都是针对一个表的，比较简单，看起来不应该会慢查询 那么有没有可能，慢查询不是 SQL 的问题，而是 MySQL 生产服务器的问题？实际上个别特殊情况下，MySQL 出现慢查询并不是 SQL 语句的问题，而是它自己生产服务器的负责太高了，导致 SQL 语句执行很慢 例如，假设现在 MySQL 服务器的磁盘 IO 负载特别高，也就是每秒执行大量的高负载的随机 IO，但是磁盘本身每秒能执行的随机 IO 是有限的。结果，就导致你正常的 SQL 语句去磁盘上执行的时候，如果要跑一些随机 IO，你的磁盘太忙了，顾不上你，导致你本来很快的 SQL，要等很久才能执行完毕，这就可能导致正常的 SQL 语句也会变成慢查询 同理，还有网络。如果网络负载很高，就可能导致你一个 SQL 语句要发送到 MySQL 上去，光是等待获取一个跟 MySQL 的连接，都要等很久；或者 MySQL 自己网络负载太高，带宽被打满了，你一个 SQL 也许执行很快，但是它查出来的数据返回给你，网络都送不出去，此时也会变成慢查询 还有 CPU 负载，如果 CPU 负载过高，也会导致 CPU 过于频繁去执行别的任务，没时间执行你这个 SQL 语句，此时也有可能导致你的 SQL 语句出现问题 所以慢查询本身不一定是 SQL 导致的，如果你觉得 SQL 不应该慢查询，但那个时间段跑这个 SQL 就是慢，那么你应该排查一下当时 MySQL 服务器的负载，尤其看看磁盘、网络以及 CPU 的负载，是否正常，如果那个时间段 MySQL 生产服务器的磁盘、网络或者 CPU 负载特别高，那么可能是服务器负载导致的问题 例如，当某个离线作业瞬间把大批量数据往 MySQL 里灌入的时候，它一瞬间服务器磁盘、网络以及 CPU 的负载会超高。此时你一个正常的 SQL 执行下去，短时间内一定会慢查询。针对此类问题，优化手段更多是控制你导致 MySQL 负载过高的那些行为，比如灌入大量数据，最好在凌晨低峰期灌入，别影响线上系统运行 但当时我们看了 MySQL 服务器的磁盘、网络以及 CPU 负载，一切正常，似乎不是这个问题导致的 profiling排查了 SQL 执行计划和 MySQL 服务器负载，都没有问题。此时就要用上一个 SQL 调优的利器了，也就是 profiling 工具，这个工具可以对 SQL 语句的执行耗时进行非常深入和细致的分析，使用这个工具的过程，大致如下所示： 首先要打开这个 profiling，要使用 set profiling = 1 这个命令，接着 MySQL 就会自动记录查询语句的 profiling 信息了 此时如果执行 show profiles 命令，就会给你列出各种查询语句的 profiling 信息，这个很关键的一点，就是它会记录下来每个查询语句的 query id，所以你要针对你需要分析的 query 找到对应的 query id，当时就是针对慢查询的那个 SQL 语句找到了 query id 然后就可以针对单个查询语句，看下它的 profiling 具体信息，使用 show profile cpu, block io for query xx，这里的 xx 是数字，此时就可以看到具体的 profile 信息了。它这里会给你展示出来 SQL 语句执行时的各种耗时，比如磁盘 IO 的耗时，CPU 等待耗时，发送数据耗时，拷贝数据到临时表的耗时等等。 这里我们检查了这个 SQL 语句的 profiling 信息，发现了一个问题，它的 Sending Data 的耗时是最高的，几乎使用了 1s 的时间，占据了 SQL 执行耗时的 99%，这就坑爹了。因为其它环节耗时低是可以理解的，毕竟这种 SQL 执行速度真的很快，基本就是 10ms 级别的，结果跑成了 1s，那肯定 Sending Data 是罪魁祸首了 Sending Data 干嘛的？MySQL 官方释义是：为一个 SELECT 语句读取和处理数据行，同时发送数据给客户端的过程。简答说就是为你的 SELECT 语句把数据读出来，同时发送给客户端 可是这个过程为什么会这么慢？profiling 确实给我们提供了线索，但是似乎还没法解决问题 接着我们又用了一个命令：show engine innodb status，看一下 InnoDB 存储引擎的一些状态，此时发现了一个奇怪的指标，就是 history list length 这个指标，它的值特别高，达到了上万这个级别 如果调优的时候发现了类似的情况，不知道一个指标什么意思，可以 Google 一下，这里直接告诉大家 之前我们讲过 MVCC 机制，这个 MVCC 和隔离级别的实现原理，跟一个 Read View 机制是有关系的，同时还有一个至关重要的机制，就是数据的 undo 多版本快照链条。你必须对一个数据有一个多版本快照链条，才能实现 MVCC 各种隔离级别 所有当你有大量事务执行的时候，就会构建这种 undo 多版本快照链条，此时 history list length 的值就会很高。然后在事务提交之后，会有一个多版本快照链条的自动 purge 清理机制，只要有清理，这个值就会降低 一般来说，这个值是不应该过于高的。但是这里的 history list length 的值过高，大量的 undo 多版本链条数据没别清理，推测可能就是有的事务长时间运行，所以他的多版本快照不能被 purge 清理，进行导致了这个 history list length 的值过高 现在我们就 GET 到了两个线索。可以肯定的是，经过两个线索的推测，在大量简单 SQL 语句变成慢查询的时候，SQL 是因为 Sending Data 环节异常耗时过高，同时此时出现了一些长事务长时间运行，大量地频繁更新数据，导致有大量的 undo 多版本快照链条，还无法 purge 清理 那这两个线索之间的关系是什么呢？我们接着排查 真相大白经过排查，发现有大量的更新语句在活跃，而且有那种长期活跃的超长事务一直在跑没有结束，结果一问系统负责人，发现他在后台跑了一个定时任务，定时清理数据，结果清理的时候一下子清理了上千万的数据 这个清理是怎么做的呢？他开了一个事务，然后在一个事务里删除上千万数据，导致这个数据一直在运行，所以才发生上面说到的现象 然后呢，这种长事务的运行会导致一个问题，那就是删除的时候仅仅只是对数据追加了一个删除标记，事实上并没有彻底删除掉。此时你如果跟长事务同时运行的其他事务在查询，它在查询的时候是可能把那上千万被标记为删除的数据都扫描一遍的。因为没扫描到一批数据，都发现标记为删除了，接着就会再继续往下扫描，所以才导致一些查询语句会那么慢 那么，为什么你启动一个事务，在事务里查询，凭什么就要去扫描之前那个长事务标记为删除状态的上千万垃圾数据呢？按说那些数据都被删除了，跟你没关系了，你可以不用去扫描他们啊 这个问题的关键点在于，那个删除千万级数据的事务是个长事务。即，当你启动新事物的时候，那个删除千万级数据的长事务一直在运行，是活跃的。 我们之前讲解 MVCC 的时候说过，当你启动一个新事务查询的时候，会生成一个 ReadView，里面包含了当前活跃事务的最大id，最下 id 和事务 id 集合，然偶胡它有一个判定规则，具体判定规则可以去回顾之前的文章 总之就是，你的新事务查询的时候，会根据 ReadView 去判断哪些数据是你可见的，以及你可见的数据版本是哪个版本，因为一个数据有一个版本链条，有时候你可能可见的仅仅是这个数据的一个历史版本而已 所以正是以为这个长事务一直在运行还在删除大量的数据，而且这些数据仅仅是标记为删除，实际还没删除，所以此时你新开事务是会读到所有被标记为删除的数据的，就会出现千万级的数据扫描，才会造成慢查询 针对这个问题，要知道的一点是，永远不要再业务高峰期去运行那种删除大量数据的语句，因为这可能导致一些正常的 SQL 都变慢查询，因为那些 SQL 也行会不断扫描你标记为删除的大量数据，好不容易扫描到一批数据，结果发现是标记为删除的，于是继续扫描下去，导致了慢查询 因此当时的解决方案也很简答，直接 kill 那个正在删除千万级数据的长事务，所有 SQL 很快恢复正常。从此以后，对于大量数据清理全部放在凌晨去执行，那个时候就没什么人使用系统了，所以查询也少]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 调优案例三]]></title>
    <url>%2FCKING.github.io%2F2020%2F09%2F25%2FSQL-%E8%B0%83%E4%BC%98%E6%A1%88%E4%BE%8B%E4%B8%89%2F</url>
    <content type="text"><![CDATA[案例背景一个商品评论系统的数据量非常大，拥有十亿量级的评论数据，所以对这个评论数据库，做了分库分表，基本上分完库和表后，单表的评论数据在百万级别。每一个商品的所有评论都是放在一个库的一张表里的，这样可以确保你作为用户在分页查询一个商品的评论时，一般都是直接从一个库的一张表里执行分页查询语句就可以了 在电商网站里，有一些热门的商品的评论可能多达几十万条。然后有些用户就喜欢不停的对某个热门商品的评论不断的进行分页，一页一页翻，有时候还会用上分页跳转功能，就是直接输入自己要跳到第几页去。所以这个时候，就会涉及到一个问题，针对一个商品几十万评论的深分页问题。 先来看看一个经过我们简化后的对评论表进行分页查询的 SQL 语句: 1SELECT * FROM comments WHERE product_id = &apos;xx&apos; AND is_good_comment = &apos;1&apos; ORDER BY id DESC LIMIT 100000, 20 它的意思是，比如用户选择了查看某个商品的评论，因此必须限定 product_id，同时还选了只看好评，所以 is_good_comment 也要限定一下。接着他要看第 5001 页评论，那么此时 limit 的 offset 就会是(5001 - 1) * 20，其中 20 就是每一页的数量，此时起始 offset 就是 100000，所以 limit 后 100000, 20 对这个评论表呢，最核心的索引就是 index_product_id，所以对上述 SQL 语句，正常情况下，肯定是会走这个索引的，即，会通过 index_product_id 索引，根据 product_id = ‘xx’ 这个条件从表里先删选出来这个表里指定商品的评论数据。 接着，按照 is_good_comment=’1’ 条件，筛选出这个商品评论数据里的所有好评。但是，index_product_id 的索引数据里，并没有 is_good_comment 字段的值，所以只能进行回表。即，对这个商品的每一条评论，都要进行一次回表操作，回到聚簇索引里，根据 id 找到那条数据，取出 is_good_comment 字段的值，接着对 is_good_comment = ‘1’ 条件做一个比对，筛选符合条件的数据。 假设这个商品的评论有几十万条，那岂不是要做几十万次回表操作？虽然每次回表都是根据 id 在聚簇索引里快速查找，但也是架不住每条数据都回表啊 接着对于筛选完毕的符合 WHERE product_id = ‘xx’ AND is_good_comment = ‘1’ 条件的数据，假设有十多万条，就这就是按照 id 做一个倒序排序，此时还得基于临时磁盘文件进行倒序排序，又要耗时很久。排序完毕，就得基于 limit 100000， 20 获取第 5001 页的 20 条数据，最后返回 这个过程，因为有几十万次回表查询，还有十多万条数据的磁盘文件，所以这条 SQL 基本要跑个 1 秒 ~ 2 秒 SQL 优化如何优化？其实优化思路，跟我们说的第二个案例反过来了。第二个案例是基于商品品类去查商品表，是尽量避免对聚簇索引进行扫描，因为有可能找不到你指定的品类下的商品，出现聚簇索引全表扫描的问题。所以在第二个案例里，反而就是选择强制使用一个联合索引，快速定位到数据，这个过程中因为不需要回表，所以效率还是很高的 接着直接根据 id 临时磁盘文件排序后找到 20 条分页数据，再回表查询 20 次，找到 20 条商品的完整数据。因此当时对第二个案例而言，因为不涉及到大量回表的问题，所以这么做基本是合适的，性能通常在 1s 以内 但是我们这个案例里，就不是这么回事了，因为 where product_id = ‘xx’ and is_good_comment = ‘1’ 这两个条件，不是一个联合索引，所以会出现大量的回表操作，这个耗时是极高的。因此对于这个案例，我们通常会采用如下方式改造分页查询语句： 1SELECT * FROM comments a, (SELECT id FROM comments WHERE product_id = &apos;xx&apos; AND is_good_comment = &apos;1&apos; ORDER BY id DESC LIMIT 100000, 20) b WHERE a.id = b.id 上面那个 SQL 语句的执行计划就会彻底改变它的执行方式。它通常会先执行括号里的子查询，子查询反而会使用 PRIMARY 聚簇索引，按照聚簇索引的 id 值的倒序方向进行排序，扫描过程中就把符合 WHERE product_id = ‘xx’ AND is_good_comment = ‘1’ 条件的数据筛选出来。 比如这里就筛选出了十万多条的数据，并不需要把符合条件的数据都找到，因为 limit 后跟的是 100000,, 20，理论上只要有 100000 + 20 条符合条件的数据，而且是按照 id 有序的，此时就可以执行根据 limit 100000, 20 提取到 5001 页的这 20 条数据 接着你会看到执行计划里会针对这个子查询的结果集，一个临时表，&lt;derived2&gt; 进行全表扫描，拿到 20 条数据，接着对 20 条数据遍历，每一条数据都按照 id 去聚簇索引里查找一下完整数据，就可以了 所以针对我们的这个场景，反而是优化成这种方式来执行分页，它会更加合适一些，它只有一个扫描聚簇索引筛选符合你分页所有数据的成本，你的分页深度越深，扫描数据越多，分页深度越浅，扫描数据就越少，然后在做一页 20 条数据的 20 次回表查询就可以了 这还还要提一下，其实 SQL 调优实际上是没有银弹的。比如第二个案例来说，按顺序扫描聚簇索引方案可能会因为找不到数据导致亿级数据量的全表扫描，所以对第二个案例而言，必须得根据二级索引去查找。但是对于我们这个案例而言，因为提前做了分库分表，评论表单表数据在一百万左右，所以，即使一个商品没有评论，有全表扫描，也绝不会像扫描上亿数据表那么慢 其次，如果你根据 product_id 的二级索引查找，反而可能出现几十万次回表查询，所以二级索引查找方式反而不适合。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 调优案例二]]></title>
    <url>%2FCKING.github.io%2F2020%2F09%2F24%2FSQL-%E8%B0%83%E4%BC%98%E6%A1%88%E4%BE%8B%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[案例背景先从一个线上的商品系统出现的一个慢查询告警开始讲起。一天晚上，我们收到了线上数据库的频繁报警，这个报警的意思是，数据库突然涌现出了大量的慢查询，而且因为大量的慢查询，导致每一个数据库连接执行一个慢查询都要耗费很久。那样，必然会导致突然过来的很多查询需要让数据库开辟出来更多的连接，因此这个时候报警也告诉我们，数据库的连接突然暴增了，而且每个连接都打满，每个连接都要执行一个慢查询，慢查询还特别慢 接着引发的问题，就是数据库的连接全部打满，没法开辟新的连接，但是还持续地有新的查询发送过来，导致数据库没法处理新的查询，很多查询发送数据库直接就阻塞然后超时了，这也直接导致了线上的商品系统频繁地报警，出现了大量的数据库查询超时报错的异常 这种情况，基本意味着你的系统濒临于崩溃了，大量慢查询耗尽了数据库的连接资源，而且一直阻塞在数据库里执行，数据库没法执行新的查询。那么慢查询的都是一些什么语句呢？其实主要就是下面的这条语句，我们做了一个简化： 1SELECT * FROM products WHERE category = &apos;xx&apos; AND sub_category = &apos;xx&apos; ORDER BY id DESC LIMIT xx, xx 这是一个很稀松平常的 SQL 语句，它就是用户在电商网站上根据商品的品类以及子类在进行筛选，当然真是的 SQL 语句里，可能还包含其他的一些子段的筛选，比如品牌之类的，我们这里做了一个简化，然后按照 id 倒序排序，最后是分页，就这么一个语句 然后语句执行的商品表里大致是 1 亿左右的数据量，这个量级已经稳定了很长时间了，主要也就是这么多商品，但是上面的那个语句一执行就是几十秒 SQL 优化接着我们分析一下，为什么会出现这样的一个情况。首先，这个表当时肯定是对经常用到的查询字段都建立好索引的，那么针对这里简化后的 SQL 语句，你可以认为存在这样的一个索引：KEY index_category(category, sub_category)，所以基本可以确认上面的 SQL 绝对是可以用上索引的 一旦你用上了品类的索引，那么按品类和子类在索引里筛选，第一，筛选很快速；第二，晒出来的数据是不多的，按说这个语句应该执行的速度是很快的，即使表有亿级数据，但是执行时间也最多不超过 1s 但是这个 SQL 语句跑了几十秒，说明它肯定没有用我们建立的那个索引，那么它是怎么执行的，看一下它的执行计划： 1EXPLAIN SELECT * FROM products WHERE category = &apos;xx&apos; AND sub_category = &apos;xx&apos; ORDER BY id DESC LIMIT xx, xx 执行计划具体内容就不写了，这里说最核心的信息。它的 possible_keys 里是有我们的 index_category 的，结果实际上用的 key 不是这个索引，而是 PRIMARY，而且 extra 里写了 Using where 到此为止，我们就知道为什么这个 SQL 语句性能那么差了。它其实本质上就是在主键的聚簇索引上进行扫描，一边扫描，一边还用了 where 条件里的两个字段去进行筛选，所以这么扫描的话，必然是会耗费几十秒了 因为为了快速解决这个问题，就需要强制性地改变 MySQL 自动选择这个不合适的聚簇索引进行扫描的行为。怎么改变？可以使用 force index 语法，如下： 1SELECT * FROM products FORCE INDEX(index_category) WHERE category = &apos;xx&apos; AND sub_category = &apos;xx&apos; ORDER BY id DESC LIMIT xx, xx 使用上述语法过后，强制让 SQL 语句使用了你指定的索引，此时再次执行这个 SQL 语句，会发现它仅仅耗费 100 多毫秒，性能瞬间就提升上去了 这是一个实战技巧，就是你如何去强制改变 MySQL 的执行计划。如果 MySQL 使用了错误的执行计划，应该怎么办？方法就是 force index 语法就可以 这个案例还没完，还遗留很多问题： 为什么这个案例中 MySQL 会默认选择对主键的聚簇索引进行扫描 为什么没使用 index_category 这个二级索引进行扫描 即使用了聚簇索引，为什么这个 SQL 以前没有问题，现在突然就有问题了 问题分析接着我们分析上面的那些问题。首先，第一个问题，为什么针对 SELECT * FROM products WHERE category = &#39;xx&#39; AND sub_category = &#39;xx&#39; ORDER BY id DESC LIMIT xx, xx 这样一个 SQL 语句，MySQL 要选择对聚簇索引进行扫描呢？ 首先，这个表是一个亿级数据量的大表，那么针对它来说，index_category 这个二级索引也是比较大的。所以此时对于 MySQL 来说，它有这么一个判断，它觉得如果要是从 index_category 二级索引里查找到符合 where 条件的一波数据，接着还得回表，回到聚簇索引里去 因为 SQL 语句是要 select * 的，所以这里必然涉及到一次回表操作，回到聚簇索引里去把所有字段的数据都查出来，但是在回表之前，它必然要做完 order by id desc limit xx, xx 这个操作 举个例子，比如它根据 where category = &#39;xx&#39; and sub_category = &#39;xx&#39;，从 index_category 二级索引里查找出了一大波数据，比如从二级索引里搂出来几万条数据，接着而已二级索引里是包含主键 id 值的，所以此时它就得按照 order by id desc 这个排序语法，对这几万条数据基于临时磁盘文件进行 filesort 磁盘排序，排序完了之后，再按照 limit xx, xx 语法，把指定位置的几条数据拿出来。假设是 limit 0, 10，那么就是拿出来 10 条数据 拿出来 10 条数据之后，再回到聚簇索引里去根据 id 查找，把这 10 条数据的完整字段都查出来，这就是 MySQL 认为你使用 index_category 的话，可能会发生的一个情况 所以它担心的是，你根据 where category = &#39;xx&#39; and sub_category = &#39;xx&#39;，从 index_category 二级索引里查出来的数据太多了，还得在临时磁盘里排序，可能性能会很差，因此 MySQL 就把这种方式判定为不太好的方式 因此它才会选择一种方式，即，直接扫描主键的聚簇索引，因为聚簇索引都是按照 id 值有序的，所以扫描的时候，直接按 order by id desc 这个倒序顺序扫描过去就可以了，因为知道你是 limit 0, 10，也就知道你仅仅只要拿到 10 条数据就行了 所以它在按顺序扫描聚簇索引的时候，就会对每一条数据都采用 Using where 的方式，跟 where category= ‘xx’ and sub_category = ‘xx’ 条件进行对比，符合条件的就直接放入结果集里去，最多就是放 10 条数据进去就可以返回了 此时 MySQL 认为，按顺序扫描聚簇索引，拿到 10 条符合 where 条件的数据，应该速度是很快的，很可能比使用 index_category 二级索引那个方案更快，因此它就采用了扫描聚簇索引的这种方式。 那这个 SQL 语句之前在线上运行一直没问题，即之前在线上系统而言，即使采用扫描聚簇索引的方案，这个 SQL 语句也确实一般都运行不慢，起码是不会超过 1s 的。那么为什么会在某一天晚上突然的就报大量的慢查询，耗时几十秒呢？ 因为之前 where category = &#39;xx&#39; and sub_category = &#39;xx&#39; 这个条件通常都是有返回值的，就是说根据条件里的取值，扫描聚簇索引的时候，通常都是很快能找到符合条件的值以及返回的，所以之前其实性能也没什么问题。但是后来可能是商品系统里的运维人员，在商品管理的时候加了几种商品分类和子类，但是这几种分类和子类的组合其实没有对应的商品 也就是说，那一天晚上，很多用户使用这种分类和子类去筛选商品，where category = &#39;新分类&#39; and sub_category = &#39;新子类&#39; 这个条件实际上是查不到任何数据的。所以说，底层在扫描聚簇索引的时候，扫来扫去都扫不到符 where 条件的结果，一下子就把聚簇索引全部扫描了一遍，等于是上亿数据全表扫描了一遍，都没有找到符合 where category = &#39;新分类&#39; and sub_category = &#39;新子类&#39; 这个条件的数据 也正是因为如此，才导致这个 SQL 语句频繁地出现几十秒的慢查询，进而导致 MySQL 连接资源被打满，商品系统崩溃]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 调优案例一]]></title>
    <url>%2FCKING.github.io%2F2020%2F09%2F24%2FSQL-%E8%B0%83%E4%BC%98%E6%A1%88%E4%BE%8B%E4%B8%80%2F</url>
    <content type="text"><![CDATA[案例背景有一个系统是专门通过各种条件筛选出大量的用户，接着对那些用户去推动一些消息的。可能是推送一些促销活动的消息，或者是告诉你有一个特价商品的消息。总之，就是通过一些条件筛选出大量的用户，接着针对这些用户做出有一些推送。这个过程，比较耗时的是筛选用户的这个过程 因为用户是日活百万级的，注册用户是千万级的，而且如果没有进行分表分库的话，那么这个数据库里的用户表可能就一张，单表里是上千万的用户数据。 现在对筛选用户的 SQL 做一个简化，这个 SQL 经过简化看起来是这样的： SELECT id, name FROM users WHERE id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time &lt; xxxx) 解释上面的 SQL 语句，一般存储用户数据的表会分为两张表，一个表用来存储用户的核心数据，比如 id、name、手机号之类的信息，也就是上面 SQL 语句里的 users 表。另外一个表可能会存储用户的一些扩展信息，比如家庭住址、兴趣爱好、最近一次登录时间之类的，就是上面的 users_extent_info 表 所以上面的 SQL 语句的意思就很明显了，有一个子查询，里面针对用户的扩展信息表，即 users_extent_info 查询了一下最近一次登录时间小于某个时间点的用户，然后给他们发送一些 push，无论哪种场景，这个 SQL 都是适用的 然后外层的查询里，直接用了 id IN 字句去查询 id 在子查询结果范围里的 users 表的所有数据，此时这个 SQL 往往一下子会查出来很多数据，可能几千、几万、几十万都有可能，所以一般运行这类 SQL 之前，都会先跑一个 count 聚合函数，看看有多少条，比如下面这样： SELECT COUNT(id) FROM users WHERE id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time &lt; xxxx) 然后内存里做一个小批量多批次读取数据的操作，比如判断如果在 1000 条以内，那么就一下子读取出来，如果超过 1000 条，可以通过 LIMIT 语句，每次就从这个结果集里查 1000 条数据，查 1000 条就做一次批量 push，再查下一波 1000 条。 这就是这个案例的一个完整的业务背景和讲解，那么当时产生的问题是什么？就是在千万级数据量的大表场景下，上面的 SQL 直接轻松跑出来耗时几十秒的速度，所以，这个 SQL 不优化是不行的 执行计划接着我们来分析 SELECT COUNT(id) FROM users WHERE id IN (SELECT user_id FROM user_extent_info WHERE latest_login_time &lt; xxxx) 的执行计划。不过要提醒一点，不同的 MySQL 版本的执行计划可能不一样，不同数据量也可能不一样，所以同样的 SQL 在不同的 MySQL 版本下跑，可能执行计划都不一样 执行计划不一样没关系，重点是执行计划分析的思路，以及如何从执行计划里看出性能问题所在，最后就是如何进行调优，重点是这个过程，没法还原出来执行计划，也是没关系的。它的执行计划如下： 从上面的执行计划，可以清晰看到这条 SQL 语句的一个执行过程。首先，针对子查询，是执行计划里的第三行实现的，它表明，针对 users_extent_info，使用了 idx_login_time 这个索引，做了 range 类型的索引范围扫描，查出来 4561 条数据，没有做其它的额外筛选，所以 filtered 是 100% 接着它这里的 MATERIALIZED，表明了这里把子查询的 4561 条数据代表的结果集进行了物化，物化成了一个临时表，这个临时表物化，是把 4561 条数据临时落到磁盘文件里去的，这个过程其实就挺慢的 然后第二条执行计划表明，接着就是对 users 表做了一个全表扫描，在全表扫描的时候扫出了 49651 条数据，同时注意 extra 字段，显示了一个 Using join buffer 的信息，这个表明，此处在执行 join 操作 接着看执行计划里的第一条，这里它是针对子查询产出的一个物化临时表，也就是 &lt;subquery2&gt;，做了一个全表查询，把里面的数据都扫描一遍，那为什么要对这个临时表进行全表扫描呢？原因就是让 users 表的每一条数据，都要去跟物化临时表里的数据进行 join，所以针对 users 表里的每一条数据，只能是全表扫描一遍物化临时表，找找物化临时表里哪条数据是跟它匹配的，才能筛选出一条结果 第二条执行计划的全表扫描的结果表明是一共扫到了 49651 条数据，但是全表扫描的过程中，因为去跟物化临时表执行了一个 join 操作，而物化临时表就 4561 条数据，所以最终第二条执行计划的 filtered 显示的是 10%，即，从 users 表里筛选出了 4000 多条数据 SQL 优化上面说过，执行过程就是先执行了子查询查出来 4561 条数据，物化成了一个临时表，接着它对 users 主表做了一个全表扫描，扫描的过程中把每一条数据都放到物化临时表里去做全表扫描，本质在做 join 的事情 这里为什么会跑这么慢呢？首先它对子查询的结果做了一次物化临时表，落地磁盘了，接着它会全表扫描了 users 表的所有数据，每一条数据居然跑到一个没有索引的物化临时表里再做一次全表扫描找匹配数据。这个过程里，对 users 表的全表扫描是耗时的，对 users 表的每一条数据跑到物化临时表里做全表扫描，也是耗时的。所以这个过程是非常慢的，几乎没有用到索引 为什么会出现一个全表扫描 users 表，然后跟物化临时表做 join，join 的时候还要全表扫描物化临时表的过程？这里说一个技巧，就是在执行上述 SQL 的 EXPLAIN 命令，看到执行计划，可以执行一下 show warning 命令。这个 show warning 命令此时显示出来的内容如下： 12/* select#1 */ select count(`d2.`users`.`user_id``) AS `COUNT(users.user_id)`from `d2`.`users` `users` semi join xxxx .....（下面省略一大段内容） 大家关注的应该是这里的 semi join 这个关键字。这里就显而易见了，MySQL 在这里，生成执行计划的时候，自动就把一个普通的 IN 子句，“优化” 成了基于 semi join 来进行 IN + 子查询的操作，这个 semi join 是什么意思？ 简单来说，对 users 表不是全表扫描了么？对 users 表里每一条数据，去物化临时表全表扫描做 semi join，不需要把 users 表里的数据真的跟物化临时表里的数据 join 上。只要 users 表里的一条数据，在物化临时表里可以找到匹配的数据，那么 users 表里的数据就会返回，这就叫 semi join，它是用来筛选的 所以慢，也就慢在这里。既然知道了是 semi join 和物化临时表导致的问题，应该如何优化？先做一个小实验，执行 SET optimizer_switch = &#39;semijoin = off&#39;，就是关闭掉半连接优化，此时执行 EXPLAIN 命令看一下此时的执行计划，发现此时会恢复为一个正常的状态。 就是有一个 SUBQUERY 的子查询，基于 range 方式去扫描索引搜索出 4561 条数据，接着有一个 PRIMARY 类型的主查询，直接是基于 id 这个 PRIMARY 主键聚簇索引去执行的搜索，然后再把这个 SQL 语句真实跑一下看看，发现性能一下子提升了几十倍 到此真相大白了，其实反而是它自动执行的 semi join 半连接优化，给咱们导致了问题，一旦禁止掉 semi join 自动优化，用正常的方式让它基于索引去执行，性能是很可观的 当然，在生产环境下不能随意更改这些设置的，所以后来想了一个办法，多种办法尝试去修改 SQL 语句的写法，在不影响它语义的情况下，尽可能去改变 SQL 语句的结构和格式，最终尝试出了一个写法，如下： 12SELECT COUNT(id) FROM users WHERE (id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time &lt; xxxx) OR id IN (SELECT user_id FROM users_extent_info WHERE latest_login_time &lt; -1)) 上述写法中，WHRE 语句的 OR 后面的第二个条件，是不可能成立的，因为没有数据的 latest_login_time 是小于 -1 的，所以那时不会影响 SQL 语义的，但是我们发现改变了 SQL 的写法之后，执行计划也随之改变。 它并没有再进行 semi join 优化了，而是正常地用了子查询，主查询也是基于索引去执行]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SQL 执行计划]]></title>
    <url>%2FCKING.github.io%2F2020%2F09%2F01%2FSQL-%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[所谓执行计划，无非就是先访问哪个表，用哪个索引还是全表扫描，拿到数据之后如何去聚簇索引回表，是否要基于临时磁盘文件做分组聚合或者排序。 在 MySQL 中，只要使用 Explain 命令，就可以拿到这个 SQL 语句的执行计划，例如：explain select * from table。拿到的执行计划可能是类似下面的东西： 如上图，我们可以看到 id、select_type、table、partitions、type 之类的数据。 如果是一个简单的单表查询，可能这里就只有一条数据，也就是代表了它是打算如何访问这一个表而已。但是如果你的 SQL 语句极为复杂，可能这里会有很多条数据，因为一个复杂的 SQL 语句的执行是要拆分为很多步骤的，比如先访问表 A，接着弄一个排序，再来一个分组聚合，再访问表 B，接着搞一个连接，类似这样 接着，我们来看看执行计划里包含的各个字段都是什么意思。 首先是 id，每个 SELECT 都会对应一个 id，说穿了，就是一个复杂的 SQL 里可能会有很多个 SELECT，也可能包含多条执行计划，每一条执行计划都会有一个唯一的 id select_type，说的是一条执行计划对应的查询是个什么类型。table 就是表名，意思是要查询哪个表，partitions 是表分区的概念。而 type 就比较关键了，针对当前这个表的访问方法，这个我们之前都讲过很多，比如 const、ref、range、index、all 之类的，分别代表了使用聚簇索引、二级索引、全表扫描之类的访问方式 possible_keys 也很关键，它是跟 type 结合起来的，意思是说你 type 确定使用方式了，那么有哪些索引是可供选择，可以使用的呢？这都会放这里。key 就是在 possible_keys 里实际选择的那个索引，而 key_len 就是索引的长度。 ref 就是使用某个字段的索引进行等值匹配搜索的时候，跟索引列进行等值匹配的那个目标值的一些信息。rows 是预估通过索引或者别的方式访问这个表的时候，大概可能会读取多少条数据。filtered，就是经过搜索条件过滤之后的剩余数据的百分比 示例首先我们先看这么一条简单的 SQL：EXPLAIN SELECT * FROM t1，此时它的执行计划如下： 我们来分析上面的执行计划。首先是 id，它的值为 1，我们先不管。select_type 是 SIMPLE，顾名思义，这个表的查询类型是很普通的。table 是 t1，即表名是 t1。type 是 all，这就是我们之前提到的多种访问方式之一，all 就是全表扫描。你完全没加任何 where 条件，就只能是全表扫描了。这里直接会扫描表的聚簇索引的叶子结点，按顺序扫描过去拿到表里全部数据 rows 是 8191，说明全表扫描会扫描这个表的 8191 条数据，说明这个表里有 8191 条数据，此时你全表扫描会全部扫描出来。filtered 是 100%，你没有任何 where 过滤条件，所以直接筛选出来的数据就是表里数据的 100% 占比 接着看另一个 SQL 语句的执行计划：EXPLAIN SELECT * FROM t1 JOIN t2。这是一个典型的多表关联语句，这种关联语句，实际上会选择一个表先查询出来数据，接着遍历每一条数据去另外一个表里查询可以关联在一起的数据，然后关联起来，它的执行计划如下： 这是一个多表关联的执行计划。它的执行分为了两条，也就是会访问两个表。它先用全表扫描方位表 t1，接着用全表扫描访问表 t2，因为它这种多表关联方式，基本上是笛卡尔积的效果。t1 表的每条数据都会去 t2 表全部扫描所有的 34110 条数据，跟 t2 表的每一条数据都会做关联，而且 extra 里说了是 Nested Loop，也就是嵌套循环的访问方式 另外上面两条执行计划的 id 都是 1，是一样的，实际上一般来说，在执行计划里，一个 SELECT 会对应一个 id，因为这两条计划对应的是一个 SELECT 语句，所以它们两的 id 都是 1，是一样的。如果你要是有一个子查询，有另外一个 SELECT，那么另外一个 SELECT 子查询对应的执行计划的 id 就可能是 2 了 接着我们看一个包含子查询的 SQL 语句执行计划：EXPLAIN SELECT * FROM t1 WHERE x1 IN ( SELECT x1 FROM t1 ) OR x3 = &#39;xxx&#39;。这个 SQL 就稍微有一点复杂了，因为主 SELECT 语句的 WHERE 条件是依赖于一个子查询的，而且除此之外还有一个自己的 WHERE 筛选条件。它的执行计划如下： 我们分析一下上面的执行计划。首先，第一条执行计划的 id 是 1，第二条执行计划的 id 是 2。因为这个 SQL 里又两个 SELECT，主查询的 SELECT 的执行计划的 id 就是 1，子查询 SELECT 的执行计划的 id 就是 2 另外，第一条执行计划里，select_type 是 PRIMARY，不是 SIMPLE 了，说明第一个执行计划的查询类型是主查询的意思。对主查询而言，它有一个条件是 x3 = &#39;xxx&#39;，所以它的 possible_keys 里包含了 index_x3，就是 x3 字段的索引，但是它的 key 实际是 NULL，而且 type 是 ALL，所以说它最后没选择用 x3 字段的索引，而是选择了全表扫描 为什么？可能它通过成本分析发现，使用 x3 字段的索引扫描 xxx 这个值，几乎就跟全表扫描差不多，所以最后就选择还不如直接全表扫描呢 接着第二条执行计划，它的 select_type 是 SUBQUERY，即子查询。子查询针对的是 t2 这个表，当然子查询本身就是一个全表查询，但是相对主查询而言，会使用 x1 in 这个筛选条件，它这里 type 是 index，说明使用了扫描 index_x1 这个 x1 字段的二级索引的方式，直接扫描 x1 字段的二级索引，来跟子查询的结果集作对比 接着看另外一个 union 的 SQL 语句：EXPLAIN SELECT * FROM t1 UNION SELECT * FROM t2 两个 SELECT 对应两个 id，就是分别从 t1 表和 t2 表里进行全表扫描。接着第三条执行计划，其实 union 字句默认的作用是把两个结果集合并起来还会进行去重，所以第三条执行计划干的是去重的活儿。 所以上面它的 table 是 &lt;union 1, 2&gt;，就是一个临时表的表名，而且它的 extra 里，有一个 using temporary，也就是使用临时表的意思，它就是把结果集放到临时表里进行去重的。当然，如果你使用 union all，那么就不会进行去重了。 执行计划中的 id、select_typeSQL 执行计划里有一个 id 的概念，这个 id 是什么意思？简单说，有一个 SELECT 子句就会对应一个 id，如果有多个 SELECT 就会对应多个 id，但是往往有时候一个 SELECT 子句涉及到了多个表，所以会对应多条执行计划，此时可能多条执行计划的 id 是一样的。 接着是 select_type，select_type 之前我们已经看过几种，有 SIMPLE 的，还有 primary 和 subquery 的，那么这些 select_type 是什么意思？还有哪几种 select_type？ 一般如果单表查询或者是多表连接查询，它们的 select_type 都是 SIMPLE，这个大家也都看到过了，意思就是简单的查询。如果是 union 语句的话，就类似于 select * from t1 union select * from t2，那么会对应两条执行计划，第一条执行计划是针对 t1 表的，select_type 是 PRIMARY，第二条执行计划是针对 t2 表的，select_type 是 UNION，这就是出现 UNION 语句的时候，它们就不一样了。 在使用 UNION 语句的时候，会有第三条执行计划。这个第三条执行计划意思是针对两个查询的结果依托一个临时表进行去重，这个第三条执行计划的 select_type 就是 union_result 另外，如果 SQL 里有子查询，类似于 SELECT * FROM t1 WHERE x1 IN (SELECT x1 FROM t2) OR x3 = &#39;xxx&#39;，此时也会有两条执行计划，第一条执行计划的 select_type 是 PRIMARY，第二条执行计划的 select_type 是 SUBQUERY。 复杂的示例接着我们看一下复杂的 SQL 语句：EXPLAIN SELECT * FROM t1 WHERE x1 IN (SELECT x1 FROM t2 WHERE x1 = &#39;xxx&#39; UNION SELECT x1 FROM t1 WHERE x1 = &#39;xxx&#39;)。它有一个外层查询，还有一个内存子查询，子查询里还有两个 SELECT 语句进行 UNION 操作，它的执行计划如下： 第一个执行计划是针对 t1 表查询的外层循环，select_type 就是 PRIMARY，因为这里涉及到了子查询，所以外层查询的 select_type 就是 PRIMARY 第二个查询计划是子查询里针对 t2 表的那个查询语句，它的 select_type 是 DEPENDENT SUBQUERY，第三个执行计划是子查询里针对 t1 表的另一个查询语句，select_type 就是 DEPENDENT_UNION，因为第三个执行计划是在执行 union 后的查询，第四个执行计划的 select_type 就是 UNION RESULT，因为在执行子查询里两个结果集的合并以及去重 接着看另一个复杂的 SQL 语句：EXPLAIN SELECT * FROM (SELECT x1, count(*) as cnt FROM t1 GROUP BY X1) AS _t1 WHERE cnt &gt; 10。它是 FROM 自己后跟了一个子查询，在子查询里是根据 x1 字段进行分组然后进行 count 聚合操作，也就是统计出来 x1 这个字段的每个值的个数，然后在外层则是针对这个内层查询的结果集进行查询通过 where 条件来进行过滤。执行计划如下： 上面的执行计划中，我们主要看第二条。它的 select_type 是 derived，意思是，针对子查询执行后的结果集会物化为一个内部临时表，然后外层查询是针对这个临时的物化表执行的。它这里执行分组聚合的时候，是使用 index_x1 这个索引进行的，type 是 index，意思是扫描了 index_x1 这个索引树的所有叶子节点，把 x1 相同值的个数都统计出来 然后外层的第一个执行计划，select_type 是 PRIMARY，针对的 table 是 &lt;derived2&gt;，就是针对一个子查询结果集物化形成的临时表，它是直接针对这个物化临时表进行全表扫描根据 where 条件进行筛选的 执行计划之 select_type 和 type首先是 select_type，它不是很关键，它主要是代表了大 SQL 里的不同的 SELECT 代表了一个什么角色，比如有的 SELECT 是 PRIMARY 查询，有的是 UNION，有的是 SUBQUERY 但这个 type 就比较关键了，因为它直接决定了对某个表是如何从里面查询数据的，包括了 const、ref、range、index、all 这几种方式，分别是根据主键/唯一索引查询，根据二级索引查询，对二级索引进行全索引扫描，对聚簇索引进行全表扫描 首先，假设是这样的一个语句：SELECT * FROM t1 WHERE id = 110 这样的 SQL，直接根据主键进行等值匹配查询，那执行计划里的 type 就会是 const，意思是极为快速的。因为主键是不会重复的，这个值一匹配，在一个索引树里跳转查询，基本上几次磁盘 IO 就可以定位到了 接着这样一个 SQL：SELECT * FROM t1 INNER JOIN t2 ON t1.id = t2.id，这里是通过两个表的 id 进行关联查询的，此时它的执行计划如下： 这个执行计划里，它针对 t1 表是一个全表扫描，这是必然的，因为关联的时候会先查询一个驱动表，这里就是 t1，它没什么 where 筛选条件，自然只能是全表扫描查出来所有的数据了 接着针对 t2 表的查询 type 是 eq_ref，而且使用了 PRIMARY 主键。即，针对 t1 表全表扫描获取到的每条数据，都会去 t2 表里基于主键进行等值匹配，此时会在 t2 表里的聚簇索引里根据主键值进行快速查找，所以在连接查询时，针对被驱动表如果基于主键进行等值匹配，那么它的查询方式就是 eq_ref 而如果是正常基于某个二级索引进行等值匹配的时候，type 就会是 ref，而如果基于二级索引查询的时候允许值为 null，那么查询方式就会是 ref_or_null。另外，有一些特殊场景下对单表查询可能会基于多个索引提取数据后进行合并，此时查询方式会是 index_merge 这种 而查询方式时 range 的话就是基于二级索引进行范围查询，查询方式是 index 的时候是直接扫描二级索引的叶子节点，也就是扫描索引里的每条数据，最后如果是 all 的话就是全表扫描，也就是对聚簇索引的叶子节点扫描每条数据 执行计划之其他字段接着我们看 possible_keys，顾名思义，其实就是针对一个表进行查询的时候有哪些潜在可以使用的索引。比如你有两个索引，一个是 KEY(x1, x2, x3)，一个是 KEY(x1, x2, x4)，此时在 where 条件里要根据 x1 和 x2 两个字段进行查询，此时上面两个索引都可以使用的，那要使用哪个呢？ 此时就需要通过成本优化方法，有估算两个索引进行查询的成本，看使用哪个索引的成本更低，那么就选择用那个索引。最终选择的索引，就是执行计划里的 key 这个字段的值了。 而 key_len，其实就是当你在 key 里选择使用某个索引之后，那个索引里的最大值的长度是多少，这个就是给你一个参考，大概知道那个索引里的值最大值能有多长，就这么个意思。 而执行计划里的 ref 也相对会关键一些。当你的查询方式是索引等值匹配的时候，比如 const、ref、eq_ref、ref_or_null 这些方式的时候这些方式的时候，此时执行计划的 ref 字段告诉你的就是：你跟索引列等值匹配的是什么？是等值匹配一个常量值，还是等值匹配另外一个字段的值？ 例如这样的一个 SQL 语句：EXPLAIN SELECT * FROM t1 WHERE x1 = ‘xxx’。执行计划如下： 如上图，针对 t1 表的查询，type 是 ref 方式，也就是说基于普通的二级索引进行等值匹配，然后 possible_key 只有一个，就是 index_x1，针对 x1 字段建立的一个索引，而实际使用的索引也是 index_x1 然后 key_len 是 5，意思是 index_x1 这个索引里的 x1 字段最大值的长度就是 5 个字节。而比较关键的是 ref 字段，它的意思是，既然你是针对某个二级索引进行等值匹配的，那么跟 index_x1 进行等值匹配的是什么？是一个常量或者是别的字段？这里的 ref 的值是 const，是使用一个常量值跟 index_x1 索引里的值进行等值匹配的 如果是这样的 SQL 语句：EXPLAIN SELECT * FROM t1 INNER JOIN t2 ON t1.id = t2.id 此时执行计划里的 ref 肯定不是 const，因为你跟 t1 表的 id 字段等值匹配的是另一个表的 id 字段，此时 ref 的值就是那个字段的名称了，如下： 如图，针对 t1 表作为驱动表执行一个全表扫描，接着针对 t1 表里每条数据都会去 t2 表根据 t2 表的主键执行等值匹配，所以第二个执行计划的 type 是 eq_ref，意思是被驱动表基于主键进行等值匹配，而且使用的是 PRIMARY，就是使用了 t2 表的主键 至于 ref，意思是，谁跟 t2 表的聚簇索引里的主键值进行等值匹配？是 test 这个库的 t1 表的 id 字段，这里跟 t2 表的主键进行等值匹配的是 t1 表的主键 id 字段，所以 ref 这里显示的很清楚了 最后简单说下 rows 和 filtered。这个 rows，就是说你使用指定的查询方式，会查出多少条数据，而 filtered 意思是，在查询方式查出来的这波数据里再用上其他的不在索引范围里的查询条件，又会过滤出百分之几的数据 比如 SQL 语句：EXPLAIN SELECT * FROM t1 WHERE x1 &gt; ‘xxx’ AND x2 = ‘xxx’ 它只有一个 x1 字段建了索引，x2 字段是没有索引的，执行计划如下： 如上图，针对 t1 表的查询方式是 range，也就是基于索引进行范围查询，用的索引是 index_x1，也就是 x1 字段的索引，然后基于 x1 &gt; ‘xxx’ 这个条件通过 index_x1 索引查询出来的数据大概是 479 条，接着会针对 479 条数据再基于 where 条件里的其他条件，即 x2 = ‘xxx’ 进行过滤 这个 filtered 是 10，意思是估算基于 x2 = ‘xxx’ 条件过滤的数据大概是 10%，即最终查出来的数据大概是 479 * 10% = 48 条左右 执行计划之 extra接着我们看 extra 字段代表什么。其实，除了 extra 字段以外的其他内容，最多就是告诉你 SQL 里的每个表是如何查询的，用了哪个索引，查出来了多少数据，但是很多时候，往往针对一个表可不是那么简单的。因为除了基于索引查询数据，可能同时还得基于 where 条件里的其他过滤条件去筛选数据，此时还会筛选出来一些数据 这个 extra 里的信息可能会非常多，我们不可能都讲一遍。主要将一些平时常见的，比较有用的 extra 信息。例如 SQL ：EXPLAIN SELECT x1 FROM t1 WHERE x1 = ‘xxx’ 它的执行计划如下： 我们看一下这个执行计划。首先它是访问了 t1 表，使用的是 ref 访问方法，也就是基于二级索引去找，找的是 index_x1 这个索引，这个索引的最大长度是 5 个字节，查找的目标是一个 const 代表的常量值，通过索引可以查出来 1 条数据，经过其他条件筛选，最终剩下数据是 100% 接着看 extra 的信息，是 Using index。就是说这次查询，仅仅涉及到了一个二级索引，不需要回表，因为它仅仅是查出来了 x1 这个字段，直接从 index_x1 索引里查就行了。如果没有回表操作，仅仅在二级索引里执行，那么 extra 会告诉你是 Using index 如果 SQL 语句是：SELECT * FROM t1 WHERE x1 &gt; ‘xxx’ AND x1 LIKE ‘%xxx’。此时它会先在二级索引 index_x1 里查找，查找出来的结构还会额外地跟 x1 LIKE ‘%xxx’ 条件做对比，如果满足条件的才会被筛选出来。这种情况下，extra 显示的是 Using index condition 接着讲一个最常见的 extra 信息：Using where。这个一般是见于你直接针对一个表扫描，没用到索引，然后 where 里好几个条件，就会告诉你 Using where。或者是你用了索引去查找，但是除了索引之外，还需要其他的字段进行筛选，也会告诉你 Using where 比如 SQL 语句：EXPLAIN SELECT * FROM t1 WHERE x2 = ‘xxx’。这里的 x2 是没有建立索引的，此时它的执行计划如下： 这里针对 t1 表进行查询，用的是全表扫描方式，没有使用任何索引。然后全表扫描，扫出来的是 5 条数据，这个时候 extra 是 Using where，意思是，它对每条数据都用了 WHERE x2 = ‘xxx’ 进行筛选。最终 filtered 告诉你，你过滤出了 20% 的数据 如果你的 where 条件里有一个条件是针对索引列查询的，有一个列是普通列的筛选，类似这样的 SQL 语句：EXPLAIN SELECT * FROM t1 WHERE x1 = ‘xxx’ AND X2 = ‘xxx’。执行计划如下： 这里针对 t1 表去查询，先通过 ref 方式直接在 index_x1 索引里查找，是跟 const 代表的常量值去查找，然后查出来了 1 条数据，接着再用 Using where 代表的方式，去使用 AND x2 = ‘xxx’ 条件进行筛选，筛选后的数据比例是 20% 另外，在多表关联的时候，有的时候你的关联条件并不是索引，此时就会用一种叫做 join buffer 的内存技术来提升关联的性能，例如：EXPLAIN SELECT * FROM t1 INNER JOIN t2 ON t1.x2 = t2.x2。它们的连接条件 x2 是没有索引的，执行计划如下： 因为要执行 join，那么肯定先得查询 t1 表的数据，此时是对 t1 表直接全表查询，查出来 5 条数据。接着就是对每条数据的 x2 字段的值，跑到 t2 表里去对应的数据，进行关联。但是此时因为 t2 表也没法根据索引来查，也是属于全表扫描，所以每次都得对 t2 表全表扫描一下。根据 extra 提示的 Using where，就是根据 t1 表每条数据的 x2 字段去 t2 表查找对应的数据了，然后此时会用 join buffer 技术，在内存里做一些特殊优化，减少 t2 表的全表扫描次数 接着看 Using fileSort。一般，我们在 SQL 语句里进行排序的时候，如果排序字段是有索引的，那么其实是直接可以从索引里按照顺序去查找数据的。例如：EXPLAIN SELECT * FROM t1 ORDER BY x1 LIMIT 10 这就是一个排序后再分页的语句，执行计划如下： 这个 SQL 语句，它是用了 index 方式访问的，意思是直接扫描了二级索引，而且实际使用的索引也是 index_x1，本质上来说，它就是在 index_x1 索引里，按照顺序找你 LIMIT 10 要求的 10 条数据而已。所以大家看到返回的数据是 10 条，也没别的过滤条件，所以 filtered 是 100%，也就是 10 条数据都返回了 但是如果我们排序的时候没有用到索引，此时就会基于内存或者磁盘文件来排序。大部分时候都得基于磁盘文件来排序，比如 EXPLAIN SELECT * FROM t1 ORDER BY x2 LIMT 10。x2 是没有索引的，执行计划如下： SQL 很明确，它基于 x2 字段来排序，是没法直接根据有序的索引去找数据的，只能把所有数据写入一个临时的磁盘文件，基于排序算法在磁盘文件里按照 x2 字段的值完成排序，然后在按照 LIMIT 10 的要求取出来头 10 条数据。这种把表全数据放磁盘文件排序的做法是相当糟糕的，性能会极差 最后，我们用 group by、union、distinct 之类的语法的时候，你要是没法直接利用索引来进行分组聚合，那么它直接会基于临时表来完成，也会有大量的磁盘操作，性能也是极地的。比如这个 SQL ：EXPLAIN SELECT x2, COUNT(*) AS amount FROM t1 GROUP BY x2 这里的 x2 是没有索引的，它的执行计划如下： 这个 SQL 里只能去全表数据放到临时表里做大量的磁盘文件操作，然后才能完成对 x2 字段的不同的值去分组，分组完了以后对不同 x2 的值的分组做聚合操作，这个过程也是相当耗时的 所有，未来在 SQL 调优的时候，核心就是分析执行计划里哪些地方出现了全表扫描，或者扫描数据过大，尽可能通过合理优化索引保证执行计划每个步骤都可以基于索引执行，避免扫描过多的数据]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[组合模式]]></title>
    <url>%2FCKING.github.io%2F2020%2F08%2F25%2F%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[树形结构在软件中随处可见，例如操作系统中的目录结构，应用软件的菜单和办公系统中的公司组织结构等。如何运用面向对象的方式来处理这种树形结构是组合模式需要解决的问题。组合模式使用户可以一致性地处理整个树形结构或者树形结构的一部分，也可以一致性处理树形结构中的叶子节点和容器节点（包含子节点的节点） 示例 Sunny 软件公司欲开发一个杀毒软件，该软件既可以对某个文件夹（Folder）杀毒，也可以对某个指定的文件（File）杀毒。该杀毒软件还可以根据各类文件的特点，为不同类型的文件提供不同的杀毒方式。先需要提供杀毒软件的整体设计方案 在 Windows 系统中，包含文件和文件夹两类不同的元素，其中文件夹中可以包含文件，还可以继续包含子文件夹，但是再文件中不能再包含子文件或者子文件夹。在此，可以称文件夹为容器（Container），而不同类型的各种文件是其成员，也称为叶子。 Sunny 软件公司的开发人员通过分析，决定使用面向对象的方式来实现对文件和文件夹的操作，定义了图像文件类 ImageFile、文本文件类 TextFile 和文件夹类 Folder，代码如下： 12345678910111213141516/** * @Description: 图像文件类 */public class ImageFile &#123; private String name; public ImageFile(String name) &#123; this.name = name; &#125; public void killVirus() &#123; // 简化代码，模拟杀毒 System.out.println("---- 对图像文件「" + name + "」进行杀毒"); &#125;&#125; 12345678910111213141516/** * @Description: 文本文件类 */public class TextFile &#123; private String name; public TextFile(String name) &#123; this.name = name; &#125; public void killVirus() &#123; // 简化代码，模拟杀毒 System.out.println("---- 对文本文件「" + name + "」进行杀毒"); &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071/** * @Description: 文件夹类 */public class Folder &#123; private String name; /** * 定义集合 folderList，用于存储 Folder 类型的成员 */ private ArrayList&lt;Folder&gt; folderList = new ArrayList&lt;&gt;(); /** * 定义集合 imageList，用于存储 ImageFile 类型的成员 */ private ArrayList&lt;ImageFile&gt; imageList = new ArrayList&lt;&gt;(); /** * 定义集合 textList，用于存储 TextFile 类型的成员 */ private ArrayList&lt;TextFile&gt; textList = new ArrayList&lt;&gt;(); /** * 增加新的 Folder 类型的成员 * @param f */ public void addFolder(Folder f) &#123; folderList.add(f); &#125; /** * 增加新的 ImageFile 类型的成员 * @param image */ public void addImageFile(ImageFile image) &#123; imageList.add(image); &#125; /** * 增加新的 TextFile 类型的成员 * @param text */ public void addTextFile(TextFile text) &#123; textList.add(text); &#125; // 提供 3 个不同的方法 removeFolder()、removeImageFile() 和 removeTextFile() 来删除成员 // 提供 3 个不同的方法 getChildFolder(int i)、getChildImageFile(int i) 和 // getChildTextFile(int i) 来获取成员 public void killVirus() &#123; // 模拟杀毒 System.out.println("**** 对文件夹「" + name + "」进行杀毒"); // 如果是 Folder 类型的成员，递归调用 Folder 的 killVirus() 方法 for(Folder obj : folderList) &#123; obj.killVirus(); &#125; // 如果是 ImageFile 类型的成员，递归调用 ImageFile 的 killVirus() 方法 for(ImageFile obj : imageList) &#123; obj.killVirus(); &#125; // 如果是 TextFile 类型的成员，递归调用 TextFile 的 killVirus() 方法 for(TextFile obj : textList) &#123; obj.killVirus(); &#125; &#125;&#125; 通过分析，发现该设计方案存在以下问题： 文件夹类 Folder 的设计和实现都非常复杂，需要定义多个集合存储不同类型的成员，而且需要针对不同的成员提供增加、删除和获取等管理和访问成员的方法，存在大量的冗余代码，系统维护较为困难 由于系统没有提供抽象层，客户端代码必须有区别地对待充当容器的文件夹 Folder 和充当叶子的 ImageFile 和 TextFile，无法统一对它们进行处理 系统的灵活性和可扩展性差，如果需要增加新的类型和叶子容器都需要对原有代码进行修改。例如，如果需要在系统中增加一种新类型的视频文件 VideoFile，则必须修改 Folder 类的源代码，否则无法在文件夹中添加视频文件 为了解决上面的问题，就要用到组合模式 组合模式概述对于树形结构，当容器对象的某一个方法被调用时，将遍历整个树形结构，寻找也包含这个方法的成员对象（可以是容器对象，也可以是叶子对象）并调用执行，牵一而动百，其中使用了递归调用的机制来对整个结构进行处理。由于容器对象和叶子节点对象在功能上的区别，在使用这些对象的代码中必须有区别地对待容器对象和叶子对象，而实际上大多数情况下希望一致地处理它们，因为对于这些对象的区别对待将会使得程序非常复杂。组合模式就是为了解决此类问题，它可以让叶子对象和容器对象的使用具有一致性 组合模式定义如下： 组合模式：组合多个对象形成树形结构以表示具有「整体 - 部分」关系的层次结构。组合模式对单个对象（即叶子对象）和组合对象（即容器对象）的使用具有一致性，组合模式是一种对象结构型模式 在组合模式中引入了抽象构件类 Component，它是所有容器类和叶子类的公共父类，客户端针对 Component 进行编程。组合模式如图所示： 由上图可知，组合模式结构图中包含 3 个角色： Component（抽象构件）：它可以是接口或抽象类，为叶子构件和容器构件对象声明接口，在该角色中可以包含所有子类共有行为的声明和实现。在抽象构件中定义了访问及管理它的子构件的方法。例如增加子构件，删除、获取子构件等 Leaf（叶子构件）：它在组合模式结构中表示叶子节点对象。叶子节点没有子节点，它实现了在抽象构件中定义的行为。对于那些访问及管理子构件的方法，可以通过捕获异常等方式处理 Composite（容器构件）：它在组合模式中表示容器节点对象。容器节点包含子节点，其子节点可以是叶子节点，也可以是容器节点，它提供一个集合用于存储子节点，实现了在抽象构件中定义的行为，包括那些访问及管理子构件的方法，在其业务方法中可以递归调用其子节点的业务方法 组合模式的关键是定义了一个抽象构件类，它既可以代表叶子，又可以代表容器，而客户端针对该抽象构件类进行编程，无须知道它到底表示的是叶子还是容器，可以对其进行统一处理。同时容器对象与抽象构建类之间还建立一个聚合关联关系，在容器中既可以包含叶子，也可以包含容器，以此实现递归，形成一个树形结构 下面通过代码来分析组合模式的各个角色的用途和实现。 对于组合模式中的抽象构件角色，其代码如下： 12345678910111213/** * @Description: 抽象文件类：抽象构建 */abstract class Component &#123; public abstract void add(Component c); public abstract void remove(Component c); public abstract Component getChild(int i); public abstract void operation();&#125; 一般将抽象构件类设计为接口或抽象类，将所有子类共有方法的声明和实现放在抽象构件类中。对于客户端而言，将针对抽象构件编程，而无须关系其具体子类是容器构件还是叶子构件。如果继承抽象构件的是叶子构件，则其典型代码如下： 12345678910111213141516171819202122public class Leaf extends Component &#123; @Override public void add(Component c) &#123; // 异常处理或错误提示 &#125; @Override public void remove(Component c) &#123; // 异常处理或错误提示 &#125; @Override public Component getChild(int i) &#123; // 异常处理或错误提示 return null; &#125; @Override public void operation() &#123; // 叶子构件具体业务方法的实现 &#125;&#125; 作为抽象构件类的子类，在叶子构件中需要实现在抽象构件类中声明的所有方法，包括业务方法以及管理和访问子构件的方法，但是叶子构件不能再包含子构件，因此在叶子构件中实现子构件管理和访问方法时需要提供异常处理和错误提示。当然，这无疑会给叶子构件的实现带来麻烦 如果继承抽象构件的是容器构件，则其典型代码如下： 12345678910111213141516171819202122232425262728public class Composite extends Component &#123; private List&lt;Component&gt; list = new ArrayList&lt;&gt;(); @Override public void add(Component c) &#123; list.add(c); &#125; @Override public void remove(Component c) &#123; list.remove(c); &#125; @Override public Component getChild(int i) &#123; return list.get(i); &#125; @Override public void operation() &#123; // 容器构件具体业务方法的实现 // 递归调用成员构件的业务方法 for(Component obj : list) &#123; obj.operation(); &#125; &#125;&#125; 在容器构件中实现了在抽象构件中声明的所有方法，既包括业务方法，也包括用于访问和管理成员子构件的方法。需要注意的是，在实现具体业务方法时，由于容器构件充当的是容器角色，包含成员构件，因此它将调用其成员构件的业务方法。 完整的解决方案接下来我们用组合模式来解决示例的那个问题。其基本机构如图所示： 上图中，AbstractFile 充当抽象构件类，Folder 充当容器构件类，ImageFile、TextFile 和 VideoFile 充当叶子构件类，代码如下： 12345678910111213/** * @Description: 抽象文件类：抽象构件 */abstract class AbstractFile &#123; public abstract void add(AbstractFile file); public abstract void remove(AbstractFile file); public abstract AbstractFile getChild(int i); public abstract void killVirus();&#125; 123456789101112131415161718192021222324252627282930313233/** * @Description: 图像文件类：叶子构件 */public class ImageFile extends AbstractFile &#123; private String name; public ImageFile(String name) &#123; this.name = name; &#125; @Override public void add(AbstractFile file) &#123; System.out.println("对不起，不支持该方法"); &#125; @Override public void remove(AbstractFile file) &#123; System.out.println("对不起，不支持该方法"); &#125; @Override public AbstractFile getChild(int i) &#123; System.out.println("对不起，不支持该方法"); return null; &#125; @Override public void killVirus() &#123; // 模拟杀毒 System.out.println("---- 对图像文件「" + name + "」进行杀毒"); &#125;&#125; 123456789101112131415161718192021222324252627282930313233/** * @Description: 文本文件类：叶子构件 */public class TextFile extends AbstractFile &#123; private String name; public TextFile(String name) &#123; this.name = name; &#125; @Override public void add(AbstractFile file) &#123; System.out.println("对不起，不支持该方法"); &#125; @Override public void remove(AbstractFile file) &#123; System.out.println("对不起，不支持该方法"); &#125; @Override public AbstractFile getChild(int i) &#123; System.out.println("对不起，不支持该方法"); return null; &#125; @Override public void killVirus() &#123; // 模拟杀毒 System.out.println("---- 对文本文件「" + name + "」进行杀毒"); &#125;&#125; 123456789101112131415161718192021222324252627282930313233/** * @Description: 视频文件类：叶子构件 */public class VideoFile extends AbstractFile &#123; private String name; public VideoFile(String name) &#123; this.name = name; &#125; @Override public void add(AbstractFile file) &#123; System.out.println("对不起，不支持该方法"); &#125; @Override public void remove(AbstractFile file) &#123; System.out.println("对不起，不支持该方法"); &#125; @Override public AbstractFile getChild(int i) &#123; System.out.println("对不起，不支持该方法"); return null; &#125; @Override public void killVirus() &#123; // 模拟杀毒 System.out.println("---- 对视频文件「" + name + "」进行杀毒"); &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142/** * @Description: 文件夹类：容器构件 */public class Folder extends AbstractFile &#123; /** * 定义集合 fileList，用于存储 AbstractFile 类型的成员 */ private ArrayList&lt;AbstractFile&gt; fileList = new ArrayList&lt;&gt;(); private String name; public Folder(String name) &#123; this.name = name; &#125; @Override public void add(AbstractFile file) &#123; fileList.add(file); &#125; @Override public void remove(AbstractFile file) &#123; fileList.remove(file); &#125; @Override public AbstractFile getChild(int i) &#123; return fileList.get(i); &#125; @Override public void killVirus() &#123; // 模拟杀毒 System.out.println("**** 对文件夹「" + name + "」进行杀毒"); // 递归调用成员构件的 killVirus() 方法 for(AbstractFile obj : fileList) &#123; obj.killVirus(); &#125; &#125;&#125; 12345678910111213141516171819202122232425262728293031public class Client &#123; public static void main(String[] args) &#123; // 针对抽象构件编程 AbstractFile file1, file2, file3, file4, file5, folder1, folder2, folder3, folder4; folder1 = new Folder("Sunny 的资料"); folder2 = new Folder("图像文件"); folder3 = new Folder("文本文件"); folder4 = new Folder("视频文件"); file1 = new ImageFile("小龙女.jpg"); file2 = new ImageFile("张无忌.gif"); file3 = new TextFile("九阴真经.txt"); file4 = new TextFile("葵花宝典.doc"); file5 = new VideoFile("笑傲江湖.rmvb"); folder2.add(file1); folder2.add(file2); folder3.add(file3); folder3.add(file4); folder4.add(file5); folder1.add(folder2); folder1.add(folder3); folder1.add(folder4); folder1.killVirus(); &#125;&#125; 由于在实例中使用了组合模式，在抽象构件类中声明了所有方法，包括用于管理和访问子构件的方法，因此在 ImageFile 等叶子构件类中实现这些方法时必须进行相应的异常处理或错误提示。在容器构件类 Folder 的 killVirus() 方法中递归调用其成员对象的 killVirus() 方法，从而实现对整个树形结构的遍历 如果需要更换操作节点，例如只需对文件夹「文本文件」进行杀毒，客户端代码只需修改一行即可：将代码 folder1.killVirus() 改为 folder3.killVirus() 透明组合模式与安全组合模式引入组合模式，Sunny 公司设计的杀毒软件具有良好的可扩展性，在增加新的文件类型时，无须修改现有类库代码，只需增加一个新的文件夹作为 AbstractFile 类的子类即可。但是由于在 AbstractFile 中声明了大量用于管理和访问成员构件的方法，例如 add()、remove() 等方法，就不得不在新增的文件类中实现这些方法，提供对应的错误提示和异常处理。为了简化代码，有以下两种结局方案 解决方案 1：将叶子构件的 add()、remove() 等方法的实现代码移至 AbstractFile 类中，由 AbstractFile 提供统一的默认实现，代码如下： 1234567891011121314151617abstract class AbstractFile &#123; public void add(AbstractFile file) &#123; System.out.println("对不起，不支持该方法"); &#125; public void remove(AbstractFile file) &#123; System.out.println("对不起，不支持该方法"); &#125; public AbstractFile getChild(int i) &#123; System.out.println("对不起，不支持该方法"); return null; &#125; public abstract void killVirus();&#125; 如果客户端代码针对抽象类 AbstractFile 编程，在调用文件对象的这些方法时将出现错误提示。如果不希望出现任何错误提示，可以在客户端定义文件对象时不使用抽象层，而直接使用具体叶子构件本身。代码如下： 123456789101112public class Client &#123; public static void main(String args[]) &#123; // 不能透明处理叶子构件 ImageFile file1, file2; TextFile file3, file4; VideoFile file5; AbstractFile folder1, folder2, folder3, folder4; // 其他代码省略 &#125;&#125; 这样就产生了一种不透明的使用方式，即在客户端不能全部针对抽象构件类编程，需要使用具体叶子构件类型来定义叶子对象 解决方案 2：在抽象构件 AbstractFile 中不声明任何用于访问和管理成员构件的方法，代码如下： 1234abstract class AbstractFile &#123; public abstract void killVirus();&#125; 此时，由于在 AbstractFile 中没有声明 add()、remove() 等访问和管理成员的方法，其叶子构件子类无须提供实现；而且无论客户端如何定义叶子构件对象都无法调用到这些方法，不需要做任何错误和异常处理，容器构件再根据需要增加访问和管理成员的方法。但这时候也存在一个问题：客户单不得不使用容器类本身来声明容器构件对象，否则无法访问其中新增的 add()、remove() 等方法。如果客户端一致性地对待叶子和容器，将会导致容器构件的新增对客户端的不可见，客户端代码对于容器构件无法再使用抽象构件来定义。代码如下： 1234567891011public class Client &#123; public static void main(String args[]) &#123; AbstractFile file1, file2, file3, file4, file5; // 不能透明处理容器构件 Folder folder1, folder2, folder3, folder4; // 其他代码省略 &#125;&#125; 使用组合模式时，根据抽象构件类的定义，可将组合模式分为透明组合模式和安全组合模式两种类型。 透明组合模式透明组合模式中，抽象构件类 Component 中声明了所有用于管理成员对象的方法，包括 add()、remove() 和 getChild() 等方法，这样做的好处是确保所有的构件类都有相同的接口。在客户端看来，叶子对象与容器对象所提供的方法时一致的，客户端可以相同地对待所有的对象。透明组合模式也是组合模式的标准形式，虽然上面的解决方案 1 在客户端可以有不透明的实现方式，但是由于在抽象构件中包含 add()、remove() 等方法，因此它还是透明组合模式 透明组合模式的缺点是不够安全，因为叶子对象和容器对象在本质上是有区别的。叶子对象不可能有下一个层次的对象，即不可能包含成员对象，因此为其提供 add()、remove() 等方法时没有意义的。这在编译阶段不会出错，但在运行阶段如果调用这些方法可能会出错（如果没有提供相应的错误处理代码） 安全组合模式安全组合模式中，在抽象构件 Component 中没有声明任何用于管理成员对象的方法，而是在 Composite 类中声明并实现这些方法。这种做法是安全的，因为根本不向叶子对象提供这些管理成员对象的方法，对于叶子对象，客户端不可能调用到这些方法，这就是解决方案 2 中所采用的实现方式。如图所示： 安全组合模式的缺点是不够透明，因为叶子构件和容器构件具有不同的方法，且容器构件中那些用于管理成员对象的方法没有在抽象构件类中定义，因此客户端不能完全针对抽象对象编程，必须与区别地对待叶子构件和容器构件。在实际应用中，安全组合模式的使用频率也非常高，在 Java AWT 中使用的组合模式就是安全组合模式 组合模式总结组合模式使用面向对象的思想来实现树形结构的构建与处理，描述了如何将容器对象和叶子对象进行递归组合，实现简单，灵活性好。由于在软件开发中存在大量的树形结构，因此组合模式是一种使用频率较高的结构型组合模式。除此之外，在 XML 解析，组织结构树处理、文件系统设计等领域，组合模式都得到了广泛应用 主要优点 组合模式可以清楚地定义分层次的复杂对象，表示对象的全部或部分层次，它让客户端忽略了层次的差异，方便对整个层次结构进行控制 客户端可以一致地使用一个组合结构或其中单个对象，不必关心处理的是单个对象还是整个组合结构，简化了客户端代码 在组合模式中增加新的容器构件和叶子构件都很方便，无须对现有类库进行任何修改，符合开闭原则 组合模式为树形结构的面向对象实现提供了一种灵活的解决方案，通过叶子对象和容器对象的递归组合，可以形成复杂的树形结构，但对树形结构的控制却非常简单 主要缺点组合模式的主要缺点是：在增加新构件时很难对容器中的构件类进行限制。有时候希望一个容器中只能有某些特定类型的对象，例如在某个文件夹中只能包含文本文件，使用组合模式时，不能依赖类型系统来施加这些约束，因为它们都来自于相同的抽象层，在这种情况下，必须通过在运行时进行类型检查来实现，这个过程较为复杂 使用场景以下情况下可以考虑使用组合模式： 在具有整体和部分的层次结构中，希望通过一种方式忽略整体与部分的差异，客户端可以一致性地对待它们 在一个使用面向对象语言开发的系统中需要处理一个树形结构 在一个系统中能够分离出叶子对象和容器对象，而且它们的类型不固定，需要增加一些新的类型 参考资料《设计模式的艺术——软件开发人员内功修炼之道》 – 刘伟]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[双指针技巧总结]]></title>
    <url>%2FCKING.github.io%2F2020%2F08%2F05%2F%E5%8F%8C%E6%8C%87%E9%92%88%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[双指针技巧可以分为两类：一类是「快慢指针」，一类是「左右指针」。前者主要解决链表中的问题，比如典型的判定链表中是否包含环；后者主要解决数组（或者字符串）的问题，比如二分查找 快慢指针的常见算法快慢指针一般都初始化指向链表的头结点 head，前进时快指针 fast 在前，慢指针 slow 在后，巧妙解决一些链表中的问题 判定链表中是否含有环单链表的特点就是每个节点只知道下一个节点，所以一个指针的话无法判断链表中是否含有环。如果链表中不含环，那么这个指针最终会遇到空指针 null，表示链表到头了，如下： 123456boolean hasCycle(ListNode head) &#123; while(head != null) &#123; head = head.next; &#125; return false;&#125; 但是链表中含有环，这个指针就会陷入死循环，因为环形数组中没有 null 指针作为尾部节点。 经典解法就是用两个指针，一个跑的块，一个跑得慢。如果不含有环，跑的块的指针最终会遇到 null，说明链表不含环；如果含有环，快指针最终会超慢指针一圈，和慢指针相遇，说明链表含有环 123456789101112131415boolean hasCycle(ListNode head) &#123; ListNode fast = head; ListNode slow = head; while(fast != null &amp;&amp; fast.next != null) &#123; fast = fast.next.next; slow = slow.next; while(fast == slow) &#123; return true; &#125; &#125; return false;&#125; 已知链表中含有环，返回这个环的起始位置 这个有点类似脑筋急转弯，先看代码： 12345678910111213141516171819202122ListNode detectCycle(ListNode head) &#123; ListNode fast = head; ListNode slow = head; while(fast != null &amp;&amp; fast.next != null)&#123; fast = fast.next.next; slow = slow.next; while(fast == slow) &#123; break; &#125; &#125; // 上面的代码类似 hasCycle 函数 slow = head; while(slow != fast) &#123; fast = fast.next; slow = slow.next; &#125; return slow;&#125; 可以看到，当快慢指针相遇时，让其中一个指针指向头结点，然后它俩以相同速度前进，再次相遇时所在的节点位置就是环开始的位置，这是为什么呢？ 第一次相遇，假设慢指针 slow 走了 k 步，那么快指针 fast 一定走了 2k 步，也就是说比 slow 多走了 k 步（也就是环的长度） 假设相遇点距环的起点的距离为 m，那么环的起点距头结点 head 的距离为 k - m，也就是说如果从 head 前进 k - m 步就能到达环起点。巧的是，如果从相遇点继续前进 k - m 步，也恰好到达环起点 所以，只要我们把快慢指针中的任何一个重新指向 head，然后两个指针同速前进，k - m 步后就会相遇，相遇之处就是环的起点了 寻找链表的中点类似上面的思路，我们还可以让快指针一次前进两次，慢指针一次前进一步，当快指针到达链表尽头时，慢指针就处于链表的中间位置 1234567while(fast != null &amp;&amp; fast.next != null) &#123; fast = fast.next.next; slow = slow.next;&#125;// slow 就在中间位置return slow; 当链表的长度是奇数时，slow 刚好停在中点的位置；如果长度是偶数，slow 最终的位置是中间偏右 寻找链表的倒数第 K 个元素思路还是使用快慢指针，让快指针先走 k 步，然后快慢指针开始同速前进。这样当快指针走到链表末尾 null 时，慢指针所在的位置就是倒数第 k 个链表节点（为了简化，k 不会超过链表长度） 123456789101112131415ListNode fast = head;ListNode slow = head;int step = 0;while(step &lt; k) &#123; fast = fast.next; step++;&#125;while(fast != null) &#123; slow = slow.next; fast = fast.next;&#125;return slow; 左右指针的常用算法左右指针在数组中实际上是两个索引值，一般初始化为 left = 0，right = nums.length - 1 二分查找简单的二分查找如下： 12345678910111213141516int binarySearch(int[] nums, int target) &#123; int left = 0; int right = nums.length - 1; while(left &lt;= right) &#123; int mid = left + (right - left) / 2; if(nums[mid] == target) &#123; return mid; &#125;else if(nums[mid] &lt; target) &#123; left = mid + 1; &#125;else if(nums[mid] &gt; target) &#123; right = mid - 1; &#125; &#125; return -1;&#125; 两数之和直接看下面的这么一道题目： 只要数组有序，就应该想到双指针技巧。这道题有点像二分查找，通过调节 left 和 right 来 调整 sum 的大小： 1234567891011121314151617181920int[] twoSum(int[] nums, int target) &#123; int left = 0; int right = nums.length - 1; while(left &lt; right) &#123; int sum = nums[left] + nums[right]; if(sum == target) &#123; // 题目要求的索引是从 1 开始的 return new int[]&#123;left + 1, right + 1&#125;; &#125;else if(sum &lt; target) &#123; // 让 sum 大一点 left++; &#125;else if(sum &gt; target) &#123; // 让 sum 小一点 right--; &#125; &#125; return new int[]&#123;-1. -1&#125;;&#125; 反转数组代码如下： 123456789101112void reverse(int[] nums) &#123; int left = 0; int right = nums.length - 1; while(left &lt; right) &#123; int temp = nums[left]; nums[left] = nums[right]; nums[right] = temp; left++; right--; &#125;&#125; 参考资料双指针技巧总结]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BFS 算法]]></title>
    <url>%2FCKING.github.io%2F2020%2F08%2F04%2FBFS-%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[BFS 广度优先搜索的核心思想，就是把一些问题抽象成图，从一个点开始，向四周开始扩散。一般来说，我们写 BFS 算法都是用「队列」这种数据结构，每次将一个节点周围的所有节点都加入队列。BFS 与 DFS 的最主要区别是：BFS 找到的路径一定是最短的，但代价就是空间复杂度比 DFS 大很多。 算法框架我们先说一下 BFS 出现的常见场景，本质就是让你在一幅「图」中找到从起点 start 到终点 target 的最近距离。这个广义的描述可以有多种变体，比如走迷宫，有的格子是围墙不能走，从起点到终点的最短距离是多少？如果这个迷宫带「传送门」可以瞬间传送呢？ 再比如说两个单词，要求你通过某些替换，把其中一个变成另一个，每次只能替换一个字符，最少替换几次？或者说连连看游戏，两个方块消除的条件不仅仅是图案相同，还得保证两个方块之间的最短连线不能多于两个拐点。你玩连连看，点击两个坐标，游戏是如何判断它俩的最短连线有几个拐点的？ 这些问题都没啥奇技淫巧，本质上都是一幅「图」，让你从一个起点，走到终点，问最短路径。记住下面的框架就 OK 了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 计算从起点 start 到终点 target 的最近距离 * @param start * @param target * @return */ public int BFS(Node start, Node target) &#123; /** * 核心数据结构 */ Queue&lt;Node&gt; q; /** * 避免走回头路 */ Set&lt;Node&gt; visited; // 将起点加入队列 q.offer(start); visited.add(start); // 记录扩散的步数 int step = 0; while(!q.isEmpty()) &#123; int size = q.size(); // 将当前队列中的所有节点向四周扩散 for(int i = 0; i &lt; size; i++) &#123; Node cur = q.poll(); // 划重点：这里判断是否到达终点 if(cur == target) &#123; return step; &#125; // 将 cur 的相邻节点加入队列 for(Node x : cur.adj()) &#123; q.offer(x); visited.add(x); &#125; &#125; // 划重点：更新步数在这里 step++; &#125; &#125; 队列 q 是 BFS 的核心数据结构；cur.adj() 泛指 cur 相邻的节点，比如说二维数组中，cur 上下左右四面的位置就是相邻节点；visited 的主要作用就是防止走回头路，大部分时候都是必须的，但是像一般的二叉树结构，没有子节点到父节点的指针，不会走回头路就不需要 visited 二叉树的最小深度此题来自 LeetCode 的一道题目：二叉树的最小深度，题目如下： 这里怎么套到 BFS 的框架里呢？首先明确一下起点 start 和终点 target 是什么，怎么判断到达终点？显然起点就是 root 根节点，终点就是最靠近根节点的那个「叶子节点」，叶子节点就是两个子节点都是 null 的节点： 12// 到达叶子节点if(cur.left == null &amp;&amp; cur.right == null) 那么，按照上述的框架稍微改造来写解法就可以了： 123456789101112131415161718192021222324252627282930313233public int minDepth(TreeNode root) &#123; if(root == null) &#123; return 0; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); // root 本身就是一层，depth 初始化为 1 int depth = 1; while (!queue.isEmpty()) &#123; int size = queue.size(); // 将当前队列中的所有节点向四周扩散 for(int i = 0; i &lt; size; i++) &#123; TreeNode cur = queue.poll(); // 判断是否到达叶子节点 if(cur.left == null &amp;&amp; cur.right == null) &#123; return depth; &#125; // 将 cur 的相邻节点加入队列 if(cur.left != null) &#123; queue.offer(cur.left); &#125; if(cur.right != null) &#123; queue.offer(cur.right); &#125; &#125; //这里增加步数 depth++; &#125; return depth; &#125; 其他复杂的问题都是这个框架的变形，在探讨复杂问题之前，我们先解答两个问题： 1、为什么 BFS 可以找到最短距离，DFS 不行吗？首先，BFS 的逻辑，depth 每增加一次，队列中的所有节点都向前迈一步，这保证了第一次到达终点的时候，走的步数是最少的。 DFS 也可以找到最短路径，但时间复杂度相对高很多。DFS 实际上是靠递归的堆栈记录走过的路径，你要找最短路径，肯定要把二叉树所有树杈都探索完才能对比出最短的路径有多长，而 BFS 借助队列做到一次一步齐头并进，是可以不遍历完整一棵树的条件下找到最短距离的 形象点说，DFS 是线，BFS 是面；DFS 是单打独斗，BFS 是集体行动。 2、既然 BFS 那么好，为啥 DFS 还要存在？BFS 可以找到最短距离，但是空间复杂度高，而 DFS 的空间复杂度较低。 那上面处理二叉树问题的例子，假设给你的二叉树是满二叉树，节点数为 N，对于 DFS 算法来说，空间复杂度无非就是递归堆栈，最坏情况下顶多就是树的高度，也就是 O(logN)。但 BFS 算法，队列中每次都会存储着二叉树一层的节点，这样的话最坏情况下空间复杂度应该是树的最底层节点的数量，也就是 N / 2，即 O(N) 所以，BFS 还是有代价的，一般来说在找最短路径的时候使用 BFS，其他时候还是 DFS 使用得多一些 解开密码锁的最少次数这也是 LeetCode 的题目：打开转盘锁 题目中描述的就是我们生活中常见的那种密码锁，如果没有任何约束，最少的拨动次数很好算，就像我们平时开密码锁那样直奔密码拨就行了。但现在出现了 deadends，那要如何计算？ 第一步，我们不管所有的限制条件，不管 deadends 和 target 的限制，就思考一个问题：如果让你设计一个算法，穷举所有可能的密码组合，怎么做？那就穷举呗，再简单一点，如果你只转一下锁，有几种可能？总共有 4 个位置，每个位置可以向上转，也可以向下转，即有 8 种可能。例如从 &quot;0000&quot; 开始，转一次，可以穷举出 &quot;1000&quot;，&quot;9000&quot;，&quot;0100&quot;，&quot;0900&quot; ... 共 8 种密码，然后再以这 8 种密码为基础，对每个密码再转一下，穷举出所有可能 这就可以抽象出一幅图，每个节点都有 8 个相邻的节点，又让你求最短距离，这就是典型的 BFS。框架就可以派上用场了，先写一个简陋的 BFS： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 将 s[i] 向上波动一次 * @param s * @param i * @return */ public String up(String s, int i) &#123; char[] chars = s.toCharArray(); if(chars[i] == '9') &#123; chars[i] = 0; &#125;else &#123; chars[i] += 1; &#125; return new String(chars); &#125; /** * 将 [i] 向下波动一次 * @param s * @param i * @return */ public String down(String s, int i) &#123; char[] chars = s.toCharArray(); if(chars[i] == '0') &#123; chars[i] = '9'; &#125;else &#123; chars[i] -= 1; &#125; return new String(chars); &#125; /** * BFS 框架，打印出所有可能的密码 * @param target */ public void BFS(String target) &#123; Queue&lt;String&gt; q = new LinkedList&lt;&gt;(); q.offer("0000"); while (!q.isEmpty()) &#123; int sz = q.size(); // 将当前队列中的所有节点向周围扩散 for (int i = 0; i &lt; sz; i++) &#123; String cur = q.poll(); // 判断是否到达终点 System.out.println(cur); /* 将一个节点的相邻节点加入队列 */ for (int j = 0; j &lt; 4; j++) &#123; String up = up(cur, j); String down = down(cur, j); q.offer(up); q.offer(down); &#125; &#125; // 在这里增加步数 &#125; return; &#125; 这段 BFS 密码已经能够穷举所有可能的密码组合了，但是显然不能完成所有题目，有如下问题需要解决： 会走回头路，比如说我们从 “0000” 拨打 “1000”，但是等从队列拿出 “1000” 时，还会拨出一个 “0000”，这样会产生死循环 没有终止条件，按照题目要求，我们找到 target 就应该结束并返回拨动的次数 没有对 deadends 的处理，按道理这些「死亡密码」是不能出现的，也就是你遇到这些密码的时候需要跳过 现在只要按照 BFS 框架在对应的位置修改即可修复这些问题： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public int openLock(String[] deadends, String target) &#123; // 记录需要跳过的死亡密码 Set&lt;String&gt; deads = new HashSet&lt;&gt;(); for (String s : deadends) &#123; deads.add(s); &#125; // 记录已经穷举过的密码，防止走回头路 Set&lt;String&gt; visited = new HashSet&lt;&gt;(); Queue&lt;String&gt; q = new LinkedList&lt;&gt;(); // 从起点开始启动广度优先搜索 int step = 0; q.offer("0000"); visited.add("0000"); while (!q.isEmpty()) &#123; int sz = q.size(); // 将当前队列中的所有节点向周围扩散 for (int i = 0; i &lt; sz; i++) &#123; String cur = q.poll(); // 判断是否到达终点 if (deads.contains(cur)) &#123; continue; &#125; if (cur.equals(target)) &#123; return step; &#125; // 将一个节点的未遍历相邻节点加入队列 for (int j = 0; j &lt; 4; j++) &#123; String up = up(cur, j); if (!visited.contains(up)) &#123; q.offer(up); visited.add(up); &#125; String down = down(cur, j); if (!visited.contains(down)) &#123; q.offer(down); visited.add(down); &#125; &#125; &#125; // 在这里增加步数 step++; &#125; // 如果穷举完都没找到目标密码，那就是找不到了 return -1; &#125; BFS 框架的应用我们看一下 LeetCode 的 单词接龙，这也是典型的 BFS 题目，可以套用我们的 BFS 算法。同样，我们也需要解决下面的问题： 每次转换只能改变一个字母 转换过程中的中间单词必须是字典中的单词 不过这次不一样的是，我们需要优化一下到达终点的位置，否则会出现「超出时间限制」的问题。具体代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public int ladderLength(String beginWord, String endWord, List&lt;String&gt; wordList) &#123; // 先将 wordList 放到哈希表里，便于判断某个单词是否在 wordList 里 Set&lt;String&gt; wordSet = new HashSet&lt;&gt;(wordList); if (wordSet.size() == 0 || !wordSet.contains(endWord)) &#123; return 0; &#125; wordSet.remove(beginWord); // 图的广度优先遍历，必须使用的队列和表示是否访问过的 visited （数组，哈希表） Queue&lt;String&gt; queue = new LinkedList&lt;&gt;(); queue.offer(beginWord); Set&lt;String&gt; visited = new HashSet&lt;&gt;(); visited.add(beginWord); int wordLen = beginWord.length(); // 包含起点，因此初始化的时候步数为 1 int step = 1; while (!queue.isEmpty()) &#123; int currentSize = queue.size(); for (int i = 0; i &lt; currentSize; i++) &#123; // 依次遍历当前队列中的单词 String word = queue.poll(); char[] charArray = word.toCharArray(); // 修改每一个字符 for (int j = 0; j &lt; wordLen; j++) &#123; // 一轮以后应该重置，否则结果不正确 char originChar = charArray[j]; for (char k = 'a'; k &lt;= 'z'; k++) &#123; if (k == originChar) &#123; continue; &#125; charArray[j] = k; String nextWord = String.valueOf(charArray); if (wordSet.contains(nextWord)) &#123; // 如果到达终点 if (nextWord.equals(endWord)) &#123; return step + 1; &#125; if (!visited.contains(nextWord)) &#123; queue.add(nextWord); // 注意：添加到队列以后，必须马上标记为已经访问 visited.add(nextWord); &#125; &#125; &#125; // 恢复 charArray[j] = originChar; &#125; &#125; step++; &#125; return 0; &#125; 参考资料BFS 算法解题套路框架]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 根据成本优化选择执行计划]]></title>
    <url>%2FCKING.github.io%2F2020%2F07%2F31%2FMySQL-%E6%A0%B9%E6%8D%AE%E6%88%90%E6%9C%AC%E4%BC%98%E5%8C%96%E9%80%89%E6%8B%A9%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[我们在执行单表查询也好，还是多表查询也好，都有多种执行计划可以选择。比如有的表可以全表扫描，有的可以用索引 A，有的用索引 B，那用哪种执行计划呢？ 我们先了解 MySQL 里的成本是什么意思。一般跑一个 SQL 语句，一般成本是两块。首先那些数据在磁盘里，是不是要从磁盘里把数据读出来？这个从磁盘读取数据到内存就是 IO 成本，而且 MySQL 里都是一页一页读的，读一页的成本约定为 1.0 接着，就是你拿到数据后，是不是要对数据做一些运算？比如验证它是否符合搜索条件，或者是搞一些排序分组之类的事，这些都是耗费 CPU 资源的，属于 CPU 成本，一般约定读取和检测一条数据是否符合的成本是 0.2 这个所谓的 1.0 和 0.2 是它自定义的一个成本值，代表的意思就是一个数据页 IO 成本是 1.0，一条数据检测的 CPU 成本是 0.2 然后，当你执行 SELECT * FROM t WHERE x1 = xx AND x2 = xx。此时你有两个索引，分别是针对 x1 和 x2 建立的。就会看看这个 SQL 可以用到哪几个索引，此时发现 x1 和 x2 的索引都能用到，他们两索引就是 possible keys 接着它会针对这个 SQL 计算一下全表扫描的成本，这个全表扫描就比较坑，因为他是需要先磁盘 IO 把聚簇索引里的叶子节点上的数据页一页一页都读到内存里，这有多少数据页就要耗费多少 IO 成本，接着对内存里的每一条都判断是否符合搜索条件的，这有多少条数据就要耗费多少 CPU 成本 那么如何计算全表扫描的成本呢？可以先通过命令 show table status like &#39;表名&#39; 拿到表的统计信息。你在对表进行增删改的时候，MySQL 会给你维护这个表的一些统计信息，比如这里可以看到 rows 和 data_length 两个信息，不过对于 InnoDB 来说，这个 rows 是估计值 rows 就是表里的记录数，data_length 就是表的聚簇索引的字节数大小，此时用 data_length 除以 1024 就是 kb 为单位的大小，然后再除以 16kb，就是有多少页，此时知道数据页的数量和 rows 记录数，就可以计算全表扫描的成本了。 IO 成本就是：数据页数量 * 1.0 + 微调值，CPU 成本就是：行记录数 * 0.2 + 微调值。它们两相加，就是一个总的成本值。比如你有数据页 100 个，记录数有 2 万条，此时总成本值就是 100 + 4000 = 4100 索引的成本计算使用索引访问数据的方式，要么你直接根据主键查，那就直接走一个聚簇索引就可以了，如果是普通索引，一般都是两步走，先从二级索引走一波数据，再根据这波数据的主键去聚簇索引回表查询 这个过程的成本计算方式稍微有点特别。首先，在二级索引里根据条件查一波数据的 IO 成本，一般是看你的查询条件涉及到几个范围，比如 name 值在 25 ~ 100,250 ~ 350 两个区间，那么就是两个范围，否则 name = xx 就是一个范围区间 一般一个范围区间就粗暴地认为等同一个数据页，所以此时可能一般根据二级索引查询的时候，这个 IO 成本都会预估地很小，可能就是 1 * 1.0 = 1，或者是 n * 1.0 = n，基本就是个位数这个级别 现在只是通过 IO 读取了二级索引的数据页而已，这仅仅只是二级索引读取的 IO 成本，但是二级索引数据页到内存里后，还要根据搜索条件去拿出来一波数据，拿这波数据的过程就是根据搜索条件在二级索引里搜索的过程。此时就要估算从二级索引里读取符合条件的数据的成本了。这需要估算一下二级索引里会查出多少条数据，这个过程有点复杂，不细节。总之，它会根据一个不是太准确的算法去估算一下根据查询条件可能在二级索引里查出多少条数据来 估算出来之后，比如估算可能会查到 100 条数据，此时从二级索引里查询数据的 CPU 成本就是 100 * 0.2 + 微调值，就是 20 左右而已。接着你拿到 100 条数据之后，就要回表到聚簇索引去查询完整数据，此时先估算回表到聚簇索引的 IO 成本，这里比较粗暴的直接默认 1 条数据就得回表到聚簇索引查询一个数据页，所以 100 条数据就是 100 个数据页的 IO 成本，也就是 100 * 1.0 + 微调值，大致是 100 左右 接着因为在二级索引里搜索到的数据是 100 条，然后通过 IO 成本最多回表到聚簇索引访问 100 个数据页之后，就可以拿到这 100 条数据的完整值了，此时就可以针对这 100 条数据去判断，它们是否符合其他查询条件，这里耗费的 CPU 成本就是 100 * 0.2 + 微调值，就是 20 左右 上面的所有成本都加起来，就是 1 + 20 + 100 + 20 = 141，这就是使用一个索引进行查询的成本的计算方法。假设你直接根据主键去查询，那么也参考上述估算过程就可以了，那就不过时仅仅查询一个聚簇索引而已 上面全表扫描发现成本是 4100 左右，这次根据索引条件查找可能就 141。所以，很多时候，使用索引和全表扫描，它的成本差距是非常大的，所以一般都会针对全表扫描和各个索引的成本，都进行估算，然后比较一下，选择一个成本最低的执行计划 多表关联查询如何选择执行计划其实多表查询的执行计划选择思路，基本跟单表查询的执行计划选择思路是类似的。单表查询的时候，主要就是对这个表的多种访问方式（全表查询，各个索引查询）来根据一定的公式计算出来每种访问方式的成本，接着选择一个成本最低的访问方式，那么就可以确定下来这个表怎么访问了 可能有人会觉得这种成本计算的方式也不是太靠谱，因为里面有些过程怪怪的，不过这也没办法，很难设计出完全公平，完全准确的成本预估算法来。因为要在一个查询执行之前，就可以针对不同的访问方法精准计算它的成本，那是不现实的，最后只是根据一些相对较为粗暴的方法，大致估算一下 接着我们看看多表关联的成本计算访问和执行计划选择方式。看下面的 SQL 语句： 1SELECT * FROM t1 JOIN t2 ON t1.x1 = t2.x1 WHERE t1.x2 = xxx AND t1.x3 = xxx AND t2.x4 = xxx AND t2.x5 = xxx 一般来说，都会先选择一个驱动表。比如 t1 作为驱动表，此时就需要根据 t1.x2 = xxx 和 t1.x3 = xxx 这个条件从表里选择一波符合条件的数据出来，此时就有一个问题，这里用了 t1 的两个字段来筛选数据，可能 x2 和 x3 字段都建了索引了，此时到底选择哪个索引呢？或者干脆就是全表扫描？ 此时就会根据上面讲的那套方法来计算针对 t1 表查询的全表扫描和不同索引，选择一个针对 t1 表的最佳访问方式，用最低成本成 t1 表里查出符合条件的数据来，接着就根据这波数据去 t2 表里查数据，按照连接条件 t1.x1 = t2.x1去查，同时要符合 t2.x4 = xxx 和 t2.x5 = xxx 这两个条件 此时一样会根据之前讲解的方法去估算，针对 t2 表的全表扫描以及基于 x4 x5 x1 几个字段不同索引的访问成本，挑选一个成本最低的方法，然后从 t2 表里把数据给查找出来就可以了。这就完成了多表关联 所以，多表关联的成本估算以及执行计划选择方式，跟单表关联基本上是差不多的，只不过多表关联要多查几个表而已]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之执行计划的索引类型]]></title>
    <url>%2FCKING.github.io%2F2020%2F07%2F15%2FMySQL-%E4%B9%8B%E6%89%A7%E8%A1%8C%E8%AE%A1%E5%88%92%E7%9A%84%E7%B4%A2%E5%BC%95%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[当我们用 EXPLAIN 查看执行计划的时候，一般如下图所示： 现在我们就来看看执行计划中 type 代表什么意思 假设你写一个 SELECT * FROM table WHERE id = x 或者 SELECT * FROM table WHERE name = x 的语句，直接就可以通过聚簇索引或者二级索引 + 聚簇索引回源，轻松查到你要的数据，这种根据索引可以快速查找数据的过程，在执行计划里称为 const，意思就是性能超高的常量级的。所以你以后在执行计划里看到 const 的时候，就知道它就是直接通过索引定位到数据，速度极快，这就是 const 的意思 但这里有一个要点，你的二级索引必须是唯一索引，才是属于 const 方式，也就是你必须建立 unique key 唯一索引，保证一个二级索引的每一个值都是唯一的才行。但是如果你是一个普通的二级索引，就是个普通的 KEY 索引。例如你写一个 SELECT * FROM table WHERE name = x 的 SQL，name 是普通二级索引，不是唯一索引，那么此时这种查询速度也是很快的，它在执行计划里面叫 ref 如果你是包含多个列的普通索引的话，那必须是从索引最左侧开始连续多个列都是等值比较才可以是 ref 方式，就是类似于 SELECT * FROM table WHERE name = x AND age = x AND xx = xx，然后索引可能是个 KEY(name, age, xx) 一个例外，就是如果你用 name IS NULL 这种语法的话，即使 name 是主键或者是唯一索引，还是只能走 ref 方式。但是如果你是针对一个二级索引同时比较了一个值还限定了 IS NULL，类似于 SELECT * FROM table WHERE name = x AND name IS NULL，那么此时执行计划里就叫 ref_of_null。即，在二级索引里搜你要的值以及是 null 的值，然后再回源去聚簇索引里查，因为同时有索引等值比较和 NULL 值查询，就叫做 ref_of_null 接着我们说说 range，顾名思义，这个就是你 SQL 里又范围查询的时候就会走这个方式。比如你一个 SQL 是 SELECT * FROM table WHERE age &gt;= x AND age &lt;= x，假设 age 就是一个普通索引，此时就必然利用索引来进行范围筛选，一旦利用索引做了范围筛选，那么这种方式就是 range 接着就是一种比较特殊的数据访问方式，就是 index。很多人都会错认为 index 就是通过索引来获取数据，从索引根节点开始二分查找，不停地往下层索引跳转就可以了，速度跟 ref 和 range 一样快 其实不是的。假设我们有一个表，里面完整的字段联合索引是 KEY(x1, x2, x3)。接着我们写的一个 SQL 语句是 SELECT x1, x2, x3 FROM table WHERE x2 = xxx。这个时候，x2 并不是联合索引的最左侧的那个字段。所以，这个 SQL 是没法直接从联合索引的索引树的根节点开始二分查找的。但是，不知道大家发现没有，这个 SQL 要查的几个字段，就是联合索引里的几个字段 所以针对这种 SQL，在实际查询的时候，就会直接遍历 KEY(x1, x2, x3) 这个联合索引的索引树的叶子节点。因为聚簇索引的叶子节点放的是完整的数据页，里面包含完整的一行一行的数据，联合索引的叶子节点放的也是页，但是页里每一行就 x1, x2, x3 和 主键的值。 所以此时针对这个 SQL，会直接遍历 KEY(x1, x2, x3) 索引树的叶子节点的那些页，一个接一个的遍历，然后找到 x2 = xxx 的那个数据，把里面的 x1, x2, x3 三个字段的值直接提取出来就可以了。这个遍历二级索引的过程，要比遍历聚簇索引快多了，毕竟二级索引叶子节点就包含几个字段的值，比聚簇索引叶子节点小多了，所以速度也快 即，只需要遍历一个 KEY(x1, x2, x3) 索引就可以了，不用回源到聚簇索引去。针对这种只需要遍历二级索引就可以拿到你想要的数据，而不需要回源到聚簇索引的访问方式，就叫做 index 访问方式 其实，上面说的 const ref 和 range，本质都是基于索引树的二分查找和多层跳转来查询，所以性能是很高的。然后 index 速度就比上面要差一些，因为它是走遍历二级索引树的叶子节点的方式来执行的，速度比基于索引树的二分查找要慢多了，但是还是比全表扫描要好的]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 索引设计实战]]></title>
    <url>%2FCKING.github.io%2F2020%2F07%2F10%2FMySQL-%E7%B4%A2%E5%BC%95%E8%AE%BE%E8%AE%A1%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[这个实战我们以陌生人社交 APP 为例。社交 APP，它本身的核心主旨，就是你进入 APP 的时候，需要录入一系列你的个人信息。接着 APP 自己会通过一定的算法推荐一些可能适合你的人给你进行线上交友。当然自己也可以通过一定的条件去搜索和筛选，查找 APP 上符合你期望的人 这里先忽略 APP 基于算法自动推荐潜在感兴趣的好友的部分，就看一下通过一系列的条件去筛选好友的过程。首先我们要有个用户表，叫做 user_info，大致会包含你的地区（这个很重要，同城方便线下见面）、性别、年龄、身高、体重、兴趣爱好、性格特点、照片等等，当然肯定还有最近一次在线时间（否则半年都不上线 APP 了，搜出来干啥）。另外如果支持交友过程中让其他人对他进行评价，那么还需要包含这个人的一个综合评分 针对这个用户表搜索，除了 SELECT xx FROM user_info WHERE xx = xx 有一系列的条件之外，还要支持分页展示，所以还得跟上 LIMIT xx, xx 的分页语句。同时，你搜索的时候，还要根据一定的规则对筛选出来的结果进行一个排序，把最符合你的条件和期望的用户排列在最上面 所以最终你的 SQL 语句可能是类似 SELECT xx FROM user_info WHERE xx = xx ORDER BY xx LIMIT xx, xx。这里就出现了一个难题，之前学习索引的时候，你在 where 条件里必须是实用联合索引里最左侧开始的连续多个字段进行筛选，然后排序的时候也必须是用联合索引里最左侧开始的多个连续字段进行排序 那问题来了，假设你的 SQL 需要按照年龄进行范围筛选，同时需要按照用户的评价排序，类似这样的 SQL ：SELECT xx FROM user_info WHERE age BETWEEN 20 AND 25 ORDER BY score，那就有问题了。假设你就一个联合索引，age 在最左侧，那你的 where 是可以用上索引来筛选的，但是排序是基于 score 字段，那就不可以用索引。如果你针对 age 和 score 分别设计两个索引，但是再你的 SQL 里假设基于 age 索引进行筛选，是没法领用另一个 score 索引进行排序的 所以，你要明白第一个难题就是：往往在类似的 SQL 里，你的 where 筛选和 order by 排序实际上大部分是没法用到索引的 WHERE 还是 order by在 where 和 order by 出现索引设计冲突的时候，到底是针对 where 去设计索引，还是针对 order by 去设计索引？ 这种时候往往都是让 where 条件去使用索引来快速筛选出来一部分指定的数据，接着再进行排序，最后针对排序后的数据拿出来一页数据。因为基于索引进行 where 筛选往往可以是最快速度筛选出你要的少部分数据，如果筛选出来的数据量不是很大的话，那么后续排序和分页的成本往往不会太大 好，假设我们针对 where 条件去设计索引，那么用户在搜索潜在好友的时候，一般会用上哪些条件呢？即，我们要把哪些字段包含到联合索引里去。其实，我们首先应该在联合索引里包含 省份、城市、性别 这三个字段，因为这三个字段都是在搜索里机会必定包含的三个字段。 但是之前说过，基数太低的字段最好别放到索引里去，那 省份、城市和性别，都是基数非常小的几个字段，可选的值就那么几个，为什么要放到索引里去？ 这是个好问题，但是规则是死的，人是活的。假设你就因为省份、城市和性别几个字段的基数太小了，此时就不把它们包含到联合索引去，那么你实际查询的时候都要基于这几个字段去搜索，此时你只能把这几个字段放在 where 条件的最后，那么最后每次查询都必须要先用联合索引查询出来一部分数据，接着数据加载到内存里去，再根据 where 条件最后的省份、城市和性别这几个字段进行过滤筛选，每次查询都要多这么一个步骤 所以与其如此，还不如把省份、城市和性别三个字段，放在联合索引的最左侧，这样跟其他字段组合联合索引之后，让大部分的查询都可以直接通过索引树就可以把 where 条件指定的数据筛选出来 范围查询接着我们的联合索引已经设计为 (province, city, sex) 的样子。假设我们查询的时候，不指定性别，就指定了省份、城市，还有年龄，即 WHERE province = xx AND city = xx AND age BETWEEN xx AND xx 此时 age 不在索引里，所以根本没法通过 age 去索引里进行筛选 如果把索引设计成 (province, city, sex, age)，此时上面的 SQL 语句也是没法让 age 用上索引的，因为 city 和 age 中间差了一个 sex，所以此时就不符合最左侧连续多个字段的原则了。其实，我们完全是可以把 age 放入联合索引的。设计成 (province, city, sex, age) 这样的索引，那么在搜索的时候就根据省份、城市和年龄来筛选，性别是不限的，此时可以把 where 语句写成：WHERE province = xx AND city = xx AND sex IN(‘female’, ‘mail’) and age &gt;= xx AND age &lt;= xx 如果我们把 SQL 语句写成这样，那么就可以让整个 WHERE 语句里的条件全部在索引树里进行筛选和搜索了。另外，假设我们在查询语句里还有一些频繁使用的条件，通常都是兴趣爱好和性格特点，这些往往都是由固定的一些枚举值的。那么针对这样的一些频繁使用的包含枚举值范围的一些字段，也可以加到联合索引里去，可以设计成 (province, city, sex, hobby, character, age) 这样的一个索引。假设此时出现了这样一个查询，按照省份、城市、性格和年龄进行搜索，此时 SQL 怎么写？ 还是用之前的策略和思路，就是写成 WHERE province = xx AND city = xx AND sex in (xx, xx) AND hobby in (xx, xx, xx) AND character = xx AND age &gt;= xx AND age &lt;= xx。即，就算你不需要按性别和爱好进行筛选，但是在 SQL 里你可以对这两个字段用 in 语句，把它们所有的枚举值都放进去，这样就可以顺利地让 province、city、character 和 age 四个真正要筛选的字段用上索引。 为什么 age 字段必须放在联合索引的最后一个？因为之前我们讲索引使用规则的时候说过，假设你 where 语句里有等值匹配，还有范围搜索，此时必须是先让联合索引最左侧开始的多个字段使用等值匹配，接着最后一个字段是范围匹配。 假设你在联合索引里把 age 放在中间的位置，设计一个类似 (province, city, sex, age, hobby, character) 的联合索引，接着 SQL 写成 WHERE province = xx AND city = xx AND sex in(xx, xx) AND age &gt;= xx AND age &lt;= xx AND hobby in (xx, xx, xx, xx) AND character = xx 的话，那么只有 province、city、sex 和 age 几个字段用上索引。因为在 SQL 里，一旦你的一个字段做范围查询用到了索引，那么这个字段接下来的条件都不能用索引了，这就是规则 所以，实际设计索引的时候，必须把经常用作范围查询的字段放在联合索引的最后一个，才能保证你 SQL 里每个字段都能基于索引去查询 用于辅助的索引接着，假设在查询的时候还有一个条件，是要根据用户最近登录时间在 7 天之内来进行筛选，筛选最近 7 天登录过 APP 的用户，那么可能你用户表有这么一个字段：latest_login_time。 你要是在 where 条件里加入这么一个 latest_login_time &lt;= 7 天内语句，肯定是没法用上索引的，因为这里必然会用一些计算或者是函数，才能进行一些时间的比对。而且假设你的查询里还有 age 进行范围查询，那么范围查询的时候，也就只有第一个范围查询时可以用上索引的，第一个范围查询之后的其它范围查询时用不上索引的 即，你索引设计成这样：(province, city, sex, hobby, character, age, latest_login_time)，然后你的 where 语句写成这样：WHERE xx xxx AND age &gt;= xx AND age &lt;= xx AND latest_login_time &gt;= xx，虽然 age 和 latest_login_time 都在联合索引里，但是按照规则，只有 age 范围查询可以用到索引，latest_login_time 是用不到索引的 此时有一个技巧，你在设计表的时候，就要考虑到这个问题，此时你可以设计一个字段：does_login_in_latest_7_days，即，这个人是否在最近 7 天内登陆过 APP。假设在 7 天内登陆过 APP，那么这个字段就是 1，否则就是 0。这样就把一个时间字段转化为了一个枚举字段 接下来就简单了，设计一个联合索引：(province, city, sex, hobby, character, does_login_in_latest_7_days, age)，然后搜索的时候再 where 条件里带上一个 does_login_in_latest_7_days = 1，最后跟上 age 范围查询，这样就可以让你的字段都用索引来筛选了 一般来说，假设你 where 语句里通过上述联合索引就可以过滤掉大部分的数据，就保留小部分数据下来基于磁盘文件进行 order by 语句的排序，最后基于 limit 进行分页，那么一般情况下性能还是比较高的。但是，万一你仅仅使用联合索引里一些基数特别小的字段来筛选呢？ 比如就基于性别来筛选，假设一下子筛选出所有的女性，可能有上百万用户数据，接着还要根据磁盘文件进行排序在分页，此时性能就很差了。 所以针对上述问题，可以针对那种基数很低的字段再加上排序字段单独设计一个辅助索引，专门用于解决 where 条件里都是基数低的字段，然后还要排序后分页的问题，比如可以设计一个联合索引为：(sex, score)。此时你写出如些 SQL：SELECT xx FROM user_info WHERE sex = &#39;female&#39; ORDER BY score LIMIT xx, xx。此时如果还用之前设计的索引，那就没了，因为根本没法用索引 但是用我们设计的那个辅助的 (sex, score) 索引，因为此时 where 条件里的字段是等值匹配，而且还是等于某个常量值，所以虽然 order by 后跟的 score 字段是 (sex, score) 索引里的第二个字段，order by 没有从索引最左侧字段开始排列，但是它也可以使用到索引来排序。 因为具体到使用索引的层面，它会先对 where 条件里的 sex = &#39;female&#39; 在索引树里筛选到这部分数据，接着在 sex = ‘female’ 的数据里，这些数据实际上都是排列在一起的，因为在索引里，会按照 sex 和 score 两个字段去进行排序，所以 sex = ‘female’ 的数据都是一块的 然后找到这部分数据之后，接着就可以确定，这部分数据肯定是按照 score 字段进行排序的，此时就可以按照 score 字段值的顺序，去读取你的 limit 语句指定的数据分页出来就可以了。所以此时你针对 sex 低基数的筛选和基于评分排序的语句，整体运行的效率是非常高的，完全可以基于辅助索引来实现 总结起来就是，可以通过对查询场景的分析，用 (province, city, sex, hobby, character, does_login_in_latest_7_days, age) 这样的联合索引去抗下复杂的 where 条件筛选的查询，此时走索引筛选速度很快，筛选出来的数据量较少，接着进行排序和 limit 分页 通过针对一些低基数字段筛选 + 评分排序的查询场景，可以设计类似 (sex, score) 的辅助索引来应对，让它快速定位到一大片低基数字段对应的数据，然后按照索引顺序去 limit 语句获取指定分页的数据，性能一样会很好 核心重点就是，尽量使用一两个复杂的多字段联合索引，抗下 80% 以上的查询，然后用一两个辅助索引抗下剩余 20% 非典型查询，保证 99% 以上查询都能充分利用索引，就能保证你的查询速度和性能]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之索引设计]]></title>
    <url>%2FCKING.github.io%2F2020%2F07%2F10%2FMySQL-%E4%B9%8B%E7%B4%A2%E5%BC%95%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[本文讲解索引设计的一般原则。 原则一首先我们在针对业务需求建立一张表的结构之后，就知道这个表有哪些字段，每个字段是什么类型的，会包含哪些数据。设计好表结构之后，就是要设计表的索引。设计索引的时候，我们要考虑第一点，就是未来我们对表进行查询的时候，大概会如何来进行查询 可能有人会说，你要我刚设计完表结构就知道未来会怎么查询表，我怎么知道？没关系，其实我们完全可以在表结构设计完毕之后，不用先急着设计索引，因为此时你根本不知道要怎么查询表。接着我们进入开发环节，根据业务把你的 Java 代码写好。当你把系统开发差不多了，此时就可以考虑如何建立索引了，因为你系统里的 SQL 语句也差不多写好了 这个时候，第一个索引设计原则就来了，针对你的 SQL 语句里的 where 条件、order by 条件以及 group by 条件去设计索引。也就是说，你的 where 条件要根据哪些字段来筛选数据？order by 要根据哪些字段来排序？group by 要根据哪些字段来分组聚合？ 此时你就可以设计一个或者两三个联合索引，每一个联合索引都尽量去包含上你的 where、order by、group by 里的字段，接着你就要仔细审查每个 SQL 语句，是不是每个 where、group by、order by 后面跟的字段顺序，都是某个联合索引的最左侧字段开始的部分字段 比如你有一个联合索引是 INDEX(a, b, c)，此时有三个 SQL，包含了 where a = ? and b = ? order by a, b group by a 这些部分，那么此时 where、order by、group by 后续跟的字段都是联合索引的最左侧开始的部分字段，这就可以了，说明你的 SQL 都会用上你的索引 原则二原则一说了你设计的索引是让你的各个 where、order by 和 group by 后面跟的字段都是联合索引的最左侧开始的部分字段，这样他们能用上索引。但是在设计索引的时候还得考虑其它一些问题。首先一个就是字段基数问题。例如，有一个字段它一共在 10 万行数据里有 10 万个值，但是这个值，不是 0 就是 1。那么它的基数就是 2，因为这个字段的值就两选择：0 和 1 假设针对上面说的这种字段建立索引的话，那就还不如全表扫描，因为你的索引树里仅仅包含了 0 和 1 两种值，根本没法进行快速的二分查找，也就没有太大的意义了。所以这种时候，选用这种基数很低的字段放索引里意义就不大 一般建立索引，尽量使用那些基数比较大的字段，就是值比较多的字段，才能发挥出 B+ 树快速二分查找的优势 另外，你尽量是对那些字段的类型比较小的列来设计索引。比如 tinyint 之类的，因为它的字段类型比较小，说明这个字段本身的值占用磁盘空间小，此时你在搜索的时候性能也会比较好 当然，这个所谓的字段类型小一点的列，也不是绝对的。很多时候你就是要针对 varchar(255) 这种字段建立索引，哪怕多占用一些磁盘空间，那你也得去设计这样的索引。比较关键的其实还是尽量别把基数太低的字段包含在索引里 如果你真的有那种 varchar(255) 的字段，可能里面的值太大了，你觉得放索引树里太占内存空间，此时完全可以换一种策略，也就是仅仅针对这个 varchar(255) 字段的前 20 个字符建立索引，即，对这个字段里的每个值的前 20 个字符放在索引树里而已 此时你建立出来的索引其实类似于 KEY my_index(name(20), age, course) 这样的一个形式。假设 name 是 varchar(255) 类型的，但是在索引树里你对 name 的值仅仅提取前 20 个字符而已 此时你在 where 条件里搜索的时候，如果是根据 name 字段来搜索，那么此时就会先到索引树里根据 name 字段的前 20 个字符去搜索，定位到之后前 20 个字符的前缀匹配的部分数据之后，再回到聚簇索引提取出来完整的 name 字段进行比对就可以了 但是如果你要是 order by name，那么此时你的 name 因为在索引树里仅仅包含了前 20 个字符，所以这个排序是没法用上索引的。group by 也是同理的。这里要对前缀索引有一个了解 原则三接着，你已经设计好了索引，然后在 SQL 里这么写：where function(a) = xx，你给你的索引里的字段 a 套了一个函数，此时这个索引就会失效。所以尽量不要让你的查询语句里的字段搞什么函数，或者是搞个计算 接着你系统跑起来了，有数据插入也有查询的情况，其实查询基本能走索引一般问题都不会太大的。但是插入就有点讲究了，因为你插入数据的时候，它肯定会更新索引树 你插入数据肯定会有主键吧，有主键就会更新聚簇索引树，你插入一条数据也会包含索引里各个字段的值，那你的联合索引的 B+ 树也要更新。即，你不停地增删改数据，就会不停地更新你的索引树。所以因为你插入的数据值可能根本不是根据顺序来的，很可能会导致索引树里的某个页就会自动分裂，这个页分裂的过程就会很耗费时间。 因此一般设计索引的时候别太多，建立两三个联合索引就应该覆盖你这个表的全部查询了。否则索引太多必然会导致你增删改数据的性能很差，因为要更新多个索引树 另外很关键的一点，建议主键一定是自增的，别用 UUID 之类的。因为主键自增，那么起码你的聚簇索引不会频繁地分裂，主键值都是有序的，就会自然地新增一个页而已。但是如果你用的是 UUID，那么也会导致聚簇索引频繁的页分裂。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 索引的使用扩展]]></title>
    <url>%2FCKING.github.io%2F2020%2F07%2F09%2FMySQL-%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BD%BF%E7%94%A8%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[SQL 排序的时候如何使用索引假设你有一个 SELECT * FROM table WHERE xxx = xxx ORDER BY xxx 这样的一个 SQL 语句，似乎应该是基于 where 语句通过索引快速筛选出来一波数据，接着放到内存里，或者放到一个临时文件里，然后通过排序算法按照某个字段走一个排序，最后把排序好的数据返回 但这么搞是有点慢的，尤其是你要排序的数据量比较大，还不能用内存来排序。如果基于磁盘文件来排序，那在 MySQL 里有一个术语，叫做 filesort，这速度就比较慢了。所以尽量被这么处理，尤其是类似于 SELECT * FROM table ORDER BY xx1, xx2, xx3 LIMIT 100 这样的 SQL 语句，按照多个字段排序然后返回去排名前 100 条数据，类似的语句常常见于分页 SQL 语句，可能需要对表里的数据进行一定的排序，然后走一个 limit 拿出来指定部分的数据 你要是纯粹把数据放到一个临时磁盘文件里，然后直接各种排序算法在磁盘文件里搞一通排序，接着按照你指定的要求走 limit 语句拿到指定分页的数据，那会让 SQL 的速度非常慢。所以通常而言，假设我们建立了一个索引 INDEX(xx1, xx2, xx3) 这样的一个联合索引，这个时候默认情况下载索引树里本身就是依次按照 xx1, xx2, xx3 三个字段的值去排序的，那么此时你再运行 SELECT * FROM table ORDER BY xx1, xx2, xx3 LIMIT 100 这样的 SQL 语句，就不用在什么临时文件里排序了 因为它要求也不过就是按照 xx1, xx2, xx3 三个字段来进行排序而已，在联合索引的索引树都排序好了，直接按照索引树里的顺序，把 xx1, xx2, xx3 三个字段从小到大的值获取前面 100 条就可以了，然后拿到 100 条数据的主键再去聚簇索引里回表查询剩余所有的字段 因此，在你的 SQL 语句里，应该尽量按照联合索引的字段顺序去进行 order by 排序，这样就可以直接利用联合索引里的数据有序性，到索引树里直接按照字段值的顺序去获取你需要的数据了。但是这里有一些限定规则，因为联合索引里的字段值在索引树里都是从小到大依次排列的，所以你在 order by 里要不就是每个字段后面什么都不加，直接就是 order by xx1, xx2, xx3，要不然就都加 DESC 降序排列，就是 order by xx1 DESC, xx2 DESC, xx3 DESC 如果都是升序排列，直接就从索引树里最小的开始读取一定条数就可以了，要是都是降序排列，就是从索引树里最大的数据开始读取一定的条数就可以了，但是你不能 order by 语句里有的字段升序有的字段降序，那是不能用索引的。另外，要是你 order by 语句有的字段不在联合索引里，或者是你对 order by 语句里的字段用了复杂的函数，这些也不能使用索引去进行排序 SQL 分组的时候如何使用索引接着我们讲讲如果 SQL 语句里用到 group by 分组词句的话是否可以用上索引 假设你走一个类似 SELECT COUNT(*) FROM table GROUP BY xx 的 SQL 语句，似乎看起来必须把你所有的数据放到一个临时磁盘文件里还有加上部分内存，去搞一个分组，按照指定字段的值分成一组一组的，接着对每一组都执行一个聚合函数。这个性能也是很差的，毕竟涉及大量的磁盘交互 因为我们的索引树里默认都是按照指定的字段都排序好的，其实字段值相同的数据都是在一起的，假设要是走索引去执行分组后再聚合，性能一定是比临时磁盘文件去执行好多了。所以对于 group by 后的字段，最好也是按照联合索引里的最左侧的字段开始，按顺序排列开来，这样，就可以完美运用索引来直接提取一组一组的数据，然后针对每一组的数据执行聚合函数即可 其实大家会发现，这个 group by 和 order by 用上索引的原理和条件都是差不多的，本质都是在 group by 和 order by 之后的字段顺序和联合索引中的从最左侧开始的字段顺序一致，然后就可以充分利用索引树已经完成排序的特性，快速地根据排序好的数据执行后续操作了。这样就不用针对杂乱无章的数据利用临时磁盘文件加上部分内存数据结构进行耗时耗力的现场排序和分组。 到这里，大家应该理解了一点，就是我们平时设计表里的索引的时候，必须充分考虑到后续的 SQL 语句要怎么写，大概率会根据哪些子段来进行 where 语句里的筛选和过滤？大概会根据哪些字段来进行排序和分组。然后在考虑后之后，就可以为表设计两三个常用的索引，覆盖常见的 where 筛选，order by 排序和 group by 分组的需求，保证常见的 SQL 语句都可以用上索引，这样你系统跑起来，是不会有太大的查询性能问题如果查询还是有问题，就需要深度理解查询的执行计划和执行原理了，然后基于执行计划来进行深度 SQL 调优。 顺便扩展一下，对于更新而言，其实最核心的就是三大问题，一个是你索引别太多，索引太多了，更新的时候维护很多索引树肯定是不行的；一个是可能会涉及到一些锁等待和死锁的问题；一个就是可能会涉及到 MySQL 连接池、写 redo log 文件之类的问题 回表查询对性能的损害以及覆盖索引一般我们自己建的索引不管是单列索引还是联合索引，其实一个索引就对应着一棵独立的索引 B+ 树，索引 B+ 树的节点仅仅包含着索引里的几个字段的值以及主键值。即使我们根据索引树找到了需要的数据，那也仅仅是索引里的几个字段的值和主键值。如果你搞了个 SELECT * 还需要很多其他的字段，那还要走一个回表操作，根据主键跑到主键的簇簇索引里去找，聚簇索引的叶子节点是数据页，找到数据页才能把一行数据的所有字段值提取出来 所以类似 SELECT * FROM table ORDER BY xx1, xx2, xx3的语句，可能你就得从联合索引的索引树里按照顺序取出所有数据，接着对每一条数据都走一个主键的聚簇索引的查找，其实性能也是不高的 有的时候 MySQL 的执行引擎可能会认为，类似 SELECT * FROM table ORDER BY xx1, xx2, xx3 的语句，相当是把联合索引和聚簇索引，两个索引的所有数据都扫描一遍，那还不如不走联合索引，直接全表扫描，这样还就扫描一个索引而已 但是你如果是 SELECT * FROM table ORDER BY xx1, xx2, xx3 LIMIT 10 这样的语句，那执行引擎就知道，你先扫描联合索引的索引树拿到 10 条数据，接着对 10 条数据在聚簇索引里查找 10 次就可以了，那么还是会走联合索引的。这个原理大家要知道 其次，就是要讲一下覆盖索引的概念。其实覆盖索引不是一种索引，它就是一种基于索引查询的方式罢了。 针对类似 SELECT xx1, xx2, xx3 FROM table ORDER BY xx1, xx2, xx3 这样的语句。这种情况下，你仅仅需要联合索引里的几个字段的值，那么其实只要扫描联合索引的索引树就可以了，不需要回表去聚簇索引里找其它字段了。所以这个时候，需要的字段直接在索引树里就能提取出来，不需要回表到聚簇索引，这种查询方式就是覆盖索引 所以在写 SQL 的时候，一方面你要注意一下也许你会用到联合索引，但是是否可能会导致大量的回表到聚簇索引，如果需要回表到聚簇索引的次数太多了，可能就直接给你做成全表扫描不走联合索引了。 一方面是尽可能还是在 SQL 里指定你仅仅需要的几个字段，不要搞一个 SELECT * 把所有字段都拿出来，甚至最好是直接走覆盖索引的方式，不要回表到聚簇索引。即使真的要回表到聚簇索引，那也尽可能用 LIMIT、WHERE 之类的语句限定一下回表到聚簇索引的次数，就熊联合索引里筛选少数数据，然后再回表到聚簇索引里去，这样性能也会好一些。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-之索引讲解（下）]]></title>
    <url>%2FCKING.github.io%2F2020%2F07%2F08%2FMySQL-%E4%B9%8B%E7%B4%A2%E5%BC%95%E8%AE%B2%E8%A7%A3%EF%BC%88%E4%B8%8B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[之前讲了 MySQL 数据库的索引结构，让大家清楚不同索引的结构，大致是如何建立的，搜索的时候是如何根据不同的索引去查找数据的。现在，我们说说在插入数据的时候，是如何维护不同索引的 B+ 树的 首先，刚开始你一个表搞出来以后，它就一个数据页，这个数据页是属于聚簇索引的一部分，而且目前还是空的。此时如果你插入数据，就是直接在这个数据页里插入就可以了，没必要弄什么索引页 这个初始的数据页其实就是一个根页，每个数据页内部默认就有一个基于主键的页目录，所以此时你根据主键来搜索时没有问题的，直接在唯一一个数据页里根据页目录找就可以了 然后你表里的数据越来越多，此时你的数据页满了，就会搞一个新的数据页，然后把你根页面里的数据都拷贝过去，同时再搞一个新的数据页，根据你的主键值的大小进行挪动，让两个新的数据页根据主键值排序，第二个数据页的主键值都大于第一个数据页的主键值。 那么此时那个根页在哪？此时根页就升级为索引页，这个根页里存放的是两个数据页的页号和它们里面最小的主键值。如下图，根页就成了索引页，引用两个数据页 接着会不停地往表里灌入数据，然后数据页不停地页分裂，分裂出来越来越多的数据页。此时你的唯一一个索引页，也就是根页里存放的数据页索引条目越来越多，连你的索引页都放不下了，那你就让一个索引页分裂成两个索引页，然后根页继续往上走一个层级引用两个索引页 接着就是以此类推，你的数据页越多，那么根页指向的索引页也会不停地分裂，分裂出更多的索引页，当你下层的索引页数量太多的时候，会导致你的根页指向的索引页太多了，此时根页继续分裂成多个索引页，根页再次往上提上去一个层级 例如你 name 字段有一个索引，那么刚开始的时候你插入一个数据，一方面在聚簇索引的唯一的数据页里插入，一方面在 name 字段的索引 B+ 树唯一的数据页里插入。然后数据越来越多，你的 name 字段的索引 B+ 树里唯一的数据页也会分裂，整个分裂的过程跟上面说的是一样的，所以你插入数据的时候，本身就会维护你各个索引的 B+树 另外补充一点，你的 name 字段的索引 B+ 树里的索引页中，其实除了存放页号和最小 name 字段值以外，每个索引页里还会存放那个最小 name 字段值对应的主键值。这是因为有时候会出现多个索引页指向的下层页号的最小 name 字段值是一样的，此时就必须根据主键判断一下 例如你插入一个新的 name 字段值，此时它需要根据 name 字段的 B+ 树索引的根页面开始，去逐层寻找和定位自己这个新的 name 字段值应该插入到哪个叶子节点的哪个数据页里去。此时万一遇到一层里不同的索引页指向不同的下层页号，但是 name 字段值一样，此时就得根据主键值比较一下，新的 name 字段值肯定是插入到主键值较大的那个数据页里去的 索引不是越多越好默认情况下 MySQL 给我们建立的聚簇索引都是基于主键的值来组织索引的，聚簇索引的叶子节点都是数据页，里面放的就是我们插入的一行一行的完整的数据。在一个索引 B+ 树中，它有一些特性，就是数据页/索引页里面的记录都是组成一个单向链表的，而且是按照数据大小有序排列的；然后数据页/索引页互相之间是组成双向链表的，而且也都是按照数据大小有序排列的，所以其实 B+ 树索引是一个完全有序的数据结构，无论是页内还是页之间 正是因为这个有序的 B+ 树索引结构，才能让我们查找数据的时候，直接从根节点开始按照数据值大小一层一层往下找，这个效率是非常高的 然后如果是针对主键之外的字段建立索引的话，实际上本质就是为那个字段的值重新建立另外一棵 B+ 树索引，那个索引 B+ 树的叶子节点，存放的都是数据页，里面放的都是你字段的值和主键值，然后每一层索引页里存放的都是下层页的引用，包括页内的排序规则，页之间的排序规则，B+ 树索引的搜索规则，都是一样的 但是，如果我们要根据其它字段的索引来搜索，那么只能基于其它字段的索引 B+ 树快速查找到那个值所对应的主键，接着再次做回表查询，基于主键在聚簇索引的 B+ 树里，重新从根节点开始查找那个主键值，找到主键值对应的完整数据 那么，你在 MySQL 的表里建立一些字段对应的索引，好处是什么？好处是显而易见的，你可以直接根据某个字段的索引 B+ 树来查找数据，不需要全表搜索，性能提升是很高的。但坏处呢？索引主要有两个缺点，一个是空间上的，一个是时间上的 空间上而言，你要是给很多字段创建很多的索引，那你会有很多棵索引 B+ 树，每一棵 B+ 树都要占用很多的磁盘空间。如果你建的索引太多，是很耗费磁盘空间的。其次，如果你建了很多索引，那么你在进行增删改的时候，每次都需要维护各个索引的数据有序性，因为每个索引 B+ 树都要求页内是按照值大小排序的，页之间也是有序的，下一个页的所有值必须大于上一个页的所有值 所以你不停地增删改，必然会导致各个数据页之间的值大小可能会没有顺序，此时只能进行数据页的挪动，维护页之间的顺序；或者你不停地插入数据，各个索引的数据页就要不停地分裂，不停地增加新的索引页，这个过程都是耗费时间的 所以你一个表里建的索引太多，很可能就会导致你的增删改的速度就比较差。因此，我们是不建议在一个表里建太多索引的 联合索引查询原理和全值匹配规则之所以讲联合索引，是因为我们设计系统的时候一般是设计联合索引，很少用单个字段做索引，原因是我们要尽可能让索引数量少一些，避免磁盘占用太多，增删改性能太差 假设我们有一个表是存储学习成绩的，这个表有 id，这个 id 是一个自增主键，默认就会基于它做一个聚簇索引。然后就是包含了「学生班级」「学生姓名」「科目名称」「成绩分数」四个字段，平时查询，比较多的就是查找某个班级的某个学生的某个科目的成绩。所以，我们针对「学生班级、学生姓名和科目名称」建一个联合索引 我们用一个图展示这三个字段组成的联合索引的部分内容，如下： 上图有两个数据页，第一个数据页里有三条数据，每条数据都包含了联合索引的三个字段的值和主键值，数据页内部都是按照顺序排序的。首先按照班级字段的值来排序，如果一样就按照学生姓名字段来排序，如果一样泽按照科目名称来排序，所以数据页内部都是按照三个字段的值来排序的，而且还组成了单向链表 然后数据页之间也是有顺序的，第二个数据页里的三个字段的值都一定大于上一个数据页里三个字段的值，比较方法也是按照班级名称、学生姓名、科目名称依次来比较，数据页之间组成双向链表 索引页里就是两条数据，分别指向两个数据页，索引存放的是每个数据页里最小的那个数据的值。而且，索引页里指向两个数据页的索引项里都是存放了那个数据页里最小的值。索引页内部的数据页是组成单向链表有序的，如果你有多个索引页，那么索引页之间也是有序的，组成了双向链表 现在我们要搜索「1 班 + 张小强 + 数学」的成绩，SQL 语句为 1SELECT * FROM student_score WHERE class_name = '1班' AND student_name = '张小强' and subject_name = '数学' 这就涉及到一个索引的使用规则，那就是你发起的 SQL 语句里，where 条件里的几个字段都是基于等值来查询的，都是用的等于号。而且 where 条件里的几个字段的名称和顺序也跟你的联合索引一模一样，此时就是等值匹配规则，上面的 SQL 语句是可以用联合索引查询的 那么查询的过程也简单，首先到索引页里去找，索引页里有多个数据页的最小值记录，此时直接在索引页里基于二分查找来找就可以了，先是根据班级名称来找 1 班这个值对应的数据页，直接可以定位到它所在的数据页 然后你就直接找到索引指向的那个数据页就可以了，在数据页内部本身也是一个单向链表，你也是直接二份查找就可以了。先按 1 班这个值找，你会发现几条数据都是 1 班；此时就可以按照「张小强」这个姓名来二分查找，此时会发现多条数据都是张小强，接着就按照「科目名称」数学来二分查找、很快就可以定位到下图中的一条数据，1 班的张小强的数学科目，它对应的数据 id 是127 然后就根据主键 id = 127 到聚簇索引里按照一样的思路，从索引根节点开始二分查找迅速定位下个层级的页，再不停地找，很快就可以找到 id = 127 的那条数据，然后从里面提取所有字段就可以了 上面整个过程就是联合索引的查找过程，以及全值匹配规则。假设你的 SQL 语句的 where 条件里用的几个字段和顺序，都跟你的索引的字段一样，同时你还是用等号在做等值匹配，那么直接就会按照上述过程来找。 对于联合索引而言，就是依次按照各个字段来进行二分查找，先定位到第一个字段对应的值在哪个页里，然后如果第一个字段有多条数据值都一样，就根据第二个字段来找，以此类推，就可以定位到某条或者某几条数据 索引使用规则接着我们讲一下几个基本的索引使用规则。还是用上面的那个例子来做说明 上面我们讲的是等值匹配原则，就是你 where 语句中的几个字段名称和联合索引名称的字段完全一样，而且都是基于等号的等值匹配，那百分百会用上我们的索引。即使你 where 语句里写的顺序和联合索引里的字段顺序不一致，也没关系，MySQL 会自动优化为按联合索引的字段顺序去找 第二个规则是最左侧列匹配。假设我们联合索引是 KEY(class_name, student_name, subject_name)，那么不一定必须要在 where 语句根据三个字段来查，其实只要根据最左侧的部分字段来查，也是可以的 例如你可以写下面的 SQL 语句，就差某个学生所有科目的成绩，这是没问题的 1SELECT * FROM student_score WHERE class_name = '' and student_name = '' 但是如果你写一个 select * from student_score where subject_name = &#39;&#39;，那就不行了，因为联合索引的 B+ 树里，是必须先按 class_name 查，再按 student_name 查，不能跳过前面两个字段，直接按最后一个 subject_name 查的 另外，如果你写一个 select * from student_score where class_name = &#39;&#39; and subject_name = &#39;&#39;，那么只有 class_name 的值可以在索引里搜索，剩下的 subject_name 是没法在索引里找的，道理同上。 所以在建立索引的时候，必须考虑好联合索引字段的顺序，以及平时写 SQL 的时候要按哪几个字段来查 第三个规则是最左前缀匹配原则，即如果你要用 LIKE 语法去查，比如 SELECT * FROM student_score WHERE class_name LIKE &#39;1%&#39;，查找所有 1 打头的班级的分数，那么可以用到索引的。因为你的联合索引 B+ 树里，都是按照 class_name 排序的，所以你给出 class_name 的确定的最左前缀是 1，然后后面的给一个模糊匹配符合，那也是可以基于索引来查找的 但是你如果写 class_name LIKE &#39;%班&#39;，在左侧用一个模糊匹配符，那他就没法用索引了，因为不知道你最左前缀是什么，没办法去索引里找 第四个就是范围查找规则，这个意思是我们可以用 SELECT * FROM student_score WHERE class_name &gt; &#39;1班&#39; and class_name &lt; &#39;5班&#39; 这样的语句来范围查找某几个班级的分数。这个时候也是会用到索引的，因为我们的索引的最下层的数据页都是按顺序组成双向链表的，所以完全可以先找到「1 班」对应的数据页，再找到「5 班」对应的数据页，两个数据页中间的那些数据页，就都是在你的范围内的数据了 但是如果你要是写 SELECT * FROM student_score WHERE class_name &gt; &#39;1 班&#39; AND class_name &lt; &#39;5 班&#39; AND student_name &gt; &#39;&#39; 这里只有 class_name 是可以基于索引来找的，student_name 的范围查询时没法用到索引的 这也是一条规则，就是你的 where 语句里如果有范围查询，那只有对联合索引里最左侧的列进行范围查询才能用到索引 第五个规则，就是等值匹配 + 范围匹配的规则。如果你是用 SELECT * FROM student_score WHERE class_name = &#39;1班&#39; AND student_name &gt; &#39;&#39; AND subject_name &lt; &#39;&#39; ，那么此时你首先可以用 class_name 在索引里精准定位到一波数据，接着这波数据里的 student_name 都是按照顺序排列的，所以 student_name &gt; &#39;&#39; 也会基于索引来查找，但是接下来的 subject_name &lt; &#39;&#39; 是不能用索引的 综上所述，一般我们写 SQL 语句，都是用联合索引的最左侧的多个字段来进行等值匹配 + 范围搜索，或者是基于最左侧的部分字段来进行最左前缀模糊匹配，或者基于最左侧字段来进行范围搜索，这就要写符合规则的 SQL 语句，才能用上联合索引]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL-之索引讲解（中）]]></title>
    <url>%2FCKING.github.io%2F2020%2F07%2F07%2FMySQL-%E4%B9%8B%E7%B4%A2%E5%BC%95%E8%AE%B2%E8%A7%A3%EF%BC%88%E4%B8%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[上篇我们讲了数据页分裂的过程，在你不停地往表里插入数据的时候，会出来一个一个的数据页，如果你的主键不是自增的，它可能会有一个数据行的挪动过程，保证你下一个数据页的主键值都大于上一个数据页的主键值 现在是这样，假设我们有很多数据页，然后我们想要根据主键来查询数据，那么直接查询是不行的，因为我们也不知道主键在哪里。如下： 假设你要搜 id = 4 的数据，但你怎么知道在哪个数据页里？没有任何证据可以告诉你它在哪个数据页里。所以如果还是这个样子的话，你也就只能全表扫描，从第一个数据页开始，每个数据页都要进入到页目录里查找主键，最坏的情况下，所有数据页你都得扫描一遍，这是很坑的 所以此时就需要针对主键设计一个索引了，针对主键索引实际上就是主键目录，这个主键目录，就是把每个数据页的页号，还有数据页里最小的主键值放在一起，组成一个索引的目录。如下图： 有了主键目录之后就方便了，直接就可以到主键目录里去搜索。比如你要找 id = 3 的数据，此时就会跟每个数据页的最小主键来比，首先 id = 3 大于数据页 2 里的最小主键值 1，接着小于数据页 8 里的最小主键值 4，所以你可以直接定位到 id = 3 的数据一定是在 数据页 = 2 里的 假设你有很多的数据页，在主键目录里就会有很多的数据页和最小主键值，此时你完全可以根据二分查找的方式来找你要找的 id 在哪个数据页里。这个效率是非常高的，而类似上面的主键目录，就可以认为是主键索引 我们的数据页都是一坨一坨的连续数据放在很多磁盘文件里的，所以只要你能够根据主键索引定位到数据所在的数据页，此时假设我们有别的方式存储了数据页跟磁盘文件的对应关系，此时你就可以找到一个磁盘文件。而且我们假设数据页在磁盘文件里的位置也就是 offset 偏移量，你也是可以知道的，此时就可以直接通过随机读的方式定位到磁盘文件的某个 offset 偏移量，然后就可以读取连续的数据页了 索引的页存储结构上面说了主键索引的目录结构。只要在一个主键索引里包含每个数据页跟它最小主键值，就可以组成一个索引目录，然后你后续查询主键值，就可以在目录里二分查找定位那条数据所属的数据页，接着到数据页里二分查找定位那条数据就可以了 现在，你的表里的数据可能有很多，比如有几百万，几千万甚至单表几亿数据都是可能的，所以你可能有大量的数据页，然后你的主键目录里就要存储大量的数据页和最小主键值，这是不行的。所以在考虑这个问题的时候，实际上是采取了一种把索引数据存储在数据页的方式来做的 也就是说，你的表的实际数据是存放在数据页里的，然后你表的索引也是存放在页里的，此时索引放在页里之后，就会有索引页。假设你有很多的数据页，那么此时就可能就有很多的索引页 现在又会存在一个问题，你现在有很多索引页，但是此时你需要知道，应该去哪个索引页里去找你的主键数据。于是我们又可以把索引页多加一个层级出来，在更高的索引层级里，保存了每个索引页和索引页里的最小主键值，如下图： 假设我们要查找 id = 6，直接先到最顶层的索引页 35 里去找，直接通过二分查找可以定位到下一步应该到索引页 20 里去找，接下来到索引页 20 里通过二分查找定位，也可以很快定位到数据应该在数据页 8里，在进入数据页 8， 可以找到 id = 6 的那一行数据 如果最顶层的那个索引页里存放的下层索引页的页号太多了，怎么办？此时可以再次分裂，再加一层索引页，如下图： 是不是觉得索引页不知不觉组成了多个层级，有点像一棵树？没错，这就是一颗 B+ 树，属于数据结构里的一种树形数据结构，所以一直说 MySQL 的索引是 B+ 树来组成的，就是这个意思 我们就以最基础的主键索引来举例，当你为一个表的主键建立起索引之后，其实这个主键的索引就是一棵 B+ 树，然后当你要根据主键来查数据的时候，直接就是从 B+ 树的顶层开始查找，一层一层往下定位，最终定位到一个数据页里，在数据页内部的目录里二分查找，找到那条数据 这就是索引最真实的物理存储结构，采用跟数据页一样的页目录来存储，一个索引就是很多页组成的一棵 B+ 树 聚簇索引上面讲了如何基于主键组织一个索引，然后建立索引之后，如何基于主键在索引中快速定位到那行数据所在的数据页，再如何进入数据页快速定位那行数据。今天我们按照主键来搜索数据的过程重新给大家梳理一遍，方便大家理解聚簇索引 首先，假设我们要搜索一个主键 id 对应的行，此时你应该先去顶层的索引页 88 里去找，通过二分查找的方式，很容易定位到你应该去下层哪个索引页里继续找。如图： 比如现在定位到了下层的索引页 35 里去继续找，此时在索引页 35 里也有一些索引条目，分别都是下层各个索引页（20，28，59）和它们最小的主键值，此时在索引页 35 的索引条目里继续二分查找，很容易定位到，应该在到哪个索引页里去继续找 假设从索引页 35 接着就找到下层的索引页 59 里去了，此时索引页 59 里肯定也是有索引条目的，这里就存放了部分数据页页号（比如数据页 2 和数据页 8）和每个数据页里最小的主键值。此时就在这里继续二分查找，就可以定位到应该到哪个数据页里去找 假设进入了数据页 2，里面就有一个页目录，都存放了各行数据的主键值和行的实际物理位置。此时在这里直接二分查找，就可以快速定位到你要搜索的主键值对应行的物理位置，然后直接在数据页 2 里找到那条数据即可 这就是基于索引结构去查找主键的一个过程。其实最下层的索引页，都是会有指针引用数据页的，所以实际上索引页之间跟数据页之间是有指针连接起来的。如图： 另外，其实索引页自己内部，对于一个层级内的索引页，互相之间都是基于指针组成双向链表的，就跟数据页自己组成双向链表是一样的 从上面的描述中我们可以发现一些亮点，假设你把索引页和数据页综合起来看，它们都是连接在一起的，看起来就如同一棵完整的大的 B+ 树一样，从根索引页开始，一直到所有的数据页，其实组成了一颗巨大的 B+ 树。在这棵 B+ 树里，最底层的一层就是数据页，数据页也就是 B+ 树里的叶子节点 所以，如果一棵大的 B+ 树索引结构里，叶子节点就是数据页自己本身，那么此时我们就可以称这棵 B+ 树索引为聚簇索引。即，上图中所有的索引页 + 数据页组成的 B+ 树就是聚簇索引 其实在 InnoDB 存储引擎里，你在对数据增删改的时候，就是直接把你的数据页放在聚簇索引里的，聚簇索引就包含了数据。比如你插入数据，那么就是在数据页里插入数据，那么就是在数据页里插入数据。如果你的数据页开始进行页分裂了，它此时会调整各个数据页内部的行数据，保证数据页内的主键值都是有序的，下一个数据页的所有主键值都大于上一个数据页的所有主键值 同时，在页分裂的时候，会维护你的上层索引结构，在上层索引页里维护你的索引条目，不同的数据页和最小主键值。然后如果你的数据页越来越多，一个索引页放不下了，此时就会在拉出新的索引页，同时再搞一个上层的索引页，上层索引页里存放的索引条目就是下层索引页页号和最小主键值 按照这个顺序，以此类推，如果你的数据量越大，此时可能就会多出更多的索引页层级来。不过说实话，一般索引页里可以存放很多索引条目，所以通常而言，即使你是亿级大表，基本上大表里建的索引也就三四层而已 这个举措索引默认是按照主键来组织的，所以你在增删改数据的时候，一方面会更新数据页，一方面其实会给你自动维护 B+ 树结构的聚簇索引，给新增和更新索引页。这个聚簇索引是默认就会给你建立的 二级索引（非聚簇索引）上面讲了聚簇索引这个东西，其实聚簇索引就是 InnoDB 存储引擎默认给我们创建的一套基于主键的索引结构，而且我们表里的数据就是直接放在聚簇索引的，作为叶子节点的数据页。而且我们也对基于主键的数据搜索也比较清晰了，就是从聚簇索引的根节点开始进行二分查找，一路找到对应的数据页里，基于页目录就直接定位到主键对应的数据就可以了 接着我们说说对主键外的其它字段建立索引的原理。其实你要是对其它字段建立索引，比如 name、age 之类的字段，都是一样的原理。即，你插入数据的时候，一方面会把完整数据插入到聚簇索引的叶子节点的数据页里去，同时维护好聚簇索引；另一方面会为你其它字段建立的索引，重新再建立一棵 B+ 树 比如你基于 name 字段建立了一个索引，那么此时你插入数据的时候，就会重新建一棵 B+ 树，B+ 树的叶子节点也是数据页，但是这个数据页里仅仅放主键字段和 name 字段 注意，这可是独立于聚簇索引之外的另外一个索引 B+ 树，严格说是 name 字段的索引 B+ 树，所以在 name 字段的索引 B+ 树里，叶子节点的数据页里仅仅放主键和 name 字段的值，至于排序规则之类的，都是跟以前一样的，即，name 字段的索引 B+ 树里，叶子节点的数据页中的 name 值都是按大小排序的，同时下一个数据页里的 name 字段值都大于上一个数据页里的 name 字段值，整个整体的排序规则都跟聚簇索引按照主键的排序规则是一样的 然后，name 字段的索引 B+ 树也会构建多层级的索引页，这个索引页存放的就是下一层的页号和最小 name 字段值，整体规则都是一样，只不过存放的是 name 字段的值，根据 name 字段值排序罢了 假设你要根据 name 字段来搜索数据，那搜索过程是一样的，就是从 name 字段的索引 B+ 树里的根节点开始找，一层一层往下找，一直找到叶子节点的数据页里，定位到 name 字段值对应的主键值。然后，此时针对 SELECT * FROM table WHERE name = &#39;xx&#39; 这样的语句，先根据 name 字段值在 name 字段的索引 B+ 树里找，找到叶子节点也仅仅可以找到对应的主键值，而找不到这行数据完整的所有字段 所以此时你还要进行「回表」。这个回表，就是还需要根据主键值，再到聚簇索引里从根节点开始，一路找到叶子结点的数据页，定位到主键对应的完整数据行，此时才能把 SELECT * 要的字段值都拿出来。 因为我们根据 name 字段的索引 B+ 树找到主键之后，还要根据主键去聚簇索引里找，所以一般把 name 字段这种普通字段的索引称为二级索引，一级索引就是聚簇索引，这就是普通字段的索引的运行原理 其实我们也可以把多个字段联合起来，建立联合索引，比如 name + age。此时联合索引的运行原理是一样的，只不过是建立一棵独立的 B+ 树，叶子节点的数据页里放了 id + name + age，然后默认按照 name 排序，name 一样就按照 age 排序，不同数据页之间的 name + age 值的排序也如此 然后这个 name + age 的联合索引的 B+ 树的索引页里，放的就是下层节点的页号和最小的 name + age 的值。以此类推，所以你根据 name + age 搜索的时候，就会走 name + age 联合索引的这棵 B+ 树了，搜索到主键，再根据主键到聚簇索引里去搜索 以上，就是 InnoDB 存储引擎的索引的完整实现原理。其实就是建立 B+ 树，根据 B+ 树一层一层二分查找而已。然后不同的索引就是建立不同的 B+ 树，然后你增删改的时候，一方面在数据页里更新数据，一方面就是维护你所有的索引。后续查询，你就要尽量根据索引来查询]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之索引讲解（上）]]></title>
    <url>%2FCKING.github.io%2F2020%2F07%2F03%2FMySQL-%E4%B9%8B%E7%B4%A2%E5%BC%95%E8%AE%B2%E8%A7%A3%EF%BC%88%E4%B8%8A%EF%BC%89%2F</url>
    <content type="text"><![CDATA[磁盘数据页的存储结构在深入研究索引之前，我们需要先来看磁盘上的数据文件中的数据页的物理存储结构。之前说过，数据库最终所有的数据（包括我们建的各种表以及表里的数据）都是要存放在磁盘上的文件里的，然后文件里存放的物理格式就是数据页，那么大量的数据页在磁盘文件里是怎么存储的呢？ 首先，大量的数据页是按顺序一页一页存放的，然后两两相邻的数据页之间会采用双向链表的格式互相引用，大概如下： 上面画的这个图在磁盘文件里到底是怎么弄出来的？其实一个数据页在磁盘里就是一段数据，可能是二进制或者别的特殊格式的数据，然后数据页里包含两个指针，一个指针指向自己上一个数据页的物理地址，一个指针指向自己下一个数据页的物理地址，大概可以认为类似下面这样： 1DataPage: xx=xx, xx=xx, linked_list_pre_pointer=15367, linked_list_next_pointer=34126 || DataPage: xx=xx, xx=xx, linked_list_pre_pointer=23789, linked_list_next_pointer=46589 || DataPage: xx=xx, xx=xx, linked_list_pre_pointer=33198, linked_list_next_pointer=55681 上面那段数据，不能完全认为是 MySQL 数据库的磁盘文件里的存储格式，这里就是给你看一些类似的东西，其实 MySQL 实际存储大致也是类似这样的，就是每个数据页在磁盘文件里都是连续的一段数据。然后每个数据页里，可以认为就是 DataPage 打头一直到 || 符合的一段磁盘里的连续的数据，你可以认为每一个数据页就是磁盘文件里这么一段连续的东西 然后每个数据页，都有一个指针指向自己上一个数据页在磁盘文件里的起始物理位置，比如 linked_list_pre_pointer=15367 就是指向了上一个数据页在磁盘文件里的起始位置，那个 15367 可以认为就是在磁盘文件里的 position 或者 offset。同理，也有一个指针指向自己下一个数据页的物理位置 接着，一个数据页内部会存储一行一行的数据，也就是平时我们在表里插入的一行一行的数据就会存储在数据页里，然后数据页里的每一行数据都会按照主键大小进行排序存储，同时每一行数据都有指针指向下一行的位置，组成单向链表。如图： 没有索引时，数据库如何查询数据上面说了数据页在磁盘文件中的物理存储结构。目前知道数据页之间是组成双向链表的，然后数据页内部的数据行是组成单向链表的，而且数据行是根据主键从小到大排序的 然后每个数据页里都会有一个页目录，里面根据数据行的主键存放了一个目录，同时数据行是被分散存储到不同的槽位里去的，所以实际上每个数据页的目录里，就是这个页里每个主键跟所在槽位的映射关系，如图： 假设你要根据主键查找一条数据，而且此时你数据库里那个表没几条数据，那个表总共就一个数据页，那就很简单了。首先就会先到数据页的页目录里根据主键进行二分查找，然后通过二分查找在目录里迅速定位到主键对应的数据是在哪个槽位里，然后到那个槽位里，遍历槽位里的每一行数据，就能快速找到那个主键对应的数据了。每个槽位里都有一组数据行，你就是在里面遍历查找就行 如果你是根据非主键的其它字段来查找数据呢？此时是没办法使用主键的那种页目录来二分查找的，只能进入到数据页里，根据单向链表依次遍历查找数据，这就性能很差了 如果我们有很多数据页呢？一个表里一般都是有大量数据的，这些数据页就存放在物理磁盘文件里，这时如何查询数据？假设你没有建立任何索引，那么无论是根据主键查询，还是根据其它字段来条件查询，都没有什么取巧的方法 你一个表里的所有数据页都是组成双向链表的，那么直接从第一个数据页开始遍历所有数据页，从第一个数据页开始，你得先把第一个数据页从磁盘上读取到内存 buffer pool 的缓存页里来。然后你就在第一个数据页对应的缓存页里，按照上述办法查找，假设是根据主键查找，你可以在数据页的页目录里二分查找；假设你是根据其它字段查找的，只能是根据数据页内部的单向链表来遍历查找，如图： 如果第一个数据页没找到你要的那条数据，那只能根据数据页的双向链表去找下一个数据页，然后读取到 Buffer Pool 的缓存页里去，然后按一样的方法在一个缓存页内部查找那条数据。如果还是找不到，那只能根据双向链表继续加载下一个数据页到缓存页里来，一次类推，循环往复 不知道你们有没有感知到，你似乎是在做一个数据库里很尴尬的操作：全表扫描。是的，上述操作过程，就是全表扫描。在你没有任何索引数据结构的时候，无论如何查找数据，都是一个全表扫描的过程，就是根据双向链表依次把磁盘上的数据页加载到缓存页里去，然后在一个缓存页内部来查找那条数据。最坏的情况下，你就得把所有数据页里的每条数据都遍历一遍，才能找到你需要的那条数据，这就是全表扫描 页分裂总结上面的内容就是，数据页之间是组成双向链表的，数据页内部的数据行是组成单向链表的，每个数据页内根据主键做了一个页目录。然后一般来说，你没有索引的情况下，所有的数据查询，其实在物理层都是全表扫描，依次扫描每个数据页内部的每个数据行。 其实，没有索引情况先一个表中的数据查询情况，这个速度是很慢的，所以一般是不能让查询走全表扫描的。因此正常在数据库中的查询，必须要运用索引来加速查询的执行。 在引入索引之前，还得讲一个知识点，就是我们在一个表里不停地插入数据的时候，会涉及到一个页分裂的过程，即，这个表里是如何出现一个又一个的数据页的。 正常情况下，我们在一个表里插入一些数据后，它们都会进入到一个数据页里去，在数据页内部，它们会组成一个单向链表，这个数据页内部的单向链表大致如下所示： 如上图，里面是一行一行的数据，刚开始第一行是个起始行，它的类型是 2，就是最小的一行，然后它有一个指针指向了下一行数据，每一行数据都有自己每个字段的值，然后每一行通过一个指针不停地指向下一行数据，普通的数据行的类型都是 0，最后一行是一个的类型 3，代表最大的一行 那什么是页分裂？假设你不停地在表里插入数据，那么刚开始就是不停地在一个数据页插入数据，接着数据越来越多，此时就要在搞一个数据页了，如图： 此时会遇到一个问题，索引运作的一个核心机制就是要求你后一个数据页的主键值都大于前面一个数据页的主键值，如果你的主键是自增的，那还可以保证这一点，因为你新插入后一个数据页的主键值一定都大于前一个数据页的主键值。但是如果你的主键不是自增长的，可能会出现你后一个数据页的主键值里，有的主键是小于前一个数据页的主键值的。例如在第一个数据页里有一条数据的主键是 10，第二个数据页里又一条数据的主键值是 8，这就有问题了 所以此时就会出现一个过程，叫做页分裂。就是万一你的主键值都是自己设置的，那么在增加一个新的数据页的时候，实际上会把前一个数据页里主键值较大的，挪动到新的数据页里来，然后把你新插入的主键值较小的数据挪到上一个数据页里去，保证新数据页里的主键值一定都比上一个数据页里的主键值大。 例如下图，新数据页里，有两条数据的主键值明显是小于上一个数据页的主键值： 上图中，第一个数据页里有 1、5、6 三条数据，第二个数据页里又 2、3、4 三条数据，明显第二个数据页里的数据的主键值比第一个数据页里的 5 和 6 两个主键都小，这个是不行的。此时就会出现页分裂的行为，把数据页里的两条数据挪动到上一个数据页，上一个数据页里挪两条数据到新数据页里去，如下图：]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 不确定性的性能抖动优化实践]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F29%2FMySQL-%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7%E7%9A%84%E6%80%A7%E8%83%BD%E6%8A%96%E5%8A%A8%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[今天我们说说，线上数据库时不时莫名地来一次性能抖动的问题，而且造成性能抖动的还不是之前我们说过的数据库锂电池充放电问题，而是另一个新的问题，跟我们之前讲解的原理是息息相关的 我们平时在数据库里执行的更新语句，实际上都是从磁盘上加载数据页到数据库内存的缓存页里来，接着就直接更新内存里的缓存页吗，同时还更新对应的 redo log 写入一个 buffer 中 既然我们更新了 Buffer Pool 里的缓存页，缓存页机会变成脏页。之所以说它是脏页，就是因为缓存页里的数据目前跟磁盘文件里的数据页是不一样的，所以此时叫缓存页是脏页 既然是脏页，那么得有一个合适的时机把脏页给刷入到磁盘文件里去。之前我们分析过这个脏页刷入磁盘的机制，它是维护了一个 LRU 链表来实现的，通过 LRU 链表，他知道哪些缓存页是最近经常被使用的。 那么如果你要加载磁盘文件的数据页到 Buffer Pool 里去了，但是此时并没有空闲的缓存页了，此时就必须要把部分脏缓存页刷入到磁盘里去，此时就会根据 LRU 链表找那些最近最少被访问的缓存页去刷入磁盘，如图： 那么万一要是你要执行的是一个查询语句，需要查询大量的数据到缓存页里去，此时就可能导致内存里大量的脏页需要淘汰出去刷入磁盘上，才能够腾出足够的内存空间来执行这条查询语句。在这种情况下，可能你会发现突然莫名其妙的线上数据库执行某个查询语句就一下子性能出现抖动，平时只要几十毫秒的查询语句，这次要几秒钟。毕竟你要等待大量脏页 flush 到磁盘，然后语句才能执行 另外还有一种脏页刷磁盘的契机，就是大家都知道 redo log buffer 里的 redo log 本身也是会随着各种条件刷入磁盘上的日志文件的，比如 redo log buffer 里的数据超过容量的一定比例了，或者是事务提交的时候，都会强制 buffer 里的 redo log 刷入磁盘上的日志文件 然后磁盘上是有多个日志文件的，它会依次不停地写，如果所有日志文件都写满了，此时会重新回到第一个日志文件再次写入，这些日志文件是不停地循环写入的，所以其实在日志文件都被写满的情况下，也会触发一次脏页的刷新 为什么？因为假设你的第一个日志文件的一些 redo log 对应的内存里的缓存页的数据都没刷新到磁盘上的数据页里去，一旦你把第一个日志文件里的这部分 redo log 覆盖了写别的日志，此时万一数据库崩溃，是不是有些你之前更新过的数据就彻底丢失了？ 因此一旦你把所有日志文件写满了，此时重新从第一个日志文件开始写的时候，它会判断一下，如果你第一个日志文件里的一些 redo log 对应之前更新过的缓存页，还没刷入磁盘，此时必然是要把那些将要被覆盖的 redo log 更新的缓存页都刷入磁盘的 尤其是这一种刷脏页的情况下，因为 redo log 所有日志文件都写满了，此时会导致数据库直接 hang 死，无法处理任何更新请求，因为执行任何一个更新请求都必须要写 redo log，此时你需要刷新一些脏页到磁盘，然后才能继续执行更新语句，把更新语句的 redo log 从第一个日志文件开始覆盖写 所以此时假设你在执行大量的更新语句，可能你突然发现线上数据库莫名地很多更新语句短时间内性能都抖动了，平时就几毫秒就执行好了，这次要等待 1 秒才能执行完毕、因为遇到这种情况，你必须要等待第一个日志文件里部分 redo log 对应的脏页都刷入磁盘了，才能继续执行更新语句，会导致更新语句的性能很差 解决方法上面说的莫名的性能抖动，在分析过底层原理之后，发现根本的原因还是两个： 第一种可能 Buffer Pool 的缓存页都满了，此时你执行一个 SQL 查询很多数据，一下子要把很多个缓存页 flush 到磁盘上去，刷磁盘太慢，就会导致你的查询语句执行的很慢。因为你必须等很多缓存页都 flush 到磁盘了，你才能执行查询从磁盘把你需要的数据页加载到 Buffer Pool 的缓存页里来 第二可能你执行更新语句的时候，redo log 在磁盘上的所有文件都写满了，此时需要回到第一个 redo log 文件覆盖写。覆盖写的时候可能就涉及到第一个 redo log 文件里又很多 redo log 日志对应的更新操作改动了缓存页，那些缓存页还没 flush 到磁盘，此时就必须把那些缓存页 flush 到磁盘，才能执行后续的更新语句，而你这么一等待，必然会导致更新执行的很慢 那么我们怎么尽可能优化 MySQL 的一些参数，减少这种缓存页 flush 到磁盘带来的性能抖动问题。 其实，要尽量避免缓存页 flush 到磁盘可能带来的性能抖动问题，核心就两点：一是尽量减少缓存页 flush 到磁盘的频率；二是尽量提升缓存页 flush 到磁盘的速度 但你要减少缓存页 flush 到磁盘的频率，这个是很困难的，因为平时你的缓存页就是正常地被使用，迟早会被填满，一旦填满，必然你执行下一个 SQL 会导致一批缓存页 flush 到磁盘。这个很难控制，除非你给你的数据库采用大内存机器，给 Buffer Pool 分配的空间大一些，那么它缓存页填满的速率低一些，flush 磁盘的频率也会比较低 所以主要还是讲解第二个问题的优化，就是尽可能提升缓存页 flush 到磁盘的速度。例如你现在要执行一个 SQL 查询语句，此时需要等待 flush 一批缓存页到磁盘，接着才能加载查询出来的数据到缓存页。那么如果 flush 那批缓存页到磁盘需要 1s，然后 SQL 查询语句自己执行的时间是 200ms，此时你这条 SQL 执行完毕的总时间就需要 1.2s 了 但是如果你把那批缓存页 flush 到磁盘的时间优化到 100ms，然后加上 SQL 查询自己执行的 200ms，这条 SQL 的总执行时间就只要 300ms 了，性能就提升了很多。 所以这里一个关键之一，就是要尽可能减少 flush 缓存页到磁盘的时间开销最小。如果要做到这一点，通常给大家的建议就是对于数据库部署的机器，一定要采用 SSD 固态硬盘，而不要使用机械硬盘，因为 SSD 固态硬盘的随机 IO 读取能力非常高，而 flush 缓存页到磁盘，就是典型的随机 IO，需要在磁盘上找到各个缓存页所在的随机位置，把数据写入磁盘里去。所以用 SSD 固态硬盘，你的 flush 缓存页到磁盘的性能就会提高不少 其次，光是 SSD 还不够，还得设置一个关键的参数，就是数据库的 innodb_io_capacity，这个参数是告诉数据库采用多大的 IO 速率把缓存页 flush 到 磁盘里去 例如，你 SSD 能承载的每秒随机 IO 次数是 600 次，结果你把数据库的 innodb_io_capacity 设置为 300，也就是 flush 缓存页到磁盘的时候，每秒最多执行 300 次随机 IO。这速度就相对来说很慢了，没把 SSD 固态硬盘的随机 IO 性能发挥出来 所以通常都会建议对数据库部署的机器的 SSD 固态硬盘能承载的最大随机 IO 速率做一个测试，这个可以使用 fio 工具来测试。fio 工具是一种用于测试磁盘最大随机 IO 速率的 Linux 工具，如何使用，可以到网上搜一下 查出来 SSD 固态硬盘的最大随机 IO 速率之后，就知道它每秒可以执行多少随机 IO，此时你把这个数值设置给数据库的 innodb_io_capacity 就可以了，尽可能地让数据库用最大速率去 flush 缓存页到磁盘 但是实际 flush 的时候，其实它会按照 innodb_io_capacity乘以一个百分比来进行刷磁盘，这个百分比就是脏页的比例，是 innodb_max_dirty_pages_pct 参数控制的，默认是 75%，这个一般不用动。另外这个比例也有可能会变化，这个比例同时会参考你的 redo log 日志来计算，但是这个细节大家不用太关注 其实比例不比例的，这里的优化不用太关注，核心就是把 innodb_io_capacity 调整为 SSD 固态硬盘的 IOPS 也就是随机 IO 速率就可以了。 另外还有一个参数，就是 innodb_flush_neighbors，它是说当 flush 缓存页到磁盘的时候，可能会控制把缓存页临近的其它缓存页也刷到磁盘，但是这样有时候会导致 flush 的缓存页太多了。实际上，如果你用的是 SSD 固态硬盘，并没有必要让他同时刷邻近的缓存页，可以把 innodb_flush_neighbors 参数设置为 0，禁止刷邻近缓存页，这样就把每次刷新的缓存页数量降到最低 综上，针对这次的案例，就是 MySQL 性能随机抖动的问题，最核心的就是把 innodb_io_capacity 设置为 SSD 固态硬盘的 IOPS，让它刷缓存页尽量快。同时设置 innodb_flush_neighbors 为 0，让它每次别刷邻近缓存页，减少要刷缓存页的数量，这样就可以把缓存页的性能提升到最高，同时也可以尽可能降低每次刷缓存页对执行 SQL 语句的影响]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 锁详解]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F28%2FMySQL-%E9%94%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[之前说过，脏写是绝对不允许的，那么这个脏写是靠什么防止的呢？其实就是靠锁机制，依靠锁机制让多个事务更新一行数据的时候串行化，避免同时更新一行数据。 在 MySQL 里，假设有一行数据摆在那不动，此时有一个事务来了要更新这行数据，这个时候它会先看看这行数据此时有没有人加锁？如果没有，此时这个事务就会创建一个锁，里面包含了自己的 trx_id 和等待状态，然后把锁跟这行数据关联在一起。 因为更新一行数据必须把它所在的数据页从磁盘文件里读取到缓存页里来才能更新，所以，此时这行数据和关联的锁数据结构，都是在内存里的。大家要明确这一点，如图： 如上图，因为事务 A 给那行数据加了锁，所以此时就可以说那行数据已经被加锁了。既然被加锁了，此时就不能再让别人访问了。现在有另外一个事务 B 过来，这个事务 B 也想更新那个数据，此时就会检查一下，当前这行数据有没有人加锁 此时事务 B 会发现这行数据已被加锁，此时事务 B 也会生成一个锁数据结构，里面有它的 trx_id，还有自己的等待状态。因为它是在排队等待，所以它的等待状态就是 true 了。 接着事务 A 更新完数据，就会把自己的锁给释放掉。锁一旦释放了，它就会去找，此时还有没有别人也对这行数据加锁了呢？它会发现事务 B 也加锁了。于是，它会把事务 B 的锁里的等待状态改为 false，然后唤醒事务 B 继续执行，此时事务 B 就获取到锁了。 共享锁和独占锁多个事务同时更新一行数据，此时都会加锁，然后都会排队等待，必须一个事务执行完毕了，提交了，释放了锁，才能唤醒别的事务继续执行。那么在多个事务运行的时候，它们加的是什么锁呢？ 其实是 X 锁，也就是 Exclude 独占锁。当有一个事务加了独占锁之后，此时其它事务要再更新这行数据，都是要加独占锁的，但是只能生成独占锁在后面等待。那么，当有人在更新数据的时候，其它的事务可以读取这行数据吗？默认情况下需要加锁吗？ 答案是：不用。默认情况下，有人在更新数据，然后你要去读取这行数据，直接默认就是开启 MVCC 机制的。即，此时对一行数据的读和写两个操作默认是不会加锁互斥的，因为 MySQL 设计 MVCC 机制就是为了解决这个问题，避免频繁加锁互斥 此时你读取数据，可以根据你的 ReadView，在 undo log 版本链条里找一个你能读取的版本，完全不用顾虑别人在更新。而且就算你等它更新完了还提交了，基于 MVCC 机制你也读不到它更新的值，因为 ReadView 机制是不允许的，所以你默认情况下的读，完全不需要加锁，不需要去 care 其他事务的更新加锁问题，直接基于 MVCC 机制读某个快照就可以了 如果你在执行查询操作的时候，就是想要加锁呢？那也是可以的，MySQL 首先支持一种共享锁，就是 S 锁。这个共享锁的语法如下：SELECT * FROM table LOCK IN SHARE MODE，你在一个查询语句后面加上 LOCK IN SHARE MODE，意思就是查询的时候对一行数据加共享锁 如果此时有别的事务在更新这行数据，已经加了独占锁，此时你的共享锁能加吗？当然不行了，共享锁和独占锁是互斥的，此时你这个查询只能等着了 如果你先加了共享锁，然后别人来更新要加独占锁行吗？这也不行，此时锁是互斥的，它只能等待 如果你在加共享锁的时候，别人也加共享锁呢？此时也是可以的，你们两都是可以加共享锁的，共享锁和共享锁是不会互斥的 所以这里可以先看出一个规律，就是更新数据的时候必要要加独占锁，独占锁和独占锁是互斥的，此时别人不能更新；但是此时你要查询，默认是不加锁的，走 MVCC 机制读快照版本，但是你查询时可以手动加共享锁的，共享锁和独占锁是互斥的，但是共享锁和共享锁是不互斥的。 锁类型 独占锁 共享锁 独占锁 互斥 互斥 共享锁 互斥 不互斥 不过，一般开发业务系统的时候，其实你查询主动加共享锁的情况是比较少见的。数据库的行锁是实用功能，但是一般不会在数据库层面做复杂的手动加锁操作，反而会用基于 Redis / ZooKeeper 的分布式锁来控制业务系统的锁逻辑 另外，查询操作还能加互斥锁，它的方法时：SELECT * FROM table FOR UPDATE。这个意思是，我查出来数据以后还要更新，此时我加独占锁，其它闲杂人等，都不要更新这个数据了。一旦你查询的时候加了独占锁，此时在你事务提交之前，任何人都不能更新数据了，只能你在本事务里更新数据，等你提交了，别人再更新数据 表锁上面已经讲解了数据库里的行锁的概念。在多个事务并发更新数据的时候，都是要在行级别加独占锁的，这就是行锁。独占锁都是互斥的，所以不可能发生脏写问题，一个事务提交了才会释放掉自己的独占锁，唤醒下一个事务执行。 如果你此时去读取别的事务在更新的数据，有两种可能： 第一种可能是基于 MVCC 机制进行事务隔离，读取快照版本，这是比较常见的 第二种可能是查询的同时基于特殊语法去加独占锁或者共享锁 如果你查询的时候加独占锁，那么跟其他更新数据的事务加的独占锁都是互斥的；如果你查询的时候加共享锁，那么跟其它查询加的共享锁是不互斥的。 当然，一般不是太建议在数据库粒度去通过行锁实现复杂的业务锁机制，而更加建议通过 Redis、ZooKeeper 来用分布式锁实现复杂业务下的锁机制。因为如果你把分布式业务里的复杂业务的一些锁机制依托数据查询的时候，在 SQL 语句里加共享锁或者独占锁，会导致这个加锁逻辑隐藏在 SQL 语句里，在你的 Java 业务系统层面其实是非常不好维护的。 比较正常的情况下，其实还是多个事务并发运行更新一条数据，默认加独占锁，同时其它事务读取基于 MVCC 机制进行快照版本读，实现事务隔离。 接着我们讲一个新的概念，就是表级锁。 在数据库里，你不光可以通过查询中的特殊语法加行锁，例如 lock in share mode、for update 等等，还可以通过一些方法在表级别去加锁 有人可能会以为当你执行增删改的时候默认加行锁，然后执行 DDL 语句的时候，比如 alter table 之类的语句，会默认在表级别加表锁。这么说也不太正确，但是也有一定的道理，因为确实你执行 DDL 的时候，会阻塞所有增删改操作，执行增删改的时候，会阻塞 DDL 操作。 但这是通过 MySQL 通用的元数据锁实现的，也就是 Metadata Locks，但这还不是表锁的概念，因为表锁其实是 InnoDB 存储引擎的概念，InnoDB 存储引擎提供了自己的表级锁，跟这里 DDL 语句用的元数据锁还不是一个概念 只不过 DDL 语句和增删改操作，确实是互斥的，大家要知道这一点 表锁和行锁互相之间的关系那么 MySQL 里是如何加表锁的？这个 MySQL 的表锁，其实是一个极为鸡肋的东西，几乎很少会用到。表锁分为两种，一种就是表锁，一种就是表级的意向锁。 首先说表锁，这个表锁，可以用如下语法来加： 12LOCK TABLES xxx READ // 这是加表级共享锁LOCK TABLES xxx WRITE // 这是加表级独占锁 其实，几乎没人会用着两个语法去加表锁，这不是纯属没事找事么，所以才说表锁特别的鸡肋。 还有就是有另外两个情况会加表级锁。如果有事务在表里执行增删改操作，那在行级会加独占锁，此时其实同时会在表级加一个意向独占锁；如果有事务在表里执行查询操作，那么会在表级加一个意向共享锁 其实平时我们操作数据库，比较常见的两种表锁，反而是更新和查询操作假的意向独占锁和意向共享锁，但是这个意向独占锁和意向共享锁，大家暂时可以当它是透明的，因为两种意向锁根本不会互斥 为啥呢？假设有一个事务要在表里更新 id = 10 的一行数据，在表上加了一个意向独占锁，此时另一个事务要在表里更新 id = 20 的一行数据，也会在表上加一个意向独占锁，你觉得这两把锁应该互斥吗？明显不应该，因为它俩更新的都是表里不同的数据，你让它俩在表上加的意向独占锁互斥干什么呢？所以意向锁之间是不会互斥的 同理，假设一个事务要更新表里的数据，在表级加了一个意向独占锁，另外一个事务要在表里读取数据，在表级加了一个意向共享锁，此时表级的意向独占锁和意向共享锁应该互斥吗？当然也不应该，一个要更新数据，一个要读取数据，两人在表上加的意向锁，为什么要互斥？ 所以，这个所谓的表级的意向独占锁和意向共享锁，有点多此一举了。 但是！！！手动加表级共享锁和独占锁，以及更新和查询的时候自动在表级加的意向共享锁和意向独占锁，它们之间反而是有一定的互斥关系，关系如下所示： 锁类型 独占锁 意向独占锁 共享锁 意向共享锁 独占锁 互斥 互斥 互斥 互斥 意向独占锁 互斥 不互斥 互斥 不互斥 共享锁 互斥 互斥 不互斥 不互斥 意向共享锁 互斥 不互斥 不互斥 不互斥 仔细看上面的表，上面说的是在表上面手动加的独占锁和共享锁，以及更新数据和查询数据默认自动加的意向独占锁和意向共享锁，它们互相之间的互斥关系，一看就明白 其实更新数据自动加的表级意向独占锁，会跟你用 LOCK TABLES xxx WRITE 手动加的表级独占锁是互斥的，所以，假设你手动加了表级独占锁，此时任何人都不能执行更新操作了 或者你用 LOCK TABLES xxx READ 手动加了表级共享锁，此时任何人也不能执行更新操作了，因为更新就要加意向独占锁，此时跟你手动加的表级共享锁，是互斥的 但是说实话，这也就是跟你讲明白这个表级锁如何加的，如何互斥的，但就一般而言，根本不会手动加表级锁，所以一般来说读写操作自动加的表级意向锁，互相之间绝对不会互斥 一般来说，但是对同一行数据的更新操作的行级独占锁是互斥的，跟读操作都是不互斥的，读操作默认都是走 MVCC 机制读快照版本的]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解 MVCC -- 多版本并发控制Ⅱ]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F24%2F%E8%AF%A6%E8%A7%A3-MVCC-%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6-%E2%85%A1%2F</url>
    <content type="text"><![CDATA[Read Committed（读已提交）隔离级别现在我们讲讲基于 ReadView 机制是如何实现 Read Committed 隔离级别的。所谓的Read Committed 隔离级别，简称为 RC，是说你事务运行期间，只要别的事务修改数据还提交了，你就是可以读到人家修改的数据的，所以是会发生不可重复读的问题，包括幻读的问题，都会有的。 而 ReadView 机制，它是基于 undo log 版本链条实现的一套读视图机制，它是说你事务生成一个 ReadView，如果是你事务自己更新的数据，自己是可以读到的；或者是在你生成 ReadView 之前提交的事务修改的值，也是可以读取到的。 但是如果是你生成 ReadView 的时候就已经活跃的事务，在你生成 ReadView 之后修改了数据，接着提交了，此时你是读不到的；或者是你生成 ReadView 以后再开启的事务修改了数据，还提交了，此时也是读不到的。 那么 ReadView 机制如何实现 RC 隔离级别呢？其实这里的一个非常核心的要点在于，当你一个事务设置他处于RC隔离级别的时候，他是每次发起查询，都重新生成 一个ReadView 举个例子，我们的数据库里有一行数据， 是事务 id = 50 的一个事务之前就插入进去的，然后活跃着两个事务，一个是事务 A （id = 60） ，一个是事务 B（id = 70） 现在事务 B 发起来一次 update 操作，把这条数据的值修改为了 B，所以此时数据的 trx_id 会变为事务 B 的 id= 70，同时会生成一条 undo log，由 roll_pointer 来指向： 此时，事务 A 要发起一次查询操作，此时它一发起查询操作，就会生成一个 ReadView，此时 ReadView 里的 min_trx_id = 60，max_trx_id = 71，creator_trx_id = 60 这个时候事务 A 发起查询，发现当前这条数据的 trx_id 是 70，即属于 ReadView 的事务 id 范围之间，说明是它生成 ReadView 之前就有这个活跃的事务，是这个事务修改了这条数据的值，但是此时事务 B 还没提交，所以 ReadView 的 m_ids 活跃事务列表里，是有 [60, 70] 两个 id 的，所以根据 ReadView 的机制，此时事务 A 是无法查到事务 B 修改的值 B 的。 接着就顺着 undo log 版本链条往下查找，就会找到一个原始值，发现它的 trx_id 是 50，小于当前 ReadView 里的 min_trx_id，说明是它生成 ReadView 之前，就有一个事务插入了这个值并且早就提交了，因此可以查到这个原始值。如下图： 接着，假设事务 B 此时就提交了，好，那么提交了就说明事务 B 不会活跃于数据库里了，是不是？大家要记住，事务 B 现在提交了，那么按照 RC 隔离级别的定义，事务 B 此时一旦提交，说明事务 A 下次再查询，就可以读到事务 B 修改过的值了，因为事务 B 提交了 那么怎么让事务 A 能够读到提交的事务 B 修改过的值呢？其实就是让事务 A 下次发起查询，再次生成一个 ReadView。此时再次生成 ReadView，数据库内活跃的事务只有事务 A 了，因此 min_trx_id 是 60，max_trx_id 是 71，但是 m_ids 这个活跃事务列表里，只会有一个 60 了，事务 B 的事务 id = 70 不会出现在 m_ids 活跃事务列表里了，如图： 此时事务 A 再次基于这个 ReadView 去查询，会发现这条数据的 trx_id = 70，虽然在 ReadView 的 min_trx_id 和 max_trx_id 范围之间，但是此时并不在 m_ids 列表内，说明事务 B 在生成本次 ReadView 之前就已经提交了。那么既然在生成本次 ReadView 之前，事务 B 就已经提交了，就说明这次你查询就可以查到事务 B 修改过的这个值了，此时事务 A 就会查到值 B 现在，RC 隔离级别如何实现的，现在应该清楚了，它的关键点在于每次查询都生成新的 ReadView，那么如果在你这次查询之前，有事务修改了数据还提交了，你这次查询生成的 ReadView 里，那个 m_ids 列表当然不包含这个已经提交的事务了。既然不包含已经提交的事务了，那么当然可以读到人家修改过的值了 实际上，基于 undo log 多版本链条以及 ReadView 机制实现的多事务并发执行的 RC 隔离级别、RR（可重复读）隔离级别，就是数据库的 MVCC 多版本并发控制机制。 Read Repeatable（可重复读）隔离级别现在我们讲讲 MySQL 中的 RR（Read Repeatable 可重复读）隔离级别，是如何同时避免不可重复读问题和幻读问题的。 在 MySQL 中让多个事务并发执行的时候能够相互隔离，避免同时读写一条数据的时候有影响，是依托 undo log 版本链条和 ReadView 机制来实现的。而 RR 级别，就是你这个事务读一条数据，无论读多少次，都是一个值，别的事务修改数据之后哪怕提交了，你也是看不到人家修改的值的，这就避免了不可重复读的问题。 同时如果别的事务插入了一些新的数据，你也是读不到的，这样你就可以避免幻读问题。 那么如何实现？举个例子，假设有一条数据是事务 id = 50 的一个事务插入的，同时此时有事务 A 和事务 B 同时在运行，事务 A 的 id 是 60， 事务 B 的 id 是70 这个时候，事务 A 发起了一个查询，它就是第一次查询会生成一个 ReadView，此时 ReadView 里的 creator_trx_id 是 60，min_trx_id 是 60， max_trx_id 是 71， m_ids 是 [60, 70]。如图： 这是时候事务 A 基于这个 ReadView 去查这条数据，会发现这条数据的 trx_id 为 50，是小于 ReadView 里的 min_trx_id 的，说明它发起查询之前，早就有事务插入这条数据还提交了，所以此时可以查到这条原始数据的。如图： 接着事务 B 此时更新了这条数据的值为值 B，此时会修改 trx_id 为 70，同时生成一个 undo log，而且关键是事务 B 此时还提交了，也就是说此时事务 B 已经结束了 此时，ReadView 中的 m_ids 此时还会是 60 和 70 吗？那必然是的，因为 ReadView 一旦生成了就不会改变了，这个时候事务 B 虽然已经结束了，但是事务 A 的 ReadView 里，还是会有 60 和 70 两个事务 id。它的意思是，在你事务 A 开启查询的时候，事务 B 当时是在运行的 接着此时事务 A 去查询这条数据的值，它会发现此时数据的 trx_id 是 70 了，70 一方面是在 ReadView 的 min_trx_id 和 max_trx_id 的范围区间的，同时还在 m_ids 列表中。这说明是事务 A 开启查询的时候，id 为 70 的这个事务还是在运行的，然后又这个事务 B 更新了这条数据，所以此时事务 A 是不能查询到事务 B 更新的这个值的，因此这个时候继续顺着指针往历史版本链条上去找。 接着事务 A 顺着指针找到下面一条数据，trx_id 为 50，是小于 ReadView 的 min_trx_id，说明在它开启查询之前，就已经提交了这个事务了，所以事务 A 是可以查询到这个值的，此时事务 A 查询到的是原始值。 这样是不是就避免了不可重复读的问题？事务 A 多次读同一个数据，每次读到的都是一样的值，除非是它自己修改了值，否则读到的一直会一样的值。不管别的事务如何修改数据，事务 A 的 ReadView 始终是不变的，它基于这个 ReadView 始终看到的值是一样的 接着我们看幻读是怎么解决的。假设事务 A 先用 SELECT * FROM x WHERE id &gt; 10 来查询，此时可能查到的就是一条数据，而且读到的是这条数据的原始值的那个版本。 现在有一个事务 C 插入了一条数据，然后提交了 接着此时事务 A 再次查询，此时会发现符合条件的有 2 条数据，一条是原始值数据，一条是事务 C 插入的那条数据，但是事务 C 插入的那条数据是 trx_id 是 80，这个 80 是大于自己的 ReadView 的 max_trx_id 的，说明是自己发起查询之后，这个事务才启动的，所以这条数据是不能查询的 因此事务 A 本次查询，还是只能查到原始值一条数据，如图： 所以，事务 A 根本不会发生幻读，它根据条件范围查询的时候，每次读到的数据都是一样的，不会读到人家插入进去的数据，这都是依托 ReadView 机制实现的。 总结我们简单梳理一下 MySQL 中的多事务并发运行的隔离原理，这套隔离原理，说白了就是 MVCC 机制，也就是 multi-version concurrent control，就是多版本并发控制机制 首先，多个事务并发运行的时候，同时读写一个数据，可能会出现脏写、脏读、不可重复读、幻读几个问题。 所谓脏写，就是两个事务都更新一个数据，结果有一个人回滚了把另外一个人更新的数据也回滚没了；脏读，就是一个事务读到了另外一个还没提交的时候修改的数据，结果另外一个事务回滚了，下次读就读不到了；不可重复读，就是多次读同一条数据，别的事务修改数据值还提交了，多次读到的值不同；幻读，就是范围查询，每次查询的的数据不同，有时候别的事务插入了新的值，就会读到的值不同 针对这些问题，所有才有了 RU（读未提交）、RC（读已提交）、RR（可重复读） 和串行四个隔离级别 RU 隔离级别，就是可以读到别人还没提交的事务修改过的数据，只能避免脏写问题；RC 隔离级别，可以读到人家提交的事务修改过的数据，可以避免脏写和脏读问题；RR 是不会读到别的事务已经提交事务修改的数据，可以避免脏读、脏写和不可重复读的问题；串行是让事务都串行执行，可以避免所有问题 然后 MySQL 实现 MVCC 机制的时候，是基于 undo log 多版本链条 + ReadView 机制来做的，默认的 RR 隔离级别，就是基于这套机制实现了 RR 级别，除了避免脏写、脏读、不可重复读，还能避免幻读问题。因此我们一般来说我们都用默认的 RR 隔离级别就可以了]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解 MVCC -- 多版本并发控制]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F23%2F%E8%AF%A6%E8%A7%A3-MVCC-%E5%A4%9A%E7%89%88%E6%9C%AC%E5%B9%B6%E5%8F%91%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[MySQL 默认的事务隔离级别是 RR（Read Repeatable 可重复读），即脏写、脏读、不可重复读、幻读都不会发生，这是怎么做到的？这就是由经典的 MVCC 多版本并发控制机制实现的。在讲解 MVCC 机制之前，我们得先讲讲 undo log 版本连。 理解 MVCC 机制的前奏：undo log 版本链简单来说，我们每条数据其实都有两个子段，一个是 trx_id，一个是 roll_pointer，这个 trx_id 就是最近一次更新这条数据的事务 id，roll_pointer 就是指向你更新这个事务之前生成的 undo log。 举个例子，假设有一个事务 A（id = 50），插入了一条数据，那么此时这条数据的隐藏字段以及指向的 undo log 如下图所示，插入的这条数据的值是值 A，因为事务 A 的 id 是 50，所以这条数据的 trx_id 就是 50，roll_pointer 指向一个空的 undo log，因为之前这条数据是没有的。 接着有一个事务 B 过来修改了这条数据，把值改成了值 B，事务 B 的 id 是 58，那么此时更新之前会生成一个 undo log 记录之前的值，然后会让 roll_pointer 指向这个实际的 undo log 回滚日志。如图： 如上图 ，事务 B 修改了值为值 B，此时表里的那行数据的值就是值 B 了，那行数据的 trx_id 就是事务 B 的 id，也就是 58，roll_pointer 指向了 undo log，这个 undo log 就记录你更新之前的那条数据的值。上面 roll_pointer 指向的那个 undo log，里面的值是值 A，trx_id 是 50，因为 undo log 里记录的这个值是事务 A 插入的，所以这个 undo log 的 trx_id 就是 50。 接着事务 C 又修改了这个值为值 C，它的事务 id 是 69，此时会把数据行里的 trx_id 改成 69，然后生成一条 undo log，记录之前事务 B 修改的那个值。如下图： 上图可以看到，数据行里的数据变成了值 C，trx_id 是事务 C 的 id，即 69，然后 roll_pointer 指向了本次修改之前生成的 undo log，也就是记录了事务 B 修改的那个值，包括事务 B 的 id，同时事务 B 修改的那个 undo log 还串联了最早事务 A 插入的那个 undo log。 总起起来，就是多个事务串行执行的时候，每个人修改了一行数据，都会更新隐藏字段 trx_id 和 roll_pointer，同时之前多个数据快照对应的 undo log，会通过 roll_pointer 指针串联起来，形成一个重要的版本链 基于 undo log 多本版链实现的 ReadView 机制上面说了 undo log 多版本链，现在我们说一下这个基于 undo log 多版本链条实现的 ReadView 机制。 这个 ReadView，简单来说就是你执行一个事务的时候，就给你生成一个 ReadView，里面比较关键的东西有 4 个： 一个是 m_ids，这个就是说此时有哪些事务在 MySQL 里执行还没提交的 一个是 min_trx_id，就是 m_ids 里面最小的值 一个是 max_trx_id，就是说 MySQL 下一个要生成的事务 id，就是最大事务 id 一个是 creator_trx_id，就是你这个事务的 id 我们举个例子，让大家来理解这个 ReadView 是怎么用的。假设原来数据库里就有一行数据，很早以前就有事务插入过了，事务 id 是 32，它的值是初始值。接着，此时两个事务并发过来执行了，一个是事务 A（id = 45），一个是事务 B（id = 59），事务 B 是要去更新这样数据的，事务 A 是要读取这行数据的值的，如下图所示： 现在事务 A 直接开启一个 ReadView，这个 ReadView 里的 m_ids 就包含了事务 A 和 事务 B 的两个 id，45 和 59，然后 min_trx_id 就是 45，max_trx_id 就是 60，creator_trx_id 就是 45，是事务 A 自己。 这个时候事务 A 第一次查询这行数据，会走一个判断，就是判断当前这行数据的 trx_id是否小于 ReadView 中的 min_trx_id，此时发现 trx_id = 32，是小于 ReadView 里的 min_trx_id 的，说明你开启事务之前，修改这样数据的事务早就提交了，所以此时你可以查到这行数据。 接着事务 B 开始动手了，它把这行数据的值修改为了值 B，然后这行数据的 trx_id 设置为自己的 id，同时 roll_pointer 指向了修改之前生成的一个 undo log，接着这个事务 B 就提交了，如下图： 这个时候事务 A 再次查询，此时查询的时候，会发现一个问题，那就是此时数据行里的 trx_id = 59，这个 trx_id 是大于 ReadView 里的 min_trx_id（45），同时小于 ReadView 里的 max_trx_id（60）的，说明更新这条数据的事务，很可能就跟自己差不多同时开启的，于是会看一下这个 trx_id = 59，是否在 ReadView 的 m_ids 列表里？ 果然，在 ReadView 的 m_ids 列表里，有 45 和 59 两个事务 id，直接证实了，这个修改数据的事务是跟自己同一时段并发执行然后提交的，所以这样数据是不能查询的。如下图所示： 那这行数据不能查，查什么呢？简单，顺着这条数据的 roll_pointer 顺着 undo log 日志链条往下找，就会扎到最新的一条 undo log，trx_id 是 32，此时发现 trx_id = 32，是小于 ReadView 里的 min_trx_id（45）的，说明这个 undo log 版本必然是在事务 A 开启之前就执行且提交的。 好，那么久查询最近的那个 undo log 里的值好了。这就是 undo log 多版本链条的作用，它可以保存一个快照链条，让你可以读到之前的快照值。 看到这里，大家有没有发现，多个事务并发执行的时候，通过这条 ReadView + undo log 日志链条的机制，就可以保证事务 A 不会读到并发执行的事务 B 更新的值，只会读到更早的值。 接着事务 A 自己更新了这行数据，改成了值 A，trx_id 修改为 45，同时保存之前事务 B 修改的值的快照，如下图： 此时事务 A 来查询这条数据，会发现这个 trx_id = 45，跟自己的 ReadView 里的 creator_trx_id（45）是一样的，说明这行数据就是自己修改的，自己修改的值当然是可以看到的。 接着在事务 A 执行的过程中，突然开启了一个事务 C，这是事务的 id 是 78，然后它更新了那行数据的值为值 C，还提交了事务，如下图： 这个时候事务 A 再去查询，会发现当前数据的 trx_id = 78，大于自己的 ReadView 中的 max_trx_id（60），说明这个事务 A 开启之后，然后有一个事务更新了数据，自己当然是不能看到的。如图： 此时就会顺着 undo log 多版本链条往下找，自然先找到值 A 自己之前修改过的那个版本，因为那个 trx_id = 45 跟自己的 ReadView 里的 creator_trx_id 是一样的，所以此时直接读取自己之前修改的那个版本，如图： 通过这一系列的图，相信每个人都能彻底理解 ReadView 的一套运行机制了。通过 undo log 多版本链条，加上你开启事务时候生产的一个 ReadView，然后再有一个查询的时候，根据 ReadView 进行判断的机制，你就知道你应该读取哪个版本的数据 而且它可以保证你只能读到你事务开启前，别的提交事务更新的值，还有就是你自己事务更新的值。假如说是你事务开启之前，还有别的事务正在运行，然后你事务开启之后，别的事务更新了值，你是绝对读不到的。或者是你事务开启之后，比你晚开启的事务更新了值，你也是读不到的。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[适配器模式]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F22%2F%E9%80%82%E9%85%8D%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[有的笔记本电脑的工作电压是 20V，而我国的家庭用电是 220V，如何让 20V 的笔记本电脑能够在 220V 的电压下工作？答案是引入一个电源适配器（AC Adapter），俗称充电器或者变压器。有了这个电源适配器，生活用电和笔记本电脑即可兼容。 在软件开发中，有时也存在这种不兼容的情况，也可以像引入一个电源适配器一样引入一个称之为适配器的角色来协调这些不兼容的结构，这种设计方案即为适配器模式。 示例 Sunny 公司在很久以前曾开发了一个算法库，里面包含了一些常用的算法。例如排序算法和查找算法，在进行各类软件开发是经常需要重用该算法。在为某学校开发教务管理系统时，开发人员发现需要对学生进行排序和查找。该系统的设计人员已经开发了一个成绩操作接口 ScoreOperation，在该接口中声明了排序方法 sort(int[]) 和查找方法 search(int[], int)。为了提高排序和查找的效率，开发人员决定重用算法库中的快速排序算法类 QuickSort 和二分查找类 BinarySearch。其中 QuickSort 的 quickSort(int[]) 方法实现了快速排序，BinarySearch 的 binarySearch(int[], int) 方法实现了二分查找 由于某些原因，现在 Sunny 公司开发人员已经找不到该算法库的源代码，无法直接通过复制和粘贴操作来重用其中的代码，部分开发人员已经针对 ScoreOperation 接口编程，如果再要求对该接口进行修改或要求大家直接使用 QuickSort 类和 BinarySearch 类将导致大量代码需要修改 Sunny 公司面对这个没有源码的算法库，遇到一个幸福而又烦恼的问题：如何在既不修改现有接口有不需要任何算法库代码的基础上实现算法库的重用？ 通过分析，现在 Sunny 公司面对的问题有点类似最开始提到的电压问题，成绩操作接口 ScoreOperation 好比只支持 20V 电压的笔记本电脑，而算法库好比 220V 的家庭用电，这两部分都没有办法再进行修改，而且他们原本是两个完全不相关的结构。而这种情况就非常适合适配者模式去解决。 适配器模式概述与电源适配器相似，在适配器模式中引入了一个被称为适配器（Adapter）的包装类，而它所包装的对象称之为适配者（Adaptee），即被适配的类。适配器的实现就是把客户类的请求转化为对适配者的相应接口的调用，即，当客户类调用适配器的方法时，在适配器类的内部将调用适配者类的方法，而这个过程对客户类是透明的，客户类并不直接访问适配者类。因此，适配器让那些由于接口不兼容而不能相互交互的类可以一起工作。 适配器模式可以将一个类的接口和另一个类的接口匹配起来，而无须修改原来的适配者接口或者抽象目标类接口。适配器模式定义如下： 适配器模式：将一个接口转换成客户希望的另一个接口，使接口不兼容的那些类可以一起工作，其别名为包装器（Wrapper）。适配器模式既可以作为类结构模式，也可以作为对象结构型模式。 在适配器模式中，通过增加一个新的适配器类来解决接口不兼容的问题，使得原本没有任何关系的类可以协同工作。根据适配器类与适配者类的关系不同，适配器模式可以分为对象适配器模式和类适配器模式两种。在对象适配器模式中，适配器与适配者之间是关联关系；在类适配器模式中，适配器与适配者之间是继承（或实现）关系。在实际开发中，对象适配器模式的使用频率更高，如图： 上图可以看出，在对象适配器模式结构图中包含以下 3 个角色： Target（目标抽象类）：目标抽象类定义客户所需接口，可以是一个抽象类或者接口，也可以是具体类。 Adapter（适配器类）：适配器可以调用另一个接口，作为一个转换器，对 Adaptee 和 Target 进行适配。适配器类是适配器模式的核心，在对象适配器模式中，它通过继承 Target 并关联一个 Adaptee 对象使二者产生联系 Adaptee（适配者类）：适配者即被适配的角色，它定义了一个已经存在的接口，这个接口需要适配，适配者类一般是一个具体类，包含了客户希望使用的业务方法，在某些情况下可能没有适配者类的源代码 在上图中，客户端需要使用 request() 方法，而适配者类 Adaptee 没有该方法，但是它所提供的 specificRequest() 方法却是客户端所需要的。为了使客户端能够使用适配者类，需要提供一个包装类 Adapter，即适配器，这个包装类包装了一个适配者的实例，从而将客户端与适配者衔接起来，在适配器的 request() 方法中调用适配者的 specificRequest() 方法。因为适配器类与适配者类是关联关系（也可称之为委派关系），所以这种适配器模式称为对象适配器模式。伪代码如下： 123456789101112class Adapter extends Target &#123; // 维持一个对适配者对象的引用 private Adaptee adaptee; public Adapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; public void request() &#123; adaptee.specificRequest(); &#125;&#125; 示例解决方案Sunny 公司开发人员决定使用适配器模式来重用算法库中的算法，其基本结构如下： 代码如下： 123456789101112131415161718192021/** * @Description: 抽象成绩操作类：目标接口 * */public interface ScoreOperation &#123; /** * 成绩排序 * @param array * @return */ int[] sort(int[] array); /** * 成绩查找 * @param array * @param key * @return */ int search(int[] array, int key);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041/** * @Description: 快速排序类：适配者 * */public class QuickSort &#123; public int[] quickSort(int[] array) &#123; sort(array, 0, array.length - 1); return array; &#125; public void sort(int[] array, int p, int r) &#123; int q = 0; if(p &lt; r) &#123; q = partition(array, p, r); sort(array, p, q - 1); sort(array, q + 1, r); &#125; &#125; public int partition(int[] a, int p, int r) &#123; int x = a[r]; int j = p - 1; for(int i = p; i &lt;= r - 1; i++) &#123; if(a[i] &lt;= x) &#123; j++; swap(a, j, i); &#125; &#125; swap(a, j + 1, r); return j +1; &#125; public void swap(int[] a, int i, int j) &#123; int t = a[i]; a[i] = a[j]; a[j] = t; &#125;&#125; 12345678910111213141516171819202122232425/** * @Description: 二分查找类：适配者 * */public class BinarySearch &#123; public int binarySearch(int[] array, int key) &#123; int low = 0; int high = array.length - 1; while(low &lt;= high) &#123; int mid = ((high - low) &gt;&gt; 1) + low; int midVal = array[mid]; if(midVal &lt; key) &#123; low = mid + 1; &#125;else if(midVal &gt; 1) &#123; high = mid - 1; &#125;else&#123; return 1; &#125; &#125; return -1; &#125;&#125; 123456789101112131415161718192021222324252627282930/** * @Description: 操作适配器：适配器 * */public class OperationAdapter implements ScoreOperation &#123; /** * 定义适配者 QuickSort 对象 */ private QuickSort sortObj; /** * 定义适配者 BinarySearch 对象 */ private BinarySearch searchObj; public OperationAdapter() &#123; sortObj = new QuickSort(); searchObj = new BinarySearch(); &#125; @Override public int[] sort(int[] array) &#123; return sortObj.quickSort(array); &#125; @Override public int search(int[] array, int key) &#123; return searchObj.binarySearch(array, key); &#125;&#125; 类适配器模式除了对象适配器模式之外，适配器还有一种模式，那就是类适配器模式。类适配器模式与对象适配器模式最大的区别在于其适配器和适配者之间的关系是继承关系。如图： 如上图所示，适配器类实现了抽象目标类接口 Target，并继承了适配者类，在适配器类的 request() 方法中调用所继承的适配者类的 specificRequest() 方法，实现了适配。典型的类适配器代码如下： 1234567class Adapter extends Adaptee implements Target &#123; public void request() &#123; specificRequest(); &#125;&#125; 由于 Java、C# 等语言不支持多重类继承，因此类适配器模式的使用受到很多限制，例如，如果目标抽象类 Target 不是借口，而是一个类，就无法使用类适配器模式；此外，如果适配者 Adaptee 为最终（final）类，也无法使用类适配器模式。在 Java 等面向对象编程语言中，大部分情况下使用的是对象适配器模式，类适配器模式较少使用 双向适配器模式在对象适配器模式的使用过程中，如果在适配中同时包含对目标类和适配者类的引用，适配者可以通过它调用目标类中的方法，那么该适配器就是一个双向适配器，如下图： 双向适配器的实现较为复杂，典型代码如下： 12345678910111213141516171819202122class Adapter implements Target, Adaptee &#123; // 同时维持对抽象目标类和适配者的引用 private Target target; private Adaptee adaptee; public Adapter(Target target) &#123; this.target = target; &#125; public Adapter(Adaptee adaptee) &#123; this.adaptee = adaptee; &#125; public void request() &#123; adaptee.specificRequest(); &#125; public void specificRequest() &#123; target.request(); &#125;&#125; 缺省适配器模式缺省适配器模式是适配器模式的一种变体，其应用也较为广泛。缺省适配器模式的定义如下： 缺省适配器模式：当不需要实现一个接口所提供的所有方式时，可以先设计一个抽象类实现该接口，并为接口中每个方法提供一个默认实现（空方法），那么该抽象类的子类可以选择性地覆盖父类的某些方法来实现需求，它适用于不想使用一个接口中的所有方法的情况，又称为单接口适配器模式 它的结构图如图所示： 在缺省适配器模式结构图中，包含 3 个角色： ServiceInterface（适配者接口）：它是一个接口，通常在该接口中声明了大量的方法 AbstractServiceClass（缺省适配器类）：它是缺省适配器模式的核心类，使用空方法的形式实现了在 ServiceInterface 接口中声明的方法。通常将它定义为抽象类，因为对它进行实例化没有任何意义 ConcreteServiceClass（具体业务类）：它是缺省适配器类的子类，在没有引入适配器之前，它需要实现适配者接口，因此需要实现在适配者接口中定义的所有方法，而对于一些无法使用的方法也不得不提供空实现。在有了缺省适配器模式之后，可以直接继承该适配器，根据需要有选择性地覆盖在适配器类中定义的方法 在JDK类库的事件处理包 java.awt.event 中广泛使用了缺省适配器模式，例如 WindowAdapter、KeyAdapter、MouseAdapter等。下面以处理窗口事件为例来进行说明。在 Java 语言中，一般可以使用两种方式来实现窗口事件处理类，一种是通过实现 WindowListener 接口，另一种是通过继承 WindowAdapter 适配器类。如果是使用第一种方式，直接实现 WindowListener 接口，事件处理类需要实现在该接口中定义的 7 个方法，而对于大部分需求可能只需要实现一两个方法，其他方法都无须实现。但由于语言特性，设计人员不得不为其他方法也提供-一个简单的实现（通常是空实现），这给使用带来了麻烦。而使用缺省适配器模式就可以很好地解决这一问题，在 JDK 中提供了一个适配器类 WindowAdapter 来实现 WindowListener 接口，该适配器类为接口中的每一个方法都提供了一个空实现，此时事件处理类可以继承 WindowAdapter 类，而无须再为接口中的每个方法都提供实现。 适配器模式总结适配器模式将现有接口转化为客户类所期望的接口，实现了对现有类的复用。它是一种使用频率非常高的设计模式，在软件开发中得以广泛应用，在 Spring 等开源框架、驱动程序设计（例如 JDBC 中的数据库驱动程序）中也使用了适配器模式 主要优点无论是对象适配器模式还是类适配器模式，都有以下优点： 将目标类和适配者类解耦，通过引入一个适配器类来重用现有适配者类，无须修改原有结构 增加了类的透明性和复用性，将具体的业务实现过程封装在适配者类中，对于客户端类而言是透明的，而且提高了适配者类的复用性，同一个适配者类可以在多个不同的系统中复用 灵活性和扩展性都非常好，通过使用配置文件，可以很方便地更换适配器，也可以在不修改原有代码的基础上增加新的适配器，符合开闭原则 具体来说，类适配器模式还有这样的优点：由于适配器类是适配者类的子类，因此可以在适配器类中置换一些适配者的方法，是的适配器的灵活性更强。 对象适配器模式还有如下优点： 一个对象适配器可以把多个不同的适配者适配到同一个目标 可以适配一个适配者的子类，由于适配器和适配者之间是关联关系，根据里氏代换原则，适配者的子类也可以通过该适配器进行适配 主要缺点类适配器模式的缺点如下： 对于 Java、C# 等不支持多重类继承的语言，一次最多只能适配一个适配者类，不能同时适配多个适配者 适配者不能为最终类，例如 Java 中不能为 final 类，C# 中不能为 sealed 类 在 Java、C# 等语言中，类适配器模式中的目标对象类只能为接口，不能为类，其使用具有一定的局限性 对象适配器模式的缺点是：与类适配器相比，要在适配器中置换适配者类的某些方法有些麻烦。如果一定要置换掉适配者类的一个或多个方法，可以先做一个适配者类的子类，在子类中将适配者类的方法置换掉，然后再把适配者类的子类当做真正的适配者进行适配，实现过程较为复杂 参考资料《设计模式的艺术——软件开发人员内功修炼之道》 – 刘伟]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 多事务运行场景]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F22%2FMySQL-%E5%A4%9A%E4%BA%8B%E5%8A%A1%E8%BF%90%E8%A1%8C%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[平时我们执行增删改的时候，无非就是从磁盘加载数据到 buffer pool 的缓存页里去，对缓存页进行更新，同时记录下来 undo log 回滚日志和 redo log 重做日志，应对的是事务提交之后 MySQL 挂了恢复数据的场景，以及事务回滚的场景 接下来我们就要理解到「事务」这个层面了。平时我们一般都是写一个业务系统，然后业务系统对去对数据库执行增删改查，然后通常而言，我们都是在业务系统里开启事务来执行增删改操作的，如下： 123456789101112@Transactionalpublic void doService() &#123; // 增加一条数据 addUser(); // 修改一条数据 updateUser(); // 删除一条数据 deleteUser();&#125; 所以一般来说，业务系统是执行一个一个的事务，每个事务里可能是一个或者多个增删改查的 SQL 语句。这个事务的概念就不用多说了，其实就是一个事务里的 SQL 要么一起成功就提交了，要不然有一个 SQL 失败，那么事务就回滚了，所有 SQL 做的修改都撤销了。 接着问题来了，这个业务系统不是一个单线程系统，他是有很多线程的，因为它面向的终端用户是有很多人的，可能会同时发起多个请求，所以它需要多个线程并发来处理多个请求的。于是，这个系统和可能是基于多线程并发地对 MySQL 数据库去执行多个事务的。如图： 那么每个事务里面的多个 SQL 语句是如何执行的？其实就是我们之前给大家讲的那一套原理了，包括从磁盘加载数据到 buffer pool 的缓存页里去，然后更新 buffer pool 里的缓存页，同时记录 redo log 和 undo log，如图： 每个事务如果提交了，那就皆大欢喜。如果事务提交之后，redo log 刷入磁盘，结果 MySQL 宕机了，是可以根据 redo log 恢复事务修改过的缓存数据的。如果要回滚事务，那么就基于 undo log 来回滚就可以了，把之前对缓存页做的修改都给回滚了就可以了。 这就是 MySQL 内核层面，把多个事务和我们讲解的 buffer pool、redo log、undo log 几个机制都结合在一起的一个场景讲解。 但是这里就有很多问题了： 多个事务并发执行的时候，可能会同时对缓存页里的一行数据进行更新，这个冲突怎么处理？是否要加锁？ 可能有的事务在一行数据做更新，有的事务在查询这行数据，这里的冲突怎么处理 脏写和脏读上面说到，对于我们的业务系统去访问数据库而言，它往往是多个线程并发执行多个事务的，对于数据库而言，它会有多个事务同时执行，可能这多个事务还会同时更新和查询同一条数据，所以这里会有一些问题需要数据库来解决 我们来看看，如果多个事务要是对缓存里的同一条数据同时进行更新或者查询，此时会产生哪些问题呢？这里实际上会涉及到脏写、脏读、不可重复读、幻读四种问题。 脏写脏写，意思是说有两个事务，事务 A 和事务 B 同时在更新一条数据，事务 A 先把它更新为 A 值，事务 B 紧接着就把它更新为 B 值。如图： 可以看到，此时事务 B 是后更新那行数据的值，所以此时那行数据的值是 B。而且此时事务 A 更新之后会记录一条 undo log 日志。因为事务 A 是先更新的，它在更新之前，这行数据的值为 NULL。所以此时事务 A 的 undo log 日志大概就是：更新之前这行数据的值为 NULL，主键为 XX 那么此时事务 B 更新完数据的值为 B，此时事务 A 突然回滚了，就会用它的 undo log 日志去回滚。此时事务 A 一回滚，直接就会把那行数据的值更新回 NULL 值。如图： 然后就尴尬了，事务 B 一看，为什么我更新的 B 值没了？就因为你事务 A 反悔了把数据值回滚成 NULL 了，结果我更新的 B 值也不见 了。所以对于事务 B 看到的场景而言，就是自己明明更新了，结果值却没了，这就是脏写。 所谓脏写，就是我刚才明明写了一个数据值，结果过了一会却没了。而它的本质就是事务 B 去修改了事务 A 修改过的值，但是此时事务 A 还没提交，所以事务 A 随时会回滚，导致事务 B 修改的值也没了，这就是脏写的定义。 脏读假设事务 A 更新了一行数据的值为 A 值，此时事务 B 去查询了一下这行数据的值，看到的值是 A 值，如图： 接着，事务 B 拿着刚才查询到的 A 值做各种业务处理。但是接着坑爹的事情发生了，事务 A 突然回滚了事务，导致它刚才功能的 A 值没了，此时那行数据的值回滚为 NULL 值。然后事务 B 紧接着此时再次查询那行数据的值，看到的居然是 NULL 值。如图： 这就是脏读。它的本质是事务 B 去查询了事务 A 修改过的数据，但是此时事务 A 还没提交，所以事务 A 随时会回滚导致事务 B 再次查询就读不到刚才事务 A 修改的数据了，这就是脏读。 其实总结一句话，无论是脏写还是脏读，都是因为一个事务去更新或者查询了另外一个还没提交的事务更新过的数据。因为另外一个事务还没提交，所以它随时可能会回滚，那么必然导致你更新的数据就没了，或者你之前查询到的数据就没了，这就是脏写和脏读两种场景。 不可重复读假设我们有一个事务 A 开启了，在这个事务 A 里会多次对一条数据进行查询。然后呢，另外有两个事务，一个是事务 B，一个是事务 C，他们两都是对一条数据进行更新的。然后我们假设一个前提，就是比如说事务 B 更新之后，如果还没提交，那么事务 A 是读不到的，必须要事务 B 提交之后，它修改的值才能被事务 A 读取到，其实这种情况下，就是我们首先避免了脏读的发生 因为脏读的意思就是事务 A 可以读到事务 B 修改过还没提交的数据，此时事务 B 一旦回滚，事务 A 再次读就读不到了，那么此时就会发生脏读问题。我们现在假设的前提是事务 A 只能在事务 B 提交之后读取到它修改的数据，所以此时必然是不会发生脏读的 但是，此时会有另外一个问题，叫做不可重复读。假设缓存页里一条数据原来的值是 A 值，此时事务 A 开启之后，第一次查询这条数据，读取到的就是 A 值。如图： 接着事务 B 更新了那行数据的值为 B 值，同时事务 B 立马提交了，然后事务 A 此时还没提交。大家注意，此时事务 A 是没提交的，它在事务执行期间第二次查询数据，此时查到的是事务 B 修改过的值，B 值，因为事务 B 已经提交了，所以事务 A 是可以读到的，如图： 紧接着事务 C 再次更新数据为 C 值，并且提交事务了，此时事务 A 在还没提交的情况下，第三次查询数据，查到的值为 C 值，如下： 那么上面的场景有什么问题呢？其实要说没问题也可以是没问题的，毕竟事务 B 和 事务 C 都提交之后，事务 A 多次查询查到它们修改的值，是 OK 的。但是你要说有问题，也可以是有问题的，就是事务 A 可能第一次查询到 A 值，那么它可能希望的是在事务执行期间，如果多次查询数据，都是同样的一个 A 值，它希望这个 A 值是它重复读取的时候一直可以读到的。它希望这行数据的值是可重复读的 但是此时，明显 A 值是不可重复读的。因为事务 B 和事务 C 一旦更新值并且提交了，事务 A 会读到别的值，所以此时这行数据的值是不可重复读的。此时对于你来说，这个不可重复读的场景，就是一种问题 上面描述的，其实就是不可重复读的问题，其实这个问题你说是问题也不一定就是什么大问题。因为这取决于你自己想要数据库是什么样子的，如果你希望看到的场景是不可重复读，也就是事务 A 在执行期间多次查询一条数据，每次都可以查到其它已经提交的事务修改过的值，那么就是不可重复读，如果你希望这样子，那也没问题。 如果你期望的是可重复读，但是数据库表现的是不可重复读，让你事务 A 执行期间多次查到的值都不一样，都的问题是别的提交过的事务修改过的，那么此时你就可以认为，数据库有问题，这个问题就是「不可重复读」 幻读脏写、脏读和不可重复读都分别代表了不同的数据库问题。脏写就是两个事务没提交的状况下，都修改同一条数据，结果一个事务回滚了，把另外一个事务修改的值也撤销了，所谓脏写就是两个事务没提交状态下修改同一个值。 脏读就是一个事务修改了一条数据的值，结果还没提交呢，另外一个事务就读到了你修改的值，然后你回滚了，人家事务再次读，就读不到了，即人家事务读到了你修改之后还没提交的值，这就是脏读了。而不可重复读，针对的是已经提交的事务修改的值，被你事务给读到了，你事务内多次查询，多次读到的是别的已经提交的事务修改过的值，这就导致不可重复读。 接着我们说说幻读。简单来说，你一个事务 A，先发送一条 SQL 语句，里面有一个条件，要查询一批数据出来，如 SELECT * FROM table WHERE id &gt; 10。然后呢，它一开始查询出来了 10 条数据。接着这个时候，别的事务 B往表里插了几条数据，而且事务 B 还提交了，此时多了几行数据。如图： 接着事务 A 此时第二次查询，再次按照之前的一模一样的条件执行 SELECT * FROM table WHERE id &gt; 10 这条 SQL 语句，由于其他事务插入了几条数据，导致这次它查询出来了 12 条数据。如图： 于是事务 A 开始怀疑自己的眼镜了，为什么一模一样的 SQL 语句，第一次查询是 10 条数据，第二次查询是 12 条数据？难道刚才出现幻觉了？这就是「幻读」这个名词的由来 幻读就是你一个事务用一样的 SQL 多次查询，结果每次查询都会发现查到一些之前没看到过的数据。注意，幻读特指的是你查询到了之前查询没看到过的数据。此时说明你是幻读了 其实，脏写、脏读、不可重复读、幻读，都是因为业务系统会多线程并发执行，每个线程可能都会开启一个事务，每个事务都会执行增删改查操作。然后数据库会并发执行多个事务，多个事务可能会并发地对缓存页里的同一批数据进行增删改查操作，于是这个并发增删改查同一批数据的问题，可能就会导致我们说的脏写、脏读、不可重复读、幻读这些问题。 所以这些问题的本质，都是数据库的多事务并发问题，那么为了解决多事务并发问题，数据库才设计了事务隔离机制、MVCC 多版本隔离机制、锁机制，用一整套机制来解决多事务并发问题。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之 undo 日志]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F18%2FMySQL-%E4%B9%8B-undo-%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[之前我们已经讲了在执行增删改操作时候的 redo log 的重做日志原理，说白了就是你对 buffer pool 里的缓存页执行增删改操作的时候，必须要写对应的 redo log 记录下来你做了哪些修改。而 redo log 都是先进入 redo log buffer 中的一个 block，然后事务提交的时候就会刷入磁盘文件里去。这样万一你提交事务了，结果事务修改的缓存页还没来得及刷入磁盘上的数据文件，此时你 MySQL 关闭了或者是宕机了，那么 buffer pool 里被事务修改的数据就全部丢失了 但是只要有 redo log，你重启 MySQL 之后完全是可以把那些修改了缓存页，但是缓存页还没来得及刷入磁盘的事务，它们对应的 redo log 都加载出来，在 buffer pool 的缓存页里重做一遍，就可以保证事务提交之后，修改的数据绝对不会丢失。 接着我们来讲另外一种日志，就是 undo log 日志，即回滚日志。这种日志要应对的场景，就是事务回滚的场景。 假设现在我们一个事务里要执行一些增删改的操作，那么必然是先把对应的数据页从磁盘加载出来放 buffer pool 的缓存页里，然后在缓存页里执行一遍增删改，同时记录 redo log 日志。如下： 但是万一一个事务的一通增删改操作执行了一半，结果就回滚事务了呢？比如一个事务里有 4 个增删改操作，结果目前为止已经执行了 2 个增删改 SQL 了，已经更新了一些 buffer pool 里的数据了，但是还有 2 个增删改 SQL 的逻辑还没执行，此时事务回滚了，咋整？ 这个时候就很尴尬了，如果你要回滚事务的话，那么必须要把已经在 buffer pool 的缓存页里执行的增删改操作给回滚了。但是要怎么回滚呢？无论是插入、更新还是删除，该做的都已经做了。所以在执行的时候，必须引入另外一种日志，就是 undo log 回滚日志。 这个回滚日志，它记录的东西其实非常简单。比如你要是在缓存里执行了一个 insert 语句，那么此时你在 undo log 日志里，对这个操作记录的回滚日志就必须是有一个主键和一个对应的 delete 操作，要能让你把这次 insert 操作给回退了。 你要是执行的是 delete 语句，那么起码你要把你删除的那条数据记录下来，如果要回滚，就应该执行一个 insert 操作把那条数据插入回去；如果你执行的是 update 语句，那么起码你要把那个更新之前的那个值记录下来，回滚的时候重新 update 一下，把你之前更新前的旧值给他更新回去。如果执行的是 select 呢？select 语句根本没有在 buffer pool 里执行任何修改，所以根本不需要 undo log。 所以你除了写 redo log 日志还必须要写 undo log 日志，这个 undo log 日志是至关重要的，没有它你都没办法回滚日志。 undo 日志长什么样上面讲解了 undo log 回滚日志的作用，即，你执行事务的时候，里面有很多 INSERT、UPDATE 和 Delete 语句都在更新缓存页里的数据，但是万一事务回滚，你必须有每条 SQL 语句对应的 undo log 回滚日志，根据回滚日志去恢复缓存页里被更新的数据。 那么我们来看一下 INSERT 语句的 undo log 语句长什么样子。INSERT 语句的 undo log 的类型是 TRX_UNDO_INSERT_REC，这个 undo log 里包含了以下一些东西： 这条日志的开始位置 主键的各列长度和值 表 id undo log 日志编号 undo log 日志类型 这条日志的结束位置 接下来我们逐一解释以下。首先，一条日志必须要有自己的一个开始位置，这个没什么好说的。那么主键的各列长度和值是什么意思？其实，你插入一条数据，必然会有一个主键。如果你自己指定了一个主键，那么可能这个主键就是一个列，比如 id 之类的，也可能是多个列组成的一个主键，比如 id + name + type 三个字段组成的一个联合主键，也是有可能的 所以这个「主键的各列长度和值」，意思是你插入的这条数据的主键的每个列，它的长度是多少，具体的值是多少。即使你没有设置主键，MySQL 自己也会给你弄一个 row_id 作为隐藏字段，做你的主键 接着是「表 id」，这个也不用多说，你插入一条数据必然是往一个表里插入数据的，那当然得有一个表 id，记录下来是在哪个表里插入的数据了。 「undo log 日志编号」，这个是说每个 undo log 日志都是由自己的编号的。而在一个事务里会有多个 SQL 语句，就会有多个 undo log 日志，在每个事务里的 undo log 日志的编号都是从 0 开始的，然后依次递增 至于「undo log 日志类型」，就是 TRX_UNDO_INSERT_REC，insert 语句的 undo log 日志类型就是这个东西。 最后一个 undo log 日志的结束位置，这个就是告诉你 undo log 日志结束的位置是什么。 接着我们用一个图画一下这个 insert 语句的 undo log 回滚日志的结构，如图： 有了这条日志之后，剩下的事情就好办了。万一要是你现在在 buffer pool 的一个缓存页里插入了一条数据，执行了 insert 语句，然后写了一条上面的那种 undo log，现在事务要是回滚了，你直接就把这条 insert 语句的 undo log 拿出来。然后在 undo log 里就知道在哪个表里插入的数据，主键是什么，直接定位到那个表和主键对应的缓存页，从里面删掉之前 insert 语句插入进去的数据就可以了，这样就可以实现事务回滚的效果了。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之 redo log buffer]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F16%2FMySQL-%E4%B9%8B-redo-log-buffer%2F</url>
    <content type="text"><![CDATA[redo log buffer之前说了一下 redo log block 这个概念，现在都知道平时我们执行完增删改之后，要写入磁盘的 redo log，其实应该是先进入到 redo log block 这个数据结构里去的，然后再进入到磁盘文件里。 那么 redo log 是如何通过内存缓冲之后，再进入磁盘文件里去的？这就涉及到了一个新的组件，redo log buffer，它就是 MySQL 专门设计了用来缓冲 redo log 写入的。这个 redo log buffer 其实就是 MySQL 在启动的时候，就跟操作系统申请的一块连续内存空间，大概可以认为相当于是 buffer pool 吧。那个 buffer pool 是申请之后划分了 N 多个空的缓存页和一些链表结构，让你把磁盘上的数据页加载到内存里来的 redo log buffer 也是类似的，它是申请出来的一片连续内存，然后里面划分出了 N 个空的 redo log block。通过设置 MySQL 的 innodb_log_buffer_size 可以指定这个 redo log buffer 的大小，默认的值就是 16MB。其实已经够大了，毕竟一个 redo log block 才 512 字节而已，每条 redo log 其实也就几个字节到几十个字节罢了 所以到这里就清楚了，上面我们说过，redo log 都是先写入内存里的 redo log block 数据结构里去的，然后完事了才会把 redo log block 写入到磁盘文件里去。所以当你要写一条 redo log 的时候，就会从第一个 redo log block 开始写入，如图： 写满了一个 redo log block，就会继续写入下一个 redo log block，以此类推，直到所有的 redo log block 都写满。当 redo log buffer 里所有的 redo log block 都写满了，那么此时会强制把 redo log block 刷入到磁盘中去的。上面说过，其实就是把 512 字节的 redo log block 追加到 redo log 日志文件里去就可以了。如图： 另外需要知道的是，在我们平时执行一个事务的过程中，每个事务会有多个增删改操作，那么就会有多个 redo log，这多个 redo log 就是一组 redo log，其实每一次 redo log 都是先在别的地方暂存，然后都执行完了，再把一组 redo log 给写入到 redo log 的 block 里去的。如果一组 redo log 实在是太多了，那么可能会存放在两个 redo log block 中，如下图： 但是反之，如果一个 redo log group 比较小，那么也可能多个 redo log group 是在一个 redo log block 里的，如图： 那 redo log buffer 里的 redo log block 到底是如何写入到磁盘文件里去的？一定要等待 redo log block 全部写满才会刷入磁盘吗？还有哪些其他的时机会把 redo log block 刷入磁盘？ redo log buffer 中的缓存日志写入磁盘上面讲了一下 redo log buffer 的缓冲机制。redo log 在写的时候，都是一个事务里的一组 redo log，先暂存在一个地方，完事了以后把一组 redo log 写入 redo log buffer。写入 redo log buffer 的时候，是写入里面提前划分好的一个一个的 redo log block 的，选择有空闲空间的 redo log block 去写入，然后 redo log block 写满之后，其实会在某个时机刷入到磁盘里去。 那么 redo log buffer 里的 redo log 日志文件什么时候可以刷入到磁盘文件里去？磁盘上有几个 redo log 日志文件，不可能大量的 redo log 日志都放在一个文件里吧？磁盘空间会占用得越来越多吗？ 首先，我们来看看 redo log block 是哪些时候会刷入到磁盘文件里去： 如果写入 redo log buffer 的日志已经占据了 redo log buffer 总容量的一半了，也就是超过了 8MB 的 redo log 在缓冲里了，此时就会把他们刷入到磁盘文件里去 一个事务提交的时候，必须把它的那些 redo log 所在的 redo log block 都刷入到磁盘文件里去，只有这样，当事务提交之后，它修改的数据绝对不会丢失，因为 redo log 里有重做日志，随时可以恢复事务做的修改（PS：当然，这个 redo log 哪怕事务提交的时候写入磁盘文件，也是先进入 os cache 的，进入 os 的文件缓冲区里，所以是否提交事务就强行把 redo log 刷入物理磁盘文件中，这个需要设置对应的参数） 后台线程定时刷新，有一个后台线程每隔 1 秒就会把 redo log buffer 里的 redo log block 刷到磁盘文件里去 MySQL 关闭的时候，redo log block 都会刷入到磁盘里去 忽略上面的第四条不说，因为关闭 MySQL 的时候必然会刷 redo log 到磁盘，其他三天我们都看到了，即，如果你瞬间执行大量的高并发 SQL 语句，1 秒内就产生了超过 8MB 的 redo log，此时占据了 redo log buffer 一半的空间了，必然会直接把你的 redo log 刷入磁盘去。这种 redo log 刷盘的情况，在 MySQL 承载高并发请求的时候比较常见，比如每秒执行上万个增删改 SQL 语句，每个 SQL 产生的 redo log 假设有 几百个字节，此时却是会在瞬间生成超过 8MB 的 redo log 日志，必然会触发立马刷新 redo log 到磁盘。 第二种情况就是平时执行了一个事务，这个事务一般都是在几十毫秒到几百毫秒执行完毕的。一般情况下，MySQL 单事务性能一般不会超过 1 秒，否则数据库操作就太慢了。而如果在几十毫秒，或者几百毫秒的时候，执行完了一个事务，此时会立马把这个事务的 redo log 都刷入磁盘。 第一种情况其实是不常见的，第二种情况就比较常见，往往 redo log 刷盘都是以一个短事务提交时候发生的，第三种情况就是后台线程每秒自动刷新到 redo log 到磁盘去，这个就是说即使没有别的情况触发，后台线程自己也会不停地刷新 redo log 到磁盘 但是不管怎样，主要是保证一个事务执行的时候，redo log 都进入 redo log buffer，提交事务的时候，事务对应的 redo log 必须是刷入磁盘文件，接着才算是事务提交成功，否则事务提交就是失败。保证这一点，就能确保事务提交之后，数据不会丢，有 redo log 在磁盘里就行了。当然，绝对保证数据不丢，还得配置一个参数，提交事务把 redo log 刷入磁盘文件的 os cache 之后，还得强行从 os cache 刷入物理磁盘 最后说一下 redo log 日志文件的问题。我们都知道平时不停地执行增删改，MySQL 会不停地产生大量的 redo log 写入日志文件，那么日志文件就用一个写入全部的 redo log？对磁盘占用空间越来越大怎么办？ 其实，默认情况下，redo log 都会写入一个目录中的文件里，这个目录可以通过 show variables like &#39;datadir&#39; 来查看，可以通过 innodb_log_group_home_dir 参数来设置这个目录。然后 redo log 是有多个的，写满了一个就会写下一个 redo log，而且可以限制 redo log 文件数量，通过 innodb_log_file_size 可以指定每个 redo log 文件的大小，默认是 48MB，通过 innodb_log_files_in_group 可以指定日志文件的数量，默认就 2 个。 所以默认情况下，日志里就两个日志文件， 分别为 ib_logfile0 和 ib_logfile1，每个 48MB。最多就这 2 个日志文件，就是先写第一个，写满了写第二个。如果第二个也写满了，就继续写第一个，覆盖第一个日志文件里原来的 redo log 就可以了。 所以 MySQL 最多就给你保留了最近的 96MB 的 redo log 而已。不过这已经算很多了，毕竟 redo log 真的很小，一条通常就几个字节到几十个字节不等，96MB 足够你存储上百万条 redo log 了。如果你还想保留更多的 redo log，上调那两个参数就可以了。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之 redo 日志]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F11%2FMySQL-%E4%B9%8B-redo-%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[之前我们说过，在我们执行增删改操作的时候，首先会在 Buffer Pool 中更新缓存页。而在更新完 Buffer Pool 中的缓存页之后，必须要写一条 redo log，这样才能记录下来我们对数据库做的修改。redo log 可以保证我们事务提交之后，如果事务中的增删改 SQL 语句更新的缓存页还没刷到磁盘上去，此时 MySQL 宕机了，那么 MySQL 重启之后，就可以把 redo log 重做一遍，恢复出来事务当时更新的缓存页，然后再把缓存页刷到磁盘就可以了 redo log 本质是保证事务提交之后，修改的数据绝对不会丢失。我们就承上启下，给大家简单回顾一下 redo log 这个机制存在的意义 首先，执行增删改 SQL 语句的时候，都是针对一个表中的某些数据去执行。此时的话，首先要找到这个表对应的表空间，然后找到表空间对应的磁盘文件，接着从磁盘文件里把你要更新的那批数据所在的数据页从磁盘读取出来，放到 Buffer Pool 的缓存页里去，如图： 接着你的增删改 SQL 语句就会针对 Buffer Pool 中的缓存页去执行你的更新逻辑，比如插入、更新或者删除一段数据。至于说数据页和数据行的格式，就不用多说了，都是 MySQL 定义的，之前都讲过。 之前学习过 Buffer Pool 底层原理之后都知道，其实你更新缓存页的时候，会更新 free 链表、flush 链表、lru 链表，然后会有专门的后台 IO 线程，不定时地根据 flush 链表、lru 链表，把你更新过的缓存页刷新会磁盘文件的数据页里去，如图： 所以这个机制里最大的漏洞就是，万一你一个事务里又增删改 SQL 更新了缓存页，然后事务提交了，结果万一你还没来得及让 IO 线程把缓存页刷新到磁盘文件里，此时 MySQL 宕机了，然后内存数据丢失，你事务更新的数据就丢失了。 但是也不可能每次你事务一提交，就把你事务更新的缓存页都刷新回磁盘文件里，因为缓存页刷新到磁盘文件里，是随机磁盘读写，性能是非常差的，这会导致你数据库性能和并发能力都很弱。所以此时才会引入一个 redo log 机制，这个机制就是说，你提交事务的时候，绝对是保证把你对缓存页做的修改以日志的形式，写入到 redo log 日志文件里去的 这种日志大致的格式如下：对表空间 XX 中的数据页 XX 中的偏移量为 XXXX 的地方更新了数据 XXX，如图所示： 只要你事务提交的时候保证你做的修改以日志形式写入 redo log 日志，那么哪怕你此时突然宕机了，也没关系。因为你 MySQL 重启之后，把你之前事务更新做过的修改根据 redo log 在 Buffer Pool 里重做一遍就可以了，就可以恢复出来当时你事务对缓存页做的修改，然后找时机再把缓存页刷入磁盘文件里。 可能有人会问，你事务提交的时候把修改过的缓存页都刷入磁盘，跟你事务提交的时候把你做的修改的 redo log 都写入日志文件，它们不都是写磁盘吗？差别在哪？实际上，如果你把修改过的缓存页都输入磁盘，这首先缓存页一个就是 16KB，数据比较大，输入磁盘比较耗时，而且你可能就修改了缓存页里的几个字节的数据，难道也把完整的缓存页刷入磁盘吗？ 而且缓存页刷入磁盘是随机写磁盘，性能是很差的，因为它一个缓存页对应的位置可能在磁盘文件的一个随机位置，比如偏移量 45536 这个地方。但是如果是写 redo log，第一个一行 redo log 可能就占据几十个字节，就包含表空间号、数据页号、磁盘文件偏移量、更新值，这个写入磁盘速度很快。此外，redo log 写日志，是顺序写入磁盘文件，每次都是追加到磁盘文件末尾去，速度也是很快的。 所以你提交事务的时候，用 redo log 的形式记录下来你做的修改，性能会远远超过刷缓存页的方式，这也可以让你的数据库的并发能力更强。 redo log接下来我们要深入研究一下 redo log 的一些技术细节，我们来看一下写入磁盘文件的 redo log，大致长个什么样，里面都包含一些什么东西。 其实 redo log 里本质上记录的就是在某个表空间的某个数据页的某个偏移量的地方修改了几个字节的值，具体修改的值是什么，它里面需要记录的就是 表空间号 + 数据页号 + 偏移量 + 修改几个字节的值 + 具体的值。 所以根据你修改了数据页里的几个字节的值，redo log 就划分为了不同的类型。MLOG_1BYTE 类型的日志指的就是修改了 1 个字节的值，MLOG_2BYTE 类型的日志指的就是修改了 2 个字节的值，以此类推，还有修改了 4 个字节的值的日志类型，修改了 8 个字节的值的日志类型 当然，如果你要是一下子修改了一大串的值，类型就是 MLOG_WRITE_STRING，就是代表了你一下子在那个数据页的某个偏移量的文职插入或者修改了一大串的值。所以其实一条 redo log 看起来大致的结构如下： 日志类型（就是类似 MLOG_IBYTE 之类的），表空间 ID，数据页号，数据页中的偏移量，具体修改的数据 大致就是一条 redo log 中依次排列上述的一些东西，这条 redo log 表达的语义就很明确了，它的类型是什么，类型就告诉你它这次增删改操作修改了多少字节的数据；然后在哪个表空间里操作的，这个就是跟你 SQL 在哪个表里执行的是对应的；接着就是在这个表空间的哪个数据页里执行的，在数据页的哪个偏移量开始执行的，具体更新的数据是哪些 有了上述信息，就可以精准完美的还原出来一次数据增删改操作做的变动了。只不过如果是 MLOG_WRITE_STRING 类型的日志，因为不知道具体修改了多少字节的数据，所以其实会多一个修改数据长度，就告诉你它这次修改了多少字节的数据，如下所示它的格式： 日志类型（就是类似 MLOG_1BYTE 之类的），表空间号，数据页号，数据页中的偏移量，修改数据长度，具体修改的数据 因此今天就简单说一下 redo log 的日志格式，没想象中的那么复杂。当然如果往深了说，那也是很复杂的，比如 redo log 日志里面可能记录你更新了哪些索引之类的，这就很复杂了。我们对 redo log 日志的格式了解到这个程度其实就可以了。就是在执行增删改的时候，在 Buffer Pool 里通过复杂的缓存页机制完成更新，然后就会以今天讲解的这种格式写入一条 redo log 日志记录本次修改。 redo log 的写入redo log 是一条一条地直接就往磁盘文件里写入吗？其实没有那么简单。平时我们执行 CRUD 的时候，从磁盘加载数据页到 Buffer Pool 的缓存页里去，然后对缓存页执行增删改，同时还会写 redo log 到日志文件里去，后续不定时把缓存页刷回磁盘文件里去。而我们也介绍了每一条 redo log 长什么样子，说白了它就是记录了： 表空间号 + 数据页号 + 数据页内偏移量 + 修改了几个字节的数据 + 实际修改数据 所以，redo log 就是按照上述格式，一条一条地直接写入到磁盘的日志文件里去了吗？当然不是，其实 MySQL 内有另外一个数据结构，叫做 redo log block，你可以简单理解为，平时我们的数据不是存放在数据页的么，用一页一页的数据页来存放数据。那么对于 redo log 也不是单行单行地写入日志文件的，它是用一个 redo log block 来存放多个单行日志的。 一个 redo log block 是 512 字节，分为三个部分：一个是 12 字节的 header 块头，一个是 496 字节的 body 块体，一个是 4 字节的 trailer 块尾。 这里面，12 字节的 header 头又分为了 4 个部分： 包括 4 个字节的 block no，就是块唯一编号 2 个字节的 data length，就是 block 里写入了多少字节数据 2 个字节的 first record group。这个是说每个事务都会有多个 redo log，是一个 redo log group，即一组 redo log。那么在这个 block 里的第一组 redo log 的偏移量，就是这 2 个字节存储的。 4 个字节的 checkpoint on 如下图，这个 header 可以进行进一步的区分： 从上面可以看到，对于我们的 redo log 日志而言，它确实是不停地追加写入到 redo log 磁盘文件里去的，但是其实每一个 redo log 都是写入到一个 redo log block 里去的，一个 block 最多放 496 字节的 redo log 日志。 那么一个一个的 redo log block 在日志文件里是怎么存放的？一条一条的 redo log 又是如何写入日志文件里的 redo log block 里去的呢？ 假设你有一个 redo log 日志文件，平时我们往里面写数据，你大致可以认为是从第一行开始，从左往右写，可能会有很多行，比如下面那样子，你看看是不是你理解的那样？ 既然如此，假设你要写第一个 redo log 了，是不是应该先在内存里把这个 redo log 给弄到一个 redo log block 数据结构里去？然后似乎你应该是等内存里的一个 redo log block 的 512 字节都满了，再一次性把这个 redo log block 写入磁盘文件？ 然后其实按照我们所说的，一个 redo log block 就是 512 字节，那么是不是真正写入的时候，把这个 redo log block 的 512 字节的数据，就写入到 redo log 文件里去就可以了？那么 redo log 文件里就多了一个 block，如下图： 看到上图演示之后，对于这个所谓的 redo log 和 redo log block 的关系，以及 redo log block 如何进入日志文件，日志文件里如何存放一个又一个所谓的 redo log block 的，都应该清楚了。其实有一定开发经验的朋友都知道，写文件的时候，可以按照字节，一个字节一个字节地写入的，文件里存放的东西就是很多很多字节，依次排开，然后其中可能 512 个字节组合起来，就固定代表了一个 redo log block。 这此时就是任何一个中间件系统，数据库系统，底层依赖磁盘文件存储数据的一个共同的原理，所以大家也不用把这个复杂数据写入磁盘文件想象得太复杂了 那么如果一次在磁盘文件里的末尾追加不停地写字节数据，就是磁盘顺序写；但是假设现在磁盘文件里已经有很多很多的 redo log block 了，此时要再在磁盘里某个随机位置找到一个 redo log block 去修改它里面几个字节的数据，这就是磁盘随机写，如图：]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 的一些生产案例]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F11%2FMySQL-%E7%9A%84%E4%B8%80%E4%BA%9B%E7%94%9F%E4%BA%A7%E6%A1%88%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[RAID 锂电池充放电导致的 MySQL 性能抖动曾经有一个业务，它的数据库是部署在高配置服务器上的，磁盘就是用 RAID10 的阵列技术，用了 6 块磁盘组成了 RAID10 磁盘阵列架构。那么 RAID10 是什么？ 在知道 RAID10 之前，我们先看一下什么是 RAID0。RAID0，就是你有很多磁盘组成了一个阵列，然后你所有的数据都是分散写入不同磁盘的。因为有多块磁盘，所以你的磁盘阵列的整体容量就很大，而且同时写入多块磁盘，让你的磁盘读写并发能力很强。如下： 但是这种模式下，最大的问题就是万一你磁盘坏了一块，那么就会丢失一部分数据了。所以一般如果要严格保证数据不丢失的话，就得用 RAID1。这个 RAID1，就是两块磁盘为镜像关系，你写的所有数据，在两块磁盘上都有，形成了数据冗余，一块磁盘坏了，另一块磁盘上还有数据。一块磁盘如果压力大，可以让请求路由到另外一块磁盘上去，分担压力，反正它俩的数据都是冗余的，是一样的。 而所谓的 RAID10，就是 RAID0 + RAID1 组合起来。就是说当时生产环境的服务器部署，我们有 6 块磁盘组成了一个 RAID 10 的阵列，那么其实就是每 2 块磁盘组成一个 RAID1 互为镜像的架构，存放的数据是冗余一样的，一共有 3 组 RAID1，然后对于每一组 RAID1 写入数据的得时候，是用 RAID0 的思路，就是不同组的磁盘的数据是不一样的，但是同一组内的两块磁盘的数据是冗余一致的。如图： 所以对于这样的一个使用 RAID10 架构的服务器，它必然内部是一个锂电池的，然后这个锂电池的厂商设定的默认是 30 天进行一次充电，每次锂电池充放电就会导致 RAID 写入时不经过缓存，性能会急剧下降，所以我们发现线上机器每隔 30 天就会有一次剧烈性能抖动，数据库性能下降了 10 倍 为了排查这个问题，使用 Linux 命令查看了 RAID 硬件设备的日志，这个命令就不说了，因为不同的厂商的 RAID 设备，这个命令其实是不一样的。发现 RAID 就是每隔 30 天就有一次充放电的日志，所以就是由于这个定期的充放电导致了线上数据库的性能定期抖动。 对于 RAID 锂电池充放电问题导致的性能抖动，一般有三个解决方案： 给 RAID 卡把锂电池换成电容，电容是不用频繁充放电的，不会导致充放电的性能抖动，还有就是电容可以支持透明充放电，就是自动检查电量，自动进行充放电，不会说在充放电的时候直接写 IO 直接走磁盘，但是更换电容很麻烦，而且电容容易老化，这个其实一般不常用 手动充放电。这个比较常用，大部分互联网大厂的数据库服务器的 RAID 就是用了这个方案避免性能的抖动。就是关闭 RAID 自动充放电，然后写一个脚本，脚本每隔一段时间自动在晚上凌晨的业务低峰时期，脚本自动触发充放电，这样可以避免业务高峰期的时候 RAID 自动充放电引起性能抖动 充放电的时候不要关闭 write back，就是设置一下，锂电池充放电的时候不要把缓存级别从 write back 修改为 write through，这个也是可以做到的，可以和第二个策略合起来使用 数据库无法连接故障：too many connections场景介绍一个经常碰到的数据库生产故障，就是数据库无法连接的问题。大家会看到的异常信息往往是 ERROR 1040(HY000): Too many connections，这个时候就是说数据库的连接池里有太多的连接了，不能再跟你建立新的连接了 之前我们讲过数据库的整体架构原理。数据库自己其实是有一个连接池的，你的每个系统部署在一台机器上的时候，你那台机器上部署的 系统实例/服务实例 自己也是有一个连接池的，你的系统每个连接 Socket 都会对应着数据库连接池里的一个连接 Socket，这就是 TCP 网络连接，如图： 所以当数据库告诉你 Too many connections 的时候，说明它的连接池已经满了，你业务系统不能跟它建立更多的连接了。 有一个场景，数据库部署在 64GB 的大内存物理机上，机器配置各方面都很高，然后连接这台物理机的 Java 系统部署在 2 台机器上，Java 系统设置的连接池最大大小是 200，即每台机器上部署的 Java 系统，最多跟 MySQL 数据库建立 200 个连接，一共最多建立 400 个连接。 但是这个时候 MySQL 报异常说 Too many Connections，就说明目前 MySQL 甚至都无法建立 400 个网络连接。这太少了，毕竟服务器都是高配置的。于是我们检查了 MySQL 的配置文件：my.cnf，里面有一个关键的参数是 max_connections，就是 MySQL 能建立的最大连接数，设置的是 800 这就奇怪了，明明设置了 MySQL 最多可以建立 800 个连接，为啥两台机器 400 个连接就不行了？我们再用命令行或者一些管理工具登陆到 MySQL 去，可以执行下面的命令看一下： 1show variables like &apos;max_connections&apos; 此时看到，当前 MySQL 仅仅只是建立了 214 个连接而已。此时我们想到，是不是 MySQL 不管我们设置的那个 max_connections，就是直接强行把最大连接数设置为 214 了？于是我们去检查了 MySQL 的启动日志，发现如下的字样： 123Could not increase num of max_open_files to more than mysqld(request: 65535)Changed limits: max_connections:214 (requested 2000)Changed limits: table_open_cache:400 (requested 4096) 看日志就很清楚了，简单来说，就是因为底层的 Linux 系统把进程可以打开的文件句柄数限制为 1024 了，导致 MySQL 最大连接数是 214。如图： 解决与原理上面说了 Too many connections 故障，它的核心就是 Linux 的文件句柄限制，导致了 MySQL 的最大连接数被限制。那如何解决这个问题？其实核心就是一行命令： 1ulimit -HSn 65535 然后就可以用如下命令检查最大文件句柄是否被修改了： 12cat /etc/security/limits.confcat /etc/rc.local 如果都修改好了，可以在 MySQL 的 my.cnf 里确保 max_connections 参数也调整好了，然后可以重启服务器，然后重启 MySQL，这样的话，Linux 的最大文件句柄就会失效了，MySQL 的最大连接数也会生效了。然后你再尝试业务系统去连接数据库，就没问题了 为什么 Linux 的最大文件句柄限制为 1024 的时候，MySQL 的最大连接数是 214 呢？这个其实是 MySQL 源码内部写死的，它在源码中就是有一个计算公式，算下来就是如此罢了。 然后 Linux 的 ulimit 命令是干嘛用的？其实，Linux 是默认会限制你每个进程对机器资源的使用的，包括可以打开的文件句柄的限制，可以打开的子进程数的限制，网络缓存的限制，最大可以锁定的内存大小。因为 Linux 系统设计的初衷，就是要尽量避免你某个进程一下子耗尽机器上所有资源，所以它默认都是会做限制的 那么对于我们来说，常见的一个问题，其实就是文件句柄的限制。因为如果 Linux 限制你一个进程的文件句柄太少的话，那么就会导致我们没办法创建大量的网络连接，此时我们系统进程就没办法正常工作了。 举例来说，比如 MySQL 运行的时候，其实就是 Linux 的一个进程，那么他其实是需要跟很多业务系统建立大量的连接的，结果你限制了它最大文件句柄数量，那么它就不能建立太多连接了。所以，往往你在生产环境部署了一个系统，比如数据库系统、中间件系统、存储系统、缓存系统之后，都需要调整一下 Linux 的一些内核参数。而这个文件句柄的数量是一定要调整的吗，通常都得设置为 65535 还有比如 Kafka 之类的消息中间件，在生产环境部署的时候，如果你不优化一些 Linux 内核参数，会导致 Kafka 可能无法创建足够的线程，此时也是无法运行的。 所以我们平时可以用 ulimit 命令来设置每个进程被限制使用的资源量，用 ulimit -a 就可以看到进程被限制使用的各种资源的量。比如 core file size 代表的进程崩溃时候的转储文件的大小限制，max locked memory 就是最大锁定内存大小，open files 就是最大可以打开的文件句柄数量，max user processes 就是最多可以拥有的子进程数量 设置之后，我们要确保变更落地到 /etc/security/limits.conf 文件里，永久性地设置进程的资源限制。所以执行 ulimit -HSn 65535 命令后，要用以下命令检查一下是否落地到配置文件里去。 12cat /etc/security/limits.confcat /etc/rc.local]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper 的一些知识点]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F06%2FZooKeeper-%E7%9A%84%E4%B8%80%E4%BA%9B%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[ZooKeeper 的应用ZooKeeper 是一个分布式协调系统，封装了分布式架构中所有核心和主流的需求和功能。主要有如下作用： 分布式锁：运用于分布式的 Java 业务系统中 元数据管理：Kafka、Canal，本身都是分布式架构，分布式集群在运行，它需要一个地方集中式地存储和管理分布式集群的核心元数据，所以它们都选择把核心元数据放在 ZooKeeper 中 分布式协调：如果有人对 ZK 中的数据做了变更，ZK 会反过来去通知其它监听这个数据的人，告诉别人这个数据变更了。例如 Kafka 有多个 Broker，多个 Broker 会竞争成为一个 controller 的角色，如果作为 controller 的 Broker 挂掉了，此时它在 ZK 里注册的一个节点就会消失，其它 Broker 瞬间会被 ZK 反向通知这个事情，继续竞争成为新的 controller Master 选举 ZooKeeper 的特点 ZooKeeper 这个系统可以存储元数据，支持 Master 选举和进行分布式协调和通知，所有它具有以下这些特点： 集群部署：不可能单机版本 顺序一致性：所有请求全部有序 原子性：要么全部机器都成功，要么全部机器都别成功 数据一致性：无论连接到哪台 ZK 上去，看到的都是一样的数据，不能有数据不一致 高可用：如果某台机器宕机，要保证数据绝对不能丢失 实时性：一旦数据反生变更，其他人要实时感知到 ZooKeeper 的架构特点 为了实现需要的一些特性，ZooKeeper 的架构设计需要有哪些特点？ 第一个就是集群化部署。3 ~ 5 台机器组成一个集群，每台机器都在内存保存了 ZK 的全部数据，机器之间互相通信同步数据，客户端连接任何一台机器都可以。 第二就是树形结构的数据模型：znode。数据模型简单，纯内存保存。ZK 的数据结构跟 UNIX 的文件系统是类似的，具有层级关系的树形的文件系统的结构，而 znode 可以认为是一个节点。例如下面 12create /usr/local/uidcreate /usr/local/test_file uid 可以写入一些数据，比如 hello world；test_file 也可以写入一些数据的值 第三就是顺序写。集群中只有一台机器可以写，所有机器都可以读，所有请求都会分配一个 ZK 集群全局的唯一递增编号：zxid，保证各种客户端发起的写请求都是有序的。 另外就是数据一致性。任何一台 ZK 机器收到了写请求之后都会同步给其他机器，保证数据的强一致，你连接到任何一台 ZK 机器看到的数据都是一致的。 还有高性能。每台 ZK 机器都在内存中维护数据，所以 ZK 集群绝对是高并发高性能的。如果你让 ZK 部署在高配置物理机上，一个 3 台机器的 ZK 集群抗下每秒几万请求是没有问题的 高可用。哪怕集群中挂掉不超过一半的机器，都能保证可用，数据不会丢失，3 台机器可以挂 1 台，5 台机器可以挂 2 台。 高并发。高性能决定的，只要基于纯内存数据结构来处理，并发能力是很高的 ZooKeeper 集群的角色通常来说 ZooKeeper 集群里有三种角色的机器：Leader、Follower、Observer。 集群启动自动选举一个 Leader 出来，只有 Leader 是可以写的，Follower 是只能同步数据和提供数据的读取。Leader 挂了，Follower 可以继续选举出来 Leader。Observer 也只能读但是 Observer 不参与选举。 客户端与 ZooKeeper 之间的长连接ZK 集群启动之后，自己分配好角色，然后客户端就会跟 ZK 建立连接，是 TCP 长连接。此时就会建立一个会话，就是 session，可以通过心跳感知到会话是否存在。有一个 sessionTimeOut，意思就是如果连接断开了，只要客户端在指定时间内重新连接 ZK 一台机器，就能继续保持 session，否则session 就超时了。 ZooKeeper 的数据模型：znode 和节点类型ZK 的核心数据模型就是 znode 树，平时我们往 ZK 写数据就是创建树形结构的 znode，里面可以写入值。这些数据模型，都在 ZK 内存里存放的。 ZK 主要有两种节点类型：持久节点和临时节点。持久节点就是哪怕客户端断开连接，也时一直存在的；临时节点就是只要客户端断开连接，节点就没了。 此外还有一种顺序节点，就是创建节点的时候自增加全局递增的序号。基于 ZK 实现的分布式锁的框架 – curator。在里面就是基于 ZK 的临时顺序节点来实现的。加锁的时候，是创建一个临时顺序节点，ZK 会自动给你的临时节点加上一个后缀，是一个全局递增的编号，如果你客户端断开连接了，就自动销毁这个你加的锁，此时人家会感知到，就会尝试去加锁。 如果你是做元数据存储，用的肯定是持久节点；如果你是做一些分布式协调和通知，很多时候用临时节点，就是说我创建一个临时节点，别人来监听这个节点的变化，如果断开连接了，临时节点消失，此时人家会感知到，就会来做点别的事情；顺序节点，在分布式锁里用的比较经典 另外每个 znode 还有一个 Stat 用来存放数据版本：version（znode 的版本）；cversion（znode 子节点的版本），aversion（znode 的 ACL 权限控制版本） ZooKeeper 最核心的一个机制：Watcher 监听回调ZooKeeper 最核心的机制，就是你一个客户端可以对 znode 进行 Watcher 监听，然后 znode 改变的时候回调通知你的这个客户端。这个是非常有用的一个功能，在分布式系统的协调中是很有必要的。 如果 ZK 只支持写和查，那么只能实现元数据存储和 Master 选举等部分功能；而分布式系统的协调需求，需要比如分布式架构中的系统 A 监听一个数据的变化，如果分布式架构中的系统 B 更新了哪个数据或者节点，ZK 会反过来通知系统 A 这个数据的变化。]]></content>
      <categories>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 杂记]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F02%2FMySQL-%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Linux 操作系统的存储系统软件层原理今天我们讲讲 MySQL 数据库在执行底层磁盘读写 IO 操作的原理，这其实就涉及到了 Linux 操作系统的磁盘 IO 原理了，不管是 MySQL 执行磁盘随机读写，还是磁盘顺序读写，其实在底层的 Linux 层面，原理几乎是一致的。 所谓的操作系统，无论是 Linux ，还是 Windows，本质上它们自己也是软件系统，之所以需要操作系统，是因为我们不可能直接去操作 CPU、内存、硬盘这些硬件，所以必须要用操作系统来管理 CPU、内存、磁盘、网卡这些硬件设备。操作系统除了管理硬件设备以外，还会提供一个操作界面给我们，例如 Windows 之所以能成功，其实就是它提供了一个比较易用的可视化界面，让我们普通人都能操作电脑内部的内存、CPU、磁盘和网卡。 至于 Linux 操作系统，其实也是类似的，只不过一般我们用 Linux 操作系统，它是不给我们提供可视化界面的，只有命令行界面，我们需要输入各种各样的命令去执行文件编辑、系统部署和运行，本质 Linux 系统在底层也是利用 CPU、内存、磁盘和网卡这些硬件设备在工作。 所以，今天要讲解的就是 Linux 操作系统的存储系统，Linux 利用这套存储系统去管理我们机器上的机械硬盘、SSD 固态硬盘。这些存储设备，可以在里面读取数据，或者是写入数据。理解了这个，你就理解了 MySQL 执行的数据页随机读写，redo log 日志文件顺序读写的磁盘 IO 操作，在 Linux 的存储系统中是如何执行的。 简单来说，Linux 的存储系统分为 VFS 层、文件系统层、Page Cache 缓存层、通用 Block 层、IO 调度层、Block 设备驱动层、Block 设备层，如图： 当 MySQL 发起一次数据页的随机读写，或者是一次 redo log 日志文件的顺序读写的时候，实际上会把磁盘 IO 请求交给 Linux 操作系统的 VFS 层，这一层的作用，就是根据你是对哪个目录的文件执行的磁盘 IO 操作，把 IO 请求交给具体的文件系统。 例如，在 Linux 中，有的目录比如 /xx1/xx2 里的文件其实是由 NFS 文件系统管理的，有的目录比如 /xx3/xx4 里的文件其实是由 Ext3 文件系统管理的，那么这个时候 VFS 层需要根据你是对哪个目录下的文件发起的读写 IO 请求，把请求转交给响应的文件系统，如下图： 接着文件系统会先在 Page Cache 这个基于内存的缓存里找你要的数据在不在里面，如果有就基于内存缓存来执行读写，如果没有就继续往下一层走，此时这个请求会交给 Block 层，在这一层会把你对文件的 IO 请求转换为 Block IO 请求。 接着 IO 请求转换为 Block IO 请求之后，会把这个 Block IO 请求交给 IO 调度层，在这一层里默认是用 CFQ 公平调度算法的。 例如，假设此时数据库发起了多个 SQL 语句同时在执行 IO 操作。有一个 SQL 语句，比如 update xxx set xx1 = xx2 where id = 1，它其实可能就只要更新磁盘上的一个 block 里的数据就可以了。但是有的 SQL 语句，比如 select * from xx where xx1 like &quot;%xx%&quot; 可能需要 IO 读取磁盘上大量数据。那么此时如果基于公平调度算法，就会导致它先执行第二个 SQL 语句的读取大量数据的 IO 操作，耗时很久，然后第一个仅仅更新少量数据的 SQL 语句的 IO 操作，就一直等待它，等不到执行的机会。 所以在这里，一般建议 MySQL 的生产环境，需要调整为 deadline IO 调度算法，它的核心思想就是，任何一个 IO 操作都不能一直不停地等待，在指定时间范围内，都必须让它去执行。所以基于 deadline 算法，上面第一个 SQL 语句的更新少量数据的 IO 操作可能在等待一会儿之后，就会得到执行的机会，这也是一个生产环境的 IO 调度优化经验。 我们看下图，此时 IO 请求被转交给了 IO 调度层 最后 IO 完成调度之后，就会决定哪个 IO 请求先执行，哪个 IO 请求后执行，此时可以执行的 IO 请求就会交给 Block 设备驱动层，然后最后经过驱动把 IO 请求发送给真正的存储硬件，也就是 Block 设备层 然后硬件设备完成了 IO 读写操作之后，要不然是写，要不然是读，最后就把响应通过上面的层级反向依次返回，最终 MySQL 可以得到本次 IO 读写操作的结果 这就是 MySQL 跟 Linux 存储系统交互的一个原理剖析，包括里面的 IO 调度算法那块的一个优化的点。 数据库服务器使用的 RAID 存储架构初步介绍实际上 MySQL 数据库就是个软件，它其实就是用编程语言写的一套数据库管理软件而已，底层就是磁盘来存储数据，基于内存来提升数据读写性能，然后设计了复杂的数据模型，帮助我们高效地存储和管理数据。所以 MySQL 数据库软件都是安装在一台 Linux 服务器上，然后启动 MySQL 的进程，就是启动了一个 MySQL 数据库。 MySQL 运行过程中，它需要使用 CPU、内存、磁盘和网卡这些硬件，但是不能直接使用，都是通过调用操作系统提供的接口，依托于操作系统来使用和运行的，然后 Linux 操作系统负责操作底层的硬件。如图： 一般来说，很多数据库部署在机器上的时候，存储都是搭建的 RAID 存储架构，其实这个 RAID 很多人觉得深奥，确实这个概念比较难以理解，而且说深了里面的技术含量也很高，但简单说一下，还是可以理解的。 简单地说，RAID 就是一个磁盘冗余阵列，什么意思呢？假设我们的服务器里的磁盘就一块，如果一块磁盘的容量不够怎么办？可以再搞几块磁盘出来放在服务器。现在多搞了几块磁盘，机器里又很多磁盘了，不好管理，怎么在多块磁盘上存放数据呢？ 所以就是针对这个问题，在存储层面往往会在机器里搞多块磁盘，然后引入 RAID 这个技术，大致理解为用来管理机器里的多块磁盘的一种磁盘阵列技术。有了它以后，你在磁盘里读写数据的时候，它会告诉你应该在那块磁盘上读写数据，如图： 有了 RAID 这种多磁盘阵列技术之后，我们就可以在一台服务器里加多块磁盘，扩大我们的磁盘空间了。当我们往磁盘里写数据的时候，通过 RAID 技术可以帮助我们选择一块磁盘写入，在读取数据的时候，我们也知道从哪块磁盘去读取。 除此之外，RAID 技术很重要的一个作用，就是它还可以实现 数据冗余机制。所谓的数据冗余机制，就是如果你写入了一批数据在 RAID 的一块磁盘上，然后这块磁盘现在坏了，无法读取了，那你就丢失了一波数据。所以其实有的 RAID 磁盘冗余阵列技术里，是可以把你写入的同样一份数据，在两块磁盘上都写入的，这样可以让两块磁盘上的数据一样，作为冗余备份，然后当你一块磁盘坏掉的时候，可以从另外一块磁盘读取冗余数据出来，这一切都是 RAID 技术自动帮你管理的，不需要你操作，如图： 所以 RAID 技术实际上就是管理多块磁盘的一种磁盘阵列技术，它有软件层面的东西，也有硬件层面的东西，比如有 RAID 卡这种硬件设备。具体来说，RAID 还可以分成不同的技术方案，比如 RAID 0、RAID 1、RAID 0 + 1、RAID 2 等等，一直到 RAID10，很多种不同的多磁盘管理技术方案。 如果有兴趣，可以自行去搜索，大家只要了解一下 RAID 这种多磁盘冗余阵列技术的基本思想就可以了，对于存储的深入学习，主要也是一些运维工程师去做的。 数据库服务器上的 RAID 存储架构的电池充放电原理服务器使用多块磁盘组成的 RAID 阵列的时候，一般会有一个 RAID 卡，这个 RAID 卡是带有一个缓存的，这个缓存不是直接用我们的服务器的主内存的那种模式，他是一种跟内存类似的 SDRAM，当然，你大致认为她也是基于内存来存储的吧 然后我们可以设置 RAID 的缓存模式设置为 write back，这样的话，所有写入到磁盘阵列的数据，会先缓存在 RAID 卡的缓存里，后续慢慢再写入到磁盘阵列里去，这种写缓冲机制，可以大幅度提升我们的数据库磁盘写的性能。如图： 如果突然断电了，或者是服务器自己故障关闭了，那么这个 RAID 卡的缓存里的数据是不是就会丢失？那么 MySQL 写入磁盘的数据不就没了？正因为如此，为了解决这个问题，RAID 卡一般都配置有自己独立的锂电池或者是电容，如果服务器突然断电了，无法接通电源了，RAID 卡自己是基于锂电池来供电运行的，然后它会赶紧把缓存里的数据写入到阵列中的磁盘上去，如图： 但是锂电池是存在性能衰减问题的，所以一般来说锂电池都是要配置定时充放电的，也就是说每隔 30天 ~ 90天（不同的锂电池厂商是不一样的），就会自动对锂电池充放电一次，这可以延长锂电池的寿命和校准电池容量。如果不这么做的话，那么可能锂电池用着用着就会发现容量不够了，可能容纳的电量在你服务器掉电之后，都没法一次性把缓存里的数据写回磁盘上去，就会导致数据丢失了 所以在锂电池充放电的过程中，RAID 的缓存级别会从 write back 变成 write through，我们通过 RAID 写数据的时候，IO 就直接写磁盘了，如果写内存的话，性能也就是 0.1ms 这个级别，但是直接写磁盘，性能就退化到 10 倍到毫秒级了。 所以，对于那些在生产环境的数据库部署使用了 RAID 多磁盘阵列存储技术的公司，通常都会开启 RAID 卡的缓存机制，但是此时一定要注意这个 RAID 的锂电池自动充放电问题，因为只要你用了 RAID 缓存机制，那么锂电池就必然会定时进行充放电去延长寿命，保证服务器掉电的时候可以把缓存数据写回磁盘，数据不会丢失 所以这个时候一旦 RAID 锂电池自动充放电吗，往往会导致你的数据库服务器的 RAID 存储定期的性能出现几十倍的抖动，间接导致你的数据库每隔一段时间就会出现性能几十倍的抖动]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 数据库的日志顺序读写以及数据文件随机读写的原理]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F02%2FMySQL-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%97%A5%E5%BF%97%E9%A1%BA%E5%BA%8F%E8%AF%BB%E5%86%99%E4%BB%A5%E5%8F%8A%E6%95%B0%E6%8D%AE%E6%96%87%E4%BB%B6%E9%9A%8F%E6%9C%BA%E8%AF%BB%E5%86%99%E7%9A%84%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[今天给大家剖析一下 MySQL 在实际工作的时候两种数据读写机制，一种是对 redo log、binlog 这种日志进行的磁盘顺序读写，一种是对表空间的磁盘文件里的数据页进行的磁盘随机读写。 磁盘随机读简单来说，MySQL 在工作的时候，尤其是执行增删改操作的时候，肯定会先从表空间的磁盘文件里读取数据页出来，这个过程其实就是典型的磁盘随机读操作。如图，图里有一个磁盘文件的示意，里面有很多数据页，然后你可能需要在一个随机的位置读取一个数据页到缓存，这就是磁盘随机读。 因为你读取的这个数据页可能在磁盘的任意一个位置，所以你在读取磁盘里的数据页的时候只能是用随机读的这种方式。磁盘随机读的性能是比较差的，所以不可能每次更新数据都进行磁盘随机读，必须是读取一个数据页之后到 Buffer Pool 的缓存里去，下次更新的时候直接更新 Buffer Pool 里的缓存页。 对于随机读来说，主要关注的性能指标是 IOPS 和 响应延迟 IOPS，就是说底层的存储系统每秒可以执行多少次磁盘读写操作。比如你底层磁盘支持每秒执行 1000 个磁盘随机读写操作和每秒执行 200 个磁盘随机读写操作，对你的数据库的性能影响是非常大的。另外，这个指标实际上对数据库的 CRUD 操作的 QPS 影响是非常大的，因为它在某种程度上几乎决定了你每秒能执行多少个 SQL 语句，底层存储的 IOPS 越高，你的数据库的并发能力就越高 另一个就是磁盘随机读写操作的响应延迟，也是对数据库的性能有很大的影响。因为假设你的底层磁盘支持你每秒执行 200 个随机读写操作，但是每个操作是耗费 10ms 完成呢，还是耗费 1ms 完成呢。这个其实也是有很大影响的，决定了你对数据库执行的单个 CRUD SQL 语句的性能 比如你一个 SQL 语句发送过去，它磁盘要执行随机读操作加载多个数据页，此时每个磁盘随机读响应时间是 50 ms，那么此时可能你的 SQL 语句要执行 几百 ms，但是如果每个磁盘随机读仅仅耗费 10ms，可能你的 SQL 就执行 100ms 就行了。 所以一般对于核心业务的数据库的生产环境机器规划，我们都是推荐用 SSD 固态硬盘的，而不是机械硬盘，因为 SSD 固态硬盘的随机读写并发能力和响应延迟要比机械键盘好得多，可以大幅度提升数据库的 QPS 和性能。 磁盘顺序读写接着我们看磁盘顺序读写。之前说过，当你在 Buffer Pool 的缓存页里更新了数据之后，必须要写一条 redo log 日志，这个 redo log 日志，其实就是走的顺序写。所谓顺序写，就是说在一个磁盘日志文件里，一直在末尾追加日志。如下图： 上图可以看到，写 redo log 日志的时候，其实是不停地在一个日志文件末尾追加日志的，这就是磁盘顺序写。磁盘顺序写的性能是很高的，某种程度上来说，几乎可以跟内存随机读写的性能差不多，尤其是在数据库里其实也用了 os cache 机制，就是 redo log 顺序写入磁盘之前，先是进入 os cache，就是操作系统管理的内存缓存里。 所有对于这个写磁盘日志文件而言，最核心关注的是磁盘每秒读写多少数据量的吞吐量指标，也就是每秒可以写入磁盘 100MB 数据和每秒可以写入磁盘 200MB 数据，对数据库的并发能力影响也是极大的。 因为数据库的每一次更新 SQL 语句，都必然涉及多个磁盘随机读取数据页的操作，也会涉及到一条 redo log 日志文件顺序写的操作。所以磁盘读写的 IOPS 指标，就是每秒可以执行多少个随机读写操作，以及每秒可以读写磁盘的数据量的吞吐量指标，就是每秒可以写入多少 redo log 日志，整体决定了数据库的并发能力和性能。包括你磁盘日志文件的顺序读写延迟，也决定了数据库的性能，因为你写 redo log 日志文件越快，那么你的 SQL 性能就越高。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初步了解 MySQL 的存储模型和数据读写机制]]></title>
    <url>%2FCKING.github.io%2F2020%2F06%2F01%2F%E5%88%9D%E6%AD%A5%E4%BA%86%E8%A7%A3-MySQL-%E7%9A%84%E5%AD%98%E5%82%A8%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[我们都清楚，最终 MySQL 的数据都是放在磁盘文件里的，那么数据在磁盘文件是怎么存放的呢？我们知道我们平时数据都是插入一个一个的表中的，而表是个逻辑概念，其实在物理层面，它对应的是表空间这个概念。 所以其实在 MySQL 的磁盘上，表空间就对应着磁盘文件，在磁盘文件里就存放着数据。那么在这个表空间的磁盘文件里，数据是如何组织的？ 这个就非常复杂了。假如让你把数据一行一行地写入一个磁盘文件，当然很简单。但你现在要存储的是数据库里如此复杂的数据，它里面有各种字段类型的，还有索引这个概念。所以其实在磁盘文件里存放的数据，它从最基本的角度来看，就是被拆分为一个一个数据区（extent）分组，每个 extent 组中包含了 256 个 extent，然后每个 extent 里包含了 64 个数据页。然后每个数据页里都包含了一行一行的数据。如图： 听到这里，是不是觉得很简单？其实不是的，在实际存储的时候，在数据行里有很多附加的信息，在数据页、数据区里，都有很多附加的特殊信息。各种各样的特殊信息，就可以让我们在简简单单的磁盘文件里实现 B+ 树索引、事务之类的非常复杂的机制。 那么问题来了，我们都知道，当我们在数据库中执行 CRUD 的时候，你必须先把磁盘文件里的一个数据页加载到内存的 Buffer Pool 的一个缓存页里去，然后当我们增删改查都是针对缓存页里的数据来执行的。所以假设此时我们要插入一条数据，那么是选择磁盘文件里的哪个数据页加载到缓存里去呢？ 大家注意，这里要划重点。其实这个时候会看你往哪个表里插入数据，然后肯定得根据表找到一个表空间。找打表空间之后，就可以定位到对应的磁盘文件。有了磁盘文件之后，就可以从里面找一个 extent 组，找到一个 extent，接着从里面找一个数据页出来。这个数据页有可能是空的，也可能已经放入一些数据行了。然后就可以把这个数据页从磁盘里完整加载出来，放入 Buffer Pool 的缓存页里了。如图： 那么，这个从磁盘文件里读取一个数据页，是怎么读取的？其实很简单，磁盘里的文件的数据都是紧挨在一起的，类似于下面的那种样子： 120xdfs3439399abc0sfsdkslf9sdfpsfds0xdfs3439399abcOsfsdksIf9sdfpsfds0xdfs3439399abc0sfsdkslf9sdfpsfds0xdfs3439399abc0sfsdkslf9sdfpsfds 其实上述字符完全无任何意义，就是为了演示随便搞出来的一段东西而已，但是大致来说磁盘里存放的数据看起来就是那样的，可能先是有一个 extent 组开始的一些东西，然后里面是一个一个的 extent，每个 extent 开始的时候回些一些特殊的信息，然后再是一个一个的数据页，里面是一个一个的数据行。 那么在读取一个数据页的时候，你就可以通过随机读写的方式来了。举个例子，我们下面有一个伪代码，就是设置一下要从一个数据文件的哪个位置开始读取，一直到哪个位置就结束。 123dataFile.setStartPosition(25347)dataFile.setEndPosition(28890)dataPage = dataFile.read() 通过上面伪代码那种方式，你指定磁盘文件里的开始截止位置，就能读取出来指定位置的一段数据，比如读取出来一大坨东西：psfds0xdfs343939。也许这坨东西就是一个数据页包含的内容了。然后把数据页放到内存的缓存页里即可。 接着 CRUD 操作都可以直接针对缓存页去执行了，会自动把更新的缓存页加入 flush 链表，然后更新它在 LRU 链表里的位置，包括更新过的缓存页会从 free 链表里拿出来，等等，后续一系列操作，都是之前我们分析过的。 此时对于那些被更新过的缓存页来说，都会有后台线程刷入磁盘的，那么刷磁盘的时候怎么刷呢？看看下面的一段伪代码： 123dataFile.setStartPosition(25347)dataFile.setEndPosition(28890)dataFile.write(cachePage) 因为一个数据页的大小其实是固定的，所以一个数据页固定就是可能在一个磁盘文件里占据了某个开始位置到结束位置的一段数据，此时你写回去的时候也是一样，选择好固定的一段位置的数据，直接把缓存页的数据写回去，就覆盖了原来的那个数据页了，就如上面的伪代码示意 今天通过一篇总结文章，让大家初步了解到的存储模型是如何跟 Buffer Pool 缓存机制配合起来实现 CRUD 的。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 的数据页、表空间和数据区]]></title>
    <url>%2FCKING.github.io%2F2020%2F05%2F26%2FMySQL-%E7%9A%84%E6%95%B0%E6%8D%AE%E9%A1%B5%E3%80%81%E8%A1%A8%E7%A9%BA%E9%97%B4%E5%92%8C%E6%95%B0%E6%8D%AE%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[数据页的结构之前一直提到的一个概念，就是「数据页」。我们平时执行 CRUD 的时候，都会从磁盘上加载数据页到 Buffer Pool 的缓存页里去，然后更新了缓存页后，又会刷新回磁盘上的数据页里去。所以其实 MySQL 中进行数据操作的最小单位应该是数据页。 每个数据页，实际上是默认有 16KB 的大小，那么这 16KB 的大小就是存放大量的数据行吗？明显不是的，其实一个数据页拆分成了很多个部分。大体上包含了 文件头、数据页头、最小记录和最大记录、多个数据行、空闲空间、数据页目录、文件尾部。如图： 其中文件头占据了 38 个字节，数据页头占据了 56 个字节，最大记录和最小记录占据了 26 个字节，数据行区域的大小是不固定的，空闲区域的大小也是不固定的，数据页目录的大小也是不固定的，然后文件尾部占据 8 个字节。 会不会觉得有点懵逼，突然多了那么多的概念出来。其实说白了，这个数据页跟每一行数据一样，都是由 MySQL 开发人员设计出来的一个特殊的存储格式。即，通过这种特殊的存储格式在磁盘文件里去存放一个又一个的数据页，每个数据页在磁盘里实际存储的时候，就是包含了上述一些特殊的数据，然后每个数据里还有专门的区域包含了多个数据行。至于数据行，就是用之前讲解的那套存储格式来存储的。 接下来看一下把这个数据插入数据页的一个过程。刚开始，一个数据页可能是空的，没有一行数据，此时这个数据页实际上是没有数据行那个区域的。如图： 然后，假设我们现在要插入一行数据，此时数据库里可是一行数据都没有的，此时是不是应该先是从磁盘上加载一个空的数据页到缓存里去？此时空的数据页就是如上图所示，至于加载的过程，则如下图所示： 接着我们应该在 Buffer Pool 中的一个空的缓存页里插入一条数据。记住，缓存页跟数据页是一一对应的，它在磁盘上的时候就是数据页，数据页加载到缓存池里了，我们就叫它缓存页了。所以此时在缓存页里插入一行数据，实际上就是在数据行那个区域里插入一行数据，然后空闲区域的空间就会减少一些，此时当缓存页里插入一行数据之后，其实缓存页此时看起来如下图所示： 接着你就可以不停低插入数据到这个缓存页里去，直到它的空闲区域都耗尽了，就是这个页满了，此时数据行区域内可能有很多行数据，而空闲区域就没了。如图： 而且，在更新缓存页的同时，其实在 LRU 链表的位置会不停地变动，而且肯定会在 flush 链表里，所以最终它一定会通过后台 IO 线程根据 LRU 链表 和 flush 链表，把这个脏的缓存页刷到磁盘上去。这样，对于数据页的整体存储结构的初步介绍，以及 MySQL 实际运行过程中，数据页的使用，我们今天就介绍完了。 表空间以及划分多个数据页的数据区我们在大致了解了数据页的结构和使用之后，就可以继续了解下一个概念，就是表空间和数据区的概念。 什么是表空间？简单说就是我们平时创建的那些表，其实都是有一个表空间的概念，在磁盘上都会对应着「表名.ibd」这样的一个磁盘数据文件。所以在物理层面，表空间就是对应一些磁盘上的数据文件。 有的表空间，比如系统表空间可能对应的是多个磁盘文件，有的我们自己创建的表对应的表空间可能就是对应了一个「表名.ibd」数据文件。然后在表空间的磁盘文件里，其实会有很多很多的数据页，因为一个数据页也就是 16KB 而已，总不可能一个数据页就是一个磁盘文件吧，所以一个表空间的磁盘文件里，其实是有很多的数据页的。 但现在的问题就是，一个表空间里包含的数据页实在是太多了，不便于管理，所以在表空间里又引入了一个数据区的概念，英文就是 extent。 一个数据区对应着连续的 64 个数据页，每个数据页是 16KB，所以一个数据区是 1MB，然后 256 个数据区被划分为一个组。 对于表空间而言，它的第一组数据区的第一个数据区的前 3 个数据页，都是固定的，里面存放了一些描述性的数据。比如 FSP_HDR 这个数据页，它里面就存放了表空间和这一组数据区的一些属性。IBUF_BITMAP 数据页，里面存放的是这一组数据页的所有 insert buffer 的一些信息。INODE 数据页，这里也是存放了一些特殊的信息。 暂时先不用了解这些东西具体是干什么的，你只要知道每一个组数据区的第一个数据区的前 3 个数据页，都是存放一些特殊的信息的。然后这个表空间的其他各组数据区，每一组数据区的第一个数据区的头两个数据页，都是存放特殊信息的。比如，XDES 数据页就是用来存放这一组数据区的一些相关属性的，其实就是很多描述这组数据区的东西，现在也不用去知道是什么。 总结起来就是，我们平时创建的那些表都是由对应的表空间的，每个表空间就是对应了磁盘上的数据文件，在表空间就是你对应了磁盘上的数据文件，在表空间里又很多组数据区，一组数据区是 256 个数据区，每个数据区包含了 64 个数据页，是 1MB 然后表空间的第一组数据区的第一个数据区的头三个数据页，都是存放特殊信息的；表空间的其他组数据区的第一个数据区的头两个数据页，也都是存放特殊信息的。 所以磁盘上的各个表空间的数据文件里是通过数据区的概念，划分了很多很多的数据页的，因此当我们需要执行 CRUD 操作的时候，说白了，就是从磁盘上的表空间的数据文件里，去加载一些数据页出来到 Buffer Pool 的缓存页里去使用。 如图，图里给出了一个表空间内部的存储结构，包括一组一组的数据区，每一组数据区都是 256 个数据区，然后互一个数据区是 64 个数据页。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 的慢查询优化方式]]></title>
    <url>%2FCKING.github.io%2F2020%2F05%2F14%2FMySQL-%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[慢查询日志概念MySQL 的慢查询日志是 MySQL 提供的一种日志记录，它用来记录在 MySQL 中相应时间超过阈值的语句，具体指运行时间超过 long_query_time 值的 SQL。则会被记录到慢查询日志中。long_query_time 的默认值是 10，意思是运行 10s 以上的语句。 默认情况下，MySQL 数据库并不启动慢查询日志，需要我们手动来设置这个参数。当然，如果不是调优需要的话，一般不需要启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。慢查询日志支持将日志记录写入文件，也支持将日志记录写入数据库表。 慢查询日志相关参数MySQL 慢查询的相关参数解释： slow_query_log：是否开启慢查询日志，1 表示开启，0 表示关闭 log-slow-queries：旧版（5.6 一下版本）MySQL 数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件 host_name-slow.log slow-query-log-file：新版（5.6 及以上版本）MySQL 数据库慢查询日志存储路径。可以不设置该参数，系统则会默认给一个缺省的文件 host_name-slow.log long_query_time：慢查询阈值，当查询时间多于设定的阈值时，记录日志 log_queries_not_using_indexes：未使用索引的查询也被记录到慢查询日志中（可选项） log_output：日志存储方式。log_output = &#39;FILE&#39; 表示将日志存入文件，默认值是 FILE。log_output = &#39;TABLE&#39; 表示将日志存入数据库，这样日志信息就会被写入到 mysql.slow_log 表中。MySQL 数据库支持两种同时日志存储方式，配置的时候以逗号隔开即可。如：log_output = &#39;FILE, TABLE&#39;。日志记录到系统的专用日志表中，要比记录到文件耗费更多的系统资源，因此对于需要启用慢查询日志，又需要能够获得更高的系统性能，那么建议优先记录到文件。 MySQL 慢查询开启 MySQL 慢查询 方式一：在 my.ini 增加几行：主要是慢查询的定义时间，以及慢查询 log 日志记录（slow_query_log） 方式二：通过 MySQL 数据库开启慢查询 分析慢查询日志直接分析 MySQL 慢查询日志，利用 explain 关键字可以模拟优化器执行 SQL 查询语句，来分析 SQL 慢查询语句。例如： 1EXPLAIN SELECT * FROM res_user ORDER BY modifiedtime LIMIT 0, 1000 得到如下结果： table | type | possible_keys | key | key_len | ref | rows | Extra 显示结果分析： table：显示这一行的数据是关于那张表的 type：这是重要的列，显示连接使用了何种类型。从最好到最差的连接类型为：const、eq_reg、ref、range、index 和 all rows：显示需要扫描的行数 key：使用的索引 常见的慢查询优化索引没起作用的情况使用 LIKE 关键字的查询语句在使用 LIKE 关键字进行查询的查询语句中，如果匹配字符串的第一个字符为 “%”，索引不会起作用。只有 “%” 不在第一个位置索引才会起作用 使用多列索引的查询语句MySQL 可以为多个字段创建索引。一个索引最多可以包括 16 个字段。对于多列索引，需要符合最左前缀匹配原则 优化数据库结构合理的数据库结构不仅可以使数据库占用更小的磁盘空间，而且能够使查询速度更快。数据库结构的设计，需要考虑数据冗余、查询和更新的速度、字段的数据类型是否合理等多方面的内容。 将字段很多的表分解成多个表对于字段比较多的表，如果有些字段的使用频率很低，可以将这些字段分离出来形成新表。因为当一个表的数据量很大时，会由于使用频率低的字段的存在而变慢。 增加中间表对于需要经常联合查询的表，可以建立中间表以提高查询效率。通过建立中间表，把需要经常联合查询的数据插入到中间表中，然后将原来的联合查询改为对中间表的查询，一次来提高查询效率 优化 LIMIT 分页在系统中需要分页的操作通常会使用 limit 加上偏移量的方法实现，同时加上合适的 order by 子句。如果有对应的索引，通常效率会不错，否则 MySQL 需要做大量的文件排序操作。 一个头疼的问题就是当偏移量很大的时候，例如可能是 limit 10000, 20 这样的查询，这时 MySQL 需要查询 10020 条然后只返回最后 20 条，前面的 10000 条记录都将被舍弃，这样的代价很高。 优化此类查询的一个最简单的方法时尽可能地使用索引覆盖扫描，而不是扫描所有的列。然后根据需要做一次关联操作再返回所需的列，对于偏移量很大的时候这样做的效率会得到很大提升。 对于下面的查询： 1SELECT id, title FROM collect LIMIT 90000, 10 该语句存在的最大问题在于 limit M, N 中偏移量 M 太大（我们暂不考虑筛选字段上要不要添加索引的影响），导致每次查询都要先从整个表中找到满足条件的前 M 条记录，之后舍弃这 M 条记录并从第 M + 1 条记录开始再依次找到 N 条满足条件的记录。 如果表非常大，且筛选字段没有合适的索引，且 M 特别大，那么这样的代价是非常高的。如果我们下一次的查询能从前一次查询结束后标记的位置开始查找，找到满足条件的 100 条记录，并记下下一次查询应该开始的位置，以便于下一次查询能直接从改位置开始，这样就不必每次查询都先从整个表中先找到满足条件的前 M 条记录，舍弃，在从 M + 1 开始再找到 100 条满足条件的记录了 方法一：先查询出主键 id 值 1SELECT id, title FROM collect WHERE id &gt;= (SELECT id FROM collect ORDER BY id LIMIT 90000, 1) LIMIT 10; 原理：先查询出 90000 条数据对应的主键 id 的值，然后直接通过改 id 的值直接查询该 id 后面的数据。 方法二：“关延迟联” 如果这个表非常大，那么这个查询可以改写成如下的方式： 1SELECT news.id, news.description FROM news INNER JOIN (SELECT id FROM news ORDER BY title LIMIT 50000, 5) as myNew using(id); 这里的 “关延迟联” 将大大提升查询的效率，它让 MySQL 扫描尽可能少的页面，获取需要的记录后再根据关联列回原表查询需要的所有列。这个技术也可以用在优化关联查询中的 LIMIT。 方法三：建立复合索引 下面的 SQL 语句 1SELECT * FROM acct_trans_log WHERE acct_id = 3095 ORDER BY create_time DESC LIMIT 0, 10 可以通过建立复合索引 acct_id 和 create_time 进行优化 日志分析工具 mysqldumpslow在生产环境中，如果要手工分析日志，查找、分析 SQL，显然是个体力活，MySQL 提供了日志分析工具 mysqldumpslow 查看 mysqldumpslow 的帮助信息： 1234567891011121314Usage: mysqldumpslow [ OPTS... ] [ LOGS... ]Parse and summarize the MySQL slow query log. Options are--verbose verbose--help write this text to standard output-v verbose-s ORDER what to sort by (al, at, ar, c, l, r, t), 'at' is default ar: average rows sent c: count r: rows sent-r reverse the sort order (largest last instead of first)-a don't abstract all numbers to N and strings to 'S'-g PATTERN grep: only consider stmts that include this string default is '*', i.e. match all-l don't subtract lock time from total time -s，是表示按照何种方式排序， c：访问计数 l：锁定时间 r：返回记录 t：查询时间 al：平均锁定时间 ar：平均返回记录数 at：平均查询时间 -t，是 top n 的意思，即为返回前面多少条的数据； -g，后边可以写一个正则匹配模式，大小写不敏感的； 比如，得到返回记录集最多的 10 个 SQL 1mysqldumpslow -s r -t 10 /database/mysql/mysql06_slow.log 得到访问次数最多的 10 个 SQL： 1mysqldumpslow -s c -t 10 /database/mysql/mysql06_slow.log 得到按照时间排序的前 10 条里面含有左连接的查询语句： 1mysqldumpslow -s t -t 10 -g "left join" /database/mysql/mysql06_slow.log 另外建议在使用这些命令时结合 | 和 more 使用，否则有可能出现刷屏的情况 1mysqldumpslow -s r -t 20 /mysqldata/mysql/mysql06_slow.log | more 参考资料常见 MySQL 的慢查询优化方式]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 的一些优化策略]]></title>
    <url>%2FCKING.github.io%2F2020%2F05%2F12%2FMySQL-%E7%9A%84%E4%B8%80%E4%BA%9B%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[MySQL 性能最大数据量抛开数据量和并发数，谈性能都是耍流氓。MySQL 没有限制单表最大记录数，它取决于操作系统对文件大小的限制。 文件系统 单文件大小限制 FAT32 最大 4G NTFS 最大 64G NTFS5.0 最大 2TB EXT2 块大小为 1024 字节，文件最大容量 16GB；块大小为 4096 字节，文件最大容量 2TB EXT3 块大小为 4KB，文件最大容量为 4TB EXT4 理论可以大于 16TB 《阿里巴巴 Java 开发手册》提出单表行数超过 500 万行或者单表容量超过 2GB，才推荐分库分表。性能有综合因素决定，抛开业务复杂度，影响程度依次是硬件配置、MySQL 配置、数据表设计、索引优化。500 万这个值仅供参考，并非铁律 最大并发数并发数是指同一时刻数据库能处理多少个请求，由 max_connections 和 max_user_connections 决定。max_connections 是指 MySQL 实例的最大连接数，上限值是 16384，max_user_connections 是指每个数据库用户的最大连接数。 MySQL 会为每个连接提供缓冲区，意味着消耗更多的内存。如果连接数设置太高硬件吃不消，太低又不能充分利用硬件。一般要求两者比值超过 10%，计算方法如下： 1max_used_connections / max_connections * 100% = 3 / 100 * 100% ≈ 3% 查看最大连接数与相应最大连接数： 12show variables like &apos;%max_connections%&apos;;show variables like &apos;%max_user_connections%&apos;; 在配置文件 my.cnf 中修改最大连接数 123[mysqld]max_connections = 100max_user_connections = 20 查询耗时 0.5 秒建议将单次查询耗时控制在 0.5 秒 以内，0.5 秒是个经验值，源于用于体验的 3 秒原则。如果用户的操作 3 秒内没有相应，将会厌烦甚至退出。响应时间 = 客户端 UI 渲染耗时 + 网络请求耗时 + 应用程序处理耗时 + 查询数据库耗时。0.5 秒就是留给数据库 1/6 的处理时间 实施原则相比 NoSQL 数据库，MySQL 是个娇气脆弱的家伙。它就像体育课上的小学生，一点纠纷就和同学闹别扭（扩容难），跑两步就气喘吁吁（容量小并发低），常常身体不适要请假（SQL 约束太多）。如今大家都会搞点分布式，应用程序扩容比数据库要容易得多，所以实施原则是数据库少干活，应用程序多干活。 充分利用但不滥用索引，须知索引也消耗磁盘和 CPU 不推荐使用数据库函数格式化数据，交给应用程序处理 不推荐使用外键约束，用应用程序保证数据准确性 写多读少的场景，不推荐使用唯一索引，用应用程序保证唯一性 适当冗余字段，尝试创建中间表，用应用程序计算中间结果，用空间换时间 不允许执行极度耗时的事务，配合应用程序拆分成更小的事务 预估重要数据表（比如订单表）的负载和数据增长态势，提前优化 数据表设计数据类型 数据类型的选择原则：更简单或者占用空间更小。 如果长度能够满足，整型尽量使用 tinyint、smallint、medium_int 而非 int 如果字符串长度确定，采用 char 类型 如果 varchar 能够满足，不采用 text 类型 精度要求较高的使用 decimal 类型，也可以使用 BigInt，比如精度两位小数就乘以 100 后保存 尽量采用 timestamp 而非 datetime 类型 占据字符 描述 datatime 8 字节 ‘1000-01-01 00:00:00.000000’ to ‘9999-12-31 23:59:59.999999’ timestamp 4 字节 ‘1970-01-01 00:00:01.000000’ to ‘2038-01-19 03:14:07.999999’ 相比 datetime，timestamp 占用更少的空间，以 UTC 的格式存储自动转换时区 避免空值MySQL 中字段为 NULL 时依然占用空间，会使索引、索引统计更加复杂。从 NULL 值更新到非 NULL 无法做到原地更新，容易产生索引分裂影响性能。尽可能将 NULL 值用有意义的值代替，也能避免 SQL 语句里面包含 is not null 的判断。 text 类型优化由于 text 字段存储大量数据，表容量会很早涨上去，影响其他字段的查询性能。建议抽取出来放在子表里，用业务主键关联 索引优化索引分类 普通索引：最基本的索引 组合索引：多个字段上建立的索引，能够加快复合查询条件的检索 唯一索引：与普通索引类似，但索引列的值必须唯一，允许有空值 组合唯一索引：列值的组合必须唯一 主键索引：特殊的唯一索引，用于唯一标识数据表中的某一条记录，不允许有空值，一般用 primary key 约束 全文索引：用于海量文本的查询，MySQL 5.6 之后的 InnoDB 和 MyISAM 均支持全文索引。由于查询精度以及扩展性不佳，更多的企业选择 Elasticsearch。 索引优化分页查询很重要，如果查询数据量超过 30%，MySQL 不会使用索引 单表索引数不超过 5 个，单个索引字段不超过 5 个 字符串可使用前缀索引，前缀长度控制在 5 - 8 个字符 字段唯一性太低，增加索引没有意义。如：是否删除、性别 合理使用覆盖索引，如下： 1SELECT login_name, nick_name FROM member WHERE login_name = ? login_name、nick_name 两个字段简历组合索引，比 login_name 简单索引更快。 SQL 优化分批处理鱼塘挖开小口子放水，水面有各种漂浮物。浮萍和树叶总能顺利通过出水口，而树枝会挡住其他物体通过，有时还会卡住，需要人工处理。MySQL 就是鱼塘，最大并发数和网络带宽就是出水口，用户 SQL 就是漂浮物，不带分页参数的查询或者影响大量数据的 update 和 delete 操作，都是树枝，我们要把它打散分批处理。 举个例子，有这么一个业务：更新用户所有已过期的优惠券为不可用状态。SQL 语句如下： 1UPDATE coupon SET status = 0 WHERE expire_data &lt;= #&#123;currentDate&#125; and status = 1 如果大量优惠券需要更新为不可用状态，执行这条 SQL 可能会堵死其他 SQL，分批处理伪代码如下： 12345678910int pageNo = 1;int PAGE_SIZE = 100;while(true) &#123; List&lt;Integer&gt; batchIdList = queryList("SELECT id FROM 'coupon' WHERE expire_data &lt;= #&#123;currentData&#125; AND status = 1 LIMIT #&#123;(pageNo - 1) * PAGE_SIZE&#125;, #&#123;PAGE_SIZE&#125;"); if(CollectionUtils.isEmpty(batchIdList)) &#123; return; &#125; update("UPDATE 'coupon' SET status = 0 WHERE status = 1 AND id IN #&#123;batchIdList&#125;"); pageNo++;&#125; 操作符 &lt;&gt; 优化通常 &lt;&gt; 操作符无法使用索引，举例如下，查询金额不为 100 元的订单： 1SELECT id FROM orders WHERE amount != 100; 如果金额为 100 的订单极少，这种数据分布严重不均的情况下，有可能使用索引。鉴于这种不确定性，采用 union 聚合搜索结果，改写方法如下： 123SELECT id FROM orders WHERE amount &gt; 100UNION ALLSELECT id FROM orders WHERE amount &lt; 100 and amount &gt; 0 OR 优化在 InnoDB 引擎下 or 无法使用组合索引，例如： 1SELECT id, product_name FROM orders WHERE mobile_no = &apos;13421800407&apos; OR user_id = 100 OR 无法命中 mobile_no + user_id 的组合索引，可采用 union，如下： 123SELECT id, product_name FROM orders WHERE mobile_no = &apos;13421800407&apos;UNIONSELECT id, product_name FROM orders WHERE user_id = 100 此时 id 和 product_name 字段都有索引，查询才最高效 IN 优化IN 适合主表大子表小，EXIST 适合主表小子表大。由于查询优化器的不断升级，很多场景这两者性能差不多一样了。尝试改为 JOIN 查询，举例如下： 1SELECT id FROM orders WHERE user_id IN (SELECT id FROM user WHERE level = &apos;VIP&apos;) 采用 JOIN 如下所示： 1SELECT o.id FROM orders o LEFT JOIN user u ON o.user_id = u.id WHERE u.level = &apos;VIP&apos; 不做列运算通常在查询条件列运算会导致索引失效，如下： 1SELECT id FROM order WHERE date_format(create_time, &apos;%Y-%m-%d&apos;) = &apos;2019-07-01&apos; date_format 函数会导致这个查询无法使用索引，改写后： 1SELECT id FROM order WHERE create_time BETWEEN &apos;2019-07-01 00:00:00&apos; AND &apos;2019-07-01 23:59:59&apos; 避免 Select all如果不查询表中所有的列，避免使用 SELECT *，它会进行全表扫描，不能有效利用索引 LIKE 优化LIKE 用于模糊查询，举个例子（field 已建立索引）： 1SELECT column FROM table WHERE field LIKE &apos;%keyword%&apos;; 上面那个查询未命中索引，换成下面的写法： 1SELECT column FROM table WHERE field LIKE &apos;keyword%&apos; 去除了前面的 % 查询将会命中索引，但是产品经理一定要前后模糊匹配呢？全文索引 fulltext 可以尝试一下，但 Elasticsearch 才是终极武器 JOIN 优化join 的实现是采用 Nested Loop Join 算法，就是通过驱动表的结果集作为基础数据，通过该数据作为过滤条件到下一个表总循环查询数据，然后合并结果。如果有多个 join，则将前面的结果集作为循环数据，再次到后一个表中查询数据。 驱动表和被驱动表尽可能增加查询条件，满足 ON 的条件而少用 WHERE，用小结果集驱动大结果集。 被驱动表的 join 字段上加上索引，无法建立索引的时候，设置足够的 Join Buffer Size 禁止 join 连接三个以上的表，尝试增加冗余字段。 Limit 优化limit 用于分页查询时往后翻性能越差，解决的原则：缩小扫描范围，如下所示： 1SELECT * FROM orders ORDER BY id DESC LIMIT 100000, 10 耗时 0.4 秒 1SELECT * FROM orders ORDER BY id DESC LIMIT 1000000, 10 耗时 5.2 秒 先筛选出 ID 缩小查询范围，写法如下： 1SELECT * FROM orders WHERE id &gt; (SELECT id FROM orders ORDER BY id DESC limit 1000000, 1) ORDER BY id DESC limit 0, 10 耗时 0.5 秒 如果查询条件仅有主键 ID，写法如下： 1SELECT id FROM orders WHERE id BETWEEN 1000000 AND 1000010 ORDER BY id DESC 耗时 0.3 秒 如果以上方案还是很慢，只好用游标了。 参考资料一手好 SQL 是如何炼成的]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写入数据库的一行数据在磁盘上是怎么存储的]]></title>
    <url>%2FCKING.github.io%2F2020%2F05%2F07%2F%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%B8%80%E8%A1%8C%E6%95%B0%E6%8D%AE%E5%9C%A8%E7%A3%81%E7%9B%98%E4%B8%8A%E6%98%AF%E6%80%8E%E4%B9%88%E5%AD%98%E5%82%A8%E7%9A%84%2F</url>
    <content type="text"><![CDATA[引入数据页当我们要执行 update 之类的 SQL 语句的时候，必然涉及到对数据的更新操作。那么此时对数据是在哪里更新的？此时并不是直接去更新磁盘文件，而是要把磁盘上的一些数据加载到内存里来，然后对内存里的数据进行更新，同时写 redo log 到磁盘上去。如图： 这里就有一个问题，难道我们每次都是把磁盘里的一条数据加载到内存里去进行更新，然后下次要更新别的数据的时候，再从磁盘里加载另外一条数据到内存里去？ 这样效率明显是很差的。所以 InnoDB 存储引擎在这里引入了一个「数据页」的概念，也就是把数据组织成一页一页的概念，每一页有 16kb，然后每次加载磁盘的数据到内存里的时候，是至少加载一页数据进去，甚至是多页数据进去。 假设我们有一次要更新一条 id = 1 的数据： 1update xxx set xxx = xxx where id = 1 那么此时它会把 id = 1 这条数据所在的一页数据都加载到内存里去，这一页数据里，可能还包含了 id = 2，id = 3 等其他数据。然后我们更新完 id = 1 的数据之后，接着更新 id = 2 的数据，那么此时就不用再次读取磁盘里的数据了，因为 id = 2 本身就跟 id = 1 在一页里，之前这一页数据就加载到内存里了，直接更新内存里的数据页中的 id = 2 这条数据即可。 这就是数据页的意义，磁盘和内存之间的数据交换通过数据页来执行，包括内存里更新后的脏数据。刷回磁盘的时候，也是至少一个数据页刷回去。 MySQL 物理数据存储格式对数据页中的每一行数据，它在磁盘上是怎么存储的？其实这里涉及到一个概念，就是行格式。我们可以对一个表指定它的行存储格式是怎么样的，比如我们这里用 COMPACT 格式 12CREATE TABLE table_name (columns) ROW_FORMAT = COMPACTALTER TABLE table_name ROW_FORMAT = COMPACT 你可以在建表的时候，就指定一个行存储的格式，也可以后续修改行存储的格式。这里指定了一个 COMPACT 行存储格式，在这种格式下，每一行数据它实际存储的时候，大概格式类似下面： 1变长字段的长度列表, null 值列表, 数据头, column01 的值, column02 的值, column0n 的值... 对于每一行数据，它其实存储的时候都会有一些头字段对这行数据进行一定的描述，然后再放上它这一行数据每一列的具体的值，这就是所谓的行格式。除了 COMPACT 以为，还有其他几种行存储格式，基本都大同小异。 变长字段在磁盘中的存储在 MySQL 里有一些字段的长度是变长的，是不固定的，比如 VARCHAR(10) 之类的这种类型的字段，实际上它里面存放的字符串的长度是不固定的，有可能是 hello 这么一个字符串，也可能是 a 这么一个字符串。 假设现在有一行数据，它的几个字段的类型为 VARCHAR(10)，CHAR(1)，CHAR(1)。那么它第一个字段是 VARCHAR(10)，这个长度是可能变化的，所以这一行数据可能就是类似于：hello a a。即第一个字段的值是 hello，后面两个字段的值都是一个字符，就是一个 a 然后另外一行数据，同样也是这几个字段，它的第一个字段的值可能是 「hi」，后面两个字段也是「a」，所以这一行数据可能是类似于：hi a a。一共三个字段，第一个字段的长度是不固定的，后面两个字段的长度都是固定的 1 个字符 假设你把上述两条数据写入了一个磁盘文件里，两行数据是挨在一起的，那么这个时候在一个磁盘文件里可能有下面的两行数据： hello a a hi a a 其实，平时你看到的表里的很多行数据，最终落地到磁盘里的时候，都是上面那种样子的，一大坨数据放在一个磁盘文件里都挨着存储的。 存储在磁盘文件里的变长字段为什么难以读取现在我们要读取上面的磁盘文件的数据，要读取出来 hello a a 这一行数据，这个过程要更困难一些。第一个问题就是，从这个磁盘文件里读取的时候，到底哪些内容是一行数据？因为这个表里的第一个字段是 VARCHAR(10) 类型的，第一个字段的长度是多少我们是不知道的 所以有可能你读取出来「hello a a hi」是一行数据，也可能读取出来「hello a」是一行数据。你在不知道一行数据的每个子弹到底是多少长度的情况下，胡乱读取时不现实的，根本不知道磁盘文件里混成一坨的数据里，哪些数据是你要读取的一行？ 引入变长字段的长度列表所以说才要在存储每一行数据的时候，都保存一下它的变长字段的长度列表，这样才能解决一行数据的读取问题。即，你在存储「hello a a」这行数据的时候，要带上一些额外的附加信息，比如第一块就是它里面的变长字段的长度列表。 也就是说，这个 hello 是 VARCHAR(10) 类型的变长字段的额值，那么这个 hello 字段值的长度是多少？我们看到 「hello」的长度是 5，十六进制就是 0x05，所以此时会在 hello a a 前面补充一些额外信息，首先就是变长字段的长度列表，你会看到这样数据在磁盘里存储的时候，其实是类似如下的格式：0x05 null 值列表 数据头 hello a a 这个时候你有两行数据，还有一行数据可能就是：0x02 null 值列表 数据头 hi a a，两行数据放在一起存储在磁盘文件里，看起来是如下所示的： 10x05 null 值列表 数据头 hello a a 0x02 null 值列表 hi a a 如何读取变长字段假设你要读取「hello a a」这行数据，你首先会知道这个表里的三个字段的类型是 VARCHAR(10) CHAR(1) CHAR(1)，那么此时你先要读取第一个字段的值，那么第一个字段是变长的，它的实际长度是多少？ 此时你会发现第一行数据的开头有一个变长字段的长度列表，里面会读取到一个 0x05 这个十六进制的数字，发现第一个变长字段的长度是 5，于是按照长度为 5， 读取出来第一个字段的值，就是 hello。接着你知道后续两个字段都是 CHAR(1)，长度都是固定的 1 个字符，于是此时就以此按照长度为 1 读取出来后续两个字段的值，分别是 a a，于是最终你会读取出 hello a a 这一行数据 假设你要读取第二行数据，你先看一下第二行数据后的变长字段的长度列表，发现它第一个变长字段的长度是 0x02，于是就读取长度为 2 的字段值，就是 hi，再读取两个长度固定为 1 的字符值，都是 a，此时读取出来 hi a a 这行数据 多个变长字段，如何存放他们的长度如果说有多个变长字段，如何存放它们的长度？比如一行数据有 VARCHAR(10) VARCHAR(5) VARCHAR(20) CHAR(1) CHAR(1) 一共 5 个字段，其中三个是变长字段，此时假设一行数据是这样的：hello hi hao a a 此时在磁盘中存储的，必须在它开头的变长字段长度列表中存储几个变长字段的长度，一定要注意，它这里是逆序存储的。 也就是说先存放 VARCHAR(20) 这个字段的长度，然后存放 VARCHAR(5) 这个字段的长度，最后存放 VARCHAR(10) 这个字段的长度。现在「hello hi hao」三个字段的长度分别是 0x05 0x02 0x03，但是实际存放在变长字段长度列表的时候，是逆序放的，所以一行数据实际存储可能是下面这样的： 10x03 0x02 0x05 null 值列表 头字段 hello hi hao a a NULL 字段值在磁盘上的存储所谓的 NULL 值列表，顾名思义，说的就是你一行数据里可能有的字段是 NULL，比如你有一个 name 字段，它是允许为 NULL 的，那么实际上在存储的时候，如果你没给它赋值，它这个字段的值就是 NULL。 假设这个字段的 NULL 值我们在磁盘上存储的时候，就是按照 “NULL” 这么个字符串来存储，是不是很浪费空间？本来它就是个 NULL，说明什么值都没有，你还给它存个 “NULL” 字符串，这是何必呢？所以实际在磁盘上存储数据的时候，一行数据里的 NULL 值是肯定不会直接按照字符串的方式存放在磁盘上浪费空间的。 NULL 值是以二进制 bit 位来存储的那 NULL 值列表在磁盘上如何存储呢？其实，对所有的 NULL 值，不通过字符串在磁盘上存储，而是通过二进制的 bit 位来存储，一行数据里假设有多个字段的值都是 NULL，那么这多个字段的 NULL，就会以 bit 位的形式来存放在 NULL 值列表中。 举个例子，先看下面的建表语句： 1234567CREATE TABLE customer ( name VARCHAR(10) NOT NULL, address VARCHAR(20), gender CHAR(1), job VARCHAR(30), school VARCHAR(50))ROW_FORMAT = COMPACT; 上面一个客户表，里面有 5 个字段，分别为 name、address、gender、job、school，代表了客户的姓名、地址、性别、工作以及学校。其中有 4 个变长字段，还有一个定长字段，然后第一个 name 字段是声明了 NOT NULL 的，就是不能为 NULL，其它 4 个字段都可能是 NULL 的 假设这个表里有这么一行数据：jack NULL m NULL xx_school，它的 5 个字段里有两个字段都是 NULL。我们看看它在磁盘上是怎么存储的。 结合案例看一行数据的磁盘存储格式上面表里的那行数据，在磁盘上应该如何存储呢？因为它有多个变长字段，还有多个字段允许为 NULL。首先我们回顾一下，一行数据在磁盘上的存储格式应该是下面这样： 1变长字段长度列表 NULL 值列表 头信息 column = value1 column2 = value2 ... columnN = valueN 所有先看变长字段长度列表应该放什么东西。它一共有 4 个变长字段，按照之前说的，是不是应该按照逆序的顺序，先放 school 字段的长度，再放 job、address、name 几个字段的长度？ 说起来是这样，但其实这里要区分一个问题，那就是如果这个变长字段的值是 NULL，就不用在变长字段长度列表里存放它的值长度了，所以在上面那行数据中，只有 name 和 school 两个变长字段是有值的，把它们的长度按照逆序放在变长字段长度列表中即可。如下： 10x09 0x04 NULL 值列表 头信息 column1 = value1 column2 = value2 ... columnN = valueN 接着来看 NULL 值列表，这个 NULL 值列表是这样存放的，你所有允许值为 NULL 的字段，注意，是允许值为 NULL，不是说一定值就是 NULL 了，只要是允许你为 NULL 的字段，在这里每个字段都有一个二进制 bit 位的值，如果 bit 值是 1 说明是 NULL，如果 bit 值是 0 说明不是 NULL 例如上面 4 个字段都允许为 NULL，每个人都会有一个 bit 位，这一行数据的值是 jack NULL m NULL xx_school，然后其中 2 个字段是 NULL，2 个字段不是 NULL，所以 4 个 bit 位应该是：1010 但是实际放在 NULL 值列表的时候，它是按逆序放的，所以在 NULL 值列表里，放的是：0101，整体这一行数据看着是下面这样的： 10x09 0x04 0101 头信息 column1 = value1 column2 = value2 ... columnN = valueN 另外就是它实际 NULL 值列表存放的时候，不会说仅仅是 4 个 bit 位，它一般起码是 8 个bit 位的倍数，如果不足 8 个 bit 为就高位补 0，所以实际存放看起来是如下的： 10x09 0x04 00000101 头信息 column1 = value1 column2 = value2 ... columnN = valueN 磁盘上的一行数据如何读取结合上面的磁盘上的数据存储格式来思考一下，一行数据到底是如何读取出来的？ 10x09 0x04 00000101 头信息 column1 = value1 column2 = value2 ... columnN = valueN 首先它必然要把变长字段列表和 NULL 值列表读取出来，通过综合分析一下，就知道有几个变长字段，哪几个变长字段是 NULL。此时就可以从变长字段长度列表中解析出来不为 NULL 的变长字段的长度，然后也知道哪几个字段是 NULL 的，此时根据这些信息，就可以从实际的列值存储区域里，把你每个字段的值读取出来了。 如果是变长字段的值，就按照它的值长度来读取，如果是 NULL，就知道它是个 NULL，没有值存储，如果是定长字段，就按照定长长度来读取，这样就可以把你一行数据的值都读取出来了。 磁盘文件中，40个 bit 位的数据头以及真实数据是如何存储的上面说了在磁盘上存储数据的时候，每一行数据都会有变长字段长度列表，逆序存放这行数据里的变长字段的长度，然后会有 NULL 值列表，对于允许为 NULL 的字段都会有一个 bit 位标识那个字段是否为 NULL，也是逆序排列的 其实每一行数据存储的时候，还得有 40 个 bit 位的数据头，这个数据头是用来描述这行数据的。这 40 个 bit 位里，第一个 bit 位和第二个 bit 位，都是预留位，是没任何含义的。 然后接下来有一个 bit 位是 delete_mask，它标识的是这行数据是否被删除了。在 MySQL 里删除一行数据的时候，未必是立马把它从磁盘上清理掉，而是给它在数据头里搞 1 个 bit 标记它已经被删了。 其实大家现在看这些数据头，只要先留有一个印象就可以了，知道每一行数据都有一些数据头，不同的数据头都是用来描述这行数据的一些状态和附加信息的 然后下一个 bit 位是 min_rec_mask，这个 bit 位先不用关注 ，它其实就说在 B+ 数里每一层的非叶子节点里的最小值都有这个标记 接下来有 4 个 bit 位是 n_owned，这个暂时也不用去管它。它其实就是记录了一个记录数 接着还有 13 个 bit 位是 heap_no，它代表的是这样数据在记录堆里的位置 然后是 3 个 bit 位的 record_type，这就是说这行数据的类型。0 代表的是普通类型，1 代表的是 B+ 树非叶子节点，2 代表的是最小值数据，3 代表的是最大值数据 最后是 16 个 bit 的 next_record，这个是指向它下一条数据的指针 每一行的实际数据在磁盘上是如何存储的接下来我们看看真实数据是如何存储的。首先我们在存储真实数据的时候，并没什么特别的，就是按照我们那个字段里的数据值去存储就行了。 比如之前说了一个例子，有一行数据是 jack NULL m NULL xx_school，那么它真实存储大致如下： 10x09 0x04 00000101 0000000000000000000010000000000000011001 jack m xx_school 刚开始先是它的变长字段的长度，用十六进制来存储，然后是 NULL 值列表，指出了谁是 NULL，接着是 40 个 bit 位的数据头，然后是真实的数据值，就放在后面。 在读取这个数据的时候，它会根据变长字段的长度，先读取出来这个 jack 这个值，因为它的长度是 4，就读取 4 个长度的数，jack 就出来了。然后发现第二个字段是 NULL，就不用读取了。第三个字段是变长字段，直接读取 1 个字符就可以了，就是 m 这个值。第四个字段是 NULL，不用读取了。第五个字段是变长字段长度是 9，读取出来 xx_school 就可以了。 但是，真正在磁盘上存储的时候，我们那些字符串不是直接这么存储在磁盘上的。实际上字符串这些东西都是根据我们数据库指定的字符集编码，就行编码之后在存储的，所以大致看起来一行数据是如下所示的： 10x09 0x04 00000101 000000000000000000010000000000000011001 616161 636320 6262626262 如上，我们的字符串和其他类型的数值最终都会根据字符集编码，搞成一些数字和符号存储在磁盘上。 所以其实一行数据是如何存储的，我们应该很清楚了。其实，在实际存储一行数据的时候，会在它的真实数据部分，加入一些隐藏字段。 首先有一个 DB_ROW_ID 字段，这就是一个行的唯一标识，是它数据库内部给你搞的一个标识，不是你的主键 ID 字段。如果我们没有指定主键和 unique key 唯一索引的时候，它就内部自动加一个 ROW_ID 作为主键 接着是一个 DB_TRX_ID 字段，这是跟事务相关的，它是说这是哪个事务更新的数据，这是事务 ID 最后是 DB_ROLL_PTR 字段，这是回滚指针，是用来进行事务回滚的。 所以如果你加上这几个隐藏字段之后，实际一行数据可能看起来如下所示： 120x09 0x04 00000101 000000000000000100000000000001 10010000000094C (DB_ _ROW_ ID)00000000032D (DB_ TRX_ ID) EA000010078E (DB_ ROL PTR) 616161 636320 6262626262 上面几个隐藏字段都加了括号说明了，那基本就是最终在磁盘上一行数据的样子了。 行溢出通过上面我们初步了解到，实际上我们每一行数据都是放在一个数据页里的，这个数据页默认的大小是 16KB。但是，万一一行数据的大小超过了页的大小怎么办呢？ 比如有一个表的字段类型是 VARCHAR(65532)，意思就是最大可以包含 65532 个字符，这就远大于 16KB 的大小了，也就是说这一行的数据的这个字段远超一个数据页的大小了 这个时候实际上会在那一页里存储你这行数据，然后在那个字段中，仅仅包含它一部分数据，同时包含一个 20 个字节的指针，指向了其他的一些数据页，那些数据页用链表串联起来，存放这个 VARCHAR(65532) 超大字段里的数据。如图： 上面的这个过程，其实就是 行溢出，就是说一行数据存储的内容太多了，一个数据页都放不下，此时只能溢出这个数据页，把数据页存放到其他数据页里去，那些数据页就叫做溢出页。包括其他的一些字段类型都是一样的，比如 TEXT、BLOB 这种类型的字段，都有可能出现溢出，然后一行数据就会存储在多个数据页里。 讲到这里，我们可以做一点总结。当我们在数据库插入一行数据的时候，实际上是在内存里插入一个有复杂存储结构的一行数据，然后随着一些条件的发生，这行数据会被刷到磁盘文件里去。在磁盘文件里存储的时候，这行数据也是按照复杂的存储结构去存放的。 而且每一行数据都是放在数据页里的，如果一行数据太大，就会产生行溢出问题，导致一行数据溢出到多个数据页里去，那么这行数据在 Buffer Pool 可能就是存在于多个缓存页里的，刷入到磁盘的时候，也是用磁盘上的多个数据页来存放这行数据的。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 之存储过程与存储函数]]></title>
    <url>%2FCKING.github.io%2F2020%2F05%2F06%2FMySQL-%E4%B9%8B%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%E4%B8%8E%E5%AD%98%E5%82%A8%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[存储过程什么是存储过程存储过程是一组为了完成某项特定功能的 SQL 语句集，其实质上就是一段存储在数据库中的代码，它可以有声明式的 SQL 语句（如 CREATE，UPDATGE，SELETE 等语句）和过程式 SQL 语句（如 IF…THEN…ELSE… 控制结构语句）组成。存储过程思想上很简单，就是数据库 SQL 语言层面的代码封装和重用。 存储过程的优缺点优点 可增强 SQL 语言的功能和灵活性。存储过程可以用流程控制语言编写，有很强的灵活性，可以完成复杂的判断和较复杂的运算。 良好的封装性。存储过程被创建后，可以在程序中被多次调用，而不必担心重写编写该存储过程的 SQL 语句。 高性能。存储过程执行一次后，其执行规划就驻留在高速缓冲存储器中，以后的操作中只需要从高速缓冲器中调用已编译好的二进制代码执行即可，从而提高了系统性能。 缺点存储过程，往往定制化与特定的数据库上，因为支持的编程语言不同。当切换到其他厂商的数据库系统时，需要重写原有的存储过程。 创建存储过程DELIMITER 定界符在 SQL 中服务器处理 SQL 语句默认是以分号作为语句的结束标志，然而在创建存储过程时，存储过程体中可能包含多条 SQL 语句，这些 SQL 语句如果仍以分号作为语句结束符，那么服务器在处理时会以第一条 SQL 语句处的分号作为整个程序的结束符，而不再去处理后面的 SQL 为解决这个问题，通常使用 DELIMITER 命令，将 SQL 语句的结束符临时修改为其他符合。DELIMITER 语法格式为： 1DELIMITER $$ $$ 是用户定义的结束符，通常这个符合可以是一些特殊的符号。另外应该避免使用反斜杠，因为它是转义字符。若希望换回默认的分号作为结束标记，只需要在命令行输入下面的 SQL 语句即可。 1DELIMITER ; 创建存储过程在 MySQL 中，使用 CREATE PROCEDURE 语句来创建存储过程。 12CREATE PROCEDURE p_name([proc_parameter[, ...]])routine_body 其中，语法项 proc_parameter 的语法格式是： 1[IN | OUT | INOUT]parame_name type p_name 用于指定存储过程的名称 proc_parameter 用于指定存储过程中的参数列表。其中，语法项 parame_name 为参数名，type 为参数的类型（类型可以是 MySQL 中任意的有效数据类型）。MySQL 的存储过程支持三种类型的参数，即输入参数 IN，输出类型 OUT，输入输出参数 INOUT。输入参数是使数据可以传递给一个存储过程；输出参数是用于存储过程需要返回的一个操作结果；输入输出参数既可以充当输入参数也可以充当输出结果 语法项 routine_body 表示存储过程的主体部分，也成为存储过程体，其包含了需要执行的 SQL。过程体以关键字 BEGIN 开始，以关键字 END 结束。若只有一条 SQL 可以忽略 BEGIN...END 标志 局部变量在存储过程中可以声明局部变量，用来存储过程体中的临时结果。在 MySQL 中使用 DECLARE 语句来声明局部变量 1DECLARE var_name type [DEFAULT VALUE] var_name 用于指定局部变量的名称；type 用来声明变量的类型；DEFAULT 用来指定默认值，如果没有指定则为 NULL 注意：局部变量只能在存储过程体的 BEGIN…END 语句块中；局部变量必须在存储过程体的开头处声明；局部变量的作用范围仅限于声明它的 BEGIN…END 语句块，其他语句块中的语句不可以使用它。 用户变量用户变量一般以 @ 开头 注意：滥用用户变量会导致程序难以理解及管理 SET 语句在 MySQL 中通过 SET 语句对局部变量赋值，其格式是： 1SET var_name = expr[, var_name2 = expr] ... SELECT…..INTO 语句在 MySQL 中，可以使用 SELECT….INTO 语句把选定的列的值存储到局部变量中，格式是： 1SELECT col_name[,...] INTO var_name[,...] table_expr 其中 col_name 用于指定列名；var_name 用于指定要赋值的变量名；table_expr 表示 SELECT 语句中 FROM 后面的部分 注意：SELECT…INTO 语句返回的结果集只能有一行数据 流程控制语句条件判断语句if-then-else 语句 12345678910111213141516mysql &gt; DELIMITER &amp;&amp; mysql &gt; CREATE PROCEDURE proc2(IN parameter int) -&gt; begin -&gt; declare var int; -&gt; set var=parameter+1; -&gt; if var=0 then -&gt; insert into t values(17); -&gt; end if; -&gt; if parameter=0 then -&gt; update t set s1=s1+1; -&gt; else -&gt; update t set s1=s1+2; -&gt; end if; -&gt; end; -&gt; &amp;&amp; mysql &gt; DELIMITER ; case 语句 12345678910111213141516mysql &gt; DELIMITER &amp;&amp; mysql &gt; CREATE PROCEDURE proc3 (in parameter int) -&gt; begin -&gt; declare var int; -&gt; set var=parameter+1; -&gt; case var -&gt; when 0 then -&gt; insert into t values(17); -&gt; when 1 then -&gt; insert into t values(18); -&gt; else -&gt; insert into t values(19); -&gt; end case; -&gt; end; -&gt; &amp;&amp; mysql &gt; DELIMITER ; 循环语句while …. end while 123456789101112mysql &gt; DELIMITER &amp;&amp; mysql &gt; CREATE PROCEDURE proc4() -&gt; begin -&gt; declare var int; -&gt; set var=0; -&gt; while var&lt;6 do -&gt; insert into t values(var); -&gt; set var=var+1; -&gt; end while; -&gt; end; -&gt; &amp;&amp; mysql &gt; DELIMITER ; repeat …. end repeat 它在执行操作后检查结果，而 while 则是执行前进行检查 12345678910111213mysql &gt; DELIMITER &amp;&amp; mysql &gt; CREATE PROCEDURE proc5 () -&gt; begin -&gt; declare v int; -&gt; set v=0; -&gt; repeat -&gt; insert into t values(v); -&gt; set v=v+1; -&gt; until v&gt;=5 -&gt; end repeat; -&gt; end; -&gt; &amp;&amp; mysql &gt; DELIMITER ; 1234repeat --循环体 until 循环条件 end repeat; loop … end loop loop 循环不需要初始条件，这点和 while 循环相似，同时和 repeat 循环一样不需要结束条件。leave 语句的意义是离开循环 123456789101112131415mysql &gt; DELIMITER &amp;&amp; mysql &gt; CREATE PROCEDURE proc6 () -&gt; begin -&gt; declare v int; -&gt; set v=0; -&gt; LOOP_LABLE:loop -&gt; insert into t values(v); -&gt; set v=v+1; -&gt; if v &gt;=5 then -&gt; leave LOOP_LABLE; -&gt; end if; -&gt; end loop; -&gt; end; -&gt; &amp;&amp; mysql &gt; DELIMITER ; ITERATE 迭代 12345678910111213141516171819mysql &gt; DELIMITER &amp;&amp; mysql &gt; CREATE PROCEDURE proc10 () -&gt; begin -&gt; declare v int; -&gt; set v=0; -&gt; LOOP_LABLE:loop -&gt; if v=3 then -&gt; set v=v+1; -&gt; ITERATE LOOP_LABLE; -&gt; end if; -&gt; insert into t values(v); -&gt; set v=v+1; -&gt; if v&gt;=5 then -&gt; leave LOOP_LABLE; -&gt; end if; -&gt; end loop; -&gt; end; -&gt; &amp;&amp; mysql &gt; DELIMITER ; 游标MySQL 中的游标可以理解为一个可迭代对象（类比 Python 中的列表、字典等可迭代对象），它可以用来存储 select 语句查询到的结果集，这个结果集可以包含多行数据，从而使我们可以使用迭代的方法从游标中依次取出每行数据。 MySQL 游标的特点： 只读：无法通过游标更新基础表中的数据 不可滚动：只能按照 select 语句确定的顺序获取行。不能以相反的顺序获取行。此外。不能跳过行或跳转到结果集中的特定行 敏感。游标分为敏感游标和不敏感游标。敏感游标指向实际数据，不敏感游标使用数据的临时副本。敏感游标比一个不敏感游标执行得更快，因为它不需要临时拷贝数据。MySQL 游标是敏感的。 声明游标游标声明必须在变量声明之后。如果在变量声明之前声明游标，MySQL 将会发出一个错误。游标必须始终与 select 语句相关联。 1DECLARE cursor_name CURSOR FOR select_statement; 打开游标使用 open 语句打开游标，只有先打开游标才能读取数据 1open cursor_name; 读取游标使用 fetch 语句来检索游标指向的一行数据，并将游标移动到结果集中的下一行 1FETCH cursor_name INTO var_name; 关闭游标使用 close 关闭游标 1CLOSE cursor_name; 当游标不再使用时，应该关闭它。当使用 MySQL 游标时，还必须声明一个 notfound 处理程序来处理游标找不到任何行时的情况。因为每次调用 fetch 语句时，游标会尝试依次读取结果集中的每一行数据。当游标到达结果集的末尾时，它将无法获得数据，并且会产生一个条件。处理程序用于处理这种情况 1declare continue handler for not found set type = 1; type 是一个变量，表示游标到达结果集的结尾。 1234567891011121314151617181920212223242526272829303132DELIMITER $$CREATE PROCEDURE phoneDeal()BEGIN DECLARE id varchar(64); -- id DECLARE phone1 varchar(16); -- phone DECLARE password1 varchar(32); -- 密码 DECLARE name1 varchar(64); -- id -- 遍历数据结束标志 DECLARE done INT DEFAULT FALSE; -- 游标 DECLARE cur_account CURSOR FOR select phone,password,name from account_temp; -- 将结束标志绑定到游标 DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE; -- 打开游标 OPEN cur_account; -- 遍历 read_loop: LOOP -- 取值 取多个字段 FETCH NEXT from cur_account INTO phone1,password1,name1; IF done THEN LEAVE read_loop; END IF; -- 你自己想做的操作 insert into account(id,phone,password,name) value(UUID(),phone1,password1,CONCAT(name1,&apos;的家长&apos;)); END LOOP; -- 关闭游标 CLOSE cur_account;END;$$ 调用存储过程使用 call 语句调用存储过程 1CALL sp_name[(传参)]; 删除存储过程使用 drop 语句删除存储过程 1DROP PROCEDURE sp_name 存储函数什么是存储函数存储函数和存储过程一样，都是 SQL 语句组成的代码块。 存储函数不能有输入参数，并且可以直接调用，不需要 call 语句，且必须有一条包含 RETURN 语句。 创建存储函数在 MySQL 中使用 CREATE FUNCTION 语句创建： 1234CREATE FUNCTION fun_name(par_name(par_name type[,...]))RETURNS type[characteristics]fun_body 其中，fun_name 为函数名，并且名字唯一，不能与存储过程重名。par_name 是指定的参数，type 为参数类型；RETURNS 字句用来声明返回值和返回值类型；fun_body 是函数体，所有存储过程中的 SQL 在村塾函数中同样可以使用。但是存储函数体中必须包含一个 RETURN 语句。 characteristics 指定存储过程的特性，有以下取值： LANGUAGE SQL：说明 routine_body 部分是有 SQL 语句组成的，当前系统支持的语言为 SQL ，SQL 是 LANGUAGE 特性的唯一值。 [NOT] DETERMINISTIC：指明存储过程执行的结果是否确定。DETERMINISTIC 表示结果是确定的，每次执行存储过程时，相同的输入会得到相同的输出；NOT DETERMINISTIC 表示结果是不确定的，相同的输入可能得到不同的输出。如果没有指定任意一个值，默认为 NOT [CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA]：指明子程序使用 SQL 语句的限制。CONTAINS SQL 表明子程序包含 SQL 语句，但不包含读写数据语句；NO SQL 表明子程序不包含 SQL 语句；READS SQL DATA 说明子程序包含读数据库的语句；MODIFIES SQL DATA 表明子程序包含写数据的语句。默认情况下，系统会指定为 CONTAINS SQL SQL SECURITY [DEFINER | INVOKER]：指明谁有权限来执行。DEFINER 表明只有定义者才能执行。INVOKER 表示拥有权限的调用者可以执行，默认情况下，系统指定我 DEFINER COMMENT ‘string’：注释信息，用于描述存储过程或函数 123456789101112DELIMITER $$CREATE FUNCTION getAnimalName(animalId int) RETURNS VARCHAR(50)DETERMINISTICbegin declare name VARCHAR(50); set name=(select name from animal where id=animalId); return (name);end$$delimiter;-- 调用select getAnimalName(4) 参考资料Mysql之存储过程与存储函数]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回溯算法]]></title>
    <url>%2FCKING.github.io%2F2020%2F05%2F04%2F%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[解决一个回溯问题，实际上就是一个决策树的遍历过程，你只需要思考三个问题： 路径：也就是已经做出的选择 选择列表：也就是你当前可以做的选择 结束条件：也就是到达决策树底层，无法再做选择的条件 如果你不理解这三个词语的解释，没关系，我们后面会用几个经典的回溯算法问题来帮你理解这些词语是什么意思。现在你先留着隐形。 代码方面，回溯算的的框架： 12345678910111213result = []def backtrack(路径, 选择列表) &#123; if(满足结束条件) &#123; result.add(路径); return; &#125; for(选择 in 选择列表) &#123; 做选择 backtrack(路径, 选择列表) 撤销选择 &#125;&#125; 其核心就是 for 循环里面的递归，在递归调用之前 「做选择」，在递归调用之后「撤销选择」。什么叫做选择和撤销选择？这个框架的底层原理是什么呢？下面我们就通过「全排列」这个问题来解开之前的疑惑。 全排列问题我们在高中的时候就做过排列组合的数学题，我们也知道 n 个不重复的数，全排列共有 n! 个。为了简单清晰起见，我们这次讨论的全排列问题不包含重复的数字。 我们当时是怎么穷举全排列的呢？比如说给三个数 [1, 2, 3]，你肯定不会无规律地乱穷举，一般是这样：先固定第一位为 1，然后第二位可以是 2，那么第三位只能是 3；然后可以把第二位变成 3，第三位就只能是 2 了；然后就只能变化第一位，变成 2，然后再穷举后两位。。。 其实这就是回溯算法，我们高中无师自通就会用，或者有的同学直接画出如下这棵回溯树： 只要从根遍历这棵树，记录路径上的数字，其实就是所有的全排列。我们不妨把这棵树称为回溯算法的「决策树」。 为啥说是决策树呢，因为你在每个节点上其实都在做决策。比如说你站在下图的红色节点上： 你现在就在做决策，可以选择 1 那条树枝，也可以选择 3 那条树枝。为啥只能在 1 和 3 之中选择呢？因为 2 这个树枝在你身后，这个选择之前做过了，而全排列是不允许重复使用数字的。 现在可以解答开头的几个名词：[2] 就是 「路径」，记录你已经做过的选择；[1, 3] 就是 「选择列表」，表示你当前可以做出的选择；「结束条件」就是遍历到树的底层，在这里就是选择列表为空的时候。 如果明白了这几个名词，可以把「路径」和「选择」列表作为决策树上每个节点的属性。比如下图列出了几个节点的属性： 我们定义的 backtrack 函数其实就像一个指针。在这棵树上游走，同时要正确维护每个节点的属性，每当走到树的底层，其「路径」就是一个全排列。 「路径」和「选择」是每个节点的属性，函数在树上游走要正确维护节点的属性，那么就要在这两个特殊时间点搞点动作： 现在，你是否理解了回溯算法的这段核心框架？ 123456789for(选择 in 选择列表) &#123; // 做选择 将该选择从选择列表移除 路径.add(选择) backtrack(路径，选择列表) // 撤销选择 路径.remove(选择) 将该选择再加入列表&#125; 我们只要在递归之前做出选择，在递归之后撤销刚才的选择，就能正确得到每个节点的选择列表和路径。下面看全排序代码： 1234567891011121314151617181920212223242526272829303132List&lt;List&lt;Integer&gt;&gt; res = new LinkedList&lt;&gt;();/* 主函数，输入一组不重复的数字，返回它们的全排列 */List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; // 记录「路径」 LinkedList&lt;Integer&gt; track = new LinkedList&lt;&gt;(); backtrack(nums, track); return res;&#125;// 路径：记录在 track 中// 选择列表：nums 中不存在于 track 的那些元素// 结束条件：nums 中的元素全都在 track 中出现void backtrack(int[] nums, LinkedList&lt;Integer&gt; track) &#123; // 触发结束条件 if (track.size() == nums.length) &#123; res.add(new LinkedList(track)); return; &#125; for (int i = 0; i &lt; nums.length; i++) &#123; // 排除不合法的选择 if (track.contains(nums[i])) continue; // 做选择 track.add(nums[i]); // 进入下一层决策树 backtrack(nums, track); // 取消选择 track.removeLast(); &#125;&#125; 至此，我们就通过全排列问题详解了回溯算法的底层原理。当然，这个算法解决全排列不是很高效，因为对链表使用 contains 方法需要 O(N) 的时间复杂度，有更好的方法通过交换元素打到目的，但是难理解一些，这里就不写了，有兴趣可以自行搜索一下。 但是必须说明的是，不管怎么优化，都符合回溯框架，而且时间复杂度都不可能低于 O(N!)，因为穷举整棵决策树事务无法避免的。这也是回溯算法的一个特点，不像动态规划存在重叠子问题可以优化，回溯算法就是纯暴力穷举，复杂度一般都很高。 明白了 全排列问题，就可以直接套回溯算法框架了，下面简单看看 N 皇后问题。 N 皇后问题这个问题很经典了，我们以力扣网第 51 题的「N 皇后」 题目为例。简单解释一下：给你一个 N * N 个皇后，使得它们不能互相攻击。 PS：皇后可以攻击同一行，同一列，左上左下右上右下四个方向的任意单位。 这个问题本质上跟全排列问题差不多，决策树的每一层表示棋盘上的每一行；每个节点可以做出的选择是，在该行的任意一列放置一个皇后。 直接套用框架： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public List&lt;List&lt;String&gt;&gt; res = new ArrayList&lt;&gt;();/** * 输入棋盘边长n，返回所有合法的放置 * @param n * @return */public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) &#123; String[][] nQueue = new String[n][n]; // "."表示空，"Q"表示皇后，初始化空棋盘 for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; nQueue[i][j] = "."; &#125; &#125; backtrack(nQueue, 0); return res;&#125;/** * @param nQueue 路径：nQueue中小于row的那些行都已经成功放置了皇后 * @param row 选择列表：第row行的所有列都是防止皇后的选择 */private void backtrack(String[][] nQueue, int row) &#123; int n = nQueue.length; // 结束条件：row超过nQueue的最后一行 if (n == row) &#123; List&lt;String&gt; re = new ArrayList&lt;&gt;(); for (String[] list : nQueue) &#123; StringBuilder sb = new StringBuilder(); for (String str : list) &#123; sb.append(str); &#125; re.add(sb.toString()); &#125; res.add(re); return; &#125; for (int col = 0; col &lt; n; col++) &#123; // 排除不合法选择 if (!isValid(nQueue, row, col)) &#123; continue; &#125; // 做选择 nQueue[row][col] = "Q"; // 进入下一行决策 backtrack(nQueue, row + 1); // 撤销选择 nQueue[row][col] = "."; &#125;&#125; 这部分代码，其实跟全排列问题差不多，isValid 函数的实现也很简单： 1234567891011121314151617181920212223242526272829303132333435/** * 是否可以在 nQueue[row][col] 放置皇后 * @param nQueue * @param row * @param col * @return */private boolean isValid(String[][] nQueue, int row, int col) &#123; int n = nQueue.length; // 检查列是否有皇后互相冲突 for (int i = 0; i &lt; row; i++) &#123; if ("Q".equals(nQueue[i][col])) &#123; return false; &#125; &#125; // 检查左上方是否有皇后互相冲突 for (int i = row - 1, j = col - 1; i &gt;= 0 &amp;&amp; j &gt;= 0; i--, j--) &#123; String s = nQueue[i][j]; if ("Q".equals(s)) &#123; return false; &#125; &#125; // 检查右上方是否有皇后互相冲突 for (int i = row - 1, j = col + 1; i &gt;= 0 &amp;&amp; j &lt; n; i--, j++) &#123; String s = nQueue[i][j]; if ("Q".equals(s)) &#123; return false; &#125; &#125; return true;&#125; 函数 backtrack 依然像个决策树上游走的指针，通过 row 和 col 就可以表示函数遍历到的位置，通过 isValid 函数可以将不符合条件的情况剪枝。 如果直接给你这么一大段解法代码，可能是懵逼的。但是现在明白了回溯算法的框架套路，还有啥难理解的？无非是改造做选择的方式，排除不合法选择的方式而已，只要框架存于心，你面对的只剩下小问题了。 有的时候，我们并不想得到所有合法的答案，只想要一个答案，怎么办？比如解数独的算法，找所有解法复杂度太高，只要找到一种解法就可以。那么我们只要稍微修改一下回溯算法的代码即可： 1234567891011121314151617181920212223242526272829303132333435363738/** 函数找到一个答案后就返回true * @param nQueue 路径：nQueue中小于row的那些行都已经成功放置了皇后 * @param row 选择列表：第row行的所有列都是防止皇后的选择 */private boolean tracebacking(String[][] nQueue, int row) &#123; int n = nQueue.length; // 结束条件：row超过nQueue的最后一行 if (n == row) &#123; List&lt;String&gt; re = new ArrayList&lt;&gt;(); for (String[] list : nQueue) &#123; StringBuilder sb = new StringBuilder(); for (String str : list) &#123; sb.append(str); &#125; re.add(sb.toString()); &#125; res.add(re); return true; &#125; for (int col = 0; col &lt; n; col++) &#123; // 排除不合法选择 if (!isValid(nQueue, row, col)) &#123; continue; &#125; // 做选择 nQueue[row][col] = "Q"; // 进入下一行决策 if(tracebacking(nQueue, row + 1)) &#123; return true; &#125; // 撤销选择 nQueue[row][col] = "."; &#125; return false;&#125; 这样修改后，只要找到一个答案，for 循环的后续递归穷举都会被阻断。也许你可以在 N 皇后问题的代码框架上，稍加修改，写一个解数独的算法。 回溯算法框架的应用我们从力扣第 1415 题「长度为 n 的开心字符串中字典序第 k 小的字符串」来应用这个回溯算法的框架。 从题目的描述中，我们可以知道我们的选择路径是 [ &#39;a&#39;, &#39;b&#39;, &#39;c&#39; ]，其中它的结束条件就是当路径的长度打到 n 时就可以结束。而且根据题目的描述，我们不用全部遍历回溯完，只要拿到第 k 小的字符串就可以结束遍历。当我们分析好这些条件的时候，就可以开始应用回溯框架写代码了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 长度为 n 的开心字符串中字典第 k 小的字符串 * @param n * @param k * @return */public String getHappyString(int n, int k) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); happyString(k, new LinkedList&lt;String&gt;(), n, list); if (list.size() &lt; k) &#123; return ""; &#125; return list.get(k - 1);&#125;/** * * @param k 第 k 个字符串 * @param strList 用于记录已经走过的路径 * @param n 字符串长度为 k * @param result 存储符合条件的路径 */private void happyString(int k, LinkedList&lt;String&gt; strList, int n, List&lt;String&gt; result) &#123; // 结束条件：路径的长度等于 n if (strList.size() == n) &#123; StringBuilder sb = new StringBuilder(); strList.stream().forEach(item -&gt; &#123; sb.append(item); &#125;); // 存储路径 result.add(sb.toString()); return; &#125; // 遍历选择列表 for (int i = 0; i &lt; 3; i++) &#123; //当获取到第 k 小的字符串时，可以停止遍历了 if (result.size() == k) &#123; break; &#125; // 如果符合开心字符串的标准 if (isValid(strList, String.valueOf((char) ('a' + i)))) &#123; strList.add(String.valueOf((char) ('a' + i))); happyString(k, strList, n, result); strList.removeLast(); &#125; &#125;&#125;/** * 判断是否符合开心字符串的要求 * @param strs * @param s * @return */private boolean isValid(List&lt;String&gt; strs, String s) &#123; if (strs.size() == 0) &#123; return true; &#125; if (strs.get(strs.size() - 1).equals(s)) &#123; return false; &#125; return true;&#125; 总结回溯算法就是个多叉树的遍历问题，算法框架如下： 12345678def backtrack(路径, 选择列表) &#123; for(选择 in 选择列表) &#123; 做选择 backtrack(路径, 选择列表) 撤销选择 &#125;&#125; 写 backtrack 函数时，需要维护走过的「路径」和当前可以做的「选择列表」，当触发「结束条件」时，将「路径」记入结果集 参考资料回溯算法解题套路框架]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jetty 服务器的 NIO 机制导致堆外内存溢出]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F26%2FJetty-%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84-NIO-%E6%9C%BA%E5%88%B6%E5%AF%BC%E8%87%B4%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[背景引入这是一个使用 Jetty 作为 Web 服务器的时候在某个非常罕见的场景下发生的一次堆外内存溢出的场景。这种场景其实并不多见，只是给大家介绍一下这种场景的排查方法 案例发生有一天收到线上的一个报警：某台机器部署的一个服务突然之间就不可以访问了。此时第一反应就是登陆机器去看日志，这个时候在机器的日志中发现了如下的一些信息： 1234nio handle failed java.lang.OutOfMemoryError: Direct buffer memoryat org.eclipse.jetty.io.nio.xxxat org.eclipse.jetty.io.nio.xxxat org.eclipse.jetty.io.nio.xxx 过多的日志信息给省略掉了，因为都是非常杂乱的一些信息，也没太大意义。上述日志中，最主要的就是告诉我们有 OOM 异常，而且还是 Direct buffer memory 这一块内存导致的 到目前为止，仅仅看到这些日志，我们基本就可以分析出这次 OOM 发生的原因了 案例分析先给大家解释一个东西： Direct buffer memory。这个东西其实就是堆外内存。它是 JVM 堆内存之外的一块内存空间，这块内存空间不是 JVM 管理的，但是你的 Java 代码确实是可以在 JVM 堆之外使用一些内存空间的。 另外再解释一下 Jetty。这个你大致可以理解为跟 Tomcat 一样的东西，就是 Web 容器。Jetty 本身也是 Java 写的，如果我们写好了一个系统，可以打包放入 Jetty，启动 Jetty 即可。Jetty 启动之后，本身就是一个 JVM 进程，它会监听一个端口号，比如说 9090 然后你就向 Jetty 监听的 9090 端口发送请求，Jetty 会把请求转交给你用的 Spring MVC 之类的框架，Spring MVC 之类的框架再去调用写好的 Controller 之类的代码。如图，我们简单看下 Jetty 作为一个 JVM 进程运行我们写好的系统的一个流程： 首先可以明确一点，这次 OOM 是 Jetty 这个 Web 服务器在使用堆外内存的时候导致的，即，基本可以推测出，Jetty 服务器可能在不停地使用堆外内存，然后堆外内存空间不足了，此时就会抛出内存溢出的异常。 至于为什么 Jetty 要不停地使用堆外内存，就暂时别管那么多，那涉及到 Jetty 作为一个 Web 服务器的底层源码细节。我们只要知道它会不停地去使用堆外内存，然后用着堆外内存不够了，就内存溢出了。 堆外内存是如何申请和释放的堆外内存是如何申请和释放的？简单说，如果在 Java 代码里要申请使用一块堆外内存空间，是使用 DirectByteBuffer 这个类，你可以通过这个类构建一个 DirectByteBuffer 对象，这个对象本身是在 JVM 堆内存里的。但是你在构建这个对象的同时，就会在堆外内存中划出来一块内存空间跟这个对象关联起来。因此在分配堆外内存的时候大致就是这个思路。 那堆外内存是如何释放的？当你的 DirectByteBuffer 对象没人引用了，成了垃圾对象之后，自然会在某一次 young gc 或者是 full gc 的时候把 DirectByteBuffer 对象回收掉。只要回收掉一个 DirectByteBuffer 对象，就会自然释放掉它关联的那块堆外内存。 为什么会出现堆外内存溢出那一般什么情况下回出现堆外内存溢出？如果你创建了很多的 DirectByteBuffer 对象，占用了大量的堆外内存，然后这些 DirectByteBuffer 对象还没有 GC 线程来回收，那么就不会释放堆外内存。久而久之，当堆外内存都被大量的 DirectByteBuffer 对象关联使用了，如果你再要使用更多的堆外内存，那么就会报内存溢出了 那什么情况下回出现大量的 DirectByteBuffer 对象一直存活着，导致大量的堆外内存无法释放呢？一种可能是系统承载了超高并发，压力很高，瞬时大量请求过来，创建了过多的 DirectByteBuffer 占用了大量的堆外内存，此时再继续想要使用堆外内存，就会内存溢出了。 但今天的这个案例不是这种情况，因为这个系统的负载其实没有想象中那么高，不会有瞬时大量的请求过来。 堆外内存溢出原因分析这个时候你的思路就要活跃起来了，我们可以去用 jstat 等工具观察一下线上系统的实际运行情况，同时根据日志看看一些请求的处理耗时，综合性地分析一下。当时我们通过 jstat 工具分析 JVM 运行情况，同时分析了过往的 gc 日志，还看了一下系统各个接口的调用耗时之后，分析出了如下思路。 首先看了一下接口的调用耗时，这个系统并发量不高，但是它每个请求处理较为耗时，平均在每个请求需要一秒多的时间去处理 然后我们通过 jstat 发现，随着系统不停地被调用会一直创建各种对象，包括 Jetty 本身会不停地创建 DirectByteBuffer 对象去申请堆外内存空间，接着直到年轻代的 Eden 区满了，就会触发 young gc。但是往往在进行垃圾回收的一瞬间，可能有的请求还没处理完毕，此时就会有不少 DirectByteBuffer 对象处于存活状态，不能被回收掉，当然之前不少 DirectByteBuffer 对象对应的请求可能处理完毕了，他们就可以被回收了。 此时肯定会有一些 DirectByteBuffer 对象以及一些其他的对象是处于存活状态的，那么就需要转入 Survivor 区域中。此时要注意一点，这个系统当时在上线的时候，内存分配地极为不合理。在当时而言，大概就给了年轻代一两百 MB 的空间，老年代反而给了七八百 MB 的空间，进而导致年轻代中的 Survivor 区域只有 10MB 左右的空间。 因此往往在 young gc 过后，一些存活下来的对象（包括了一些 DirectByteBuffer 在内）会超过 10MB，没法放入 Survivor 中，就会直接进入老年代。因此上述的过程就这么反复执行，会慢慢的导致一些 DirectByteBuffer 对象慢慢地进入老年代中，老年代中的 DirectByteBuffer 对象会越来越多，而且这些 DirectByteBuffer 都是关联了很多堆外内存的。如图： 这些老年代里的 DirectByteBuffer 其实很多都是可以回收的状态了，但是因为老年代一直没塞满，所以没触发 full gc，也就自然不会回收老年代里的这些 DirectByteBuffer 了，所以老年代里这些没有被回收的 DirectByteBuffer 就一直关联占据了大量的堆外内存空间了 直到最后，当你要继续使用堆外内存的时候，结果所有的堆外内存都被老年代里大量的 DirectByteBuffer 给占用了，虽然他们可以被回收，但是无奈因为始终没有触发老年代的 full gc，所以堆外内存也始终无法被回收掉。最终就会导致内存溢出问题的发生。 Java NIO 如何解决这个问题难道 Java NIO 就没考虑过会有上述问题的产生吗？当时不是，Java NIO 是考虑到的。它知道可能很多 DirectByteBuffer 对象也许没人用了，但是因为没有触发 gc 就导致它们一直占据着堆外内存。 所以在 Java NIO 的源码中会做如下处理，它每次分配新的堆外内存的时候，都会调用 System.gc() 去提醒 JVM 去主动执行一下 gc 去回收掉一些没人引用的 DirectBYteBuffer 对象，释放堆外内存。只要能触发垃圾回收去回收掉一些没人引用的 DirectByteBuffer，就会释放一些堆外内存，自然就可以分配更多的对象到堆外内存去了。 但是我们又在 JVM 中设置了如下参数：-XX:+DisabledExplicitGC，导致这个 System.gc() 是不生效的，因此就会导致上述的情况。 问题的优化其实项目问题有两个，一个是内存设置不合理，导致 DirectByteBuffer 对象一直慢慢进入老年代，导致堆外内存一直释放不掉。另一个是设置了 -XX:+DisableExplicitGC 导致 Java NIO 没法主动提醒去回收掉一些垃圾 DirectByteBuffer 对象，同样最终导致堆外内存无法释放。 因此最终对这个项目做得事情就是： 合理分配内存，给年轻代更多内存，让 Survivor 区域有更大的空间 放开 -XX:+DisableExplicitGC 这个限制，让 System.gc() 生效 做完优化之后，DirectByteBuffer 一般就不会不断进入老年代了。只要它停留在年轻代，随着 young gc 就会正常回收释放堆外内存了。另外，放开了 -XX:+DisableExplicitGC 的限制，Java NIO 发现堆外内存不足了，自然会通过 System.gc() 提醒 JVM 去主动垃圾回收，可以回收掉一些 DirectByteBuffer 释放一些堆外内存。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 的一些特殊场景解决方案]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F24%2FRocketMQ-%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%AE%8A%E5%9C%BA%E6%99%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[RocketMQ 百万消息积压问题有一个系统，它是由生产者系统和消费者系统两个环节组成的，生产者系统会负责不停地把消息写入 RocketMQ 里去，然后消费者系统就是负责从 RocketMQ 里消费消息。这个系统是有高峰和低谷的，在晚上几个小时的高峰期内，大概会有 100 多万条消息进入 RocketMQ，然后消费者系统从 RocketMQ 里获取到消息之后，会依赖一些 NoSQL 数据库去进行一些业务逻辑的实现。 然后有一天晚上出现了一个问题，消费者系统依赖的 NoSQL 数据库挂掉了，导致消费者系统自己也没法运作，此时就没法继续从 RocketMQ 里消费数据和处理了，消费者系统几乎就处于停滞不动的状态。然后生产者系统在晚上几个小时的高峰期内，往 MQ 里写入了 100 多万的消息，此时都积压在 MQ 里了，没人消费和处理。 针对这种情况，一般来说有几种方案可以快速搞定。如果这些消息你是允许丢失的，那么此时你就可以紧急修改消费者系统的代码，在代码里对所有的消息都获取到就直接丢弃，不做任何的处理，这样可以迅速地让积压在 MQ 里的百万消息被处理掉，只不过处理方式是全部丢弃而已。 但是对很多系统而言，不能简单粗暴地丢弃这些消息，所以最常见的方法，还是先等待消费者系统底层依赖的 NoSQL 数据库先恢复了。恢复之后，就可以根据你的线上 Topic 的 MessageQueue 的数量来看看如何后续处理。 加入你的 Topic 有 20 个 MessageQueue，然后你只有 4 个消费者系统在消费，那么每个消费者系统会从 5 个 MessageQueue 里获取消息。所以此时你仅仅依靠 4 个消费者系统是不够的，毕竟 MQ 了积压了百万消息了。所以此时你可以临时申请 16 台机器多部署 16 个消费者系统的实例，然后 20 个消费者系统同时消费，每个人消费一个 MessageQueue 的消息。此时你消费的速度提高了 5 被，很快积压的百万消息也会被处理掉。 但是这里你同时要考虑到你的消费者系统底层依赖的 NoSQL 数据库必须要能抗住临时增加了 5 倍的读写压力，因为原来就 4 个消费者系统在读写 NoSQL，现在临时变成了 20 个消费者系统了。当你处理完百万积压的消息之后，就可以下线多余的 16 台机器了。 那如果你的 Topic 总共就只有 4 个 MessageQueue，然后你就只有 4 个消费者系统呢？这个时候就没办法扩容消费者系统了，因为你加再多的消费者系统，还是只有 4 个 MessageQueue，没法进行消费。 所以此时往往是临时修改那 4 个消费者系统的代码，让他们获取到消息然后不写入 NoSQL，而是直接把消息写入一个新的 Topic，这个速度是很快的，因为仅仅是读写 MQ 而已。然后新的 Topic 有 20 个 MessageQueue，然后再部署 20 台临时增加的消费者系统，去消费新的 Topic 后写入数据到 NoSQL 里去，这样子也可以迅速地增加消费者系统的并行处理能力，使用一个新的 Topic 来运行更多的消费者并行处理。 金融级的系统针对 RocketMQ 集群崩溃设计高可用方案金融级的系统中如果依赖了 RocketMQ 集群，那么在 RocketMQ 集群彻底崩溃的时候，我们应该如何设计它的高可用方案？比如跟金钱相关的一些系统，它可能需要依赖 MQ 去传递消息，如果你 MQ 崩溃了，可能导致很多跟钱相关的东西就会出问题。 类似的场景有很多，针对这种场景，我们通常会在你发送消息到 MQ 的那个系统中设计高可用的降级方案。这个降级方案通常的思路是，你需要在你发送消息到 MQ 代码里去 try catch 捕获异常，如果你发送发送消息到 MQ 有异常，此时你需要进行重试。 如果你发现连续重试了比如超过 3 次还是失败了，说明此时可能就是你的 MQ 集群彻底崩溃了，此时你必须把这条重要消息写入到本地存储中去，可以是数据库，也可以是写入到本地磁盘文件里去，或者是 NoSQL 存储中去。具体要根据你们的具体情况来决定。 之后你要不停地尝试发送消息到 MQ 去，一旦发现 MQ 集群恢复了，你必须有一个后台线程可以把之前持久化存储的消息都查询出来，然后依次按照顺序发送到 MQ 集群里去，这样才能保证你的消息不会因为 MQ 彻底崩溃而丢失。 这里有一个很关键的点，就是你把消息写入存储中暂存时，一定要保证它的顺序，比如按照顺序一条一条的写入本地磁盘文件去暂存消息。而且一旦 MQ 集群故障了，你后续的所有写消息的代码必须严格按照顺序把消息写入到本地磁盘文件去暂存，这个顺序性是要严格保证的。 只要有这个方案在，那么哪怕你的 MQ 集群突然崩溃了，你的系统也是不会丢失消息的，对于一些跟金钱相关的金融系统，广告系统来说，这种高可用的方案设计，是非常有必要的。 Kafka 到 RocketMQ 的双写 + 双读技术方案，实现无缝迁移假设你们公司本来线上的 MQ 用的主要是 Kafka，现在要从 Kafka 迁移到 RocketMQ 去，那么这个迁移的过程该怎么做？这里给大家介绍一个 MQ 集群迁移过程中的双写 + 双读技术方案。 简单来说，如果你要做 MQ 集群迁移，是不可能那么简单粗暴的，因为你不可能说在某一个时间点突然之间说把所有的 Producer 系统都停机，然后更新它的代码，接着全部上线，然后所有 Producer 系统都把消息写入到 RocketMQ 去了。 一般来说，首先你要做到双写，也就是说，在你所有的 Producer 系统中，要引入一个双写的代码，让它同时往 Kafka 和 RocketMQ 中去写入消息，然后多写几天，起码双写要持续一周左右，因为 MQ 一般都是实时数据，里面的数据也就最多保留一周。当你的双写持续一周后，你会发现你的 Kafka 和 RocketMQ 里的数据看起来几乎是一模一样，因为 MQ 反正也就保留最近几天的数据，当你双写持续超过一周过后，你会发现 Kafka 和 RocketMQ 里的数据几乎一模一样了 但是光是双写还是不够的，还需要同时进行双读，也就是说在你双写的同时，你所有的 Consumer 系统都需要同时从 Kafka 和 RocketMQ 里获取消息，分别用一模一样的逻辑处理一遍。只不过从 Kafka 里获取到的消息还是走核心逻辑去处理，然后可以落入数据库或者别的存储之类的，但是对月 RocketMQ 里获取到的消息，你可以用一样的逻辑处理，但是不能把处理结果具体的地落入数据库之类的地方 你的 Consumer 系统在同时从 Kafka 到 RocketMQ 进行消息读取的时候，你需要统计每个 MQ 当日读取和处理的消息的数量，这点非常重要，同时对于 RocketMQ 读取到的消息处理之后的结果，可以写入一个临时的存储中。 同时你要观察一段时间，当你发现坚持双写和双读一段时间之后，如果所有的 Consumer 系统通过对比发现，从 Kafka 和 RocketMQ 读取和处理的消息数量一致，同时处理之后得到的结果也是一致的，此时就可以判断说当前 Kafka 和 RocketMQ 里的消息是一致的，而且计算出来的结果也是一致的。 这个时候就可以实施正式的切换了，你可以停机 Producer 系统，再重修修改后上线，全部修改为仅仅写 RocketMQ，这个时候它数据不会丢，因为之前已经双写了一段时间了，然后所有的 Consumer 系统可以全部下线后修改代码再上线，全部基于 RocketMQ 来获取消息，计算和处理，结果写入存储中。 基本上对于类似的一些重要中间件的迁移，往往都会采取双写的方法，双写一段时间，然后观察两个方案的结果都一致了，你再正式下线旧的一套东西]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 实践经验]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F22%2FRocketMQ-%E5%AE%9E%E8%B7%B5%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[灵活地运用 tags 来过滤数据之前我们讲解过基于 tags 来过滤数据的功能，其实在真正的生产项目中，建议大家合理地规划 Topic 和里面的 tags。一个 Topic 代表了一类业务消息数据，然后对于这类业务消息数据，如果你希望继续划分一些类别的话，可以在发送消息的时候设置 tags 例如，我们知道现在常见的外卖平台有美团外卖。饿了么和其他一些外卖，假设你现在一个系统要发送外卖订单数据到 MQ 里去，就可以针对性地设置 tags。比如不同的外卖数据都到一个 “WaimaiOrderTopic” 里去，但是不同类型的外卖可有不不同的 tags：”meituan_waimai”，”eleme_waimai”，”other_waimai” 等等。然后你对消费 “WaimaiOrderTopic” 的系统，可以根据 tags 来筛选，可能你就需要某一种类别的外卖数据而已。 基于消息 key 来定位消息是否丢失在消息零丢失方案中，可能要解决的消息是否丢失的问题，那么如果消息真的丢失了，我们就需要排查，需要从 MQ 里查一下，这个小时是否丢失了 那怎么从 MQ 里查消息是否丢失？可以基于消息 key 来实现。比如通过这样的方式设置一个消息的 key为订单 id：message.setKeys(orderId)，这样这个消息就具备一个 key 了。接着这个消息到 Broker 上，会基于 key 构建 hash 索引，这个 hash 索引就存放在 IndexFile 索引文件里。然后后续我们可以通过 MQ 提供的命令去根据 key 查询这个消息，类似下面这样： 1mqadmin queryMsgByKey -n 127.0.0.1:9876 -t SCANRECORD -k orderId 具体的命令，可以去查官方手册 消息零丢失方案的补充之前有讲过零丢失方案，其实在消息零丢失方案还有一个问题，就是 MQ 集群彻底故障，此时就是不可用了，那这么处理？ 其实对于一些金融级的系统，或者跟钱相关的支付系统，或者是广告系统，类似这样的系统，都必须有超高级别的高可用保障机制，一般假设 MQ 集群彻底崩溃了，你生产者就应该把消息写入到本地磁盘里去进行持久化，或者写入数据库里去暂存起来，等待 MQ 恢复之后，然后再把持久化的消息继续投递到 MQ 里去。 提高消费者的吞吐量如果消费的时候发现消费地比较慢，那么可以提高消费者的并行度，常见的就是部署更多的 consumer 机器。但是这里要注意，你的 Topic 的 MessageQueue 得是有对应的增加，因为如果你的 consumer 机器有 5 台，然后 MessageQueue 只有 4 个，那么意味着有一个 consume 机器是获取不到消息的。 然后就是可以增加 consumer 的线程数量，可以设置 consumer 端的参数：consumeThreadMin、consumeThreadMax，这样一台 consumer 机器上的消费线程越多，消费的速度就越快。 此外，还可以开启消费者的批量消费功能，就是设置 consumeMessageBatchMaxSize 参数，它默认是 1，但是你可以设置的多一些，那么一次就会交给你的回调函数一批消息给你处理，此时你可以通过 SQL 一次性批量处理一批数据。比如：update xxx set xxx where id in(xx,xx,xx) 企业级的 RocketMQ 集群进行权限机制的控制如果一个公司有很多技术团队，每个技术团队都会使用 RocketMQ 集群中的部分 Topic，那么此时可能就会有一个问题，如果订单团队使用的 Topic，被商品团队不小心写入了错误的脏数据，怎么办？可能导致订单团队的 Topic 里的数据出错了。 此时就需要在 RocketMQ 中引入权限功能，也就是说规定好订单团队的用户，只能使用 OrderTopic，然后商品团队的用户只能使用 ProductTopic，大家互相之间不能混乱地使用别人的 Topic。要在 RocketMQ 中实现权限控制也不难，首先我们需要在 Broker 端放一个额外的 ACK 权限控制配置文件，里面需要规定好权限，包括什么用户对哪些 Topic 有什么操作权限，这样的话，各个 Broker 才知道你每个用户的权限。 首先在每个 Broker 的配置文件里需要设置 aclEnable = true 这个配置，开启权限控制。其次，在每个 Broker 部署机器的 ${ROCKETMQ_HOME}/store/config 目录下，可以放一个 plain_acl.yml 的配置文件，这个里面就可以进行权限配置，类似下面这样子： 123456789101112131415161718192021222324252627282930313233343536373839# 这个参数就是全局性的白名单# 这个定义的 ip 地址，都是可以访问 Topic 的globalWhiteRemoteAddresses:- 10.10.15.*- 192.168.0.*# 这个 accounts 就是说，你在这里可以定义很多账号accounts:# 这是 AccessKey 就是用户名的意思，比如我们这里叫做 “订单技术团队”- accessKey: OrderTeam# 这个 secretKey 就是这个用户名的密码 secretKey: 123456# 下面这个是当前这个用户名下哪些机器要加入白名单 whiteRemoteAddress:# admin 指的是这个账号是不是管理员账号 admin: false# 这个指的是默认情况下这个账号的 Topic 权限和 ConsumerGroup 权限 defaultTopicPerm: DENY defaultGroupPerm: SUB# 这个就是这个账号具体的一些账号的权限# 下面就是说当前这个账号对应两个 Topic，都具备 PUB|SUB 权限，就是发布和订阅的权限# PUB 就是发布消息的权限，SUB 就是订阅消息的权限# DENY 就是拒绝你这个账号访问这个 Topic topicPerms: - topicA=DENY - CreateOrderInformTopic=PUB|SUB - PaySuccessInformTopic=SUB|SUB# 下面就是对 ConsumerGroup 的权限，也是同理的 groupPerms: - groupA=DENY - groupB=PUB|SUB - groupC=SUB# 下面就是另一个账号了，比如是商品技术团队的账号- accessKey: ProductTeam secretKey: 12345678 whiteRemoteAddress: 192.168.1.* # 如果设置为 true，就是具备一切权限 admin: true 上面配置中，需要注意一点，就是如果你一个账号没有对某个 Topic 显式地指定权限，那么就是会采用默认 Topic 权限。 接着我们看看你的生产者和消费者里，如何指定你的团队分配到的 RocketMQ 的账号。当你使用一个账号的时候，就只能访问你有权限的 Topic 1234DefaultMQProducer producer = new DefaultMQProducer( "OrderProducerGroup", new AclClientRPCHook(new SessionCredentials("OrderTeam", "123456")) ); 上面的代码中就是在创建 Producer 的时候，传入进去一个 AclClientRPHook，里面就可以设置你这个 Producer 的账号密码。对于创建 Consumer 也是同理的，通过这样的方式，就可以在 Broker 端设置好每个账号对 Topic 的访问权限，然后你不同的技术团队就用不同的账号就可以了。 RocketMQ 集群进行消息轨迹的追踪如何在生产环境里查询一条消息的轨迹？即，对于一个消息，我想要知道，这个消息是什么时候从哪个 Producer 发送出来？它在 Broker 端是进入到了 哪个 Topic 里去的？它在消费者层面是被 哪个 Consumer 什么时候消费出来的？ 我们有时候对于一条消息的丢失，可能就想要了解到这样的一个消息轨迹，协助我们去进行线上问题的排查，所以此时就可以使用 RocketMQ 支持的消息轨迹功能，我们看下面的配置过程。 首先需要在 Broker 的配置文件里开启 traceTopicEnable = true 这个选项，此时就会开启消息轨迹追踪的功能。接着当我们开启了上述的选项之后，我们启动这个 Broker 的时候会自动创建一个内部的 Topic，就是 RMQ_SYS_TRACE_TOPIC，这个 Topic 就是用来存储所有的消息轨迹追踪的数据的。 接着做好上述一切事情之后，我们需要在发送消息的时候开启消息轨迹，此时创建 Producer 的时候要用如下的方式，下面构造函数中的第二个参数，就是 enableMsgTrace 参数，它设置为 true，就是说可以对消息开启轨迹追踪。 12DefaultMQProducer producer = new DefaultMQProducer(&quot;TestProducerGroup&quot;, true); 在订阅消息的时候，对于 Consumer 也是同理的，在构造函数的第二个参数设置为 true，就是开启了消费时候的轨迹追踪。 其实，一旦我们在 Broker、Producer、Consumer 都配置好了轨迹追踪之后，其实 Producer 在发送消息的时候，就会上报这个消息的一些数据到内置的 RMQ_SYS_TRACE_TOPIC 里去。此时会上报如下的一些数据：Producer 的消息、发送消息的时间、消息是否发送成功、发送消息的耗时。 接着消息到 Broker 端之后，Broker 端也会记录消息的轨迹数据，包括如下：消息存储的 Topic、消息存储的位置、消息的 key、消息的 tags。然后消息被消费到 Consumer 端之后，它也会上报一些轨迹数据到内置的 RMA_SYS_TRACE_TOPIC 里去，包括如下一些东西：Consumer 的消息、投递消息的时间、这是第几轮投递消息、消息消费是否成功，消费这条消息的耗时。 接着如果我们想要查询消息轨迹，也很简单。在 RocketMQ 控制台里，在导航栏里就有一个消息轨迹，在里面可以创建任务，你可以根据 messageId、message key 或者 Topic 来查询，查询任务执行完毕之后，就可以看到消息轨迹的界面了。 在消息轨迹的界面就会展示出来刚才说的 Producer、Broker、Consumer 上报的一些轨迹数据了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次系统 OOM]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F21%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%B3%BB%E7%BB%9F-OOM%2F</url>
    <content type="text"><![CDATA[由此系统因为 OOM 问题而挂掉了，当时我们就登录到线上系统去下载日志，并在日志中发现类似这么一句话： 1Exception in thread "http-nio-8080-exec-1089" java.lang.OutOfMemoryError: Java heap space 日志中，http-nio-8080-exec 1089 说的其实是 Tomcat 的工作线程，而后面的 java.lang.OutOfMemoryError: Java heap space 指的就是堆内存溢出的问题，所以连起来看，这段日志的意思是 Tomcat 的工作线程在处理请求的时候需要在堆内存里分配对象，但是发现堆内存塞满了，而且根本没办法回收多余的对象，堆内存已经放不下更多对象了，就报了这个异常。 简单说说 Tomcat 的底层原理讲到这，我们看看 Tomcat 的基本工作原理，以及发生这个 OOM 异常的基本原因。首先，我们写的系统一般都是部署在 Tomcat 中的。最早我们会在 Eclipse / IDEA 开发工具上写一堆 Servlet，然后打包放入 Tomcat，再启动 Tomcat。接着我们访问 Tomcat 监听的一个端口号（一般是 8080），然后系统的功能就可以运行起来了。 后来随着技术的发展，我们不再写 Servlet 这么原始的东西，有一些类似 Spring MVC 之类的框架把 Servlet 封装起来，我们就基于 Spring MVC 之类的框架去开发。再后面，出现了 SpringBoot，我们可以把 Tomcat 之类的 Web 容器都内嵌在系统里。 Tomcat 会监听一个默认的 8080 端口号，然后我们就通过浏览器可以对这个机器上的 Tomcat 发起请求，类似下面的请求： 1http://192.168.200.15:8080/order?userid=100 接着 Tomcat 会监听 8080 端口收到这个请求，通常来说它会把请求交给 Spring Web MVC 之类的框架去处理，这类框架一般底层都封装了 Servlet / Filter 之类的组件，它也是用这类组件去处理请求的，如图： 然后类似 Spring MVC 的框架的 Servlet 组件，就会根据你的请求路径，比如 /order 这种东西，去找到你代码中用来处理这个请求的 Controller 组件。那我们来思考一个问题，Tomcat是个什么东西？ 如果我们是把写好的系统放入 Tomcat 目录中，然后启动 Tomcat，此时我们启动的 Tomcat 本身就是一个 JVM 进程，因为 Tomcat 自己也是 Java 写的。所以要明确一个概念，就是 Tomcat 自己就是一个 JVM 进程，我们写好的系统只不过是一些代码而已，这些代码时一个一个的类，这些类被 Tomcat 加载到内存里去，然后由 Tomcat 来执行我们写的类。 既然如此，Tomcat 本身是如何去监听 8080 端口上收到的请求？其实，Tomcat 有自己的工作线程，大家要对 Tomcat 的工作线程这个概念有一个认识，即 Tomcat 有很多自己的工作线程，少则一两百个，多则三四百个也是可以的。 然后从 8080 端口上收到的请求都会均匀地分配给这些工作线程去处理，而这些工作线程收到请求之后，就负责调用 Spring MVC 框架的代码，Spring MVC 框架有负责调用我们自己写的代码，比如 Controller 之类的。所以最终运行起来原理如下图： 再回顾异常日志接着我们回过头看当时在线上系统的日志中发现的异常： 1Exception in thread "http-nio-8080-exec-1089" java.lang.OutOfMemoryError: Java heap space 这个时候理解起来就很简单了，http-nio-8080-exec-1089 这个说白了就是上图中的 Tomcat 工作线程，因为它是负责调用 Spring MVC 以及我们写的 Controller、Service、DAO 等一大堆的代码的，所以它发现运行的时候堆内存不够了，就会抛出堆内存溢出的异常了。 一个关键的 JVM 参数一旦我们发现线上系统发生了内存溢出的异常，第一步是看日志，具体看两点： 看是堆内存溢出，还是栈内存溢出，或者是 Metaspace 内存溢出。首先得确定一下具体的溢出类型 看是哪个线程代码运行的时候内存溢出了，因为 Tomcat 运行的时候不光有自己的工作线程，我们写的代码也可能创建一些线程出来 看完这两个东西之后，就得记得每个系统上线，必须设置一个参数：-XX:+HeapDumpOnOutOfMemoryError。这个参数会在系统内存溢出的时候导出来一份内存快照到我们指定的位置，接着排查和定位内存溢出问题，主要就得依托这个自动导出来的内存快照了。 对内存快照进行分析一般我们都是用 MAT 来分析内存快照，主要就是通过 MAT 来找到那些占据内存最大的对象。 通过内存快照分析我们发现占据内存最大的是大量的 byte[] 数组，一大堆 byte[] 数组就占据了大约 8G 左右的内存空间，而我们当时线上机器给 Tomcat 的 JVM 堆内存分配的也就是 8G 左右的内存而已。因此我们可以直接得出第一个结论：Tomcat 工作线程在处理请求的时候会创建大量的 byte[] 数组，大约有 8G 左右，直接把 JVM 堆内存占满了。 接着我们想知道到底是哪些 byte[] 数组在这里，因此我们通过 MAT 深入查看，发现大概是类似下面的一大堆 byte[] 数组： byte[10008192] @ 0x7aa800000 GET /order/v2 HTTP/1.0-forward… byte[10008192] @ 0x7aa800000 GET /order/v2 HTTP/1.0-forward… byte[10008192] @ 0x7aa800000 GET /order/v2 HTTP/1.0-forward… 当时看到了很多类似这样的数组，而且数组大小都是一致的 10MB，大概清点了一下，类似上面那样的数据，大概有 800 个左右，也就对应了 8G 的空间。 那这些数组时谁创建的？我们在 MAT 上可以继续查看一下这个数组时谁引用的，大致可以发现是 Tomcat 的类引用的，具体来说是类似下面这个类： 1org.apache.tomcat.util.threads.TaskThread 这个一看就是 Tomcat 自己的线程类，因此可以认为是 Tomcat 的线程创建了大量的 byte[] 数组，占据了 8G 的内存空间。 而我们发现 Tomcat 的工作线程大致有 400 个左右，也就是说每个 Tomcat 的工作线程都会创建 2 个 byte[] 数组，每个 byte[] 数组是 10MB 左右，最终就是 400 个 Tomcat 工作线程同时在处理请求，结果创建出来了 8G 内存的 byte[] 数组，进而导致了内存溢出。如图： 系统每秒的 QPS根据上面的分析，有可能一秒钟之内瞬间来了 400 个请求，导致 Tomcat 的 400 个工作线程全部上阵处理，每个工作线程在处理一个请求的时候，会创建 2 个数组，每个数组是 10MB，结果导致瞬间让 8G 的内存空间被占满。 但我们检查了系统的监控，发现每秒的请求并不是 400，而是 100。那么出现这种情况只有一种可能，就是每个请求处理需要 4 秒钟的时间。如果每秒来 100 个请求，但是每个请求处理完毕需要 4 秒钟的时间，那么在 4 秒内会导致有 400 个请求同时在处理，也就会导致 Tomcat 的 400 个工作线程都在工作，接着就会导致上述的情况。 另外，为什么 Tomcat 工作线程在处理一个请求的额时候会创建 2 个 10MB 的数组？通过检查 Tomcat 的配置文件，发现了一个配置 max-http-header-size: 10000000。有了这个东西，导致 Tomcat 工作线程在处理请求的时候会创建 2 个数组，每个数组的大小如上面配置就是 10MB。 为什么处理一个请求需要 4 秒钟为什么处理一个请求需要 4 秒钟。经过咨询得知这个问题是偶发性，不是每次处理请求都这样，平时处理一个请求也就几百毫秒的时间而已。这样就只能在日志里去找问题了，继续翻看事故发生的日志，发现日志中除了 OOM 以外，还有大量的服务请求超时的异常，类似下面： 1Timeout Exception.... 即，我们系统在调用其他系统的时候出现了大量的请求超时，看了一下调用超时的配置，发现负责这个系统的工程师将服务调用超时的时间设置为了刚好是 4 秒！也就是说，在这个时间里，远程服务自己故障了，导致我们的系统调用其他服务的时候是访问不通的，然后就会在配置好的 4 秒超时时间之后抛出异常，在这 4 秒钟内，工作线程会直接卡死在无效的网络访问上。 上图可以清楚看到，之所以每个请求需要处理 4 秒钟，是因为下游服务故障了，网络请求都是失败的，此时会按照设置好的 4 秒钟时间一直卡住 4 秒之后才会抛出 Timeout 异常，然后请求处理结束。这就是一个请求处理需要 4 秒钟的根本原因，进而导致 100 个请求的压力下，4 秒内积压 400 个请求同时在处理，导致 400 个工作线程创建了 800 个数组，每个数组 10MB 内存，耗尽了 8G 的内存，最终导致内存溢出。 对系统进行优化要解决上述问题，分析清楚原因之后，对症下药即可。 最核心的问题就是那个超时时间设置太长了，因此将超时时间改为 1 秒即可。这样的话，每秒 100 个请求过来，也就只有 200 个数组，占据 2G 内存，远远不会把堆内存塞满，然后 1 秒内这 100 个请求会全部超时，请求就处理结束了。下一秒再来 100 个请求又是新的一轮处理，不会每秒积压 100 个请求，4 秒积压 400 个请求同时处理了 另外，对 Tomcat 的那个参数，max-http-header-size，可以适当调节地小一些就可以了，这样 Tomcat 工作线程自身为请求创建的数组，不会占据太大的内存空间的。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 内存溢出的解决方案]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F20%2FJVM-%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[对于内存溢出，我们需要生成并分析一下 GC 日志，然后再让 JVM 自动 dump 出来内存快照，最后用 MAT 来分析一下这份内存快照，从内存快照里去找到内存溢出的原因。 Metaspace 内存区域溢出首先我们先看下面的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Demo1 &#123; public static void main(String[] args) &#123; long counter = 0; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Car.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; if(method.getName().equals("run")) &#123; System.out.println("启动汽车之前，先进行自动的安全检查。。。。。。"); return methodProxy.invokeSuper(o, objects); &#125;else&#123; return methodProxy.invokeSuper(o, objects); &#125; &#125; &#125;); Car car = (Car) enhancer.create(); car.run(); System.out.println("目前创建了 " + (++counter) + " 个Car类的子类了"); &#125; &#125; static class Car &#123; public void run() &#123; System.out.println("汽车启动，开始行使。。。。。。"); &#125; &#125; static class SafeCar extends Car &#123; @Override public void run() &#123; System.out.println("汽车启动，开始行使。。。。。。"); super.run(); &#125; &#125;&#125; 我们用上面的代码来说明，不过需要在 JVM 参数中加入一些东西，以为我们要看一下 GC 日志和导出内存快照，如下： 1-XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m -XX:PrintGCDetails -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./ 注意，上面那个 HeapDumpPath 参数我给调整为当前项目的根目录下了，这样我们看的时候方便一些。 分析 GC 日志我们用上述 JVM 参数运行这段程序，项目下面会多了两个文件，一个是 gc.log，还有一个是 java_pid16056.hrof。当然不同的机器运行生成的 hrof 文件的名字是不太一样的，因为它会用你的 PID 进程 id 作为文件名字。 接着我们先来分析一下这个 gc.log，看一下它是如何往 Metaspace 区域里放入大量生成的类，然后出发 Full GC，接着回收 Metaspace 区域，回收后还是无法放下更多的类，接着才会抛出内存溢出的异常。然后我们再用 MAT 分析一下 OOM 的时候的内存快照，找 Metaspace 内存溢出的原因。 首先看下面一段 GC 日志： 10.716: [GC (Allocation Failure) 0.717: [ParNew: 139776K-&gt; 2677K(157248K), 0.0038770 secs] 139776K-&gt; 2677K(506816K),0.0041376 secs] [Times: user=0.03 sys=0.01, real=0.00 secs] 上面那段日志，这是第一次 GC，它本身是一个 Allocation Failure 的问题。即，它是在 Eden 区中分配对象时，发现 Eden 区内存不足，于是触发了一次 ygc。那这个对象是什么对象？ 回顾我们的代码，Enhancer 本身是一个对象，它是用来生成类的，Enhancer enhancer = new Enhancer()。接着我们基于每次 Enhancer 生成的类还会生成那个类的对象：Car car = (Car) enhancer.create()。因此上述代码不光是动态生成类，本身它也是对应很多对象的，因此你在 while(true) 循环里不停地创建对象，当然也会塞满 Eden 区。 上述日志中：[ParNew: 139776K -&gt; 2677K(157248K), 0.0038770 secs]，就是说在默认的内存分配下，年轻代一共可用空间是 150MB 左右，然后还包含了一点 Survivor 区域的大小。然后大概用到了 140MB 左右了，也就是 Eden 区塞满了，此时就触发 Allocation Failure，没 Eden 区的空间分配对象了，此时就触发 ygc 了。 接着下面这段日志： 10.771: [Full GC (Metadata GC Threshold) 0.771: [CMS: 0K-&gt; 2161 K(349568K), 0.0721349 secs] 20290K-&gt;2161 K(506816K),[Metaspace: 9201K-&gt;9201K(105881 6K)], 0.0722612 secs] [Times: user=0.12 sys=0.03, real=0.08 secs] 这就是 Full GC，而且通过 “Metadata GC Threshold” 清楚看到，是 Metaspace 区域满了，所以触发了 Full GC。这个时候继续看日志：20290K -&gt; 2161K(506816K)，这个就是说堆内存（年轻代 + 老年代）一共是 500MB 左右，然后有 20 MB 左右的内存被使用了，这个是年轻代用的。 然后 Full GC 会带着一次 Young GC，因此这次 Full GC 其实是执行了 ygc，所以回收了很多对象，剩下了 2161KB 的对象，这个大概就是 JVM 的一些内置对象了。然后直接就把这些对象放入老年代了：[CMS: 0K -&gt; 2161K(349568K), 0.0721349 secs]。这里明显说了，Full GC 带着 CMS 进行了老年代的 Old GC，结果人家本来是 0KB，然后从年轻代转移来了 2161KB 的对象，所以老年代变成 2161KB 了。 接着看日志：[Metaspace: 9201K -&gt; 9201K(1058816K)]。此时 Metaspace 区域已经使用了差不多 9MB 左右的内存了，此时明显离我们限制的 10MB 内存很接近了，所以触发了 Full GC，但是对 Metaspace GC 后发现类全部存活，因此还是剩余 9MB 左右的类在 Metaspace 里。 接着看下面的日志： 120.843: [Full GC (Last ditch collection) 0.843: [CMS: 2161K-&gt; 1217K(349568K), 0.01 64047 secs] 2161K-&gt; 1217K(506944K),0.843: [Full GC (Last ditch collection) 0.843: [CMS: 2161K-&gt; 1217K(349568K), 0.01 64047 secs] 2161K-&gt; 1217K(506944K),[Metaspace: 9201K-&gt; 9201K(105881 6K)], 0.0165055 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 这个又是一个 Full GC，注意这个 Last ditch collection。就是说，最后一次拯救机会了，因为之前 Metaspace 回收了一次但是没有类可以回收，所以新的类无法放入 Metaspace 了。所以最后试一试 Full GC，结果如下：[Metaspace: 9201K -&gt; 9201K(1058816K), 0.0165055 secs]。Metaspace 区域还是无法回收掉任何的类，几乎还是占满了我们设置的 10MB 左右。 12345678910111213140.860: [GC (CMS Initial Mark) [1 CMS-initial-mark: 1217K(349568K)] 1217K(506944K), 0.0002251 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]0.860: [CMS-concurrent-mark-start]0.878: [CMS-concurrent-mark: 0.003/0.018 secs] [Times: user=0.05 sys =0.01, real=0.02 secs]0.878: [CMS-concurrent- preclean-start]Heappar new generation total 157376K, used 6183K [0x0000005ffe00000, 0x000000060a8c0000, 0x0000000643790000)eden space 139904K，4% used [00000005f00000, 0x0000000600409d48, 0x00000006086a0000)from space 17472K，0% used [000000006086a0000, 0x00000006086a0000, 0x00000006097b0000)to space 17472K，0% used [00000006097b0000, 0x00000006097b0000, 000000060a8c0000)concurrent mark- sweep generation total 349568K, used 1217K [0000000643790000, 0000000658c0000,0x00000007ffe00000)Metaspaceused 9229K, capacity 10146K, committed 10240K, reserved 1058816Kclass space used 794K, capacity 841K, committed 896K, reserved 1048576K 接着 JVM 就退出了，退出的时候就打印出了当前内存的一个情况，年轻代和老年代几乎没占用，但是 Metaspace 的 capacity 是 10MB，使用了 9MB，无法再继续使用，所以触发了内存溢出。此时就会在控制台打印出如下的一些东西： 1234Caused by: java.lang.OutOfMemoryError: Metaspaceat java.lang.ClassLoader.defineClass1(Native Method)at java.lang.ClassLoader.defineClass(ClassLoaderjava:763)...11 more 明确抛出异常，说 OutOfMemoryError，原因就是 Metaspace 区域满了导致的。 分析内存快照当我们知道是 Metaspace 引发的内存溢出之后，可以把内存快照文件从线上机器拷回本地电脑，打开 MAT 工具进行分析，如下： 从这里可以看到实例最多的就是 AppClassLoader。为啥有这么多的 ClassLoader？一看就是 CGLIB 之类的东西在动态生成类的时候搞出来的，我们点击上图的 Detail 进去看看 为什么这里有一堆自己的 Demo1 中动态生成出来的 Car$$EnhancerByCGLIB 的类呢？看到这里就真相大白了，上图告诉了我们，是我们自己的哪个类搞出来了一大堆的动态生成的类，所以填满了 Metaspace 区域。所以此时直接去代码里排查动态生成类即可。 解决这个问题的办法也很简单，直接对 Enhancer 做一个缓存，只有一个，不要无限制地去生成类即可。 1234567891011121314151617181920212223private volatile Enhancer enhancer = null;public void doSomething() &#123; if(enhancer == null) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Car.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; if (method.getName().equals("run")) &#123; System.out.println("启动汽车之前，先进行自动的安全检查。。。。。。"); return methodProxy.invokeSuper(o, objects); &#125; else &#123; return methodProxy.invokeSuper(o, objects); &#125; &#125; &#125;); &#125; Car car = (Car) enhancer.create(); car.run();&#125; 栈内存溢出首先，栈内存溢出能根据之前的方法解决吗？其实，栈内存溢出跟堆内存是没有关系的，因为它的本质是一个线程的栈压入了过多方法调用的栈帧，比如几千次方法调用的几千个栈帧，此时就导致线程的堆内存不足，无法放入更多栈帧了。所以 GC 日志对你有用吗？ 没用。因为 GC 日志主要是分析堆内存和 Metaspace 区域的一些 GC 情况的，就线程的栈内存而言，它们不存在所谓的 GC。因为调用一个方法时在栈里压入栈帧，接着执行完整的方法，栈帧从栈里出来，然后一个线程运行完毕时，它的栈内存就没了。所以本身这块内存不存在所谓的 GC 和回收，调用方法就给栈分配内存，执行完方法就回收掉那个栈帧的内存。 内存快照呢？内存快照主要是分析一些内存占用的，同样是针对堆内存和 Metaspace 的，所以对线程的栈内存而言，也不需要借助这个东西。 示例代码12345678910111213public class Demo2 &#123; public static long counter = 0; public static void main(String[] args) &#123; work(); &#125; public static void work() &#123; System.out.println("目前是第 " + (++counter) + " 次调用方法"); work(); &#125;&#125; 使用的 JVM 参数如下： -XX:ThreadStackSize=1m -XX:+PrintGCDetails -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./ -XX:+UseParNewGC -XX:+UseConcMarkSweepGC 运行代码后分析异常报错信息的调用栈接着我们运行代码让它产生栈内存溢出的保存，如下： 实际上我们会在这里看到大段如上所示的异常，即，它会直接告诉你这个栈内存溢出的问题，是因为你拼命地调用 Demo2 这个类的 work() 方式时发生的。因此就定位栈内存溢出而言，我们定位和解决问题非常简单，你只要把所有的异常都写入本地日志文件，那么当你发现系统崩溃时，第一步就去日志里定位一下异常信息就知道了 堆内存溢出我们看下面的示例代码： 123456789101112public class Demo3 &#123; public static void main(String[] args) &#123; Long counter = 0L; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new Object()); System.out.println("当前创建了第" + (++counter) + "个对象"); &#125; &#125;&#125; 采用的 JVM 参数如下： -Xms10m -Xmx10m -XX:+PrintGCDetails -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./ -XX:+UseParNewGC -XX:+UseConcMarkSweepGC 接着我们运行上述程序。 运行后的观察其实堆内存溢出的现象也是很简单的，在系统运行一段时间之后，直接会发现系统崩溃了，然后登陆到线上机器检查日志文件，先看为什么崩溃。 这就告诉我们是 Java 堆内存溢出了，而且他还给我们导出了一份内存快照。所以我们 GC 日志都不用分析了，因为堆内存往往对应着大量的 GC 日志，所以分析起来很麻烦。此时直接将线上自动导出的内存快照拷贝会本地电脑，用 MAT 分析即可。 用 MAT 分析内存快照使用 MAT 打开内存快照之后会看到下图： 这次 MAT 比较简单，直接在内存泄露报告中告诉我们内存溢出原因只有一个，只有上面哪一个问题，因为它没提示任何其他的问题。 我们看这句：The thread java.lang.Thread @ 0x7bf6a9a98 main keeps local variables with total size 7203536(92.03%) bytes。这个意思就是 main 线程通过局部变量引用了 7203536 个字节对象，大概是 7MB左右。考虑到我们总共就给堆内存 10MB，所以 7MB 基本上就已经到极限了，是差不多的。 接着看：The memory is accumulated in one instance of &quot;java.lang.Object[]&quot; loaded by &quot;&lt; system class loader &gt;&quot;。这句话的意思就是内存都被一个对象占用了，就是 java.lang.Object[]。我们不知道这个是什么东西，所以点击 Details 继续往下看： 在 Details 里我们能看到这个东西，也就是占用了 7MB 内存的 java.lang.Object[]，它里面的每个元素在这里都有，我们看到的是一大堆的 java.lang.Object。这些 java.lang.Object 不就是我们在代码里创建的吗？至此就很清楚了，我们知道是一大堆 Object 对象占用了 7MB 的内存导致了内存溢出。 接着就是要知道这些对象是怎么创建出来的，我们看下图： 这个是说可以看看创建那么多对象的线程，它的一个执行栈，这样我们就知道这个线程执行什么方法的时候创建了一大堆的对象。 大家看上面的调用栈，在 Demo3.main() 方法中，一直在调用 ArrayList.add() 方法，然后此时直接引发了内存溢出。所以我们只要在对应代码里看一下，立马就知道怎么回事了。接下来优化对应的代码即可，就不会发生内存溢出了。 总结堆内存溢出的问题如何分析和定位？一个是必须在 JVM 参数中加入自动导出内存快照，一个是到线上看一下日志文件里的报错，如果是堆溢出，立马用 MAT 分析内存快照。 MAT 分析的时候，先看占用内存最多的对象是谁，然后分析那个线程的调用栈，接着就可以看到是哪个方法引发的内存溢出了，接着优化代码即可。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ - 基于延迟消息机制的大量订单的定时退款扫描]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F18%2FRocketMQ-%E5%9F%BA%E4%BA%8E%E5%BB%B6%E8%BF%9F%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6%E7%9A%84%E5%A4%A7%E9%87%8F%E8%AE%A2%E5%8D%95%E7%9A%84%E5%AE%9A%E6%97%B6%E9%80%80%E6%AC%BE%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[我们来看一个订单退款扫描的问题。一个正常的电商购物流程，一般来说我们现在作为用户在一个电商 APP 上都会选择一些商品加入购物车，然后对购物车里选择的一些商品统一下一个订单，此时后台的订单系统会在订单数据库中创建一个订单。 但是我们下了一个订单之后，虽然订单数据库里会有一个订单，订单的状态却是 “待支付” 状态，因此此时你还没有支付这个订单，我们的订单系统其实也在等待用户完成这个订单的支付 这里就有两种可能了，一种可能是用户下单之后立马就支付掉了，那么接着订单系统可以走后续的流程，比如通过 MQ 发送消息通知优惠券系统给用户发优惠券，通知仓储系统进行调度发货等等。另外一种可能就是用户下单之后，没有支付订单。在实际情况中，APP 的大量用户每天会下很多订单，但是不少订单可能是一直没有进行支付的，可能它下单之后犹豫了，也可能是忘记支付了。 所以一般订单系统都必须设置一个规则，当一个订单下单之后，超过一定时间，比如 30 分钟没有支付，那么久必须订单系统自动关闭这个订单，后续你如果要购买这个订单里的商品，就得重新下单。 可能你的订单系统就需要有一个后台线程，不停地扫描订单数据库里所有的未支付状态的订单，如果它超过 30 分钟还没支付，那么就必须自动把订单状态更新为 “已关闭” 但是这里就出现了一个问题，就是订单系统的后台线程必须要不停地扫描各种未支付的订单，这种实现方式并不是很好。一个原因是未支付订单状态的订单可能是比较多的，然后你需要不停地扫描它们，可能每个未支付状态的订单要被扫描 N 多遍，才会发现它已经超过 30 分钟没支付了。 另一个是很难去分布式并行扫描你的订单。因为假设你的订单数据特别多，然后你打算用多台机器部署订单扫描服务，但是每天机器扫描哪些订单？怎么扫描？什么时候扫描？都是一系列的麻烦问题 因此针对这种场景，MQ 里的延迟消息就登场了。它特别适合在这种场景里使用，而且再实际项目中，MQ 的延迟消息使用的往往是很多的。 所谓的延迟消息，意思是我们订单系统在创建了一个订单之后，可以发送一条消息到 MQ 里去，我们指定这条消息是延迟消息，比如要等到 30 分钟之后，才能被订单扫描服务给消费到。 这样当订单扫描服务在 30 分钟后消费到了一条消息之后，就可以针对这条消息的信息，去订单数据库里查询这个订单，看看它在创建过后都过了 30 分钟了，此时它是否还是未支付状态？如果此时订单还是未支付状态，那么就可以关闭它，否则订单如果已经支付了，就什么都不用做了。如图： 这种方式就比你用后台线程扫描订单的方式要好得多，一个是对每个订单你只会在它创建 30 分钟后查询它一次而已，不会反复扫描订单多次。另外就是如果你的订单数量很多，你完全可以让订单扫描服务多部署几台机器，然后对 MQ 中的 Topic 可以多指定一个 Mess阿甘Q，这样每个订单扫描服务的机器作为一个 Consumer 都会处理一部分订单的查询任务。 所以 MQ 的延迟消息，是非常常用并且实用的一个功能。 RocketMQ 的延迟消息的代码实现接下来我们看一下 RocketMQ 中对延迟消息的代码实现。其实 RocketMQ 对延迟消息的支持是很好的，实现起来也非常容易，我们先看发送延迟消息的代码示例： 1234567891011121314151617181920212223public class ScheduledMessageProducer &#123; public static void main(String[] args) throws Exception &#123; // 这是订单系统的生产者 DefaultMQProducer producer = new DefaultMQProducer("OrderSystemProducerGroup");\ // 启动生产者 producer.start(); Message message = new Message( "CreateOrderInformTopic", // 这是创建订单通知 Topic orderInfoJSON.getBytes() // 这是订单信息的 json 串 ); // 这里设置了消息为延迟消息，延迟级别为 3 message.setDelayTimeLevel(3); // 发送消息 producer.send(message); &#125;&#125; 大家看上面的代码，其实发送延迟消息的核心，就是设置消息的 delayTimeLevel，也就是延迟级别。 RocketMQ 默认支持一些延迟级别如下： 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 所以上面代码中设置延迟级别为 3，意思就是延迟 10s，你发送出去的消息，会过 10s 被消费者获取到。那么如果是订单延迟扫描场景，可以设置级别为 16，也就是对应上面的 30 分钟 接着我们看看一个消费者，比如订单扫描服务，正常它会对每个订单创建的消息，在 30 分钟以后才获取到，然后去查询订单状态，判断是否是未支付的订单，就自动关闭这个订单。 12345678910111213141516171819202122232425262728293031323334public class ScheduledMessageConsumer &#123; public static void main(String[] args) throws Exception &#123; // 这里扫描服务的消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("OrderScanServiceConsumer"); // 订阅订单创建通知 Topic consumer.subscribe("CreateOrderInformTopic", "*"); // 注册消息监听者 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage( List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context) &#123; for(MessageExt message : messages) &#123; // 这里打印一下消息的存储时间到消费时间的差值 // 大概就是我们设置的延迟级别的时间 System.out.println("Receive message[msgId" + message.getMsgId() + "]" + (System.currentTimeMills() - message.getStoreTimestamp()) + "ms later"); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者 consumer.start(); &#125;&#125; 把延迟消息的使用搞明白之后，大家以后再自己的系统中就可以使用延迟消息去支持一些特殊的业务场景了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ - 消息乱序]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F16%2FRocketMQ-%E6%B6%88%E6%81%AF%E4%B9%B1%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[案例分析大数据团队需要获取订单数据库中的全部数据，然后将订单数据保存一份在自己的大数据存储系统中，比如 HDFS、Hive、HBASE 等。接着基于大数据技术对这些数据进行计算。 如果让大数据系统自己跑负责的大 SQL 在订单系统的数据库上来出一些数据报表，是会严重影响订单系统的性能的，所有采用了基于 canal 这样的中间件去监听订单数据库的 binlog，就是一些增删改查的日志，然后把这些 binlog 发送到 MQ 里去。接着大数据系统自己从 MQ 里获取 binlog，落地到自己的大数据存储中去，然后对自己的存储中的数据进行计算得到数据报表即可。如图： 大数据团队遇到的问题：数据指标错误这个方案运行一段时间后遇到了一些奇怪的问题。他们通过这个方案计算出来的数据报表，被发现很多数据指标都是错误的。于是他们就展开了排查，在对自己的大数据存储中的订单数据与订单数据库中的订单数据进行了一次比对之后，发现他们那儿的一些订单数据是不对的。比如在订单数据库中一个订单的字段 A 的值是 100，结果在大数据存储中的一个订单的字段 A 的值是 0 如果两边的订单数据的字段值不一致的话，必然导致最终计算出来的数据报表的指标是错误的。 订单数据库的 binlog 消息乱序针对这个问题，在系统中打印了很多的日志，观察了几天，发现订单数据库的 binlog 在通过 MQ 同步的过程中，出现了奇怪的消息乱序的现象。 比如订单系统在更新订单数据库的时候，有两条 SQL 语句： 12insert into order values(xx, 0);update order set xxvalue = 100 where id = xxx; 就是先插入一条数据，刚开始它一个字段的值是 0，接着更新它的一个字段的值是 100。然后这两条SQL 语句是对应是两个 binlog，也就是两个更新日志，一个 binlog 是 insert 语句的，一个 binlog 是 update 语句的，这个 binlog 会进入到 MQ 中去，然后大数据系统从 MQ 获取出来 binlog 的时候，居然是先获取出来了 update 语句的 binlog，然后再获取了 insert 语句的 binlog。 即，这个时候会先执行更新操作，但是此时数据根本不存在，没法进行更新，接着执行插入操作，也就是插入一条字段值为 0 的订单数据进去，最后大数据存储中的订单记录的字段值就是0 正是这个消息乱序的原因，导致了大数据存储中的数据都错乱了。 基于 MQ 来传输数据为什么会出现消息乱序这个原因很简单。我们之前讲过，可以给每个 Topic 指定多个 MessageQueue，然后你写入消息的时候，其实是会把消息均匀分发给不同的 MessageQueue 的。 比如我们在写入 binlog 到 MQ 的时候，可能会把 insert binlog 写入到一个 MessageQueue 里去，update binlog 写入到另外一个 MessageQueue 里去。 接着大数据系统在获取 binlog 的时候，可能会部署多台机器组成一个 Consumer Group，对于 Consumer Group 中的每台机器都会负责消费一部分 MessageQueue 的消息，所以可能一台机器上 ConsumeQueue01 中获取 insert binlog，一台机器从 ConsumeQueue02 中获取 update binlog。 上图中，是两台机器上的大数据系统并行地去获取 binlog，所以完全有可能是其中一个大数据系统先获取到了 update binlog 去执行，此时存储中没有数据，自然是没法更新的。然后另外一个大数据系统再获取到 insert binlog 去执行插入操作，最终导入只有一个字段值为 0 的订单数据。 消息乱序实际上，在使用 MQ 的时候出现消息乱序是非常正常的一个问题，因为我们原本有顺序的消息，完全有可能分发到不同的 MessageQueue 中去，然后不同的机器上部署的 Consumer 可能会用混乱的顺序从不同的 MessageQueue 里获取消息然后处理。所以在实际使用 MQ 的时候，我们必须要考虑到这个问题。 解决消息乱序问题上面我们分析了订单数据库同步过程中的消息乱序问题产生的根本原因，最关键的是，属于同一个订单的 binlog 进入不同的 MessageQueue，进而导致一个订单的 binlog 被不同机器上的 Consumer 来获取和处理。 让属于同一个订单的 binlog 进入一个 MessageQueue所以要解决这个消息乱序的问题，就得想办法让一个订单的 binlog 进入到一个 MessageQueue 里去。 举个例子，比如对一个订单，我们先后执行了 insert、update 两条 SQL 语句，也对对应了 2 个 binlog。那么我们就要想办法让这个订单的 2 个 binlog 都直接进入到 Topic 下的一个 MessageQueue 里去。我们可以怎么做？可以根据订单 id 来进行判断，我们可以往 MQ 里发送 binlog 的时候，根据订单 id 来判断一下，如果订单 id 相同，你必须保证它进入同一个 MessageQueue 我们可以采用取模的方法。比如有一个订单 id 是 1100，那么他可能有 2 个 binlog，对着两个 binlog，我们用订单 id = 1100 对 MessageQueue 的数量进行取模，比如 MessageQueue 一共有 15 个，那么此时 1100 对 15 取模，就是 5。即，凡是订单 id = 1100 的binlog，都应该进入位置为 5 的 MessageQueue 中去。 通过这个方法，我们就可以让一个订单的 binlog 都按照顺序进入到一个 MessageQueue 中去。如图： 获取 binlog 的时候也要有序接着，只要一个订单的 binlog 都进入一个 MessageQueue 就搞定这个问题了吗？显示不是的，我么要考虑一个问题，就是我们的 MySQL 的数据库的 binlog 是有顺序的。 比如，订单系统对订单数据执行两条 SQL，先是 insert 语句，然后是 update 语句，那么此时 MySQL 数据库自己必然是在磁盘文件里按照顺序写入 insert 语句的 binlog，然后写入 update 语句的 binlog。当我们从 MySQL 数据中获取它的 binlog 的时候，此时也必须是按照 binlog 的顺序来获取的，也就是说比如 Canal 作为一个中间件从 MySQL 那里监听和获取 binlog，那么当 binlog 传输到 Cancel 的时候，也必然是有先后顺序的 接着我们将 binlog 发送给 MQ 的时候，必须将一个订单的 binlog 都发送到一个 MessageQueue 里去，而且发送过去的时候，也必须是严格按照顺序来发送的。只有这样，最终才能让一个订单的 binlog 进入同一个 MessageQueue，而且还是有序的。如图： Consumer 有序处理一个订单的 binlog接着，一个 Consumer 可以处理多个 MessageQueue 的消息，但是一个 MessageQueue 只能交给一个 Consumer 来进行处理，所以一个订单的 binlog 只会有序地交给一个 Consumer 来进行处理。如图： 消息处理失败这样就万事大吉了吗？绝对不是，这样说过，在 Consumer 处理消息的时候，可能会因为底层存储挂了导致消息处理失败，此时可以返回 RECONSUME_LATER 状态，然后 Broker 会过一会自动给我们重试。但是这个方案是绝对不可以用在我们的有序消息中的。因为如果你的 consumer 获取到订单的一个 insert binlog，结果处理失败了，此时返回 RECONSUME_LATER，那么这条消息会进入重试队列，过一会才会交给你重试。 但是此时 Broker 会直接把下一条消息，也就是订单的 update binlog 交给你处理，此时万一你执行成功了，就根本没有数据可以更新。又会出现消息乱序的问题。 所以对于有序消息的方案中，如果你遇到消息处理失败的场景，就必须返回 SUSPEND_CURRENT_QUEUE_A_MOMENT 这个状态，意思是先等一会，一会再继续处理这批消息，而不能把这批消息放入重试队列去，然后直接处理下一批消息。 有序消息方案与其他消息方案的结合如果你一定要求消息是有序的，那么必须得用上述的有序消息方案，同时对这个方案，如果你要确保消息不丢失，那么可以和消息零丢失方案结合起来。如果你要避免消息重复处理，还需要在消费者那里处理消息的时候，去看一下，消息如果已经存在就不能重复插入等等。 同时还需要设计自己的消息处理失败的方案，也就是不能让消息进入重试队列，而是暂停等待一会，继续处理这批消息。 RocketMQ 的顺序消息机制的伪代码实现首先要实现消息顺序，必须让一个订单的 binlog 都进入一个 MessageQueue 中，此时我们可以写如下的代码： 12345678910111213141516SendResult sendResult = producer.send( message, new MessageQueueSelector() &#123; @Override public MessageQueue select( List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Long orderId = (Long) arg; // 根据订单id选择发送queue long index = id % mqs.size(); // 用订单id对MessageQueue 数量取模 return mqs.get((int) index); //返回一个MessageQueue &#125; &#125;, orderId //这里传入订单id); 上面代码中，我们看到关键因素有两个，一个是发送消息的时候传入一个 MessageQueueSelector，在里面你要根据订单 id 和 MessageQueue 数量去选择这个订单 id 的数据进入哪个 MessageQueue。同时在发送消息的时候除了带上消息自己以外，还要带上订单 id，然后 MessageQueueSelector 就会根据订单 id 去选择一个 MessageQueue 发送过去，这样的话，就可以保证一个订单的多个 binlog 都会进入一个 MessageQueue 中去。 消费者如何保证按顺序来获取一个 MessageQueue 中的消息接着，就是消费者如何按照顺序，来获取一个 MessageQueue 中的消息。 12345678910111213141516171819202122consumer.registerMessageListener( new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage( List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); try &#123; for(MessageExt msg : msgs) &#123; // 对有序的消息进行处理 &#125; return ConsumerOrderlyStatus.SUCCESS; &#125;catch(Exception e) &#123; // 如果消息处理有问题 // 返回一个状态，让它暂停一会再继续处理这批消息 return SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; &#125; &#125;); 在上面的代码中，有一个点要注意一下。我们使用的是 MessageListenerOrderly 这个东西，它里面有 Orderly 这个名词，也就是说，Consumer 会对每一个 ConsumeQueue，都仅仅用一个线程来处理其中的消息。 比如对 ConsumeQueue01 中的订单 id = 1100 的多个 binlog，会交给一个线程来按照 binlog 顺序依次处理。否则如果 ConsumeQueue01 中的订单 id = 1100 的多个 binlog 交给 Consumer 的多个线程来处理的话，那还是会有消息打乱的问题。 基于 RocketMQ 的数据过滤机制，提升订单数据库同步的处理效率我们讲完了消息顺序方案，现在我们基于订单数据库同步的这个场景，来简单看一下如何对混杂在一起的数据进行过滤的方案。 我们都知道，一个数据库可能包含很多表的数据，比如订单数据库，它里面除了订单信息表以外，可能还包含很多其他的表。所以我们在进行数据库 binlog 同步的时候，很可能是把一个数据库里所有表的 binlog 都推送到 MQ 里去的。 所以在 MQ 的某个 Topic 中，可能是混杂了订单数据的几个甚至十几个表的 binlog 数据，不一定仅仅包含我们想要的表的 binlog 数据。 处理不关注的表 binlog，是很浪费时间的此时假设我们的大数据系统仅仅关注订单数据库中的表 A 的 binlog，并不关注其它表的 binlog，那么大数据系统可能需要在获取到所有表的 binlog 之后，对每一条 binlog 判断一下，是否是表 A 的binlog？如果不是表 A 的binlog，就直接丢弃不处理；如果是表 A 的binlog，才会去进行处理。 但是这样，必然会导致大数据系统处理很多不关注的表的 binlog，也会很浪费时间，降低效率。 发送消息的时候，给消息设置 tag 和属性针对这个问题你，我们可以采用 RocketMQ 支持的数据过滤机制，来让大数据系统仅仅关注它想要的表的 binlog 数据即可。 我们在发送消息的时候，可以给消息设置 tag 和属性，如下： 123456789Message msg = new Message( "TopicOrderDbData", // 这是我们订单数据库写入的 Topic "TableA", // 这是这条数据的 tab，可以是表的名字 ("binlog").getBytes(RemotingHelper.DEFAULT_CHARSET) // 这是一条 binlog 数据);// 我们可以给一条消息设置一些属性msg.putUserProperty("a", 10);msg.putUserProperty("b", "abc"); 上面的代码清晰地展示了我们发送消息的时候，其实是可以给消息设置 tag、属性等多个附加的消息的。 消费数据的时候根据 tag 和属性进行过滤接着我们可以在消费的时候根据 tag 和 属性进行过滤，比如我们可以通过下面的代码去指定，我们只要 tag = TableA 和 tag = TableB 的数据。 1consumer.subscribe("TopicOrderDbData", "TableA || TableB"); 或者我们也可以通过下面的语法去指定，我们要根据每条消息的属性的值进行过滤，此时可以支持一些语法，比如： 12consumer.subscribe("TopicOrderDbData", MessageSelector.bySql("a &gt; 5 AND b = 'abc'")); RocketMQ 还是支持比较丰富的数据过滤语法的，如下： 数值比较，比如：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，= 字符比较，比如：=，&lt;&gt;，IN IS NULL 或者 IS NOT NULL 逻辑符号 AND，OR，NOT 数值，比如：123，3.1415 字符，比如：’abc’，必须用单引号包裹起来 NULL，特殊的常量 布尔值，TRUE 或 FLASE 基于数据过滤减轻 Consumer 负担在使用 MQ 的时候，如果 MQ 里混杂了大量的数据，可能 Consumer 仅仅对其中一部分数据感兴趣，此时可以在 Consumer 端使用 tag 等数据过滤语法，过滤出自己感兴趣的数据来消费。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ-重发机制]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F15%2FRocketMQ-%E9%87%8D%E5%8F%91%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[背景示例今天客户给技术团队反馈了一个问题，说是有用户在支付一个订单之后，一下子收到了多个优惠券，本来按照规则只应该有一个优惠券的。也就是说，我们给用户重复发放了一个优惠券 优惠券系统重复消费了一条消息目前订单系统已经跟各个系统进行了解耦，也就是说当订单支付成功之后，会发送一条消息到 MQ 里去，然后红包系统从里面获取消息派发红包，优惠券系统从里面获取消息派发优惠券，其他系统也是同理。 通过查看日志发现，优惠券系统对同一个订单支付成功的消息处理了两次，就导致给用户重复发放了两张优惠券。为什么优惠券会对同一个消息重复处理两次？ 订单系统发送消息到 MQ 的时候会重复吗首先，我们的订单系统在收到一个支付成功的通知之后，它在发送消息到 MQ 的时候，会重发把一个消息发送两次吗？这是有可能的。 首先，假设用户在支付成功之后，我们的订单系统收到了一个支付成功的通知，接着它就向 MQ 发送了一条订单支付成功的消息。但是可能因为不知道什么原因，你的订单系统处理的速度有点慢。然后可能因为你的订单系统处理的速度有点慢，这就导致支付系统跟你订单系统之间的请求出现了超时，此时有可能支付系统再次重试调用了你订单系统的接口去通知了，然后你的订单系统这个时候可能有一次推送了一条消息到 MQ 里去，相当于是一个订单支付成功的消息，你重复推送了两次到 MQ。 此时相当于是 MQ 里就会对一个订单的支付成功消息，总共有两条。 如果订单系统重复推送了两次支付成功消息的 MQ，MQ 里对一个订单有两条重复的支付成功消息，优惠券必然会消费到一个订单的两条重复的支付成功消息，也会针对这个订单用户重复地派发两个优惠券。 因此，如果出现了接口超时等问题，可能会导致上游的支付系统重试调用订单系统的接口，进而导致订单系统对一个消息重复发送两条到 MQ 里去。 订单系统自己重复发送消息假设支付系统没有对一个订单重复调用你的订单系统的接口，而是你订单系统自己可能就重复发送消息到 MQ 里去。假设我们的订单系统为了保证消息一定能投递到 MQ 里去，因此采用了重试的代码，如下面的代码片段，如果发现 MQ 发送有异常，则会进行几次重试。 12345678910111213try &#123; // 执行订单本地事务 orderService.finishOrderPay(); // 发送消息到 MQ 去 producer.sendMessage();&#125;catch(Exception e) &#123; // 如果发送消息失败了，进行重试 for(int i = 0; i &lt; 3; i++) &#123; // 重试发送消息 &#125; // 如果多次充实发送消息之后，还是不行，回滚本地订单事务 orderService.rollbackOrderPay();&#125; 但是这种重试的方式 ，其实是一把双刃剑，因为正是这个重试可能导致消息重复发送。我们来考虑一个情况，假设你发送一条消息到 MQ 了，其实 MQ 是已经收到这条消息了，结果 MQ 返回响应给你的时候，网络有问题了超时了，就是你没能及时收到 MQ 返回给你的响应。但是，此时 MQ 里其实是已经有你发送过去的消息了，只不过它返回给你的响应没能给到你而已。 这个时候，你的代码里可能会发现一个网络超时的异常，然后你就会进行重试再次发送这个消息到 MQ 去，然后 MQ 会收到一条一模一样的消息，进而导致你的消息重复发送了。 所以这种重试代码大家在使用的时候要小心，因为它还是有一定的概率会导致你重发消息的。 优惠券系统重复消费一条消息接着我们继续，即使你没有重复发送消息到 MQ，哪怕 MQ 里就一条消息，优惠券系统也有可能会重复进行消费。 假设你的优惠券系统拿到一条订单支付成功的消息，然后都已经进行处理了，也就是说都已经对这个订单发了一张优惠券了，这个时候它应该返回一个 CONSUME_SUCCESS 的状态，然后提交消费进度 offset 到 broker 的。 但是，你刚发完优惠券，还没来得及提交消息 offset 到 broker，优惠券系统就进行了一次重启，这是因为你没提交这条消息的 offset 给 broker，broker 并不知道你已经处理了这条消息，然后优惠券系统重启之后，broker 就会再次把这条消息交给你，让你再一次进行处理，然后你会再一次发送一张优惠券，导致重复发送了两次优惠券。 消息重复问题实际上，对类似优惠券系统这样的业务系统，一般会频繁地更新代码，可能每隔几天就需要重启一次系统进行代码的更新。所以你重启优惠券系统的时候，可能有一批消息刚处理完，还没来得及提交 offset 给 broker，然后你重启之后就会再一次重复处理这批数据，这种情况是比较常见的。 另外就是对于系统之间的调用，有的时候出现超时和重试的情况也是很常见的，所以你负责发消息到 MQ 的系统，很可能时不时地出现一次超时，然后被别人重试调用你的接口，你可能会重复发送一条消息到 MQ 里去，这也是很常见的。 引入幂等性机制要解决上述问题，我们就要先引入一个概念，叫做幂等性机制。这个幂等性机制，就是用来避免对同一个请求或者同一条消息进行重复处理的机制。幂等，就是比如你有一个接口，然后如果别人对一次请求重试了多次，来调用你的接口，你必须保证自己系统的数据是正常的，不能多出来一些重复的数据，这就是幂等性的意思。 发送消息到 MQ 的时候如何保证幂等性当我们的订单系统发送消息到 MQ 的时候需要保证幂等性吗？订单系统的接口有可能被重复调用导致发送重复的消息到 MQ 去，也可能有重试机制导致发送重复的消息到 MQ。那我们应该怎样避免这种情况？ 业务判断法业务判断法。也就是说你的订单系统必须要知道自己到底是否发送过消息到 MQ 去，消息到底是否已经在 MQ 里了。 例如，当支付系统重试调用你的订单系统的接口时，你需要发送一个请求到 MQ 去，查询一下当前 MQ 里是否存在针对这个订单的支付消息？如果 MQ 告诉你，针对 id = 1000 这个订单的支付成功消息，MQ 已经有了，那么订单系统可以不要再次发送这条消息到 MQ 去了。 这个业务判断法的核心在于，你的消息肯定是存在于 MQ 里的，到底发没发送过，只有 MQ 知道，如果没发送过这个消息，MQ 肯定没有这个消息，如果发送过这个消息，MQ 里就有这个消息。 所以当你的订单系统的接口被重试调用的时候，你这个接口上来就应该发送请求到 MQ 里查询一下，如果在 MQ 中已经存在，那就不再重复发送消息了。 基于 Redis 缓存的幂等性机制第二种方法，就是状态判断法。 这个方法的核心在于，你需要引入一个 Redis 缓存来存储你是否发送过消息的状态，如果你成功发送了一个消息到 MQ 里去，你得在 Redis 缓存里写一条数据，标记这个消息已经发送过。 那么当你的订单接口被重读调用的时候，你只要根据订单 id 去 Redis 缓存里查询一下，这个订单的支付消息是否已经发送给 MQ 了，如果发送过了，就别再次发送了。 其实两种幂等性机制都是很常用的，但是，基于 Redis 的状态判断法，有可能没办法完全做到幂等性。例如，你的支付系统发送请求给订单系统，然后已经发送消息到 MQ 去了，但是此时订单系统突然崩溃了，没来得及把消息发送的状态写入 Redis。这个时候如果你的订单系统在其他机器上部署了，或者是它重启了，那么这个时候订单系统被重试调用的时候，它去找 Redis 查询消息发送状态，会以为消息没发送过，然后会再次发送重复消息到 MQ 去。 有没有必要在订单系统环节保证消息不重复发送在我们这个场景中，如果在订单系统要保证消息不重复发送，上面讲的两种方案，其实都不是太好。因为 RocketMQ 虽然是支持你查询某个消息是否存在，但是在这个环节你直接从 MQ 查询消息是没这个必要的，它的性能也不是太好，会影响你的接口的性能。 另外基于 Redis 的消息发送状态的方案，在极端情况下还是没法 100% 保证幂等性，所以也不是特别好的一个方案。所以在这里建议是不用在这个环节保证幂等性，也就是我们可以默许它可能会发送重复的消息到 MQ 里去。 优惠券系统如何保证消息处理的幂等性接着我们来看优惠券系统假设会拿到重复的消息，那么如何保证消息处理的幂等性？这个就比较简单了，直接基于业务判断法就可以了，因为优惠券每次拿到一条消息后会给用户发一张优惠券，实际上核心就是在数据库里给用户插入一条优惠券记录。 那么如果优惠券系统从 MQ 那里拿到一个订单的两条重复支付成功消息，这个时候它只要先去优惠券数据库中查询一下，比如对订单 id = 1000 的订单，是否已经发放过优惠券了，如果有的话，就不要重复发券了。通过这个业务判断的方法，就可以简单高效地避免消息的重复处理了。 MQ 消息幂等性的方案总结一般来说，对于 MQ 的重复消息问题而言，我们往 MQ 里重复发送一些消息其实还是可以接收的，因为 MQ 里有许多条重复消息，它不会对系统的核心数据直接造成影响，但是我们关键要保证的，是你从 MQ 里获取消息进行处理的时候，必须保证消息不能重复处理。 要保证消息的幂等性，优先推荐的其实还是业务判断法，直接根据你的数据存储中的记录来判断这个消息是否已经处理过，如果处理过，就不需要再处理了。因为，基于 Redis 的消息发送状态的方案，在一些极端情况下还是无法保证幂等性的。 死信队列解决数据库宕机问题上述我们已经分析和解决了 MQ 实践使用过程中可能存在的消息丢失问题和消息重复问题，现在假设我们可以基本确保 MQ 的消息不丢失，同时不会对消息进行重复处理，在正常流程下，基本没啥问题。 假设我们的 MQ 使用过程中都没问题，但是如果我们的优惠券系统的数据库宕机了呢？这个时候，就会导致我们从 MQ 里获取到消息之后是没办法进行处理的。现在我们对这个实际的生产场景进行分析。 数据库宕机的时候，可以返回 CONSUME_SUCCESS 吗我们看下面的代码片段，可以看到，我们注册了一个监听器回调函数，当 Consumer 获取到消息之后，就会交给我们的函数来处理。 123456789consumer.registerMessageListener(new MessageListenerConcurrently() &#123; public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; // 在这里对获取到的 msgs 订单消息进行处理 // 比如增加积分，发送优惠券，通知发货等等 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;) 上述代码返回 CONSUME_SUCCESS，那么 Consumer 就知道这批消息处理完成了，就会提交这批消息的 offset 到 broker 去，然后下次就会继续从 broker 获取下一批消息来处理。 但是如果此时我们在上面的回调函数中，对一批消息发优惠券的时候，因为数据库宕机了，导致优惠券发放逻辑无法完成，此时我们还能返回 CONSUME_SUCCESS 状态码？如果你返回的话，下一次就会处理下一批消息，但是这批消息其实没处理成功，此时必然导致这批消息就丢失了。 消息处理有异常，可以返回 RECONSUME_LATER 状态实际上如果我们因为数据库宕机等问题，对这批消息的处理是异常的，此时没法处理这批消息，我们就应该返回一个 RECONSUME_LATER 状态。它的意思是，我现在没法完成这批消息的处理，你稍后过段时间再次给我这批消息让我重试一下。 所以，我们应该改成如下的代码： 123456789101112131415consumer.registerMessageListener(new MessageListenerConcurrently() &#123; public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; try &#123; // 在这里对获取到的 msgs 订单消息进行处理 // 比如增加积分，发送优惠券，通知发货等等 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; catch(Exception e) &#123; // 如果因为数据库宕机等问题，对消息处理失败了 // 此时返回一个稍后重试消费的状态 return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; &#125;&#125;) RocketMQ 是如何让你进行消费重试的RocketMQ 在收到你返回的 RECONSUME_LATER 状态之后，是如何让你进行消费重试的？简单说，RocketMQ 会有一个针对你这个 ConsumerGroup 的重试队列。如果你返回了 RECONSUME_LATER 状态，它会把你这批消息放到你这个消费组的重试队列中去。 比如你的消费组的名称是 “VoucherConsumerGroup”，意思是优惠券系统的消费组，那么它会有一个 “%RETRY%VoucherConsumerGroup” 这个名字的重试队列。如图： 然后过一段时间之后，重试队列中的消息会再次发送给我们，让我们进行处理。如果再次失败，又返回了 RECONSUME_LATER，那么会再过一段时间让我们来处理，默认最多是重试 16 次。每次重试之间的间隔时间是不一样的，这个间隔时间可以进行如下配置： 1messageDelayLevel = 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 上面这段配置的意思是，第一次重试是 1秒 后，第二次重试是 5秒 后，第三次重试是 10秒 后，第四次重试是 30秒 后，第五次重试是 1分钟 后，以此类推，最多重试 16 次。 连续重试 16 次还是无法处理消息如果在 16次 重试范围内消息处理成功了，自然没问题，但是如果你对一批消息重试了 16 次还是无法成功处理，这个时候就需要另外一个队列了，叫死信队列。所谓的死信队列，就是死掉的消息就放进这个队列里。 什么是死掉的消息？就是一批消息交给你处理，你重试了 16 次还是一直没处理成功，就不要继续重试这批消息了，你就认为他们死掉了就可以了。然后这批消息就会自动进入死信队列。死信队列的名字是 “%DLQ%VoucherConsumerGroup”。我们在 RocketMQ 的管理后台上是可以看到的。如图： 那么我们对死信队列中的消息我们怎么处理？其实这个就看你的使用场景了，比如我们可以专门开一个后台线程，就是订阅 “%DLQ%VoucherConsumerGroup” 这个队列，对死信队列中的消息，还是一直不停地重试。 总结这一次我们搞清楚了另外一个生产环境下的问题，就是消费者底层的一些依赖可能有故障，比如数据库宕机，缓存宕机之类的，此时就就没办法完成消息的处理了，那么可以通过一些返回状态去让消息进入 RocketMQ 自带的重试队列，如果反复重试还是不行，可以让消息进入 RocketMQ 自带的死信队列，后续针对死信队列中的消息进行单独的处理就可以了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见的网络攻击]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F12%2F%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BD%91%E7%BB%9C%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[XSS 攻击XSS 的全称是 Cross Site Script，就是跨站点脚本攻击，意思就是，黑客恶意篡改你的网页的前端代码，在里面注入一些它自己的 html + JavaScript 的脚本和代码，然后在你访问那个网站的网页的时候，他注入的那些恶意脚本就会运行。恶意脚本运行的时候就会控制你的浏览器，这个时候它的脚本就可以做很多的事情了。 XSS 反射性攻击第一种 XSS 攻击是反射性攻击，它主要是想办法让你点击一个 URL 链接，在这个 URL 链接里就嵌入它自己的恶意脚本，你点击那个 URL 链接之后，那个 URL 指向的是黑客自己服务器上的一段恶意脚本。 它可能给你展示的是一个图片，或者是一个 flash 动图，亦或是一个小视频的东西，引诱你去点击，然后恶意脚本被返回到你的浏览器里运行，就可以控制你的浏览器里的行为了。这个控制行为就很恐怖了，它可以干很多事情，比如说脚本可以让你自动关注某个用户 id，然后控制你发自动发布一个带有病毒的微博，这是比较简单的。 实际上，一段恶意的 JS 脚本，几乎是无恶不作的。因为它一旦控制你的浏览器就可以得到大量的东西。浏览器一般包含了你的一些 cookie，有的浏览器还可能存储了你的密码，通过知道你的 cookie，就可以利用 cookie 伪造你的用户登录的 session 状态，以你的名义去干一些事情。 XSS 持久型攻击另一种 XSS 攻击是叫持久型攻击。举个例子，例如一个论坛，或者社交网站之类的系统，你可以发布一些帖子，或者是评论啥的内容，此时黑客就可以在里面写一段恶意脚本，然后把恶意脚本混杂在评论内容里提交到你的网站数据库里去。 然后后面其他用户在社交网站里浏览到你的评论，评论内容会被返回到浏览器里去，此时评论内容是包含恶意 JS 脚本的。恶意脚本一运行，又可以干坏事了。 解决方案消毒机制。就是说，如果黑客在一些评论之类的内容里混入恶意脚本，那么你的代码必须对内容进行消毒，就是进行一些转义。这样就可以把恶意脚本里的 HTML 标签，JS 代码之类的东西，给转义掉，让这些恶意脚本失效。 HttpOnly 方式。如果你在浏览器里存放 cookie 的时候，可以设置一个 HttpOnly 属性，比如存放用户加密认证消息的 cookie，这样的话，在浏览器里运行的 JS 脚本是被禁止访问这些 HttpOnly cookie 的。他就无法窃取你在浏览器里存储的 cookie 了。 SQL 注入系统在数据库里执行 SQL 语句的时候，可能也存在漏洞，导致黑客把一些恶意的 SQL 语句注入进去，让你的系统在你的数据库里执行。例如下面这么一个请求： 1http://www.xxx.com/goods?goodsSkuNo=xxxxx 通过前端传递 goodsSkuNo 的数据 “xxxxx”，然后在后台执行这么一条 SQL 语句来查询数据： 1SELECT * FROM eshop_goods_sku WHERE goods_sku_no = 'xxxxx' 但是如果后台的 SQL 语句是手动拼接的，那前端传过来的数据有可能就会拼接成如下的 SQL 语句： 1SELECT * FROM eshop_goods_sku WHERE goods_sku_no = 'xxxxx'; drop table eshop_goods_sku;--'; 这样就直接恶意给你造成删库跑路的效果了。这还不算什么，关键是这种 SQL 语句里可以拼接进入各种支持的 SQL 语法，包括对数据库施加的命令，甚至通过附加一些脚本直接窃取你的数据，都是有可能的。 但是如果要给你搞 SQL 注入，其实也不是那么容易的，因为必须要知道你的数据库表结构才行。一般获取数据库表结构的方式就下面几种： 如果你使用的是开源软件，比如开源的博客系统，论坛系统，或者别的什么系统，那么人家自然知道你的表结构了。这种情况是比较少见的。 错误回显。就是有时候把系统跑在 web 服务器里，然后程序报错了，结果直接在浏览器页面上显示出来你的异常堆栈信息，包括有错误的 SQL 语句。这就尴尬了，通过这个，黑客就知道你的表结构了。 根据你的请求参数的名称，大致推测你的数据库表结构。这个一般不现实。 所以要防止 SQL 注入，一个是别让人家知道你的数据表结构，关闭 web 服务器的错误回显，显示一个 400,500 之类的就可以了。另外，就是要用预编译的方式。现在 mybatis、hibernate 都是支持预编译的。 预编译，放到底层的 JDBC 里，就是 PrepareStatement 对SQL 进行预编译。如果你给 SQL 的某个参数传入进去的是一个恶意 SQL 语句，人家预编译过后，会让你的恶意 SQL 语句是无法执行的，所以千万不要直接自己用字符串去拼接 SQL 语句。 例如 INSERT INTO xxx_table(xx, xxx, xx) VALUES(?, ?, ?) 对这个 SQL 进行预编译，然后把里面各个参数设置进去，此时参数里如果带有恶意 SQL 是不会作为 SQL 去执行的。 在 Mybatis 中。对这个方法比如传进去一个 map 或者是对象，mybatis 会根据你的占位符的变量名字，从你的 map 里或者是对象里提取出来一个一个的参数的值，进行预编译 SQL 的参数值的设置。 1INSERT INTO xxx_table(xx, xxx,xx) VALUES(#&#123;xx&#125;, #&#123;xxx&#125;, #&#123;xx&#125;) 这个预编译，就是说把黑客在参数里混进来的 SQL 语句当做一个参数，而绝对不会作为独立的 SQL 语句去执行，这就避免了 SQL 注入攻击了。 CSRF 攻击CSRF（Cross Site Request Forgery），跨站点请求伪造。这个就是黑客想办法去伪造你这个用户发送请求到某个系统上去，然后查询你的数据，或者进行转账交易之类的。伪装成你，有很多办法，比如利用 XSS 搞一个恶意脚本让你执行，然后盗取你的浏览器里的 cookie，利用你的 cookie 伪装成你登录的状态，然后去执行一些请求。 防御 CSRF 的方法主要是以下几种： 防止 cookie 被窃取：最根本的，还是防止 cookie 被窃取，可以给你的网站的cookie 设置 HttpOnly 属性，禁止别别人的 script 脚本窃取，那么别人就无法伪造用户登录请求了。 随机 token：每次返回一个页面给你的时候，都生成一个随机 token 附加在页面的随机元素里，同时可以在你的 redis 里可以存一下，然后页面发送请求的时候附加随机 token，验证过来才能执行请求，黑客要是用 postman 构造请求就不知道随机 token 是什么了 验证码：页面提交搞一个验证码，那种图形的。现在比较流行的还有拖动一个拼图什么的，必须验证码通过了才能执行你的请求，避免黑客直接伪造请求发送过来，这个其实是比较常见的，最好是在用户进行支付交易的时候，要求必须在页面上拖拽一个拼图验证码 Referer请求头：这个是 http 请求里有一个 referer 请求头，带有这个请求头的来源，你可以验证一下这个请求是不是从自己的页面里来的，如果是的话才执行，否则就不要执行。 文件上传可以遭受的攻击很多时候我们的网站允许别人上传文件，那么文件可能是可执行的脚本，可能是病毒或者木马文件，这个是非常危险的。如果是脚本的话，可能在服务器执行，搞很多破坏，比如黑客黑掉你的服务器，勒索你给他比特币之类的。他们会把自己的文件后缀改成 .jpg、.txt 之类的来上传，其实本质上是病毒文件。 对于文件上传这块，核心就是要进行白名单校验，限制上传文件的类型，而且要限制文件的大小，还要对文件重命名。限制文件类型不能简单地根据后缀来判断，要根据文件二进制数据的开头几个字节代表的 magic number 来判断文件的类型。例如 JPEG 的魔数是 FFD8FF；PNG 的魔数是 89504E47。以此类推。 网上可以查到完整的 magic number 列表，根据这个限制一下，哪些文件可以上传，这样就避免木马、病毒之类的可执行文件被上传了。 另外，最好对文件进行一定的压缩，这样可以破坏原来的 文件结构，避免文件在服务器执行。利用 imagemagick 这种开源包，可以很方便进行文件缩放。 DDoSDDoS，distributed denial of service，分布式拒绝服务攻击。可以把你的网站、APP、系统搞瘫痪了。DDos 攻击，就是说黑客知道你的服务器地址了，然后你的系统假设每秒就抗 1000 请求，黑客就以每秒 1000 请求访问你，你的服务器线程资源全部打满，正常用户根本无法发送请求，你的网站就宕机了。甚至他以每秒 1万 请求攻击你的服务器，那你的系统机器就挂了。 Dos 攻击是一对一的，就是黑客搞一台高性能服务器，拼命发送请求给你的一台服务器，但是如果你的服务器配置超高，每秒抗 1万 请求，结果黑客的机器才每秒 5000 请求，那么就没用了。 DDos 意思就是黑客控制大量的机器，比如普通人的电脑，或者是一些公司的服务器，被他的一些木马植入给控制了，就是所谓的 “肉鸡”，然后黑客下达指令，让所有肉鸡一起发送请求给攻击目标，直接搞瘫你的服务器。 如何防御 DDoS 攻击？如果只靠自己还是挺难的，这其实是非常专业的一种攻击手段，通常我们可以采购云厂商的安全服务，比如 DDoS 高防 IP，可以把攻击流量到导入到云厂商的高防 IP 的服务器上去，他们有专业的技术方案和算法来防御。 基于 SYN Flood 模式的 DDoS 攻击我们简单说一下 TCP 三次握手： 客户端发送一个 SYN 请求，指明客户端的端口号以及 TCP 连接的初始序列号 服务器收到 SYN 后，返回一个 SYN + ACK，表示请求被接收，TCP 序列号加 1 客户端收到服务器的 SYN + ACK 后，返回一个 ACK 给服务器，TCP 序列号加 1，连接建立完毕，接着可以通信了。 如果服务器没有收到第三步的 ACK，会重试返回 SYN + ACK 给客户端，同时处于 SYN_RECV 状态，把客户端放入等待列表，重试会 3 ~ 5 次，每隔 30 秒重试一次，遍历等待列表，再次重试发送 SYN + ACK]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ - 事务消息机制的底层原理]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F09%2FRocketMQ-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[half 消息的实现我们之前已经说过了 RocketMQ 事务消息的全流程。在这个流程中，第一步就是要由订单系统去支付一个 half 消息给 MQ。当时我们说过，对于这个 half 消息，红包系统这个时候是看不到它的，没法消费这条消息去处理，那这个 half 消息是如何做到的？ 其实 RocketMQ 底层采取了一个巧妙的设计。举个例子，订单系统发送了一个 half 状态的订单支付消息到 “OrderPaySuccessTopic” 里去，这是一个 Topic。然后，红包系统也是订阅了这个 “OrderPaySuccessTopic” 从里面获取消息的。 之前我们有讲过，写入一个 Topic，最终是定位到这个 Topic 的某个 MessageQueue，然后定位到一台 Broker 机器上去，然后写入的是 Broker 上的 CommitLog 文件，同时将消费索引写入 MessageQueue 对应的 ConsumeQueue 文件。所以你写入一条 half 消息到 “OrderPaySuccessTopic” 里去，会定位到这个 Topic 的一个 MessageQueue，然后定位到 RocketMQ 的一台机器上去，按理说，消息会写入 CommitLog。 同时消息的 offset 会写入 MessageQueue 对应的 ConsumeQueue，这个 ConsumeQueue 是属于 OrderPaySuccessTopic 的，然后红包系统按理说会从这个 ConsumeQueue 里获取到你写入的这个 half 消息。但是实际上红包系统却没法看到这条消息，原因就是 RocketMQ 一旦发现你发送的是一个 half 消息，它不会把这个 half 消息的 offset 写入 OrderPaySuccessTopic 的 ConsumeQueue 里去。 它会把这条 half 消息写入到自己内部的 “RMQ_SYS_TRANS_HALF_TOPIC” 这个 Topic 对应的一个 ConsumeQueue 里去。如图： 真相大白了，所以对于事务消息机制之下的 half 消息，RocketMQ 是写入内部的 Topic 的 ConsumeQueue 的，不是写入你指定的 OrderPaySuccessTopic 的 ConsumeQueue 的。 什么情况下订单系统会收到 half 消息成功的响应接着，在什么情况下订单系统会收到 half 消息成功的响应呢？结合上面的内容，可以判断出，必须要 half 消息进入到 RocketMQ 内部的 RMQ_SYS_TRANS_HALF_TOPIC 的 ConsumeQueue 文件了，此时就会认为 half 消息写入成功了，然后就会返回响应给订单系统。 所以这个时候，一旦你的订单系统收到这个 half 消息写入成功的响应，就知道这个 half 消息已经在 RocketMQ 内部了。 没有执行 rollback 或者 commit 会怎样接着，如果因为网络故障，订单系统没有收到 half 消息的响应，或者说自己发送的 rollback/commit 请求失败了，那么 RocketMQ 会干什么？其实这个时候它会在后台有定时任务，定时任务会去扫描 RMQ_SYS_TRANS_HALF_TOPIC 中的 half 消息，如果你超过一定时间还是 half 消息，它会回调订单系统的接口，让你判断这个 half 消息是要 rollback 还是 commit。如图： 执行 rollback，如何标记消息回滚假设我们的订单系统执行了 rollback 请求，那么此时就需要对消息进行回滚。之前我们说过，RocketMQ 会把这个 half 消息给删除，但是大家觉得删除消息是真的会在磁盘文件里删除吗？ 显然不是的，因为 RocketMQ 都是顺序把消息写入磁盘文件的，所以在这里如果你执行 rollback，它的本质就是用一个 OP 操作来标记 half 消息的状态。RocketMQ 内部有一个 OP_TOPIC，此时你可以写一条 rollback OP 记录到这个 topic 里，标记某个 half 消息是 rollback 了。如图： 另外，假设你一直没有执行 commit/rollback，RocketMQ 会回调订单系统的接口去判断 half 消息的状态，但是它最多就是回调 15 次，如果 15 次之后你没法告知它 half 消息的状态，就自动把消息标记为 rollback。 执行 commit 操作，如何让消息对系统可见最后，如果订单系统执行了 commit 操作，如何让消息对这个红包系统可见？其实也简单，你执行 commit 之后，RocketMQ 就会在 OP_TOPIC 里写入一条记录，标记 half 消息已经是 commit 状态了。接着需要把放在 RMQ_SYS_TRANS_HALF_TOPIC 中的 half 消息写入到 OrderPaySuccessTopic 的 ConsumeQueue 里去，然后我们的红包系统就可以看到这条消息进行消费了。 总结看到这里，大家对事务消息机制的底层原理应该比较了解了。其实它的本质都是基于 CommitLog、ConsumeQueue 这套存储机制来做的，只不过中间有一些 Topic 的变换，half 消息可能就是写入内部 Topic 的。 Broker 消息零丢失方案：同步刷盘 + Raft 协议主从同步如果我们在生产消息的时候用了事务消息之后，就可以保证数据不会丢失吗？假设我们现在订单系统已经通过事务消息的机制，通过 half 消息 + commit 的方式，把消息在 MQ 里提交了。也就是说，现在对于 MQ 而言，那条消息已经进入它的存储层了，可以被红包系统看到了。 但是，你的这条消息在 commit 之后，会从 half topic 里进入 OrderPaySuccessTopic 中，但是此时仅仅是消息进入了这个你预定的 Topic 而已，仅仅是可以被红包系统看到而已，此时可能你的红包系统还没来得及去获取这条消息。 然后恰巧这个时候，你的这条消息仅仅停留在 os cache 中，还没有进入到 ConsumeQueue 磁盘文件里，然后此时这台机器突然宕机了，os cache 中的数据全部丢失了，此时会导致你的消息丢失，红包系统再没机会读到这条消息了。 接着，就算我们运气好，消息已经进入 OrderPaySuccessTopic 的 ConsumeQueue 磁盘文件了，不是停留在 os cache 里，此时消息就一定不会丢失吗？这也未必，即使消息已经进入磁盘文件了，但是这个时候红包系统还没来得及消费这条消息，然后此时这台机器的磁盘突然坏了，就会一样导致消息丢失，而且可能消息再也找不回来了，同样丢失数据。 保证消息写入 MQ 不代表不丢失所以，我们要明确一个前提，哪怕我们确保消息已经写入 MQ 成功了，此时也未必消息就不会丢失了。因为即使你写入 MQ 成功了，这条消息也大概率是仅仅停留在 MQ 机器的 os cache 中，一旦机器宕机内存里的数据都会丢失。即使消息已经写入了 MQ 机器的磁盘文件里，但是磁盘一旦坏了，消息也会丢失。 异步刷盘 VS 同步刷盘到底怎么去确保消息写入 MQ 之后，MQ 自己不要随便丢失数据呢？解决这个问题的第一个关键点，就是将异步刷盘调整为同步刷盘。所谓的异步刷盘，即使之前我们一直说的那种模式，即，你的消息即使成功写入了 MQ，它也就在机器的 os cache 中，没有进入磁盘里，要过一会等操作系统自己把 os cache 里的数据实际刷入磁盘文件中。 所以在异步刷盘的模式下，我们的写入消息的吞吐量肯定是极高的，毕竟消息只要进入 os cache 这个内存就可以了，写消息的性能就是写内存的性能，那每秒钟可以写入的消息数量肯定更多了，但是这个情况下，可能会导致数据的丢失。 所以如果一定要保证数据零丢失的话，可以调整 MQ 的刷盘策略，我们需要调整 Broker 的配置文件，将其中的 flushDiskType 配置设置为 SYNC_FLUSH，默认它的值是 ASYNC_FLUSH，即默认是异步刷盘的。 如果调整为同步刷盘之后，只要 MQ 返回响应式 half 消息发送成功了，那么就说明消息已经进入磁盘文件了，不会停留在 os cache 里。如图： 通过主从架构模式避免磁盘故障导致的数据丢失接着，如何避免磁盘故障导致的数据丢失？其实道理也很简单，我们必须要对 Broker 使用主从架构模式。也就是说，必须让一个 Master Broker 有一个 Slave Broker 去同步它的数据，而且你一条消息写入成功，必须是让 Slave Broker 也写入成功，保证数据有多个副本的冗余。如图： 这样一来，你一条消息写入成功，此时主从两个 Broker 上都有这条数据了，此时如果你的 Master Broker 的磁盘坏了，但是 Slave Broker 上至少还是有数据的，数据不会因为磁盘故障而丢失的。 对于主从架构，如果你是基于 Dledger 技术和 Raft 协议的主从同步架构，对于你所有的消息写入，只要它写入成功，那就一定会通过 Raft 协议同步给其他的 Broker 机器。 Consumer 消息零丢失方案：手动提交 offset + 自动故障转移通过上面，我们知道了如果确保订单系统发送出去的消息一定会到达 MQ 中，而且也能确保了如果消息到达了 MQ，如果确保一定不会丢失。现在的问题在于，即使红包系统拿到了这条消息，就一定可以成功的派发红包吗？ 答案是未必。如果红包系统已经拿到了这条消息，但是消息目前还在它的内存里，还没执行派发红包的逻辑，此时它就直接提交了这条消息的 offset 到 Broker 去说自己已经处理过了。如图： 接着红包系统在上图这个状态的时候就直接崩溃了，内存里的消息就没了，红包也没派发出去。结果 Broker 已经收到它提交的消息 offset 了，以为它 处理完这个消息了。等红包系统重启的时候，就不会再次消费这条消息了。 所以，即使保证发送消息到 MQ 的时候绝不会丢失，而且 MQ 收到消息之后一定不会把消息搞丢，但是你的红包系统在获取到消息之后还是可能会搞丢。 RocketMQ 消费者的处理方式我们看一下下面的 RocketMQ 消费者的代码，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class RocketMQConsumer &#123; public static void start() &#123; new Thread() &#123; @SneakyThrows @Override public void run() &#123; // 这是 RocketMQ 消费者实例对象 // "credit_group" 之类的就是消费者分组 // 一般来说比如积分系统就用 "credit_consumer_group" // 比如营销系统就用 "marketing_consumer_group" // 以此类推，不同的系统给自己取不同的消费者名字 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("credit_group"); // 这是给消费者设置 NameServer 的地址 // 这样就可以拉取到路由信息，知道 Topic 的数据在哪些 Broker 上 // 然后可以从对应的 Broker 上拉取数据 consumer.setNamesrvAddr("localhost:9876"); // 选择订阅 "TopicOrderPaySuccess" 的消息 // 这样就会从这个 Topic 的 Broker 机器上拉取订单消息过来 consumer.subscribe("TopicOrderPaySuccess", "tags"); // 注册消息监听器来处理拉取到的订单消息 // 如果 consumer 拉取到了订单消息，就会回到这个方法交给处理 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; // 在这里对获取到的 msgs 订单消息进入处理 // 比如增加积分、发送优惠券、通知发货等等 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者实例 consumer.start(); System.out.println("Consumer Stratd. %n"); while (true) &#123; // 别让线程退出，就让创建好的 consumer 不停消费数据 Thread.sleep(1000); &#125; &#125; &#125;.start(); &#125;&#125; 其中我们重点看下面这段代码： 12345678consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; // 在这里对获取到的 msgs 订单消息进入处理 // 比如增加积分、发送优惠券、通知发货等等 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); RocketMQ 的消费者中会注册一个监听器，就是上面小块代码中的 MessageListen而Concurrently 这个东西，当你的消费者获取到一批消息之后，就会回调你的这个监听器函数，让你来处理一批消息。当你处理完毕之后，你才会返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 作为消费成功的示意，告诉 RocketMQ，这批消息我已经处理完毕了。 所以对于 RocketMQ 而言，其实只要你的红包系统是在这个监听器的函数中先处理一批消息，基于这批消息都派发完了红包，然后返回了这个消费成功的状态，接着才会去提交这批消息的 offset 到 Broker 去。所以这这个情况下，如果你对一批消息都处理完毕了，然后再提交消息的 offset 给 Broker，接着红包系统崩溃了，此时是不会丢失消息的。 如果是红包系统获取到一批消息之后，还没处理完，也没返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 这个状态，自然没提交这批消息的 offset 给 Broker，此时红包系统突然挂了，会怎么样？ 其实在这种情况下，你对一批消息都没提交它的 offset 给 Broker 的话，Broker 不会认为你已经处理完了这批消息，此时你突然红包系统的一台机器宕机了，它其实会感知到你的红包系统的一台机器作为一个 Consume 挂了。接着它会把还没处理完的那批消息交给红包系统的其他机器去进行处理。所以这种情况下，消息也是不会丢失的。 需要警惕的地方：不能异步消费消息在默认的 Consumer 的消费模式之下，必须是你处理完一批消息之后，才会返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 这个状态标识消息都处理结束了，才提交 offset 到 Broker 去。在这种情况下，正常来说是不会丢失消息的，即使你一个 Consumer 宕机了，它会把你还没处理完的消息交给其他 Consumer 去处理。 但是我们要警惕一点，就是我们不能再代码中对消息进行异步的处理。如下错误的示范，我们开启了一个子线程去处理这笔消息，然后启动线程之后，就直接返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 状态了。 12345678910111213consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; // 开启一个子线程处理这批数据 new Thread() &#123; @Override public void run() &#123; // 处理消息 &#125; &#125;.start(); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); 如果要是用这种方式来处理消息的话，那可能就会出现你开启的子线程还没处理完消息，你就已经返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 状态了，就可能提交这批消息的 offset 给 Broker 了，认为已经处理结束了。然后此时你红包系统突然宕机，就会导致你的消息丢失了。 因此在 RocketMQ 的场景下，如果要保证消费数据的时候别丢失，你就老老实实在回调函数里处理消息，处理完了你再返回 ConsumeConcurrentlyStatus.COMSUME_SUCCESS 状态表明你处理完毕了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 的事务消息]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F08%2FRocketMQ-%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%2F</url>
    <content type="text"><![CDATA[示例背景在一个电商系统中，按照规则在支付之后可以拿到一个现金红包的，但是在支付了一个订单之后，却没有收到这个现金红包。这是怎么回事？ 经过一通排查，找了系统中打印的很多日志之后，发现了一个奇怪的现象。按理来说，订单系统在完成支付之后，会推送一条消息到 RocketMQ 里去，然后红包系统会从 RocketMQ 里接收那条消息去给用户发现金红包：如图： 但是从订单系统和红包系统当天那个时间段的日志来看，只看到了订单系统有推送消息到 RocketMQ 的日志，但是并没有看到红包系统从 RocketMQ 中接收消息以及发现金红包的日志。 大家推测可能问题就出在这，有可能支付订单系统在传输的过程中丢失了，导致现金红包没有派发出去。 订单系统推送消息到 MQ 的过程会丢失消息首先，订单系统在接收到订单支付成功的通知之后，会去推动一条订单支付成功的消息到 MQ 的，那么这个过程中，会出现丢失消息的问题吗？当然有可能。例如，订单系统在推送消息到 RocketMQ 的过程中，是通过网络去进行传输的，但是这个时候恰巧网络发送了抖动，也就是网络突然出了问题，导致这次网络通信失败了，于是这个消息就没有成功投递给 MQ。 除此之外，还有其他情况。例如 MQ 的确收到消息了，但是它的网络通信模块的代码出现了异常，可能是它内部的网络通信的 bug，导致消息没成功处理；或者是你在写消息到 RocketMQ 的过程中，刚好遇到了某个 Leader Broker 自身故障，其他的 Follower Broker 正在尝试切换为 Leader Broker，这个过程中也可能有异常等等。 因为我们在使用任何一个 MQ 的时候，无论是 RocketMQ、还是 RabbitMQ 或者 Kafka，都要明确一点：不一定你发送消息出去就一定会成功，有可能就会失败，此时你的代码里可能会抛出异常，也可能不会抛出异常，这都不好说，要具体看什么原因导致的消息推送失败。 消息到达 MQ 后，MQ 自己丢失信息接下来，假设我们的订单系统成功地把消息写入了 MQ，此时我们可以认为你写成功了，此时消息有可能丢失吗？这也是有可能的。通过之前的 RocketMQ 的底层原理的分析，我们知道一点，就是你的消息写入 MQ 之后，其实 MQ 可能仅仅把这个消息给写入 page cache 里，也就是操作系统自己管理的一个缓冲区，这本质也是内存。如图： 可能你认为写成功了一个消息，但是此时仅仅进入了 os cache，还没有写入磁盘。然后这个时候，假如出现了 Broker 机器的崩溃，机器宕机了，是不是 os cache 内存中的数据就没了？ 消息进入磁盘，真的万无一失吗之前说过，Broker 把消息写入 os cache 之后，其实操作系统自己在一段不太确定的时间之后，它自己是会把数据从内存刷入磁盘文件里的。假设我们写入 MQ 的一条消息已经稳稳进入 Broker 所在机器的磁盘文件里了，这个时候数据一定不会丢失吗？ 答案是不，因为如果你的磁盘出现故障，你上面的存储的数据还是会丢失。之前就有互联网公司把数据存储在服务器的磁盘上，但是因为没有做完善的冗余备份，结果机器磁盘故障导致公司运营几年的核心数据没了。所以如果消息进入 Broker 机器的磁盘之后，赶上机器刚好磁盘坏了，可能上面的消息也就都丢失了。 红包系统拿到消息，就不会丢失吗接着，假设红包系统这个时候顺利从 MQ 里拿到了一条消息，然后它就能安稳地把现金红包发出去吗？这也是未必的，要解释这个问题，就需要牵扯到消息的 offset 这个概念了。 之前已经在底层原理分析的部分解释了 MQ 底层的存储结构，包括消息的 offset 的概念，说白了，offset 就是代表了一个消息的标识，代表了它的位置。 假设现在有两个消息，offset 分别为 1 和 2，现在我们假设红包系统已经获取到了消息 1 了，然后消息 1 此时就在它的内存里，正准备运行代码去派发现金红包，但是要注意，此时还没发红包。如图： 默认情况下，MQ 的消费者有可能会自动提交已经消费的 offset，如果此时你还没处理这个消息派发红包的情况下，MQ 的消费者可能直接给你提交这个消息 1 的 offset 到 Broker 去了，标识为你已经成功处理了这个消息。接着恰巧在这个时候，我们的红包系统突然宕机了，或者是可能在派发红包的时候更新数据库失败了，总之就是它突然故障了，然后此时内存里的消息 1 必然丢失了，而且红包也没发出去。 总结红包为什么没发出去？原因有很多，比如订单系统推送消息到 MQ 就失败了，压根就没推送出去；或者是消息确实推送到 MQ 了，但是结果 MQ 自己机器故障，把消息搞丢了；或者是红包系统拿到了消息，但是它把消息搞丢了，红包也没来得及发。 发送消息零丢失方案：RocketMQ 的事务消息我们明确了消息在基于 MQ 传输的过程中可能丢失的几个地方，那么我们就要一步一步考虑如何去解决各个环节丢失信息的问题。 首先要解决的第一个问题，就是订单系统推送消息到 MQ 的过程中，可能消息就丢失了。在 RocketMQ 中，有一个非常牛逼的功能，就是事务消息功能。凭借这个事务级的消息机制，就可以让我们确保订单系统推送出去的消息一定会成功写入 MQ 里，不会半路就搞丢了。 发送 half 消息到 MQ 去，试探 MQ 是否正常作为订单系统而言，假设它收到了一个订单支付成功的通知之后，它必然是需要在自己的订单数据库里做一些增删改操作的，比如更新订单状态之类的。可能有些人会认为，订单系统不就是在自己数据库里做一些增删改操作，然后直接发个消息到 MQ 去，让其他关注这个订单支付成功消息的系统从 MQ 获取消息做对应的处理就行了么？ 其实并不会这么简单。在基于 RocketMQ 的事务消息机制中，我们先让订单系统发送一条 half 消息到 MQ 去。这个 half 消息本质就是一个订单支付成功的消息，只不过你可以理解为这个 half 消息的状态是 half 状态，这个时候红包系统是看不见这个 half 消息的。然后我们去等待接收这个 half 消息写入成功的响应通知。如图： 发送这个 half 消息有什么用？假设你二话不说就让订单系统直接做了本地的数据库操作，比如订单状态都更新为了已完成，然后你再发送消息给 MQ，结果报出一堆异常，发现 MQ 挂了。这个时候，会导致你没法通过消息通知到红包系统去派发红包，那用户一定会发现自己订单支付了，结果红包没收到。 所以，这里我们第一件事，不是先让订单系统做一些增删改操作，而是先发一个 half 消息给 MQ 以及收到它的成功的相应，初步先跟 MQ 做个联系和沟通。 half 消息写入失败如果 half 消息写入失败，例如 MQ 挂了，或者网络故障了，总之你现在没法跟 MQ 通信了。这个时候你的订单系统就应该执行一系列回滚操作，比如对一个订单状态做一个更新，让状态变成 “关闭交易”，同时通知支付系统自动进行退款，这才是正确的做法。 因为你订单虽然支付了，但是派发红包、发送优惠券之类的后续操作是无法执行的，所以此时必须把钱款退还给用户，说交易失败了。 half 消息成功之后，订单系统完成自己的任务接着，如果你的 half 消息写成功了，这个时候你的订单系统就应该在自己的本地数据库里执行一些增删改操作了，因为一旦 half 消息写成功了，就说明 MQ 肯定已经收到这条消息了，MQ 还活着，而且目前你是可以跟 MQ 正常沟通的。 订单系统的本地事务执行失败接着上面的情况，如果订单更新自己的数据库失败了怎么办？比如订单系统的数据当时也有网络异常，或者数据库挂了等等。这个时候也简单，就是让订单系统发送一个 rollback 请求给 MQ 就可以了。意思是说，你可以把之前我发送给你的 half 消息给删除掉了，因为我自己出现问题了，已经没办法跟你继续后续的流程了。 当然你发送 rollback 请求给 MQ 删除那个 half 消息之后，你的订单系统就必须走后续的回退流程了，就是通知支付系统退款。当然这里可能还有一些订单系统自己的高可用降级的机制需要考虑，比如数据库无法更新了，此时你可能需要在机器本地磁盘文件里写入订单支付失败的记录，然后你可以开一个后台线程在 MySQL 数据库恢复之后，把订单状态更新为 “已关闭”。 订单完成本地事务之后如果订单系统成功完成了本地的事务操作，此时你就可以发送一个 commit 请求给 MQ，要求让 MQ 对之前的 half 消息进行 commit 操作，让红包系统可以看见这个订单支付成功消息。 之前我们说过，half 消息实际就是订单支付成功的消息，只不过它的状态是 half，红包系统是看不见它的，没法获取这条消息，必须等到订单系统指定 commit 请求，消息比 commit 之后，红包系统才可以看到和获取这条消息进行后续操作。 half 消息发送成功，但没有收到响应大致的事务流程是讲完了。但是接着我们进行比较严谨的分析。如果我们把 half 消息发送给 MQ，MQ 给保存下来了，但是 MQ 返回给我们的响应我们没收到呢？此时会发生什么？ 这个时候我们没收到响应，有可能是网络超时报错，或者是其他的异常错误，这个时候订单系统会误以为是发送 half 消息到 MQ 失败，订单系统会直接执行退款流程，订单状态也会标记为 “已关闭”。 但这个时候 MQ 已经存储下来一条 half 消息了，那这个消息怎么处理？其实 RocketMQ 这里有一个补偿流程，它会去扫描自己处于 half 状态的消息，如果我们一直没有对这个消息执行 commit/half 操作，超过了一定的时间，它就会回调你的订单系统的一个接口。 它会询问这个消息是打算 commit 还是 rollback，这个时候订单系统就得去查一下数据库，查询订单的状态，发现状态是 “已关闭”，就得发送 rollback 请求给 MQ 去删除之前那个 half 消息了。 rollback 或者 commit 发送失败如果订单系统是收到 half 消息写入成功的相应了，同时尝试对自己的数据库更新了，然后根据失败或者成功去执行了 rollback 或者 commit 请求，发送给 MQ 了，结果因为网络故障，导致 rollback 或者 commit 请求发送失败了。这时候要怎么处理？ 其他也简单，因为 MQ 里的消息一直是 half 状态，所以说它过了一定的超时时间会发现这个 half 消息有问题，它会回调你的订单系统的接口，此时你要判断一下，这个订单的状态如果更新为了 “已完成”，那你就得再次执行 commit 请求，反之则再次执行 rollback 请求。 本质这个 MQ 的回调就是一个补偿机制，如果你的 half 消息响应没收到，或者 rollback、commit 请求没发送成功，它都会来找你询问 half 消息后续如何处理。 如果订单系统收到了 half 消息写入成功的相应了，同时尝试对自己的数据库更新了，然后根据失败或者成功去执行了 rollback 或者 commit 请求，发送给 MQ 了。但 MQ 在这个时候挂掉了，导致 rollback 或者 commit 请求发送失败。如果是这种情况，那就等 MQ 自己重启了，重启之后它会扫描 half 消息，然后还是通过上面说到的补偿机制，去回调你的接口。 总结上面的流程意义是什么？其实，如果你的 MQ 有问题或者网络有问题，half 消息根本都发布出去，此时 half 消息肯定是失败的，那么订单系统就不会执行后续流程了。 如果 half 消息发送出去了，但是 half 消息的响应没收到，然后执行了退款流程，那 MQ 会有补偿机制来回调你询问要 commit 还是 rollback，此时你选择 rollback 删除消息就可以了，不会执行后续流程。 如果订单系统收到 half 消息响应了，但是订单系统自己更新数据库失败了，那他它也不会执行后续流程了。如果它更新数据库成功了，订单状态是 “已完成”，此时就会发送 commit 请求给 MQ，一旦消息 commit 了，那么可以保证红包系统可以收到这个消息。 而且即使你 commit 请求发送失败了，MQ 也会有补偿机制，回调你接口让你判断是否重新发送 commit 请求。 总之，就是你的订单系统只要成功了，那么必然要保证 MQ 里的消息是 commit 了，可以让红包系统看到它。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬件层面聊聊可见性和有序性]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F06%2F%E7%A1%AC%E4%BB%B6%E5%B1%82%E9%9D%A2%E8%81%8A%E8%81%8A%E5%8F%AF%E8%A7%81%E6%80%A7%E5%92%8C%E6%9C%89%E5%BA%8F%E6%80%A7%2F</url>
    <content type="text"><![CDATA[高速缓存的数据结构处理器高速缓存的底层数据结构实际上一个拉链散列表的结构，就是有很多个 bucket，每个 bucket 挂了很多的 cache entry，每个 cache entry 由三个部分组成：tag、cache line 和 flag，其中的 cache line 就是缓存的数据；tag 指向了这个缓存数据在主内存中的数据地址，flag 标识了缓存行的状态。另外需要注意的一点是，cache line 中可以包含多个变量的值 处理器会操作一些变量，那怎么在高速缓存里定位到这个变量呢？其实处理器在读写高速缓存的时候，实际上会根据变量名执行一个内存地址解码的操作，解析出 3 个东西：index、tag 和 offset。index 用于定位到拉链散列表中的某个 bucket，tag 是用于定位 cache entry，offset 是用于定位一个变量时在 cache line 中的位置。 如果说可以成功定位到一个高速缓存中的数据，而且 flag 还标志着有效，则缓存命中；否则不满足上述条件，就是缓存未命中。如果是读数据未命中的话，会从主内存重新加载数据到高速缓存中。现在处理器一般都有三级高速缓存：L1、L2 和 L3，越靠前面的缓存读写速度越快。 缓存一致性协议（MESI 协议）因为有高速缓存的存在，所以就导致各个处理器可能对一个变量会在自己的高速缓存里有自己的副本，这样一个处理器修改了变量值，别的处理器是看不到的。为了解决这个问题，引入了缓存一致性协议（MESI 协议） MESI 协议规定：对一个共享变量的读操作可以是多个处理器并发执行的，但是对于一个共享变量的写操作，只有一个处理器可以执行。其实也会通过排他锁的机制保证就一个处理器能写。 之前说过那个 cache entry 的 flag 代表了缓数据的状态，MESI 协议中划分为： invalid：无效的。标记为 I。这个意思是当前 cache entry 无效，里面的数据不能使用 shared：共享的。标记为 S。这个意思是当前 cache entry 有效，而且里面的数据在各个处理器都有各自的副本，但是这些副本的值跟主内存的值是一样的，各个处理器就是并发地在读而已 exclusive：独占的。标记为 E。这个意思就是当前处理器对这个数据独占了，只有它可以有这个副本，其它的处理器都不能包含这个副本 modified：修改的。标记为 M。只能有一个处理器对共享数据更新，所以只有更新数据的处理器的 cache entry，才是 exclusive 状态。表明当前线程更新了这个数据，这个副本的数据跟主内存是不一样的。 MESI 协议规定了一组消息，就是各个处理器在操作内存数据的时候，都会往总线发送消息，而且各个处理器还会不停地从总线嗅探最新的消息，通过这个总线的消息传递来保证各个处理器的协作。 下面来详细地图解 MESI 协议的工作原理，处理器0 读取某个变量的数据时，首先会根据 index、tag 和 offset 从高速缓存的拉链散列表读取数据，如果发现状态为 I，也就是无效的，此时就会发送 read 消息到总线。 接着主内存会返回对应的数据给 处理器0，处理器0 就会把数据放到高速缓存里，同时 cache entry 的 flag 状态为 S。 在 处理器0 对一个数据进行更新的时候，如果数据状态是 S，则此时就需要发送一个 invalidate 消息到总线，尝试让其他的处理器的高速缓存的 cache entry 全部变为 I，以获得数据的独占锁。其他的 处理器1 会从总线嗅探到 invalidate 消息，此时就会把自己的 cache entry 设置为 I，也就是过期掉自己本地的缓存，然后就是返回 invalidate ack 消息到总线，传递回 处理器0，处理器0 必须收到所有处理器返回的 ack 消息 接着 处理器0 就会将 cache entry 先设置为 E，独占这条数据，在独占期间，别的处理器就不能修改数据了，因为别的处理器此时发出 invalidate 消息，这个 处理器0 是不会返回 invalidate ack 消息的，除非它先修改完再说 接着 处理器0 就修改这条数据，接着将数据设置为 M，也有可能是把数据此时强制写会到主内存中，具体看底层硬件实现 然后其他处理器此时这条数据的状态都是 I 了，如果要读的话，全部都需要重新发送 read 消息，从出内存（或者是其他处理器）来加载，这个具体怎么实现看底层的硬件，都有可能的 这套机制其实就是缓存一致性在硬件缓存模型下的完整执行原理。 采用写缓冲器和无效队列优化 MESI 协议MESI 协议如果每次写数据的时候都要发送 invalidate 消息等待所有处理器返回 ack，然后获取独占锁后才能写入数据，那可能就会导致性能很差了。因为对这个共享变量的写操作，实际上在硬件级别变成串行的。所以为了解决这个问题，硬件层面引入了写缓冲器和无效队列。 写缓冲器的作用是，一个处理器写数据的时候，直接把数据写入缓冲器，同时发送 invalidate 消息，然后就认为写操作完成了，接着就干别的事情，不会阻塞在这里。接着这个处理器如果收到其他处理器的 ack 消息之后，才会把写缓冲器中的写结果拿出来，通过堆 cache entry 设置为 E 加独占锁，同时修改数据，然后设置为 M。 其实写缓冲器的作用，就是处理器写数据的时候直接写入缓冲器，不需要同步阻塞等待其他处理器的 invalidate ack 返回，这就大大提升了硬件层面的执行效率了。包括查询数据的时候，会先从写缓冲器里查，因为有可能刚修改的值在这里，然后才会从高速缓存里查，这个就是存储转发。 引入无效队列，就是说其他处理器在接收到 invalidate 消息之后，不需要立马过期本地缓存，直接把消息放入无效队列，就返回 ack 给那个写处理器了，这就进一步加速了性能，然后之后从无效队列里取出消息，过期本地缓存即可 通过引入写缓冲器和无效队列，一个处理器要写数据的话，这个性能是很高的，它直接写数据到写缓冲器，发送一个 invalidate 消息出去，就立马返回，执行别的操作了；其他处理器收到 invalidate 消息之后直接放入无效队列，立马就返回 invalidate ack 硬件层面的 MESI 协议引发有序性和可见性的问题通过上面的讲解，MESI 协议在硬件层面的原理大家应该清晰了。现在就讲讲 MESI 协议引发的可见性和有序性问题。 可见性可见性是写缓冲器和无效队列导入的。写数据不一定立马写入自己的高速缓存（或者主内存），有可能写入了写缓冲器，导致其他处理器读不到最新的值；读数据不一定立马从别人的高速缓存（或者主内存）刷新最新的值过来，invalidate 消息还无效队列里面，高速缓存还保留着未被无效化的旧值，处理器会在自己的高速缓冲中读取旧值。 有序性StoreLoad 重排序1234567int a = 0;int c = 1;线程1:a = 1;int b = c; 上面线程 1 的代码，第一个是 Store，第二个是 Load。但是可能处理器对 store 操作先写入了写缓冲器，此时这个写操作相当于没执行，然后就执行第二行代码，第二行代码的 b 是局部变量，那这个操作等于是读取 c 的值，是 load 操作。这就导致了好像第二行代码的 load 先执行了，第一行代码的 store 后执行 第一个 store 操作写到写缓冲器里去了，导致其他的线程是读取不到的，看不到的，好像是第一个写操作没执行一样，而第二个 load 操作是成功地执行了。 StoreStore 重排序12resource = loadResource();loaded = true; 上面两个写操作，但是可能第一个写操作写入了写缓冲器，然后第二个写操作是直接修改的高速缓存，这个时候不久导致了两个写操作顺序颠倒了？ 诸如此类的重排序，都可能因为 MESI 的机制发生。可见性问题也是一样的，写入写缓冲器之后，没输入高速缓存，导致别人读不到；读数据的时候，可能 invalidate 消息在无效队列里，导致没法立马感知到过期的缓存，立马加载最新的数据 内存屏障在硬件层面的实现以及问题解决解决可见性问题，可以通过 Store 屏障 + Load 屏障。 如果加了 Store 屏障之后，就会强制性要求你对一个写操作必须阻塞等待到其他的处理器返回 invalidate ack 之后，对数据加锁，然后修改到高速缓存中，在写数据之后，必须强制执行 flush 操作。它的效果，是要求一个写操作必须刷到高速缓存（或者主内存），不能停留在写缓冲器里。 如果加了 Load 屏障之后，就从高速缓存读取数据的时候，如果发现无效队列里有一个 invalidate 消息，此时会立马强制那个 invalidate 消息把自己本地缓存的数据过期掉（设置为 I），然后就可以强制从其他处理器的高速缓存中加载最新的值了，这就是 refresh 操作。 为了解决有序性问题，可以通过内存屏障。通过使用 Acquire 屏障（StoreStore 屏障）、Release 屏障（StoreLoad 屏障），可以避免重排序 StoreStore 屏障，会强制让写数据的操作全部按照顺序写入写缓冲器里，不会让你第一个写到写缓冲器里去，第二个直接修改高速缓存了。 12345resource = loadResource();StoreStore 屏障loaded = true; StoreLoad 屏障，它会强制先将写缓冲器里的数据写入高速缓存中，接着读数据的时候强制清空无效队列，对里面的 invalidate 消息全部过期掉高速缓存中的条目，然后强制从主内存里重新加载数据。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 杂记之消费者]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F02%2FRocketMQ-%E6%9D%82%E8%AE%B0%E4%B9%8B%E6%B6%88%E8%B4%B9%E8%80%85%2F</url>
    <content type="text"><![CDATA[消费者如何获取消息处理以及进行 ACK消费者组首先，我们需要了解一个概念，就是消费者组。消费者组的意思，就是你给一组消费者起一个名字。比如我们有一个 Topic 叫 “TopicOrderPaySuccess”，然后假设有库存系统、积分系统、营销系统、仓储系统他们都要去消费这个 Topic 中的数据。此时我们应该给那四个系统分别起一个消费组的名字，比如： stock_consumer_group，marketing_consumer_group，credit_consumer_group，wms_consumer_group。 设置消费组的方式是在代码里进行的，如下： 12DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("stock_consumer_group") 比如说库存系统部署了 4 台机器，每台机器上的消费者组的名字都是 “stock_consumer_group”，那么这 4 台机器就同属于一个消费者组。以此类推，每个系统的几台机器都是属于各自的消费者组的。 然后跟大家说一下不同消费者之间的关系，假设库存系统和营销系统作为两个消费者组，都订阅了 “TopicOrderPaySuccess” 这个订单支付成功信息的 Topic，此时假设订单系统作为生产者发送了一条消息到这个 Topic。如图： 此时这条消息这么被消费呢？正常情况下，这条消息进入 Broker 之后，库存系统和营销系统作为两个消费组，每个组都会拉取到这条消息。也就是说这个订单支付成功的消息，库存系统会获取一条，营销系统也会获取到一条，他们都会获取到这条消息。 但是，库存系统这个消费组组里有两台机器，是两台机器都获取到这条消息，还是说只有一台机器会获取到这条消息？正常情况下，库存系统的两台机器只有一台会获取到这条消息，营销系统也是同理。如图： 这就是在消费的时候我们要注意的一点，不同的系统应该设置不同的消费组，如果不同的消费组订阅了同一个 Topic，对 Topic 里的一条消息，每个消费组都会获取到这条消息。 集群模式消费 VS 广播模式消费接着，对于一个消费组而言，它获取到一条消息之后，如果消费组内部有多台机器，到底是只有一台机器可以获取到这个消息，还是每台机器都可以获取到这个消息。这个就是集群模式和广播模式的区别。 默认情况下都是集群模式，即一个消费组获取到一条消息，只会交给组内的一台机器去处理，不是每台机器都可以获取到这条消息的。但是我们可以通过如下设置来改变为广播模式： 1consumer.setMessageModel(MessageModel.BROADCASTING) 如果修改为广播模式，那么对于消费者组获取到的一条消息，组内每台机器都可以获取到这条消息。但是相对而言广播模式其实用的很少，常见基本上都是使用集群模式来进行消费的。 重温 MessageQueue、CommitLog、ConsumeQueue 之间的联系接着我们来看一下 MessageQueue 与消费者的关系。通过之前的文章我们知道，一个 Topic 在创建的时候我们是要设置它有多少个 MessageQueue 的，而且我们也知道，在 Broker 上 MessageQueue 是如何跟 ConsumeQueue 对应起来的。 根据之前的文章，我们大致可以如此理解，Topic 中的多个 MessageQueue 会分散在多个 Broker 上，每个 Broker 机器上，一个 MessageQueue 就对应了一个 ConsumeQueue，当然在物理磁盘上其实是对应了多个 ConsumeQueue 文件的，但是我们也大致理解为一一对应的关系。 但是对于一个 Broker 机器而言，存储在它上面的所有 Topic 以及 MessageQueue 的消息数据都是写入一个统一的 CommitLog 的，然后对于 Topic 的MessageQueue 而言，就是通过各个 ConsumeQueue 文件来存储属于 MessageQueue 的消息在 CommitLog 文件中的物理位置，就是一个 offset 偏移量。如图： MessageQueue 与消费者的关系对于一个 Topic 上的多个 MessageQueue，是如何由一个消费者中的多台机器来进行消费的？其实这里的源码实现细节较为复杂，我们可以简单理解为，它会均匀的将 MessageQueue 分配给消费者的多台机器来消费。 例如，假设我们的 “TopicOrderPaySuccess” 里有 4 个 MessageQueue，这 4 个 MessageQueue 分布在两个 Master Broker 上，每个 Master Broker 上有 2 个 MessageQueue。然后库存系统作为一个消费者组里有两台机器，那么正常情况下，当然最好的就是让这两台机器每个都负责 2 个 MessageQueue 的消费了。 比如库存系统的 机器01 从 Master Broker01 上消费 2 个 MessageQueue，然后库存系统的 机器02 从 Master Broker02 上消费 2 个 MessageQueue，这就就把消费的负载均摊到两台 Maser Broker 上去了。 所以你大致可以认为一个 Topic 的多个 MessageQueue 会均匀分摊给消费组内的多个机器去消费，这里的一个原则就是：一个 MessageQueue 只能被一个消费者机器去处理，但是一台消费者机器可以负责多个 MessageQueue 的消息处理。 Push 模式 VS Pull 模式我们已经知道了一个消费组内的多台机器是分别负责一部分 MessageQueue 的消费的，那么既然如此，每台机器就必须去连接到对应的 Broker，尝试消费里面的 MessageQueue 对应的消息。此时就涉及到两种消费模式了，一个是 Push，一个是 Pull。实际上，这两个消费模式本质是一样的，都是消费者机器主动发送请求到 Broker 机器去拉取一批消息下来。 Push 消费模式本质也是基于这种消费者主动拉取到的模式来实现的，只不过它的名字叫 Push 而已，意思是 Broker 会尽可能实时的把新消息交给消费者机器来进行处理，它的消息时效性会更好。一般我们使用 RocketMQ 的时候，消费模式通常都是基于它的 Push 模式来做的，因为 Pull 模式的代码写起来更加的复杂和繁琐，而且 Push 模式底层是基于消息拉取的方式来做的，只不过时效性更好而已。 Push 模式的实现思路简单说一下：当消费者发送请求到 Broker 去拉取消息的时候，如果有新的消息可以消费那么就会立马返回一批消息到消费机器去处理，处理完之后会接着立刻发送请求到 Broker 机器去拉取下一批消息。所以消费机器在 Push 模式下会处理完一批消息，立马发起请求拉取下一批消息，消息处理的时效性非常好，看起来就跟 Broker 一直不停地推送消息到消费者一样。 另外 Push 模式下有一个请求挂起和长轮询的机制，也简单说一下。当你的请求发送到 Broker，结果发现没有新的消息给你处理的时候，就会让请求线程挂起，默认是挂起 15秒，然后这个期间它会有后台线程每隔一会就去检查一下是否有新的消息给你。另外如果在这个挂起过程中，如果有新的消息到达了会主动唤醒挂起的线程，然后把消费返回给你。 Broker 如何将消息读取出来返回给消费机器Broker 在收到消费机器的拉取请求之后，如何将消息读取出来返回给消费机器？其实这里涉及到两个概念，分别是 ConsumeQueue 和 CommitLog。 假设一个消费者机器发送了拉取请求到 Broker 了，它说这次要拉取 MessageQueue0 中的消息，然后我之前都没拉取过消息，所以就从这个 MessageQueue0 中的第一条消息开始拉取就好了。于是，Broker 就会找到 MessageQueue0 对应的 ConsumeQueue0，从里面找到第一条消息的 offset。 接着 Broker 就需要根据 ConsumeQueue0 中找打的第一条消息的地址，去 CommitLog 中根据这个 offset 地址去读取这条消息的数据，然后把这条消息的数据返回给消费者机器。 所以其实消费信息的时候，本质上就是根据你要消费的 MessageQueue 以及开始消费的位置，去找到对应的 ConsumeQueue 读取里面对应位置的消息在 CommitLog 中的物理 offset 偏移量，然后到 CommitLog 中根据 offset 读取消息数据，返回给消费者机器。 消费者机器处理消息、进行 ACK 以及提交消费进度接着消费者机器拉取到一批消息之后，就会将这批消息回调我们注册的一个函数，如下面： 123456789consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage( List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; // 处理信息 // 标记改消息已经被成功消费 return ConsumerConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;) 当我们处理完这批消息之后，消费者机器就会提交我们目前的一个消费进度到 Broker 上，然后 Broker 就会存储我们的消费进度。 比如我们现在对 ConsumeQueue0 的消费进度假设就是在 offset = 1 的位置，那么它会记录下来一个 ConsumeOffset 的东西去标记我们的消费进度，如图： 那么下次这个消费组想要再次拉取这个 ConsumeQueue 的消息，就可以从 Broker 记录的消费位置开始拉取，不用重头开始拉取了。 消费组中出现机器宕机或者机器扩容最后，如果消费组中出现机器宕机或者扩容机器的情况，会怎么处理？ 这个时候会进入一个 rebalance 的环节，也就是重新给各个消费机器分配它们要处理的 MessageQueue。 例如现在 机器01 负责 MessageQueue0 和 Message1，机器02 负责 MessageQueue2 和 MessageQueue3，现在 机器02 宕机了，那么 机器01 就会接管 机器02 之前负责的 MessageQueue2 和 MessageQueue3；或者如果此时消费组加入了一台 机器03，此时就可以把 机器02 之前负责的 MessageQueue3 转移给 机器03，然后 机器02 就只负责一个 MessageQueue2 的消费了。这就是负载重平衡的概念。 消费者根据什么策略从 Master 或 Slave 上拉取消息Broker 实现高可用架构的时候是有主从之分的，消费者消费消息，可以从 Master Broker 拉取，也可以从 Slave Broker 拉取，具体是要看机器负载来定。所以，到底什么时候从 Master Broker 拉取，什么时候从 Slave Broker 拉取？ 我们先来简单回顾一下，之前我们对 Broker 的读写分离架构师怎样描述的。之前说过，刚开始消费者都是连接到 Master Broker 机器去拉取消息，然后如果 Master Broker 机器觉得自己负载比较高，就会告诉消费者机器，下次可以从 Slave Broker 机器去拉取。 CommitLog 基于 os cache 提升写性能上面我们说过，拉取消息的时候必然会先读取 ConsumeQueue 文件，这个 ConsumeQueue 文件的读取时如何优化的？要搞明白这个，就要回顾一下之前说过的 CommitLog 文件写入的优化原理，其实本质就是基于 os cache 来进行优化的。也就是说，Broker 收到一条消息，会写入 CommitLog 文件，但是会先把 CommitLog 文件中的数据写入 os cache（操作系统管理的缓存）中去，然后 os 自己有后台线程，过一段时间会异步把 os cache 缓存中的 CommitLog 文件的数据刷入磁盘中去。 就是依靠这个写入 CommitLog 时先进入 os cache 缓存，而不是直接进入磁盘的机制，就可以实现 Broker 写 CommitLog 文件的性能是内存写级别的，这才能实现 Broker 超高的消息接入吞吐量。 ConsumeQueue 文件也是基于 os cache 的接下来一个关键的问题，就是 ConsumeQueue 会被大量的消费者发送的请求给高并发地读取，所以 ConsumeQueue 文件的读操作是非常频繁的，而且同时会极大地影响到消费者进行消息拉取的性能和消费吞吐量。 所以实际上 Broker 对 ConsumeQueue 文件同样也是基于 os cache 来进行优化的。即，对于 Broker 机器的磁盘上的大量 ConsumeQueue 文件，在写入的时候也都是优先进入 os cache 中的。而且 os 自己有一个优化机制，就是读取一个磁盘文件的时候，它会自动把磁盘文件的一些数据缓存到 os cache 中。而且 ConsumeQueue 文件主要是存放消息的 offset，所以每个文件很小，30万 条消息的 offset 就只有 5.72MB 而已。所以实际上 ConsumeQueue 文件们不占多多少磁盘空间，它们整体数据量很小，几乎可以被 os 缓存在内存 cache 里。 所以实际上消费者拉取消息的时候，第一步大量地频繁读取 ConsumeQueue 文件，几乎可以说就是跟读内存里的数据的性能是一样的，通过这个就可以保证数据消费的高性能以及高吞吐。 CommitLog 是基于 os cache + 磁盘一起读取的接下来看第二个关键的问题，在进行消息拉取的时候，先读 os cache 里的少量 ConsumeQueue 的数据，这个性能是极高的，然后第二步就是根据你读取到的 offset 去 CommitLog 里读取消息的完整数据了。所以，这个从 CommitLog 里读取消息完整数据是如何读取的？是从 os cache 里读取？还是从磁盘里读取？ 答案是，两者都有。因为 CommitLog 是用来存放消息的完整数据的，所以容量是很大的，毕竟它一个文件就要 1GB，所以整体完全有可能多达几个 TB。这么多数据，不可能都放在 os cache 里。因为 os cache 用的也是机器的内存，一般多也就是几十个 GB 而已，何况 Broker 自身的 JVM 也要用一些内存，留给 os cache 的内存只是一部分而已，比如 10GB ~ 20GB。所以 os cache 对于 CommitLog 而言，无法把它全部数据放在里面给你读取的。 即，os cache 对于 CommitLog 而言，主要是提升文件写入性能，当你不停地写入的时候，很多最新写入的数据都会先停留在 os cache 里，比如这可能有 10GB ~ 20GB 的数据。之后 os 会自动把 cache 里的比较旧的数据刷入磁盘里，腾出来空间给更新写入的数据放在 os cache 里，所以大部分数据可能多达几个 TB 都是在磁盘上的。 所以，当你拉取消息的时候，可以轻松从 os cache 里读取少量的 ConsumeQueue 文件里的 offset，这个性能是极高的，但是当你去 CommitLog 文件里读取完整消息数据的时候，会有两种情况： 如果你读取的是那种刚刚写入 CommitLog 的数据，那么大概率它们还停留在 os cache 中，此时你可以顺利地直接从 os cache 里读取 CommitLog 中的数据，这个就是内存读取，性能是很高的。 你读取的是比较早之前写入 CommitLog 的数据，那些数据早就被刷入磁盘了，已经不再 os cache 里了，那么此时你就只能从磁盘上的文件读取了，这个性能是比较差一些的。 什么时候从 os cache 读？什么时候从磁盘读如果你的消费者机器一直快速地在拉取和消费处理，紧紧地跟上了生产者写入 Broker 的消息速率，那么你每次拉取几乎都是在拉取最近人家刚写入 CommitLog 的数据，那几乎都在 os cache 里。但是如果 Broker 的负载很高，导致你拉取消息的速度很慢，或者是你自己的消费者机器拉取到一批消息之后处理的性能很低，处理的速度很慢，这都会导致你跟不上生产者的写入速率。 比如人家到写入 10万 条数据了，而你才拉取了 2万 条数据，此时有 5万 条最新的数据是在 os cache 里，有 3万 条你还没拉取的数据是在磁盘里，那么后续当你再拉取的时候，必然很大概率是从磁盘里读取早就刷入磁盘的 3万 条数据。 接着之前再 os cache 里的 5万 条数据可能又被刷入磁盘了，取而代之的是更新的几万条数据在 os cache 里，然后你再次拉取的时候，又会从磁盘里读取刷入磁盘里的 5万 条数据，相当你每次都在从磁盘里读取数据了。 Master Broker 什么时候会让你从 Slave Broker 拉取数据那到底什么时候 Master Broker 会让你从 Slave Broker 拉取数据？假设此时你的 Broker 里已经写入了 10万 条数据，但是你仅仅拉取了 2万 条数据，下次你拉取的时候，是从第 2万 零 1 条数据开始继续往后拉，也就是说，此时你有 8万 条数据是没有拉取的。 然后 Broker 自己是知道机器上当前的整体物理内存有多大的，而且它知道自己可用的最大空间占里面的比例，它是知道自己的消息最多可以在内存里放多少的。比如它知道它最多在内存里存放 5万 条消息而已。然后这个时候你过来拉取消息，它发现你还有 8万 条消息没有拉取，这个 8万 条消息它发现是大于最多存放的 5万 条消息的，那么此时就说明，肯定有 3万 条消息目前是在磁盘上的，不在 os cache 内存里。 所以经过上述判断，会发现此时你很大概率会从磁盘里加载 3万 条消息出来，他会认为，出现这种情况，很可能是因为自己作为 Master Broker 负载太高，导致没法及时把消息给你，所以你落后的进度比较多。这个时候，它会告诉你，我这次给你从磁盘里读取 3万 条消息，但是下次你还是从 Slave Broker 去拉取吧。 以上就是对这个关键问题的解答，本质是对你当前没有拉取消息的数量和大小，以及最多可以存放在 os cache 内存的消息的大小，如果你没拉取的消息超过了最大能使用的内存的量，那么说明你后续会频繁从磁盘加载数据，此时就让你从 Slave Broker 去加载数据了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ - 基于 DLedger 技术的 Broker 主从同步班原理]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F02%2FRocket-%E5%9F%BA%E4%BA%8E-DLedger-%E6%8A%80%E6%9C%AF%E7%9A%84-Broker-%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%8F%AD%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[之前有跟大家说过 Broker 的数据存储原理，接下来我们就说说 Broker 接收到数据写入之后，是如何同步给其他的 Broker 做多副本冗余的。这里就会牵扯到 DLedger 是个什么东西，因为我们是基于 DLedger 实现 Broker 多副本高可用的。 首先，我们回顾一下，producer 写入消息到 broker 之后，broker 会将消息写入本地 CommitLog 磁盘文件中，然后还有一些 ConsumeQueue 会存储 Topic 下各个 MessageQueue 的消息的物理位置。而且，要让 Broker 实现高可用，那么必须有一个 Broker 组，里面有一个是 Leader Broker 可以写入数据，然后让 Leader Broker 接收到数据之后，直接把数据同步给其他的 Follower Broker。如图： 这样的话，一条数据就会在三个 Broker 上有三份副本，此时如果 Leader Broker 宕机，那么就直接让其它的 Follower Broker 自动切换为新的 Leader Broker，继续接收客户端的额数据写入就可以了。 基于 DLedger 技术替换 Broker 的 CommitLog首先，Broker 上述高可用架构就是基于 Dledger 技术来实现的，所以，我们要先知道 DLedger 技术可以干什么。 DLedger 技术实际上它自己就有一个 CommitLog 机制，你把数据交给它，它会写入 CommitLog 磁盘文件里去，这是它干的第一件事。如图，如果基于 DLedger 技术来实现 Broker 高可用架构，实际上就是用 DLedger 先替换原来 Broker 自己管理的 CommitLog，由 DLedger 来管理 CommitLog。 所以第一步，我们需要使用 DLedger 来管理 CommitLog，然后 Broker 还是可以基于 DLedger 管理的 CommitLog 去构建机器上的各个 ConsumeQueue 磁盘文件。 DLedger 基于 Raft 协议选举 Leader Broker我们知道首先基于 Dledger 替换各个 Broker 上的 CommitLog 管理组件了，那么就是每个 Broker 上都有一个 Dledger 组件了。接着我们思考一下，如果我们配置了一组 Broker，比如有 3 台机器，Dledger 是如何从 3 台机器里选举出一个 Leader 的？ 实际上 Dledger 是基于 Raft 协议来进行 Leader Broker 选举的，那么 Raft 协议中是如何进行多台机器的 Leader 选举的？ 这需要发起一轮一轮的投票，通过三台机器互相投票选出来一个人作为 Leader。简单来说，三台 Broker 机器启动的时候，他们会投票自己作为 Leader，然后把这个投票发送给其他 Broker。例如，Broker01 是投票给自己的，Broker02 是投给自己的，Broker03 是投给自己的，他们把自己的投票发送给了别人。 此时在第一轮的选举中，Broker01 会收到别人的投票，它发现自己是投给自己的，其他人也是投给自己的，所以第一轮选举是失败的。因为大家都投票给自己，是选举不出一个 Leader 的。 接着每个 Broker 会进入一个随机的休眠，比如 Broker01 休眠 3 秒，Broker02 休眠 5 秒，Broker03 休眠 4 秒。此时 Broker01 必然是先苏醒过来，它苏醒之后，会继续尝试投票给自己，并且发送自己的选票给别人。 接着 Broker03 休眠 4 秒过后苏醒，它发现 Broker01 已经发送来了一个选票是投给 Broker01 自己的，此时它因为自己没投票，随意会尊重别人的选择，直接把票投给 Broker01了，同时把自己的投票发送给别人。 接着 Broker02 苏醒了，它收到了 Broker01 投票给 Broker01 自己，Broker03 也投票给了 Broker01，此时它自己因为没投票，也会尊重别人的选择，直接把票投给 Broker01 了，并且把自己的投票发送给别人。 此时所有 Broker 都会收到三张投票，都是投给 Broker01 的，那么 Broker01 就会当选为 Leader。其实只要有 （3 台机器 / 2）+ 1 个人投票给某人，就会选举它当 Leader，这个 （机器数量 / 2）+ 1 就是大多数的意思。 这就是 Raft 协议中选举 Leader 算法的简单描述，简单来说，它确保有人可以成为 Leader 的核心机制就是一轮选举不出来 Leader 的话，就让大家随机休眠一下，先苏醒过来的人会投票给自己，其他人苏醒过后发现自己收到选票了，就会直接投票给那个人。依靠这个随机休眠的机制，基本上几轮投票过后，一般都是可以快速选举出来一个 Leader。 因此，在三台 Broker 机器刚刚启动的时候，就是靠这个 Dledger 基于 Raft 协议实现的 Leader 选举机制，互相投票选举出一个 Leader，其他人就是 Follower，然后只有 Leader 可以接收数据写入，Follower 只能接收 Leader 同步过来的数据。 Dledger 是如何基于 Raft 协议进行多副本同步的接下来，Leader Broker 收到消息之后，是怎么基于 DLedger 把数据同步给其他 Broker 的。Dledger 在进行同步的时候是采用 Raft 协议进行多副本同步的，我们接下来就说说 Raft 协议中的多副本同步机制。 简单来说，数据同步会分为两个阶段，一个 uncommitted 阶段，一个是 committed 阶段。 首先 Leader Broker 上的 DLedger 收到一条数据之后，会标记为 uncommitted 状态，然后它会通过自己的 DLedgerServer 组件把这个 uncommitted 数据发送给 Follower Broker 的 DLedgerServer。如图： 接着 Follower Broker 的 DLedgerServer 收到 uncommitted 消息之后，必须返回一个 ack 给 Leader Broker 的 DLedgerServer，然后如果 Leader Broker 收到超过半数的 Follower Broker 返回 ack之后，就会将消息标记为 committed 状态。然后 Leader Broker 上的 DLedgerServer 就会发送 committed 消息给 Follower Broker 机器的 DLedgerServer，让它们也把消息标记为 committed 状态。 这个就是基于 Raft 协议实现的两阶段完成的数据同步机制。 Leader Broker 崩溃了怎么办通过上面分析我们知道，对于高可用 Broker 架构而言，无论是 CommitLog 写入，还是多副本同步，都是基于 DLedger 来实现的。那么，如果 Leader Broker 挂了怎么办。 如果 Leader Broker 挂了，此时剩下的两个 Follower Broker 就会重新发起选举，它们会基于 DLedger 采用 Raft 协议的算法，去选举一个新的 Leader Broker 继续对外提供服务，而且会对没有完成的数据同步进行一些恢复性的操作，保证数据不会丢失。 如下图就是示意 Leader Broker 挂了之后，Follower Broker 称为了新的 Leader Broker，然后生产者吸入新的 Leader Broker 的一个过程。新选举出来的 Leader 会把数据通过 DLedger 同步给剩下的一个 Follower Broker。 总结今天我们讲了基于 DLedger 技术的高可用 Broker 集群是如何运行的，包含了一下的一些内容： Broker 高可用架构原理回滚：多副本同步 + Leader 自动切换 基于 DLedger 基础管理 CommitLog Broker 集群启动时，基于 DLedger 技术和 Raft 协议完成 Leader 选举 Leader Broker 写入之后，基于 DLedger 技术和 Raft 协议同步给 Follower Broker 如果 Leader Broker 崩溃，则基于 DLedger 和 Raft 协议重新选举 Leader]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F01%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal 用在什么地方讨论 ThreadLocal 用在什么地方之前，我们先明确下，如果仅仅只有一个线程，都不用谈 ThreadLocal 了，因为 ThreadLocal 是用在多线程的场景的！！ ThreadLocal 归纳下来就 2 类用途： 保存线程上下文信息，在任意需要的地方可以获取 线程安全的，避免某些情况需要考虑线程安全必须同步带来的性能损失 保存线程上下文信息，在任意需要的地方可以获取由于 ThreadLocal 的特性，同一线程在某地方进行设置，在随后的任意地方都可以获取到，从而可以用来保存线程上下文信息。 常用的比如每个请求怎么把一串后续关联起来，就可以用 ThreadLocal 进行 set，在后续的任意需要记录日志额的方法里进行 get 获取到请求 id，从而把整个请求串起来。还有比如 Spring 的事务管理，用 ThreadLocal 存储 Connection，从而各个 DAO 可以获取同一个 Connection，可以进行事务回滚，提交等操作。 备注：ThreadLocal 的这种用处，很多时候是用在一些优秀的框架里面的，一般我们很少接触，反而下面的场景我们接触的更多一些 线程安全，避免某些情况需要考虑线程安全必须同步带来的性能损失ThreadLocal 为解决多线程程序的并发问题提供了一种新的思路，但是 ThreadLocal 也有局限性，我们来看看阿里的规范： 【参考】ThreadLocal 无法解决共享对象的更新问题，ThreadLocal 对象建议使用 static 修饰。这个变量时针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享次静态变量，也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象（主要是这个线程内定义的）都可以操控这个变量。 每个线程往 ThreadLocal 中读写数据是线程隔离，互相之间不会影响的，所以 ThreadLocal 无法解决共享对象的更新问题。 由于不需要共享信息，自然就不存在竞争问题，从而保证了某些情况下线程的安全，以及避免了某些情况需要考虑线程安全必须同步带来的性能损失。 这类场景阿里规范也提到了： ThreadLocal 一些细节ThreadLocal 使用示例代码： 12345678910111213141516171819202122232425262728293031323334353637public class ThreadLocalTest &#123; private static ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void main(String[] args) &#123; new Thread(() -&gt; &#123; try &#123; for (int i = 0; i &lt; 100; i++) &#123; threadLocal.set(i); System.out.println(Thread.currentThread().getName() + "===" + threadLocal.get()); try&#123; Thread.sleep(200); &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; finally &#123; threadLocal.remove(); &#125; &#125;, "threadLocal1").start(); new Thread(() -&gt; &#123; try &#123; for(int i = 0; i &lt; 100; i++) &#123; System.out.println(Thread.currentThread().getName() + "===" + threadLocal.get()); try &#123; Thread.sleep(200); &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; finally &#123; threadLocal.remove(); &#125; &#125;, "threadLocal2").start(); &#125;&#125; 代码运行结果： 从运行的结果我们可以看到 ThreadLocal1 进行 set 值对 ThreadLocal2 没有任何影响 Thread、ThreadLocalMap、ThreadLocal 总览图： Thread 类有属性变量 threadLocals（类型是 ThreadLocal.ThreadLocalMap），也就是说每个线程有一个自己的 ThreadLocalMap，所以每个线程往这个 ThreadLocal 中读写隔离的，并且是互相不会影响的。 一个 ThreadLocal 只能存储一个 Object 对象，如果需要存储多个 Object 对象那么就需要多个 ThreadLocal。如图： 看到上面的几个图，大概思路应该都清晰了，我们 Entry 的 key 指向 ThreadLocal 用虚线表示弱引用，下面我们看看 ThreadLocalMap： java 对象的引用包括：强引用、软引用、弱引用、虚引用。因为这里涉及到弱引用，简单说明下，弱引用也是用来描述非必需对象的，当 JVM 进行垃圾回收时，无论内存是否充足，该对象仅仅被弱引用关联，那么就会被回收。 当仅仅只有 ThreadLocalMap 中的 Entry 的 key 指向 ThreadLocal 的时候，ThreadLocal 会进行回收的。ThreadLocal 被垃圾回收后，在 ThreadLocalMap 里对应的 Entry 的 key 值会变成 null，但是 Entry 是强引用，那么 Entry 里面存储的 Object，并没有办法进行回收。所以，ThreadLocal 做了一些额外的回收工作。 虽然做了但是也会存在内存泄露风险，所以后面会提到 ThreadLocal 最佳实践 ThreadLocal 的最佳实践ThreadLocal 被垃圾回收后，在 ThreadLocalMap 里对应的 Entry 的键值会变成 null，但是 Entry 是强引用，那么 Entry 里面存储的 Object，并没有办法进行回收，所以，ThreadLocalMap 做了一些额外的回收工作。 备注：很多时候，我们都是用在线程池的场景，程序不停止，线程基本不会销毁 由于线程的生命周期很长，如果我们往 ThreadLocal 里面 set 了很大很大的 Object 对象，虽然 set、get 等等方法在特定的条件会调用进行额外的清理，但是 ThreadLocal 被垃圾回收后，在 ThreadLocalMap 里对应的 Entry 的键值会变成 null，但是后续也没有操作 set、get 等方法了。 所以最佳实现，应该在我们不使用的时候，主动调用 remove 方法进行清理。 【参考】ThreadLocal 无法解决共享对象的更新问题，ThreadLocal 对象建议使用 static 修饰。这个变量时针对一个线程内所有操作共享的，所以设置为静态变量，所有次类实例共享次静态变量，也就是说再类第一次被使用时装载，只分配一块存储空间，所有此类的对象（只要是这个线程内定义的）都可以操控这个变量。 这里把 ThreadLocal 定义为 static 还有一个好处是，由于 ThreadLocal 里有强引用在，那么在 ThreadLocalMap 里对应的 Entry 的键也会永远存在，那么执行 remove 的时候就可以正确进行定位并且删除。 所以最佳实践做法应该为： 参考资料ThreadLocal]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Synchronized 和 volatile]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F30%2FSynchronized-%E5%92%8C-volatile%2F</url>
    <content type="text"><![CDATA[Synchronized 关键字Synchronized 关键字，可以同时保证原子性、可见性以及有序性 原子性层面而言，它加了 synchronized 之后，就有一个加锁和释放锁的机制。加锁之后，同一段代码就只有它可以执行了 可见性，它会通过加入一些内存屏障，使得它在同步代码块中对变量做的写操作，都会在释放锁的时候，全部强制执行 flush 操作；在进入同步代码块的时候，对变量的读操作，全部会强制执行 refresh 操作。这样那些更新了的数据，别的线程只要进入代码块，就可以读到 有序性，synchronized 关键字，它会通过加各种各样的内存屏障，来解决 LoadLoad、StoreStore 等重排序。 Synchronized 通过加锁保证原子性之前有跟简单说过 synchronized 加锁的原理，说白了，就是在进入加锁代码块的时候加一个 monitorenter 的指令，然后针对锁对象关联的 monitor 累加加锁计数器，同时标识自己这个线程加了锁。通过 monitor 里的加锁计数器可以实现可重入的加锁。 在出锁代码块的时候，加一个 monitorexit 的指令，然后递减锁计数器。如果锁计数为 0，就会标志当前线程不持有锁，从而释放锁。 另外，wait 和 notify 关键字的实现也是依托于 monitor 实现的。在线程执行 wait 之后，自己会加入一个 waitset 中等待唤醒获取锁。notifyall 操作会从 monitor 的 waitset 中唤醒所有的线程，让他们竞争获取锁。 我们看如下的代码： 12345MyObject lock = new MyObject();synchronized(lock)&#123;&#125; Java 对象都是分为对象头和实例变量两块的，其中实例变量就是平时看到的对象里的那些变量数据。然后对象头包含了两块东西，一个是 Mark Word（包含了 hashCode、锁数据、GC 数据等等），另一个是 Class Metadata Address（包含了指向类的元数据的指针） 在 Mark Word 里就有一个指针，是指向了这个对象实例关联的 monitor 的地址，这个 monitor 是 c++ 实现的，不是 Java 实现的。这个 monitor 实际上就是 c++ 实现的一个 ObjectMonitor 对象，里面包含了一个 _owmer 指针，指向了持有锁的线程 ObjectMonitor 里还有一个 entrylist，想要加锁的线程全部先进入这个 entrylist 等待获取机会尝试加锁，有机会加锁的线程，就会设置 _owner 指针指向自己，然后对 _count 计数器累加 1 次。 各个线程尝试竞争进行加锁，此时竞争加锁是在 JDK1.6 以后优化成了基于 CAS 来进行加锁，理解为跟之前的 Lock API 的加锁机制是类似的。通过 CAS 操作，操作 _count 计数器，例如将 _count 值尝试从 0 变为 1 如果成功了，那么执行加锁成功，如果失败了，那么加锁就失败了 然后释放锁的时候，先是对 _count 计数器递减 1，如果为 0 了就会设置 _owner 为 null，不再指向自己，代表自己彻底释放锁。 如果获取锁的线程执行 wait，就会将计数器递减，同时 _owner 设置为 null，然后自己进入 waitset 中等待唤醒，别人获取了锁执行 notify 的时候就会唤醒 waitset 中的线程竞争尝试获取锁。 这里需要注意的是，尝试加锁这个过程，也就是对 _count 计数器累加操作。如何保证多线程并发安全的原子性？就如上面说的，在 JDK1.6 之后，对 synchronized 内的加锁机制做了大量的优化，这里就是优化为 CAS 加锁的。 Synchronized 使用内存屏障保证可见性和有序性Java 的并发技术底层很多都对应了内存屏障的使用，包括 synchronized，它底层也是依托于各种不同的内存屏障来保证可见性和有序性的。 按照可见性来划分的话，内存屏障可以分为 Load 屏障和 Store 屏障。 Load 屏障的作用是执行 refresh 处理器缓存的操作。说白了就是对别的处理器更新过的值，从其他处理器的高速缓存（或者主内存）加载数据到自己的高速缓存来，确保自己看到的是最新的数据。 Store 屏障的作用是执行 flush 处理器缓存的操作，就是把自己当前处理器更新的变量的值，都刷到高速缓存（或者主内存）里去。 在 monitorexit 指令之后，会有一个 Store 屏障，让线程把自己在同步代码块里修改的变量的值都执行 flush 处理器缓存的操作，刷到高速缓存（或者主内存）里去；然后在 monitorenter 指令之后会加一个 Load 屏障，执行 refresh 处理器缓存的操作，把别的处理器修改过的最新值加载到自己高速缓存里来。 所以说，通过 Load 屏障和 Store 屏障，就可以让 synchronized 保证可见性 123456789101112int b = 0;int c = 0;synchronized(this) &#123; -&gt; monitorenter Load 内存屏障 int a = b; c = 1; // synchronized 代码块里还是可能发生指令重排&#125; -&gt; monitorexitStore 内存屏障 按照有序性保障来划分的话，还可以分为 Acquire 屏障和 Release 屏障 在 monitorenter 指令之后，Load 屏障之后，会加一个 Acquire 屏障，这个屏障的作用是禁止读操作和读写操作之间发生指令重排序；在 monitorexit 指令之前，会加一个 Release 屏障，这个屏障的作用是禁止写操作和读写操作之间发生重排序。 所以说，通过 Acquire 屏障和 Release 屏障，就可以让 synchronized 保证有序性，只有 synchronized 内部的指令可以重排序，但是绝对不会跟外部的指令发生重排序。 1234567891011121314151617int b = 0;int c = 0;synchronized(this) &#123; -&gt; monitorenter Load 内存屏障 Acquire 内存屏障 int a = b; c = 1; // synchronized 代码块里还是可能发生指令重排 Release 内存屏障 &#125; -&gt; monitorexitStore 内存屏障 总结： 原子性：通过加锁和释放锁来保证原子性 可见性：加了 Load 屏障和 Store 屏障，释放锁 flush 数据，加锁会 refresh 数据 有序性：Acquire 屏障和 Release 屏障，保证同步代码块内部的指令可以重排，但是同步代码块内部的指令和外面的指令是不能重排的。 Volatilevolatile 对原子性的保证是非常有限的，其实主要是 32 位 JVM 中的 long/double 类型变量的赋值操作是不具备原子性的，加上 volatile 就可以保证原子性了。 在 volatile 变量写操作的前面会加一个 Release 屏障，然后在之后会加入一个 Store 屏障，这样就可以保证 volatile 写跟 Release 屏障之前的任何读写操作都不会指令重排。然后 Store 屏障保证了，写完数据之后，立马会执行 flush 处理器缓存的操作。 在 volatile 变量读操作的前面会加入一个 Load 屏障，这样就可以保证对这个变量的读取时，如果被别的处理器修改过了，必须得从其他处理器的高速缓存（或者主内存）中加载到自己本地高速缓存里，保证读到的是最新的数据。之后会加入一个 Acquire 屏障，禁止 volatile 读操作之后的任何读写操作会跟 volatile 读指令重排序。 那个 Acquire 屏障其实就是 LoadLoad 屏障 + LoadStore 屏障，Release 屏障就是 StoreLoad 屏障 + StoreStore 屏障 1234567线程1:Release 屏障isRunning = false;Store 屏障 123456789线程2:Load 屏障while(isRunning) &#123; Acquire 屏障 // 代码逻辑&#125; 总结volatile 和 synchronized 保证可见性和有序性，原来都是通过各种内存屏障来实现的，因为加了内存屏障，就会有一些特殊的指令和实现，就可以保证可见性和有序性了。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再谈原子性、可见性和有序性]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F26%2F%E5%86%8D%E8%B0%88%E5%8E%9F%E5%AD%90%E6%80%A7%E3%80%81%E5%8F%AF%E8%A7%81%E6%80%A7%E5%92%8C%E6%9C%89%E5%BA%8F%E6%80%A7%2F</url>
    <content type="text"><![CDATA[思维导图 原子性Java 语言规范里，int i = 0、resource = loadResources、flag = true，各种变量的简单赋值操作，规定都是原子的，包括引用类型的变量的赋值操作，也是原子的。 但是很多复杂的操作，例如 i++，先读取 i 的值，再更新 i 的值。还有 i = y + 2，先读取 y 的值，再更新 i 的值，这种复杂操作，不是简单赋值写，它是有计算的过程在里面的，此时 Java 语言规范默认是不保证原子性的。 volatile 关键字，保证了可见性和有序性，但不保证原子性。像上面的 i++，i = y + 2，volatile都是不保证原子性的。 赋值写操作中不保证原子性的特例原子性这块，在 32 位虚拟机里的 long/double 类型的变量的简单赋值写操作，不是原子的。例如 long i = 30、double c = 45.0，在 32 位虚拟机里就不是原子的，因为 long 和 double 是 64 位的。 如果多个线程同时并发执行 long i = 30，long 是 64 位的，就会导致有的线程在修改 i 的高 32 位，有的线程在修改 i 的低 32 位，多线程并发给 long 类型的变量进行赋值操作，在 32 位的虚拟机下，是有问题的。可能会导致多线程给 long i = 30 赋值之后，导致 i 的值不是 30，可能是 -3333334429 乱码一样的数字，就是因为高低 32 位赋值错了，就导致二进制数字转换为十进制之后是一个很奇怪的数字。 volatile 保证原子性的特例volatile 对原子性保证的语义，在 Java 里是很有限的，几乎可以忽略不计。32 位的 Java 虚拟机里面，对 long/double 变量的赋值写是不原子的，此时如果对变量加上了 volatile，就可以保证在 32 位 Java 虚拟机里面，对 long/double 变量的赋值是原子的了。 硬件级别思考可见性的问题每个处理器都有自己的寄存器（register），所以多个处理器各自运行一个线程的时候，可能导致某个变量给放到寄存器里去，接着就会导致各个线程没法看到其他处理器寄存器里的变量的值修改了。可见性的第一个问题，就有可能在寄存器的级别，导致变量副本的更新，无法让其他处理器看到。 然后处理器运行的线程对变量的操作都是针对写缓冲来的（store buffer），并不是直接更新主内存，所以很可能导致一个线程更新了变量，但是仅仅是在写缓冲区而已，没有更新到主内存里去。这个时候，其他处理器的线程是没法读到它的写缓冲区的变量值的，所以此时会有可见性的问题，这是第二个可见性发生的场景。 然后即使这个时候一个处理器的线程更新了写缓冲区之后，将更新同步到了自己高速缓存里（cache，或者是主内存），然后还把这个更新通知给了其他的处理器，但是其他处理器可能就是把这个更新放到无效队列里，没有更新它的高速缓存。此时其他处理器的线程从高速缓存里读数据的时候，读到的还是过时的旧值。 MESI协议如果要实现可见性，其中一个方法就是通过 MESI 协议。这个 MESI 协议实际上有很多种不同的实现，因为它不过就是一个协议，具体的实现机制要考具体底层的系统如何实现。根据具体底层硬件的不同，MESI 协议的实现是有区别的。 比如说 MESI 协议有一种实现，就是一个处理器将另外一个处理器的高速缓存中的更新后的数据拿到自己的高速缓存中更新一下，这样大家的缓存不就实现同步了，然后各个处理器的线程看到的数据就一样了。 为了实现 MESI 协议，有两个配套的专业机制需要说一下：flush 处理器缓存、refresh 处理器缓存。 flush 处理器缓存，它的意思是把自己更新的值刷新到高速缓存里去（或者是主内存），因为必须要刷到高速缓存（或者是主内存）里，才有可能在后续通过一些特殊的机制让其他的处理器从自己的高速缓存（或者是主内存）里读取到更新的值。 除了 flush 以外，它还会发送一个消息到总线（bus），通知其他处理器，某个变量的值被它修改了。 refresh 处理器缓存，它的意思就是说再读取一个变量的值的时候，如果发现其他处理器的线程更新了变量的值，必须从其他处理器的高速缓存（或者是主内存）里，读取这个最新的值，更新到自己的高速缓存中。 所以，为了保证可见性，在底层是通过 MESI 协议、flush 处理器缓存和 refresh 处理器缓存，这一整套机制来保障的。要记住，flush 和 refresh 这两个操作，flush 是强制刷新数据到高速缓存（或主内存），不要仅仅停留在写缓冲器里面；refresh，是从总线嗅探发现某个变量被修改，必须强制从其他处理器的高速缓存加载变量的最新值到自己的高速缓存里去。 内存屏障的使用，在底层硬件级别的原理，其实就是在执行 flush 和 refresh。还有 volatile 关键字： 1volatile boolean isRunning = true; 当执行 isRunning = false 时，就是写 volatile 变量，就会通过执行一个内存屏障，在底层触发 flush 处理器缓存的操作；while(isRunnig) {}，读 volatile 变量，也会通过执行一个内存屏障，在底层触发 refresh 操作。 一个变量加了 volatile 修饰之后，对这个变量的写操作，会执行 flush 处理器缓存，把数据刷到高速缓存（或者是主内存）中，然后对这个变量的读操作，会执行 refresh 处理器缓存，从其他处理器的高速缓存中，读取最新的值。 有序性Java 程序运行过程中发生指令重排的几个地方我们写好的代码在实际执行的时候那个顺序可能在很多环节都会被人给重排序，一旦重排序之后，在多线程并发的场景下，就有可能出现一些问题。 1、自己写的源代码中的执行顺序，这个是我们自己写的代码，一般来说就是按照我们自己脑子里想的那样来写。 2、编译后的代码的执行顺序。java 里有两种编译器，一个是静态编译器（javac），一个是动态编译器（JIT）。javac 负责把 .java 文件中的源代码编译为 .class 文件中的字节码，这个一般是程序写好之后进行编译的。JIT 负责把 .class 文件中的字节码编译为 JVM 所在操作系统支持的机器码，一般在程序运行过程中进行编译。 在这个编译的过程中，编译器是很有可能调整代码的执行顺序的，为了调高代码的执行效率，很可能调整代码的执行顺序。JIT 编译器对指令重排的还是挺多的。 3、处理器的执行顺序。哪怕你给处理器一个代码的执行顺序，但是处理器还是可能会重排代码，更换一种执行顺序。JIT 编译好的指令，还是可能会被处理器调整顺序 4、内存重排序。有可能你这个处理器在执行指令的时候，在高速缓存和写缓冲器、无效队列等等硬件层面的组件，也可能导致你的指令的执行看起来的顺序跟想象的不太一样。 上述就是我们在写好 java 代码之后，从编译到执行的过程中，代码的执行顺序可能有指令重排的地方，只要有指令重排就有一定可能造成程序执行异常。 但是编译器和处理器不是胡乱地重排序，他们会遵循一个关键的规则，就是数据依赖规则。如果说一个变量的结果依赖于之前的代码执行结果，那么就不能随意进行重排序，要遵循数据的依赖。例如： 123int a = 3;int b = 5;int c = a * b; 那第三行代码依赖于上面两行代码，第一行和第二行代码可以重排序，但是第三行代码必须放在最下面。 此外还有 happens-before 原则，就是有一些基本的规则是要遵守的，不会让你胡乱地重排序。在遵守一定的规则的前提下，有好几个层面的代码和指令都可能出现重排序。 JIT编译器指令重排的例子JIT 动态编译的时候，有可能造成一个非常经典的指令重排。 1234567891011121314public class MyObject &#123; private Resource resource; public MyObject() &#123; // 从配置文件里加载数据构造 Resource 对象 this.resource = loadResource(); &#125; public void execute() &#123; this.resource.execute(); &#125;&#125; 假设线程 1 执行我们写的这么一行代码： 1MyObject myObj = new MyObject(); 而线程 2 执行下面这行代码： 1myObj.execute(); 首先，我们要知道 new Object() 是如何创建一个 MyObject 对象实例的。 步骤1：以 MyObject 类作为原型，给它的对象实例分配一块内存空间。objRef 就是指向了分配好的内存空间的地址的引用。 1objRef = allocate(MyObject.class); 步骤2：就是针对分配好内存空间的一个对象实例，执行它的构造函数，对这个对象进行初始化的操作，执行我们自己写的构造函数里的一些代码，对各个实例变量赋值，执行初始化的逻辑。 1invokeConstructor(objRef); 步骤3：上面两个步骤搞定之后，一个对象实例就算创建完成。此时就是把 objRef 指针指向的内存地址，赋值给我们自己的引用类型的变量，myObj 就可以作为一个类似指针的概念指向了 MyObject 对象实例的内存地址。 1myObj = objRef; 有可能 JIT 动态编译为了加速程序的执行速度，因为步骤 2 是在初始化一个对象实例，这个步骤是有可能很耗时的，比如说你可能会在这里执行一些网络的通信，磁盘文件的读写等等。而 JIT 为了加速程序的执行性能和效率，就可能发生指令重排，把顺序排为：步骤 1 -&gt; 步骤 3 -&gt; 步骤 2 此时线程 1 刚好执行完了 步骤 1 和步骤 3，步骤 2 还没执行，此时 myObj 已经不是 null 了，但是 MyObject 对象实例内部的 resource 还是 null。而线程 2 直接调用 myObj.execute 方法，此时内部会调用 resource.execute() 方法。但因为 resource 还是 null，直接导致空指针错误。 double check 单例模式里面，就是可能会出现这样的 JIT 指令重排。如果你不加 volatile 关键字，会导致一些问题的发生。volatile 可以避免出现 步骤1、步骤3、步骤2 这样的重排序。 现代处理器为了提升性能的指令乱序和猜测执行机制指令乱序机制指令不一定说是拿到了一个指令立马可以执行的，比如有的指令是要进行网络通信、磁盘读写、获取锁等等，因此有的指令不是立马就绪可以执行的。为了调高效率，在现代处理器里面都是走的指令的乱序执行机制。 把编译好的指令一条一条读取到处理器里，但是哪个指令先就绪可以执行，就先执行，不是按照代码顺序来的。每个指令的结果放到一个重排序处理器中，重排序处理器把各个指令的结果按照代码顺序应用到主内存或者写缓冲器里。 这就导致处理器可能在乱序执行我们代码编译后的指令。 猜测执行机制还有一个猜测执行。比如一个 if 判断有一堆代码，很可能先去执行 if 的代码算出来结果，然后再来判断 if 是否成立。 123456int sum = 0;if(flag) &#123; for(int i = 0; i &lt; 10; i++) &#123; &#125;&#125; 内存重排序处理器会将数据写入写缓冲器，这个过程是 store；从高速缓存里读数据，这个过程是 load。写缓冲器和高速缓存执行 load 和 store 的过程，都是按照处理器指示的顺序来的，处理器的重排处理器也是按照程序顺序来 load 和 store 的。 但是有个问题，就是在其他的处理器看到的一个视觉假象而言，有可能会出现看到的 load 和 store 是重排序的，也就是内存重排序。 处理器的乱序执行和猜测执行，都是指令重排序，这次说的是内存重排序，因为都是发生在内存层面的写缓冲器和高速缓存中的。 这个内存重排序，有 4 种可能性： LoadLoad 重排序：一个处理器先执行一个 L1 读操作，再执行一个 L2 读操作。但是另外一个处理器看到的是先 L2 再 L1 StoreStore 重排序：一个处理器先执行一个 W1 写操作，再执行一个 W2 写操作。但是另外一个处理器看到的是先 W2 再 W1 LoadStore 重排序：一个处理器先执行一个 L1 读操作，再执行一个 W2 写操作。但是另外一个处理器看到的是 W2 在 L1 StoreLoad 重排序：一个处理器先执行一个 W1 写操作，再执行一个 L2 读操作。但是另外一个处理器看到的是先 L2 在 W1 例如，一个处理器向写缓冲器先后写入 W1 W2 的指令。但写缓冲器在内部进行了 指令重排，变成 W2 W1 的顺序写入到高速缓冲中。此时其他处理器看到的顺序就是 W2 再 W1了，这就是 StoreStore 重排序。 再比如，看下面的代码： 12345678910111213141516171819// 共享变量Resource resource = null;Boolean resourceLoaded = false;// 处理器0resource = loadResourceFromDish();resourceLoaded = true;// 处理器1while(!resourceLoaded) &#123; try&#123; Thread.sleep(1000); &#125;catch(Exception e) &#123; &#125;&#125;resource.execute(); 类似上面的代码，很可能处理器 0 先写了 resource，再写了 resourceLoaded。结果写缓冲器进行内存重排序，先落地了 resourceLoaded = true，此时 resource 还是 null。此时处理器 1 就会看到 resourceLoaded = true，就会对 resource 对象执行了 execute() 方法，此时就会有空指针异常的问题。 总之，高速缓存和写缓冲器都可以自己对 Load 和 Store 操作的结果落地到内存进行各种不同的重排序，进而造成上述 4 种内存重排序问题的发生。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 锁]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F26%2FMySQL-%E9%94%81%2F</url>
    <content type="text"><![CDATA[MySQL 的锁类型，一般就是表锁、行锁和页锁。 MyIsam一般 MyIsam 会加表锁。就是在 MyIsam 引擎下，执行查询的时候，会默认加个表共享锁，也就是表读锁，这个时候别人只能来查，不能写数据。当 MyIsam 写的时候，也会加个表独占锁，也就是写表锁，别人不能读也不能写。 InnoDBInnoDB 引擎一般用行锁，但是也有表锁。 InnoDB 的行锁有共享锁（S）和排它锁（X）。共享锁就是，多个事务可以加共享读锁读同一行数据，但是别的事务不能写这行数据；排它锁，就是一个事务只能写这行数据，别的事务只能读，不能写。 InnoDB 的表锁，分成意向共享锁，就是说加共享行锁的时候，必须先加这个共享表锁；还有一个意向排他锁，就是说，给某行加排他锁的时候，必须先给表加排他锁。这个表锁，是 InnoDB 引擎自动加的，不用你自己去加。 对于 insert、update、delete，InnoDB 会自动给那一行加行级排他锁。而对于 select，InnoDB 啥锁都不加，因为 InnoDB 默认实现了可重复读，也就是 mvcc 机制，所以多个事务随便读一个数据，一般不会有冲突，大家就读自己那个快读照就可以了，不涉及到什么锁的问题。 但是 InnoDB 从来不会自己主动加这个共享锁的，除非你用下面的语句自己手动加个锁： 手动加共享锁：SELECT * FROM table WHERE id = 1 LOCK IN SHARE MODE，那你就给那一行加了个共享锁，其他事务就不能来修改这行数据了。 手动加排他锁：SELECT * FROM tabel WHERE id = 1 FOR UPDATE，那你就给那一行加了个排他锁，意思是你准备修改，别的事务就不能修改了。别的事务会 hang 住。这个要慎用，一般我们线上系统不用这个，容易搞出问题。 所以，MySQL 的默认数据库的锁机制，就是：对一行数据，如果有人在修改，会加个排他锁，然后你不能修改，只能等着获取这把锁，但是这个时候你可以随便 select，就是查询你的事务开始之前那行数据的某个版本而已。然后你修改某行数据，会同时拿这个表的排他锁，但是，如果不同的事务修改不同的行，会拿不同行的行级排他锁，但是大家都会拿一个表的排他锁。实际上，InnoDB 的表级排他锁可以随便拿，这个是没有冲突的。 这就是 MySQL InnoDB 存储引擎默认的锁模式。相当于就是一行数据，同一个时刻只能一个人在修改，但是别人修改，你可以随便读，读的都是读某个版本的，走 mvcc 机制。 悲观锁和乐观锁MySQL 里的悲观锁是走 SELECT * FROM table WHERE id = 1 FOR UPDATE。意思是我很悲观，我担心自己拿不到这把锁，我必须先锁死，然后就我一个人可以搞事情，别人都不行，不能加共享锁，也不能加排他锁。 乐观锁，就是我觉得应该没啥问题，我修改的时候感觉差不多可以获取到锁，不需要提前搞一把锁，我就先查出来某个数据，SELECT id, name, version FROM table WHERE id = 1，接着再执行各种业务逻辑之后再修改， UPDATE table SET name = &#39;新值&#39;, version = version + 1 WEHRE id = 1 AND version = 1。就是说每次修改，比较一下这条数据的当前版本号跟我之前查出来的版本号是不是不一样。如果是一样的就修改然后把版本号加 1，否则就不会更新任何一行数据，此时就重新查询后再次更新。 一般悲观锁什么时候用？比如你查出来了一条数据，要在内存中修改后再更新到数据库中去，但是如果这个过程中数据被别人更新了，你是不能直接干这个操作的。这个时候，你就得走上面那个操作，查询之后就不能让别人更新了。 但是真有这种场景，推荐还是用乐观锁。悲观锁实现简单一点，但是太有风险了，很容易死锁。比如事务 A 拿了数据 1 的锁，事务 B 拿了数据 2 的锁，然后事务 A 又要获取数据 2 的锁就会等待，事务 B 又要获取数据 1 的锁，也会等待。此时就会造成死锁，互相等待，永不释放。 死锁事务 A： SELECT * FROM table WHERE id = 1 FOR UPDATE 事务 B： SELECT * FROM table WHERE id = 2 FOR UPDATE 事务 A： SELECT * FROM table WHERE id = 2 FOR UPDATE 事务 B： SELECT * FROM table WHERE id = 1 FOR UPDATE 常见的死锁就是类似上面那种，给大家说过了，分别都持有一个锁，结果还去请求别人的那把锁，结果就是谁也出不来，死锁了。 情况太多，不一一列举了，就说一下发现死锁的时候怎么排查。 其实就是看死锁日志就可以了，然后根据对应的 SQL，找一下对应的代码，具体判断一下为啥死锁了。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 杂记]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F13%2FRocketMQ-%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[RocketMQ 生产者工作原理MessageQueue要清楚生产者的工作原理，就需要明白一个概念：MessageQueue。而要明白 MessageQueue 是什么，就必须把它跟 Topic 以及 Broker 综合起来看。 如果我们要使用 RocketMQ，要先部署一套 RocketMQ集群，在有了集群之后，就要根据你的业务去创建一些 Topic。比如说创建一个 “TopicOrderPaySuccess” 的 Topic 去存放订单支付成功的消息。像这些 Topic 就可以在 RocketMQ 可视化工作台里去创建，在里面就可以创建一个 Topic 出来，在创建 Topic的时候需要制定一个很关键的参数，就是 MessageQueue。 简单来说，就是要走指定你的 Topic 对应了多少个队列，也就是多少个 MessageQueue。 Topic、MessageQueue 以及 Broker之间是什么关系其实 Topic、MessageQueue 以及 Broker 之间是有关系的。比如你现在有一个 Topic，我们为它指定 4 个 MessageQueue，那么这个 Topic 的数据在 Broker 集群中是如何分布的？ 其实，每个 Topic 的数据都是分布式存储在多个 Broker 中的，如图： 但是我们如何决定这个 Topic 的哪些数据放在这个 Broker 上，哪些数据放在另一个 Broker 上？所以在这里引入了 MessageQueue 的概念，本质上就是一个数据分片的机制。 在这个机制中，假设你的 Topic 有 1 万条数据，然后你的 Topic 有 4 个 MessageQueue，那么大致可以认为在每个 MessageQueue 中放入 2500 条数据。当然，这个不是绝对的，有可能有的 MessageQueue 的数据多，有的数据少，要根据你的消息写入 MessageQueue 的策略来定。 我们先假定在每个 MessageQueue 中会平均分配 Topic 的数据吧。那么，我们有 4 个 MessageQueue 平均分配了 Topic 的数据，这些 MessageQueue 放在哪里？当然是 Broker 上了。可能就是在 2 个 Broker 上，每个 Broker 放两个 MessageQueue。如图： 所以 MessageQueue 是 RocketMQ 中非常关键的一个数据分片机制，它通过 MessageQueue 将一个 Topic 的数据拆分成了很多个数据分片，然后再每个 Broker 机器上存储一些 MessageQueue。通过这个方法，就可以实现 Topic 数据的分布式存储。 生产者发送消息的时候写入哪个 MessageQueue生产者在发送消息的时候，会写入哪个 MessageQueue 中？其实，生产者会跟 NameServer 进行通信获取 Topic 的路由数据。所以生产者从 NameServer 中就会知道，一个 Topic 有几个 MessageQueue，哪些 MessageQueue 在哪台机器上。 然后呢，我们暂时先认为生产者会均匀地把消息写入各个 MessageQueue。比如生产者发送出去了 20 条数据，那么 4 个 MessageQueue 就会每个写入 5 条数据。如图： 通过这个方法，就可以让生产者把写入请求分散给多个 Broker，让每个Broker 都均匀分摊到一定的写入请求压力。假设单个 Broker 可以抗每秒 7 万并发，那么两个 Broker 可以抗每秒 14 万并发，可以实现 RocketMQ 集群每秒 10万+ 超高并发的场景了。 另外通过这个方法，可以让一个 Topic 的数据分散在多个 MessageQueue 中，进而分散在多个 Broker 机器上，就可以实现 RocketMQ 集群分布式存储海量的消息数据了。 某个 Broker 出现故障如果某个 Broker 临时出现故障了，此时正在等待其它 Slave Broker 自动切换为 Master Broker，那么这个时候这一组 Broker 就没有 Master Broker 可以写入了。 如果还是按照之前的策略来均匀把数据写入各个 Broker 上的 MessageQueue，那么会导致你在一段时间内，每次访问到这个挂掉的 Master Broker 都会访问失败，这不是我们想要的。 对于这个问题。建议大家在 Producer 中开启一个开关，就是 sendLatencyFaultEnable。一旦打开了这个开关，那么它会有一个容错机制，例如如果某次访问一个 Broker 发现网络延迟有 500ms，然后还无法访问，那么就会自动回避访问这个 Broker 一段时间，比如接下来 300ms 内，就不会访问这个 Broker 了。 这样的话，就可以避免一个 Broker 故障之后，短时间内生产者频繁地发送消息到这个故障的 Broker 上，出现较多次数的异常。而是在一个 Broker 故障之后，自动回避一段时间不要访问这个 Broker，过段时间访问它。 RocketMQ 如何持久化存储消息首先我们要明确一点，Broker 数据存储是最重要的一个环节。实际上类似 RocketMQ，Kafka、RabbitMQ 的消息中间件系统，它们不只是让你写入消息和获取消息，它们本身最重要的是提供强大的数据存储能力，可以把亿万级的海量消息存储在自己的服务器的磁盘上。 这样的话，各种不同的系统从 MQ 中消费消息的时候，才可以从 MQ 服务器的磁盘中读取到自己需要的消息。否则如果 MQ 不在机器磁盘上存储大量的消息，都放在自己的内存里，一个是内存很可能放不下，另外一个是可能你机器重启，内存里的消息就会全部丢失了。 所以，Broker 数据存储实际上才是一个 MQ 最核心的环节。它决定生产者消息写入的吞吐量，决定了消息不能丢失，决定了消费者获取消息的吞吐量。所以，我们来说一下 Broker 的数据存储机制。 CommitLog 消息顺序写入机制当生产者的消息发送到一个 Broker 上的时候，它会把这个消息写入磁盘的一个日志文件，叫做 commitLog，直接顺序写入这个文件。 这个 CommitLog 文件是很多磁盘文件，每个文件限定最多 1GB，Broker 收到消息之后就直接追加写入这个文件的末尾，就跟上图一样。如果一个 CommitLog 写满了 1GB，就会创建一个新的 CommitLog 文件。 MessageQueue 在数据存储中体现在哪我们写入 Broker 的消息都是进入到 CommitLog 中去存储的，那么 MessageQueue 是体现在哪里的？其实在 Broker 中，对 Topic 下的每个 MessageQueue 都会有一系列的 ConsumeQueue 文件。 什么意思？就是在 Broker 的磁盘上，会有下面这种格式的一系列文件： $HOME/store/consumequeue/{topic}/{queueId}/{fileName} 上面的那一串是什么意思？其实，每个 Topic 在这台 Broker 上都会有一些 MessageQueue，所以，{topic} 指代的就是某个 Topic，{queueId} 指代的就是某个 MessageQueue。然后对存储在这台 Broker 机器上的 Topic 下的一个 MessageQueue，它有很多的 ConsumeQueue 文件，这个 ConsumeQueue 文件里存储的是一条消息对应在 CommitLog 文件中的 offset 偏移量。 例如，有一个 Topic，它有 4 个 MessageQueue，然后在两台 Broker 机器上，每台 Broker 机器会存储两个 MessageQueue。此时假设生产者选择对其中一个 MessageQueue 写入一条消息，此时消息会发送到 Broker 上。然后 Broker 会把这个消息写入自己的 CommitLog 文件中。 如下图，我在图里加入了两个 ConsumeQueue，分别叫做 ConsumeQueue0 和 ConsumeQueue1，分别对应着 Topic 里的 MessageQueue0 和 MessageQueue1。 即，Topic 下的 MessageQueue0 和 MessageQueue1 就放在这个 Broker 机器上，而且它们每个 MessageQueue 目前在磁盘上对应了一个 ConsumeQueue。即 MessageQueue0 对应着 Broker 磁盘上的 ConsumeQueue0，MessageQueue1 对应着磁盘上的 ConsumeQueue1。 假设 Queue 的名字叫做 TopicOrderPaySuccess，那么此时在 Broker 磁盘上应该有如下两个路径的文件： $HOME/store/consumequeue/TopicOrderPaySuccess/MessageQueue0/ConsumeQueue0 磁盘文件 $HOME/store/consumequeue/TopicOrderPaySuccess/MessageQueue1/ConsumeQueue1 磁盘文件 然后，当你的 Broker 收到一条消息写入 CommitLog 之后，它会同时将这条消息在 CommitLog 中的物理位置，也就是一个文件偏移量，就是一个 offset，写入到这条信息所属的 MessageQueue 对应的 ConsumeQueue 文件中去。 比如现在这条消息在生产者发送的时候是发送给 MessageQueue0 的，那么此时 Broker 就会将这条消息在 CommitLog 中 offset 偏移量，写入到 MessageQueue 对应的 ConsumeQueue0 中去。所以实际上，ConsumeQueue0 中存储的是一个一个消息在 CommitLog 文件中的物理位置，也就是 offset。 如下图，图里展示出来的是 ConsumeQueue 中的一个物理位置其实是对 CommitLog 文件中一个消息的引用。 实际上在 ConsumeQueue 中存储的每条数据不只是消息在 CommitLog 中的 offset 偏移量，还包含了消息的长度，以及 tag hashcode，一条数据是 20 个字节，每个 ConsumeQueue 文件保存 30万 条数据，大概每个文件是 5.72MB 所以 Topic 的每个 MessageQueue 都对应了 Broker 机器上的多个 ConsumeQueue 文件，保存了这个 MessageQueue 的所有消息在 CommitLog 文件中的物理位置，也就是偏移量。 如何让消息写入 CommitLog 文件近乎内存写性能对于生产者把消息写入到 Broker 时，Broker 会直接把消息写入 CommitLog 文件，那么 Broker 是如何提升整个过程的性能的。因为这个部分的性能提升会直接提升 Broker 处理消息写入的吞吐量，比如你写入一条消息到 CommitLog 磁盘文件假设需要 10ms，那么每个线程每秒可以处理 100个 写入消息，100个 线程每秒只能处理 1万 个写入消息请求。 但是把消息写入 CommitLog 磁盘文件的性能优化为只需要 1ms，那么每个线程每秒可以处理 1000个 消息写入，此时 100个 线程可以处理 10万 个写入消息请求。所以，Broker 把接收到的消息写入 CommitLog 磁盘文件的性能，对它的 TPS 有很大的影响。 所以，Broker 是基于 OS 操作系统的 PageCache 和 顺序写 两个机制，来提升写入 CommitLog 文件的性能的。 首先 Broker 是以顺序的方式将消息写入 CommitLog 磁盘文件的，也就是每次写入就是在文件末尾加一条数据即可，对文件进行顺序写的性能比对文件随机写的性能提升很多。 另外，数据写入 CommitLog 文件的时候，其实不是直接写入底层的物理磁盘文件的，而是先进入 OS 的 PageCache 内存缓存中，然后后续由 OS 的后台线程选一个时间，异步化地将 OS PageCache 内存缓冲中的数据刷入底层的磁盘文件。如图： 这样的优化下，采用 磁盘文件顺序写 + OS PageCache 写入 + OS 异步刷盘 的策略，基本上可以让消息吸入 CommitLog 的性能跟你直接写入内存里是差不多的，所以正是如此，才可以让 Broker 高吞吐地处理每秒大量的消息写入。 同步刷盘与异步刷盘上述的模式，其实就是异步刷盘模式。在异步刷盘模式下，生产者把消息发送给 Broker，Broker 将消息写入 OS PageCache 中，就直接返回 ACK 给生产者了。此时生产者就认为消息写入成功了，那么会有什么问题？ 问题是有的。如果生产者认为消息写入成功了，但是实际上那条消息此时是在 Broker 机器上的 OS cache 中的，如果此时 Broker 直接宕机，那么 os cache 中的这条数据就会丢失。所以异步刷盘的策略下，可以让消息写入吞吐量非常高，但是有数据丢失的风险，这个是需要清楚的。 另外一种模式叫同步刷盘。如果你使用同步刷盘，那么生产者发送一条消息出去，Broker 收到了消息，必须直接强制把这个消息刷入底层的物理磁盘文件中，然后才返回 ack 给 producer，此时你才知道消息写入成功了。 只要消息进入了物理磁盘上，除非是你的物理磁盘坏了导致数据丢失，否则正常情况下数据就不会丢失了。如果 Broker 还没来得及把数据同步刷入磁盘，然后它自己挂了，那么此时对生产者来说会感知到消息发送失败了，然后只要不停地重试发送就可以了，直到有 slave broker 切换成 master broker 重新让你可以写入信息，此时可以保证数据是不会丢的。 但是如果你强制每次消息写入都要直接进入磁盘中，必然导致每条消息写入性能急剧下降，导致消息写入吞吐量下降，但是可以保证数据不会丢失]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单说说秒杀系统的技术难点]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F11%2F%E7%AE%80%E5%8D%95%E8%AF%B4%E8%AF%B4%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8A%80%E6%9C%AF%E9%9A%BE%E7%82%B9%2F</url>
    <content type="text"><![CDATA[思维导图 秒杀活动压力过大怎么办秒杀活动压力过大，是否能通过堆机器解决？比如说给订单系统部署更多的机器，是不是可以抗下更高的并发？这个是没问题的，订单系统可以通过部署更多的机器机型线性扩展。 那数据库呢？是否也要部署更多的服务器，进行分库分表，然后让更多的数据库服务器来抗更高的数据库高并发访问？大概思路是这样，所谓分库分表，就是把目前的一台数据库服务器变成多台数据库服务器，然后把一张订单表变成多张订单表。 例如，假设订单表里有 1200 万条数据，然后有一台数据库服务器，如果我们现在变成 3 台数据库服务器，那么可以在每台数据库服务器里放 400 万订单数据，这就是所谓的分库分表。这样的好处是什么呢？如果未来订单系统的整体访问压力达到了每秒 3 万请求了，此时订单系统通过扩容可以部署更多机器，然后其中每台数据库服务器承受 1 万的请求，如图： 这样不就可以通过增加更多的数据库服务器来抗下更高的并发请求了吗？但其实这不太靠谱。除非是技术能力比较弱的公司，没有厉害的架构师去利用已有的技术合理设计优秀的架构，才会用这种堆机器的方式简单地抗下超高的并发。 如果用堆机器的方式来解决这个问题，必然存在一个问题，就是随着你的用户量越来越大，你的并发请求越来越多，会导致你要不停地增加更多的机器。所以解决问题不能用这种简单粗暴堆机器的方案。 高并发的商品详情页请求秒杀活动主要涉及到的并发压力有两块：一个是高并发地读，一个是高并发地写。 首先思考一下，平时大量的用户是怎么参与到秒杀活动里来的？往往是这样。假设每天晚上 8:30 有一波秒杀商品开始售卖，因为每次到了晚上 8:30 之前，就有很多用户会登陆 APP，然后再 APP 前坐等秒杀特价商品。 所以这个时候，必然会出现一种场景，就是首先大量用户会拿着 APP 不停地刷新一个秒杀商品的页面。那么这些秒杀商品页面是从哪儿加载出来的？本质上来说从商品技术团队负责的商品详情页加载出来的，如图，引入了一个商品详情页系统的概念，它负责提供我们看到的各种秒杀商品页面。 所以这个商品详情页系统就是在秒杀活动开始之前最先被大量用户高并发访问的一个系统了。如果没有秒杀活动的时候，其实大量的用户是分散在不同的时间段来逛 APP 的，并且逛的是不同的人会看不同的商品的页面。 但是在秒杀活动的时候，面临的第一个问题是，可能几十万人会同一时间频繁地访问同一个秒杀商品的页面，对商品详情页系统造成巨大的访问压力。 商品团队的秒杀架构优化：页面数据静态化为了解决商品详情页系统的技术难点，一般采取的是 页面数据静态化 + 多级缓存 的方案。 首先第一步，秒杀商品页面必须是将其数据做到静态化，这是什么意思呢？ 如果让秒杀商品页面是动态化的，那么每次一个用户只要访问这个商品详情页，就必须发送一次请求到后端的商品详情页来获取数据。比如商品的标题、副标题、价格、优惠策略、库存、大量的图片、商品详情说明。售后政策等等，这都是商品详情页的数据。 那么你可以选择让用户浏览这个秒杀商品的时候，每次都发送请求到后台去加载这些数据过来，然后渲染出来给用户看这个商品页面，这就是所谓的动态模式。 如果这商品详情页里的大量数据都是存储在商品团队里的数据库里的，那么岂不是大量用户同时频繁访问这个商品详情页，会直接导致商品详情页系统承受高并发的访问？同时导致商品数据库承受高并发的访问？ 所以首先需要将这个秒杀活动的商品详情页里的数据做成静态化的，也就是提前就从数据库里把这个页面需要的数据都提取出来组装成一份静态数据放在别的地方，避免每次访问这个页面都要访问后端数据库。 商品团队的秒杀架构优化：多级缓存接着就是多级缓存的架构，我们会使用 CDN + Nginx + Redis 的多级缓存架构。 比如说秒杀商品详情页的数据，首先会放一份在离用户地理位置比较近的 CDN 上。CDN 你大致可以这么理解，比如你们公司的机房在广州，系统也部署在广州，那么对于陕西的用户，我们可以将一份静态化好的数据放在陕西的一个 CDN 上。然后不同地方的用户在加载这个秒杀商品的详情页数据时，就是从附近的 CDN 上加载的，不需要每次请求都发送到我们公司在广州的机房去。 这个 CDN 缓存就是我们多级缓存架构里的第一级缓存。那如果因为缓存过期之类的问题，CDN 上没有用户要加载的商品详情页数据，此时用户就会发送请求到我们公司的机房里的机器上去请求加载这个商品的数据了，这个时候我们需要在 Nginx 这样的服务器里做一级缓存。 在 Nginx 中是可以基于 Lua 脚本实现本地缓存的，我们可以提前把秒杀商品详情页的数据放到 Nginx 中进行缓存，如果请求发送过来，我们可以从 Nginx 中直接加载缓存数据，不需要把请求转发到我们商品系统上去。 这个时候如果在 Nginx 服务器上也没加载到秒杀商品的数据呢？此时就可以由 Nginx 中的 Lua 脚本发送请求去 Redis 集群中加载我们提前放进去的秒杀商品数据。 如果在 Redis 中还是没有找到，那么就由 Nginx 中的 Lua 脚本直接把请求转发到商品详情页系统里去加载就可以了，此时就会直接从数据库中加载数据出来。但是一般来说数据是可以从 CDN、Nginx、Redis 中加载到的，可能只有极少的请求会直接访问到商品系统去从数据库里加载商品页数据。 通过这样的一套方案。我们就可以把用于秒杀活动的商品详情页数据进行静态化，然后把静态化以后的一串商品数据（例如 JSON 串）放到 CDN、Nginx、Redis 组成的多级缓存里去，这样大量的用户同时访问这个商品页面对我们系统本身就没什么压力了。 订单方面的优化用答题的方式避免作弊软件抢购以及延缓下单首先我们要防止有人写一个抢购的脚本或者作弊软件，疯狂地发送请求去抢商品，所以一般来说，现在你要参与抢购，都会让你点击按钮之后先进行答题，就是说先弹出一个框，让你回答一个问题，回答正确了你才能发起抢购的请求。 这个办法是非常有效的，因为首先它避免了一些作弊软件去发送抢购请求，另外就是不同的人答题的速度是不一样的，所以可以通过这个答题让不同的人发送请求的时间错开，不会在一个时间点发起请求。如图： 为秒杀独立出来一套订单系统接着用户下单抢购的请求发送出去之后，会达到我们的后台系统，对于后台系统而言，我们需要思考，是否直接用我们目前已有的订单系统去抗所有的请求？ 答案是否定的。假设你有 100 万用户在这个时间段很活跃来购买物品，但是可能只有其中 50 万用户在参与秒杀活动，同一时间发送了大量的抢购请求到后台系统，但是同时还有很多其它的用户这个时候并不在参与秒杀系统，他们在进行其它商品的常规性浏览和下单。 如果你让秒杀下单和普通下单请求都由一套订单系统来承载，那么可能会导致秒杀下单请求耗尽了订单系统的资源，或者导致系统不稳定，然后导致其他普通下单请求也出现问题，没有办法完成下单。所以我们一般会对订单系统部署两个集群，一个集群是秒杀订单系统集群，一个集群是普通订单系统集群。如图： 基于 Redis 实现下单时精准扣减库存在后台系统中首先要做的一个事情，就是扣减库存。秒杀商品一般是有数量限制的，所以当大量的请求到达后台系统之后，第一步，就是先去扣减库存。 在秒杀场景下，一般会将每个商品的库存提前写入 Redis 中，然后当请求到来之后，就直接对 Redis 中的库存进行扣减。Redis 是可以轻松用单机抗每秒几万高并发的，因此这里就可以抗下高并发额库存扣减。比如我们总共就 1 万件秒杀商品，其实最多就是前 1 万个到达的请求可以成功从 Redis 中扣减库存，抢购到这个商品，接着后续的请求从 Redis 里扣减库存的时候，都会发现库存已经没有了，无法抢购商品了。 抢购完毕之后提前过滤无效请求在 Redis 中的库存被扣减完之后，就说明后续其他的请求都没有必要发送到秒杀系统了，此时我们一颗让 Nginx 在接收到后续请求之后，直接就把后续请求过滤掉。 比如一旦商品请购完毕，可以在 ZooKeeper 中写入一个秒杀完毕的标志位，然后 ZK 会反向通知 Nginx 中我们自己写的 Lua 脚本，通过 Lua 脚本后续在请求后来的时候直接过滤掉，不要向后转发了。这样就可以最大幅度削减对后端秒杀系统的请求压力。 瞬时高并发下单请求进入 MQ 进行削峰接着我们来思考下，即使是有 1 万件商品同时被 1 万人秒杀成功了，那么可能瞬间会有 1 万请求涌入正常的订单系统进行后续的处理，此时可能还是会有瞬间上万请求访问到订单数据库中创建订单。这个时候，完全可以引入 MQ 进行削峰处理。 对于秒杀系统而言，如果发现通过 Redis 完成了库存扣减，并且此时库存还大于 0，说明秒杀成功了需要生成订单，此时就直接发送一个消息到 MQ 中即可，然后普通订单系统熊 MQ 中消费秒杀成功的消息进行常规化的流程处理即可，比如创建订单等等。 这样的话，瞬间上万并发的压力会被 MQ 轻松抗下来，然后普通的订单系统可以根据自己的工作负载慢慢地从 MQ 中拉取秒杀成功的消息，然后进行后续操作即可，不会对订单数据造成过大的压力。否则如果你让瞬间产生的一万或者几万的订单请求直接访问订单数据库，必然还是会让它压力过大，需要额外增加机器，这就没有必要了。 因此这里利用 MQ 抗下每秒几万并发的下单请求，然后让订单系统已每秒几千的速率慢慢处理即可，也就是延迟可能几十秒，这些下单请求就会处理完毕。如图： 秒杀架构的核心要点通过这篇文章的思路，就会清晰地看到，对于一个秒杀系统而言，比较重要的一下几点： 在前端/客户端通过设置秒杀答题，错开大量下单的时间，组织作弊器刷点 独立出来一套秒杀系统，专门负责处理秒杀请求 优先基于 Redis 进行高并发的库存扣减，一旦库存扣减完则秒杀结束 秒杀结束后，Nginx 层过滤掉无效的请求，大幅度削减转发到后端的流量 瞬时生成的大量下单请求直接进入 MQ 进行削峰，订单系统慢慢拉取消息完成下单操作]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 事务]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F09%2FMySQL-%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[MySQL 的特性 — ACIDMySQL 的特性，就是大家常常听到的 ACID。 Atomic：原子性。就是一堆SQL，要么一起成功，要么一起失败。不允许某个 SQL 执行成功了，某个 SQL 却失败了。这样就不是原子性了。 Consistency：一致性。这个是针对数据一致性来说的，就是一组 SQL 执行之前，数据必须是准确的，执行之后，数据也必须是准确的。别搞了半天，执行完 SQL，结果 SQL 对应的数据修改没执行，这就很坑爹了。 Isolation：隔离性。这个就是说多个事务在跑的时候不能互相干扰。不能事务 A 操作个数据，弄到一半还没弄好，结果事务 B 来改了这个数据，导致事务 A 的操作出错了。 Durability：持久性。事务成功了，就必须永久对数据的修改是有效的，别过来一会数据自己不见了。 MySQL 事务隔离级别MySQL 的事务隔离级别主要有 读未提交、读已提交（不可重复读）、可重复读和串行化四种。 1、读未提交，Read UnCommitted。这个很坑爹，就是说某个事务还没提交的时候，修改了数据，就让别的事务给读到了。这很容易导致出错，这个也叫做脏读。 2、读已提交，Read Committed（不可重复度）。这个比上面那个好一点，但是也比较尴尬。 就是说事务 A 在跑的时候，先查询了一个数据的值是 1，然后过了断时间，事务 B 把那个数据给修改了还提交了。此时事务 A 再次查询这个数据就变成了值 2 了，这是读了人家事务提交的数据了，所以是读已提交。 这个也叫不可重复读，就是所谓的一个事务内对一个数据两次读，可能会读到不一样的值。如图： 3、可重复读，Read Repeatable。这个比上面那个再好一点。就是说事务 A 在执行的过程中，对某个数据的值，无论读多少次都是值 1。哪怕这个过程中事务 B 修改了数据的值还提交了，但是事务 A 读到的还是自己事务开始时这个数据的值。如图： 幻读，不可重复读和可重复读都是针对两个事物同时对某条数据在修改，但是幻读针对的是插入。比如某个事物把所有行的某个字段都修改为了 2，结果另一个事务插入了一条数据，那个字段的值是 1。然后就尴尬了，第一个事务会突然发现多出来一条数据，那个数据的字段是 1。 幻读会带来什么问题？在此隔离级别下，例如，事务 1 要插入一条数据，我先查询一下有没有相同的数据，但是这时事务 2 添加了这条数据，这就会导致事务 1 插入失败，并且它就算再一次查询，也无法查询到与其插入相冲突的数据，同时自身死活都插入不了。 4、串行化，如果要解决幻读，就需要使用串行化级别的隔离级别，所有事务都串行起来，不允许多个事务并行操作。 MySQL 的默认隔离级别是 Read Repeatable，就是可重复读，就是说每个事务都会开启一个自己要操作的某个数据的快照，事务期间，读到的都是这个数据的快照而已，对一个数据的多次读都是一样的。 MySQL 中的隔离级别的实现上面的内容解释了一些数据库理论的概念，但是在 MySQL、Oracle 这样的数据库中，为了性能的考虑并不是完全按照上面的理论来实现的。 MVCCMVCC，全称 Multi-Version Concurrency Control。是 MySQL 中基于乐观锁理论实现可重复读隔离级别的方式。 这里先引入两个概念： 系统版本号：一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号：事务开始时的系统版本号。 在 MySQL 中，会在表中每一条数据后面添加两个字段： 创建版本号：创建一行数据时，将当前系统版本号作为创建版本号赋值。 删除版本号：删除一行数据时，将当前系统版本号作为删除版本号赋值。 SELECTselect 时读取数据的规则为：创建版本号 &lt;= 当前事务版本号，删除版本号为空或 &gt; 当前事务版本号。 创建版本号 &lt;= 当前事务版本号保证取出的数据不会有后启动的事务中创建的数据；而删除版本号为空或 &gt; 当前事务版本号保证了至少在改事务开启之前数据没有被删除，是应该被查出来的数据。 INSERTinsert 时将当前的系统版本号赋值给创建版本号字段。 UPDATE插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行，实际上这里的更新是通过 delete 和 insert 实现的。 DELETE删除时将当前的系统版本号赋值给删除版本号字段，标识该行数据在哪一个事务中会被删除，即使实际上在 commit 时该数据没有被删除，根据 select 的规则后开启数据也不会查询该数据。 示例假设现在有这么一个表，如下： id name 创建事务id 删除事务id 1 张三 120 122 2 李四 119 空 事务 id = 121 的事务，查询 id = 1 的这一行的时候，一定会找到创建事务 id &lt;= 当前事务 id 的那一行。所以 SELECT * FROM table WHERE id = 1 就可以查到上面那一行。 事务 id = 122 的事务，将 id = 1 的这一行给删除了，此时就会将 id = 1 的行的删除事务 id 设置为 122。当事务 id = 121 的事务，再次查询 id = 1 的那一行，是可以查到的。因为创建事务 id &lt;= 当前事务 id，且 当前事务 id &lt; 删除id。 如果某个事务执行期间，别的事务更新了一条数据呢？这个很关键的一个实现，其实在 InnoDB 中，就是插入了一行记录，然后将新插入的记录的创建事务 id 设置为新的事务的 id，同时将这条记录之前的那个版本的删除 id 设置成新的事务 id。 id name 创建事务id 删除事务id 1 张三 120 122 2 李四 119 空 2 小李四 122 122 事务 id = 121 的事务，查询 id = 2 的那一行，查到 name = 李四。事务 id = 122 的事务，将 id = 2 的那一行的 name 修改成 name = 小李四。事务 id = 121 的事务，查询 id = 2 的那一行，只能查询到 李四。因为创建事务 id &lt;= 当前事务 id，当前事务 id &lt; 删除 id。 快照读和当前读select 快照读当执行 select 操作时，InnoDB 默认会执行快照读，会记录下这次 select 后的结果，之后 select 的时候就会返回这次快照的数据，即使其他事务提交了不会影响当前 select 的数据，这就实现了可重复读了。快照的生成当在第一次执行 select 的时候，也就是说假设当事务 A 开启了事务，然后没有执行任何操作，这时候事务 B insert 了一条数据然后 commit，这时候 A 执行 select，那么返回的数据中就会有 B 添加的那条数据。之后无论有其他事务 commit 都没有关系，因为快照已经生成了，后面的 select 都是根据快照来的。 当前读对于会对数据修改的操作（update、insert、delete）都是采用当前读的模式。在执行这几个操作的时候会读取最新的记录，即使是别的事务提交的数据也可以查询到。假设要 update 一条记录，但是在另一个事务中已经 delete掉这条数据并且 commit 了。如果 update 就会产生冲突，所以在 update 的时候需要知道最新的数据。 select 的当前读需要手动地加锁： 12SELECT * FROM table WHERE ? LOCK IN SHARE MODE;SELECT * FROM table WHERE ? FOR UPDATE 参考资料MySQL的可重复读级别能解决幻读吗 事务的几个特性和隔离方式]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解 MySQL 中的 Buffer Pool]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F04%2F%E8%AF%A6%E8%A7%A3-MySQL-%E4%B8%AD%E7%9A%84-Buffer-Pool%2F</url>
    <content type="text"><![CDATA[思维导图 配置 Buffer Pool 的大小Buffer Pool 本质上是数据库的一个内存组件，你可以理解它就是一片内存数据结构，所以这个内存数据结构肯定是有一定大小的，不可能是无限大的。这个 Buffer Pool 默认情况下是 128MB，还是有一点偏小的，我们实际生产环境可以对 Buffer Pool 进行调整。 比我我们数据库如果是 16 核 32G 的机器，那么你可以给 Buffer Pool 分配 2GB 的内存，使用下面的配置就可以了。 12[server]innodb_buffer_pool_size = 2147483648 Buffer Pool 的数据结构数据页：MySQL 中抽象出来的数据单位假设我们的数据库中有一片内存区域是 Buffer Pool 了，那么我们的数据如何放在 Buffer Pool 中？我们都知道数据库的核心数据模型就是表 + 字段 + 行的概念，即我们都知道数据库里有一个个表，一个表有很多字段，然后每个表里有许多行数据，每行数据都有自己的字段值。所以我们的数据是一行一行放在 Buffer Pool 里面的吗？ 当然不是，实际上 MySQL 对数据抽象出来了一个数据页的概念，它是把很多行数据放在一个数据页里，也就是说我们的磁盘文件中会有很多的数据页，每一页数据放了很多行数据。所以实际上假设我们要更新一行数据，此时数据库会找到这行数据所在的数据页，然后从磁盘文件里把这行数据所在的数据页直接加载到 Buffer Pool 里去。也就是说，Buffer Pool 中存放的是一个一个的数据页。如图： 磁盘上的数据文件和 Buffer Pool 中的缓存页如何对应起来实际上默认情况下，磁盘中存放的数据页的大小是 16KB，即，一页数据包含了 16KB 的内容。而 Buffer Pool 中存放的一个一个的数据页，我们通常叫做缓存页，因为 Buffer Pool 是一个缓冲池，里面的数据都是从磁盘缓存到内存去的。 而 Buffer Pool 中默认情况下，一个缓存页的大小和磁盘上的一个数据页的大小是一一对应起来的，都是 16KB。 缓存页对应的描述信息我们要知道一个概念，对于每个缓存页，它实际上都会有一个描述信息，这个描述信息大体可以认为是用来描述这个缓存页的。比如包含如下的一些东西：这个数据页所属的表空间、数据页的编号、这个缓存页在 Buffer Pool 中的地址以及别的一些东西。 每个缓存页都会对应一个描述信息，这个描述信息本身也是一块数据，在 Buffer Pool 中，每个缓存页的描述数据放在最前面，然后各个缓存页放在后面。所以，Buffer Pool 实际看起来大概长这个样子： 这里我们要注意一点，Buffer Pool 中的描述信息大概相当于缓存页大小的 5% 左右，也就是每个描述数据大概是 800 个字节左右的大小，然后假设你设置的 buffer pool 大小是 128MB，实际上 Buffer Pool 真正的最终大小会超出一些，可能有 130 多 MB 的样子，因为它里面还要存放每个缓存页的描述数据。 Buffer Pool 中的 free 链表通过上面的讲解我们大概知道 MySQL 中的 Buffer Pool 到底长什么样，那么在数据库启动的时候，它是如何初始化 Buffer Pool 的呢？ 其实很简单，数据库只要一启动，就会按照你设置的 Buffer Pool 大小，稍微再加大一点，去找操作系统申请一块内存区域，作为 Buffer Pool 的内存区域。然后当内存区域申请完毕之后，数据库就会按照默认的缓存页的 16KB 的大小以及对应的 800 个字节左右的描述数据的大小，在 Buffer Pool 中划分出来一个一个的缓存页和一个一个它们对应的描述数据。 当数据库把 Buffer Pool 划分完毕之后，看起来就是上面的那张图。只不过这个时候，Buffer Pool 中的一个一个的缓存页都是空的，里面什么都没有，要等数据运行起来之后，当我们要对数据进行增删改查的操作的时候，才会把数据对应的页从磁盘文件里读取出来，放入 Buffer Pool 中的缓存页中。 哪些缓存页是空闲的当数据库运行起来之后，随着增删改查操作的执行，此时就需要不停地从磁盘上读取一个一个的数据页放入 Buffer Pool 中对应的缓存页里去，把数据缓存起来，那么以后就可以对这个数据在内存里执行相应操作了。 但是此时在磁盘上读取数据页放入 Buffer Pool 中的缓存页的时候，会涉及到一个问题：哪些缓存页是空闲的。因为默认情况下磁盘上的数据页和缓存页是一一对应起来的吗，都是 16KB，所以我们要知道 Buffer Pool 中哪些缓存页是空闲的状态。 所以数据库会为 Buffer Pool 设计一个 free 链表，它是一个双向链表数据结构。这个 free 链表里，每个节点就是一个空闲的缓存页的描述数据块的地址。也就是说，只要你一个缓存页是空闲的，那么它的描述数据块就会被放入这个 free 链表中。 刚开始数据库启动的时候，可能所有的缓存都是空闲的，因此此时可能是一个空的数据库，一条数据都没有，所以此时所有缓存页的描述数据块，都会被放入这个 free 链表中。 这个 free 链表里面就是各个缓存页的描述数据块，只要缓存页是空闲的，那么它们对应的描述数据块就会加入到这个 free 链表，每个节点都会双向链接自己的前后节点，组成一个双向链表。另外，这个 free 链表有一个基础节点，它会引用链表的头结点和尾节点，里面还存储了链表中有多少个描述数据块的节点，也就是有多少个空闲的缓存页。 free 链表占用多少内存空间可能有人会以为这个描述数据块，在 Buffer Pool 里有一份，在 free 链表里也有一份，好像在内存里有两个一模一样的描述数据块。其实这个是错误的，这个 free 表，它本身就是由 Buffer Pool 里的描述数据块组成的，你可以认为是每个描述数据块里都有两个指针，一个是 free_pre，一个是 free_next，分别指向自己的上一个 free 链表的节点，以及下一个 free 链表的节点。 通过 Buffer Pool 中的描述数据块的 free_pre 和 free_next 两个指针，就可以把所有的描述数据块串成一个 free 链表。上面为了画图需要，所以把描述数据块单独画了一份出来，表示他们之间的指针引用关系。 对于 free 链表而已，只有一个基础节点是不属于 Buffer Pool 的，它是 40 字节大小的一个节点，里面存放了 free 链表的头结点的地址，尾结点的地址，还有 free 链表里当前有多少个节点。 如何将磁盘上的页读取到 Buffer Pool 的缓存页中去当你想要把磁盘上的数据页读取到 Buffer Pool 中的缓存页里去的时候，要怎么做？其实有了 free 链表之后，这就很简单了。 首先，我们需要从 free 链表里获取一个描述数据块，然后就可以对应的获取这个描述数据块对应的空间缓存页。接着我们就可以把磁盘上的数据页读取到对应的缓存页里去，同时把相关的一些描述数据写入到缓存页的描述数据块里去，比如这个数据页所属的表空间之类的信息，最后把那个描述数据块从 free 链表里去除就可以了。 如何知道数据页有没有被缓存我们在执行增删改查的时候，肯定是先看看这个数据页有没有被缓存，如果没被缓存就走上面的逻辑，从 free 链表中找到一个空闲的缓存页，从磁盘上读取数据页写入缓存页，写入描述数据，从链表中移除这个描述数据块。但是如果数据页已经被缓存了，那么就会直接使用了。 所以其实数据库还会有一个哈希表数据结构，它会用表空间号 + 数据页号，作为一个 key，然后缓存页的地址作为 value。当你要使用一个数据页的时候，通过 “表空间号 + 数据页号” 作为 key 去哈希表里查一下，如果没有就读取数据页，如果已经有了，就说明数据页已经被缓存了。 Buffer Pool 中的 flush 链表脏缓存页你在执行增删改的时候，如果发现数据页没缓存，那么会基于 free 链表找到一个空闲的缓存页，然后读取到缓存页里去，但是如果已经缓存了，那么下一次就必然会直接使用缓存页。即，你要更新的数据页都会在 Buffer Pool 的缓存页里，供你在内存页中直接执行增删改的操作。 接着你去更新 Buffer Pool 的缓存页中的数据，此时一旦你更新了缓存页中的数据，那么缓存页里的数据和磁盘上的数据页里的数据，就不一致了。这个时候，我们就说缓存页是脏数据，脏页。 哪些缓存页是脏页上面说的那些在内存里更新的脏页的数据，都是要被刷新会磁盘文件的。但就有一个问题，不可能所有的缓存页都刷回磁盘的，因为有的缓存页可能是因为查询的时候被读取到 Buffer Pool 里的，可能根本没有修改过！ 所以数据库在这里引入了另外一个跟 free 链表类似的 flush 链表，这个 flush 链表本质也是通过缓存页的描述数据块中的两个指针，让被修改过的缓存页的描述数据块，组成一个双向链表。凡是被修改过的缓存页，都会把它的描述数据块加入到 flush 链表中去，flush 的意思就是这些都是脏页，后续都是要 flush 刷新到磁盘上的。 所以 flush 链表的结果跟 free 链表几乎是一样的，如图： Buffer Pool 中的缓存页不够时，基于 LRU 算法淘汰部分缓存当我们执行 CRUD 操作的时候，无论是查询数据，还是修改数据，都会把磁盘上的数据页加载到缓存页里来。那么在加载数据到缓存页的时候，必然是要加载到空闲的缓存页里去的，所以必须要从 free 链表中找一个空闲的缓存页，然后把磁盘上的数据页加载到空闲的缓存页里去。 随着不停地把磁盘上的数据页加载到空闲的缓存页里去，free 链表中的空闲缓存页也会越来越少，当你不停地把磁盘上的数据页加载到空闲缓存页里去，free 链表中不停地移除空闲缓存页，迟早有那么一个瞬间，free 链表已经没有空闲缓存页了。 淘汰掉一些缓存数据如果所有的缓存页都被塞了数据，此时无法从磁盘上加载新的数据页到缓存页里去了，此时只有一个办法，就是淘汰掉一些缓存页。所谓的淘汰缓存页，就是把一个缓存页里修改过的数据，给刷到磁盘上的数据页里去，然后这个数据页就可以清空了，让它重新变成一个空闲的缓存页。接着你再把磁盘上需要的新的数据页加载到这个腾出来的空闲缓存页中去。 那要把一个缓存页里的数据刷入磁盘，腾出来一个空闲缓存页，那应该把哪个缓存页的数据给刷入磁盘呢？ 缓存命中率这里我们先提一个概念，叫缓存命中率。假设现在有两个缓存页，一个缓存页的数据，经常会被修改和查询，比如在 100 次请求中，有 30 次都是在查询和修改这个缓存页里的数据，那么此时我们可以说这种情况下，缓存命中率很高。 另外一个缓存页里的数据，就是刚从磁盘加载到缓存页之后，就修改和查询过一次，之后100 次中没有一次是修改和查询这个缓存页的数据的，那么我们就说缓存命中率有点低。因为大部分请求可能还需奥走磁盘查询数据，它们要操作的数据不在缓存中。 一般来说我们都是优先淘汰缓存命中率低的缓存页。 引入 LRU 链表来判断哪些缓存页是不常用的接下来我们就要知道，哪些缓存页是经常被访问，哪些缓存页是很少被访问的。此时就要引入一个新的 LRU 链表了。这个所谓的 LRU 就是 Least Recently Used，最近最少使用的意思。 这个 LRU 链表的工作原理是什么？简单说就是，我们从磁盘加载一个数据页到缓存页的时候，就把缓存页的描述数据块放到 LRU 表头部去，那么只要有数据的缓存页，它都会在 LRU 里了，而且最近被加载数据的缓存页，都会放到 LRU 链表的头部去。 然后假设某个缓存页的描述数据块本来在 LRU 链表的尾部，后续只要你查询或者修改这个缓存页的数据，也要把这个缓存页挪动到 LRU 链表的头部去，也就是说最近被访问过的缓存页，一定在 LRU 链表的头部。 那样的话，当你的缓存页没有一个空闲的时候，你是不是要找出来那个最近最少被访问的缓存页去刷入磁盘？此时你就直接在 LRU 链表的尾部找到一个缓存页，它一定是最近最少被访问的那个缓存页。 然后你就把 LRU 链表尾部的那个缓存页刷入到磁盘中，然后把你需要的磁盘数据页加载到腾出来的空闲缓存页就可以了。 简单的 LRU 链表在 Buffer Pool 实际运行中可能导致的问题上面说的那个 LRU 机制在实际运行过程中，是存在巨大的隐患的。首先会带来隐患的就是 MySQL 的预读机制。这个所谓的预读机制，就是当你从磁盘上加载一个数据页的时候，它可能会连带着把这个数据页相邻的其他数据页，也加载到缓存里去。 例如，现在有两个空闲的缓存页，然后在加载一个数据页的时候，连带着把它的一个相邻的数据页也加载到缓存里去了。但是，实际上只有一个缓存页是被访问了，另外一个通过预读机制加载的缓存页，其实没人访问，此时这两个缓存页都在 LRU 链表的前面。如图： 例如上面的情景，前两个缓存页都是刚加载进来的，但是此时第二个缓存页是通过预读机制连到这加载进来的，它也被放到了链表的前面，但实际上没人访问它。 除此之外还有尾巴上的两个缓存页，都是一直有人访问的缓存页，只不过上图代表的是刚刚把头部两个缓存页加载进来的时候的一个 LRU 链表当时的情况。这个时候，如果空闲页没有了，此时要加载新的数据页了，是不是就要从 LRU 链表的尾部把所谓的 “最近最少使用的一个缓存页” 给刷入磁盘，腾出一个空闲缓存页出来？ 这个是不合理的。最后一个之前一直频繁被人访问，只不过在这一个瞬间，被新加载进来的两个缓存页给占据了 LRU 链表前面的位置，尤其是第二个缓存页，还是通过预读机制加载进来的。根本没人访问。所以最合理的应该是把上图中第二个通过预读机制加载进来的缓存页给输入磁盘和清空。 哪些情况会触发 MySQL 的预读机制以下情况会触发 MySQL 的预读机制： 有一个参数是 innodb_read_ahead_threshold，它的默认值是 56，意思是如果顺序访问了一个区里的多个数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制，把下一个相邻区的所有数据页都加载到缓存里去。 如果 Buffer Pool 里缓存了一个区里的 13 个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去。这个机制是 innodb_random_read_ahead 来控制的，它默认是 OFF，也就是关闭的。 所以默认情况下，主要是第一个规则可能触发预读机制，一下子就把很多相邻区里的数据页加载到缓存里去，这些缓存页如果一下子都放在 LRU 链表的前面，而且没什么人会访问的话，就会跟上图一样，导致本来就在缓存里的一些频繁被访问的缓存页在 LRU 链表的尾部。 另外一种可能导致频繁被访问的缓存页被淘汰的场景另外一种可能，就是全表扫描。 例如 SELECT * FROM users。它没加任何一个 where 条件，会导致它直接一下子把这个表里所有的数据页，都从磁盘加载到 Buffer Pool 里去。这个时候它可能会一下子就把这个表的所有数据页都一一装入各个缓存页里去，此时可能 LRU 链表中排在前面的一大串缓存页，都是全表扫描加载进来的缓存页。如果这次全表扫描过后，后续几乎没用到这个表的数据呢？ 此时 LRU 链表的尾部，可能全部都是之前一直被频繁访问的那些缓存页。然后当你要淘汰一些缓存页腾出空间的时候，就会把 LRU 链表尾部一直被频繁访问的缓存页给淘汰掉，而留下了之前全表扫描加载进来的大量不经常访问的缓存页。 基于冷热数据分离的思想设计 LRU 链表为了解决上面说的简单 LRU 链表的问题，真正 MySQL 在设计 LRU 链表的时候，采取的是冷热数据分离的思想。真正的 LRU 链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据。这个冷热数据的比例是由 innodb_old_blocks_pct 参数控制的，默认是 37，也就说冷数据占比 37%。如图： 数据页第一次被加载到缓存的时候既然 LRU 链表已经按照比例拆分成了冷热两块区域，那么在运行期间，冷热两个区域是如何使用的。 首先数据页第一次被加载到缓存的时候，缓存页会被放在冷数据区域的链表头部。 冷数据区域的缓存页何时被放入热数据区域接着下一个问题。冷数据区域的缓存页什么时候会放到热数据区域呢？MySQL 设计了一个柜子，它设计了 innodb_old_blocks_time 参数，默认值是 1000，也就是 1000 毫秒。即，必须是一个数据页被加载到缓存页之后，在 1s 之后，你访问这个缓存页，它才被挪动到热数据区域的链表头部去。 因为假设你加载了一个数据页到缓存区，然后过了 1s 之后你还访问了这个缓存页，说明你后续很可能会经常访问它。这个时间限制就是 1s，只有了 1s 后访问了这个缓存页，它才会把缓存页放到热数据区域的链表头部去。 如何用冷热数据分离 LRU 链表解决简单 LRU链表带来的隐患预读以及全表扫描加载进来的一大堆缓存页在基于冷热数据分离的 LRU 链表的方案下，预读机制以及全表扫描加载进来的一大堆缓存页，他们会放在哪里？明显是放在 LRU 链表的冷数据区域的前面。 假设这个时候热数据区域已经有很多被频发访问的缓存页了，你会发现热数据区域还是存放被频发访问的缓存页，只要热数据区域有缓存页被访问，它还是会被移动到热数据区域的链表头部去。 所以，预读机制和全表扫描加载进来的一大堆缓存页，此时都在冷数据区域里，跟热数据区域里的频繁访问的缓存页，是没有关系的。 预读机制和全表扫描加载进来的缓存页，何时进热数据区域如果你仅仅是一个全表扫描的查询，此时肯定是在 1s 内就把一大堆缓存页加载进来，然后就访问了这些缓存页一下，通常这些操作 1s 内就结束了。 所以基于目前的一个机制，可以确定的是，这种情况下，那么缓存页是不会从冷数据区域转移到热数据区域的。除非你在冷数据区域里的缓存页，在 1s 之后还被人访问了，那么此时它们就会判定未来可能会被频繁访问的缓存页，然后移动到热数据区域的链表头部去。 如何淘汰一些缓存假设此时缓存页不够了，需要淘汰一些缓存页，要怎么处理？ 方法时直接可以找到 LRU 链表中的冷数据区域的尾部的缓存页，他们肯定是之前就被加载进来的，而且加载进来 1s 过后都没人访问过，说明这个缓存页是冷数据。所以此时就直接淘汰冷数据区域的尾部缓存页，刷入磁盘，就可以了。 LRU 链表热数据区域的优化接着我们看一下 LRU 链表的热数据区域的一个性能优化的点，就是，在热数据区域中，如果你访问了一个缓存页，是否应该要把它立刻移动到热数据区域的链表头部去？ 这个是没必要的。因为热数据区域里的缓存页可能是经常被访问的，所以这么频繁地进行移动性能也不是太好，也没必要。 因此，LRU 链表的热数据区域的访问规则被优化了一下，即你只有在热数据区域的后 3/4 部分的缓存页被访问了，才会给你移动到链表头部去。如果你是热数据区域的前面 1/4 的缓存页被访问了，它是不会被移动到链表头部的。 例如，假设热数据区域的链表里有 100 个缓存页，那么排在前面的 25 个缓存页，即使被访问了，也不会移动到链表头部去。但是对于后面的 75 个缓存页，只要被访问，就会移动到链表头部去。 对于 LRU 链表中尾部的缓存页，如何淘汰他们刷入磁盘Buffer Pool 在运行过程中被使用的时候，实际上会频繁地从磁盘上加载数据页到它的缓存页里去，然后 free 链表、flush 链表、lru 链表都会在使用的使用同时被使用。 比如数据加载到一个缓存页，free 链表里会移除这个缓存页，然后 lru 链表的冷数据区域的头部会放入这个缓存页。 然后如果你修改了一个缓存页，那么 flush 链表中会记录这个脏页，lru 链表还可能会把你从冷数据区域移动到热数据区域的头部去。 总之，MySQL 在执行 CRUD 的时候，首先是大量的操作缓存页以及对应的几个链表。然后再缓存页都满的时候，必然要想办法把一些缓存页给刷入磁盘，然后清空这几个缓存页，接着把需要的数据页加载到缓存里去。我们已经知道它是根据 LRU 链表去淘汰缓存页的，那么它到底什么时候把 LRU 链表的冷数据区域中的缓存页刷入到磁盘呢？ 定时把 LRU 尾部的部分缓存刷入磁盘首先第一个时机，并不是在缓存页满的时候，才会挑选 LRU 冷数据区域尾部的几个缓存页刷入磁盘，而是有一个后台线程，它会运行一个定时任务，这个定时任务每隔一段时间就会把 LRU 链表的冷数据区域的尾部一些缓存页，刷入磁盘里去，清空这几个缓存页，把他们加入回 free 链表去。 所以实际上在缓存页没用完的时候，可能就会清空一些缓存页了。 所以，只要有这个后台线程定时运行，可能你的缓存还没用完，人家就把一批冷数据的缓存页刷入磁盘，清空出一批缓存页了，那么你就多了一批可以使用的缓存页了。只要有缓存页被刷入磁盘，那么这个缓存页必然会加入到 free 链表，从 flush 链表中移除，从 lru 链表中移除。 把 flush 链表中的一些缓存页定时刷入磁盘如果仅仅把 LRU 链表中的冷数据区域的缓存页刷入磁盘，明显是不够的，因为在 LRU 链表的热数据区域里很多缓存页可能也会被频繁地修改，难道它们永远都不刷入磁盘中了吗？ 所以这个后台线程同时也会在 MySQL 不那么繁忙的时候，找个时间把 flush 链表中的缓存页都刷入磁盘中，这样被你修改过的数据，迟早都会刷入磁盘的。 只要 flush 链表中的一波缓存页被刷入磁盘，那么这些缓存页也会从 flush 链表和 LRU 链表中移除，然后加入到 free 链表中去。 可以理解为，你一边不停地加载数据到缓存页里去，不停地查询和修改缓存数据，然后 free 链表页不停地减少，flush 链表中的缓存页不停地在增加，lru 链表中的缓存页不停地在增加和移动；另外一边，你的后台线程不停地把 LRU 链表的冷数据区域的缓存页以及 flush 链表的缓存页，刷入磁盘中来清空缓存页，然后 flush 链表和 LRU 链表中的缓存页不断减少，free 链表中的缓存页不断增加。 这就是一个动态运行起来的效果！ 实在没有空闲缓存页怎么办如果实在没有空闲缓存页了怎么办？此时可能所有的 free 链表都被使用了，然后 flush 链表中有一大堆被修改过的缓存页，LRU 链表中有一大堆的缓存页，根据冷热数据进行了分离，大致是如此的效果。 这个时候如果要从磁盘加载数据页到一个空闲缓存页中，此时就会从 LRU 链表的冷数据区域的尾部找到一个缓存页，它一定是最不经常使用的缓存页。然后把它刷入磁盘和清空，然后把数据页加载到这个腾出来的空闲缓存页里去。 这就是 MySQL 的 Buffer Pool 缓存机制的一整套运行原理。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模拟 JVM 内存溢出]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F02%2F%E6%A8%A1%E6%8B%9F-JVM-%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[模拟 Metaspace 内存溢出Metaspace 区域发生内存溢出的一个场景，就是如果我们在程序里不停地动态生成类，就会导致不停地加载类到 Metaspace 区域里去，而且这些动态生成的类必须还是不能被回收的。接着一旦 Metaspace 区域满了，就会触发 Full GC 连带着回收 Metaspace 中的类，但是此时大量的类是不能被回收的。 因此即使触发过 Full GC 过后，Metaspace 区域几乎还是不能放下任何一个类，此时必然会触发 Metaspace 区域的内存溢出。 CGLIB 动态生成类的代码示例以下代码时用 Maven 来进行项目构建的，如果要用 CGLIB 来动态生成一些类，那么必须在你项目的 pom.xml 中引入以下的一些依赖 12345&lt;dependency&gt; &lt;groupId&gt;cblib&lt;/gruopId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; 接着就可以使用 CGLIB 来动态生成类了，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;public class Demo1 &#123; public static void main(String[] args) &#123; long counter = 0; while (true) &#123; System.out.println("目前创建了 " + (++counter) + " 个Car类的子类了"); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Car.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; if(method.getName().equals("run")) &#123; System.out.println("启动汽车之前，先进行自动的安全检查。。。。。"); return methodProxy.invokeSuper(o, objects); &#125;else &#123; return methodProxy.invokeSuper(o, objects); &#125; &#125; &#125;); Car car = (Car) enhancer.create(); car.run(); &#125; &#125; static class Car &#123; public void run() &#123; System.out.println("汽车启动，开始行使。。。。。。"); &#125; &#125;&#125; 跟大家解释以下上面的代码。首先我们可以看到我们在这里定义了一个类，代表了一个汽车，它有一个 run() 方法，执行的时候就会启动汽车，开始让汽车行驶，如下： 12345static class Car &#123; public void run() &#123; System.out.println("汽车启动，开始行使。。。。。。"); &#125;&#125; 接着我们看下面的代码片段，我们通过 CGLIB 的 Enhancer 类生成一个 Car 类的子类。从这里开始，就动态生成类了，如下： 123Enhancer enhancer = new Enhancer();enhancer.setSuperclass(Car.class);enhancer.setUseCache(false); 你权且当做 Enhancer 是用来生成类的一个 API，代码中的 enhancer.setSuperclass(Car.class); 的意思是说 Enhancer 生成的类是 Car 类的子类，Car 类是生成类的父类。至于那个 UseCache 是什么意思，就先别管了。 既然 Enhancer 动态生成的类是 Car 的子类，那么子类也会有 Car 的 run() 方法，而且我们在调用子类的 run() 方法的时候可以做点手脚，如下： 123456789101112enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; if(method.getName().equals("run")) &#123; System.out.println("启动汽车之前，先进行自动的安全检查。。。。。"); return methodProxy.invokeSuper(o, objects); &#125;else &#123; return methodProxy.invokeSuper(o, objects); &#125; &#125;&#125;); 这个片段的意思是，如果你调用子类对象的 run() 方法，会先被这里的 MethodInterceptor 拦截一下，如果判断了一下，如果你调用的 Method 是 run 方法，那么就先对汽车做一下安全检查。安全检查做完之后，再通过 “methodProxy.invokeSuper(o, objects)” 调用父类 Car 的 run() 方法，去启动汽车，这行代码就会执行到 Car 类的 run() 方法。 到此为止，我们就已经通过 CGLIB 的 Enhancer 生成了一个 Car 类的子类了，而且定义好了对这个子类调用继承自父类的 run() 方法的时候，先干点别的，再调用父类的 run() 方法。 这样子，就跟下面手写的一个 Car 子类是类似的 12345678static class SafeCar extends Car &#123; @Override public void run() &#123; System.out.println("汽车启动，开始行使。。。。。。"); super.run(); &#125;&#125; 限制 Metaspace 大小看内存溢出效果接着我们可以设置一下这个程序的 JVM 参数，限制它的 Metaspace 区域小一点。例如我们用 -XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m。接着我们可以在上述代码中做一下修改。大家看到上面的代码时有一个 while 循环的，所以它会不停地创建 Car 类的子类，我们在里面可以加一个计数器，就是看看当前创建了多少个 Car 的子类，如下： 1234long counter = 0;while(true) &#123; System.out.println("目前创建了" + (++counter) + "个 Car 类的子类了");&#125; 接着用上述 JVM参数来运行这个程序即可，如图： 模拟 JVM 栈内存溢出Metaspace 区域我们一般会设置为 512MB 左右的大小，这个大小只要你代码里没有自己胡乱生成类，一般都是够你存放一个系统运行时需要的类的。堆内存的大小，一般分配在机器内存的一半就差不多了，毕竟还要考虑其他对内存的使用。 最后一个内存区域就是栈内存区域。在一个基本的线上机器配置，比如 4 核 8G 的线上机器，其中 512M 给了 Metaspace，4G 给了堆内存（其中包括了年轻代和老年代），剩余只有 3G 左右的内存了，要考虑到操作系统自己也会用掉一些内存。那么剩余你就认为有一两个 GB 的内存可以留给栈内存好了。 通常来讲，我们会设置每个线程的栈内存为 1MB，假设你一个 JVM 进程内包括它自带的后台线程，你依赖的第三方组件的后台线程，加上你的核心工作线程（比如你部署在 Tomcat 中，那就是 Tomcat 的工作线程），还有你自己可能额外创建的一些线程，可能要你一个 JVM 中有 1000 个线程。那么 1000 个线程就需要 1GB 的栈内存空间，每个线程有 1MB 的空间。 所以 Metaspace 区域 + 堆内存 + 几百个线程的栈内存，就是 JVM 一共对机器上的内存资源的一个消耗，所以你也能理解这么一个道理：你要是给每个线程的栈内存分配过大的空间，那么会导致机器上能创建的线程数量变少，要是给每个线程的栈内存相对较小，能创建的线程就会比较多一些。当然，现在都建议给栈内存 1MB 就可以了。 示范栈内存溢出先看一段代码： 12345678910111213public class Demo2 &#123; public static long counter = 0; public static void main(String[] args) &#123; work(); &#125; public static void work() &#123; System.out.println("目前是第 " + (++counter) + " 次调用方法"); work(); &#125;&#125; 上面的代码就是 work() 方法调用自己，进入一个无限制的递归调用，陷入死循环，也就是在 main 线程的栈中，会不停地压入 work() 方法调用的栈帧，知道 1MB 的内存空间耗尽。 另外需要设置这个程序的 JVM 参数：-XX:ThreadStackSize=1m。通过这个参数设置 JVM 的栈内存为 1MB。接着运行代码，就会看到如下： 12目前是第 6203 次调用方法Exception in thread "main" java.lang.StackOverflowError 也就是说，当这个线程调用了 6203 次方法之后，它的栈里压入了 6203 个栈帧，最终把 1MB 的栈内存给塞满了，引发了栈内存的溢出。 模拟 JVM 堆内存溢出之前已经讲过堆内存溢出的原理，现在用代码给大家演示一下： 123456789101112public class Demo3 &#123; public static void main(String[] args) &#123; Long counter = 0L; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new Object()); System.out.println("当前创建了第" + (++counter) + "个对象"); &#125; &#125;&#125; 代码很简单，就是在一个 while 循环里不停地创建对象，而且对象全部都是放在 List 里面被引用的，也就是不能回收的。 如果你不停地创建对象，Eden 区满了，它们全部存活的话就会转移到老年代，反复几次之后老年代满了，然后 Eden 区再次满了，ygc 后存活对象再次进入老年代，此时老年代先 full gc，但是回收不了任何对象，因此 ygc 后的存活对象就一定是无法进入老年代的。 所以我们用 -Xms10m -Xmx10m 限制了堆内存大小总共就只有 10m，这样可以尽快触发堆内存的溢出。我们可以在控制台打印的信息看到如下： 12当前创建了第360145个对象Exception in thread "main" java.lang.OutOfMemoryError: Java heap space 从这里看出，在 10M 的堆内存中，用最简单的 Object 对象搞到老年代被塞满大概需要 36 万个对象，然后堆内存实战放不下任何对象，此时就会 OutOfMemory 了，而且告诉你是 Java heap space，也就是堆空间发生了内存溢出。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OOM 内存溢出]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F28%2FOOM-%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[系统 OOM作为 Java 程序员而言，先不考虑自己系统外部依赖的缓存、消息队列、数据库等服务挂掉。就我们本身系统而言，最常见挂掉的原因是什么？就是系统 OOM，也就是所谓的内存溢出。那什么是内存溢出？简单说就是你的 JVM 内存就这么点，结果你拼命往里面塞东西，结果内存塞不下了，就直接溢出了。 那有哪些情况会导致系统发生 OOM 内存溢出？我们从 JVM 的核心原理出发，给大家讲讲哪些地方可能会发生内存溢出。 运行一个 Java 系统首先我们要明白一个事情，就是我们平时启动一个 Java 系统，本质上就是启动一个 JVM 进程。我们用最基本的情况来演示一下，比如下面的代码： 1234567public class HelloWorld &#123; public static void main(String[] args) &#123; String message = "Hello World"; System.out.println(message); &#125;&#125; 当我们在 Eclipse 或者 Intelij IDEA 中写好这个代码，然后通过 IDE 来运行这个代码时，会发生哪些事情？ 首先，我们写好的代码都是后缀为 “.java” 的源代码，这个代码时不能运行的。所以第一步就是将这份 “.java” 源代码文件编译成一个 “.class” 字节码文件，这个字节码才是可以运行的。 对于这种编译好的字节码文件，比如 HelloWorld.class，如果里面包含了 main 方法。接下来我们就可以用 “java 命令” 来执行这个字节码文件了。实际上一旦你执行 “java 命令”，相当于就会启动一个 JVM 进程，这个 JVM 进程就会负责执行你写好的那些代码。 所以要知道一点，运行一个 Java 系统，本质上就是启动一个 JVM 进程，这个 JVM 进程负责来执行你写好的一大堆代码。只要你的 Java 系统中包含一个 main 方法，JVM 进程就会从你指定的这个 main 方法入手，开始执行你写的代码。 JVM 加载你写的类接下来，JVM 进程怎么执行你写的那些代码？Java 是一个面向对象的语言，所以最基本的代码组成单元就是一个一个的类，平时我们写的 Java 代码，不就是写一个一个的类吗？然后再类里我们会定义各种变量、方法、数据结构，通过 if else 之类的语法，写出各种各样的系统业务逻辑，这就是所谓的编程了。 所以 JVM 要执行你的代码，首先要把你写好的代码加载到内存里来。在 JVM 的内存区域里，有一块内存区域叫做永久代，当然 JDK 1.8 以后都叫做 Metaspace 了，这块内存就是用来存放你系统里的各种类的信息，包括 JDK 自身内置的一些类的信息，都在这块区域里。 JVM 有类加载器和一套类加载的机制，包括 加载、验证、准备、解析、初始化、使用、卸载这几个阶段，详细内容可以查看这篇文章，这里不再赘述。他会负责把我们写好的类从编译好的 “.class” 字节码文件里加载到内存里来。如图： 既然有这么一块 Metaspace 区域是用来存放类信息的，那就有可能在这个 Metaspace 区域里发生 OOM。 Java 虚拟机栈：让线程执行各种方法一般情况下，我们写好的那些 Java 代码虽然是一个一个的类，但是核心的代码逻辑一般是封装在类里面的各种方法中的。比如 JVM 已经加装了我们写好的 HelloWorld 类到内存里，接着要怎么执行它里面的代码呢？ Java 语言中的一个通用规则，就是一个 JVM 进程总是从 main 方法开始执行的，所以我们既然在 HelloWorld 中写了一个 mian() 方法，那么就得执行这个方法中的代码了。 那谁去执行 main() 方法的代码？其实我们所有的方法执行，都依赖于 JVM 进程中的某个线程去执行，你可以理解为线程才是执行我们写的代码的核心主体。JVM 进程启动之后默认就会有一个 main 线程，这个 main 线程就是专门负责执行 main() 方法的。 还有一个问题，在 main() 方法中定义了一个局部变量 message，一般情况下，这些方法里的局部可能会有很多，那么这些局部变量放在哪里呢？其实，每个线程都有一个自己的虚拟机栈，就是所谓的栈内存。然后这个线程只要执行一个方法，就会为方法创建一个栈帧，将栈帧放入自己的虚拟机栈里，然后这个栈帧放入方法中定义的各种局部变量。如图： 我们可以通过一个 JVM 参数来设置每个线程中的虚拟机栈的内存大小，一般是设置为 1 MB。那么既然每个线程的虚拟机栈的内存大小是固定的，那么第二块可能发生 OOM 的区域，就是每个线程的虚拟机栈内存。 堆内存：存放我们创建的各种对象最后，在我们写好的代码里，特别在一些方法中，可能会频繁地创建各种各样的对象，这些对象都是放在堆内存里的。如图： 而且，通常我们在 JVM 中分配给堆内存的空间其实是固定的。既然如此，我们还不停在堆内存里创建对象，那堆内存也是有可能会发生内存溢出。 Metaspace 区域因类太多而发生内存溢出在启用一个 JVM 时可以设置很多参数，其中一些参数是专门用来设置 Metaspace 区域的内存大小的。就是 -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m 这两个。所以实际上来说，在一个 JVM 中，Metaspace 区域的大小是固定的，比如 512MB。 那么一旦 JVM 不停地加载类，加载了很多的类，然后 Metaspace 区域放满了，就会触发 Full GC。Full GC 会回收老年代和年轻代，当然也会尝试着回收 Metaspace 区域中的类。 那什么样的类才可以被回收呢？这个条件是相当苛刻的，包括不限于以下一些：比如这个类的类加载器先要被回收，比如这个类的所有对象实例都要被回收等等。所以一旦你的 Metaspace 区域满了，未必能回收掉里面很多的类。 那么一旦回收不了多少类，此时 JVM 还在拼命地加载类放到 Metaspace 里去，一旦塞满 Metaspace 区域，就会引发内存溢出的问题，因为此时 Metaspace 区域的内存空间不够了。 什么情况会发生 Metaspace 内存溢出一般情况，Metaspace 这块区域一般很少发生内存溢出，如果发送内存溢出一般都是因为这两个原因： 第一种原因，很多工程师不懂 JVM 的运行原理，在上线时对 Metaspace 区域直接用默认的参数，即根本不设置其大小。这会导致默认的 Metaspace 区域可能才几十 MB 而已，此时对于稍微大型一点的系统，因为它自己有很多类，还依赖了很多外部的 jar 包的类，几十 MB 的Metaspace 很容易就不够了。 第二种原因，很多人写系统的时候会用 cglib 之类的技术动态生成一些类，一旦代码没有控制好，导致你生成的类过于多的时候，就很容易把 Metaspace 给塞满，进而引发内存溢出。 对于第一种问题，只要在系统上线的时候设置好对应的 Metaspace 大小就可以了。推荐 512MB 第二种情况，稍微我们会用模拟代码给大家演示那种不停的生成大量的类的情况。 无限制地调用方法让线程的栈内存溢出我们先看下面的代码： 1234567891011public class HelloWorld &#123; public static void main(String[] args) &#123; String message = "Hello World"; System.out.println(message); sayHello("ckin"); &#125; public static void sayHello(String name) &#123; System.out.println("你好，" + name); &#125;&#125; 按照之前说的，JVM 启动之后，HelloWorld 类被加载到了内存里来，然后会通过 main 线程执 main() 方法。此时在 main 线程的虚拟机栈里，就会压入 main() 方法对应的栈帧，里面就会放入 main() 方法中的局部变量。 而且，我们是可以手动设置每个线程的虚拟机栈的内存大小的，一般来说现在默认都是给 1MB。所以 main 线程的虚拟机栈内存大小一般也是固定的。现在看上面的代码，代码中的 main() 方法中又继续调用一个 sayHello() 方法，而且 sayHello() 方法中也有自己的局部变量，所以此时会继续将 sayHello() 方法的栈帧压入到 main 线程的虚拟机栈中去，如图： 接着 sayHello() 方法如果运行完毕之后，就不需要为这个方法在内存中保存它的一些局部变量之类的东西了，此时就会将 sayHello() 方法对应的栈帧从 main 线程的虚拟机栈里出栈，再接着，一旦 main() 方法自己本身也运行完毕，自然会将 main() 方法对应的栈帧也从 main 线程的虚拟机栈里出栈。这个我们就不在图里表示了。 一个重要的概念：每次方法调用的栈帧都是占用内存的在这里要跟大家说一个概念，就是每个线程的虚拟机栈的大小是固定的，比如就 1MB，然后每次这个线程调用一个方法，都会将方法调用的栈帧压入虚拟机栈里，这个栈帧是有方法的局部变量的。 虽然一些变量和其他的一些数据占用不了太大的内存，但是要注意，每次方法调用的栈帧实际上也是会占用内存的。这是非常关键的一点，哪怕一个方法调用的栈帧就占用几百个字节的内存，那也是内存占用。 什么情况会导致 JVM 中的栈内存溢出既然明确了上述前提之后，那到底什么情况下 JVM 中的栈内存会溢出呢？既然一个线程的虚拟机内存大小是有限的，比如 1MB，那么假设你不停地让这个线程去调用各种方法，然后不停地把方法调用的栈帧压入栈中，此时终有一个时刻，大量的栈帧就会消耗完毕这个 1MB 的线程栈内存，最终就会导致出现栈内存溢出的情况。 通常而言，哪怕你的线程的虚拟机栈内存就 128KB，或者 256KB，通常都是足够进行一定深度的方法调用的，但是如果你要是走一个递归方法调用，那就不一定了，例如下面代码： 123public static void sayHello(String name) &#123; sayHello(name);&#125; 一旦出现上述代码，一个线程就会不停地调用同一个方法，即使是同一个方法，每次方法调用也会产生一个栈帧压入栈里，例如对 sayHello() 进行 100 次调用，那么就会有 100 个栈帧压入栈中。所以如果疯狂地运行上述代码，就会不停地将 sayHello() 方法的栈帧压入栈里，最终一定会消耗掉线程的栈内存，引发内存溢出。 所以一般来说，引发栈内存溢出，往往都是代码里写了些 bug 才会导致的，正常情况下发生的比较少。 对象太多导致的堆内存溢出如果要把大量的对象是如何导致堆内存溢出的说清楚，那就要从系统运行，在 Eden 区创建对象开始讲起。之前我们说过，平时系统运行的时候一直不停地创建对象，然后大量的对象会填满 Eden 区，一旦 Eden 区满之后，就会触发一次 Young GC，然后存活对象进入 S 区。 高并发场景下导致 ygc 后存活对象太多当然因为各种各样的情况，一旦出现了高并发场景，导致 ygc 后很多请求还没处理完毕，存活对象太多，可能就在 Survivor 区域放不下了，此时只能进入到老年代里去了，老年代很快会填满。一旦老年代放满了就会触发 Full GC，如图所示： 我们假设 ygc 过后有一批存活对象，Survivor 放不下，此时就等着要进入老年代里，然后老年代也满了，就等着老年代进行 CMS GC，必须回收掉一批对象，才能让年轻代里存活下来的一批对象。但是，如果 Full GC 之后还是存活了很多的对象，如果这时候年轻代还有一批对象等着放进老年代，人家 GC 过后空间还是不足，就只能内存溢出了。 什么时候会发生堆内存的溢出发生堆内存溢出的原因总结下来就是，有限的内存中存放了过多的对象，而且大多数都是存活的，此时即使 GC 过后还是大部分都存活吗，所以要继续放入更多对象已经不可能了，此时只能引发内存溢出问题。 所以一般来说发生内存溢出有两种情况： 系统承载高并发请求，因为请求量过大，导致大量对象都是存活的，所以要继续放入新的对象实在是不行了，此时就会引发 OOM 系统崩溃。 系统有内存泄露问题，就是莫名其妙弄了很多的对象，结果对象都是存活的，没有及时取消对他们的引用，导致触发 GC 还是无法回收，此时只能引发内存溢出。 因此总结起来，一般引发 OOM，一是系统负载过高，二是有内存泄露问题。这个 OOM 问题，一旦你的代码写的不太好，或者设计有缺陷，还是比较容易引发的。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[元数据区导致的频繁 Full GC]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F18%2F%E5%85%83%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%AF%BC%E8%87%B4%E7%9A%84%E9%A2%91%E7%B9%81-Full-GC%2F</url>
    <content type="text"><![CDATA[场景一个新手工程师在网上看了某个 JVM 参数，在测试环境部署系统的时候，设置了一个 JVM 参数。由于测试环境有接触 Zabbix 监控系统，可以让你的系统进去，在上面可以看到每台机器的 CPU、磁盘、内存和网络的一些负载。 那个工程师设置了一个 JVM 参数之后，直接导致线上系统频繁接到 JVM 的 Full GC 的报警。于是就开始排查那个系统了。 查看 GC 日志之前有说过如果在系统启动的时候让他输出 GC 日志，所以一旦发现报警，直接登录到线上机器，然后就可以看到对应的 GC 日志了。 在日志里，看到了一个 Metadata GC Threshold 的字样，类似于如下位置： 1[Full GC (Metadata GC Threshold) xxxxx, xxxxx] 从这里就可以看出，这频繁的 Full GC，实际上是 JDK1.8 以后的 Metadata 元数据区导致的，也就是类似我们之前说的永久代。 这个 Metadata 区域一般是放一些加载到 JVM 里去的类，所以此时就很奇怪了，为什么会因为 Metadata 区域频繁地被塞满，进而触发 Full GC？而且 Full GC 会带动 CMS 回收老年代，还会回收 Metadata 区域本身。如图： 查看 Metaspace 内存占用情况接着我们看一下 Metaspace 区域的内存占用情况，简单点你可以通过 jstat 来观察。如果有监控系统，它会给你展示出来一个 Metaspace 内存区域占用的波动曲线图，类似下面： 看起来 Metaspace 区域的内存呈现一个波动的状态，它总是会先不断增加，达到一个顶点之后，就会把 Metaspace 区域给占满，然后自然就会触发一次 Full GC，Full GC 会带着 Metaspace 区域的垃圾回收，所以接下来 Metaspace 区域的内存占用又变得很小了。 一个综合性的分析思路看到这里，相信大家肯定有一点感觉了。这个明显是系统在运行过程中，不停地有新的类产生被加载到 Metaspace 区域里去，然后不停地把 Metaspace 区域占满，接着触发一次 Full GC 回收掉 Metaspace 区域中的部分类。然后这个过程反复不断地循环，进而造成 Metaspace 区域反复被占满，然后反复导致 Full GC 的发生，如图： 到底是什么类不停地被加载那到底是什么类不停地被加载到 JVM 的 Metaspace 区域里去？这个时候就要在 JVM 启动参数中加入这个参数了：-XX:TraceClassLoading -XX:TraceClassUnloading。 这两个参数，顾名思义，就是追踪类加载和类卸载的情况，它会通过日志打印出来 JVM 中加载了哪些类，卸载了哪些类。加入这两个参数后，我们就可以看到 JVM 日志文件中，输出流一堆日志，里面显示如下的内容： 1[Loaded sun.reflect.GeneratedSerializationConstructorAccessor from _JVM Defined_Class] 明显可以看到，JVM 在运行期间不停地加载了大量的所谓 “GeneratedSerializationConstructorAccessor” 类到了 Metaspace 区域里去。就是因为 JVM 运行期间不停地加载这种奇怪的类，然后不停地把 Metaspace 区域占满，才会引发不停地执行 Full GC。 这是一个非常实用的技巧。频繁 Full GC 不光是老年代触发的，有时候也会因为 Metaspace 区域的类太多而触发。 为什么会频繁加载奇怪的类接着遇到类似这种情况，通过 Google 发现，那个类大概是你使用 Java 中的反射加载的，所谓反射代码类似如下： 12Method method = XXX.class.getDeclareMethod(xx, xx);method.invoke(target, params); 简单来说就是通过 XXX.class 获取到某个类，然后通过 getDeclaredMethod 获取到那个类的方法。这个方法就是一个 Method 对象，接着通过 Method.invoke 可以去调用那个类的某个对象的方法，大概就这个意思。 在执行这种反射的时候，JVM会在你反射调用一定次数之后就动态生成一些类，就是我们之前看到的那种莫名其妙的类。下次你再次执行反射的时候，就是调用这些类的方法，这是 JVM 的一个底层优化。 看到这，是不是有点懵。这个倒无所谓，不影响你进行 JVM 的优化。你只需要记住一个结论：如果你在代码里大量用了类似上面反射的东西，那么 JVM 就是会动态地去生成一些类放入 Metaspace 区域里的。所以上面看到的那些奇怪的类，就是由于不停地执行反射的代码才生成的。如图： JVM 创建的奇怪类有什么玄机那么 JVM 为什么要不停地创建那些奇怪的类然后放入 Metaspace 中去？其实这要从一个点入手来分析一下了，因为上面说的那种 JVM 自己创建的奇怪的类，它们的 Class 对象都是 SoftReference，也就是软引用。 可能有人不知道类的 Class 是什么。简单来说，每个类本身自己也是一个 Class，就是一个 Class 对象，一个 Class 对象就代表了一个类。同时这个 Class 对象代表的类，可以派生出很多实例对象。例如，Class Student，这就是一个类，它本身是由一个 Class 类型的对象表示的。但是如果你走一个 Student student = new Student()，这就是实例化了这个 Student 类的一个对象，这是一个 Student 类型的实例对象。 所以我们这里说的 Class 对象，就是 JVM 在反射过程中动态生成的类的 Class 对象，它们都是 SoftReference 软引用的。所谓的软引用，正常情况下不会回收，但是如果内存比较紧张的时候就会回收这些对象。 那么 SoftReference 对象到底在 GC 的时候要不要回收是通过什么来判断的呢？就是这么一个公式： clock - timestamp &lt;= freespace * SoftRefLRURPolicyMSPerMB 这个意思是，clock - timestamp 代表了一个软引用对象它有多久没被访问过了，freespace 代表了 JVM 中的空闲内存空间，SoftRefLRUPolicyMSPerMB 代表每一 MB 空闲内存空间可以允许 SoftReference 对象存活多久。 举个例子，加入说现在 JVM 创建了一大堆的奇怪的类出来，这些类本身的 Class 对象都是被 SoftReference 软引用的。然后新增 JVM 的内存空间有 3000 MB，SoftRefLRURPolicyMSPerMB 默认值是 1000 毫秒，那么就意味着，此时那些奇怪的 SoftReference 软引用的 Class 对象，可以存活 3000 * 1000 = 3000 秒，就是 50 分钟左右。 当然上面也只是举例子。正常情况下，发生 GC 时，其实 JVM 内部或多或少都有一些空间内存的，所以基本上如果不是快要发生 OOM 内存溢出了，一般软引用也不会被回收了。所以正常情况下，JVM 会随着反射代码的执行，动态地创建一些奇怪的类，它们的 Class 对象都是软引用，正常情况下不会被回收，但是也不应该快速增长才对。 为什么 JVM 创建的奇怪的类会不停地变多那为什么 JVM 创建的那些奇怪的类会不停地变多呢？原因是，文章开头的新手工程师不知道从哪里扒出来了 SoftRefLRUPolicyMSPerMB 这个JVM 启动参数，它直接把这个参数设置为 0 了。他想的是，一旦这个参数设置为 0，任何软引用对象就可以尽快释放掉，不用留存，尽量给内存释放空间出来，这样就可以提高内存利用率了。 实际上一旦这个参数设置为 0 之后，直接导致 clock - timestamp &lt;= freespace * SoftLRUPolicyMSPerMB 这个公式的右半边是 0，就导致所有的软引用对象，比如 JVM 生成的那些奇怪的 Class 对象，刚创建出来就可能被一次 Young GC 给带着立马回收掉了。 比如 JVM 给你弄出 100 个奇怪的类，结果你瞎设置软引用的参数，导致突然一次 GC 就给你回收掉几十个类。接着 JVM 在反射代码执行的过程中，就会继续创建这种奇怪的类，这 JVM 的机制之下，会导致这种奇怪的类越来越多。 也许下一次 GC 又会回收掉一些奇怪的类，但是马上 JVM 还会继续生成这种类，最终导致 Metaspace 区域就被放满了，一旦 Metaspace 区域放满了，就会触发 Full GC，然后回收掉很多类，接着再次重复上述循环。 为什么软引用的类因为错误的参数设置被快速回收之后，就会导致 JVM 不停创建更多的新的类呢？其实大家不用去扣这里的细节，这里有大量的底层 JDK 源码的实现，异常复杂，大家只要记住这个结论就好。 如何解决这个问题虽然底层 JDK 的一些实现细节没分析，但是大致梳理出来了一个思路，大家也清楚问题所在和原因了。解决方案很简单，在有大量反射代码的场景下，主要把 -XX:SoftRefLRUPolicyMSPerMB = 0 这个参数设置大一些即可。千万不要设置为 0，可以设置个 1000,2000，或者 5000 毫秒。 提高这个数值，就是让反射过程中 JVM 自动创建的软引用的一些类的 Class 对象不要被随便回收。当我们优化这个参数之后，就可以看到系统稳定运行了，基本上 Metaspace 区域的内存占用是稳定的，不会来回大幅度波动了。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[企业级 JVM 参数模板]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F16%2F%E4%BC%81%E4%B8%9A%E7%BA%A7-JVM-%E5%8F%82%E6%95%B0%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[在一些微小型创业公司中，虽然有少数几个比较好的架构师，但是架构师往往没那么大精力把控到特别细节的地方。如果一些一线普通工程师对 JVM 那么快没有那么的精通，在开发完一个系统之后，部署生产环境的时候没有对 JVM 进行什么参数设置的时候，可能很多时候就是用一些默认的 JVM 参数。 默认的 JVM 参数绝对是系统负载逐渐增高的时候一个最大的问题。如果你不设置 -Xms、-Xmx 之类的堆内存大小的话，你启动一个系统，可能默认就给你几百 MB 的堆内存大小，新生代和老年代可能都是几百 MB 的样子。 新生代内存过小，会导致 Survivor 区域内存过小，同时 Eden 区域也很小。Eden 区域过小，自然会频繁地触发 Young GC，Survivor 区域过小，自然会导致经常在 Young GC 之后存活对象其实也没多少，但就是 Survivor 区域放不下。此时必然会导致对象经常进入老年代中，因此也必然会导致老年代过一段时间就被放慢，然后就会触发 Full GC。 Full GC 一般在正常情况下，都是以天为单位发生的，比如每天发生一次，或者是几天发生一次 Full GC。要是每小时都发生几次 Full GC，那么就会导致系统每小时都卡顿几次，这个时候肯定是不行的。在大部分工程师都对 JVM 优化不是很精通的情况下，通过推行一个 JVM 参数模板，可以让各个系统短时间内迅速就优化了 JVM 的性能。 企业级的 JVM 参数模板假设在一台 4 核 8 G 的机器上部署项目，那么我们的 JVM 参数可以这么设置： 1-Xms4096M -Xmx4096M -Xmn3072M -Xss1M -XX:PermSize=256M -XX:MaxPermSize=256M -XX:+UseParNewGc -XX:+UseConMarkSweepGC -XX:CMSInitiatingOccupancyFraction=92 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 为什么要这样定制 JVM 参数模板？首先，8G 的机器上给 JVM 堆内存分配 4G 就差不多了。毕竟可能还有其他进程会使用内存，一般别让 JVM 堆内存把机器内存给占满。然后年轻代给到 3G，之所以给到 3G 的内存时间，就是因为让年轻代尽量大一些，进而让每个 Survivor 区域都打到 300MB 左右。 根据当时对公司某个业务系统的分析，假设使用默认的 JVM 参数，可能年轻代就几百 MB 的内存，Survivor 区域就几十 MB 的内存。那么每次垃圾回收过后存活对象可能会有几十 MB，这是因为在垃圾回收的一瞬间可能有部分请求没处理完毕，此时会有几十 MB 对象式存活的，很容易触发动态年龄判定规则，让部分对象进入老年代。 所以在分析过后，给年轻代更大内存空间，让 Survivor 空间更大，这样在 Young GC 的时候，这一瞬间可能有部分请求没处理完毕，有几十 MB 的存活对象，这个时候再几百 MB 的 Survivor 空间中，可以轻松放下，不会进入老年代。 不同的系统运行时的情况略有不同，但是基本上都是在每次 Young GC 过后存活几 MB ~ 几十 MB，所以此时在这个参数下，都可以抗住。 这里有几个参数要简单介绍一下。-XX:CMSInitiatingOccupancyFraction=92 是指 CMS 垃圾回收器，当老年代达到 92% 时，触发 CMS 垃圾回收。而 -XX:+UseCMSCompactAtCollection -XX:+CMSFullGCsBeforeCompaction=0 则表示每次 Full GC 后都整理一下内存碎片。否则如果每次 Full GC 过后，都造成老年代里很多内存碎片，那么必然导致下一次 Full GC 更快到来，因为内存碎片会导致老年代可用内存变少。 如何优化每次 Full GC 的性能这里再介绍一下当时做优化调整的另外两个参数，这两个参数可以帮助优化 Full GC 的性能，把每次 Full GC 的时间进一步降低一些。一个参数是 -XX:+CMSParallelInitalMarkEnable，这个参数会在 CMS 垃圾回收器的 “初始标记” 的阶段开启多线程并发执行。 在初始标记阶段，是会进行 Stop the World 的，会导致系统停顿，所以这个阶段开启多线程并发之后，可以尽可能优化这个阶段的性能，较少 Stop the world 的时间。 另一个参数是 -XX:+CMSScavengeBeforeRemark，这个参数会在 CMS 重新标记之前阶段之前，先尽量执行一次 Young GC。因为 CMS 的重新标记也是会 Stop the World 的，所以如果在重新标记之前，先执行一次 Young GC，就会回收掉一些年轻代里没有引用的对象。 所以如果提前先回收掉一些对象，那么在 CMS 重新标记阶段就可以少扫描一些对象，此时就可以提升 CMS 重新标记阶段的性能，较少它的消耗。 所以在 JVM 参数模板中，同样也加入了这两个参数： 1-Xms4096M -Xmx4096M -Xmn3072M -Xss1M -XX:PermSize=256M -XX:MaxPermSize=256M -XX:+UseParNewGc -XX:+UseConMarkSweepGC -XX:CMSInitiatingOccupancyFraction=92 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 -XX:CMSParallelInitalMarkEnable -XX:+CMSScavengeBeforeRemark]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 和 HTTPS]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F13%2FHTTP-%E5%92%8C-HTTPS%2F</url>
    <content type="text"><![CDATA[HTTPHTTP 1.0互联网初期，一般一个网页几乎没什么图片，当时就是挂一些文字，一个网页里就是一堆文字。那个时候使用的是 HTTP 1.0 版本。HTTP 1.0 要指定 keep-alive 来开启持久连接，默认是短连接，就是浏览器每次请求都要重新建立一次 tcp 连接，完了就释放 tcp 连接。早期的网页都比较简单，没什么东西，就一些文字，当时你打开一个网页，就是现场底层 tcp 三次握手，跟网站建立一个 tcp 连接，然后通过这个 tcp 连接，发送一次 http 请求，网站返回一个 http 响应（网页的 html，里面有一大段文字），浏览器收到 html 渲染成网页，浏览器就走 tcp 四次挥手，跟网站断开连接了。 到了后面，网页发展很迅猛，一个网页包含着大量的 css、js、图片等资源。比如你请求一个网页，这个网页的 html 先过来。过来之后，浏览器再次发起大量的请求去加载 css、js、图片。打开一个网页可能浏览器要对网站服务器发送几十次请求。 而这时候使用 HTTP 1.0 的短连接是不合适的，几十次频繁的建立 tcp 连接以及释放 tcp 资源，是非常慢的。最慢的不是发送请求和获取响应，而是打开和释放连接，这都是很重的过程。 HTTP 1.1http 1.1 默认支持长连接，就是说，浏览器打开一个网页之后，底层的 tcp 连接就保持着，不会立马断开。之后加载 css、js 之类的请求，都会基于这个 tcp 连接来走。http 1.1 还支持 host 头，也就可以支持虚拟主机；而且对断电续传有支持。 浏览器，第一次请求去一个网站的一个页面的时候，就会打开一个 tcp 连接，接着会在一段时间内不关闭。然后接下来这个网页加载 css、js、图片大量的请求全部走同一个 tcp 连接，频繁的发送请求和获取响应，等过了一段时间，这些事情都处理完了，然后才会去释放那一个 tcp 连接。这样可以大幅度提升网页的打开的速度和性能。 HTTP 2.0http 2.0 支持多路复用，基于一个 tcp 连接并行发送多个请求以及接收响应，解决了 http 1.1 对同一个时间同一个域名的请求有限制的问题。而且还支持二进制分帧，将传输数据拆分为更小的帧（数据包），提高了性能，实现低延迟高吞吐。 HTTPShttp 协议都是明文的，是没有加密的，所以其实现在一般大部分应用都是 https 协议的。HTTPS，是以安全为目标的 HTTPS 通道，简单讲是 HTTP 的安全版。之前是基于 SSL 协议对 http 进行加密，后来又升级到了 TSL 协议来加密。现在我们来看一下HTTPS 的原理。 HTTPS 故事讲解为了更好的了解 HTTPS 的原理，我们用一个故事来讲解。 序言来自中国的张大胖和位于美国的 Bill 进行通信。 总有一种被偷看的感觉由于张大胖和 Bill 都是使用 HTTP 进行通信，HTTP 是明文的，所以他们的聊天都是可被窥视的。于是，二人想要改变现状，所以 HTTP 首先要解决的问题就是要保证传输的内容只有两个人能看懂。 方法一：使用对称秘钥 两人商量了一下，可以使用对称秘钥进行加密。（对称秘钥就是加密和解密使用的是同一个秘钥）但是问题又来了，既然网络是不安全的，那么最开始的时候怎么将这个对称秘钥发送出去呢？如果对称秘钥在发送的时候就已经被拦截了，那么发送的消息还是会被篡改和窥视。 所以这种对称秘钥的弊端就是，可能被中间人拦截，这样中间人就可以获取到秘钥，就可以对传输的信息进行窥视和篡改。 方式二：使用非对称秘钥 RSA（非对称加密算法）：双方必须协商一对秘钥，一个私钥一个公钥。用私钥加密的数据，只有对应的公钥才能解密；用公钥加密的数据，只有对应的私钥才能解密。 有了这两个漂亮的特性，当张大胖给 Bill 发消息的时候，就可以先用 Bill 的公钥加密（反正 Bill 的公钥是公开的，地球人都知道），等到消息被 Bill 收到后，他就可以用自己的私钥去解密了（只有 Bill 才能解开，私钥是保密的） 返过来也是如此，当 Bill 想给张大胖发送消息的时候，就用张大胖的公钥加密，张大胖收到后，就用紫的私钥解密。这样一来，通信安全就固若金汤了。 但是这样有个弊端：RSA 算法很慢。为了解决这个问题，我们使用非对称 + 对称秘钥结合的方式。 方法三：非对称秘钥 + 对称秘钥使用对称秘钥的好处时速度比较快，使用非对称的好处是可以使得传输的内容不能被破解，因为就算你拦截到了数据，但是没有 Bill 的私钥，也是不能破解内容的。就好像你抢了一个保险柜，但是没有保险柜的钥匙也不能打开保险柜。 所以我们要结合两者的优点，使用 RSA 的算法将加密算法的秘钥发送过去，之后就可以使用这个秘钥，利用对称秘钥来通信了。 中间人攻击还有一个问题就是在使用非对称秘钥的时候，首先要将 Bill 的公钥给张大胖，那么在这个过程中，安全是没有保证的，中间人可以拦截到 Bill 的公钥，就可以对拦截到的公钥进行篡改。就相当于我有手机号，虽然是公开的，谁都可以给我打电话，但是你一开始并不知道我的手机号，我需要将我的手机号发给你。在我发给你手机号的时候，被中间人拦截了，然后将我正确的手机号改成了错误的手机号，但你并不知道这是错误的手机号。如果你一打电话，那就尴尬了。 确认身份—数据证书所以以上的步骤都是可行的，只需要最后一点就可以了，要确定 Bill 给张大胖的公钥确实是 Bill 的公钥，而不是别人，那怎么确认 Bill 给张大胖的公钥确实是 Bill 的呢？ 这个时候就需要公证处的存在 了。也就是说我需要先将我的电话号码到公证处去公证一下，然后我将电话号码传给你，你再将你收到的电话号码和公证处的对比下，就知道是不是我的了。 对应到计算机世界，那就是数字签名。 简单来讲是这样的，Bill 可以把他的公钥和个人信息用一个 Hash 算法生成一个消息摘要，这个 Hash 算法有个极好的特性，主要输入数据有一点点变化，那生成的消息摘要就会有巨变，这样可以防止别人修改原始内容。 这个时候黑客虽然没办法该公钥，但是可以把整个原始信息都替换了，生成一个新的消息摘要，从而来混淆我们。这个时候，我们就需要有公信力的认证中心（简称 CA）用它的私钥对消息摘要加密，形成签名： 这还不算，还要把原始信息和数据签名合并，形成一个全新的东西，叫做 “数字证书“ 当 Bill 把他的证书发给张大胖的时候，就用同样的 Hash 算法，再次生产消息摘要，然后用 CA 的公钥对数字签名解密，的到 CA 创建的消息摘要，两者一比，就知道有没有人篡改了。 这样子已经算是相当安全了。但是，CA 的这个公钥要怎么拿到？难道不怕攻击者在传输 CA 公钥的时候发起攻击吗？如果攻击者成功的伪装成了 CA，这一套体系就彻底玩完了。 所以折腾了半天，又回到了公钥安全传输的问题。不过要解决鸡生蛋，蛋生鸡的问题，就必须得打破这个怪圈。我必须得信任 CA，并且通过安全的方式获取他们的公钥。 注：这些 CA 本身也有证书来证明自己的身份，并且 CA 的信用是像树一样分级的，高层的 CA 给底层的 CA 做信用背书，而操作系统 / 浏览器会内置一些顶层的 CA 证书，相当于你自动信任了他们。这些顶层的 CA 证书一定得安全地放入操作系统 / 浏览器当中。 HTTPS 工作原理HTTPS 的工作原理大概是这样的： 浏览器请求服务端的时候，把自己支持的加密规则发送给网站 服务端从这套加密规则里选出来一套加密算法和 hash 算法，然后把自己的身份信息用数字证书的方式发回给浏览器。证书里有服务端地址、加密公钥、证书颁发结构等。 浏览器验证数字证书的合法性，接着浏览器会生成一个随机密码（就是公钥），然后用证书里的公钥进行加密，这块走的是非对称加密。用约定好的 hash 算法生成握手消息的 hash 值，然后用随机生成的公钥对消息进行加密，然后再把所有的东西都发送给服务端。 服务端从消息里面取出来浏览器用服务端公钥加密后的随机密码，然后后自己的私钥解密取出来密码。然后后密码解密浏览器发来的握手消息，计算握手消息的 hash 值，并验证与浏览器发送过来的 hash 值是否一致，最后用这个随机密码加密一段握手信息，发给浏览器 浏览器解密握手消息，然后计算消息的 hash 值。如果跟网站发来的 hash 一样，握手就结束，之后所有的数据都会由之前浏览器生成的随机密码，用对称加密的方法来进行加密。 参考资料码农翻身公众号]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 的三次握手和四次挥手]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F11%2FTCP-%E7%9A%84%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[TCP 三次握手客户端与服务端通过传输层的 tcp 协议建立网络连接的时候，其实走的是三次握手的过程。建立三次握手的时候，TCP 报头用到了 ACK、SYN 这几个标志。 第一次握手，客户端发送连接请求报文，此时 SYN = 1、ACK = 0，这就是说这是个连接请求，seq = x，接着客户端处于 SYN_SEND 状态，等待服务器响应。 第二次握手，服务端收到 SYN = 1 的请求报文，需要返回一个确认报文，ack = x + 1、SYN = 1、ACK = 1、seq = y，发送给客户端，自己处于 SYN_RECV 的状态。 第三次握手，客户端收到了报文，将 ack = y + 1、ACK = 1、seq = x + 1 发送给服务端。 这三次握手，说白了，就是来回来去三次请求，每次请求带上一堆 TCP 报文，根据报文是否正确来建立连接。 为什么是 3 次握手而不是 2 次 或者 4 次3 次握手，是为了确认客户端和服务端都能正常的发送和接受信息所需的最少次数。 我们用 SEND 和 ACCEPT 来标志发送信息和接收信息的能力。 第一次握手，客户端并不知道自己是否能正常发送信息，有可能网络不通或者其他原因导致信息丢失。此时它 C_SEND = 0、C_ACCEPT = 0。当服务端接收到数据的时候，那么可以肯定的是服务端能正常接收信息，此时 S_ACCEPT = 1，而S_SEND = 0 第二次握手，服务端发送信息给客户端，同样服务端不知道自己能否正常发送信息，数据能否正确抵达客户端，所以它的 S_SEND = 0。而当客户端收到服务端的响应后，说明自己能正常接收信息，C_ACCEPT = 1，而服务端能返回响应给我，说明第一次的消息发送是正常的，那么也表示客户端发送信息的能力没问题，C_SEND = 1 第三次握手，服务端收到信息，说明第二次握手的时候发送的信息能正常到达客户端，说明服务端的发送信息的能力也没问题。S_SEND = 1 至此，就能确认客户端和服务端都能正常的发送和接收信息。 假设两次握手就 OK 了。如果客户端第一次握手过去，结果卡在了某个地方，没到服务端。超过一定时间，客户端再次重新发送了第一次握手过去，服务端收到了，服务端在发送一个响应正常到达客户端，OK 了，连接建立了。 然后尴尬的事情发生了，之前卡在某个地方的旧的第一次握手终于到达了服务端，然后服务端就直接返回了第二次握手，这个时候服务器开辟了资源准备接收客户端发送数据，但是客户端不会理睬这个第二次握手，因为之前都通信过了。这样就会浪费服务端的资源。 但是如果是三次握手，那个二次握手发回去，客户端发现不对，就会发送个复位的报文过去，让服务端撤销开辟的资源。 至于为什么不是 4 次握手，因为 3 次握手就够了，就不需要 4 次或者 5 次浪费资源了。 TCP 断开连接的 4 次挥手第一次挥手，客户端发送报文，FIN = 1、seq = u，此时进入 FIN-WAIT-1 状态 第二次挥手，服务端收到报文，此时进入 CLOSE_WAIT 状态，返回一个报文，ACK = 1、ack = u + 1、seq = v。客户端收到这个报文之后，直接进入 FIN-WAIT-2 状态，此时客户端到服务端的连接就释放了。 第三次挥手，服务端发送连接释放报文，FIN = 1、ack = u + 1、seq = w，服务端进入 LAST_ACK 状态。 第四次挥手，客户端收到连接释放报文之后，发应答报文，ACK = 1、ack = w + 1、seq = u + 1，进入 TIME_WAIT 状态，等待一会儿客户端进入 CLOSED 状态，服务端收到报文之后就进入 CLOSED 状态。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器请求一个网址时，都干了什么]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F11%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E8%AF%B7%E6%B1%82%E4%B8%80%E4%B8%AA%E7%BD%91%E5%9D%80%E6%97%B6%EF%BC%8C%E9%83%BD%E5%B9%B2%E4%BA%86%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[首先我们假设，我们给电脑设置了几个东西： ip 地址：192.168.31.37 子网掩码：255.255.255.0 网关地址：192.468.32.1 DNS 地址：8.8.8.8 这时我们打开一个浏览器，请求 www.baidu.com 地址时，这个时候找 DNS 服务器，DNS 服务器解析域名之后，返回一个 ip 地址，比如 172.194.26.108 接着会判断两个 ip 地址是不是一个子网的，用子网掩码 255.255.255.0，对两个 ip 地址做与运算，拿到 192.168.31.1 和 172.194.26.0，明显不是一个子网的。如图： 那就得发送一个数据包给网关，其实你就认为是我们的路由器吧，就是 192.168.31.1，而且我们是可以拿到网关 ip 地址的 mac 地址的。现在我们从应用层出发，通过浏览器访问一个网站，是走应用层的 http 协议的，并且要把浏览器发出的请求打包成数据包。要把哪些东西放到数据包中去呢？ http 协议分为几个部分：请求方法 + URL 地址 + http 版本 比如： GET http://172.194.26.108/test HTTP/1.1 类似这种请求头，类似下面这种请求体 Host:upload,jiangsu.io Proxy-Connection:keep-alive User-Agent:Mozilla/5.0 等等。。。 比如常见的可以放一个 json，这就构成了一个 http 请求报文。浏览器请求一个地址，先按照应用层的 http 协议，封装一个应用层数据包，数据包里就存放了 http 请求报文，这个时候会将这个 http 请求报文打包成一个数据包，仅仅只是数据包的数据部分，此时数据包是没有头的。上面根据 http 协议弄一个 http 请求报文，然后弄一个数据包出来，就是网络模型中的应用层干的事情。 接着就跑传输层来了。这个层是 TCP 协议，这个 tcp 协议会让你设置一个端口，接收方的端口一般是默认的 80 端口。这个时候，会把应用层数据包给封装到 tcp 数据包中去，而且会加一个 tcp 头，这个 tcp 数据包是对应一个 tcp 头的，这个 tcp 头里就存放了端口号信息。如图： 接着跑到网络层来了，走 ip 协议。这个时候会把 tcp 头和 tcp 数据包，放到 ip 数据包里去，然后再搞一个 ip 头，ip 头里有本机和目标机器的 ip 地址。 这里本机地址是 192.168.31.37 目标机器地址是 172.194.26.108 因为，通过 ip 协议，可以判断说，两个 ip 地址不是在一个子网内的，所以此时只能将数据包先通过以太网协议广播到网关上去，通过网关再给它发送出去。如图： 接着是数据链路层，这块走以太网协议，这里是把 ip 头和 ip 数据包封到以太网数据包里去，然后再加一个以太网数据包里的头，头里放了本机网卡 mac 地址和网关的 mac 地址。但是以太网数据包的限制是 1500 个字节，而此时假设这个 ip 数据包都 5000 个字节了，那么久需要将 ip 数据包切割一下。 这个时候一个以太网数据包要切割为 4 个数据包，每个数据包包含了以太网头、ip 头和切割后的 ip 数据包。4 个数据包的大小分别是 1500, 1500, 1500, 500 个字节。ip 头里包含了每个数据包的序号。如图： 这 4 个以太网数据包都会通过交换机发送到你的网关上，然后你的路由器是可以联通别的子网的，这个时候你的路由器就会转发到别的子网的可能也是某个路由器里去，然后依次类推，N 多个路由器或者你叫网关也行，N 多个网关转发之后，就会跑到百度的某台服务器，接收到 4 个以太网的数据包。 百度服务器接收到 4 个以太网数据包以后，根据 ip 头的序号，把 4 个以太网数据包里的 ip 数据包给拼起来，就还原成一个完整的 ip 数据包了。接着就从 ip 数据包里面拿出来 tcp 数据包，再从 tcp 数据包里取出 http 数据包，读取出来 http 数据包里的各种协议内容，接着就是做一些处理，然后再把相应结果封装成 http 相应报文，封装在 http 数据包里，再一样的过程，封装 tcp 数据包，封装 ip 数据包，封装以太网数据包，接着通过网关给发回去。如图： 参考资料https://mp.weixin.qq.com/s/rqa_YoBkkavJ12GAXZHTYA]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP 四层网络模型和 OSI 七层网络模型]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F09%2FTCP-IP-%E5%9B%9B%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%92%8C-OSI-%E4%B8%83%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[其实，四层模型和七层模型，是可以一块儿讲的。首先先思考一个问题，为什么要有协议？ 如果各个电脑厂商，像 IBM，苹果和联想，都弄自己的协议，结果就是苹果电脑和苹果电脑可以通信，但和其它厂商的电脑就可能无法通信，因为各自的协议不一样。所以就弄了一个国际通行的协议，大家都按照这个来，所有电脑就可以通信了。 此时就要搞一个标准的网络模型出来，大家都按照这个来走，都遵守统一的规范。这就是所谓的 OSI 七层模型。它们分别是：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。在这个基础上，又简化出了 TCP/IP 四层模型：数据链路层、网络层、传输层、应用层。 从底向上的网络分层物理层如果电脑要联网，怎么联？可以在电脑上插根网线，或者联个 WIFI，就可以上网。往大了说就还有中国和美国之间的海底光缆。所以物理层指的就是这个，就是怎么把各个电脑联结起来，形成一个网络，这就是物理层的含义。物理层复制传输 0 和 1 的电路信号，因为计算机最底层都是用 0 1 来表示数据的。 数据链路层物理层将各个电脑连接起来了，还传输最底层的 0 和 1 电路信号。但这样还不行。你得定义清楚哪些 0 和 1 分为一组，这些信号啥意思，这样才能进行通信、所以数据链路层就是做这种事，定义一下电路信号怎么分组。例如： 00000011（从电脑 1 出发，要到电脑 2 去） 00101（从电脑 1 出发，要到电脑 3 去） 以前，每个公司都定义自己的电路信号分组方式，但是后来出来了以太网协议。以太网，一组电路信号就是一个数据包，叫一个帧（frame），每个帧分为两个部分，标头（head）和数据（data），标头包含一些说明性的东西，比如发送者、接受者和数据类型之类的。 每台电脑要往另一台电脑发送数据，一堆 0/1 信号，封装成数据包，包含头和数据，头里包含了从哪儿来到哪儿去，必须从一台电脑的一个网卡，发送到另外一个电脑的一个网卡，所以以太网的数据包必须指定目标电脑的 mac 地址。 以太网规定了，每个网卡必须包含一个 mac 地址，mac 地址就是这个网卡的唯一标识。接入网络里的所有设备，都得有个网卡。以太网协议里的那个数据包，在数据链路层传输的数据包，必须从一个电脑的网卡传输到另外一个电脑的网卡，而这个网卡的地址就叫 mac 地址。 每个网卡出厂的时候，就有一个唯一的 mac 地址，48 位的二进制，但是一般使用 12 个 16 进制数字表示，前 6 个 16 进制是厂商编号，后 6 个 16 进制是网卡的流水号。在 Windows 系统中，可以通过命令 ipconfig /all 查看物理地址，就是 mac 地址。 所以在以太网里传输数据包的时候，必须指定接受者的 mac 地址才能传输数据。但是以太网的数据包怎么从一个 mac 地址发送到另一个 mac 地址？这个不是精准推送的。以太网里面，如果一个电脑发个数据包出去，会广播给局域网内的所有电脑设备的网卡，然后每台电脑都从数据包里获取接收者的 mac 地址，跟自己的 mac 地址对比一下，如果一样，就说明这是给自己的数据包。 但是上面这种广播的方式。仅仅针对一个子网（局域网）内的电脑才会广播，否则一个电脑不能广播数据包给全世界所有的其他电脑吧，仅仅只是广播给一个子网里面的电脑。 网络层上面说到，子网内的电脑，通过以太网发个数据包，对局域网内的电脑，是广播出去的。那么怎么知道哪些电脑在一个子网内呢？这就得靠网络层了，这里有一套 IP 地址，IP 地址就可以让我们区分哪些电脑是一个子网的。 网络层里有个 IP 协议，IP协议定义的地址就叫做 IP 地址。IP地址有 IPv4 和 IPv6 两个版本，目前广泛使用的是 IPv4，是 32 个二进制数字组成的，但是一般用 4 个十进制数字表示，范围从 0.0.0.0 到 255.255.255.255 之间。 每台计算机，都会分配一个 ip 地址，ip 地址的前 24 位（就是前面 3 个十进制数字），代表了网络，后 8 位（最后 1 个十进制数字），代表了主机。如果几台电脑是一个子网的，那么前面的 3 个十进制数字一定是一样的。举个例子，像平时我们在自己 Windows 上开几个 Linux 虚拟机，你会发现，Win 上的 ip 地址可能是 192.168.0.103，然后几个虚拟机的 ip 地址是 192.168.0.182，192.168.0.125 类似这样的。 这个 Win 机器和几个虚拟机，前面 3 个十进制数字都是 192.168.0，就代表大家是一个子网内的，最后一个数字是这个子网的不同主机的编号。但是实际上这就是举个例子，单单从 ip 地址是看不出哪些机器是一个子网的，因为从 10 进制是判断不出来的，需要通过 ip 地址的二进制来判断，结合一个概念来判断，叫做：子网掩码。 比如说 ip 地址是 192.168.56.1，子网掩码是 255.255.255.0。知道子网掩码之后，如果要判断两个 ip 地址是不是一个子网的，就分别把两个 ip 地址和自己的子网掩码进行二进制的与运算，与运算之后，比较一下代表网络的那部分。 例如 192.168.53.1 和 192.168.32.7，判断是不是一个子网的，拿子网掩码 255.255.255.0，跟两个 ip 地址的二进制做与运算，通过二进制来比较网络部分的地址是不是一模一样的。 11000000.10101000.00111000.00000001 11111111.11111111.11111111.00000000 有了网络层的 ip 地址之后，两台在子网内的电脑终于可以通过广播 + mac 地址判断来传输数据包进行通信 了。但是如果发现要接收数据包的计算机不在子网内，那么就不能通过广播来发送数据包，需要通过路由来发送数据包。 看到路由，就想到了路由器。说到路由器，相信大家会比较熟悉，基本家里上网都会弄个路由器。路由器负责将多个子网进行连接，因为你在自己家里，其实你就只是你自己的一个子网，你要是访问网站啥的，是跟那个网站机器所在的子网进行通信。 每个电脑都可以有多个网卡，不是只有一个网卡。一般笔记本都会有以太网网卡和 WiFi 网卡，发送数据包的时候决定走哪个网卡。路由器，其实就是配置了多个网卡的一个专用设备，可以通过不同的网卡接入不同的网络。 网关其实就是路由器的一种，运作在网络层，这个概念不多解释，大家看可以把路由器上的 ip 地址认为是网关。路由器上每个网卡都有 mac 地址和对应的 ip 地址，路由器虽然有 mac 地址，但是不能通过 mac 地址寻址，必须通过 ip 地址寻址，所以路由器其实是工作在网络层的设置。 网络交换机，也是一种设备，是工作在数据链路层的，路由器是工作在网络层的。网络交换机是通过 mac 地址来寻址和传输数据包的；但是路由器是通过 ip 地址寻址和传输数据包的。网络交换机用在局域网的通信，一般你架设一个局域网，里面的电脑通信是通过数据链路层发送数据包，通过 mac 地址来广播的，广播的时候就是通过网络交换机这个设备来把数据广播到局域网内的其他机器上去的。而路由器一般用来让你连入英特网。 LAN，就是 local area network，就是局域网；WAN，就是 wide area network，就是广域网。WLAN 是 wireless local area network，就是无限局域网，也就是 WiFi，在局域网内，可以直接通过 WiFi 无线联网。家里的路由器就是包含了交换机和路由的两个功能，如果是连接到局域网内的设备就把线插到 LAN 那儿，如果是连接到因特网，就把线插在 WAN 上。 举个例子，就是两个局域网之间，如果是通过一个路由器进行通信的话，要怎么进行。大概过程就是，路由器配置了两块网卡，每个网卡可以连到一个局域网内。局域网 1 内的电脑，要发送数据包到局域网 2 内的电脑，在数据包上写上自己的 ip 地址和对方的 ip 地址。但是它们不在一个局域网内，于是局域网 1 内的电脑，先通过交换机将数据包发送到路由器，这个过程需要将路由器的一块网卡的 ip 地址对应的 mac 地址写到数据包的头部，然后才能通过交换机广播出去，路由器接收到之后比较自己一块网卡的 mac 地址，就知道是来找自己的。 接着路由器收到数据包之后，就会在局域网 2 内，将目标机器的 ip 地址对应的 mac 地址写入头部，接着再次通过交换机发送广播通知，发送给局域网 2 的电脑。 一个局域网内的每台机器都有自己的 ARP cache，这个 ARP 就是用来在一个局域网内让各个设备都知道每个设备的 ip 地址和 mac 地址的对应关系的，一般就是某个机器发送广播通知自己的 ip 地址和 mac 地址的对应关系，然后每个机器给他一个回应。以此类推，大家都互相这样广播一把，ip 地址和 mac 地址的对应关系，大家就都知道了。 总结来说就是，一个子网内的机器之间通信，就是在数据包里写上对方的 mac 地址，然后交换机广播出去就 OK 了；但是如果是跨子网的通信，就是写上对方的 ip 地址，然后先通过 mac 地址广播到路由器，让路由器再根据另外一个子网的 ip 地址转换为 mac 地址，通过另外一个子网的交换机广播过去。 传输层上面我们大概明白了通过网络层的 ip地址怎么划分出一个一个的子网，然后在子网内部怎么通过 mac 地址广播通信；跨子网的时候，怎么通过 ip 地址 -&gt; mac 地址 -&gt; 交换机 -&gt; 路由器 -&gt; ip 地址 -&gt; mac 地址 -&gt; 交换机的形式来通过路由器进行通信。 但是还有一个问题，就是一台机器上，是很多程序用一个网卡进行网络通信的，比如说浏览器、QQ、视频直播等等，这些软件都用了一个网卡往外面发送数据，然后从网卡接收数据。 所以还需要一个端口号的概念，就是你得发送数据包到某个机器的一个网卡的某个端口号上去，然后那个机器上监听那个端口的程序，就可以提取发送到这个端口的数据，知道是自己的数据。端口号是 0 ~ 65536 的范围内，其中 0 ~ 1023 被系统占用，别的应用程序就用 1024 以上的端口号。 电脑 1，是在端口号 48632 监听的，通过网卡发送了一条数据 -&gt; 电脑 2 的 ip 地址的 20386 这个端口 -&gt; 电脑 2 的上面的某个 QQ，监听着 20386 的端口 -&gt; 电脑 2 的网卡接收到一条数据之后，发现人家找的是 20386 这个端口，就去找谁在监听 203836，发现 QQ 在监听，我就把这个网卡过来的数据，传递给 QQ，通过端口知道，哪条数据是给你的。 所以大家会发现，网络层，是基于 ip 协议，进行主机和主机间的寻址和通信的，然后传输层，是建立某个主机的某个端口，到另外一个主机的某个端口的连接和通信的。这个通信，就是通过 socket 来实现的，通过 socket 就可以基于 tcp/ip 协议完成上面说的一系列的比如基于 ip 寻址 和 mac 地址转换和寻址，通过路由通信之类的，而且会建立一个端口到另外一个端口的连接。 UDP 和 TCP 都是传输层的协议，作用就是在数据包里加入端口号，可以通过端口号进行点对点的通信了。UDP 是不可靠的，发出去人家收到没有就不知道了；TCP 协议是可靠的，要求三次握手，而且要求人家接收到数据必须回复你。 传输层的 TCP 协议，仅仅只是规定了一套基于端口的点对点的通信协议，包括如何建立连接，如果发送和读取消息，但是实际上如果你要基于 TCP 协议来开发，一般使用 socket，java socket，netty开进行网络编程。 应用层通过传输层的 TCP 协议可以传输数据，但是人家收到数据之后，怎么来解释？比如收到个邮件你要怎么处理，收到个网页呢。所以针对不同的应用，邮件、网页之类的，都是定义不同的应用层协议的。这个应用层，我们就假设综合了会话层、表示层和应用层了。比如最常见的，应用层的协议就是 HTTP 协议。 电脑 1 走 TCP 协议发送了一段东西过来，发送到电脑 2 的 20386 端口： 1234GET http://localhost:8080/ http/1.1key:value1key:value 电脑 2 走 TCP 协议读取到了属于自己这个 20386 端口的一段数据，并发送了一段相应 1234200key:valuekey:value 又是通过底层的 TCP 发了出去，电脑 1 的 30987 端口，ip 电脑 1，网卡，走以太网协议收到一个数据包 1234200key:valuekey:value 总结我们看一下自己的网络设置，一般包含了 ip 地址、子网掩码、网关地址、DNS 地址。前面 3 个我们都知道什么意思了。ip 地址和子网掩码用来划分子网的，判断哪些 ip 地址在一个子网内，同时你的 ip 地址和 mac 地址关联起来，唯一定位了你的网关。网关地址，你就认为是路由器上的那个网卡的 ip 地址吧。路由器的网卡也有 mac 地址，mac 地址对应一个 ip 地址。 DNS地址是啥呢？Domain Name System。因为我们一般定位是通过ip地址+mac地址+端口号来定位一个通信目标的，但是如果在浏览器上输入一个www.baidu.com，咋整？这个时候是先把www.baidu.com发给DNS服务器，然后DNS服务器告诉你www.baidu.com对应的ip地址的 参考资料 网络模型]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 之 jstat 案例分析 - Full GC]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F31%2FJVM-%E4%B9%8B-jstat-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-Full-GC%2F</url>
    <content type="text"><![CDATA[案例分析日处理上亿数据的计算系统假设有这么一个数据计算系统，日处理数据量在上亿的规模。简单来说，这个系统就是会不停地从 MySQL 数据库以及其他数据源里大量地加载数据到自己的 JVM 内存里来进行计算，一般情况下的生产负载是每分钟大概需要执行 500 次数据提取和计算的任务。 但这是一套分布式运行的系统，所以生产环境部署了多台机器，每台机器大概每分钟负责执行 100 次数据提取和计算的任务，每次会提取大概 1 万条左右的数据到内存里来计算，平均每次计算大概需要耗费 10 秒左右的时间。然后每台机器是 4 核 8G 的配置，JVM 内存给了 4G，其中新生代和老年代分别是 1.5G 的内存空间。如图： 这个系统何时塞满新生代既然这个系统每台机器上部署的实例，每分钟会执行 100 次数据计算任务，每次是 1 万条数据计算需要计算 10 秒的时间，那么每次 1 万条数据大概会占用多大的内存空间呢？ 假设平均每条数据在 1KB 左右的大小，那么每次计算任务的 1 万条数据就对应了 10MB 的大小。如果新生代是按照 8 : 1 : 1 的比例来分配 Eden 和两块 Survivor 的区域，那么大体上来说，Eden 区就是 1.2GB，每块 Survivor 区域在 100MB 左右。如图： 按照上面的内存大小，基本执行一个计算任务，就会在 Eden 区里分配 10MB 左右的对象，一分钟大概对应 100 次计算，基本上一分钟过后，Eden 区里就全是对象，基本就全满了。 触发 Minor GC 的时候会有多少对象进入老年代此时假设新声代的 Eden 区在 1 分钟后都塞满对象了，然后接着继续执行计算任务的时候，势必会导致需要进行 Minor GC 回收一部分的垃圾对象。 之前说过执行 Minor GC 之前会先进行检查。那么首先第一步，先看看老年代的可用内存空间是否大于新生代。此时老年代是空的，大概有 1.5G 的可用内存空间，新生代的 Eden 区大概算他有 1.2G 的对象好了，此时会发现老年代的可用内存空间有 1.5GB，新生代的对象总共有 1.2GB，即使一次 Minor GC 过后，全部对象都存活，老年代也能放得下，那么此时就直接执行 Minor GC 了。 之前说过每个计算任务 1 万条数据需要计算 10 秒钟，所以假设此时的 80 个计算任务都执行结束了，但是还有 20 个计算任务共计 200MB 的数据还在计算中，那么此时就是 200MB 的对象是存活的，不能被垃圾回收掉，然后有 1GB 的对象是可以垃圾回收的。 但是因为剩余的存活对象 200MB 大于 Survivor 区的 100MB 的空间。此时就会通过空间担保机制，让这 200MB 直接进入老年代去，占用里面 200MB 内存空间，然后 Eden就清空了。 系统运行多久，老年代大概会填满按照上述计算，每分钟都是一个轮回，大概算下来是每分钟都会把新生代的 Eden 区填满，然后触发一次 Minor GC，然后大概会有 200MB 左右的数据进入老年代。假设现在 2 分钟运行过去了，此时老年代已经有 400MB 内存被占用，只有 1.1GB 的内存可用，此时如果第 3 分钟运行完毕，又要进行 Minor GC 会做什么检查呢？ 此时会先检查老年代可用空间是否大于新生代全部对象，此时老年代可用空间 1.1GB，新生代对象有 1.2GB，那么此时假设一次 Minor GC 过后新生代对象全部存活，老年代是放不下的，那么此时就得看另一个参数是否打开了。 如果 -XX:-HandlePromotionFailure 参数被打开了，此时会进入第二步检查，就是看看老年代可用空间是否大于历次 Minor GC 过后进入老年代的对象的平均大小。我们己经计算过了，每次大概 200MB 对象进入老年代。 那么此时老年代是 1.1GB 空间，是大于每次 Minor GC 后平均 200MB 对象进入老年代的大小的，所以基本可以推测，本次 Minor GC 后大概率还是有 200MB 对象进入老年代，1.1G 可用空间是足够的。所以此时就会放心执行一次 Minor GC，然后又是 200MB 对象进入老年代。 转折点大概在运行了 7 分钟后，7 次 Minor GC 执行过后，大概 1.4G 对象进入老年代，老年代空间就不到 100MB了，几乎快满了。 这个系统运行多久会触发一次 Full GC大概在第 8 分钟运行结束的时候，新生代又满了，执行 Minor GC 之前进行检查，此时发现老年代只有 100MB 内存空间了，比之前每次 Minor GC 后进入老年代的 200MB 要小，此时就会触发一次 Full GC。Full GC 会把老年代的垃圾对象都回收了，假设此时老年代被占据的 1.4G 空间里，全部都是可以回收的对象，那么此时一次性就会把这些对象都给回收了。 然后接着就会执行 Minor GC，此时 Eden 区情况，200MB 对象再次进入老年代，之前的 Full GC 就是为这些新生代本次 Minor GC 要进入老年代的对象准备的。如图： 按照这个运行模型，基本上平均就是七八分钟一次 Full GC，这个频率就相当高了，因为每次 Full GC 速度都是很慢的，性能很差。 该案例如何进行 JVM 优化这个系统，其实要优化也是很简单的，因为这个系统是数据计算系统，每次 Minor GC 的时候，必然会有一批数据没计算完毕，但是按照现有的内存模型，最大的问题，就是每次 Survivor 区域放不下存活对象。 所以可以这么优化，增加新生代的内存比例，3GB 左右的堆内存，其中 2GB 分配给新生代，1GB 留给老年代。这样 Survivor 区大概就是 200MB，每次刚好能放得下 Minor GC 过后存活的对象。 只要每次 Minor GC 过后 200MB 存活对象可以放 Survivor 区域，那么等下一次 Minor GC 的时候，这个 Survivor 区的对象对应的计算任务早就结束了，都是可以回收的了。例如此时 Eden 区里的 1.6GB 空间被占满了，然后 Survivor1 区里有 200MB 上一轮 Minor GC 后存活的对象吗，如图： 此时执行 Minor GC，就会把 Eden 区里 1.4GB 对象回收掉，Survivor1 区里的 200MB 对象也会回收掉，然后 Eden 区里剩余的 200MB 存活对象会放入 Survivor2 区里，如图： 以此类推，基本上就很少对象会进入老年代中，老年代里的对象也不会太多。通过分析和优化，我们成功把系统的老年代 Full GC 的频率从几分钟一次降低到了几个小时一次，大幅度提升了系统的性能，避免了频繁 Full GC 对系统运行的影响。 代码示例运行程序用的示例 JVM 参数使用下面的 JVM 参数运行程序： 1-XX:NewSize=104857600 -XX:MaxNewSize=104857600 -XX:InitialHeapSize=209715200 -XX:MaxHeapSize=209715200 -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=20971520 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimesStamps -Xloggc:gc.log 上面的参数需要注意的是 -XX:PretenureSizeThreshold，把大对象阈值修改为了 20MB，避免我们程序里分配的大对象直接进入老年代。 示例程序12345678910111213141516171819202122232425public class Demo1 &#123; public static void main(String[] args) throws Exception &#123; Thread.sleep(30000); while(true) &#123; loadData(); &#125; &#125; private static void loadData() throws Exception &#123; byte[] data = null; for(int i = 0; i &lt; 4; i++) &#123; data = new byte[10 * 1024 * 1024]; &#125; data = null; byte[] data1 = new byte[10 * 1204 * 1024]; byte[] data2 = new byte[10 * 1024 * 1024]; byte[] data3 = new byte[10 * 1024 * 1024]; data3 = new byte[10 * 1024 * 1024]; Thread.sleep(1000); &#125;&#125; j简单解释上面的程序，大概意思就是，每秒钟都会执行一次 loadData() 方法，它会分配 4 个 10MB 的数组，但是都立马成了垃圾。但是会有 data1 和 data2 两个 10MB 的数组时被变量引用必须存活的，此时 Eden 区已经占用了六七十 MB 空间了，接着是 data3 变量依次指向了两个 10MB 的数组，这是为了在 1s 内触发 Young GC 的。 基于 jstat 分析程序运行的状态接着我们基于 jstat 分析程序运行的状态，启动程序后立马采用 jstat 监控其运行状态可以看到如下的信息： 我们一点一点来分析这个 JVM 的运行状态。首先先看如下这一行截图： 在这里的最后一行，可以看到，程序运行起来之后，在一秒内就发生一次 Young GC，因为按照我们上述的代码，它一定会在一秒内触发一次 Young GC 的。 Young GC 过后，我们发现 S1U，也就是一个 Survivor 区中有 587KB 的存活对象，这应该就是那些未知对象了。然后我们明显看到在 OU 中多出来了 30MB 左右的对象，因此可以确定，在这次 Young GC 的时候，有 30MB 的对象存活了，此时因为 Survivor 区域放不下，所以直接进入老年代了。 接着看下面的图： 看红圈的部分，很明显每秒会发生一次 Young GC，都是导致 20MB ~ 30MB 左右的对象进入老年代。因为每次 Young GC 都会存活下来这么多对象，但是 Survivor 区域是放不下的，所以会直接进入老年代。此时看到老年代的对象占用从 30KB 一路到 60MB 左右，此时突然在 60MB 之后下一秒，明显发生了一次 Full GC，对老年代进行了垃圾回收，因为此时老年代重新变成了 30MB 了。 为什么会这样？因为老年代总共就 100MB 左右，已经占用了 60MB 了，此时如果发生一次 Young GC，有 30MB 存活对象要进入老年代的话。此时会进行 Full GC，回收掉之前那 60MB，然后再放进去新的 30MB 对象。 所以按照我们的这段代码，几乎是每秒新增 80MB 左右，触发每秒 1 次 Young GC，每次 Young GC 后存活下来 20MB ~ 30MB 的对象，老年代每秒新增 20MB ~ 30MB 的对象，触发老年代几乎三秒一次 Full GC，是不是跟我们上面的案例分析的场景很类似？Young GC 太频繁了，而且每次 GC 后存活对象太多，频繁进入老年代，频繁触发 Full GC。 继续看下图： 大家看上图，发现 28 次 Young GC，结果耗费了 180 毫秒，平均下来一次 Young GC 要 6 毫秒左右。但是 14 次 Full GC 才耗费 34 毫秒，平均下来一次 Full GC 才耗费两三毫秒。这是为什么？道理是这样，按照上述程序，每次 Full GC 都是由 Young GC 触发的，因为 Young GC 过后存活对象太多要放入老年代，老年代内存不够触发 Full GC，所以必须等 Full GC 执行完毕了，Young GC 才能把存活对象放入老年代才算结束。这就导致 Young GC 也是速度非常慢。 对 JVM 性能进行优化我们只需要调大年轻代的内存空间，增加 Survivor 的内存即可。看如下参数： 1-XX:NewSize=209715200 -XX:MaxNewSize=209715200 -XX:InitialHeapSize=314572800 -XX:MaxHeapSize=314572800 -XX:SurvivorRatio=2 -XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=20971520 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log 我们把堆大小调整为 300MB，年轻代给了 200MB，同时 -XX:SurvivorRatio=2 表明，Eden : Survivor 的比例为 2 : 1 : 1，所以 Eden 区是 100MB，每个 Survivor 区是 50MB，老年代是 100MB。 接着我们用这个 JVM 参数运行程序，用 jstat 来监控其运行状态如下： 在上图可以看到，每秒的 Young GC 过后，都会有 20MB 左右的存活对象进入 Survivor，但是每个 Survivor 区都是 50MB 的大小，因此可以轻松容纳，而且一般不会超过 50% 的动态年龄判定的阈值。 我们可以清楚地看到每秒触发 Young GC 过后，几乎就没有对象会进入老年代，最终 600KB 的对象进入了老年代里。在看下面的截图： 我们可以看到，只有 Young GC，没有 Full GC，而且 11 次 Young GC 才不过 9 毫秒，平均一次 GC 1 毫秒都不到，没有 Full GC 干扰之后，Young GC 的性能极高。 所以这个案例的优化就成功了，同样的程序，仅仅是调整了内存分配比例，立马就大幅度提升了 JVM 的性能，几乎把 Full GC 消灭了。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 杂记]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F27%2FSpring-%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Bean 的生命周期Spring Bean 的生命周期，大致上可以分为创建、使用、销毁三个阶段。具体由可以分为以下几个阶段： 实例化 Bean对于 BeanFactory 容器，当客户向容器请求一个尚未初始化的 bean 时，或初始化 bean 的时候需要注入另一个尚未初始化的依赖时，容器就会调用 createBean 进行实例化。对于 ApplicationContext 容器，当容器启动结束后，通过获取 BeanDefinition 对象中的信息，实例化所有的 bean。 容器在内部实现的时候，采用“策略模式”来决定采用何种方式初始化 bean 实例。通过，可以通过反射或者 CGLIB 动态字节码生成来初始化相应的 bean 实例或者动态生成其子类。 设置对象属性（依赖注入）实例化后的对象被封装在 BeanWrapper 对象中，紧接着，Spring 根据 BeanDefinition 中的信息以及通过 BeanWrapper 提供的设置属性的接口完成依赖注入。 说人话就是 spring 容器需要去看看这个 bean 依赖了谁，把你依赖的 bean 也创建出来，给你进行一个注入。比如说通过构造函数，setter 注入等等。如下代码： 123456789101112public class MyService &#123; private MyDao myDao; public MyService(MyDao myDao) &#123; this.myDao = myDao; &#125; public void setMyDao(MyDao myDao) &#123; this.myDao = myDao; &#125;&#125; 处理 Aware 接口接着，Spring 会检测该对象是否实现了 xxxAware 接口，并将相关的 xxxAware 实例注入给 Bean： 如果这个 Bean 已经实现了 BeanNameAware 接口，Spring 容器会调用这个 bean 实现的 setBeanName(String beanId) 方法，此处传递的就是 Spring 配置文件中 Bean 的 id 值。 如果这个 Bean 已经实现了 BeanFactoryAware 接口，Spring 容器会调用这个bean 实现的 setBeanFactory() 方法，传递的是 Spring 工厂自身。 如果这个 Bean 已经实现了 ApplicationContextAware 接口，Spring 容器会调用我们 bean 的 setApplicationContext(ApplicationContext ctx) 方法，传入 Spring 上下文，把 Spring 容器传递给这个 bean。 BeanPostProcessor如果我们想在 bean 实例构建好之后，此时想在这个时间点，如果想对这个 Bean 进行一些自定义的处理，那么可以让 Bean 实现 BeanPostProcessor 接口，那将会调用 postProcessBeforeInitialization(Object obj, String s)方法。 InitializingBean 与 init-method如果 Bean 在 Spring 配置文件中配置了 init-method 属性，则会自动调用其配置的初始化方法。 BeanPostProcessor如果这个 Bean 实现了 BeanPostProcessor 接口，将会调用 postProcessAfterInitialization(Object obj, String s)方法。这个方法是在 Bean 初始化结束时调用，所以可以被应用于内存或缓存技术。 以上几个步骤完成后，Bean 就已经被正确创建了，之后就可以使用这个 Bean 了。 DisposableBean当 Bean 不再需要时，会经过清理阶段，如果 Bean 实现了 DisposableBean 接口，会调用其实现的 destroy() 方法。 destroy-method最后，如果这个 Bean 的 Spring 配置中配置了 destroy-method 属性，会自动调用其配置的销毁方法。 推断构造方法Spring 在基于某个类生成 Bean 的过程中，需要利用该类的构造方法来实例化得到一个对象，但是如果一个类存在多个构造方法，Spring 会使用哪个呢？ Spring 的判断逻辑如下： 如果一个类只存在一个构造方法，不管该构造方法是无参构造方法，还是有参构造方法，Spring 都会用这个构造方法 如果一个类存在多个构造方法 这些构造方法中，存在一个无参的构造方法，那么 Spring 就会用这个无参的构造方法 这些构造方法中，不存在一个无参的构造方法，那么 Spring 就会报错 Spring 的设计思想是这样的： 如果一个类只有一个构造方法，那么没得选择，只能用这个构造方法 如果一个类存在多个构造方法，Spring 不知道如何选择，就会看是否有无参的构造方法，以为无参构造方法本身表示了一种默认的意义 如果某个构造方法上加了 @Autowired 注解，那就表示程序员告诉 Spring 就用这个加了注解的方法，那 Spring 就会用这个加了 @Autowired 注解构造方法了 如果 Spring 选择了一个有参的构造方法，Spring 在调用这个有参构造方法时，需要传入参数，那这个参数是怎么来的？ Spring 会根据入参的类型和入参的名字去 Spring 中找 Bean 对象（以单例 Bean 为例，Spring 会从单例池那个 Map 去找）： 先根据入参类型去找，如果只知道一个，那就直接用来作为入参 如果根据类型找到多个，则根据入参名字来确定唯一一个 如果最终没有找到，则会报错，无法创建当前 Bean 对象 确定用哪个构造方法，确定入参的 Bean 对象，这个过程就叫做推断构造方法 Spring Web MVC 执行流程 客户端（浏览器）发送请求，直接请求到 DispatcherServlet。（请求 DispatcherServlet） DispatcherServlet 根据请求信息调用 HandlerMapping，解析请求对应的 Handler。（查找 @Controller） 解析到对应的 Handler 后，开始由 HandlerAdapter 适配器处理。（查找 @RequestMapping） HandlerAdapter 会根据 Handler 来调用真正的处理器开始处理请求，并处理相应的业务逻辑。（处理方法） 处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View。（返回处理结果） ViewResolver 会根据逻辑 View 查找实际的 View。（逻辑视图解析为真正的视图） DispatcherServlet 把返回的 Model 传给 View。（DispatcherServlet 视图渲染） 通过View 返回给请求者（浏览器） 将上面的内容应用到实际项目中，大概流程就是这样： Tomcat 的工作线程将请求转交给 Spring MVC 框架的 dispatcherServlet DispatcherServlet 查找 @Controller 注解的 controller。我们一般会给 controller 加上 @RequestMapping 的注解，标注说哪些 controller 用来处理哪些请求，此时根据请求的 URI，去定位到哪个 controller 来进行处理。 根据 @RequestMapping 去查找，使用这个 controller 内的哪个方法来进行请求的处理，对每个方法一般也会加 @RequestMapping 的注解。 直接调用我们 controller 里面的某个方法来进行请求的处理 我们的 controller 的方法会有一个返回值，以前的时候，一般来说还是走 jsp、模板技术，我们会把前端页面放在后端的工程里面，返回一个页面模板的名字，然后 spring MVC 的框架使用模板技术，对 HTML 页面做一个渲染。到了前后端分离，可能前端发送一个请求过来，我们只要返回json数据。 前端负责把 HTML 页面渲染给浏览器就可以了。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初步了解 InnoDB 存储引擎的架构设计]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F26%2F%E5%88%9D%E6%AD%A5%E4%BA%86%E8%A7%A3-InnoDB-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[我们知道，MySQL 最常用的就是 InnoDB 存储引擎，那么我们今天借助一条更新语句的执行，来初步地了解一下 InnoDB 存储引擎的架构设计。 首先假设我们一条 SQL 语句： 1UPDATE users SET name = &apos;xxx&apos; WHERE id = 10 首先我们的系统通过一个数据库连接发送到 MySQL 上，然后经过 SQL 接口、解析器、优化器、执行器几个环节，解析 SQL 语句，生成执行计划，接着由执行器去负责这个计划的执行，调用 InnoDB 存储引擎的接口去执行。所以如下图，大致会走下图的这个流程： 接下来我们看一下这个存储引擎里的架构设计，以及如何基于存储引擎完成一条更新语句的执行。 InnoDB 的重要内存结构：缓冲池InnoDB 存储引擎中有一个非常重要的放在内存里的组件，就是缓冲池（Buffer Pool），这里面会缓冲很多的数据，以便于以后在查询的时候，如果内存缓冲池里有数据，就可以不用去查磁盘了。 引擎执行更新语句的时候，比如对 “id = 10” 这一行数据，它其实会将 “id = 10” 这一行数据看看是否在缓冲池里，如果不在的话，那么会直接从磁盘里加载到缓冲池里来，而且接着会对这行记录加独占锁。因为在我们更新 “id = 10” 的这一行数据的时候，肯定是不允许别人同时更新的，所以必须要对这行记录加独占锁。 undo 日志文件：让你更新的数据可以回滚接着，假设 “id = 10” 这行数据的 name 原来是 “zhangsan”，现在我们要更新为 “xxx”，那么此时我们得先把要更新的原来的值 “zhangsan” 和 “id = 10” 这些信息，写入到 undo 日志文件中去。 如果之前有接触过数据库的话，我们应该知道，如果我们要执行一个更新语句，要是他是在一个事务里的话，那么事务提交之前我们都是可以对数据进行回滚的，也就是把你更新为 “xxx” 的值回滚到之前的 “zhangsan” 去。所以为了考虑到未来可能要回滚数据的需要，这里会把你更新前的值写入 undo 日志文件，如图： 更新 buffer pool 中的缓存数据当我们把要更新的那行记录从磁盘文件加载到缓冲池，同时对它加锁之后，而且还要把更新前的旧值写入 undo 日志文件之后，就可以正式更新这行数据了。更新的时候，先更新缓冲池中的记录，此时这个数据就是脏数据了。这里所谓的更新内存缓冲池里的数据，意思就是把内存里的 “id = 10” 这行数据的 name 字段修改为 “xxx”。 那为什么说此时这行数据是脏数据呢？因为这个时候磁盘上 “id = 10” 这行数据的 name 字段还是 “zhangsan” ，但是内存里这行数据已经被修改了，所以就会叫它是脏数据。如图： Redo Log Buffer：万一系统宕机，如何避免数据丢失接下来，按照上图的说明，现在已经把内存里的数据进行修改，但是磁盘上的数据还没修改。那么此时万一 MySQL 所在的机器宕机了，必然会导致内存里修改过的数据丢失，这怎么解决？这个时候，就必须把对内存所做的修改写入到一个 Redo Log Buffer 里去，这也是内存里的一个缓冲区，是用来存放 redo 日志的。 所谓的 redo 日志，就是记录下来你对数据做了什么修改，比如对 “id = 10” 这行数据修改了 name 字段的值为 “xxx”，这就是一个日志。 这个 redo 日志是用来在 MySQL 突然宕机的时候，用来恢复你更新过的数据的。 如果还没提交事务，MySQL 宕机了怎么办一般情况下，在数据库中，哪怕执行一条 SQL 语句，其实也可以是一个独立的事务，只有当你提交事务之后，SQL 语句才算执行结束。所以到目前为止，其实还没有提交事务，那么此时如果 MySQL 崩溃，必然导致内存里 Buffer Pool 中的修改过的数据丢失，同时你写入 Redo Log Buffer 中的 redo 日志也会丢失。 那么此时数据丢失要紧吗？其实不要紧，因为你一条更新语句，没提交事务，就代表它没执行成功，此时 MySQL 宕机虽然导致内存里的数据都丢失了，但是磁盘上的数据依然还停留在原样子。也就是说，”id = 1” 的那行数据的 name 字段的值还是老的值 “zhangsan”，所以此时你的这个事务就是执行失败了，没能成功完成更新，你会收到一个数据库的异常。然后当 mysql 重启之后，你会发现你的数据没有任何变化。 所以此时如果 MySQL 宕机，不会有任何问题。 提交事务的时候将 redo 日志写入磁盘中接着我们要提交一个事务了，此时就会根据一定的策略把 redo 日志从 redo log buffer 里刷入到磁盘文件里去。此时这个策略是通过 innodb_flush_log_at_trx_commit 来配置的，它又几个选项： 当这个参数的值为0时，你提交事务的时候，不会把 redo log buffer 里的数据刷入磁盘文件，此时可能你都提交事务了，结果 MySQL 宕机了，然后此时内存里的数据全部丢失。相当于你提交事务成功了，但是由于 MySQL 突然宕机了，导致内存中的数据和 redo 日志都丢失了。 当这个参数的值为1时，你提交事务的时候，就必须把 redo log 从内存刷入到磁盘文件里去，只要事务提交成功，那么 redo log 就必然在磁盘里了。 那么只要提交事务成功之后，redo 日志一定在磁盘文件里，此时你肯定会有一条 redo 日志说“我此时对哪个数据做了哪些修改，比如 name 字段 修改为了 xxx 了”。 然后哪怕此时 buffer pool 中更新过的数据还没刷新到磁盘里去，此时内存里的数据是已经更新过的 “name = xxx”，然后磁盘上的数据是还没更新的 “name = zhangsan”。然后此时 MySQL 系统突然崩溃了，此时会丢失数据吗？答案是不会，因为虽然内存里的修改成 name = xxx 的数据会丢失，但是 redo 日志里已经说了，对某某数据做了修改 name=xxx，所以此时 MySQL 重启之后，它可以根据 redo 日志去恢复之前做过的修改。 最后来看看，如果 innodb_flush_log_at_trx_commit 的值是 2，那么提交事务的时候，把redo 日志写入磁盘文件对应的 os cache 缓存里去，而不是直接进入磁盘文件，可能 1 秒后才会把 os cache 里的数据写入到磁盘文件里去。 这种模式下，你提交事务之后，redo log 可能仅仅停留在 os cache 内存缓存里，没实际进入磁盘文件，万一此时你要是机器宕机了，那么 os cache 里的 redo log 就会丢失，同样会让你感觉提交事务了，结果数据丢失了。 扩展：binlog首先，我们要知道 MySQL binlog 是个什么东西？实际上我们之前说的 redo log，它是一种偏向物理性质的重做日志，因为它里面记录的是类似这样的东西：“对哪个数据页中的什么记录，做了个什么修改”。而且 redo log 本身是属于 InnoDB 存储引擎特有的一个东西。而 binlog 叫做归档日志，它里面记录的是偏向于逻辑性的日志，类似于 “对 users 表中的 id= 10 的一行数据做了更新操作，更新以后的值是什么”。 binlog 不是 InnoDB 存储引擎特有的日志文件，是属于 MySQL Server 自己的日志文件。 提交日志的时候，同时写入 binlog在上面我们说到，在我们提交事务的时候，会把 redo log 日志写入磁盘文件中去。然后其实在提交事务的时候，我们同时还会把更新对应的 binlog 日志写入到磁盘文件中去。如图所示： 上图会有一些变化，就是把跟 InnoDB 存储引擎进行交互的组件加了之前说过的执行器。它会负责跟 InnoDB 进行交互，包括从磁盘里加载数据到 Buffer Pool 中进行缓存，包括写入 undo 日志，包括更新 Buffer Pool 里的数据，以及写入 redo log buffer，redo log 刷入磁盘，写binlog 等等。 实际上，执行器是一个非常核心的组件，负责跟存储引擎配合完成一个 SQL 语句在磁盘与内存层面的全部数据更新操作。而且我们在上图可以看到，我把一次更新语句的执行，拆分为了两个阶段，上图中的 1、2、3、4 几个步骤，本质上你执行这个更新语句的时候干的事。而 5、6 阶段，是从你提交事务开始的，属于提交事务的阶段了。 binlog 日志的刷盘策略分析对于 binlog 日志，也有不同的刷盘策略。有一个 sync_binlog 参数可以控制 binlog 的刷盘策略，它的默认值是 0，此时你把 binlog 写入磁盘的时候，其实不是直接写入磁盘文件，而是进入 os cache 内存缓存。所以跟之前分析的一样，如果此时机器宕机，那么你在 os cache 里的 binlog 日志是会丢失的。 如果把 sync_binlog 参数设置为 1 的话，那么此时会强制在提交事务的时候，把 binlog 直接写入到磁盘文件里去，那么这样提交事务之后，哪怕机器宕机了，磁盘上的 binlog 是不会丢失的。 基于 binlog 和 redo log 完成事务的提交当我们把 binlog 写入磁盘文件之后，接着就会完成最终的事务提交，此时会把本次更新对应的 binlog 文件名称和这次更新的 binlog 日志在文件里的位置，都写入到 redo log 日志文件里去，同时在 redo log 日志文件里写入一个 commit 标记。 在完成这个事情之后，才算最终完成率事务的提交，如图所示： redo 日志中写入 commit 标记的意义为什么最后要在 redo 日志中写入 commit 标记？它其实是用来保持 redo log 日志与 binlog 日志一致的。 举个例子，假设我们在提交事务的时候，一共有上图中的 5、6、7 三个步骤，必须是三个步骤都执行完毕，才算是提交了事务。如果我们刚完成步骤 5 的时候，也就是 redo log 刷入磁盘文件的时候，MySQL 宕机了，此时怎么办？ 这个时候因为没有最终 commit 标记在 redo 日志里，所以此次事务可以判定为不成功。不会说 redo 日志文件里有这次更新的日志，但是 binlog 日志文件里没有这次更新的日志，不会出现数据不一致的问题。 如果是完成步骤 6 的时候，也就是 binlog 写入磁盘了，但是 MySQL 宕机了，又如何？还是一样的，因为没有 redo log 中的最终 commit 标记，因此此时事务的提交也是失败的。必须是在 redo log 中写入最终的事务 commit 标记了，然后此时事务提交成功，而且 redo log 里有本次更新对应的日志，binlog 里也有本次更新对应的日志。最终redo log 和 binlog完全是一致的。 后台 IO 线程随机将内存更新后的脏数据刷回磁盘假设现在我们已经提交事务了，此时一次更新 UPDATE users SET name = &#39;xxx&#39; WHERE id = 10 它已经把内存里的 buffer pool 中的缓存数据更新了，同时磁盘里有 redo 日志和 binlog 日志，都记录了我们把指定的 “id = 10” 这行数据修改了 “name = xxx”。 此时会有一个问题，就是这个时候磁盘上的数据文件里的 “id = 10” 这行数据的 name 字段还是等于 zhangsan 这个旧值啊。所以MySQL 有一个后台的 IO 线程，会在之后某个时间里，随机的把内存 buffer pool 中的修改的脏数据给刷回磁盘上的数据文件里如。如下图： 当上图中的 IO 线程把 buffer pool 里的修改后的脏数据刷回磁盘后，磁盘上的数据才会跟内存里一样，都是 name = xxx 这个修改以后的值了。 在 IO 线程把脏数据刷回磁盘之前，哪怕 MySQL 宕机崩溃了也没关系，因为重启之后，会根据 redo 日志恢复我们之前提交事务做过的修改到内存里去，就是 id = 10 的数据的 name 修改为了 xxx，然后等适当时机，IO 线程自然还是会把这个修改后的数据刷到磁盘上的数据文件里去的。 总结通过一次更新数据的流程，可以清楚地看到，InnoDB 存储引擎主要就是包含了一些 buffer pool、redo log buffer 等内存里的缓存数据，同时还包含了一些 undo 日志文件、redo 日志文件等东西，同时 MySQL Server 自己还有 binlog 日志文件。 在你执行更新的时候，每条 SQL 语句，都会对应修改 buffer pool 里的缓存数据、写 undo 日志、写 redo log buffer 几个步骤。 但是当你提交事务的时候，一定会把 redo log 刷入磁盘，binlog 刷入磁盘，完成 redo log 中的事务 commit 标记，最后后台的 IO 线程会随机地把 buffer pool 里的脏数据刷入磁盘里去。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch 介绍]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F22%2FElasticsearch-%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[思维导图 Elasticsearch 简介Elasticsearch 是一个近实时的分布式存储、搜索、分析的引擎。它是专门做搜索的，接下来我们简单说说 Elasticsearch 的相关知识。 Elasticsearch 的数据结构一般来说，要想知道查询的时候大概花多少时间，就需要知道它的底层数据结构是怎么样的。例如： 树形的查找时间复杂度一般是 O(logn) 链表的查找时间复杂度一般是 O(n) 哈希表的查找时间复杂度一般是 O(1) 不同的数据结构所花的时间往往是不一样的，你要查找的时候快，就需要有底层的数据结构支持。而我们要想知道 Elasticsearch 为什么模糊查询速度快，就需要知道它的底层数据结构是什么。 倒排索引Elasticsearch 最强大的就是为每个字段提供了倒排索引，当查询的时候不用担心没有索引可以利用，什么是倒排索引，举个简单例子： 文档id 年龄 性别 1 25 女 2 32 女 3 25 男 每一行是一个文档（document），每个 document 都有一个文档 id，那么给这些文档建立的倒排索引就是： 年龄的索引： 年龄 文档 id 25 [1,3] 32 [2] 性别的索引： 性别 文档 id 女 [1,2] 男 [3] 可以看到，倒排索引是针对每个字段的，每个字段都有自己的倒排索引，25、32 这些叫做 term，[1,3] 这种叫做 posting list。 首先我们得知道为什么 Elasticsearch 为什么可以实现快速的“模糊查询”或者“相关性查询”，实际上是你写入数据到 Elasticsearch 的时候会进行分词。如图： 它会根据文档内容进行分词，上面是分成四个单词，并统计每个单词的个数以及位置。当然这只是一个例子，并不是 Elasticsearch 真正的原理。 我们都知道，世界上有很多语言，那 Elasticsearch 怎么切分这写词呢？其实 Elasticsearch 内置了一些分词器： Standard Analyzer：按词切分，将词小写 Simple Analyzer：按非字母过滤（符号被过滤掉），将词小写 WhitespaceAnalyzer：按照空格切分，不转小写 等等等。。。 Elasticsearch 分词器主要由三部分组成： Character Filter：文本过滤器，取出 HTML Tokenizer：按照规则切分，比如空格 TokenFilter：将切分后的词进行处理，比如转小写 Elasticsearch 内置的分词器都是英文类的，而我们用户搜索的时候往往搜的是中文，现在中文分词器用的最多的就是 IK。 说了那么多，那 Elasticsearch 的数据结构是怎么样的呢？如图： 我们输入一段文字，Elasticsearch 会根据分词器对我们的那段文字进行分词（也就是图上看到的 Ada/Allen/Sara..），这些分词汇总起来我们叫做 Term Dictionary，而我们需要通过分词找到对应的记录，这些文档 ID 保存在 PostingList 在 Term Dictionary 中的词由于是非常非常多的，所以我们会为其进行排序，等要查找的时候就可以通过二分来查，不需要遍历整个 Term Dictionary。由于 Term Dictionary 的词实在太多，不可能把 Term Dictionary 都放在内存中，于是 Elasticsearch 还抽了一层叫做 Term Index，这层只存储部分词的前缀，Term Index 会存在内存中，检索会特别快。 Term DictionaryElasticsearch 为了能快速找到某个 term，将所有的 term 进行了排序，然后二分查找 term，类似于上学时候老师教我们的翻新华字典的方式，所以叫做 Term Dictionary，这种查询方式其实和传统关系型数据库的 B-Tree 的方式很相近，所以这并不是 Elasticsearch 快的原因。 Term Index如果说 Term Dictionary 是直接去二分法翻字典，那么 Term Index 就是字典的目录页，当然这比我们真的去翻字典目录快多了，假设我们的 term 如果全是英文，那么 Term Index 就是 26 个字母表，但是通常 term 未必都是英文，而可以是任意的 byte 数组。因为就算 26 个英文字符也不一定都有对应的 term。例如，a 来头的 term 只有一个，c 开头的 term 有一百万个，x 开头的 term 一个也没有，这样查询到 c 的时候又会很慢了。所以通常情况下 term index 是包含 term 的一些前缀的一棵树，例如这样的一个 Term Index： 这样的情况下通过 term index 就可以根据快速定位到某个 offset（分支的开端），然后以此位置向下查找，再加上 FST（Finite-State-Transducer，Lucene4.0 开始使用该算法来查找 Term 在 Dictionary 中的位置）的压缩技术，将 Term Index 缓存到内存中，通过 Term Index 找到对应的 Term Dictionary 的 block，然后直接 去磁盘直接找到 term，减少磁盘的随机读写次数，大大地提升查询效率。 Posting List 压缩技术 Roaring Bitmap说到 roaring bitmaps 就要先了解 bitset 或者 bitmap。bitset 是一种数据结构，对应 posting list 如果是：[2, 3, 5, 7, 9]，那么对应的 bitset 就是：[0,1,1,0,1,0,1,0,1,0]。用 0 和 1 来表示该位置的数值的有无，这种做法就是一个 byte 可以代表 8 个文档。当大数据量时，仍然会消耗很多内存，所以直接将 bitset 结构存入内存不太理想。 Elasticsearch 不仅压缩了 Term Index，还对 posting list 进行了压缩。posting list 虽然只存储了文档 id，但是文档 id 很大的时候，可以达到 PB 级的数据，所以 Elasticsearch 对 posting List 的压缩做了两件事：排序和大数变小数。如图： 简单解读一下这种压缩技巧： step1：在对 posting list 进行压缩时进行了正序排序。 step2：通过增量将 73 后面的大数变成小数存储增量值。例如 300 - 73 = 227、302 - 300 = 2 step3：转换成二进制，取占最大位的数，227 占 8 位，前三个占八位，30 占五位，后三个数每个占五位。 从第三步可以看出，这种压缩方式仍然不够高效，所以 Lucene 使用的数据结构叫做 Roaring Bitmap，其压缩原理可以理解为：与其保存 100 个 0，占用 100 个 bit，还不如保存 0 一次，然后声明这个 0 有 100 个，它以两个自己可以表示的最大数 65535 为界，将 posting list 分块。比如第一块是 0 - 65535，第二块是 65535 - 131071，如图： 压缩技巧解读： step1：从小到大进行排序 step2：将大数除以 65536，用除得的结果和余数来表示这个大数 step3：以 65535 为界进行分块 Elasticsearch 的术语和架构在讲解 Elasticsearch 的架构之前，首先我们得了解一下 Elasticsearch 的一些常见术语： Index：Elasticsearch 的 Index 相当于数据库的 Table Type：这个在新的 Elasticsearch 版本已经废除（在以前的 Elasticsearch 版本，一个 Index 下支持多个 Type，有点类似消息队列一个 topic 下多个 group 的概念） Document：Document 相当于数据库的一行记录 Field：相当于数据库的 Column 的概念 Mapping：相当于数据库的 Schema 的概念 DSL：相当于数据库的 SQL（给我们读取 Elasticsearch 数据的 API） RDBMS Elasticsearch TABLE Index(Type) Row Document Column Field Schema Mapping SQL DSL 说完 Elasticsearch 的相关术语，我们看一下 Elasticsearch 的架构。一个 Elasticsearch 集群会有多个 Elasticsearch 节点，所谓节点实际上就是运行着 Elasticsearch 进程上的机器。 在众多节点中，会有一个 Master Node，它主要负责维护索引元数据、负责切换主分片和副分片本身等工作，如果主节点挂了，会选举出一个新的主节点。 Elasticsearch 最外层的是 Index（相当于数据库 表的概念），一个 Index 的数据我们可以分发到不同的 Node 上进行存储，这个操作就叫做分片。比如说我集群里有4个节点，我现在有一个 Index，想将这个 Index 在 4 个节点上存储，那我们可以设置 4 个分片，这 4 个分片的数据合起来就是 Index 的数据。 使用分片的原因： 如果一个 Index 的数据量太大，只有一个分片，那只会在一个节点上存储，随着数据量的增长，一个节点未必能把一个 Index 存储下来。 多个分片，在写入或查询的时候就可以进行并行操作，从各个节点中读写数据，提高吞吐量 如果某个节点挂了，那部分数据就丢了吗？为了解决这个问题，Elasticsearch 分片有主分片和副分片之分，为了实现高可用。数据写入的时候写到主分片，副本分片复制主分片的数据，读取的时候主分片和副本分片都可以读。 Index 需要分为多少个分片和副本分片都是可以 通过配置设置的。 如果某个节点挂了，Master Node 就会把对应的副本分片提拔为主分片，这样即便节点挂了，数据就不会丢失了。 Elasticsearch 写入流程上面我们说过当我们向 Elasticsearch 写入数据的时候，是写到主分片上的，我们可以了解更多的细节。 客户端写入一条数据，到 Elasticsearch 集群里边就是由节点来处理这次请求： 集群上的每个节点都是 coordinating node（协调节点），协调节点表明这个节点可以做路由。比如节点 1 收到了请求，但发现这个请求的数据应该是由节点 2 处理（因为主分片在节点 2 上），所以会把请求转发到节点 2 上。coordinate（协调）节点通过 hash 算法可以计算出在哪个主分片上，然后路由到对应的节点。shard = hash(document_id) % (num_of_primary_shards) 路由到对应的节点以及对应的主分片时，会做以下的事： 将数据写到内存缓冲区 然后将数据写到 translog 缓冲区. 每隔 1s 数据从 buffer 中 refresh 到 FileSystemCache 中，生成 segment 文件，一旦生成 segment 文件，就能通过索引查询到了 refresh 完，memory buffer 就清空了 每隔 5s，translog 从 buffer flush 到磁盘中 定期/定量 从 FileSystemCache 中，结合 translog 内容 flush index 到磁盘中 其中： Elasticsearch 会把数据先放入内存缓冲区，然后每隔 1s 刷新到文件系统缓存区（当数据被刷新到文件系统缓冲区以后，数据才可以被检索到）。所以，Elasticsearch 写入的数据需要 1s 才能查询到。 为了防止节点宕机，内存中的数据丢失，Elasticsearch 会另写一份数据到日志文件上。但最开始的还是写入到内存缓冲区，每隔 5s 才会将缓冲区的数据刷到磁盘中。所以，Elasticsearch 某个节点如果挂了，可能会造成 5s 的数据丢失。 等到磁盘上的 translog 文件打到一定程度或者超过了 30 分钟，会触发 commit 操作，将内存中的 segment 文件异步刷到磁盘中，完成持久化操作。 说白了就是，写内存缓冲区（定时去生成 segment，生成 translog），能够让数据被索引、被持久化。最后通过 commit 完成一次的持久化。 等主分片写完了以后，会将数据并行发送到副本节点上，等到所有的节点写入成功就返回 ack 给协调节点，协调节点返回 ack 给客户端，完成一次的写入。 Elasticsearch 更新和删除Elasticsearch 的更新和删除操作流程： 给对应的 doc 记录打上 .del 标识，如果是删除操作就打上 delete 状态，如果是更新操作就把原来的 doc 标志为 delete，然后重新写入一条数据。 前面讲到，每隔 1s 会生成一个 segment 文件，那 segment 文件会越来越多。Elasticsearch 会有一个 merge 任务，会将多个 segment 文件合并成一个 segment 文件。在合并的过程中，会把带有 delete 状态的 doc 给物理删除掉。 Elasticsearch 查询查询我们最简单的方式可以分为两种： 根据 ID 查询 doc 根据 query（搜索词）去查询匹配的 doc 根据 ID 去查询具体的 doc 的流程是： 检索内存的 Translog 文件 检索硬盘的 Translog 文件 检索硬盘的 Segment 文件 根据 query 去匹配 doc 的流程是：同时去查询内存和硬盘的 segment 文件 Elasticsearch 查询又可以分为五种搜索类型： QUERY_AND_FETCH：向索引的所有分片（shard）都发出请求，各分片返回的时候把文档（document）和计算后的排名信息一起返回。这种搜索方式是最快的。因为相比下面的几种搜索方式，这种查询方法只需要去 shard 查询一次。但是各个 shard 返回的结果的数量之和可能是用户要求的 size 的 n 倍。 QUERY_THEN_FETCH：如果你搜索时，没有指定搜索方式，那默认就是使用这种方式。这种搜索方式，大概分为两个步骤。第一步，先向所有的 shard 发出请求，各分片只返回排序和排名相关的信息（注意，不包括文档 document），然后按照各分片返回的分数进行重新排序和排名，取前 size 个文档。然后第二步，去相关的 shard 取 document。这种方式返回的 document 与用户要求的 size 是相等的。 DFS_QUERY_AND_FETCH：这种方式比第一步多了一个初始化散发（initial scatter）步骤。有这一步，可以更精确控制搜索打分和排名。 DFS_QUERY_THEN_FETCH：比第二种多了一个初始化散发步骤。 COUNT：这种一种特殊的搜索类型，只返回匹配查询的文档数目。 初始化散发其实就是在进行真正的查询之前，先把各个分片的词频率和文档频率收集一下，然后进行词搜索的时候，各分片依据全局的词频率和文档频率进行搜索和排名。显然如果使用 DFS_QUERY_THEN_FETCH 这种查询方式，效率是最低的，因为一个搜索，可能要查询 3 次分片，但使用 DFS 方法，搜索精度应该是最高的。 一般我们用得最多的就是 QUERY_THEN_FETCH，第一种查询完就返回这个 doc 内容（QUERY_AND_FETCH）只适合于只需要查一个分片的请求。 QUERY_THEN_FETCH 总体的流程大概是： 客户端请求发送到集群的某个节点上。集群上的每个节点都是 coordinate node（协调节点） 然后协调节点将搜索的请求转达到所有分片上（主分片和副本分片都行） 每个分片将自己搜索出的结果（doc id）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。 接着由协调节点根据 doc id 去各个节点上拉取实际的 document 数据，最终返回给客户端。 Query Phase 时节点做的事： 协调节点向目标分片发送查询的命令（转发请求到主分片或者副本分片上） 数据节点（在每个分片内做过滤，排序等操作），返回 doc id 给协调节点 Fetch Phase 阶段时节点做的事： 协调节点得到数据节点返回的 doc id，对这些 doc id 做聚合，然后将目标数据分片发送抓取命令（希望拿到这个 doc 记录） 数据节点按照协调节点发送的 doc id，拉取实际需要的数据返回给协调节点 主流程其实说白了就是：由于 Elasticsearch 是分布式的，所以需要从各个节点都拉取对应的数据，然后最终统一合成给客户端。只是Elasticsearch 把这些活都干了，我们在使用的时候无感知而已。 参考资料扫盲–Elasticsearch Elasticsearch 原理]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 的架构设计]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F22%2FMySQL-%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[一般情况下，我们的系统采用数据库连接池的方法去并发访问数据库，然后数据库自己也会维护一个连接池，其中管理了各种系统跟这台数据库服务器建立的所有连接。 当我们的系统只要能从连接池获取到一个数据库连接之后，我们就可以执行增删改查的SQL语句了。但大部分人都停留在把 MySQL 当成一个黑盒的阶段，只知道执行相应的 SQL 语句就可以得到相应的结果，如果语句性能差了，就在表里建几个索引，完全当它是个黑盒子，来建表以及执行 SQL 语句。 接下来我们就要深入底层，去探索数据库的工作原理以及生产问题的优化手段。 网络连接必须让线程来处理假设我们的数据库服务器的连接池中的某个连接接收到了网络请求，假设就是一条 SQL 语句，那么由谁负责从这个连接中去监听网络请求？谁负责从网络连接里把请求数据读取出来？大家应该或多或少都知道一点，那就是网络连接必须得分配给一个线程去处理，由一个线程来监听请求以及读取请求数据，比如从网络连接中读取和解析出来一条我们的系统发送过去的 SQL 语句。如图： SQL 接口：负责处理接收到的 SQL 语句当 MySQL 内部的工作线程从一个网络连接中读取出来一个 SQL 语句之后，此时会如何执行这个 SQL 语句呢？为了执行这些 SQL 语句，去完成底层数据的增删改查，MySQL 内部提供了一个组件，就是 SQL 接口（SQL Interface），它是一套执行 SQL 语句的接口，专门用于执行我们发送给 MySQL 的那些增删改查的 SQL 语句。 因此 MySQL 的工作线程接收到 SQL 语句之后，就会转交给 SQL 接口去执行，如图： 查询解析器：让 MySQL 能看懂 SQL 语句当工作线程将 SQL 语句交给 SQL 接口去执行，那么 SQL 接口怎么执行 SQL 语句呢？直接把 SQL 语句交给 MySQL，它能看懂和理解这些 SQL 语句吗？ 例如有这么一个 SQL 语句： 1SELECT id, name, age FROM users WHERE id = 1 这个 SQL 语句，我们用人脑是直接就可以处理一下，只要懂 SQL 语法的人，一看就知道是什么意思。但是 MySQL 自己本身也是一个系统，是一个数据库管理系统，它没直接理解这些 SQL 语句。所以这就需要一个关键的组件：查询解析器 这个查询解析器就是负责对 SQL 语句进行解析的，比如上面的那个 SQL 语句进行一些拆解，拆解成以下几个部分： 我们现在要从 “users” 表里查询数据 查询 “id” 字段的值等于 1 的那行数据 对查出来的那行数据要提取里面的 “id, name, age” 三个字段 所谓的 SQL 解析，就是按照既定的 SQL 语法，对我们按照 SQL 语句规则编写的 SQL 语句进行解析，然后理解这个 SQL 语句要干什么事情，如图所示： 查询优化器：选择最优的查询路径当我们通过解析器理解了 SQL 语句要干什么时候，接着会找查询优化器来选择一个最优的查询路径。 什么叫做最优的查询路径？举个简单的例子，就拿上面的那个 SQL 语句，现在 SQL 要干这么一件事情：我们要从 “users” 表里查询数据，查询 “id” 字段的值等于 1 的那行数据，对查出来的那行数据要提取里面的 “id, name, age” 三个字段。那到底应该怎么来实现呢？ 假设要完成这件事有以下几个查询路径（只是用于大家理解的例子，不代表真实的 MySQL 原理，但是通过这个例子，能让大家理解最优查询路径的意思）： 直接定位到 “users” 表中的 “id” 字段等于 1 的一行数据，然后查出来那行数据的 “id, name, age” 三个字段的值就可以了 先把 “user” 表中的每一行数据的 “id, name, age” 三个字段的值都查出来，然后从这批数据里过滤出来 “id” 字段等于 1 的那行数据的 “id, name, age” 三个字段 上面就是那个 SQL 语句的两种实现路径，我们会发现，要完成这个 SQL 的目标，两个路径都可以做到，但很显然感觉上是第一种查询路径更好。 所以查询优化器大概就是干这个的，它会针对你编写的几十行、几百行复制 SQL 语句生成查询路径树，然后从里面选择一条最优的查询路径处理。相当于会告诉你，你应该按照一个什么样的步骤和顺序，去执行哪些操作，然后一步一步地把 SQL 语句给完成了。 调用存储引擎接口，真正执行 SQL 语句接下来，就是把查询优化器选择的最优查询路径，也就是你到底应该按照一个什么样的顺序和步骤去执行这个 SQL 语句的计划，把这个计划交给底层的存储引擎去真正的执行。这个存储引擎是 MySQL 的架构设计中很有特色的一个环节。 真正在执行 SQL 语句的时候，要不然是更新数据，要不是查询数据，那数据会放在哪里？说到底数据库也不是什么神秘莫测的东西，可以把它理解成一个类似你平时写的图书管理系统，电信计费系统之类的系统。 数据库自己本身就是一个编程语言写出来的系统而已，然后启动之后也是一个进程，执行它里面的各种代码。所以对数据库而言，我们的数据要不是放在内存里，要不就是放在磁盘文件里，没什么特殊的地方。假设我们的数据有的放在内存里，有的放在磁盘文件里，如图： 那么问题来了，我们已经知道一个 SQL 语句要如何执行了，但是我们现在要怎么知道哪些数据在内存里，哪些数据在磁盘里，我们执行的时候是更新内存的数据，还是更新磁盘的数据，我们如果更新磁盘的数据，是先查询哪个磁盘文件，再更新哪个磁盘文件？ 是不是感觉很懵逼。这个时候就需要存储引擎了。存储引擎其实就是执行 SQL 语句的，它会按照一定的步骤去查询内存缓存数据，更新磁盘数据，查询磁盘数据等等诸如一系列的操作。如图： MySQL 的架构设计中，SQL 接口、SQL 解析器、查询优化器其实都是通用的，它就是一套组件而已。但是存储引擎的话，它是支持各种各样的存储引擎的，比如我们常见的 InnoDB、MyISAM、Memory 等等，我们是可以选择使用哪种存储引擎来负责具体的 SQL 语句执行的。当然现在 MySQL 一般都是使用 InnoDB 存储引擎的。 执行器：根据执行计划调用存储引擎的接口看完存储引擎之后，我们回过头来思考一个问题，存储引擎可以帮助我们去访问内存以及磁盘上的数据，那么是谁来调用存储引擎的接口呢？ 其实我们还漏了一个执行器的概念，这个执行器会根据优化器选择的执行方案，去调用存储引擎的接口按照一定的顺序和步骤，把 SQL 语句的逻辑给执行了。 例如，执行器可能会先调用存储引擎的一个接口，去获取 “users” 表中的第一行数据，然后判断一下这个数据的 “id” 字段的值是否等于我们期望的一个值，如果不是的话，那就继续调用存储引擎的接口，去获取 “users” 表的下一行数据。 就是基于上述的思路，执行器就会根据我们的优化器生成的一套执行计划，然后不停地调用存储引擎的各种接口去完成 SQL 语句的执行计划，大致就是不停地更新或提取一些数据出来。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 的事务实现原理和传播机制]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F22%2FSpring-%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%92%8C%E4%BC%A0%E6%92%AD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 事务管理是应用系统开发中必不可少的一部分。Spring 为事务管理提供了丰富的功能支持。Spring 事务管理分为编程式和声明式两种。编程式事务指的是通过编码方式实现事务；声明式事务基于 AOP，将具体的逻辑与事务处理解耦。生命式事务管理使业务代码逻辑不受污染，因此实际使用中声明式事务用的比较多。 声明式事务有两种方式，一种是在配置文件（XML）中做相关的事务规则声明，另一种是基于 @Transactional 注解的方式。本文着重介绍基于 @Transactional 注解的事务管理。 需要明确几点： 默认配置下 Spring 只会回滚运行时、未检查异常（继承自 RuntimeException 的异常）或者 Error。 @Transactional 注解只能应用到 public 方法才有效。 事务的实现原理事务的实现原理。如果说你加了一个 @Transactional 注解，此时 Spring 会使用 AOP 思想，对你的这个方法在执行之前，先去开启一个事务。执行完毕之后，根据你的方法是否报错，来决定回滚还是提交事务。 @Transactional 注解的属性介绍下面分别介绍一下 @Transactional 的几个属性 value 和 transactionManager 属性它们两个是一样的意思。当配置了多个事务管理器时，可以使用该属性指定选择哪个事务管理器。 isolation 属性事务的隔离级别，默认值为 Isolation.DEFAULT。可选的值有 Isolation.DEFAULT：使用底层数据库默认的隔离级别 Isolation.READ_UNCOMMITTED：读取未提交数据（会出现脏读，不可重复读）基本不使用 Isolation.READ_COMMITTED：读取已提交数据（会出现不可重复读和幻读） Isolation.REPEATABLE_READ：可重复读（会出现幻读） Isolation.SERIALIZABLE：串行化 tip： MySQL 默认为 REPEATABLE_READ 级别 SQL_SERVER 默认为 READ_COMMITED 级别 脏读：一个事务读取到另一个事务未提交的更新数据 不可重复读：同一事务中，多次读取同一数据返回的结果有所不同，即，后续读取可以读到另一事务已提交的更新数据 可重复读：在同一事务中多次读取数据时，能够保证所读数据一样，也就是后续读取不能读到另一事务已提交的更新数据 幻读：一个事务读到另一个事务已提交的 insert 数据。 timeout 属性事务的超时时间，默认值为 -1。如果超过该时间限制但事务还没有完成，则自动回滚事务。 readOnly 属性指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true rollbackFor 属性用于指定能够触发事务回滚的异常类型，可以指定多个异常类型 noRollbackFor 属性抛出指定的异常类型，不会滚事务，也可以指定多个异常类型 propagation 属性事务的传播行为，默认值为 Propagation.REQUIRED。可选的值有： PROPAGATION.REQUIRED：如果当前没有事务，则创建一个新事务。如果当前存在事务，就加入该事务。该设置是最常用的设置。 PROPAGATION.SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务。如果当前不存在事务，就以非事务执行。 PROPAGATION.MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。 PROPAGATION.REQUIRE_NEW：创建新事务，无论当前存不存在事务，都创建新事务。 PROPAGATION.NOT_SUPPORTED：以非事务方式执行操作，如果当前事务存在，就把当前事务挂起。 PROPAGATION.NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION.NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按 REQUIRED 属性执行。 @Transactional 的 propagation 属性代码示例比如如下代码，save 方法首先调用 method1 方法，然后抛出了异常，就会导致事务回滚，如下两条数据都不会插入数据库。 1234567891011121314151617@Transactional(propagation = Propagation.REQUIRED)public void save() &#123; method1(); User user = new User("服部半藏"); userMapper.insertSelective(user); if(true) &#123; throw new RuntimeException("save 抛异常了"); &#125;&#125;public void method1() &#123; User user = new User("宫本武藏"); userMapper.insertSelective(user);&#125; 现在有需求如下，就算 save 方法的后面抛异常了，也不能影响 method1 方法的数据插入。一般方法时给 method1 加入一个新的事务，这样 method1 就会在这个新的事务中执行，原来的事务不会影响到新的事务。例如给 method1 加 propagation 属性为 Propagation.REQUIRES_NEW 的事务。 123456789101112131415161718@Transactional(propagation = Propagation.REQUIRED)public void save() &#123; method1(); User user = new User("服部半藏"); userMapper.insertSelective(user); if(true) &#123; throw new RuntimeException("save 抛异常了"); &#125;&#125;@Transactional(propagation = Propagation.REQUIRES_NEW)public void method1() &#123; User user = new User("宫本武藏"); userMapper.insertSelective(user);&#125; 运行之后，发现并没有起作用，数据也是没有插入数据库。通过查看日志发现，两个方法都是处于同一个事务中，method1 方法并没有创建一个新的事务。 通过 Spring 官方文档可以知道：在默认的代理模式下，只有目标方法由外部调用，才能被 Spring 的事务拦截器拦截。在同一个类中的两个方法直接调用，是不会被 Spring 的事务拦截器拦截，就像上面的 save 方法直接调用了同一个类中 method1 方法，method1 方法不会被 Spring 的事务拦截器拦截。可以使用 AspectJ 取代 Spring AOP 代理来解决这个问题。但是这里不展开。 为了解决这个问题，我们可以新建一个类： 123456789101112@Servicepublic class OtherServiceImpl implements OtherService &#123; @Autowired private UserMapper userMapper; @Transactional(propagation = Propagation.REQUIRES_NEW) public void method1() &#123; User user = new User("风魔小太郎"); userMapper.insertSelective(user); &#125;&#125; 然后再 save 方法中调用 otherService.method1 方法 12345678910111213141516@Autowiredprivate OtherService otherService;@Transactional(propagation = Propagation.REQUIRED)@Overridepublic void save() &#123; otherService.method1(); User user = new User("服部半藏"); userMapper.insertSelective(user); if (true) &#123; throw new RuntimeException("save 抛异常了"); &#125;&#125; 这下，otherService.method1 方法的数据插入成功，save 方法的数据未插入，事务回滚。继续查看日志： 从日志可以看出，首先创建了 save 方法的事务，由于 otherService.method1 方法的 @Transactional 的 propagation 属性为 Propagation.REQUIRES_NEW，所以接着暂停了 save 方法的事务，重新创建了 otherService.method1 方法的事务，接着 otherService.method1 方法的事务提交，接着 save 方法的事务回滚，这就印证了只有目标方法由外部调用，才能被 Spring 的事务拦截器拦截。 Spring 事务传播机制总结Spring 事务传播机制总共有 7 种，其中使用最多的应该是 PROPAGATION_REQUIRES、PROPAGATION_REQUIRES_NEW 和 PROPAGATION_NESTED。其中所谓的嵌套事务，是指外层的事务如果回滚，会导致内层的事务也回滚；但是内层的事务如果回滚，仅仅是滚回自己的代码。 比如现在有一段业务代码，方法 A 调用方法 B，我希望的是如果方法 A 出错了，此时仅仅回滚方法 A，不能回滚方法 B，这个时候可以给方法 B 使用 REQUIRES_NEW 传播机制，让他们两的事务是不同的。 如果方法 A 调用方法 B，如果出错，方法 B 只能回滚它自己，方法 A 可以带着方法 B 一起回滚。那这种情况可以给方法 B 加上 NESTED 嵌套事务。 参考资料Spring Boot 中使用 @Transactional 注解配置事务管理]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK 动态代理和 CGLIB 动态代理]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F10%2FJDK-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%92%8C-CGLIB-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[什么是动态代理动态代理即动态的代理模式，所谓动态，是指抽象类（即抽象角色）在编译期是未确定的，在运行期生成。相对的，静态代理中抽象类的行为是在编译期确定的。动态代理是 AOP（面向切面编程）常见的实现方式。 Spring 里使用 AOP，比如说你对一批和它们的方法做了一个切面，定义好了要在这些类的方法里的增强代码，那 Spring 要对那些类生成动态代理，在动态代理中去执行你定义的那些增强代码。 JDK 动态代理动态代理使用示例JDK 动态代理使用起来比较简单，只要我们掌握 Proxy.newProxyInstance 方法即可。Proxy。newProxyInstance 方法在 JDK 中定义如下： 1234567891011121314151617181920212223242526/** * 返回一个受调用处理器 (InvocationHandler) 管理，实现了指定接口的代理类的实例 * * @param loader 声明这个代理类的 ClassLoader * @param interfaces 代理类实现的接口列表 * @param h 处理代理类的调用的调用处理器 * @return 一个受调用处理器 (InvocationHandler) 管理，实现了指定接口的代理类的实例 * @throws IllegalArgumentException 违反了 getProxyClass 函数的参数限制条件 * @throws SecurityException 如果安全管理器存在并且下面的任意条件满足： * (1) 传入的 loader 是 null 且调用者的类加载器非空， * 使用 RuntimePermission("getClassLoader")权限 * 调用 SecurityManager#checkPermission禁止访问 * * (2) 对于每一个代理接口，调用者的类加载器与接口类加载器不同或不是其父类, * 并且调用 SecurityManager#checkPackageAccess 无权访问接口 * * (3) 所有传入的代理接口都是非公共的，且调用者类与非公共接口不在同一个包下， * 使用 ReflectPermission("newProxyInPackage.&#123;package name&#125;") 调用 * SecurityManager#checkPermission 无访问权限 * @throws NullPointerException interfaces 数组参数或其中的元素为 null，以及调用处理器 h 为 null */@CallerSensitivepublic static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException; 从 Javadoc 中我们可以获知，主需要传入相应的类加载器，接口，调用处理器即可产生一个代理实例，那么我们不熟悉的就是 InvocationHandler 类，我们看一下 InvocationHandler 类的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package java.lang.reflect;/*** InvocationHandler是代理实例的调用处理器实现的接口。* 每个代理实例都有一个关联的调用处理器。* 在调用代理实例的方法时，方法调用将被编码并分派给其调用处理程序的 invoke 方法。** @author Peter Jones* @see Proxy* @since 1.3*/public interface InvocationHandler &#123; /** * 在代理实例上处理方法调用并返回结果。当在与其关联的代理实例上调用 * 方法时，将调用处理期上的此方法。 * * @param proxy 该方法被调用的代理实例 * * @param method Method 对象将是代理接口声明的方法，它可能是代理 * 类继承方法的代理接口的超级接口。 * @param args 包含在代理实例的方法调用中传递的参数值的对象数组， * 如果interface方法不带参数，则为null。基本类型的参 * 数被封装在适当的基本封装类的实例中，比如 * java.lang.Integer 或者 java.lang.Boolean。 * @return 调用代理实例上的方法获得的返回值。如果接口方法的声明返 * 回类型是基本类型，则此方法返回的值必须是相应基本包装类 * 的实例;否则，它必须是转换为声明的返回类型的类型。如果 * 此方法返回的值为null，并且接口方法的返回类型为原始类型， * 则代理实例上的方法调用将引发NullPointerException。如果 * 此方法返回的值与上面所述的接口方法的声明返回类型不兼容， * 则将通过代理实例上的方法调用抛出ClassCastException。 * * @throws 抛出调用代理实例的方法时抛出的异常。异常的类型必须可以 * 转化为接口方法的 throws 子句中声明的异常类型，也可以分 * 配给不强制检查的异常类型 java.lang.RuntimeException 或 * java.lang.Error。如果这个方法抛出一个强制检查的异常， * 这个异常不能转化为接口方法的 throws 子句中声明的异常类 * 型，那么将会抛出包含这个异常的 * UndeclaredThrowableException 异常。 * * @see UndeclaredThrowableException */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; 从 Javadoc 中我们知道，通过调用 Proxy.newProxyInstance 方法创建的代理实例中的方法时，会执行传入的 InvocationHandler#invoke 方法，代理实例中方法返回值为 InvocationHandler#invoke 方法返回值。 我们做一个测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 代理接口 */public interface ITest &#123; String test(String val);&#125;/** * 代理实现类 */public class Test implements ITest &#123; @Override public String test(String val) &#123; return val + "我是Test"; &#125;&#125;/** * 调用处理器 */public class TestInvocationHandler implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(method); return args[0] + "我是TestProxy"; &#125;&#125;public class Main &#123; /** * 分别对正常实现的 ITest 实现类和动态代理实现类进行调用 * @param args */ public static void main(String[] args) &#123; ITest test = new Test(); ITest testProxy = (ITest) Proxy.newProxyInstance(test.getClass().getClassLoader(), new Class[] &#123;ITest.class&#125;, new TestInvocationHandler()); System.out.println(test.test("Hello，")); System.out.println("------------"); System.out.println(testProxy.test("Hello，")); &#125;&#125; 输出结果为： 1234Hello，我是Test----------public abstract java.lang.String com.example.demo.Main$ITest.test(java.lang.String)Hello，我是TestProxy 从测试例子中，我们可以看出两个特点： 实现了 ITest 接口的实现类并不需要我们手动写，是自动生成并实例化的。 调用自动生成的 ITest 代理类实例，将调用 InvocationHandler#invoke 方法。 不知各位使用 MyBatis 的时候有没有疑问，为什么可以直接调用接口？答案就在这里，事实上，MyBatis 使用类似的技术，帮我们实现了一个代理类，我们拿到的都是接口的代理类实例。 JDK动态代理实现原理为了突出重点，以下代码仅展示与主题相关的代码，防御性编程，异常处理等无关内容已被省略，完整实现请自寻 JDK 源码 那么 Java 的动态代理是怎样实现的呢？我们去 JDK 源码，查看 Proxy.newProxyInstance 的实现： 12345678910111213141516public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; final Class&lt;?&gt; intfs = interfaces.clone(); // 通过类加载器和接口使用 getProxyClass0 方法创建实现类 Class&lt;?&gt; c1 = getProxyClass0(loader, intfs); // 获得指定构造器 final Constructor&lt;?&gt; cons = c1.getConstructor(constructorParams); // 创建实例 return cons.newInstance(new Object[](h));&#125; 其中两句创建实例的过程都是常见的反射操作，这里不赘述。但是 getProxyClass0 方法是如何通过接口创建类的？我们继续跟进 getProxyClass0 方法的实现： 1234private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; return proxyClassCache.get(loader, interfaces);&#125; 我们跟进至 proxyClassCache.get 的实现，这应该是一个负责缓存管理的类： 123456public V get(K key, P parameter) &#123; // Cache 置换，检查等实现均已省略，已下是 Cache 未命中时，创建新实现类的代码 Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); V value = supplier.get(); return value;&#125; 我们跟进至 ProxyClassFactory#apply 的实现： 1234567891011public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt; interfaces) &#123; for(Class&lt;?&gt; intf : interfaces) &#123; interfaceClass = Class.forName(intf.getName(), false, loader); // 对 interfaceClass 进行了系列权限检查，实现略 &#125; // 根据 interfaces.accessFlags 产生名为 proxyName 的代理类字节码 byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interface, accessFlags); // 加载字节码，产生类对象 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length);&#125; 从代码中，可以看到： ProxyGenerator.generateProxyClass 用于产生代理类的字节码 defineClass0 用于加载字节码产生类对象 这里的 defineClass0 是一个 native 方法，我们不深究。ProxyGenerator.generateProxyClass 是对字节码进行操作。我们做一个小实验： 123456789101112131415161718public class Main2 &#123; /** * 代理接口 */ interface ITest &#123; String test(String val); &#125; public static void main(String[] args) throws IOException &#123; // 通过 ProxyGenerator.generateProxyClass 产生字节码 byte[] testProxyBytes = ProxyGenerator.generateProxyClass("TestProxy", new Class[]&#123;ITest.class&#125;); // 将字节码输出到文件，然后我们再反编译它，看看它的内容是什么 FileOutputStream fileOutputStream = new FileOutputStream("TestProxy.class"); fileOutputStream.write(testProxyBytes); fileOutputStream.flush(); fileOutputStream.close(); &#125;&#125; TestProxy.class 反编译后的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public final class TestProxy extends Proxy implements ITest &#123; private static Method m1; private static Method m2; private static Method m3; private static Method m0; public TestProxy(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final String test(String var1) throws &#123; try &#123; return (String)super.h.invoke(this, m3, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName("java.lang.Object").getMethod("equals", Class.forName("java.lang.Object")); m2 = Class.forName("java.lang.Object").getMethod("toString"); m3 = Class.forName("com.example.demo.Main2$ITest").getMethod("test", Class.forName("java.lang.String")); m0 = Class.forName("java.lang.Object").getMethod("hashCode"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 通过 ProxyGenerator.generatorProxyClass 生成的类字节码有以下特点： 该类继承了 Proxy 实现了传入接口类（ITest） 该类在 static 代码块中定义了所有该类包含的方法的 Method 实例。 该类有一个构造器 TestProxy(InvocationHandler var1) 传入调用处理器。 该类所有方法都执行 super.h.invoke 并返回结果。 那么这里的 super.h 是什么呢，我们看其父类 Proxy 的代码： 12345protected InvocationHandler h;protected Proxy(InvocationHandler h) &#123; Objects.requireNonNull(h); this.h = h;&#125; 恍然大悟！这里的 super.h 就是 TestProxy(InvocationHandler var1) 构造器中传入的h。 总结 用户通过 Proxy.newProxyInstance 方法传入类加载器、接口对象、调用处理器来创建代理类实例。 JDK 中通过 ProxyGenerator.generateProxyClass 方法根据传入接口类对象生成代理类的字节码，并加载字节码产生代理类对象。 生成的代理类继承了 Proxy 实现了传入接口类。 该类的每一个方法都会执行调用处理器的 invoke 方法，传入相应参数，返回 invoke 方法的返回值 CGLIB 动态代理CGLIB 是什么CGLIB（Code Generation Library）是一个开源项目，是一个强大的，高性能，高质量的 Code 生成类库，它可以在运行期扩展 Java 类与实现 Java 接口。CGLIB 是一个强大的高性能的代码生成包。它广泛地被许多 AOP 框架使用，例如 Spring AOP 和 dynaop。 CGLIB 实现动态代理先来个 service，注意没有接口 1234567891011121314151617181920public class CglibService &#123; public CglibService() &#123; System.out.println("CglibDao 构造方法"); &#125; /** * 该方法不能被子类覆盖，Cglib是无法代理final修饰的方法的 * @param name * @return */ final public String sayOthers(String name) &#123; System.out.println("CglibDao final sayOthers：" + name); return null; &#125; public void sayHello() &#123; System.out.println("CglibDao:syaHello"); &#125;&#125; 新建一个 Interceptor 实现 org.springframework.cglib.proxy.MethodInterceptor 123456789101112131415161718public class MyMethodInterceptor implements MethodInterceptor &#123; /** * * @param o 代理对象 * @param method 被代理的对象方法 * @param objects 方法入参 * @param methodProxy 代理方法 * @return * @throws Throwable */ @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("===========插入前通知==========="); Object object = methodProxy.invokeSuper(o, objects); System.out.println("===========插入后通知==========="); return object; &#125;&#125; 新建测试类 1234567891011121314151617public class cglibAgentTest &#123; public static void main(String[] args) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(CglibService.class); // 设置 enhancer 的回调对象 enhancer.setCallback(new MyMethodInterceptor()); // 创建代理对象 CglibService proxy = (CglibService) enhancer.create(); // 通过代理对象调用目标方法 proxy.sayHello(); proxy.sayOthers("小明"); &#125;&#125; 打印的值 12345CglibDao 构造方法======插入前置通知======CglibDao:sayHello======插入后置通知======CglibDao final sayOthers:小明 可以看出，会先执行它的构造方法，当调用 sayHello 时会先调用它们的代理方法，如果当方法为 final 修饰时，无法实现代理。 原理CGLIB 可以在运行时，动态生成一个代理类继承我们的目标类，并重写了目标方法，如下： 动态生成的代理类，在方法中调用了父类（目标类）的目标方法，并在调用前后做了一些处理。 JDK 代理和 CGLIB 代理的区别这里稍微总结一下两者的区别： JDK 动态代理只能对实现了接口的类生成代理，而不能针对类 CGLIB 是针对类实现代理，主要是对指定的类生成一个子类，覆盖其中的方法（继承） Spring AOP 选择用 JDK 还是 CGLIB 的依据： 当 Bean 实现接口时，Spring 就会用 JDK 的动态代理 当 Bean 没有实现接口时，Spring 使用 CGLIB 来实现 默认是使用 JDK 代理，可以强制使用 CGLIB（在 Spring 配置中加入 &lt;aop:aspectj - autoproxy proxy-target-class = “true”/&gt;） JDK 和 CGLIB 的性能对比： 使用 CGLIB 实现动态代理，CGLIB 底层采用 ASM 字节码生成框架，使用字节码技术生成代理类，在 JDK1.6 之前比使用 JAVA 反射要高。唯一需要注意的是，CGLIB 不能对生命为 final 的方法进行代理，因为 CGLIB 原理是动态生成被代理类的子类 总结如果你的类是实现了某个接口的，Spring AOP 会使用 JDK 动态代理，生成一个跟你实现同样接口的一个代理类，构造一个实例对象出来，JDK 动态代理，其实就是在你的类有接口的时候，就会来使用。 如果你的类是没有实现接口的，Spring AOP 会改用 cglib 来动态生成代理，它是生成你的类的一个子类，可以动态生成字节码，覆盖你的一些方法，在方法里加入增强的代理。 参考资料小豹子带你看源码：JDK 动态代理 CGLIB 动态代理]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IOC 和 Spring AOP]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F09%2FSpring-IOC-%E5%92%8C-Spring-AOP%2F</url>
    <content type="text"><![CDATA[Spring IOC在没有 Spring 之前，我们开发 Web 系统基本是使用 Servlet + Tomcat。就是 Tomcat 启动之后，它可以监听一个端口号的 http 请求，然后可以把请求转交给你的 servlet，jsp 配合起来使用，由 servlet 处理请求。大概像下面的代码： 123456789101112131415public class MyServlet &#123; private MyService myService = new MyServiceImpl(); public void doPost(HttpServletRequest request) &#123; // 对请求一通处理 // 调用自己的业务逻辑组件 myService.doService(request); &#125;&#125;public interface MyService &#123;&#125;public class MyServiceImpl implements MyService &#123;&#125;public class NewServiceManagerImpl implements MyService &#123;&#125; 例如我们的一个 Tomcat + servlet 的这样的一个系统里，有几十个地方，都是直接用 MyService myService = new MyServiceImpl() 直接创建，引用和依赖了一个 MyServiceImpl 这样的一个类的对象。那么在这个系统里，就有几十个地方都跟 MyServiceImpl 类直接耦合在一起了。 如果现在不想用 MyServiceImpl 了，希望使用 NewServiceManagerImpl，同样也是 implements MyService 这个借口的。那么所有的实现逻辑都不同了，我们需要在这个系统的几十个地方，都去修改对应的 MyServiceImpl 这个类，切换为 NewServiceManagerImpl 这个类。这样就很麻烦。而且代码的改动成本很大，改动以后的测试成本很大，改动的过程可能会有点复杂，出现一些 bug。归根到底，代码里各种类之间完全耦合在一起，出现任何一丁点的变动，都需要改动大量的代码，重新测试，可能还有 bug。 这个时候，Spring IOC 框架就出场了。IOC（Inversion Of Control），中文翻译为“控制反转”，我们也叫依赖注入。之前是通过 XML 文件进行一个配置，现在可以基于注解来进行自动依赖注入。 1234567891011121314151617@Controllerpublic class MyController &#123; @Resource private MyService myService; public void doRequest(HttpServletRequest request) &#123; // 对请求一通处理 // 调用自己的业务逻辑组件，去执行一些业务逻辑 myService.doService(request); &#125;&#125;public class MyServiceImpl implements MyService &#123;&#125;@Servicepublic class NewServiceManagerImpl implements MyService &#123;&#125; 我们只要在这个工程里通过 maven 引入一些 spring 框架的依赖，就可以实现 IOC 的功能。 Tomcat 在启动的时候，会直接启动 spring 容器。而 spring 容器，会根据 XML 的配置，或者是你的注解，去实例化一些 bean 对象，然后根据 XML 配置或者注解，去对 bean 对象之间的引用关系，进行依赖注入，某个 bean 依赖了另一个 bean。而这底层的核心技术，就是反射。它会通过反射的技术，直接根据你的类去构建对应的对象出来。 Spring IOC，最大的好处就是让系统的类与类之间彻底的解耦合。 Spring AOPSpring AOP，又叫面向切面编程，可以应用于事务和日志等场景。拿事务举个例子，在数据库里，例如 MySQL，都提供一个事务机制，如果我们开启一个事务，在这个事务里执行多条增删改的 SQL 语句。在这个过程中，如果任何一个 SQL 语句失败了，会导致这个事务的回滚，把其他 SQL 做的数据更改都恢复回去。 在一个事务里的所有 SQL，要么一起成功，要么一起失败，事务功能可以保证我们的数据的一致性。我们可以在业务逻辑组件里加入这个事务。 123456789101112131415161718192021222324252627282930313233343536373839@Controllerpublic class MyController &#123; @Resource private MyService myServiceA; public void doRequest() &#123; myServiceA.doServiceA(); &#125;&#125;@Servicepublic class MyServiceAImpl implements MyServiceA &#123; public void doServiceA() &#123; // 开启事务 //insert语句 //update语句 //delete语句 //根据是否抛出异常，回滚事务 or 提交事务 &#125;&#125;@Servicepublic class MyServiceBImpl implements MyServiceB &#123; public void doServiceB() &#123; // 开启事务 // update语句 // update语句 // insert语句 //根据是否抛出异常，回滚事务 or 提交事务 &#125;&#125; 由上面的代码可以看出，所有的业务逻辑都有几段跟事务相关的代码。假设我们有几十个 Service 组件，类似一样的代码，重复的代码，必须在几十个地方都去写一样的东西，这就很难受了。这时候就轮到 Spring AOP 机制出马了。 AOP 作为一种编程范式，已经衍生出了属于它的一些先关术语。为了更好地理解如何在 Spring 中使用 AOP，我们必须对这些术语有一定的认知。 通知（Advice）Spring AOP 支持五种类型的通知，它们分别定义了切面在什么时候使用，以及定义了切面需要做些什么。 @Before 前置通知，目标方法被调用之前执行 @After 后置通知，目标方法完成之后执行 @AfterReturning 返回通知，目标方法执行成功（未抛出异常）之后执行 @AfterThrowing 异常通知，目标方法执行失败（抛出异常）之后执行 @Around 环绕通知，目标方法执行前后都会调用 连接点（JoinPoint）程序执行的某个特定位置：如类开始初始化前、类初始化后、类满足某个方法调用前、调用后、方法抛出异常后。一个类或一段程序代码拥有一些具有边界性质的特定点，这些点中的特定点就称为“连接点”。Spring 仅支持方法的连接点，即仅能在方法调用前、方法调用后、方法抛出异常时以及方法调用前后这些程序执行点织入增强。连接点由两个信息确定：第一是用方法表示的程序执行点，第二是用相对点表示的方位。 切点（Poincut）每个程序类都拥有多个连接点，如一个拥有两个方法的类，这两个方法都是连接点，即连接点是程序中客观存在的事物。AOP 通过“切点”定位特定的连接点。连接点相当于数据库中的记录，而切点相当于查询条件。切点和连接点不是一对一的关系，一个切点可以匹配多个连接点。在 Spring 中，切点通过 org.springframework.aop.Pointcut 接口进行描述，它使用类和方法作为连接点的查询条件，Spring AOP 的规则解析引擎负责切点所设定的查询条件，找打对应的连接点。其实确切地说，不能称之为查询连接点，因为连接点是方法执行前、执行后等包括方位信息的具体程序执行点，而切点只定位到某个方法上，所以如果希望定位到具体连接点上，还需要提供方位信息。 切面（Aspect）切面由切点和增强（引介）组成，它既包括了横切逻辑的定义，也包括了连接点的定义，Spring AOP 就是负责实施切面的框架，它将切面所定义的横切逻辑织入到切面所指定的连接点中。 引入（Introduction）引入使我们具备了为类添加一些属性和方法的能力。这样，即使一个业务类原本没有实现某个接口，通过 AOP 的引介功能，我们可以动态地为该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。 织入（weaving）织入是将增强添加对目标类具体连接点上的过程。AOP 像一台织布机，将目标类、增强或引介通过 AOP 这台织布机天衣无缝地编织到一起。根据不同的实现技术，AOP 有三种织入的方式：1. 编译期织入，这要求使用特殊的Java编译器。2. 类装载期织入，这要求使用特殊的类装载器。3. 动态代理织入，在运行期为目标类添加增强生成子类的方式。Spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装载期织入。 代理（Proxy） 一个类被 AOP 织入增强后，就产出了一个结果类，它是融合了原类和增强逻辑的代理类。根据不同的代理方式，代理类既可能是和原类具有相同接口的类，也可能就是原类的子类，所以我们可以采用调用原类相同的方式调用代理类。 一个切面，如何定义呢？例如 MyServiceImplXXXX 的这种类，在这些类的所有方法中，都去织入一些代码，在所有这些方法刚开始运行的时候，都先去开启一个事务，在所有这些方法执行完毕之后，去根据是否抛出异常来判断一下，如果抛出异常，就回滚事务，如果没有异常，就提交事务。 Spring 在运行的时候，会使用动态代理技术，这也是 AOP 的核心技术，来给你的那些类生成动态代理。 1234567891011public class ProxyMyServiceA implements MyServiceA &#123; private MyServiceA myServiceA; public void doServiceA() &#123; // 开启事务 // 直接去调用我依赖的MyServiceA对象的方法 myServiceA.doServiceA(); // 根据是否抛出异常，回滚事务 or 提交事务 &#125;&#125; 那么上面的代码就可以变成这样： 123456789101112131415161718192021@Controllerpublic class MyController &#123; @Resource private MyService myServiceA; // 注入的是动态代理的对象实例，ProxyMyServiceA public void doRequest() &#123; myServiceA.doServiceA(); // 直接调用到动态代理的对象实例的方法中去 &#125;&#125;@Servicepublic class MyServiceAImpl implements MyServiceA &#123; public void doServiceA() &#123; //insert语句 //update语句 //delete语句 &#125;&#125; 下面给个简单的AOP代码的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Aspect@Componentpublic class ApiIdempotentAop &#123; @Autowired private JedisUtil jedisUtil; @Pointcut("@annotation(com.example.midx.annotation.ApiIdempotent)") public void apiIdempotentPointCut() &#123; &#125; @Around("apiIdempotentPointCut()") public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; System.err.println("进来AOP了"); Object[] args = joinPoint.getArgs(); //获取request和response ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); HttpServletResponse response = attributes.getResponse(); String requestURI = request.getRequestURI(); MethodSignature signature = (MethodSignature) joinPoint.getSignature(); ApiIdempotent annotation = signature.getMethod().getAnnotation(ApiIdempotent.class); Object result; if(annotation != null) &#123; String token = request.getHeader("token"); if (StringUtils.isBlank(token)) &#123;// header中不存在token token = request.getParameter("token"); if (StringUtils.isBlank(token)) &#123;// parameter中也不存在token throw new ServiceException("参数不合法"); &#125; &#125; if (!jedisUtil.exists(token)) &#123; System.err.println("请勿重复操作"); throw new ServiceException("请勿重复操作"); &#125; result = joinPoint.proceed(); Long del = jedisUtil.del(token); if (del &lt;= 0) &#123; throw new ServiceException("请勿重复操作"); &#125; return result; &#125; return null; &#125; @Before("execution(* com.cdc.bdom.portal..*.mapper.*Mapper.select*(..)) || execution(* com.cdc.bdom.portal..*.mapper.*Mapper.get*(..)) || execution(* com.cdc.bdom.portal..*.mapper.*Mapper.find*(..))") public void setReadDataSourceType() &#123; logger.info("调用读数据库"); DataSourceContextHolder.read(); &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx详解]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F07%2FNginx%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Nginx 简介​ Nginx是一个免费、开源、高性能、轻量级的HTTP和反向代理服务器，也是一个电子邮件（IMAP/POP3）代理服务器，其特点是占有内存少，并发能力强。 ​ Nginx由内核和一系列模块组成，内核提供Web服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。 ​ Nginx的各种功能和操作都由模块来实现。Nginx的模块从结构上分为： 核心模块：HTTP模块、EVENT模块和MAIL模块。 基础模块：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块和HTTP Rewrite模块。 第三方模块：HTTP Upstream Request Hash模块、Notice模块和HTTP Access Key模块及用户自己开发的模块。 ​ 这样的设计使Nginx方便开发和扩展，也因此才使得Nginx功能如此强大。Nginx的模块默认编译进Nginx中，如果需要增加或删除模块，需要重新编译Nginx，这一点不如Apache的动态加载模块方便。如果有需要动态加载模块，可以使用由淘宝网发起的Web服务器Tengine，在Nginx的基础上增加了很多高特定，完全兼容Nginx，已被国内很多网站采用。Nginx有很多扩展版本： 开源版nginx.org 商业版NGINX Plus 淘宝网发起的Web服务器Tengine 基于Nginx和Lua的Web平台OpenResty Nginx 作为 Web 服务器​ Web服务器也称为WWW（World Wide Web）服务器，主要功能是提供网上信息浏览服务，常常以B/S（Browser/Server）方式提供服务： 应用层使用HTTP协议 HTML文档格式 浏览器统一资源定位器（URL） ​ Nginx可以作为静态页面的Web服务器，同时还支持CGI协议的动态语言，比如Perl、PHP等，但是不支持Java。Java程序一般都是通过与Tomcat配合完成，让我们看看Nginx和Tomcat的区别。 ​ Nginx、Apache和Tomcat： Nginx：由俄罗斯程序员lgor Sysoev所开发的轻量级，高并发HTTP服务器。 Apache HTTP Server Project：一个Apache基金会下的HTTP服务项目，和Nginx功能类似。 Apache Tomcat：是Apache基金会下的另外一个项目，是一个Application Server。更准确地说是一个Servlet应用容器，与Apache HTTP Server和Nginx相比，Tomcat能够动态生成资源并且返回到客户端。 ​ Apache HTTP Server和Nginx本身不支持生成动态页面，但它们可以通过其他模块来支持（例如通过Shell、PHP、Python脚本程序来动态生成内容）。 ​ 一个HTTP Server关心的是HTTP协议层面的传输和访问控制，所以在Apache/Nginx上你可以看到代理、负载均衡等功能。客户端通过HTTP Server访问服务器上存储的资源（HTML文件、图片文件等待）。通过CGI技术，也可以将处理过的内容通过HTTP Server分发，但是一个HTTP Server始终只是把服务器上的文件如实地通过HTTP协议传输给客户端。 ​ 而应用服务器，则是一个应用执行的容器。它首先需要支持开发语言的运行（对于Tomcat来说，就是Java），保证应用能够在应用服务器上正常运行。其次，需要支持应用相关的规范，例如类库、安全方面的特性。对于Tomcat来说，就是需要提供JSP/Servlet运行需要的标准库。Interface等。 ​ 为了方便，应用服务器往往也会集成HTTP Server的功能，但是不如专业的HTTP Server那么强大。所以应用服务器往往是运行在HTTP Server的背后，执行应用，将动态的内容转化为静态的内容之后，通过HTTP Server分发到客户端。 正向代理正向代理：如果把局域网外的Internet想象成一个巨大的资源库，则局域网中的客户端要访问Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理。 正向代理“代理”的是客户端。例如你想去YouTube看个动作片，可国内不允许啊，就需要找翻墙代理，这个就是所谓的“正向代理”。 反向代理与负载均衡反向代理与正向代理相反，反向代理是指以代理服务器来接收Internet上的连接请求，然后将请求转发到内部网络上的服务器，并将服务器上得到的结果返回给客户端。此时代理服务器对外表现就是一个服务器，客户端对代理是无感知的。反向代理“代理”的是服务端。 再比如，你想在“优酷”上看个综艺，youku.com 会把你的请求分发到存放视频的那台机器上，这就是所谓的“反向代理”。 为什么使用反向代理，原因如下： 保护和隐藏原始资源服务器 加密和SSL加速 通过缓存静态资源，加速Web请求 实现负载均衡 地址重定向：Nginx的Rewrite主要的功能就是实现URL重写，比如输入360.com跳转到360.cn。 动静分离为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度，降低原来单个服务器额的压力。 这里指的就是让动态程序（Java、PHP）去访问应用服务器，让缓存、图片、JS、CSS等去访问Nginx。 Nginx 安装​ 1、下载nginx 1wget http://nginx.org/download/nginx-1.16.1.tar.gz 2、安装需要编译的插件 用于编译C、C++代码的GCC 用C语言编写的正则表达式函数库Pcre（使用Rewrite模块） 用于数据压缩的函数库Zlib 安全套接字层密码库OpenSSL（启用SSL支持） 1234yum install gcc c++ yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel 3、解压、配置（nginx支持各种配置选项）。编译、安装Nginx 1234tar -zxvf nginx-1.15.tar.gz cd nginx-1.16.1cd nginx-1.16.1./configuremake &amp;&amp; sudo make install 4、启动、重启、关闭 123456789cd /usr/local/nginx/ cd sbin./nginx#关闭命令 ./nginx -s stop#重启，热部署./nginx -s reload#修改配置文件后也别嘚瑟，反正我会动不动就写错，检查修改的nginx.conf配置是否正确./nginx -t 5、验证（浏览器输入IP） 配置文件nginx.conf配置文件主要分为三部分： 全局块 Events 块 HTTPS 块 ​ Nginx配置语法： 配置文件由指令和指令块构成 每条指令以分号（;）结尾，指令和参数间以空格符分隔 指令块以大括号{}将多条指令组织在一起 include 语句允许组合多个配置文件以提高可维护性 使用#添加注释 使用$定义变量 部分指令的参数支持正则表达式 全局块全局配置部分用来配置对整个Server都有效的参数。主要会设置一些影响 Nginx 的服务器整体运行的配置指令，包括配置运行Nginx服务器的用户（组）、允许生成的 Work Process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。示例如下： 123user nobody;worker_processes 4;error_log /data/nginx/logs/error.log notice; Events 块Events块涉及的指令主要影响Nginx服务器与用户的网络连接，常用的设置包括是否开启对多 Work Process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 Work Process 可以同时支持的最大连接数等。 1234events &#123; #每个 work process 支持的最大连接数为 1024 work_connections 1024;&#125; HTTP 块这算是Nginx服务器配置中最频繁的部分。代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。需要注意的是：HTTP 块也可以包括 HTTP 全局快、Server 块。 HTTP 全局块HTTP 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求上限等。 123456http &#123; include mime.types; default_type application/octet-stream sendfile on; keepalive_timeout 65;&#125; Server 块这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。 每个 HTTP 块可以包括多个 Server 块，而每个 Server 块就相当于一个虚拟主机。而每个 Server 块也分为全局 Server 块，以及可以同时包含多个 Location 块。 全局 Server 块：也被叫做“ 虚拟服务器 ”部分，它描述的是一组根据不同 server_name 指令逻辑分割的资源，这些虚拟服务器响应 HTTP 请求，因此都包含在 HTTP 部分。最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置。 12345server &#123; listen 80; #server_name 也支持通配符，*.example.com、www.example.*、.example.com server_name localhost;&#125; Location 块：一个 Server 块可以配置多个 Location 块。 这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称（也可以是IP别名）之外的字符串（例如前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。 Location 指令说明：该指令用于匹配 URL。语法如下：location [ = | ~ | * | ^ ] uri {} =：该修饰符使用精确匹配并且终止搜索。 ~：该修饰符使用区分大小写的正则表达式匹配。 ~*：该修饰符使用不区分大小写的正则表达式匹配。 ^~：用于不含正则表达式的 URI 前，要求 Nginx 服务器找到表示 URI 和请求字符串匹配度最高的 Location 后，立即使用此 Location 处理请求，而不再使用 Location 块中的正则 URI 和请求字符串做匹配。 注意，如果 URI 包含正则表达式，则必须要有 ~ 或者 ~* 标识。 当一个请求进入时，URI 将会被检测匹配一个最佳的 Location： 没有正则表达式的 Location 被作为最佳的匹配，独立于含有正则表达式的 Location 顺序。 在配置文件中按照查找顺序进行正则表达式匹配。在查找到第一个正则表达式匹配之后结束查找。由这个最佳的 Location 提供请求处理。 1234location / &#123; root html; index index.html index.htm;&#125; nginx.conf 详细配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293#定义Nginx运行的用户和用户组uesr www www;#nginx进程数，通常设置成和cpu的数量相等work_processes 4;#全局错误日志定义类型，[debug | info | notice | warn | error | crit]#error_log /data/nginx/logs/error.log;#error_log /data/nginx/logs/error.log notice;#日志文件存放路径 access_log path [format [buffer=size | off]]access_log /data/nginx/logs/lazyegg.com/web/access/log combinedio;#进程pid文件#pid logs/nginx.pid;#指定进程可以打开的最大描述符：数目#工作模式与连接上限#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit - n）#与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit - n的值保持一致。这是因#为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可#能超过10240了，这时会返回502错误worker_rlimit_nofile 65535;################################# events ###############################events &#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll]; epoll模型 use epoll #单个进程最大连接数（最大连接数 = 连接数 + 进程数） worker_connections 1024; #keepalive 超时时间 keepalive_timeout 60; #客户端请求头部的缓冲区大小 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致， #inactive是指经过多少时间文件没被请求后删除缓存 open_file_cache max=65535 inactive=60s; #这个指多长时间检查一次缓存的有效信息 open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述 #符一直是在缓存中打开的。如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除 open_file_cache_min_uses 1; #语法：open_file_chche_errors on | off 默认值：open_file_cache_errors off 使用 #字段：http，server，location 这个指令指定是否在搜索一个文件是否记录cache错误 open_file_cache_errors on;&#125;############################## http ###################################设定http服务器，利用它的反向代理功能提供负载均衡支持http &#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 charset utf-8; #服务器名字的hash表大小 server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小 client_header_buffer_size 32k; #客户请求头缓冲大小 large_client_header_buffers 4 64k; #允许客户端请求的最大单个文件字节数 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用 #应该设置为on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理 #速度，降低系统的负载。注意：如果图片显示不正常把这个改成off sendfile on; #开启目录列表访问，适合下载服务器，默认关闭 autoindex on; #此选项允许或禁止使用socket的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩类型，默认就已经包含了textml，所以下面就不用再写了，写了也不会有问题，但是会有一个warn gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream lazyegg.net &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weight参数表示权值，权 #值越高被分配的几率越大 server 192.168.80.121:80 weigth=3; server 192.168.80.122:80 weigth=2; server 192.168.80.123:80 weigth=3; #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按照时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况 #例如： #upstream bakend &#123; # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #&#125; #3、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session问题 #例如： #upstream bakend &#123; # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #&#125; #4、fair（第三方） #按后端服务器的相应时间来分配请求，相应时间短的优先分配 #upstream backend &#123; # server server1; # server server2; # fair; #&#125; #5、uil_hash（第三方） #按访问URL的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效 #例：在upstream中加入hash语句，server语句中不能写入weight等其他参数，hash_method #是使用的hash算法 #upstream backend &#123; # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #&#125; #tips: #upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123; # ip_hash; # server 127.0.0.1:9090 down; # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # server 127.0.0.1:7070 backup; #&#125; #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为： #1、down表示单前的server暂时不参与负载 #2、weight为weight越大，负载的权重就越大 #3、max_fails：允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4、fail_timeout：max_fails次失败后，暂停的时间。 #5、backup：其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力最轻 #nginx支持同时设置多组的负载均衡，用来给不同的server使用 #client_body_in_file_only 设置为 on，可以将client post过来的数据记录到文件中用来做debug #client_body_temp_path 设置记录文件的目录，可以设置最多3层目录 #location对URL进行匹配，可以进行重定向或者进行新的代理，负载均衡 &#125; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name lazyegg.net; #默认入口文件名称 index index.html index.htm index.php; root /data/www/lazyegg; #对******进行复制均衡 location ~ .*.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址 #$remote_user：用来记录客户端用户名称 #$time_local：用来记录访问时间与时区 #$request：用来记录请求的url与http协议 #$status：用来记录请求状态，成功是200 #$body_bytes_sent：记录发送给客户端文件主体内容大小 #$http_referer：用来记录从哪个页面链接访问过来的 #$http_user_agent：记录客户浏览器的相关信息 #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_addr拿 #到的IP地址是反向代理服务器的ip地址。范子昂代理服务器在转发请求的http头信息中，可以增加 #x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址 log_format access '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" $http_x_forwarded_for'; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 "/connect-controller"启用反向代理 location /connect_controller &#123; proxy_pass http://127.0.0.1:88 #此处端口号不能与虚拟主机监听的端口号一样 proxy_redirect off; proxy_set_header X_Real_IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded-for; #以下是一些反向代理的配置，可选 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数 #如果把它设置为比较大的数值，例如256k，那么，无论使用Firefox还是IE浏览器，来提交 #任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size #设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了 #无论使用Firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候相应超时时间 #nginx跟后端服务器连接超时时间（代理连接超时） proxy_connect_timeout 90; #后端服务器数据回传时间（代理发送超时） #后端服务器数据回传时间，就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间（代理接收超时） #连接成功后，等待后端服务器相应时间，其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #proxy_buffer缓冲区，网页平均在32k一下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也认为页大小，根据操作系统的不同可能是4K或者是8K proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件是阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; #本地动静分离反向代理配置 #所有jsp页面均交由Tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X_Real_IP $remote_addr; proxy_set_header X-Forwarded_For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; &#125; &#125; Nginx 配置实例反向代理 Demo 1实现效果：使用 nginx 反向代理，访问 www.12345.com 直接跳转到自己的机器 127.0.0.1:8080。 1、创建一个SpringBoot项目，写一个简单的Controller。 12345678@RestControllerpublic class TestController &#123; @RequestMapping(method = &#123;RequestMethod.POST, RequestMethod.GET&#125;) public String helloWorld() &#123; return "Hello World"; &#125;&#125; 启动项目后，在浏览器访问 127.0.0.1:8080，出现如下界面： 2、通过修改本地Host文件（ C:\Windows\System32\drivers\etc ），添加 127.0.0.1 www.12345.com 将 www.12345.com 映射到自己的机器IP上。 3、配置完成之后，我们便可以通过 www.12345.com:8080 访问到第一步出现的界面。 那么如何主需要输入 www.12345.com 便可以跳转到初始界面呢？这是就可以用到 nginx 的反向代理 4、修改 nginx.conf 配置文件，增加如下配置 proxy_pass: 12345678server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://127.0.0.1:8080; &#125; 5、如上配置，我们监听 80 端口，访问域名为 www.12345.com，不加端口号时默认为 80 端口，故访问该域名时会跳转到 127.0.0.1:8080 路径上。 在浏览器输入 www.12345.com 结果如下： 反向代理 Demo 2实现效果：使用 Nginx 反向代理，根据访问的路径跳转到不同端口的服务中： 访问 http://127.0.0.1/java/ 直接跳转到 127.0.0.1:8080 访问 http://127.0.0.1/egg/ 直接跳转到 127.0.0.1:8081 先启动两个 springboot 项目，其中 8080 端口的项目返回 “Hello java”，8081 的端口返回 “Hello egg”。 修改 nginx.conf，在 HTTP 块中添加 server{} : 123456789101112server &#123; listen 80; server_name localhost; location ~ /java/ &#123; proxy_pass http://127.0.0.1:8080; &#125; location ~ /egg/ &#123; proxy_pass http://127.0.0.1:8081; &#125;&#125; 重启 nginx，验证结果： Nginx 配置：负载均衡随着互联网信息的爆炸性增长，负载均衡已经不再是一个陌生的话题。顾名思义，负载均衡是将负载分摊到不同的服务单元，既保证服务的可用性，又保证相应足够块，给用户很好的体验。Nginx 的负载均衡是 Proxy 模块和 Upstream 模块搭配实现的。Upstream 模块将会启用一个新的配置区段，在改区段定义了一组上游服务器。 实现效果：配置负载均衡还是使用上次两个 springboot 的项目，其中 8080 端口 返回 “Hello java”，而 8081 端口返回 “Hello egg”。 接着，修改 nginx.conf： 123456789101112http &#123; upstream myserver &#123; server localhost:8080; server localhost:8081; &#125; server &#123; listen 80; location / &#123; proxy_pass http://myserver; &#125; &#125;&#125; 重启 Nginx，验证结果（默认轮询的方式，每次打开新窗口，8080 和 8081 会交替出现，同一个窗口的话需要关闭浏览器缓存）。 Nginx 分配策略： 轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 Down 掉，能自动剔除。 Weight ：代表权重，默认为 1，权重越高被分配的客户端越多，指定轮询几率，Weight 和访问比率成正比，用于后端服务器性能不均的情况。例如： 1234upstream server_pool &#123; server 192.168.0.1 weight=10; server 192.168.0.2 weigth=10;&#125; ip_hash：每个请求按访问 IP 的 Hash 结构分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。例如： 12345upstream server_pool &#123; ip_hash; server 192.168.0.1:80; server 192.168.0.2:80;&#125; fair（第三方）：按后端服务器的相应时间来分配请求，相应时间短的优先分配。 12345upstream server_pool &#123; server 192.068.0.1:80; server 192.168.0.2:80; fair;&#125; Nginx 配置：动静分离Nginx 动静分离简单说就是把动态和静态请求分开，不能理解成只是单纯地把动态页面和静态页面物理分离。严格意义上说应该是动态跟静态请求分开，可以理解成使用 Nginx 处理静态页面，Tomcat 处理动态页面。 动静分离从目前实现角度来说大致分为两种： 纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案； 动态跟静态文件混合在一起发布，通过 Nginx 来分开。 通过 Location 指定不同的后缀名实现不同的请求转发。通过 Expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之间的请求和流量。 具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无须去服务端验证，直接通过浏览器自身确认是否过期，所以不会产生额外的流量。此种方法非常适合不经常变动的资源（如经常更新的文件，不建议使用 Expires 来缓存） 我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码 304，如果有修改，则直接从服务器重启下载，返回状态码 200。 服务器找个目录存放自己的静态文件： 配置 Nginx： 1234567891011121314151617181920212223242526272829303132333435363738server &#123; listen 80;#端口号 server_name localhost;#本机 charset utf-8; #access_log logs/host.access.log main; location ~ .*\.(gif|jpg|jpeg|png)$ &#123; expires 24h; root /usr/data/image/;#指定图片存放路径 access_log /usr/local/websrv/nginx-1.9.4/logs/images.log;#日志存放路径 proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path /usr/data/image/;#图片访问路径 proxy_redirect off; proxy_set_header Host 127.0.0.1; client_max_body_size 10m; client_body_buffer_size 1280k; proxy_connect_timeout 900; proxy_send_timeout 900; proxy_read_timeout 900; proxy_buffer_size 40k; proxy_buffers 40 320k; proxy_busy_buffers_size 640k; proxy_temp_file_write_size 640k; if ( !-e $request_filename) &#123; proxy_pass http://127.0.0.1;#默认80端口 &#125; &#125; location / &#123; root /home/html; #html访问路径 index index.html index2.htm; #html文件名称 &#125;&#125; 重启 Nginx，验证结果： Nginx 的 RewriteRewrite 是 Nginx 服务器提供的一个重要的功能，它可以实现 URL 重写和重定向功能。 场景如下： URL 访问跳转，支持开发设计。页面跳转、兼容性支持（新旧版本更迭）、展示效果（网址精简）等 SEO 优化（Nginx 伪静态的支持） 后台维护、流量转发 安全（动态界面进行伪装） 该指令是通过正则表达式的使用来改变 URI。可以同时存在一个或多个指令。需要按照顺序依次对 URI 进行匹配和处理。 采用反向代理 Demo2 中的例子，修改 nginx.conf（只多加一行 rewrite） 12345678910111213server &#123; listen 80; server_name localhost; location /java/ &#123; proxy_pass http://127.0.0.1:8080; rewrite ^/java /egg/ redirect; &#125; location /egg/ &#123; proxy_pass http://127.0.0.1:8081; &#125;&#125; 重启 nginx，验证结果（输入 ip/java/ 被重定向到 egg）： Rewrite 指令可以在 Server 块或 Location 块中配置，其基本语法结构如下： 1rewrite regex replacement [flag]; rewrite 的含义：该指令是实现 URL 重写的指令。 regex 的含义：用于匹配 URI 的正则表达式。 replacement：将 regex 正则匹配到的内容替换成 replacement。 flag：flag 标记 flag 有如下值： last：本条规则匹配完成后，继续向下匹配新的 Location URI 规则（不常用）。 break：本条规则匹配完成即终止，不再匹配后面的任何规则（不常用）。 redirect：返回 302 临时重定向，浏览器地址会显示新的 URL地址。 permanent：返回 301 永久重定向。浏览器会显示跳转新的 URL 地址。 1rewrite ^/(.*) http://www.360.cn/$1 permanent; Nginx 高可用如果将 Web 服务器集群当做一个城池，那么负载均衡服务器就相当于城门。如果“城门”关闭了，与外界的通道就断了。如果只有一台 Nginx 复制均衡器，当故障宕机的时候，就会导致整个网站无法访问。所以我们需要两台以上的 Nginx 来实现故障转移和高可用。那么如何实现？ 双机热备方案这种方案是国内企业中最为普遍的一种高可用方案，双机热备其实就是指一台服务器在提供服务，另一台为某服务的备用状态，当一台服务器不可用时另一台就会顶替上去。 Keepalived 是什么？Keepalived 软件起初是转为 LVS 负载均衡软件设计的，用来管理并监控 LVS 集群系统中各个服务节点的状态。后来又加入了可以实现高可用的 VRRP（Virtual Router Redundancy Protocol，虚拟路由器冗余协议）功能。因此，Keepalived 高可用服务之间的故障切换转移，是通过 VRRP 来实现的。 故障转移机制Keepalived 高可用服务之间的故障切换转移，是通过 VRRP 来实现的。 在 Keepalived 服务正常工作时，主 Master 节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉 Backup 节点自己还活着。 当主 Master 节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master 节点的心跳了，于是调用自身的接管程序，接管主 Master 节点的 IP 资源及服务。 而当主 Master 节点恢复时，背 Backup 节点又会释放主节点故障时自身接管的 IP 资源及服务，恢复到原来的备用角色。 实现方法如下： 准备两台安装 Nginx 和 Keepaliver（yum install keepalived -y）的服务器 修改两台服务器上的 /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526#主机#检测脚本vrrp_script chk_http_port &#123; script "/usr/local/src/check_nginx.sh" #心跳执行的脚本，检测nginx是否启动 interval 2 #（检测脚本执行的间隔，单位是秒） weight 2 #权重&#125;#vrrp 实例定义部分vrrp_instance VI_1 &#123; state MASTER # 指定keepalived的角色，MASTER为主，BACKUP为备 interface ens33 # 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡 virtual_router_id 66 # 虚拟路由编号，主从要一直 priority 100 # 优先级，数值越大，获取处理请求的优先级越高 advert_int 1 # 检查间隔，默认为1s(vrrp组播周期秒数) #授权访问 authentication &#123; auth_type PASS #设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信 auth_pass 1111 &#125; track_script &#123; chk_http_port #（调用检测脚本） &#125; virtual_ipaddress &#123; 192.168.16.150 # 定义虚拟ip(VIP)，可多设，每行一个 &#125;&#125; 1234567891011121314151617181920212223242526# 备机#检测脚本vrrp_script chk_http_port &#123; script "/usr/local/src/check_nginx.sh" #心跳执行的脚本，检测nginx是否启动 interval 2 #（检测脚本执行的间隔） weight 2 #权重&#125;#vrrp 实例定义部分vrrp_instance VI_1 &#123; state BACKUP # 指定keepalived的角色，MASTER为主，BACKUP为备 interface ens33 # 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡 virtual_router_id 66 # 虚拟路由编号，主从要一直 priority 99 # 优先级，数值越大，获取处理请求的优先级越高 advert_int 1 # 检查间隔，默认为1s(vrrp组播周期秒数) #授权访问 authentication &#123; auth_type PASS #设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信 auth_pass 1111 &#125; track_script &#123; chk_http_port #（调用检测脚本） &#125; virtual_ipaddress &#123; 192.168.16.150 # 定义虚拟ip(VIP)，可多设，每行一个 &#125;&#125; 新建检测脚本（chmod 775 check_nginx.sh）： 123456789#!/bin/bash#检测nginx是否启动了A=`ps -C nginx --no-header |wc -l` if [ $A -eq 0 ];then #如果nginx没有启动就启动nginx systemctl start nginx #重启nginx if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then #nginx重启失败，则停掉keepalived服务，进行VIP转移 killall keepalived fifi 启动 Nginx 和 Keepalived（systemctl start keepalived.service） 模拟 Nginx 故障（关闭主服务器 Nginx），验证，仍可以通过配置的虚拟 IP 访问，OK Nginx 原理与优化参数配置Nginx 默认采用多进程工作方式，Nginx 启动后，会运行一个 Master 进程和多个 Worker 进程。 其中 Master 充当整个进程组与用户的交互接口，同时对进程进行监护，管理 Worker 进程来实现重复服务、平滑升级、更护日志文件、配置文件实时生效等功能。 Worker 用来处理基本的网络事件，Worker 之间是平等的，他们共同竞争来处理来自客户端的请求。 master-worker 的机制的好处： 可以使用 nginx -s reload 热部署 每个 Worker是独立的进程，不需要加锁，省掉了锁带来的开销。采用独立的进程，可以让互相之间不会影响。一个进程退出后，其他进程还在工作，服务不会中断，Master 进程则很快启动新的 Worker 进程。 需要设置多少个 Worker？Nginx 同 Redis 类似都采用了 IO 多路复用机制，每个 Worker 都是独立的进程，但每个进程里只有一个主线程，通过异常非阻塞的方式来处理请求，即使是成千上万个请求也不在话下。 每个 Worker 的线程可以把一个 CPU 的性能发挥到极致。所以 Worker 数和服务器的 CPU 数相等是最为适宜的。设少了浪费 CPU，设多了会造成 CPU 频繁切换上下文带来的损耗。 123456#设置 worker 数量。 worker_processes 4 #work 绑定 cpu(4 work 绑定 4cpu)。 worker_cpu_affinity 0001 0010 0100 1000 #work 绑定 cpu (4 work 绑定 8cpu 中的 4 个) 。 worker_cpu_affinity 0000001 00000010 00000100 00001000 连接数 worker_connection：这个值是表示每个 Worker 进程所能建立连接的最大值。所以，一个 Nginx 能建立的最大连接数，应该是 worker_connections * worker_processes。 当然这里说的是最大连接数，对于 HTTP 请求本地资源来说，能够支持的最大并发数量是 worker_connections * worker_process，如果是支持 http1.1 的浏览器，每次访问要占两个连接，所以普通的静态访问最大并发数是：worker_connections * worker_processes / 2。 而如果是 HTTP 作为反向代理来说，最大并发数量应该是 worker_connections * worker_processes / 4，因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。 Nginx 总结Nginx 在项目中的作用反向代理服务器 实现负载均衡 做静态资源服务器 作为 HTTP Server Nginx 常用的命令1234567启动nginx ./sbin/nginx停止nginx ./sbin/nginx -s stop ./sbin/nginx -s quit重载配置 ./sbin/nginx -s reload(平滑重启) service nginx reload重载指定配置文件 ./sbin/nginx -c /usr/local/nginx/conf/nginx.conf查看nginx版本 ./sbin/nginx -v检查配置文件是否正确 ./sbin/nginx -t显示帮助信息 ./sbin/nginx -h Nginx 如何实现高并发Nginx 采用的是多进程（单线程）&amp; 多路 IO 复用模型，异步，非阻塞。 一个主进程 Master，多个工作进程 Worker，每个工作进程可以处理多个请求，Master 进程主要负责收集、分发请求。每当一个请求过来时，Master 就会拉起一个 Worker 进程负责处理这个请求。同时Master进程也复制监控Work的状态，保证高可用性。 在 Nginx 中的 Work 进程中，为了应对高并发场景，采取了 Reactor 模型（也就是 I/O 多路复用，NIO）。 I/O 多路复用模型：在 I/O 多路复用模型中，最重要的就是系统调用 Select 函数。该方法能够同时监控多个文件描述符的可读可写情况（每一个网络连接其实都对应一个文件描述符），当其中的某些文件描述符可读可写时，Select 方法就会返回可读以及可写的文件描述符个数。 Nginx Work 进程使用 I/O 多路复用模块同时监听多个 FD（文件描述符）。当 Accept、Read、Write 和 Close 事件产生时，操作系统就会回调 FD 绑定的事件处理器。这时候 Work 进程再去处理相应事件，而不是阻塞在某个请求连接上等待。这样就可以实现一个进程同时处理多个连接。每一个 Worker 进程通过 I/O 多路复用处理多个连接请求。 为了减少进程切换（需要系统调用）的性能损耗，一般设置 Worker 进程数量和 CPU 数量一致。 Nginx 和 Apache 的区别轻量级，同样是 Web 服务，比 Apache 占用更少的内存及资源抗并发，Nginx 处理请求是异步非阻塞的，而 Apache 则是阻塞型的。 在高并发下 Nginx 能保持低资源低消耗高性能高度模块化的设计，编写相对简单，最核心的区别在于 Apache 是同步多线程模型，一个连接对应一个进程；Nginx 是异步的，多个连接（万级别）可以对应一个进程。 Nginx 的 upstream 支持的负载均衡模式 轮询 weight：指定权重 ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访问固定访问一个后台服务器 第三方：fair、url_hash Nginx 常见的优化配置 调整 worker_processes：指 Nginx 要生成的 Worker 数量。最佳实践是每个 CPU 运行 1 个工作进程。 最大化 worker_connections。 启用 Gzip：压缩文件大小，减少客户端 HTTP 的传输带宽，因此提高了页面加载速度。 为静态文件启用缓存。 禁用 access_logs：访问日志记录，它记录每个 Nginx 请求，因此消耗了大量 CPU 资源，从而降低了 Nginx 性能。 参考资料Nginx 的这些妙用，你都 get 到了吗]]></content>
      <categories>
        <category>NGINX</category>
      </categories>
      <tags>
        <tag>NGINX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F06%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式的动机对于一个系统的某些类而言，无须创建多个实例。举个例子– Windows 任务管理器、在正常情况下，无论启动任务管理器多少次，Windows 系统始终只能弹出一个任务管理器窗口。也就是说，在一个Windows 系统中，任务管理器存在唯一性。这样设计有两个原因：第一，如果能弹出多个窗口，且这些窗口的内容完全一致，全部是重复对象，这势必会浪费系统资源（任务管理器需要获取系统运行时的诸多信息，这些信息的获取需要消耗一定的系统资源，包括 CPU 资源及内存资源等），而且根本没有必要显示多个内容完全相同的接口；第二，如果弹出的多个窗口不一致，问题就更加严重了，这意味着在某一瞬间系统资源使用情况和进程。服务等信息存在多个状态，例如任务管理器窗口 A 显示“CPU 使用率”为 10%，窗口B显示“CPU 使用率”为 15%，到底哪个才是正确的？这会给用户带来误解，更不可取。由此可见，确保 Windows 任务管理器在系统中有且仅有一个非常重要。 在实际开发中也经常遇到类似的情况，为了节约系统资源，有时需要确保系统中某个类只有唯一一个实例，当这个唯一实例创建成功之后，无法再创建一个同类型的其他对象，所有的操作都只能基于这个唯一实例。为了确保对象的唯一性，可以通过单例模式来实现，这就是单例模式的动机所在。 单例模式概述下面来模拟实现 Windows 任务管理器。假设任务管理器的类名为 TaskManager，在 TaskManager 类中包含了大量的成员方法，例如构造函数 TaskManager()，显示进程的方法 displayProcesses()，显示服务的方法 displayServices()等，该类的示意代码如下： 123456789101112131415161718class TaskManager&#123; // 初始化窗口 public TaskManager() &#123; ... &#125; // 显示进程 public void displayProcesses() &#123; ... &#125; // 显示服务 public void displayServices() &#123; ... &#125; ...&#125; 为了实现 Windows 任务管理器的唯一性，通过以下3步对TaskManager类进行重构： （1）由于每次使用 new 关键字来实例化 TaskManager 类时都将产生一个新对象，为了确保 TaskManager 实例的唯一性，需要禁止类的外部直接引用使用 new 来创建对象，因此需要将 TaskManager 的构造函数的可见性改为 private，如下 1private TaskManager() &#123; ... &#125; （2）将构造函数的可见性改为 private 后，虽然类的外部不能在使用 new 来创建对象，但是在 TaskManager 的内部还是可以创建对象的，可见性只对类外有效。因此，可以在 TaskManager 中创建并保存这个唯一实例。为了让外界可以访问这个唯一实例，需要在 TaskManager 中定义一个静态的 TaskManager 类型的私有变量，代码如下： 1private static TaskManager tm = null; （3）为了保证成员变量的封装性，将 TaskManager 类型的 tm 对象的可见性设置为 private，但外界该如何使用该成员变量并何时实例化该成员变量呢？答案是增加一个工友的静态方法，如下： 123456public static TaskManager getInstance() &#123; if (tm == null) &#123; tm = new TaskManager(); // 自行实例化 &#125; return tm;&#125; 在 getInstance() 方法中首选判断 tm 对象是否存在，如果不存在，则使用 new 关键字创建一个新的 TaskManager 类型的 tm 对象，再返回新创建的 tm 对象；否则直接返回已有的 tm 对象。需要注意的是 getInstance() 方法的修饰符。 首先它应该是一个 public 方法，以便外界其他对象使用；其次它使用了 static 关键字，即它是一个静态方法，在类外可以直接通过类名来访问，而无须创建 TaskManager 对象。事实上，在类外也无法创建 TaskManager 对象，因为构造函数是私有的。最终整合的代码如下： 12345678910111213class TaskManager &#123; private static TaskManager tm = null; private TaskManager() &#123; ... &#125; // 初始化窗口 public void displayProcesses() &#123; ... &#125; // 显示进程 public void displayServices() &#123; ... &#125; // 显示服务 public static TaskManager getInstance() &#123; if(tm === null) &#123; tm = new TaskManager(); &#125; return tm; &#125;&#125; 上述代码是单例模式的一种最典型实现方式，有了以上基础，理解单例模式的定义和结构就非常容易了。单例模式定义如下： 单例模式：确保某一个类只有一个实例，而且自行实例化并向这个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。单例模式是一种对象性创建模式。 单例模式有 3 个要点：（1）某个类只有有一个实例；（2）它必须自行创建这个实例；（3）它必须自行向整个系统提供这个实例。单例模式的结构图如图所示： 负载均衡器的设计Sunny 软件公司承接了一个服务器负载均衡（Load Balance）软件的开发工作，该软件运行在一台负载均衡服务器上，可以将并发访问和数据流量分发到服务器集群中的多台设备上进行并发处理，提高系统的整体处理能力。由于集群汇总的服务器需要动态删减，且客户端请求需要统一分发，因此需要确保负载均衡器的唯一性，即只能有一个负载均衡器来负责服务器的管理和请求的分发，否则会带来服务器状态的不一致以及请求分配冲突等问题。 Sunny 公司开发人员通过分析和权衡，决定使用单例模式来设计该负载均衡器。将负载均衡器 LoadBalancer 设计为单例类，其中包含一个存储服务器信息的集合 serverList，每次在 serverList 中随机选择一台服务器来相应客户端的请求，实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 负载均衡器 LoadBalancer:单例类，真实环境该类非常复杂，包括大量初始化的工作和 * 业务方法，考虑到代码的可读性和易理解性，只列出部分与模式相关的核心代码 */public class LoadBalancer &#123; // 私有静态成员变量，存储唯一实例 private static LoadBalancer instance = null; // 服务器集合 private List serverList = null; private LoadBalancer() &#123; serverList = new ArrayList(); &#125; public static LoadBalancer getLoadBalancer() &#123; if (instance == null) &#123; instance = new LoadBalancer(); &#125; return instance; &#125; /** * 增加服务器 * @param server */ public void addServer(String server) &#123; serverList.add(server); &#125; /** * 删除服务器 * @param server */ public void removeServer(String server) &#123; serverList.remove(server); &#125; /** * 使用 Random 类随机获取服务器 * @return */ public String getServer() &#123; Random random = new Random(); int i = random.nextInt(serverList.size()); return (String) serverList.get(i); &#125;&#125; 1234567891011121314151617181920212223242526272829public class Client &#123; public static void main(String[] args) &#123; // 创建 4 个 LoadBalancer 对象 LoadBalancer balancer1, balancer2, balancer3, balancer4; balancer1 = LoadBalancer.getLoadBalancer(); balancer2 = LoadBalancer.getLoadBalancer(); balancer3 = LoadBalancer.getLoadBalancer(); balancer4 = LoadBalancer.getLoadBalancer(); // 判断服务器复制均衡器是否相同 if (balancer1 == balancer2 &amp;&amp; balancer2 == balancer3 &amp;&amp; balancer3 == balancer4) &#123; System.out.println("服务器负载均衡器具有唯一性"); &#125; // 增加服务器 balancer1.addServer("Server 1"); balancer1.addServer("Server 2"); balancer1.addServer("Server 3"); balancer1.addServer("Server 4"); // 模拟客户端请求的分发 for(int i = 0; i &lt; 10; i++) &#123; String server = balancer1.getServer(); System.out.println("分发请求至服务器： " + server); &#125; &#125;&#125; 编译并运行程序，输出结果如下： 虽然创建了 4 个 LoadBalancer 对象，但是它们实际上是同一个对象，因此，通过使用单例模式可以确保 LoadBalancer 对象的唯一性。 饿汉式单例与懒汉式单例的讨论Sunny 公司开发人员使用了单例模式实现了负载均衡器的设计，但是在实际使用中出现了一个非常严重的问题，当负载均衡器在启动过程中用户再次启动负载均衡器时，系统无任何异常，但当客户端提交请求时出现请求分发失败，通过仔细分析发现原来系统中还是存在多个负载均衡器对象导致分发时目标服务器不一致，从而产生冲突。为什么会这样？ 现在对负载均衡器的实现代码进行再次分析，当第一次调用 getLoadBalancer() 方法创建并启动负载均衡器时， instance 对象为 null 值，因此系统将执行代码 instance = new LoadBalancer()，在此过程中，由于要对 LoadBalancer 进行大量初始化工作，需要一段时间来创建 LoadBalancer 对象。而在此时，如果再一次调用 getLoadBalancer() 方法（通常发生在多线程环境中），由于 instance 尚未创建成功，仍为 null 值，判断条件 instance == null 为真值，因此代码 instance = new LoadBalancer() 将再次执行，导致最终创建了多个 instance 对象，这违背了单例模式的初衷，也导致系统发生运行错误。 如何解决该问题？至少有两种解决方案，在此之前，先介绍一下单例类的两种不同实现方式—饿汉式单例类和懒汉式单例类 饿汉式单例类饿汉式单例类是实现起来最容易的单例类，其代码如下： 12345678class EagerSingleton &#123; private static final EagerSingleton instance = new EagerSingleton(); private EagerSingleton() &#123;&#125; public static EagerSingleton getInstance() &#123; return instance; &#125;&#125; 当类被加载时，静态变量 instance 会被初始化，此时类的私有构造函数会被调用，单例类的唯一实例将被创建。如果使用饿汉式单例类实现负责均衡器 LoadBalancer 类的设计，则不会创建出多个单例对象的情况，可确保单例对象的唯一性。 懒汉式单例类与线程锁定除了饿汉式单例，还有一种经典的懒汉式单例，就是前面的负载均衡器 LoadBalancer 类的实现方式。由之前的代码可以看出，懒汉式单例在第一次调用 getInstance() 方法时实例化，在类加载时并不自行实例化，这种技术又称为延迟加载技术，即需要的时候再加载实例，为了避免多个线程同时调用 getInstance() 方法，可以使用关键字 synchronized，代码如下： 123456789101112class LazySingleton &#123; private static LazySingleton instance = null; private LazySingleton() &#123;&#125; synchronized public static LazySingleton getInstance() &#123; if (instance == null) &#123; instance = new LazySingleton(); &#125; return instance; &#125;&#125; 该懒汉式单例类在 getInstance() 方法面前增加了关键字 synchronized 进行线程锁定，以处理多个线程同时访问的问题。上述代码虽然解决了线程安全问题，但是每次调用 getInstance() 时都需要进行线程锁定判断，在多线程高并发访问环境中，将会导致系统性能大大降低。继续对懒汉式单例进行改进，事实上，无须对整个 getInstance() 方法进行锁定，只需锁定代码 instance = new LazySingleton() 即可。如下： 12345678public static LazySingleton getInstance() &#123; if (instance == null) &#123; synchronized (LazySingleton.class) &#123; instance = new LazySingleton(); &#125; &#125; return instance;&#125; 其实这样子也没有解决问题。原因如下：如果某一瞬间线程 A 和线程 B 都在调用 getInstance() 方法，此时 instance 对象为 null 值，均能通过 instance == null 的判断，由于实现了 synchronized 加锁机制，线程 A进入synchronized 锁定的代码中执行实例创建代码。但当 A 执行完毕时，线程 B并不知道实例已经创建，将继续创建新的实例，导致产生多个单例对象，因此需要进一步改进，在synchronized 锁定代码中再进行一次 instance == null 判断，这种方式称为双重检查锁定。完整代码如下： 12345678910111213141516171819class LazySingleton &#123; private volatile static LazySinleton instance = null; private LazySingleton() &#123;&#125; public static LazySingleton getInstance() &#123; // 第一重判断 if (instance == null) &#123; // 锁定代码块 synchronized(LazySingleton.class) &#123; // 第二重判断 if (instance == null) &#123; instance = new LazySingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 需要注意的是，如果使用双重检查锁定来实现懒汉式单例类，需要在静态成员变量 instance 之前增加修饰符 volatile，被 volatile 修饰的成员变量可以确保多个线程都能够正确处理，且该代码只能在 JDK 1.5 及以上版本才能正确执行。由于 volatile 关键字会屏蔽 Java 虚拟机所做的一些代码优化，可能会导致系统运行效率降低，因此使用双重检查来实现单例模式也不是一种完美的实现方式。 饿汉式单例类与懒汉式单例类比较饿汉式单例类在类被加载时就将自己实例化，它的优点在于无须考虑多线程访问问题，可以确保实例的唯一性；从调用速度和反应时间来说，由于单例对象一开始就得以创建，因此要优于懒汉式单例。但是无论系统在运行时是否需要使用该单例对象，由于在类加载时该对象就需要创建，因此从资源利用效率角度来讲，饿汉式单例不及懒汉式单例，而且在系统加载时由于需要创建饿汉式单例对象，加载时间可能会比较长。 懒汉式单例类在第一次使用时创建，无须一直占用系统资源，实现了延迟加载，但是必须处理好多个线程同时访问的问题，特别是当单例类作为资源控制器，在实例化时必然涉及资源初始化，而资源初始化很有可能耗费大量时间，这意味着出现多线程同时首次引用此类的几率变得比较大，需要通过双重检查锁定机制进行控制，这将导致系统性能受到一定影响。 一种更好的单例实现方法饿汉式单例类不能实现延迟加载，不管将来用不用，它始终占据内存；懒汉式单例类线程安全控制烦琐，而且性能受影响。无论是饿汉式单例还是懒汉式单例都存在问题，接下来就介绍一种更好的方法，称之为 Initialization on Demand Holder（IoDH）。 实现 IoDH 时，需在单例类中增加一个静态内部类，在该内部类中创建单例对象，再将该单例对象通过 getInstance() 方法返回给外部使用，代码如下： 123456789101112131415161718192021class Singleton &#123; private Singleton() &#123; &#125; private static class HolderClass&#123; private static final Singleton instance = new Singleton(); &#125; public static Singleton getInstance() &#123; return HolderClass.instance; &#125; public static void main(String args[]) &#123; Singleton s1, s2; s1 = Singleton.getInstance(); s2 = Singleton.getInstance(); System.out.println(s1 == s2); &#125;&#125; 编译并运行上述代码，运行结果为 true，即创建的单例对象 s1 和 s2 为同一对象。由于静态单例对象没有作为 Singleton 的成员变量直接实例化，因此类加载时不会实例化 Singleton，第一次调用 getInstance() 时将加载内部类 HolderClass，在该内部类中定义了一个 static 类型的变量 instance，此时会首先初始化这个成员变量，由 Java 虚拟机来保证其线程安全性，确保该成员变量只能初始化一次。由于 getInstance() 方法没有任何线程锁定，因此其性能不会造成任何影响。 通过使用 IoDH，既可以实现延迟加载，又可以保证线程安全，不影响系统性能，因此，IoDH不失为一种比较好的 Java 语言单例模式实现方式；其缺点是与编程语言本身的特性相关，很多面向对象语言不支持 IoDH。 单例模式总结单例模式作为一种目标明确，结构简单，理解容易的设计模式，在软件开发中使用频率相当高，在很多应用软件和框架中得以广泛应用。 主要优点 单例模式提供了对唯一实例的受控访问。因为单例类封装了它的唯一实例，所以它可以严格控制客户怎样以及何时访问它。 由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象，单例模式无疑可以提高系统的性能。 允许可变数目的实例。基于单例模式，开发人员可以进行扩展，使用与控制单例对象相似的方法来获得指定个数的实例对象，既节省资源系统，又解决了由于单例对象共享过多有损性能的问题。 主要缺点 由于单例模式中没有抽象层，因此单例类的扩展有很大的困难。 单例类的职责过重，在一定程度上违背了单一原则。因为单例类既提供了业务方法，又提供了创建对象的方法（工厂方法），将对象的创建和对象本身的功能耦合在一起。 很多面向对象语言的运行环境都提供了自动垃圾回收技术，因此，如果实例化的共享对象长时间不被利用，系统会认为它是垃圾，会自动销毁并回收资源，下次利用时又将重新实例化，这将导致共享的单例对象状态的丢失。 使用场景 系统只需要一个实例对象。例如，系统要求提供一个唯一的序列号生成器或资源管理器，或者需要考虑资源消耗太大而只允许创建一个对象。 客户调用类的单个实例只允许使用一个公共访问点，除了该公共访问点，不能通过其他途径访问该实例。 参考资料《设计模式的艺术——软件开发人员内功修炼之道》 – 刘伟]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之jstat案例分析-Young GC]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F02%2FJVM%E4%B9%8Bjstat%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-Young-GC%2F</url>
    <content type="text"><![CDATA[百万级商机的BI系统​ 有这么一个场景，有一个服务于百万级商机的BI系统。所谓BI系统，简单来说，就是一个平台有数十万甚至上百万的商家在你的平台上做生意，会使用你的这个平台系统，此时会产生大量的数据。然后基于这些数据我们需要为商家提供一些数据报表，比如：每个商家每天有多少访客？有多少交易？付费转化率是多少？当然实际情况会比这个更复杂，这里只是说个概念。 ​ 此时就需要一套BI系统，所谓BI，全称是Business Intelligence，就是“商业智能”。就是把一些商家平时日常经营的数据收集起来进行分析，然后把各种数据报表展示给商家的一套系统。而所谓的商业智能，指的就是给你看一些数据报表，然后让你平时更好地了解自己的经营情况，然后让老板“智能”地去调整经营策略，提升业绩。 ​ 所以类似这样的一个BI系统，大致的运行逻辑如下所示： 首先，从我们提供给商家日常使用的一个平台上会采集出来很多商家日常经营的数据； 接着可以对这些经营数据依托各种大数据计算平台，比如Hadoop、Spark、Flink等技术进行海量数据的计算，计算出各种各样的数据报表； 然后我们需要将计算好的各种数据分析报表都放入一些存储中，比如MySQL、Elasticsearch、HBase都可以存放类似的数据； 最后，就是基于MySQL、HBase、Elasticsearch中存储的数据报表，基于Java开发出来一个BI系统，通过这个系统把各种存储好的数据暴露给前端，允许前端基于各种条件对存储的数据进行复杂的筛选和分析。 ​ 这个流程如图所示： 刚开始上线时的架构部署​ 我们这里重点作为案例分析的就是上述场景中的“BI系统”，其他环节都跟大数据相关的技术有关联的，暂时先不care。 ​ 刚开始的时候BI系统使用的商家是不多的，因为即使在一个庞大的互联网大厂里，虽然大厂本身积累了大量商家，但是要针对他们上线一个付费产品，刚开始未必所有人都买账，所以一开始系统上线就少数商家在使用，比如就几千个商家。 ​ 刚开始系统部署非常简单，就是用几台机器来部署上述的BI系统，机器都是普通的4核8G配置。在这个配置下，一般来说给堆内存中的新生代分配的内存都在1.5G左右，Eden区大概也就1G左右的空间，如图： 技术痛点：实时自动刷新报表 + 大数据量报表​ 刚开始，在少数商家的量级下，这个系统是没多大问题，运行的非常良好。但是问题恰恰就出在突然使用系统的商家数量开始暴涨的时候，突然使用系统的商家开始越来越多，例如，当商家的数量级达到几万的时候。此时要给大家说明一个此类BI系统的特点，就是在BI系统中有一种数据报表，它是支持前端页面有一个JS脚本，自动每隔几秒钟就发送请求到后台刷新一下数据的，这种报表称之为“实时数据报表” ​ 那么大家设想一下，假设仅仅就几万商家作为你的系统用户，很可能同一时间打开那个实时报表的商家就有几千个，然后每个商家打开实时报表后，前端页面都会每隔几秒钟发送请求到后台加载最新数据，基本上会出现BI系统部署的每台机器每秒的请求会达到几百个，这里我们假设就是每秒500个请求吧。然后每个请求都会加载出来一张报表需要的大量数据，因为BI系统可能还需要针对那些数据进行内存中的现场计算加工一下，才能返回给前端页面展示，根据我们之前的测算，每个请求大概需要加载出来100KB的数据进行计算，因此每秒500个请求，就需要记载出来50MB的数据到内存中进行计算，如图： 没什么大影响的频繁Young GC​ 在上述系统运行模型下，基本上每秒会加载50MB的数据到Eden区中，只要区区20s，就会迅速填满Eden区，然后触发一次Young GC对新生代进行垃圾回收。当然1G左右的Eden进行Young GC速度相对是比较快的，可能也就几十ms的时间就可以搞定了。所以其实对系统性能影响并不大，而且上述BI系统场景下，基本上每次Young GC后存活对象可能就几十MB，甚至是几MB。 ​ 所以如果仅仅只是这样的话，那么大家可能会看到如下场景，BI系统运行20s过后，就会突然卡顿个10ms，但是对终端用户和系统性能几乎是没有影响的。 模拟频繁Young GC场景​ 接着我们会用一段程序来模拟上述BI系统那种频繁Young GC的一个场景，此时JVM参数如下所示： 1-XX:NewSize=104857600 -XX:MaxNewSize=104857600 -XX:InitialHeapSize=209715200 -XX:MaxHeapSize=209715200 -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=3145728 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log ​ 大家只要注意一下上述我们把堆内存设置为了200MB，把年轻代设置为了100MB，然后Eden区是80MB，每块Survivor区是10MB，老年代也是100MB。我们把案例中的内存大小适当缩小了一些，这样方便在本地电脑进行试验。 示例程序123456789101112131415161718public class Demo1 &#123; public static void main(String[] args) throws Exception &#123; Thread.sleep(30000); while (true) &#123; loadData(); &#125; &#125; private static void loadData() throws Exception &#123; byte[] data = null; for(int i = 0; i &lt; 50; i++) &#123; data = new byte[100 * 1024]; &#125; data = null; Thread.sleep(1000); &#125;&#125; ​ 针对这段示例程序给大家做一点说明。首先看第一行代码：Thread.sleep(30000);。这里刚开始休眠30s，是为了启动程序后，让我们找到这个程序的PID，也就是进行ID，然后再执行jstat命令来观察运行时的JVM的状态。 ​ 接着看loadData()方法内的代码，它会循环50次，模拟每秒50个请求，然后互每次请求都会分配一个100KB的数组，模拟每次请求会从存储中加载100KB的数据，接着会休眠1秒钟，模拟这一切都是发生在1秒内的。其实这些对象都是短生存周期的对象，所以方法运行结束直接对象都是垃圾，随时可以回收的。然后在main()方法里有一个while(true)循环，模拟系统按照每秒钟50个请求，每个请求加载100KB数据的方式不停地运行，除非我们手动终止程序，否则永不停歇。 通过jstat观察程序的运行状态​ 接着我们使用预定的JVM参数启动程序，此时程序会先进入一个30秒的休眠状态，此时尽快执行JPS命令，查看一下我们启动程序的进程ID，如下图： ​ 此时会发现我们运行的Demo1这个程序的JVM进程ID是51464，然后尽快执行下述jstat命令：jstat -gc 51464 1000 1000。它的意思是针对51464这个进程统计JVM运行状态，同时每隔1秒钟打印一次统计信息，连续打印1000次。然后我们就让jstat开始统计运行，每隔一秒它都会打印一行新的统计信息，过了几十秒后可以看到如下图所示的统计信息： ​ 接着我们一点点来分析这个图。首先我们先看如下图所示的一段信息： ​ 这个EU，就是之前我们所说的Eden区被使用的容量，可以发现它刚开始是3MB左右的内存使用量。接着从我们程序开始运行，会发现每秒钟都会有对象增长，从3MB左右到7MB左右，接着是12MB，17MB，22MB，每秒都会新增5MB左右的对象。这个跟我们写的代码是完全吻合的，我们就是每秒钟会增加5MB左右的对象。然后当Eden区使用量达到70多MB的时候，再要分配5MB的对象就失败了，此时就会触发一次Young GC，然后大家继续看下图： ​ 注意看上面红圈里的内容，大家会发现，Eden区的使用量从70多MB降低为1MB多，这就是因为一次Young GC直接回收掉了大部分对象。所以我们现在就知道了，针对这个代码示例，可以清晰地从jstat中看出来，对象增速大致为5MB每秒，大致在十几秒左右会触发一次Young GC。这就是Young GC的触发频率，以及每次Young GC的耗时。接着看下图： ​ 上图清晰告诉你，一次Young GC回收70多MB对象，大概就1毫秒，所以Young GC其实是很快的，即使回收800MB的对象，也就10毫秒那样。所以如果是线上系统，Eden区800MB的话，每秒新增对象50MB，十多秒一次Young GC，也就10毫秒左右，系统卡顿10毫秒，几乎没什么大影响。所以我们继续推论，在这个示例中，80MB的Eden区，每秒新增对象5MB，大概十多秒触发一次Young GC，每次Young GC耗时在1毫秒左右。 ​ 那么每次Young GC过后存活的对象呢？简单看上图，S1U就是Survivor中被使用的内存，之前一直都是0，在一次Young GC过后变成了675KB，所以一次Young GC后也就存活675KB的对象而已，轻松放入10MB的Survivor中。 ​ 而且大家注意上上图中的OU，那是老年代被使用的内存量，在Young GC前后都是0。说明这个系统运行良好，Young GC都不会导致对象进入老年代，这就几乎不需要什么优化了，因为几乎可以默认老年代对象增速为0，Full GC发生频率趋向于0，对系统无影响。 ​ 所以回顾一下，通过这个示例程序的运行，是不是可以通过jstat分析出来以下信息： 新生代对象增长的速率 Young GC的触发频率 Young GC的耗时 每次Young GC后有多少对象是存活下来的 每次Young GC过后有多少对象进入了老年代 老年代对象的增长速率 Full GC的触发频率 Full GC的耗时]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程杂记Ⅱ]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F02%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%9D%82%E8%AE%B0%E2%85%A1%2F</url>
    <content type="text"><![CDATA[Java内存模型​ Java线程之间的通信采用的是共享内存模型，这里提到的共享内存模型指的就是Java内存模型（Java Memory Model，简称JMM），JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量额的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓存区，寄存器以及其他的硬件和编译器优化。 ​ Java内存模型主要有read、load、use、assign、store、write这几个动作。举一个例子，下面这么一段代码： 12345678910111213141516171819202122232425262728293031323334public class HelloWorld &#123; private int data = 0; public void increment() &#123; data++; &#125; public int getData() &#123; return data; &#125; public static void main(String[] args) &#123; final HelloWorld helloWorld = new HelloWorld(); Thread thread1 = new Thread() &#123; @Override public void run() &#123; helloWorld.increment(); System.out.println("=====线程1：" + helloWorld.getData() + " ====="); &#125; &#125;; Thread thread2 = new Thread() &#123; @Override public void run() &#123; helloWorld.increment(); System.out.println("=====线程2：" + helloWorld.getData() + " ====="); &#125; &#125;; thread1.start(); thread2.start(); &#125;&#125; ​ 通过上面的代码，我们来梳理一下线程与共享变量之间的关系： Java并发之原子性、有序性和可见性原子性​ 原子性指的是一个或者多个操作在CPU执行的过程中不被中断的特性。 ​ 线程切换带来的原子性问题 ​ Java并发程序都是基于多线程的，操作系统为了充分利用CPU的资源，将CPU分成若干个时间片，在多线程环境下，线程会被操作系统调度进行任务切换。 ​ 为了直观了解什么是原子性，我们看下面哪些操作是原子性操作 123int count = 0;count++;int a = count; ​ 上面展示语句中，除了语句1是原子操作，其它两个语句都不是原子性操作，下面来分析一下语句2。其实语句2在执行的时候，包含三个指令操作： 指令1：首先。先把变量count从内存加载到CPU的寄存器 指令2：之后，在寄存器中执行 +1 操作 指令3：最后，将结果写入内存 ​ 对于上面的三条指令来说，如果线程A在指令1执行后做线程切换，线程A和线程B按照下图的序列执行，那么我们会发现两个线程都执行了count += 1的操作，但是得到的结果不是我们期待的2，而是1。 ​ 操作系统做任务切换，可以发生在任何一条CPU指令执行完 有序性​ 有序性指的是程序按照代码的先后顺序执行 ​ 编译优化带来的有序性问题 ​ 为了性能优化，编译器和处理器会进行指令重排序，有时候会改变程序中语句的先后顺序，比如程序： 12345678910flag = false;// 线程1prepare(); // 准备资源falg = true;// 线程2while(!flag) &#123; Thread.sleep(1000);&#125;execute(); // 基于准备好的资源执行操作 ​ 重排序之后，让flag = true先执行了，会导致线程2直接跳过while等待，执行某段代码，结果prepare()方法还没执行，资源还没准备好，此时就会导致代码逻辑出现异常。 ​ synchronized（具有有序性、原子性、可见性）表示锁在同一时刻中一个线程进行获取，当锁被占用后，其他线程只能等待。在单例模式的实现上有一种双重检验锁定的方式 1234567891011121314151617181920public class Singleton &#123; private Singleton() &#123; &#125; private volatile static Singleton instance = null; public static Singleton getInstance() &#123; if(instance == null) &#123; synchronized (Singleton.class) &#123; if(instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; ​ 我们先看instance = new Singleton()的未被编译器优化的操作： 指令1：分配一块内存M； 指令2：在内存M初始化Singleton对象； 指令3：然后M的地址赋值给instance变量； 编译器优化后的操作指令： 指令1：分配一块内存M； 指令2：将M的地址赋值给instance变量； 指令3：然后内存M上初始化Singleton对象。 ​ 现有A，B两个线程，我们假设线程A先执行了getInstance()方法，当执行编译器优化后的操作指令2时（此时未完成对象的初始化），这时发生了线程切换，那么线程B进入，刚好执行到第一次判断instance == null会发现instance不等于null了，所以直接返回instance，而此时的instance，是没有初始化过的。 可见性​ 可见性指的是当一个线程修改了共享变量后，其它线程能够立刻得知这个修改。 缓存导致的可见性问题 ​ 让我们回顾一下上面讲的java内存模型： 我们定义的所有变量都存储在主内存中。 每个线程都有自己独立的功能内存，里面保存该线程使用到的变量的副本（主内存中该变量的一份拷贝） 线程对共享变量所有的操作都必须在自己的工作内存中进行，不能直接从主内存中读写（不能越级） 不同线程之间也无法直接访问其他线程的工作内存中的变量，线程间变量值的传递需要通过主内存来进行。（同级之间不能相互访问） ​ 线程1对共享变量的修改要被线程2及时看到的话，要经过如下步骤： 把工作内存1中更新的变量刷新到主内存中； 把主内存中的变量的值更新到工作内存2中 我们可以使用synchronized、volatile、final来保证可见性 volatile​ volatile关键字是用来保证可见性和有序性，在有些罕见的条件下，可以有限的保证原子性，但它不是用来保证原子性的。基本原理是当一个线程对一个volatile修饰的共享变量进行修改后，会强制线程将这个修改后的副本刷入主内存，同时，让其他线程对这个共享变量的副本进行失效，让他们重新去主内存中读取数据，从而保证可见性。 ​ 那volatile是如何保证有序性的呢？它是如何避免指令重排的呢？这就涉及了Java中的一个原则，叫做happens-before原则。在编译器对代码进行代码重排序之前，要遵守happens-before原则。如果符合happens-before原则，那么就不能胡乱重排，如果不符合这些规则，那就可以自己排序。happens-before规则包括以下几个： 程序次序规则：一个线程内，按照代码顺序，书写前面的操作先行发生于书写后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。比如说在代码里对一个锁的lock.lock()、lock.unlock()、lock.lock()操作，第二个unlock操作要先行发生于第三个的lock操作，而不能重排序成lock.lock()、lock.lock()、lock.unlock()。 volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个volatile变量的读操作。volatile变量写，再读，必须保证是先写，再读。 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。例如thread.start()要先行发生于thread.interrupt()，而不能将thread.interrupt()重排序到thread.start()前面。 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。 线程终结原则：线程中所有的操作都先行发生于线程的终止检测。我们可以通过thread.join()方法结束、thread.isAlive()的返回值手段检测到线程已经终止执行。 对象终结规则：一个对象的初始化完成先行发生于它的finalize()方法的开始。 ​ 这8条规则是避免出现乱七八糟扰乱秩序的指令重排，要求是这几个重要的场景下，要按照顺序来执行。这8条规则之外，可以重排指令。这happens-before规则也说明了为什么volatile为什么能保证它的有序性。因为volatile要求的是，volatile前面的代码一定不能指令重排到volatile变量操作后面，volatile后面的代码也不能指令重排到volatile前面。 ​ volatile在底层是如何保证可见性和有序性的呢？ （1）lock指令：volatile保证可见性 ​ 对volatile修饰的变量，执行写操作的话，JVM会发送一条lock前缀指令给CPU，CPU在计算完之后会立即将这个值写会主内存，因为同时有MESI缓存一致性协议，所以各个CPU都会对总线进行嗅探，自己本地缓存中的数据是否被别人修改。 ​ 如果发现别人修改了某个缓存的数据，那么CPU就会将自己本地缓存的数据过期掉，然后这个CPU上执行的线程在读取这个变量的时候，就会从主内存重新加载最新的数据了。 ​ lock前缀指令+ MESI缓存一致性协议 （2）内存屏障：volatile禁止指令重排序 ​ 先简单了解两个指令： Store：将处理器缓存的数据刷新到内存中 Load：将内存存储的数据拷贝到处理器的缓存中 屏障类型 指令示例 说明 LoadLoad Load1;LoadLoad;Load2 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的操作 StoreStore Store1;StoreStore;Store2 该屏障确保Store立刻刷新数据到内存（使其对其它处理器可见）的操作先于Store2及其后所有存储指令的操作 LoadStore Load1;LoadStore;Store2 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作 StoreLoad Store1;StoreLoad;Load2 该屏障确保Store1立刻刷新到内存的操作先于Load2及其后所有装载指令的操作。它会使屏障之前的所有内存访问指令（存储指令和访问指令）完成之后，才执行改屏障之后的内存访问指令 1234Load1:int localVar = this.variableLoadLoad屏障int localVar = this.variable2 12345Store1:this.variable = 1StoreStore屏障Store2:this.variable = 2 ​ 那么volatile的作用是什么呢？ 123volatile variable = 1this.variable = 2 // store操作int localVariable = this.variable // load操作 ​ 每个volatile写操作前面，加StoreStore屏障，禁止上面的普通写和他重排；每个volatile写操作后面，加StoreLoad屏障，禁止跟下面的volatile读/写重排。 ​ 每个volatile读操作后面，加LoadLoad屏障，禁止下面的普通读和volatile读重排；每个volatile读操作后面，加LoadStore屏障，禁止下面的普通写和volatile读重排。 ​ volatile经常用于以下场景：状态标记变量、Double Check、一个线程写多个线程读。 参考资料 Java并发之原子性、有序性、可见性]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池杂记]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F27%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[简单说一下Java线程池的底层工作原理​ 一般情况下，系统是不会说无限制地创建大量的线程，会构建一个线程池，保持一定数量的线程，让他们执行各种各样的任务，线程执行完任务后，不要销毁自己，继续去等待执行下一个任务。这样可以避免频繁地创建线程和销毁线程。 12345678ExecutorService threadPool = Executors.newFixedThreadPool(3);threadPool.submit(new Callable&lt;Object&gt;() &#123; @Override public Object call() throws Exception &#123; return null; &#125;&#125;); ​ 大概流程是这样的：提交任务，先看一下线程池里的线程数量是否小于corePoolSize，也就是上面代码的3。如果小于，直接创建一个线程出来执行你的任务；执行完任务之后，这个线程是不会死掉的，它会尝试从一个无界的LinkedBlockingQueue里获取新的任务，如果没有新的任务，此时就会阻塞住，等待新的任务到来。 ​ 应用持续提交任务，上述流程反复执行，只要线程池的线程数量小于corePoolSize，都会直接创建新线程来执行这个任务，执行完了就尝试从无界队列里获取任务，知道线程里有corePoolSize个线程；接着再次提交任务，会发现线程数量已经跟corePoolSize一样大了，此时就会直接把任务放入队列中就可以了，线程会争取获取任务执行。如果所有人的线程此时都在执行任务，那么无界队列里的任务就可能会越来越多。 线程池的核心配置参数​ 上面的那段代码：Executors.newFixedThreadPool(3);，进去里面查看源码，是这样子的： 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; ​ 创建一个线程池就是这样子的。除了那个0L，参数依次是corePoolSize、maximumPoolSize，keepAliveTime，queue。如果你不用fixed之类的线程池，可以自己通过这个构造函数创建自己的线程池。 1234corePoolSize: 3maximumPoolSize: 200keepAliveTime: 60snew ArrayBlockingQueue&lt;Runnable&gt;(200) ​ 如果你把queue做成有界队列，比如上面的new ArrayBlockingQueue(200)，假设corePoolSize个线程都在繁忙地工作，大量的任务进入有界队列，队列满了，如果你的maximumPoolSize是比corePoolSize大的，此时会继续创建额外的线程放入线程池里，来处理这些任务，然后超过corePoolSize数量的线程如果处理完了一个任务也会尝试从队列里去获取任务来执行。 ​ 如果额外线程都创建完了去处理任务了，队列还是满了，此时还有新的任务，那该怎么办？只能reject掉。目前有几种reject策略，可以传入RejectExecutionHandler AbortPolicy DiscardPolicy DiscardOldestPolicy CallerRunsPolicy 自定义 ​ 如果后续队列里，慢慢没有任务了，线程空闲了，超过corePoolSize的线程会自动释放掉，在keepAliveTime之后就会释放。在具体场景中，我们可以根据上述原理定制自己的线程池，来考虑corePoolSize的数量、队列类型、最大线程数量、拒绝策略和线程释放时间等等。一般常用的是fixed线程。 线程池的队列满了之后会发生什么事情​ 这个要分情况考虑，如果maximumPoolSize是Integer.MAX_VALUE，那么线程池会创建无限多的线程，最终有可能导致内存溢出或者CPU负载过高而服务器挂掉。如果maximumPoolSize不是Integer.MAX_VALUE，而线程池的队列是无界队列，那么有可能系统会创建大量任务塞进队列中，最终导致内存溢出；如果队列是有界的，并且maximumPoolSize不是Integer.MAX_VALUE，那么有可能部分任务没被执行到而被reject掉。可以自定义一个reject策略，如果线程池无法执行更多的任务，此时建议可以把这个任务信息持久化写入到磁盘里去，后台专门启动一个线程，后续等待线程池的工作负载降低了，可以慢慢地从磁盘读取之前持久化的任务，重新提交到线程池里去执行。 线上机器突然宕机，如果处理线程池阻塞队列中的请求​ 服务器突然宕机，会导致线程池里积压的任务丢失。可以这么处理，如果你要提交一个任务到线程池里去，在提交之前，先在数据库里插入这个任务的信息，更新它的状态：未提交。已提交、已完成。提交成功之后，更新它的状态是已提交状态。 ​ 系统重启，后台线程去扫描数据库里的未提交和已提交状态的任务，可以把任务的信息读取出来，重新提交到线程池里去，继续执行。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程杂记]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F23%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[synchronized关键字的底层原理​ synchronized底层的原理，是跟jvm指令和monitor有关系的。你如果用到了synchronized关键字，在底层编译后的jvm指令中，会有monitorenter和monitorexit两个指令。 123monitorenter // 代码对应的指令monitorexit ​ 那么monitorenter指令执行的时候会干什么呢？每个对象都有一个关联的monitor。比如一个实例对象就有一个monitor，一个类的Class对象也有一个monitor，如果要对这个对象加锁，那么必须先获取这个对象关联的monitor的lock锁。 ​ 它的原理和思路大概是这样的：monitor里面有一个计数器，从0开始。如果一个线程要获取monitor的锁，就看看它的计数器是不是0，如果是0的话，那么说明没人获取锁，它就可以获取锁了，然后对计数器加1。 ​ 这个monitor的锁是支持重入加锁的，什么意思呢？好比下面的代码片段： 12345678synchronized(myObject) &#123; // 一大堆代码 synchronized(myObject) &#123; // 一堆代码 &#125;&#125; ​ 加锁，一般来说都是必须对同一个对象进行加锁。如果一个线程第一次synchronized那里，获取到了myObject对象的monitor的锁，计数器加1，然后第二次synchronized那里，会再次获取myObject对象的monitor的锁，这个就是重入加锁了，然后计数器会再次加1，变成2。 ​ 这个时候，其他的线程在第一次synchronized那里，会发现myObject对象的monitor锁的计数器是大于0的，意味着被别人加锁了，然后此时线程就会进入block阻塞状态，什么都干不了，就是等着获取锁。 ​ 接着如果出了synchronized修饰的代码片段的范围，就会有一个monitorexit指令在底层。此时获取锁的线程就会对那个对象的monitor的计数器减1，如果有多次重入加锁就会对应多次减1，直到最后计数器是0。然后后面block住阻塞的线程，会再次尝试获取锁，但是只有一个线程可以获取到锁。 CAS的理解及其底层实现原理​ 首先我们先看这一段代码： 12345678910111213141516public class MyObject &#123; int i = 0; // 在一个对象实例的方法上加上synchronized // 同一时间只有一个线程可以进入这个方法 public synchronized void increment() &#123; i++ &#125; public static void main(String[] args) &#123; // 第一个线程同时都基于myObject这一个对象，来执行increment()方法 MyObject myObject = new MyObject(); myObject.increment(); &#125;&#125; ​ 上面的代码中，synchronized的意思就是针对当前执行这个方法的myObject对象进行加锁，此时只有一个线程可以成功地对myObject加锁，可以对它关联的monitor的计数器加1.一旦多个线程并发的去执行synchronized加锁，这就会变成串行化，导致很多线程都要去排队去执行，效率并不是太高。 ​ 再来看下面的这段代码： 1234567891011public class MyObject &#123; // 底层就是基于CAS来进行实现的 AtomicInteger i = new AtomicInteger(0); // 多个线程此时执行这段代码 // 不需要synchronized加锁，也是线程安全的 public void increment() &#123; i.incrementAndGet(); &#125;&#125; ​ CAS（compare and set）。就是设值的时候先进行比较，如果当前的值等于之前获取到的旧值，就说明之前没有其他线程对这个值进行过修改，就可以将我们的新值设置给它。如果当前的值不等于我们之前获取的旧值，说明之前有线程对它进行过修改，那么就设置新值失败。 ​ CAS在底层的硬件级别给你保证一定是原子性的，同一时间只有一个线程可以执行CAS。先比较再设置，其他的线程的CAS同时间去执行就会失败。 ​ ConcurrentHashMap实现线程安全的底层原理​ 多个线程访问同一个数据，为了保证线程安全，可以synchronized加锁，或者CAS进行安全的累加，从而实现多线程场景下安全更新一个数据的效果。在比较多的情况下，可能就是多个线程同时读写一个HashMap。 ​ 为了保证线程安全，可以对HashMap进行synchronized，但没这个必要。HashMap的底层就是一个大的数组，假设多个线程过来，线程1要put的位置是数组[5]，线程2要put的位置是数组[21]，如果使用synchronized加锁，那么线程1跟线程2就要排队执行，但这明显不好，锁的粒度太粗，效率太低。除非是对同一个元素执行put操作，此时多线程才需要进行同步。 ​ 因此，JDK并发包里推出了一个ConcurrentHashMap，它默认实现了线程安全。在JDK1.7以及之前的版本，ConcurrentHashMap底层采取的是分段加锁来实现线程安全。ConcurrentHashMap本身是一个大数组，把它拆成多个数组：[数组1]，[数组2]，[数组3]…，每个数组都对应一个锁，这就是分段加锁。 ​ [数组1]，[数组2]，[数组3] -&gt; 每个数组都对应一个锁，分段加锁 ​ 当多个线程过来，线程1要put的位置是数组1的第五个位置[5]，线程2要put的位置是数组2的第21个位置[21]，那这样子两个线程就互不干扰，可以同时对ConcurrentHashMap赋值。 ​ JDK1.8以及之后，对ConcurrentHashMap做了一些优化和改进，就是细化锁的粒度。在JDK1.8及其之后，ConcurrentHashMap底层还是一个大的数组，但对数组每个元素进行put操作，都是有一个不同的锁。刚开始进行put的时候，如果两个线程都是在数组[5]这个位置进行put。这个时候，就是对数组[5]这个位置进行put的时候，采取的是CAS的策略。 ​ 同一时间，只有一个线程能成功执行这个CAS。就是说，它刚开始先获取一下数组[5]这个位置的值，为null，然后执行CAS，然后线程1比较当前还是null，就可以put进去我的这条数据。同时间，其他线程执行CAS，都会失败。 ​ 这其实也可以算是分段加锁，通过对数组每个元素执行CAS的策略。如果是很多线程对数组里不同的元素执行put，大家互不干扰，没有关系。如果其他线程失败了，发现数组[5]这个位置，已经别人放进去值了，就需要在这个位置基于链表+红黑树进行处理。就是synchronized(数组[5])进行加锁，然后基于链表或者红黑树在这个位置插进去自己的数据。所以说，如果你是对数组里同一个位置的元素进行操作，才会加锁进行串行化处理；如果是对数组不同位置的元素操作，那么此时大家可以并发执行。 ​ 总的来说，在JDK1.8之前，多个数组，分段加锁，一个数组一个锁。在JDK1.8之后，优化细粒度，一个数组，每个元素进行CAS，如果失败说明有人了，此时synchronized对数组元素进行加锁，基于链表+红黑树处理，对数组每个元素加锁。 简单说一下AQS​ AQS，全称 Abstract Queue Synchronizer，中文名叫抽象队列同步器。java 并发包中的 Semahore 和部分Lock底层的实现原理都是利用AQS，例如可重入锁ReentrantLock。现在简单说一下AQS的原理。 ​ AQS内部主要包含state变量，一个存储当前加锁线程的变量和一个等待队列。当多个线程访问时，先通过CAS尝试更新state的变量，如果成功了，将加锁线程的变量更改为自己，并进行后续操作。如果失败了，进入队列等待，等待拥有锁的线程释放锁后唤醒。大概如下图： ​ 接下来会涉及到公平锁和非公平锁。像ReentractLock，默认就是非公平锁。只有ReentrantLock lock = new ReentrantLock(true)时，才是公平锁。那什么是公平锁，什么是非公平锁。例如上面那个图，非公平锁就是，此时线程1释放了资源，唤醒线程2，但此时刚好线程3来进行CAS加锁等操作，并且成功了，那是此时就是线程3获取这个锁，而线程2继续回到等待队列。这就是非公平锁。 ​ 公平锁就是新的线程来获取锁时，会先看等待队列是否有其它线程，有的话就进入等待队列。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[捋一遍MySQL索引结构]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F18%2F%E6%8D%8B%E4%B8%80%E9%81%8DMySQL%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[从一个简单的表开始​ 首先我们先建一个表，语句如下： 1234567create table user( id int primary key, age int, height int, weight int, name varchar(32))engine = innoDb; ​ 然后往这个表中插入一些数据： 12345INSERT INTO user(id,age,height,weight,name)VALUES(2,1,2,7,'小吉');INSERT INTO user(id,age,height,weight,name)VALUES(5,2,1,8,'小尼');INSERT INTO user(id,age,height,weight,name)VALUES(1,4,3,1,'小泰');INSERT INTO user(id,age,height,weight,name)VALUES(4,1,5,2,'小美');INSERT INTO user(id,age,height,weight,name)VALUES(3,5,6,7,'小蔡'); ​ 最后，我们查一下这些数据是否已经放入表中 1select * from user; ​ 结果如下： ​ 可以看到，数据已经完整地放到我们创建的user表中。但是有一个地方需要注意：我们插入的数据都是乱序的，但MySQL好像按照id给我们的数据排了序。为什么会出现MySQL在我们没有显式排序的情况下，默默帮我们排序了？它是在什么时候进行排序的？ 页的引入​ 在操作系统的概念中，当我们往磁盘中取数据，假设要取出的数据的大小是1KB，但是操作系统并不会只取出这1KB的数据，而是会取出4KB的数据，因为操作系统的一个页表项的大小是4KB。那为什么我们只需要1KB的数据，但是操作系统要取出4KB的数据呢？ ​ 这就涉及到一个程序局部性的概念，大概就是“一个程序在访问了一条数据之后，在之后会有极大可能再次访问这条数据和访问这条数据的相邻数据”。所以索性直接加载4KB的数据到内存，下次要访问这一页的数据时，直接从内存中找，可以减少磁盘IO次数。因此磁盘IO是影响程序性能主要的因素，因为磁盘IO和内存IO的速度是不可同日而语的。 ​ 我们回到数据库层面中，重新理解页的概念。假设还是我们刚才插入的那些数据，我们现在要找id=5的数据，依照最原始的方式，我们一定会想到的就是遍历。这也是我们刚开始学计算机的时候最常用的寻找数据的方式。我们来看看，以遍历的方式，我们找到id=5的数据，需要经历几次磁盘IO。 ​ 首先，我们得先从id=1的数据开始读起，然后判断是否是我们需要的数据，如果不是，就再取id=2的数据，再进行判断，循环往复。在MySQL帮我们排好序之后，我们需要经历五次磁盘IO，才能将5号数据找到并读出来。 ​ 如果引入页的概念后，我们是如何读取数据的。 ​ 在引入页的概念后，MySQL会将多条数据存入一个叫“页”的数据结构中，当MySQL读取id=1的数据时，会将id=1数据所在的页整页读到内存中，然后在内存中进行遍历判断，由于内存的IO速度比磁盘高很多，所以相对于磁盘IO，几乎可以忽略不计。 ​ 假设一页可以存4条数据，那么我们第一次读取id=1的数据，并且将id=1到id=4的数据全部读到内存中，这是第一次磁盘IO。第二次将读取id=5的数据到内存中，这是第二次磁盘IO。我们只需要经历2次磁盘IO就可以找到id=5的这条数据。 ​ 但其实，在MySQL的InnoDB引擎中，页的大小是16KB，是操作系统的4倍，而int类型的数据是4个字节，其他类型的数据的字节数通常也在4000字节以内，所以一页是可以存放很多条数据的。而MySQL的数据正是以页为基本单位组合而成的。 ​ 上图是我们目前为止所理解的页的结构，它包含我们的多条数据。另外，MySQL的数据以页组成，那么它有指向下一页的指针和指向上一页的指针。 ​ 到这里，可以回答第一个问题。MySQL实际上就是在我们插入数据的时候，就帮我们在页中排好了序。至于为什么排序，接着往下看。 排序对性能的影响​ 上面我们提了一个问题，为什么数据库再插入数据时要对其进行排序呢？这就涉及到一个数据库查询流程的问题了。无论如何，我们是绝对不会平白无故地在插入数据时增加一个操作让流程复杂化的，所以插入数据时排序一定有其目的，就是优化查询的效率。而我们不难看出，页内部存放数据的模块，实质上就是一个链表结构，链表的特点就是增删快，查询慢。所以优化查询的效率是必须的。 基于单页模式存储的查询流程​ 还是基于上面的那张页图来说，我们插入了五条数据，id分别是从1-5，那么假设我要找一个表中不存在的id，假设id = -1，那么查询的流程就是： ​ 将id=1的这一整页数据取出，进行逐个比对，那么当我们找到id=1的这条数据时，发现这个id大于我们所需要找的那个id。由于数据库再插入数据时，已经进行过排序了，那么在id=1的数据后面，都是id &gt; 1的数据，所以我们就不需要再继续往下找了。 ​ 如果在插入时没有进行排序，那我们需要在继续往下寻找，逐条查找直到结尾也没有找到这条数据，才能返回不存在这条数据。当然，这只是排序优化的冰山一角。 上述页模式可能带来的问题​ 说完了排序，我们就分析一下上面的那张页图，对于大数据量下有什么弊端，或者说，我们可以怎么对这个模式进行优化。 ​ 不难看出，现阶段我们了解的页模式中，只有一个功能，就是在查询某条数据的时候直接将一整页的数据加载到内存中，以减少磁盘IO次数，从而提高性能。但是，我们也可以看到，现在的页模式内部，实际上是采用了链表的结构，前一条数据指向后一条数据，本质上还是通过数据的逐条比较来取出特定的数据。 ​ 如果这一页中有一百万条数据，我们要查的数据正好在最后一个，那么我们是不是一定要从前往后找到这一条数据呢r？如果是这样，我们需要查找的次数就达到了一百万次，即使是在内存中查找，这个效率也是不高的。那么有什么办法来优化这种情况下的查找效率呢？ 页目录的引入​ 打个比方，我们在看书的时候，如果要找到某一节，而这一节我们并不知道在哪一页，我们不需要从前往后，一节一节寻找我们需要的内容。因为在书的前面，存在目录，它会告诉你这一节在哪一页。在数据库的页中，实际上也使用了这种目录的结构，这就是页目录。 ​ 在引入页目录之后，我们所理解的页结构，就变成了这样： ​ 分析下这张图，实际上页目录就像是我们在看书的时候书本的目录一样，目录项1就相当于第一节，目录项2就相当于第二节，而每一条数据就相当于书本的每一页，这张图就可以解释成：第一节从第一页开始，第二节从第三页开始。而实际上，每个目录项会存放自己这个目录项当中最小的id，也就是说，目录项1中会存放1，而目录项2会存放3。 ​ 对比一下数据库在没有页目录时候的查找流程，假设要查找id=3的数据，在没有页目录的情况下，需要查找id=1、id=2、id=3，三次才能找到该数据，而如果有页目录之后，只需要先查看一下id=3存在于哪个目录项下，然后直接通过目录项进行数据的查找即可，如果在该目录项下没有找到这条数据，那么就可以直接确定这条数据不存在，这样就大大提升了数据库的查找效率。但是这种页目录的实现，首先就需要基于数据是在已经进行过排序的场景下，才可以发挥其作用，所以到这里，大家应该明白第二个问题了，为什么数据库在插入时会进行排序，这才是真正发挥排序的作用的地方。 页的扩展​ 在上文中，我们基本上说明白了数据库中页的概念，以及它是如何基于页来减少磁盘IO次数，以及排序是如何优化查询的效率的。 ​ 那么第三个问题：在开头说页的概念的时候，我们有说过，MySQL中每一页的大小只有16KB，不会随着数据的插入而自动扩容，所以这16KB不可能存下我们所有的数据，那么必定会有多个页来存储数据。那么在多页的情况下，MySQL中又是怎么组织这些页的呢？ ​ 针对这个问题，我们继续画出来我们现在多了解的多页的结构图： ​ 可以看到，在数据不断变多的情况下，MySQL会再去开辟新的页来存放新的数据，而每个页都有指向下一页的指针和指向上一页的指针，将多个页组织起来（这里修改了数据，将每一列的数据都放到了数据区中，其中第一个空格之前的代表id）,第一页中存放id为1-5的数据，第二页存放id为6-10的数据，第三页存放id为11-15的数据。需要注意的是，在开辟新页的时候，我们插入的数据不一定是在新开辟的页上，而是要进行所有页的数据比较，来决定这条插入的数据放在哪一页上，而完成数据插入后，最终的多页结构会像上图中画的那样。 多页模式​ 在多页模式下，MySQL终于完成多数据的存储，就是采用开辟新页的方式，将多条数据放在不同的页中，然后同样采用链表的数据结构，将每一页连接起来，那么可以思考第四个问题：多页情况下是否对查询效率有影响呢？ 多页模式对于查询效率的影响​ 答案是肯定的，多页会对查询效率产生一定的影响，影响主要就体现在，多页其本质也是一个链表结构，只要是链表结构，查询效率一定不会高。 ​ 假设数据又非常多，数据库就会开辟非常多的新页，而这些新页就会像链表一样连接在一起，当我们要在这么多页中查询某条数据时，它还是会从头节点遍历到存在我们需要的那条数据所存在的页上。我们好不容易通过页目录优化了页中数据的查询效率，现在又出现了以页为单位的链表。 优化多页模式​ 由于多页模式会影响查询的效率，那么肯定需要有一种方式来优化多页模式下的查询。既然我们可以用页目录来优化页内的数据区，那么我们也可以采取类似的方式来优化这种多页的情况。是的，页内数据区和多页模式本质上都是链表，的确可以采用相同的方式来对其进行优化，它就是目录页。 ​ 我们对比页内数据区，来分析如何优化多页结构。在单页时，我们采用了页目录的目录项来指向一行数据，这条数据就是存在于这个目录项中的最小数据，那么就可以通过页目录来查找所需数据。 ​ 所以对于多页结构也可以采用这种方式，使用一个目录项来指向某一页，而这个目录项存放的就是这一页中存放的最小数据的索引值。和页目录不同的地方在于，这种目录管理的级别是页，而页目录管理的级别是行。 ​ 分析到这里，我们多页模式的结构就会是下图所示的那样： ​ 存在一个目录页还管理目录，目录页中的数据存放就是指向的那一页中最小的数据。这里需要注意的一点是：其实目录页的本质也是页，普通页中存放的数据是项目数据，而目录页中存的数据是普通页的地址。 ​ 假设我们要查找id = 19的数据，按照以前的查找方式，我们需要从第一页开始查找，发现不存在那么再到第二页查找，一直找到第四页才能找到id = 19的数据，但是如果有了页目录，就可以使用id = 19与页目录中存放的数据进行比较，发现19大于任何一条数据，于是进入id = 16指向的页进行查找，然后再通过页内的页目录行级别的数据的查找，很快就可以找到id为19的数据了。随着数据越来越多，这种结构的效率相对于普通的多页模式，优势也就越来越明显。 ​ 相信对MySQL比较了解的同学已经发现，我们画的最终的这幅图，就是MySQL中的一种索引结构-B+树。 B+树的引入​ 接着往下说，我们将我们画的存在在目录页的多页模式图宏观化，可以形成下面的这张图： ​ 这就是我们兜兜转转由简到繁形成的一颗B+树。和常规B+树有些许不同，这是一棵MySQL意义上的B+树，MySQL上的一种索引结构，其中的每个节点就可以理解为是一个页，而叶子节点也就是数据页，除了叶子节点以外的节点就是目录页。 ​ 这一点在图中也可以看出来，非叶子节点只存放了索引，而只有叶子节点存放了真实的数据，这也是符合B+树的特点。 B+树的优势由于叶子节点上存放了所有的数据，并且有指针相连，每个叶子节点在逻辑上是相连的，所以对于查找范围比较友好。 B+树的所有数据都在叶子节点上，所以B+树的查询效率稳定，一般都是查询3次。 B+树有利于数据库的扫描。 B+树有利于磁盘的IO，因为它的层高基本不会因为数据扩大而增高（三层树结构大概可以存放两千万数据量）。 页的完整结构​ 说完了页的概念和页时如何一步一步地组合成为B+树的结构之后，相信大家对于页都有了一个比较清楚的认知。所以这里就要开始说说官方的概念了。基于我们上文所说的，给出一个完整的页结构，也算是对上文中理解的页结构的一种补充。 ​ 上图为Page数据结构，File Header字段用于记录Page的头信息，其中比较重要的是FIL_PAGE_PREV和FIL_PAGE_NEXT字段，通过这两个字段，我们可以找到该页的上一页和下一页，实际上所有页通过这两个字段可以形成一条双向链表。 ​ Page Header字段用于记录Page的状态信息。接下来的Infimum和Supremum是两个伪行记录，Infimum（下确界）记录比该页中任何主键值都要小的值，Supremum（上确界）记录比该页中任何主键值都要大的值，这个伪记录分别构成了页中记录的边界。 ​ User Records中存放的是实际的数据行记录。Free Space中存放的是空闲空间，被删除的行记录会被记录成空闲空间。Page Directory记录着与二叉查找相关的信息。File Trailer存储用于检测数据完整性的校验和等数据。 基于B+树聊赖MySQL的其他知识点​ 看到这里，我们已经了解了MySQL从单条数据开始，到通过页来减少磁盘IO次数，并且在页中实现了页目录来优化页中的查询效率，然后使用多页模式来存储大量的数据，最终使用目录页来实现多页模式的查询效率并形成我们口中的索引结构—B+树。接下来，我们说说MySQL的其他知识点。 聚簇索引和非聚簇索引​ 简单地说，所谓聚簇索引，就是将索引和数据放到一起，找到索引也就找到了数据，我们刚才看到的B+树索引就是一种聚簇索引。而非聚簇索引就是将数据和索引分开，查找时需要先查找到索引，然后通过索引回表找到相应的数据。InnoDB有且只有一个聚簇索引，而MyISAM中都是非聚簇索引。 联合索引的最左前缀匹配原则​ 在MySQL数据库中不仅可以对某一列建立索引，还可以对多列建立一个联合索引，而联合索引存在一个最左前缀匹配原则的概念，如果基于B+树来理解这个最左前缀匹配原则，相对来说就会容易很多了。 ​ 首先我们基于文首的这张表建立一个联合索引： 1create index idx_obj on user(age asc,height asc,weight asc) ​ 我们已经了解了索引的数据结构是一棵B+树，也了解了B+树优化查询效率的其中一个因素就是对数据进行了排序，那么我们在创建idx_obj这个索引的时候，也就相当于创建了一颗B+树索引，而这个索引就是依据联合索引的成员来进行排序，这里是age，height，weight。 ​ InnoDB中只要有主键被定义，那么主键列被作为一个聚簇索引，而其他索引都被作为非聚簇索引，所以自然而然的，这个索引就会是一个非聚簇索引。所以根据这些我们可以得出结论： idx_obj这个索引会根据age，height，weight进行排序 idx_obj这个索引是一个非聚簇索引，查询时需要回表 ​ 根据这两个结论，首先需要了解的就是，如何排序？单列排序很简单，就是比大小。但多列排序是基于什么原则呢？实际上在MySQL中，联合索引的排序有这么一个原则，从左到右依次比较大小。就拿刚才建立的索引，它会先去比较age的大小，如果age的大小相同，那么比较height的大小，如果height也无法比较大小，那么就比较weight的大小，最终对这个索引进行排序。 ​ 那么根据这个排序我们也可以画出一个B+树，这里就不像上文画的那么详细了，简化一下： ​ 数据： ​ B+树： ​ 注意，此时由于是非聚簇索引，所以叶子节点不在有数据，而是存了一个主键索引，最终会通过主键索引来回表查询数据。 ​ B+树的结构有了，就可以通过这个来理解最左前缀匹配原则了。我们先下一个查询语句： 1SELECT * FROM user WHERE age=1 and height = 2 and weight = 7 ​ 毫无疑问，这条语句一定会走idx_obj这个索引。那我们再看一个语句： 1SELECT * FROM user WHERE height=2 and weight = 7 ​ 这条SQL会走索引吗？答案是否定的。为什么这条语句不会走索引？上文中我们提到了一个多列的排序原则，是从左到右进行比较然后排序的，而我们的idx_obj这个索引从左到右依次是age，height，weight，所以当我们使用height和weight来作为查询条件时，由于age的缺失，那么就无法从age来进行比较了。 ​ 难道不能直接用height和weight来进行比较吗？显然是不可以的。举个例子，我们把缺失的这一列写作一个问号，那么这条语句的查询条件就变成了?27，那么我们从这棵B+树的根节点开始，根节点上有127和365，那么以height和weight来进行比较的是，走的一定是127这一边，但是如果缺失的数字是大于3的呢？比如427,527,627，那么如果走索引来查询数据，将会丢失数据，错误查询。所以这种情况下是不会走索引查询的。这就是最左前缀匹配原则的成因。 ​ 1、最左前缀匹配原则，MySQL会一直向右匹配直到遇到范围查询（&gt;、&lt;、between、like）就停止匹配。比如a = 3 and b = 4 and c &gt; 5 and d = 6，如果建立（a, b, c, d）顺序的索引，d是无法使用索引的，如果建立（a, b, d, c）的索引则都可以使用到。a、b、d的顺序可以任意调整。 ​ 2、=和in可以乱序。比如a = 1 and b = 2 and c = 3，建立(a, b, c)索引可以任意顺序，MySQL的查询优化器会帮你优化成索引可以识别的形式。 ​ 根据我们了解的可以得出结论：只要无法进行排序比较大小的，就无法走联合索引。 ​ 再看几个语句： 1SELECT * FROM user WHERE age=1 and height = 2 ​ 这条语句是可以走idx_obj索引的，因为它可以通过比较（12? &lt; 365）。 1SELECT * FROM user WHERE age=1 and weight=7 ​ 这条语句也是可以走idx_obj索引的，因为它也可以通过比较(1?7 &lt; 364)，走左子树，但是实际上weight并没有用到索引，因为根据最左匹配原则，如果有两页的age都等于1，那么会去比较height，但是height在这里并不作为查询条件，所以MySQL会将这两页全都加载到内存中进行最后的weight字段的比较，进行扫描查询。 1SELECT * FROM user where age&gt;1 ​ 这条语句不会走索引，但是可以走索引。这句话什么意思呢？这条SQL很特殊，由于其存在可以比较的索引，所以它走索引也可以查询出结果，但是由于这种情况是范围查询并且是全字段查询，如果走索引，还需要进行回表，MySQL查询优化器就会认为走索引的效率比全表扫描还要低，所以MySQL会去优化它，让它直接进行全表扫描。 1SELECT * FROM user WHERE age=1 and height&gt;2 and weight=7 ​ 这条语句可以走索引的，因为它可以通过age进行比较，但是weight不会用到索引，因为height是范围查找，与第二条语句类似，如果有两页的height都大于2，那么MySQL会将两页的数据都加载进内存，然后再来通过weight匹配正确的数据。 索引的范围列匹配假设创建索引 create index (shop_id,product_id,gmt_create)。如果你是范围查询，比如 &gt;=，&lt;=，between 操作，你只能是符合最左前缀的规则才可以范围，范围之后的列就不用索引了。 1SELECT * FROM product WHERE shop_id &gt;= 1 AND product_id = 1 这里就只有 shop_id 走索引查询了，而 product_id 没有走索引。 索引的包含函数如果你对某个列用了函数，比如 substring 之类的，那么那一列不用索引 1SELECT * FROM product WHERE shop_id = 1 AND 函数(product_id) = 2 上面就只有 shop_id 在联合索引中走了索引。 为什么InnoDB只有一个聚簇索引，而不将所有索引都是用聚簇索引​ 因为聚簇索引是将索引和数据都存放在叶子节点中，如果所有的索引都是用聚簇索引，则每一个索引都将保存一份数据，会造成数据的冗余，在数据量很大的情况下，这种数据冗余是很消耗资源的。 补充两个索引的点​ 1、什么情况下会发生明明创建了索引，但是执行的时候并没有通过索引呢？ ​ 查询优化器执行一条SQL语句的查询，可以有不同的执行方案，至于最终选择哪种方案，需要通过优化器进行选择，选择执行成本最低的方案。 ​ 在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案。这个成本最低的方案就是所谓的执行计划。优化过程大致如下： 根据搜索条件，找出所有可能使用的索引 计算全表扫描的代价 计算使用不同索引执行查询的代价 对比各种执行方案的代价，找出成本最低的那一个 ​ 2、在非聚簇索引情况下通常需要通过叶子节点的指针回表查询数据，什么情况下不需要回表？ ​ 覆盖索引。覆盖索引是指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。 ​ 当一条查询语句符合覆盖索引条件时，MySQL只需要通过索引就可以返回查询所需要的数据，这样避免了查到索引后再返回表操作，减少I/O提高效率。 ​ 例如，表covering_index_sample中有一个普通索引idx_key1_key2(key1, key2)。当我们通过SQL语句：select key2 from covering_index_sample where key1 = &#39;keytest&#39;;的时候，就可以通过覆盖索引查询，无需回表。 ​ 例如上面的SELECT age FROM user where age = 1。这句话就不需要进行回表查询。 索引的缺点以及使用注意索引是有缺点的，常见的就是会增加磁盘消耗，因为要占用磁盘文件，同时高并发的时候频繁插入和修改索引，会导致性能消耗。我们给的建议是就是，尽量创建少的索引。比如一个表建两三个索引。 某些字段只有两个值，例如 status、is_delete 等，就只有 0 和 1。这些建立索引就没有意义了，几乎跟全表扫描差不多。你有个 id 字段，每个 id 都不太一样，建立个索引，这个时候用索引效果就很好。比如定位到某个 id 的行，通过索引二分查找，可以大大减少要扫描的数据量，性能是非常好的。 另外，InnoDB 下不要用 UUID 生成的超长字符串作为主键。因为这么搞会导致所有的索引的 data 都是那个主键值，最终导致索引会变得过大，浪费很多磁盘空间。 还有，一般 InnoDB 表里，建议统一用 auto_increment 自增作为主键值，因为这样可以保持聚簇索引直接加记录就可以了。如果用那种不是单调递增的主键值，可能会导致 B+ 树分裂后重新组织，浪费时间。 结语​ 本文着重讲解关于MySQL的索引结果，从零开始慢慢构建了一个B+树索引，并且根据这个过程谈了B+树是如何一步一步去优化查询效率的。简单地归纳一下就是： ​ 排序：优化查询的根本，插入时进行排序实际上就是为了优化查询的效率。 ​ 页：用于减少IO次数，还可以利用程序局部性原理，来稍微提高查询的效率。 ​ 页目录：用于规避链表的软肋，避免在查询时进行链表的扫描。 ​ 多页：数据量增加的情况下开辟新页来保存数据。 ​ 目录页：特殊的页目录，其中保存的数据是页的地址。查询时可以通过目录页快速定位到页，避免多页的扫描。 参考资料​ 转载自索引很难么？带你从头到尾捋一遍MySQL索引结构，不信你学不会！ ​]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Netty底层架构原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F13%2F%E6%B5%85%E8%B0%88Netty%E5%BA%95%E5%B1%82%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 对于高性能的RPC框架，Netty作为异步通信框架，几乎成了必需品。例如Dubbo框架中通信组件，还有RocketMQ中生产者和消费者的通信，都是用了Netty。现在让我们开简单看一下Netty的基本架构和原理。 Netty的特点与NIO​ Netty是一个异步的、基于事件驱动的网络应用框架，它可以用来开发高性能服务端和客户端。以前编写网络调用程序的时候，我们都会在客户端创建一个Socket，通过这个Socket连接到服务端。服务端根据这个Socket创建一个Thread，用来发出请求。客户端在发起调用以后，需要等待服务端处理完成，才能继续后面的操作。这样线程会出现等待的状态。 ​ 如果客户端请求数越多，服务端创建的处理线程也会越多，JVM管理如此多的线程并不是容易的事。 ​ 为了解决上述问题，退出了NIO的概念，就是（Non-blocking I/O）。其中Selector机制就是NIO的核心。当每次客户端请求时，会创建一个Socket Channel，并将其注册到Selector上（多路复用器），然后Selector关注服务端IO读写事件，此时客户端并不用等待IO事件完成，可以继续做接下来的工作。一旦服务端完成了IO读写操作，Selector会接到通知，同时告诉客户端IO操作已经完成。接到通知的客户端，就可以通过SocketChannel获取需要的数据了。 ​ 上面描述的过程有异步的意思，不过，Selector实现的并不是真正意义上的异步操作。因为Selector需要通过线程阻塞的方式监听IO事件变更，只是这种方式没有让客户端等待，是Selector在等待IO返回，并且通知客户端去获取数据。 ​ 谈好了NIO再来谈谈Netty。Netty作为NIO的实现，它适用于服务器/客户端通讯的场景，以及针对于TCP协议下的高并发应用。对于开发者来说，它具有以下特点： 对NIO进行封装，开发者不需要关注NIO的底层原理，只需要调用Netty组件就能完成工作。 对网络调用透明，从Socket建立TCP连接到网络异常的处理都做了包装 对数据处理灵活，Netty支持多种序列化框架，通过ChannelHandler机制，可以自定义“编/解码器” 对性能调优友好，Netty提供了线程池模式以及Buffer的重用机制（对象池化），不需要构件复制的多线程模型和操作队列。 从一个简单的例子开始​ 现在通过一个例子来讲解。假设有一个客户端去调用一个服务端，假设服务端叫做EchoServer，客户端叫做EchoClient，用Netty架构实现代码如下。 服务端代码​ 构建服务器端，假设服务器接受客户端传来的信息，然后在控制台打印。首先，生成EchoServer，在构件函数中传入需要监听的端口号。然后再编写服务的启动方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package server;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import java.net.InetSocketAddress;public class EchoServer &#123; private final int port; public EchoServer(int port) &#123; this.port = port; &#125; public void start() throws Exception&#123; final EchoServerHandler serverHandler = new EchoServerHandler(); // 1、创建EventLoopGroup EventLoopGroup group = new NioEventLoopGroup(); try &#123; // 2、创建ServerBootstrap ServerBootstrap b = new ServerBootstrap(); b.group(group) // 3、指定所使用的 NIO 传输 Channel .channel(NioServerSocketChannel.class) // 4、使用指定的端口设置套接字地址 .localAddress(new InetSocketAddress(port)) // 5、添加一个 EchoServerHandler 到 Channel 的 ChannelPipeline .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(serverHandler); &#125; &#125;); // 6、异步绑定服务器：调用sync()方法阻塞等到直到绑定完成 ChannelFuture f = b.bind().sync(); System.out.println(EchoServer.class.getName() + "started and listening for connections on " + f.channel().localAddress()); // 7、获取Channel 的 CloseFuture，并且阻塞当前线程直到它完成 f.channel().closeFuture().sync(); &#125;finally &#123; // 8、关闭EventLoopGroup，释放所有的资源 group.shutdownGracefully().sync(); &#125; &#125;&#125; ​ Server的启动方法涉及到了一些组件的使用，例如EventLoopGroup、Channel。这些后面会讲解，这里有个大概的印象就好： 创建EventLoopGroup。 创建ServerBootstrap。 指定所使用的NIO传输Channel。 使用指定的端口设置套接字地址。 添加一个ServerHandler到Channel的ChannelPipeline。 异步地绑定服务器，调用sync()方法阻塞等待直到绑定完成。 获取Channel的CloseFuture，并且阻塞当前线程直到它完成。 关闭EventLoopGroup，释放所有的资源。 ​ NettyServer启动以后会监听某个端口的请求，当接收到了请求就需要处理了。在Netty中客户端请求服务端，被称为“入站”操作。可以通过ChannelInboundHandlerAdapter实现，具体内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940package server;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFutureListener;import io.netty.channel.ChannelHandler;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import io.netty.util.CharsetUtil;@ChannelHandler.Sharablepublic class EchoServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf in = (ByteBuf) msg; //将消息记录到控制台 System.out.println("Server received：" + in.toString(CharsetUtil.UTF_8)); //将接收到的消息写给发送者，而不冲刷出站消息 ctx.write(in); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx)throws Exception &#123; //将未决消息冲刷到远程节点，并且关闭该 Channel ctx.writeAndFlush(Unpooled.EMPTY_BUFFER) .addListener(ChannelFutureListener.CLOSE); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; //打印异常栈跟踪 cause.printStackTrace(); //关闭该Channel ctx.close(); &#125;&#125; ​ 从上面的代码可以看出，服务端处理的代码包含了三个方法。这三个方法是根据事件触发的。它们分别是： 当接收到消息时的操作：channelRead。 消息读取完成时的方法：channelReadComplete。 出现异常时的方法：exceptionCaught 客户端代码​ 客户端和服务端的代码基本相似，在初始化时需要输入服务端的IP和Port。整个客户端的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package client;import io.netty.bootstrap.Bootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import java.net.InetSocketAddress;public class EchoClient &#123; private final String host; private final int port; public EchoClient(String host, int port) &#123; this.host = host; this.port = port; &#125; public void start() throws Exception&#123; EventLoopGroup group = new NioEventLoopGroup(); try &#123; // 创建 Bootstrap Bootstrap b = new Bootstrap(); // 指定 EventLoopGroup以处理客户端事件：需要适用于NIO的实现 b.group(group) // 适用于NIO传输的Channel 类型 .channel(NioSocketChannel.class) // 设置服务器的InetSocketAddress .remoteAddress(new InetSocketAddress(host, port)) // 在创建C喊你了时，向ChannelPipeline中添加一个 EchoClientHandler实例 .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new EchoClientHandler()); &#125; &#125;); // 连接到远程节点，阻塞等待直到连接完成 ChannelFuture f = b.connect().sync(); //阻塞，直到Channel 关闭 f.channel().closeFuture().sync(); &#125;finally &#123; // 关闭线程池并且释放所有的资源 group.shutdownGracefully().sync(); &#125; &#125;&#125; ​ 客户端的启动程序的顺序： 创建Bootstrap。 指定EventLoopGroup用来监听事件。 定义Channel的传输模式为NIO。 设置服务器的InetSocketAddress。 在创建Channel时，向ChannelPipeline中添加一个EchoClientHandler实例。 连接到远程节点，阻塞等待直到连接完成。 阻塞，直到Channel关闭。 关闭线程池并且释放所有的资源。 ​ 客户端在完成以上操作以后，会与服务端建立连接从而传输数据。同样在接受到Channel中触发的事件时，客户端会触发对应事件的操作。 1234567891011121314151617181920212223242526272829package client;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;import io.netty.util.CharsetUtil;public class EchoClientHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt; &#123; @Override public void channelActive(ChannelHandlerContext ctx) &#123; // 当被通知 Channel是活跃的时候，发送一条信息 ctx.writeAndFlush(Unpooled.copiedBuffer("Netty rocks!", CharsetUtil.UTF_8)); &#125; @Override public void channelRead0(ChannelHandlerContext ctx, ByteBuf in) throws Exception &#123; //记录已接收信息的转储 System.out.println("Client received：" + in.toString(CharsetUtil.UTF_8)); &#125; // 在发生异常时，记录错误并关闭Channel @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; ​ 例如Channel激活，客户端接受到服务端的消息，或者发生异常的捕获。 Netty核心组件​ 通过上面的例子，发现有些Netty组件在服务初始化以及通讯时被用到，下面就来介绍这些组件的用途和关系。 Channel​ 上面的例子可以看出，当客户端和服务端连接的时候会建立一个Channel。这个Channel可以理解为Socket连接，它负责基本的IO操作，例如：bind()、connect()、read()和write()等等。简单理解就是，Channel就是代表连接，实体之间的连接，程序之间的连接，文件之间的连接，设备之间的连接。同时它也是数据入站和出站的载体。 EventLoop和EventLoopGroup​ 既然有了Channel连接服务，让信息之间可以流动。如果服务发出的消息称作“出站”消息，服务接受的消息称作“入站”消息，那么消息的“出站”/“入站”就会产生事件（Event）。例如：连接已激活；数据读取；用户事件；异常事件；打开链接；关闭链接等待。 ​ 顺着这个思路往下想，有了数据，数据的流动产生事件，那么就有一个机制去监控和协调事件。这个机制（组件）就是EventLoop。在Netty中每个Channel都会被分配到一个EventLoop，而一个EventLoop可以服务多个Channel。而每个EventLoop会占用一个Thread，同时这个Thread会处理EventLoop上面发生的所有IO操作和事件（Netty 4.0）。 ​ 理解了EventLoop，理解EventLoopGroup就容量了。EventLoopGroup是用来生成EventLoop的。上面的例子代码中第一行就new了EventLoopGroup对象。一个EventLoopGroup包含了多个EventLoop对象，而EventLoopGroup要做的就是创建一个新的Channel，并且给他分配一个EventLoop。 ​ 在异步传输的情况下，一个EventLoop是可以处理多个Channel中产生的事件的，它主要的工作就是事件的发现以及通知。相对于以前一个Channel就占用一个Thread的情况，Netty的方式要合理多了。 ​ 客户端发送消息到服务端，EventLoop发现以后会告诉服务端：“你去获取消息”，同时客户端进行其他的工作；当EventLoop检测到服务端返回的消息，也会通知客户端：“消息返回了，你去取吧”。客户端再去获取消息。整个过程EventLoop就是监视器 + 传声筒。 ChannelHandler，ChannelPipeline和ChannelHandlerContext​ 如果说EventLoop是事件的通知者，那么ChannelHandler就是事件的处理者。在ChannelHandler中可以添加一些业务代码，例如数据转换，逻辑运算等等。正如上面的例子中展示的，Server和Client分别都有一个ChannelHandler来处理，读取信息，网络可用，网络异常之类的信息。并且，针对出站和入站的事件，有不同的ChannelHandler，分别是： ChannelInBoundHandler（入站事件处理器） ChannelOutBoundHandler（出站事件处理器） ​ 假设每次请求都会触发事件，而由ChannelHandler来处理这些事件，这个事件的处理顺序是由ChannelPileLine来决定的。 ​ ChannelPipeline为ChannelHandler链提供了容器，到Channel被创建的时候，会被Netty框架自动分配到ChannelPipeline上。ChannelPipeline保证了ChannelHandler按照一定顺序处理事件，当事件触发以后，会将数据通过ChannelPipeline按照一定的顺序通过ChannelHandler。级，ChannelPipeline是复制“排队”的。这里的“排队”是处理事件的顺序。同时，ChannelPipeline也可以添加或者删除ChannelHandler，管理这个队列。 ​ 如上图，ChannelPipeline使ChannelHandler按照先后顺序排列，信息按照箭头所示方向流动并且被ChannelHandler处理。 ​ 说完了ChannelPipeline和ChannelHandler，前者管理后者的排列顺序。那么它们之间的关联就有ChannelHandlerContext来表示了。每当有ChannelHandler添加到ChannelPipeline时，同时会创建ChannelHandlerContext。ChannelHandlerContext的主要功能就是管理ChannelHandler和ChannelPipeline的交互。 ​ 上面的例子中，几乎ChannelHandler中每个处理事件函数，传入的参数就ChannelHandlerContext。ChannelHandlerContext参数贯穿ChannelPipeline，将信息传递给每个ChannelHandler，是个合格的“通讯员”。 ​ 把上面提到的几个核心组件归纳一下，用下图表示方便记忆它们之间的关系： Netty的数据容器​ 前面介绍了Netty的几个核心组件，服务器在数据传输的时候，产生事件，并且对事件进行监控和处理。接下来看数据是如何存放以及读写的。Netty将ByteBuf作为数据容器，来存放数据。 ByteBuf工作原理​ 从结构上来说，ByteBuf由一串字节数组构成。数组中每个字节用来存放信息。ByteBuf提供了两个索引，一个用于读取数据，一个用于写入数据，这两个索引通过在字节数组中移动，来定位需要或者读写信息的位置。当从ByteBuf读取时，它的readerIndex（读索引）将会根据读取的字节数递增。同样，当写ByteBuf时，它的writeIndex也会根据写入的字节数进行递增。 ​ 需要注意的是极限的情况是readerIndex刚好读到了writeIndex写入的地方。如果readerIndex超过了writeIndex的时候，Netty会抛出IndexOutOfBoundsException异常。 ByteBuf使用模式​ 说了ByteBuf的工作原理后，再来看它的使用模式。根据存放缓冲区的不同分为三类： 堆缓冲区：ByteBuf将数据存储在JVM的堆中，通过数组实现，可以做到快速分配。由于在堆上被JVM管理，在不被使用时可以快速释放。可以通过ByteBuf.array()来获取byte[]数据。 直接缓冲区：在JVM的堆之外直接分配内存，用来存储数据。其不占用堆空间，使用时需要考虑内存容量。它在使用Socket传递时性能较好，因为间接从缓冲区发送数据，在发送之前JVM会先将数据复制到直接缓冲区再进行发送。由于直接缓冲区的数据分配在堆之外，通过JVM进行垃圾回收，并且分配时也需要做复制的操作，因此使用成本较高。 复合缓冲区：顾名思义就是将上述两类缓冲区聚合在一起。Netty提供了一个CompsiteByteBuf，可以将堆缓冲区和直接缓冲区的数据放在一起，让使用更加方便。 ByteBuf的分配​ 接下来看看ByteBuf如何分配缓冲区的数据。Netty提供了两种ByteBufAllocator的实现，他们分别是： PooledByteBufAllocator：实现了ByteBuf的对象的池化，提高性能减少内存碎片。 UnpooledByteBufAllocator：没有实现对象的池化，每次会生成新的对象实例。 ​ 对象池化的技术和线程池比较相似，主要目的是提高内存的使用率。池化的简单实现思路，是在JVM堆内存上构建一层内存池，通过allocate方法获取内存池中的空间，通过release方法将空间归还给内存池。 ​ 对象的生成和销毁，会大量地调用allocate和release方法，因此内存池面临碎片空间回收的问题，在频繁申请和释放空间后，内存池需要保证连续的内存空间，用于对象的分配。基于这个需求，有两种算法用于优化这一块的内存分配：伙伴系统和slab系统。 ​ 伙伴系统，用完全二叉树管理内存区域，左右节点互为伙伴，每个节点代表一个内存块。内存分配将大块内存不断二分，直到找到满足所需的最小内存分片。内存释放会判断释放内存分片的伙伴（左右节点）是否空闲，如果空闲则将左右节点合成更大快内存。 ​ slab系统，主要解决内存碎片问题，将大块内存按照一定内存大小进行等分，形成相等大小的内存片构成的内存集。按照内存申请空间的大小，申请尽量小块内存或者其整数倍的内存。释放内存时，也是将内存分片归还给内存集。 ​ Netty内存池管理以Allocate对象的形式出现。一个Allocate对象由多个Arena组成，每个Arena能执行内存块的分配和回收。Arena内有三类内存管理单元： TinySubPage SmallSubPage ChunkList ​ Tiny和Small符合Slab系统的管理策略，ChunkList符合伙伴系统的管理策略。当用户申请内存介于tingSize和smallSize之间时，从tinySubPage中获取内存块；申请内存介于smallSize和pageSize之间时，从smallSubPage中获取内存块；介于pageSize和chunkSize之间时，从ChunkList中获取内存；大于ChunkSize（不知道分配内存的大小）的内存块不通过池化分配。 Netty的Bootstrap​ 说完了Netty的核心组件以及数据存储。回到最开始的例子程序，在程序最开始的时候会new一个Bootstrap对象，后面所有的配置都是基于这个对象展开的。Boosttrap的作用就是将Netty核心组件配置到程序中，并且让他们运行起来。 ​ 从Bootstrap的继承结构来看，分为两类，分别是Bootstrap和ServerBootstrap，一个对应客户端的引导，一个对应服务端的引导。 ​ 客户端引导Bootstrap，主要有两个方法：bind()和connetct()。Bootstrap通过bind()方法创建一个Channel。在bind()之后，通过调用connect()方法来创建Channel连接。 ​ 服务端引导ServerBootstrap，与客户端不同的是在bind()方法之后会创建一个ServerChannel，它不仅会创建新的Channel，还会管理已经存在的Channel。 ​ 通过上面的描述，服务端和客户端的引导存在两个区别： ServerBootstrap（服务端引导）绑定一个端口，用来监听客户端的连接请求。而Bootstrap（客户端引导）只要知道服务端IP和Port建立连接就可以了。 Bootstrap（客户端引导）需要一个EventLoopGroup，但是ServerBootstrap（服务端引导）则需要两个EventLoopGroup。因为服务器需要两组不同的Channel。第一组ServerChannel自身监听本地端口的套接字，第二组用于监听客户端请求的套接字。 总结​ 我们从NIO入手，谈到了Selector的核心机制。然后通过介绍Netty客户端和服务端的代码运行流程。让大家对Netty编写代码有基本的认识。 ​ 在Netty的核心组件中，Channel提供Socket的连接通道，EventLoop会对应Channel监听其产生的事件，并且通知执行者。EventLoopGroup负责生成和管理EventLoop。 ​ ChannelPipeline作为ChannelHandler的容器会绑定到Channel上，然后由ChannelHandler提供具体事件处理。另外，ChannelHandlerContext为ChannelHandler和ChannelPipeline提供信息共享。 ​ ByteBuf作为Netty的数据容器，通过字节数组的方式存储数据，并且通过读索引和写索引来引导读写操作。 ​ 上述的核心组件都是通过Bootstrap来配置并且引导启动的，Bootstrap启动方式虽然一致，但是针对客户端和服务端有些许的区别。 参考资料Netty底层架构原理]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ详解]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F10%2FRocketMQ%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MQ 集群化部署以支撑高并发访问 假设 RocketMQ 部署在一台机器上，即使这个机器的配置很高，但一般来说一台机器也就是支撑 10万+ 的并发访问。如果这个时候，有大量的系统都要往 RocketMQ 里高并发的写入消息，可能达到每秒几十万请求，这个时候就要将 RocketMQ 进行集群化部署，部署在多台机器上。假设每台机器能抗 10 万并发，只要让几十万请求分散到多台机器上接可以了。 MQ 存储海量消息一般情况下，MQ 收到的大量消息并不是立马会被所有的消费方获取过去消费，所以 MQ 一般都得把消息在自己本地磁盘存储起来，然后等到消费方去处理。这样，MQ 就得存储大量的消息，可能是几百万条，甚至几亿条，这么多的消息在一台机器上是没法存储的，那 RocketMQ 是如何处理的？ 其实发送消息到 MQ 的系统会把消息分散发送给多台不同的机器，假设有一万条消息，分散发送给 10 台机器，可能每台机器就是接收到 1000 条消息。 其次，每台机器上部署的 RocketMQ 进程一般称之为 Broker，每个 Broker 都会接收到不同的消息，然后就会把这批消息存储在自己本地的磁盘文件里。 高可用保障如果某一台 Broker 宕机了，导致 RocketMQ 里一部分的消息没了，这就会导致 MQ 的不可靠和不可用。而RocketMQ的解决思路就是 Broker 主从架构以及多副本策略。 简单来说，Broker 有 Master 和 Slave 两种角色： Master Broker 收到消息之后会同步给Slave Broker，这样 Slave Broker 上就能有一模一样的一份副本数据。这个时候如果任何一个 Master Broker 出现故障，还有一个Slave Broker上有一份数据副本，可以保证数据不丢失，还能继续对外提供服务，保证了 MQ 的可靠性和高可用性。 数据路由：消息中间件路由中心对于系统来说，要发送消息到 MQ 去，还要从 MQ 里消费信息，因此需要解决一个问题：大家怎么知道有哪些 Broker？怎么知道要连接哪一台 Broker 上去发送和接收消息？RocketMQ 为了解决这个问题，有一个 NameServer 的概念。它也是独立部署在几台机器上，然后所有的 Broker 都会把自己注册到 NameServer 上去，NameServer 就知道集群里有哪些Broker了。 对于我们系统而言，如果它要发送消息到 Broker，会找 NameServer 去获取路由信息，就是集群里有哪些 Broker 等信息；如果系统要从 Broker 获取消息，也会找 NameServer 获取路由信息，去找到对应的 Broker 获取消息。 NameServer 的集群化部署NameServer 集群化部署的一个主要原因，就是高可用性。NameServer 是集群里非常关键的一个角色，它要管理 Broker 信息，别人都要通过它才知道跟哪个 Broker 通信，如果 NameServer 就部署一台机器的话，一旦 NameServer 宕机了，就会导致 RocketMQ 集群出现故障。所以通常来说，NameServer 一定会多机器部署，实现一个集群，起到高可用的效果。 Broker挂了，NameServer 如何感知一个 Broker 启动之后向 NameServer 注册了，每个 NameServer 都知道集群里有这么一台 Broker 的存在了，然后各个系统从 NameServer 也拉取到了一台信息，知道集群里有这么一台 Broker，但如果这台 Broker 挂了之后，NameServer 要如何感知？ 这个问题的解决靠的就是 Broker 跟 NameServer 之间的心跳机制，Broker 会每隔 30s 给所有的 NameServer 发送心跳，告诉每个 NameServer 自己还活着，每次 NameServer 收到一个 Broker 的心跳，就可以更新一下它的最近一次心跳的时间，然后每隔 10s 运行一个任务，去检查各个 Broker 最近的一次心跳时间，如果某个 Broker 超过 120s 都没发送心跳了，那么就认为这个 Broker 已经挂掉了。 Broker 的主从架构Master Broker 如何将消息同步给 Slave Broker一般情况下，为了保证 MQ 的数据不丢失且具备一定的高可用性，所以一般都是将 Broker 部署成 Master-Slave 模式的，也就是一个 Master Broker 对应一个 Slave Broker。然后 Master 需要在接收的到消息之后，将数据同步给 Slave，这样一旦 Master Broker 挂了，还有 Slave 上有一份数据。需要注意的是，Slave Broker 也会向所有的 NameServer 进行注册，也会向所有的 NameServer 每 30s 发送心跳。 那么，Master Broker 是如何将消息同步给 Slave Broker 的？答案是 RocketMQ 自身的 Master-Slave 模式采取的是 Slave Broker 不停地发送请求到 Master Broker 去拉取消息。即我们要明白一点，就是 RocketMQ 自身的 Master-Slave 模式采取的是 Pull 模式拉取消息。如图： RocketMQ 有实现读写分离吗既然 Master Broker 主要是接收系统的消息写入，然后会同步给 Slave Broker，那么 Slave Broker 也应该有一份一样的数据。所以，作为消费者的系统在获取消息的时候，是从 Master Broker 获取的？还是从 Slave Broker 获取的？ 其实都不是，答案是：有可能是从 Master Broker 获取消息，也有可能从 Slave Broker 获取消息。作为消费者的系统在获取消息的时候会先发送请求到 Master Broker 上去，请求获取一批消息，此时 Master Broker 是会返回一批消息给消费者系统的。 然后 Master Broker 在返回消息给消费者系统的时候，会根据当时 Master Broker 的负载情况和 Slave Broker 的同步情况，向消费者建议下一次拉取消息的时候是从 Master Broker 拉取还是从 Slave Broker 拉取。 例如，要是这个时候 Master Broker 负载很重，本身要抗 10 万写并发了，你还要从它这里拉取信息，增加负担，那肯定是不合适的。此时 Master Broker 就会建议你从 Slave Broker 去拉取消息。又或者，本身这个时候 Master Broker 上都已经写入了 100 万条数据了，但是Slave Broker 不知道啥原因，才同步了 96 万条数据，落后了整整 4 万条消息的同步，这个时候你作为消费者系统可能都已经获取到 96 万条数据了，那么下次还是只能从 Master Broker 去拉取消息。因为 Slave Broker 同步太慢了，导致你没法从它那里获取更新的消息了。 所以这一切都会有 Master Broker 根据情况来决定，如图： 总结一下就是：在写入消息的时候，通常来说肯定是选择 Master Broker 去写入的，但是在拉取消息的时候，有可能从 Master Broker 获取，也可能从 Slave Broker 去获取，一切都根据当时的情况来定。 Slave Broker 挂掉了会有什么影响如果 Slave Broker 挂掉了，那么会对这个系统有一点影响，但是影响并不大。因为消息写入全部是发送到 Master Broker 的，然后消息获取也可以走 Master Broker，只不过有一些消息获取可能是从 Slave Broker 去走的。 所以如果 Slave Broker 挂了，那么此时无论消息写入还是拉取，还是可以继续从 Master Broker 去走，对整体运行不影响。只不过少了 Slave Broker，会导致所有读写压力都集中在 Master Broker 上。 Master Broker 挂掉了会有什么影响如果 Master Broker 挂掉了，这个时候对消息的写入和获取都有一定的影响。但是，Slave Broker 也是跟 Master Broker 一样有一份数据在的，只不过 Slave Broker 上的数据可能有部分没来得及从 Master Broker 同步。但是此时RocketMQ 可以实现直接自动将 Slave Broker 切换为 Master Broker 吗？ 在 RocketMQ 4.5 版本之前，是不能的。所以在这种情况下，如果 Master Broker 宕机了，这是就得手动做一些运维操作，把 Slave Broker 重新修改一些配置，重启机器给调整为 Master Broker，这有点麻烦，而且会导致中间一段时间不可用。所以这种 Master-Slave 模式不是彻底的高可用模式，它没法实现自动把 Slave 切换为 Master。 基于 Dledger 实现 RocketMQ 高可用自动切换在 RocketMQ 4.5 之后，这种情况得到看改变，因为 RocketMQ 支持了一种新的机制，叫做 Dledger。简单来说，把 Dledger 融入 RocketMQ 之后，就可以让一个 Master Broker 对应多个 Slaver Broker，也就是一份数据可以有多份副本，比如一个 Master Broker 对应两个 Slave Broker。然后依然会在 Master 和 Slave 之间进行数据同步。 此时一旦 Master Broker 宕机了，就可以在多个 Slave 中，通过 Dledger 技术和 Raft 协议算法进行 leader 选举，直接将一个 Slave Broker 选举为新的 Master Broker，然后这个新的 Master Broker 就可以对外提供服务了。 这个过程也许只要 10 秒或者几十秒的时间就可以完成，这样的话，就可以实现 Master Broker 挂掉之后，自动从多个 Slave Broker 中选举出来一个新的 Master Broker，继续对外服务，一切都是自动的。 所以，我们在设计 RocketMQ 生成部署架构的时候，可以采用基于 Dledger 的部署方式，这样可以让 RocketMQ 做到自动切换故障了。 Broker 如何跟 NameServer 进行通信上面说过，Broker 会每隔 30 秒发送心跳到所有的 NameServer 上去，然后每个 NameServer 都会每隔 10s 检查一次有没有哪个 Broker 超过 120s 没发送心跳。如果有，就认为那个 Broker 已经宕机了，从路由信息里要摘除这个 Broker。 那么 Broker 和 NameServer 是如何进行通信的呢？在 RocketMQ 的实现中，Broker 和 NameServer 之间的通信是采用 TCP 长连接进行通信的。也就是说，Broker 会跟每个 NameServer 都建立一个 TCP 长连接，然后定时通过 TCP 长连接发送心跳请求过去。 所以各个 NameServer 就是通过跟 Broker 建立好的长连接不断收到心跳包，然后定时检查 Broker 有没有 120s 都没发送心跳包，来判定集群里各个 Broker 到底挂掉了没有。 MQ 的核心数据模型：Topic生产者和消费者都会往 MQ 里写入消息和获取消息，但是，MQ 中的数据模型是什么？你投递出去的消息在逻辑上到底是放到哪去的？ 这就涉及到一个概念，这个就是 MQ 中的核心数据模型：Topic。这个 Topic，表达的意思就是一个数据集合的意思。举个例子，现在你的订单系统都是进入这个 “topic_order_info” 里面去的，如果你的仓储系统要获取订单消息，那么它可以指定从 “topic_order_info” 这里面去获取消息，获取出来得都是它想要的订单消息。 总结起来就是，Topic 其实就是一个数据集合的意思，不同类型的数据你得放到不同的 Topic 里去。要是你有一些商品数据要发送到 MQ 里，你就应该创建一个 Topic 叫做 “topic_product_info”，代表里面都是商品数据，那些想要从 MQ 里获取商品数据的系统就可以从 “topic_product_info” 里获取了。 所以，你的系统如果要往 MQ 里写入信息或者获取信息，首先就得创建一些 Topic，作为数据集合存放不同类型的消息。 Topic 怎么在 Broker 集群里存储那我们创建的那些 Topic 是怎么存储在 Broker 集群里的？这就体现出一个分布式存储的概念了。 如果我们有一个订单 Topic，可能订单系统每天都会往里面投递几百万条数据，然后这些数据在 MQ 的集群上还得保留几天，那么最终可能会有几千万的数据量，这还只是一个 Topic。如果有多个 Topic，并且里面都有大量的数据，最终加起来的总和也许就是一个惊人的数字，而这么大的数据本身是不太可能存放在一台机器上的。这个时候，就需要分布式存储了。 我们可以在创建 Topic 的时候指定让它里面的数据分散存储在多台 Broker 机器上，比如一个 Topic 里有 1000 万条数据，此时有 2 台Broker，那么可以让每台 Broker 都放 500 万条数据。这样就可以把一个 Topic 代表的数据集合分布式存储在多台机器上了。 另外很重要的一件事是，每个 Broker 在进行定时的心跳汇报给 NameServer 的时候，都会告诉 NameServer 自己当前的数据情况，比如有哪些 Topic 的哪些数据在自己这里，这些信息都是属于路由信息的一部分。 生产者系统如何将消息发送给 Broker接下来，生产者系统是如何将消息发送到 Broker 上的？ 我们在上面说过，在发送消息之前，得有一个 Topic，然后在发送消息的时候你得指定你要发送到哪个 Topic 里面去。既然你知道你要发送的 Topic，那么就可以跟 NameServer 建立一个 TCP 长连接，然后定时从它那里拉取到最新的路由信息，包括集群里有哪些 Broker，集群里有哪些 Topic，每个 Topic 都存储在哪些 Broker上。 然后生产者系统就可以通过路有信息找到自己要投递的 Topic 分布在哪几台 Broker 上。此时可以根据负载均衡算法，从里面选择一台 Broker机器出来。比如 round robine 轮询算法，或者 hash 算法等等。然后选择一台 Broker 之后，就可以跟那个 Broker 也建立一个 TCP 长连接，然后通过长连接向 Broker 发送消息即可。 这里要注意的一点是，生产者一定是投递消息到 Master Broker 的，然后 Master Broker 会同步数据给它的 Slave Brokers，实现一份数据多份副本，保证 Master 故障的时候数据不丢失，而且可以自动把 Slave 切换为 Master 提供服务。 消费者如何从 Broker 上拉取消息消费者系统跟生产者原理是类似的。它们也会跟 NameServer 建立长连接，然后拉取路由消息，接着找到自己要获取的 Topic 在哪几台 Broker 上，就可以跟 Broker 建立长连接，从里面拉取消息了。 这里要注意的一点是，消费者系统可能会从 Master Broker 拉取消息，也可能从 Slave Broker 拉取消息。一切都看具体情况。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM工具使用-使用jmap和jhat弄清楚线上系统的对象分布]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F09%2FJVM%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8-%E4%BD%BF%E7%94%A8jmap%E5%92%8Cjhat%E5%BC%84%E6%B8%85%E6%A5%9A%E7%BA%BF%E4%B8%8A%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AF%B9%E8%B1%A1%E5%88%86%E5%B8%83%2F</url>
    <content type="text"><![CDATA[​ JVM中有两个非常实用的工具：jmap和jhat。这两个工具可以帮助我们观察线上JVM中的对象分布，了解到你的系统运行过程中，哪些对象占据了主角位置，占据了多少内存空间，让你对你的系统有更加细致的了解。 使用jmap了解系统运行时的内存区域​ 如果只是要了解JVM的运行状况，然后去进行JVM GC优化，一般情况下jstat就够用了。但是有时候我们会发现JVM新增对象的速度很快，想要了看看，到底什么对象占据了那么多的内存。如果发现有的对象在代码中可以优化一下创建的时机，避免多种对象对内存占用过大，也许甚至可以去反过来优化一下代码。当然，如果不是出现OOM那种极端情况，也没有那么大的必要着急优化代码。 ​ 先看一个命令：jmap -heap PID，这个命令可以打印出来一系列的信息，大致来说，这个信息会打印出来堆内存相关的一些参数设置，然后就是当前堆内存里的一些基本各个区域的情况。比如Eden区总容量，已经使用的容量、剩余空间容量、两个Survivor区的总容量、已经使用的容量和剩余的空间容量、老年代的总容量、已经使用和剩余的容量等等。 ​ 但是其实这些信息jstat就已经有了，所以一般不会用jmap去看这些信息，毕竟它的信息还没jstat全，例如缺少gc相关的统计。 使用jmap了解系统运行时的对象分布​ jmap命令比较有用的使用方式，是jmap -histo PID。这个命令会打印出类似下面的信息： ​ 这个命令打印出来的东西，会按照各种对象占用内存空间的大小降序排列，把占用内存最多的对象放在最上面。所以如果你只是想要简单了解一下当前JVM中的对象对内存占用的情况，直接使用jmap -histo命令即可。这样就可以快速了解到当前内存里到底是哪个对象占用了大量的内存空间。 使用jmap生成堆内存转储快照​ 如果上面的信息还不够深入，想要更仔细点的。那就可以使用jmap命令生成一个堆内存快照放到一个文件里，用如下的命令：jmap -dump:live,format=b,file=dump.hprof PID。这个命令会在当前目录下生成一个dump.hrpof文件，你不能直接打开看得，它把这一时刻JVM堆内存里所有对象的快照放到文件里去，以方便后续去分析。 使用jhat在浏览器中分许堆转储快照​ 接着就可以使用jhat去分析堆快照了。jhat内置了web服务器，它会支持你通过浏览器以图形化的方式分析堆转储快照。使用jhat dump.hprof命令即可启动jhat服务器，还可以指定自己想要的http端口号，默认是7000端口号。接着你就在浏览器上访问当前这台机器的7000端口号，就可以通过图形化的方式去分析堆内存里的对象分布情况了。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM工具使用-使用jstat了解线上系统的JVM运行状况]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F02%2FJVM%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8-%E4%BD%BF%E7%94%A8jstat%E4%BA%86%E8%A7%A3%E7%BA%BF%E4%B8%8A%E7%B3%BB%E7%BB%9F%E7%9A%84JVM%E8%BF%90%E8%A1%8C%E7%8A%B6%E5%86%B5%2F</url>
    <content type="text"><![CDATA[​ 平时我们对运行中的系统，如果要检查他的JVM的整体运行情况，比较实用的工具是jstat。它可以让你看到当前运行中的系统，它的JVM内的Eden、Survivor、老年代的内存使用情况，还有Young GC和Full GC的执行次数以及耗时。通过这些指标，我们可以分析出当前系统的运行情况，判断当前系统的内存使用压力以及GC压力，还有就是内存分配是否合理。 jstat的使用jstat -gc PID​ 首先要在生产机器linux上，找出Java进程的PID。接着就针对我们的Java进程执行jstat -gc PID。这样就可以看到这个Java进程（其实本质就是一个JVM）的内存和GC情况了。 ​ 运行这个命令之后会看到如下列： 123456789101112131415S0C：这是From Survivor区的大小S1C：这是To Survivor区的大小S0U：这个From Survivor区当前使用的内存大小S1U：这是To Survivor区当前使用的内存大小EC：这是Eden区的大小EU：这是Eden区当前使用后的内存大小OC：这是老年代的大小OU：这是老年代当前使用的内存大小MC：这是方法区（永久代、元数据区）的大小MU：这是方法区（永久代、元数据区）的当前使用的内存大小YGC：这是系统运行迄今为止的Young GC次数YGCT：这是Young GC的耗时FGC：这是系统运行迄今为止的Full GC次数FGCT：这是Full GC的耗时GCT：这是所有GC的总耗时 其他的jstat命令​ 除了上面的jstat -gc命令是最常用的以外，它还有一些命令可以看到更多详细的信息： 123456jstat -gccapacity PID：堆内存分析jstat -gcnew PID：年轻代GC分析，这里的TT和MTT可以看到对象在年轻代存活的年龄和存活的最大年龄jstat -gcnewcapacity PID：年轻代内存分析jstat -gcold PID：老年代GC分析jstat -gcoldcapacity PID：老年代内存分析jstat -gcmetacapacity PID：元数据区内存分析 如何使用jstat工具​ 一般我们分析线上JVM线程，最想知道的信息有哪些？包括如下：新生代对象增长的速率、Young GC的触发频率，Young GC的耗时，每次Young GC后有多少对象是存活下来的，每次Young GC过后有多少对象进入了老年代、老年代对象增长的速率，Full GC的触发频率，Full GC的耗时。 新生代对象增长的速率​ 这其实是对JVM第一个要了解的事情，就是随着系统运行，每秒种会在年轻代的Eden区分配多少对象。要分析这个，你只要在线上linux机器上运行如下命令：jstat -gc PID 1000 10。它的意思是每隔一秒钟更新出最新的一行jstat统计信息，一共执行10次jstat统计。 ​ 通过这个命令，可以非常灵活的对线上机器通过固定频率输出统计信息，观察每隔一段时间的jvm中的Eden区对象占用变化。例如，执行这个命令后，第一秒先显示出Eden区使用了200MB内存，第二秒显示出的统计信息里，Eden区使用了205MB，第三秒显示出Eden区使用了209MB内存，以此类推。此时你就可以推断出这个系统每秒种会新增5MB左右的对象。 ​ 这里大家可以根据自己系统的情况灵活多变地使用，比如系统负载很低，不一定每秒都有请求，那么可以把上面的1秒钟调整为1分钟，甚至10分钟，去看你们系统每隔一定时间大概增长多少对象。还有就是一般系统都有高峰和日常两种状态，比如系统高峰期用的人很多，此时就应该用上述命令看看高峰期的对象增长率，然后还得在非高峰的日常时间段内看看对象的增长速率。 Young GC的触发频率和每次耗时​ 多久触发一次Young GC很容易推测出来，因为系统高峰和日常的对象增长速率都知道了，那么非常简单就可以推测出高峰期多久发生一次Young GC，日常期多久发生一次Young GC。 ​ 比如你Eden区有800MB内存，发现高峰期每秒新增5MB对象，大概高峰期就是3分钟会触发一次Young GC。日常期每秒新增0.5MB，那么日常期大概需要半个小时才会触发一次Young GC。 ​ 至于如何计算Young GC的平均耗时，jstat会告诉你迄今为止系统已经发生了多少次Young GC以及这些Young GC的总耗时。例如系统运行24小时后发生了260次Young GC，总耗时为20s，那么平均下来每次Young GC大概就耗时几十毫秒的时间，你就知道每次Young GC的时候会导致系统停顿几十毫秒。 每次Young GC后有多少对象是存活和进入老年代​ 接着我们想知道每次Young GC后有多少对象会存活下来，以及有多少对象会进入老年代。这个没办法直接看出来，但有办法可以大概推算出来。 ​ 之前我们推算出高峰期的时候多久发生一次Young GC，比如3分钟会有一次Young GC，那么此时我们可以执行下述jstat命令：jstat -gc 180000 10。这就是让他每隔三分钟执行一次统计，连续执行十次。此时可以观察一下，每隔三分钟之后发生了一次Young GC，此时Eden、Survivor和老年代的对象变化。 ​ 正常来说，Eden区肯定会几乎放满之后重新变得里面对象很少，比如800MB的空间就使用了几十MB，Survivor区肯定会放入一些存活对象，老年代可能会增长一些对象占用，所以这里的关键，就是观察老年代的对象增长速率。 ​ 一般情况下，老年代的对象不太可能不停地快速增长的，因为普通的系统没那么多长期存活的对象，如果你发现每次Young GC过后，老年代对象都要增长几十MB，那很有可能就是你一次Young GC过后存活的对象太多了。存活的对象太多，可能导致放入到Survivor区域之后触发了动态年龄判定规则进入老年代，也可能是Survivor区域放不下了，所以大部分存活对象进入老年代。 ​ 最常见的情况是这种：如果你的老年代每次在Young GC过后就新增几百KB，或者几MB的对象，这个还算情有可原，但是如果老年嗲对象快速增长，那一定是不正常的。所以通过上述观察策略，你就可以知道每次Young GC过后多少对象是存活的，实际上Survivor区域里和进入老年代的对象，都是存活的。你也可以知道老年代对象的增长速率，比如每隔3分钟一次Young GC，每次会有50MB对象进入老年代，这就是老年代对象的增长速率，每隔3分钟增长50MB。 Full GC的触发时机和耗时​ 只要知道了老年代对象的增长速率，那么Full GC的触发时机就很清晰了。比如老年代总共有800MB的内存，每隔3分钟新增50MB对象，那么大概每小时就会触发一次Full GC。然后可以看到jstat打印出来的系统运行迄今为止的Full GC次数以及总耗时，比如一共执行了10次Full GC，总耗时30s，每次Full GC大概就是需要耗费3s左右。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之看懂垃圾回收的日志]]></title>
    <url>%2FCKING.github.io%2F2019%2F11%2F29%2FJVM%E4%B9%8B%E7%9C%8B%E6%87%82%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%9A%84%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[打印JVM的GC日志​ 如果想打印GC日志，需要在系统的JVM参数中加入GC日志的打印选型，如下： 123-XX:+PrintGCDetail #打印详细的gc日志-XX:+PrintGCTimeStamps #打印出每次GC发生的时间-Xloggc:log #设置将gc日志写入一个磁盘文件 示例示例程序代码12345678910111213public class Demo1 &#123; public static void main(String[] args) &#123; byte[] array1 = new byte[1024 * 1024]; array1 = new byte[1024 * 1024]; array1 = new byte[1024 * 1024]; array1 = null; byte[] array2 = new byte[2 * 1024 * 1024]; &#125;&#125; ​ 给上述程序配置一下JVM参数： 1-XX:NewSize=5242880 -XX:MaxNewSize=5242880 -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:SurvivorRatio=8 -XX:PretenureSizeThreshold=10485760 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log ​ 这些JVM参数的意思是给堆内存分配10MB内存空间，其中新生代是5MB内存空间，其中Eden区占4MB，每个Survivor区占0.5MB，大对象必须超过10MB才会直接进入老年低，年轻代使用ParNew垃圾回收器，老年代使用CMS垃圾回收器，如图所示： 对象如何分配在Eden区内的​ 上面的代码比较简单。先通过“new byte[1024 * 1024]”这样的代码连续分配了3个数组，每个数组都是1MB。然后通过array1这个局部变量依次引用这三个对象，最后还把array1这个局部变量指向了null。那么在JVM中上述代码如何运行？ ​ 首先第一行代码：byte[] array1 = new byte[1024 * 1024]。这个代码一运行，会在JVM的Eden区内放一个1MB的对象，同时在main线程的虚拟机栈中会压入一个main()方法的桢栈，在main()方法桢栈内部，会有一个“array1”变量，这个变量是指向堆内存Eden区的那个1MB的数组，如下图： ​ 接着第二行代码：array1 = new byte[1024 * 1024]。此时会在堆内存的Eden区中创建第二个数组，并且让局部变量指向第二个数组，然后第一个数组就没人引用了，此时第一个数据就变了没人引用的“垃圾对象”，如图所示： ​ 然后第三行代码：byte[] array1 = new byte[1024 * 1024]。这行代码在堆内存的Eden区内创建了第三个数组，同时让array1变量指向了第三个数组，此时前面两个数组都没有引用了，变成了垃圾对象。 ​ 第四行代码：array1 = null。这行代码一执行，就让array1这个变量什么都不指向，此时会导致之前创建的3个数组全部变成垃圾对象，如图： ​ 最后第五行代码：byte[] array2 = new byte[2 * 1024 * 1024]。此时会分配一个2MB大小的数组，尝试放入Eden区中。但这是不行的，因为Eden区总共就4MB大小，而且里面已经放入了3个1MB的数组，所以剩余空间只有1MB，此时放一个2MB的的数组是放不下的。这个时候就会触发年轻代的Young GC。 讲解GC日志​ 当我们以指定的JVM参数运行，会在根目录生成一个文件gc.log。打开gc.log文件，会看到如下内容： 1234567891011121314151617181920212223Java HotSpot(TM) 64-Bit Server VM (25.151-b12) for windows-amd64 JRE (1.8.0_151-b12), built on Sep 5 2017 19:33:46 by "java_re" with MS VC++ 10.0 (VS2010)Memory: 4k page, physical 33450456k(25709200k free), swap 38431192k(29814656k free)CommandLine flags: -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:MaxNewSize=5242880 -XX:NewSize=5242880 -XX:OldPLABSize=16 -XX:PretenureSizeThreshold=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:-UseLargePagesIndividualAllocation -XX:+UseParNewGC0.268: [GC (Allocation Failure) 0.269: [ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs] 4030K-&gt;574K(9728K), 0.0017518 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]Heappar new generation total 4608K, used 2601K [0x00000000ff600000, 0x00000000ffb00000, 0x00000000ffb00000) eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000)concurrent mark-sweep generation total 5120K, used 62K [0x00000000ffb00000, 0x0000000100000000, 0x0000000100000000)Metaspace used 2782K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K ​ 现在让我们来讲解一下这个日志。 ​ 首先在GC日志中，可以看到以下内容： CommandLine flags: -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:MaxNewSize=5242880 ......... ​ 这是说明这次运行程序采取的JVM参数是什么，基本是我们设置的，同时还有一些参数默认就给设置了，不过一般关系不大。 ​ 接着看GC日志中的如下一行： 0.268: [GC (Allocation Failure) 0.269: [ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs] 4030K-&gt;574K(9728K), 0.0017518 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] ​ 这个就是概要说明了本次GC的执行情况。GC (Allocation Failure)是发生GC的原因，我们要分配一个2MB的数组，结果Eden区内存不够，所以就出现了“Allocation Failure”，即对象分配失败。所以此时就要触发一次Young GC。 ​ 那这次GC什么时候发生呢？通过上面的一个数字0.268，这个意思是说你的系统运行以后过了多少秒发生了本次的GC，比如这里就是大概系统运行之后大概200多毫秒，发生了本次GC。 ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs ​ 这个ParNew。我们触发的是年轻代的Young GC，所以用我们指定的ParNew垃圾回收器执行GC的。而4030K -&gt; 512K(4608K)，这个代表的意思是年轻代可用的空间是4608KB，也就是4.5MB。因为上面的例子中，Eden区是4MB，两个Survivor中只有一个是可以放存活对象的，另外一个必须一致保持空闲，所以它考虑年轻代的可用空间，就是Eden + 1个Survivor的大小，也就是4.5MB。 ​ 然后4030K -&gt; 512K。意思是对年轻代执行了一次GC，GC之前都使用了4030KB，但是GC之后只有512KB的对象存活了下来。而0.0015734 secs这个是本次GC耗费的时间。这里大概是1.5ms，仅仅是回收3MB的对象而已。 ​ 4030K-&gt;574K(9728K), 0.0017518 secs，这段话指的是整个Java堆内存的情况。意思是整个Java堆内存是总可用空间9728KB（9.5MB），其实就是4.5MB + 老年代5MB，然后GC前整个Java堆内存里使用了4030KB，GC之后Java堆内存使用了574KB。 [Times: user=0.00 sys=0.00, real=0.00 secs] ​ 这个意思就是本次GC消耗的时间。这里最小单位是小数点之后两位，但是这里全部是0.00 secs，也就是说本次gc就耗费了几毫秒。所以从秒为单位来看，几乎是0。 图解GC执行过程​ 第一个问题，ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs。在GC之前，明明在Eden区域里放了3个1MB的数组，一共是3MB，也就是3072KB的对象，那么GC之前年轻代应该是使用了3072KB的内存，为什么是4030KB的内存？其实要明白两点： 虽然你创建的数组本身是1MB，但是为了存储这个数组，JVM内置还会附带一些其他信息，所以每个数组实际占用的内存是大于1MB的； 除了你自己创建的对象以外，可能还有一些你看不见的对象在Eden区里。 ​ 如图所以，GC之前，三个数组和其他一些未知对象加起来，就是占据了4030KB的内存： ​ 接着你要在Eden分配一个2MB的数组，此时肯定触发了“Allocation Failure”，对象分配失败，就触发了Young GC，然后ParNew执行垃圾回收，回收掉之前我们创建的三个数组，此时因为它们都没人引用了，一定是垃圾对象，如图： ​ 继续看gc日志：ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs。gc回收之后，从4030KB内存使用降低到了512KB的内存使用，也就是说这次gc日志有512KB的对象存活了下来，从Eden区转移到了Survivor1区。或者我们改一下称呼，叫做Survivor From区，另外一个叫做Survivor To区。 ​ 结合GC日志日志就能看出，这就是本次GC的全过程。 GC过后的堆内存使用情况​ 接着我们看下面的GC日志： 123456789101112131415Heappar new generation total 4608K, used 2601K [0x00000000ff600000, 0x00000000ffb00000, 0x00000000ffb00000) eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000)concurrent mark-sweep generation total 5120K, used 62K [0x00000000ffb00000, 0x0000000100000000, 0x0000000100000000)Metaspace used 2782K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K ​ 这段日志是在JVM退出的时候打印出来的当前堆内存的使用情况，其实也很简单。先看这段： 1234567par new generation total 4608K, used 2601K [0x00000000ff600000, 0x00000000ffb00000, 0x00000000ffb00000) eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000) ​ par new generation total 4608K,used 2601K，就是说“ParNew”垃圾回收器复制的年轻代共有4608KB（4.5MB）可用内存，目前是使用了2601KB（2.5MB）。为什么JVM退出之前，年轻代占用了2.5MB的内存？因为在gc之后，我们有通过了代码byte[] array2 = new byte[2 * 1024 * 1024]分配了一个2MB的数组，所以此时Eden区中会有一个2MB的数组，也就是2048KB，然后上次gc之后在From Survivor区中存活了一个512KB的对象。但2048 + 512 = 2560KB，为什么年轻代使用了2601KB？因为之前说过每个数组会额外占据一些内存来存放一些自己这个对象的元数据，所以你可以认为多出来的41KB可以是数组对象额外使用的空间。如图： ​ 继续看日志 12345eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000) ​ 通过GC日志可以验证我们的推测是正确的，这里说的很清楚，Eden区此时4MB的内存被使用了51%，就是因为有一个2MB的数组在里面，然后From Survivor区，512KB是100%的使用率，此时被之前gc后的512KB的未知对象占据了。 ​ 后面的日志 12345concurrent mark-sweep generation total 5120K, used 62K [0x00000000ffb00000, 0x0000000100000000, 0x0000000100000000)Metaspace used 2782K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K ​ concurrent mark-sweep generation total 5120K, used 62K这就是CMS垃圾回收器，管理的老年代内存空间一共是5MB。此时使用了62KB的空间。而下面两段日志也很简单，就是Metaspace元数据空间和Class空间，存放一些类信息、常量池之类的东西，此时他们的总容量和使用内存等等。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾回收器之G1回收器]]></title>
    <url>%2FCKING.github.io%2F2019%2F11%2F05%2FJVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%E4%B9%8BG1%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[ParNew + CMS组合的痛点​ 传统的JVM垃圾回收器ParNew + CMS组合有一个很大的痛点，就是Stop the World。无论是新生代垃圾回收，还是老年代垃圾回收，都会或多或少产生“Stop the World”现象，对系统的运行有一定的影响。所以后面对垃圾回收器的优化，都是朝着减少“Stop the World”的目标去做的。在这个基础上，G1垃圾回收器就应运而生，它提供了比ParNew + CMS组合更好的垃圾回收的性能。 G1垃圾回收器​ G1垃圾回收器是可以同时回收新生代和老年代的对象的，不需要两个垃圾回收器配合起来运作，它一个人就可以搞定所有的垃圾回收。 ​ 它最大的一个特点，就是把Java堆内存拆分为多个大小相等的Region，如图： ​ 然后G1也会有新生代和老年代的概念，但是只不过是逻辑上的概念，即，新生代可能包含了某些Region，老年代也可能包含了某些Region，如图： ​ 而且G1最大的一个特点，就是可以让我们设置一个垃圾回收的预期停顿时间。也就是说比如我们可以指定：希望G1在垃圾回收的时候，可以保证，在一小时内由G1垃圾回收导致的“Stop the World”时间，不能超过一分钟。 ​ 这个就很厉害了，我们之前的一系列JVM优化思路，包括内存合理分配等待，都是为了尽可能减少Minor GC和Full GC带来的系统停顿，避免影响系统处理请求。但是我们现在可以直接给G1指定，在一个时间内，垃圾回收导致的系统停顿时间不能超过多久，G1全权给你负责，保证达到目标，这相当于我们就可以直接控制垃圾回收对系统性能的影响了。 G1对垃圾回收导致的系统停顿可控的原理​ G1要做到这一点，就必须要追踪每个Region里的回收价值。也就是说，它必须搞清楚每个Region里的对象有多少是垃圾，如果对这个Region进行垃圾回收，需要耗费多长时间，可以回收掉多少垃圾。 ​ 如下图，G1通过追踪发现，1个Region的垃圾对象有10MB，回收它们需要耗费1秒钟，另外一个Region中对垃圾对象有20MB，回收它们需要耗费200毫秒。 ​ 然后在垃圾回收的时候，G1会发现在最近一个时间段内，比如一小时内，垃圾回收已经导致了几百毫秒的停顿了，现在又要执行一次垃圾回收，那么必须是回收上图中那个只需要200ms就能回收掉20MB垃圾的Region，于是G1触发一次垃圾回收，虽然导致了系统停顿了200ms，但是一下子回收了更多的垃圾。 ​ 所以简单来说，G1可以做到让你来设定垃圾回收对系统的影响，它自己通过把内存拆分为大量小Region，以及追踪每个Region中可回收对象大小和预估时间，最后在垃圾回收的时候，尽量把垃圾回收对系统造成的影响控制在你指定的时间范围内，同时在有限的时间内尽量回收尽可能多的垃圾对象。这就是G1的核心设计思路。 Region可能属于新生代也可能是老年代​ 在G1中，每一个Region可能属于新生代，也可能属于老年代。刚开始Region可能谁都不属于，然后接着就分配给了新生代，放了很多属于新生代的对象，接着就触发了垃圾回收这个Region。然后下一次同一个Region可能又分配了老年代，用来存放老年代的长生存周期的对象。 ​ 所以其实在G1对应的内存模型中，Region随时会属于新生代也会属于老年代，所以没有所谓新生代给多少内存，老年代给多少内存这一说了，实际上新生代和老年代各自的内存区域是不停变动的，由G1自动控制。 设定G1对应的内存大小​ 上面说到G1对应的是一大堆的Region内存区域，每个Region的大小是一致的。那到底有多少个Region呢？每个Region的大小是多大呢？其实这个默认情况下是自动计算和设置的，我们可以给整个堆内存设置一个大小，比如用-Xms和-Xmx来设置堆内存的大小，然后JVM启动的时候发现你使用的是G1垃圾回收器，可以使用-XX:+UseG1GC来指定使用G1垃圾回收器，此时会自动用堆大小除以2048，因为JVM最多可以有2048个Region，然后Region的大小必须是2的倍数，比如说1MB、2MB和4MB之类的。 ​ 比如说堆大小是4G，就是4096MB，此时除以2048个Region，每个Region的大小就是2MB，大概就是这个样子来决定Region的数量和大小的，一般保持默认的计算方式就可以。如果通过手动的方式来指定，则可以使用-XX:G1HeapRegionSize。 ​ 刚开始的时候，默认新生代对堆内存的占比是5%，也就是占据200MB左右，对应大概是100个Region。这个可以通过-XX:G1NewSizePercent来设置新生代初始占比，其实维持这个默认值即可，因为在系统运行中，JVM会不停地给新生代增加更多的Region，但是最多新生代的占比不会超过60%，可以通过-XX:G1MaxNewSizePercent来设置。而且一旦Region进行了垃圾回收，此时新生代的Region数量还会减少，这些其实都是动态的。 新生代还有Eden和Survivor的概念​ 虽然G1把内存划分了很多的Region，但是其实还是有新生代和老年代的区分，而且新生代里还是有Eden和Survivor的划分的。之前说过的一个新生代的参数：-XX:SurvivorRatio=8，比如说新生代刚开始的时候，有100个Region，那么可能80个Region就是Eden，两个Survivor各自占10个Region。所以大家要明白这里其实还是有Eden和Survivor的概念的，它们会各自占据不同的Region，只不过随着对象不停地在新生代里分配，属于新生代的Region会不断增加，Eden和Survivor对应的Region也会不断增加。 G1的新生代垃圾回收​ 既然G1的新生代也有Eden和Survivor的区分，那么触发垃圾回收的机制都是类似的。 ​ 随着不停地在新生代的Eden对应的Region中放对象，JVM会不停地给新生代加入更多的Region，直到新生代占据堆大小的最大比例60%。一旦新生代达到了设定的占据堆内存的最大大小60%，比如都有1200个Region了，里面的Eden可能占据了1000个Region，每个Survivor是100个Region，而且Eden区还占满了对象，如图： ​ 这个时候还是会触发新生代的GC，G1就会用之前说过的复制算法来进行垃圾回收，进入了一个“Stop the World”状态，然后把Eden对应的Region中的存活对象放入到S1对应的Region中，接着回收掉Eden对应的Region中的垃圾对象。 ​ 但是这个过程还有跟之前有区别的，因为G1是可以设定目标GC停顿时间的，也就是G1执行GC的时候最多可以让系统停顿多长时间，可以通过-XX:MaxGCPauseMills参数来设定，默认值是200ms。那么G1就会通过之前说的，对每个Region追踪回收它需要多少时间，可以回收多少对象来选择回收一部分的Region，保证GC停顿时间控制在指定范围内，尽可能多地回收掉一些对象。 对象什么时候进入老年代​ 在G1的内存模型下，新生代和老年代各自都会占据一定的Region，老年代也会有自己的Region，按照默认，新生代最多只能占据堆内存60%的Region来推算，老年代最多可以占据40%的Region。那么对象什么时候可以从新生代进入老年代呢？ 对象在新生代躲过了很多次的垃圾回收，达到了一定的年龄了，-XX:MaxTenuringThreshold参数可以设置这个年龄，他就会进入老年代。 动态年龄判定规则，如果一旦发现某次新生代GC过后，存活对象超过了Survivor的50%。此时就会判断一下，比如年龄为1岁、2岁、3对和4岁的对象的大小综合超过了Survivor的50%，此时4岁以上的对象全部会进入老年代。这就是动态年龄判定规则。 ​ 经过一段时间的新生代使用和垃圾回收之后，总有一些对象会进入老年代中。 大对象Region​ 在以前，大对象是可以直接进入老年代的，那G1这套内存模型下呢？实际上这里会有所不同，G1提供了专门的Region来存放大对象，而不是让大对象进入老年代的Region中。 ​ 在G1中，大对象的判定规则就是一个大对象超过了一个Region大小的50%，例如按照上面的算的，每个Region是2MB，只要一个对象超过了1MB，就被被放入专门的Region中。而且一个大对象如果太大，可能会横跨多个Region来存放。如图： ​ 那堆内存哪些Region用来存放大对象呢？之前不是说60%给新生代，40%给老年代吗，那还有哪些Region给大对象？很简单，之前说过了，在G1里，新生代和老年代的Region是不停变化的。比如新生代占据了1200个Region，但是一次垃圾回收之后，就让里面1000个Region都空了，此时那1000个Region就可以不属于新生代了，里面很多Region可以用来存放大对象。 ​ 在垃圾回收方面，新生代、老年代在回收的时候，会顺带着对大对象Region一起回收，所以这就是G1内存模型下对大对象的分配和回收的策略。 新生代 + 老年代的混合垃圾回收​ G1有一个参数，是-XX:InitiatingHeapOccupancyPercent，它的默认值是45%。意思是说，如果老年代占据了堆内存的45%的Region的时候，此时就会尝试触发一个新生代 + 老年代一起回收的混合回收阶段。 G1垃圾回收的过程​ 首先会触发一个“初始标记”的操作，这个过程需要进入“Stop the World”，但仅仅只是标记一下GC Roots直接能引用的对象，这个过程是很快的。它会先停止系统的运行，然后对各个线程栈内存中的局部变量代表的GC Roots、以及方法区中的静态变量代表的GC Roots，进行扫描，标记出它们直接引用的那些对象。 ​ 接着会进入“并发标记”的阶段，这个阶段允许系统程序的运行，同时进行GC Roots，从GC Roots开始追踪所有的存活对象。 ​ 这里对GC Roots追踪做更加详细的说明，比如下面的代码 12345678public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125;public class ReplicaManager &#123; public ReplicaFetcher replicaFetcher = new ReplicaFetcher();&#125; ​ 上面代码中，Kafka类有一个静态变量是“replicaManager”，它就是一个GC Roots对象，初始标记阶段，仅仅就是标记这个“replicaManager”作为GC Roots直接关联的对象，就是“ReplicaManager”对象，它肯定是要存活的。 ​ 然后在并发标记阶段，就会进行GC Roots追踪，会从“replicaManager”这个GC Roots对象直接关联的“ReplicaManager”对象开始往下追踪，可以看到“ReplicaManager”对象里有一个实例变量“replicaFetcher”，此时追踪这个“replicaFetcher”变量可以看到它引用了“ReplicaFetcher”对象，那么此时这个“ReplicaFetcher”对象也要被标记为存活对象。 ​ 这个并发标记阶段还是很耗时的，因为要追踪全部的存活对象，但是这个阶段可以跟系统程序并发运行，所以对系统程序的影响不太大，而且JVM会对并发标记阶段对对象做出的一些修改记录起来，比如说哪个对象被新建了，哪个对象失去了引用。 ​ 接着下一个阶段，最终标记阶段，这个阶段会进入“Stop the World”，系统程序是禁止运行的，但是会根据并发标记阶段记录的那些对象修改，最终标记有哪些存活对象，有哪些是垃圾对象。 ​ 最后一个极端就是“混合回收”阶段。这个阶段会计算老年代中每个Region中的存活对象数量，存活对象的占比，还有执行垃圾回收的预期性和效率。接着系统会停止系统程序，然后全力以赴尽快进行垃圾回收，此时会选择部分Region进行回收，因为必须让垃圾回收的停顿时间控制在我们指定的范围内。 ​ 这里需要注意的是，老年代对堆内存占比达到45%的时候，触发的是混合回收。即，此时垃圾回收不仅仅是回收老年代，还会回收新生代和大对象。那到底是回收这些区域的哪些Region呢？这个就要看情况了，因为我们设定了对GC停顿时间的目标，所以它会从新生代、老年代和大对象各自挑选一些Region，保证用指定的时间回收尽可能多的垃圾，这就是所谓的混合回收。 G1垃圾回收器的一些参数​ 上面说过老年代的Region占据了堆内存的Region的45%之后，会触发一个混合回收的过程，并且分了四个阶段。在最后一个阶段，就是执行混合回收，从新生代和老年代都回收一些Region。但是最后一个阶段混合回收的时候，其实会停止所有程序运行，所以说G1是允许执行多次混合回收的。 ​ 例如先停止工作，执行一次混合回收回收掉一些Region，接着恢复系统运行，然后再次停止系统运行，再执行一次混合回收回收掉一些Region。 ​ 有一些参数可以控制这个，比如-XX:G1MixedGCCountTarget参数，就是在一次混合回收的过程中，最后一个阶段执行几次混合回收，默认是8次。意味着最后一个阶段，先停止系统运行，混合回收一些Region，再恢复系统运行，接着再次禁止系统运行，混合回收一些Region，反复8次。 ​ 例如一次混合回收预期要回收一共有160个Region，那么此时第一次混合回收，会回收掉一些Region，比如就是20个Region，接着恢复系统一会儿，然后再执行一次“混合回收”，再次回收掉20个Region。如此反复执行8次回收阶段之后，就可以把预期的160个Region都回收掉了，而且还把系统停顿时间控制在指定范围内。 ​ 为什么要反复回收多次？因为你停止系统一会儿，回收掉一些Region，再让系统运行一会儿，然后再次停止系统一会儿，再次回收掉一些Region，这样可以尽可能让系统不要停顿时间过长，可以在多次回收的间隙，也运行一下。 ​ 还有一个参数：-XX:G1HeapWasterPercent，默认值是5%。它的意思是说，在混合回收的时候，对Region回收都是基于复制算法进行的，都是把要回收的Region里的存活对象放入其他Region，然后这个Region中的垃圾对象全部清理掉。 ​ 这样的话回收过程就会不断空出来新的Region，一旦空闲出来的Region数量达到了堆内存的5%，此时就会立即停止混合回收，意味着本次混合回收就结束了。而且G1整体是基于复制算法对Region进行垃圾回收的，不会出现内存碎片的问题，不需要像CMS那样标记-清理之后，再进行内存碎片的整理。 ​ 还有一个参数：-XX:G1MixedGCLiveThresholdPercent，它的默认值是85%，意思就是确定要回收的Region的时候，必须是存活对象低于85%的Region才可以进行回收。 回收失败的Full GC​ 如果在进行Mixed回收的时候，无论是年轻代还是老年代都基于复制算法进行回收的，都要把各个Region的存活对象拷贝到别的Region里去，此时万一出现拷贝的过程中发现没有空闲的Region可以承载自己的存活对象那，就会处罚一次失败。 ​ 一旦失败，立马就会切换为停止系统程序，然后采用单线程进行标记、清理和压缩整理，空闲出来一批Region，这个过程是极慢极慢的。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Stream入门]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F29%2FSpring-Cloud-Stream%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Spring Cloud Stream​ 官方定义Spring Cloud Stream是一个构建消息驱动微服务的框架。应用程序通过inputs或者outputs来与Spring Cloud Stream中binder交互，通过我们来配置binding，而Spring Cloud Stream的binder负责与消息中间件交互。所以，我们只需要搞清楚如何与Spring Cloud Stream交互就可以方便使用消息驱动的方式。它通过使用Spring Integration来连接消息中间件以实现消息事件驱动。Spring Cloud Stream为一些供应商的消息中间件产品提供了个性化的自动化配置实现，引用了发布-订阅、消费组、分区的三个概念。目前支持市场上主流的多个消息中间件。 发布/订阅​ 简单的讲就是一种生产者、消费者模式。发布者是生产，将输出发布到数据中心，订阅者是消费者，订阅自己感兴趣的数据。当有数据到达数据中心，就把数据发送给对应的订阅者。 消费组​ 直观的理解就是一群消费者一起处理消息。需要注意的是：每个发动到消费组的数据，仅有消费组中的一个消费者处理。 分区​ 类比于消费组，分区是将数据分区。例如，某个应用有多个实例，都绑定到同一个数据中心，也就是不同实例都将数据发布到同一个数据中心。分区就是将数据中心的数据再细分成不同的区。为什么需要分区？因为即使是同一个应用，不同实例发布的数据类型可能不同，也希望这些数据由不同的消费者处理。这就需要，消费者可以仅订阅一个数据中心的部分数据，这就需要分区这个东西了。 Stream解决了什么问题​ Stream解决了开发人员无感知地使用消息中间件的问题，因为Stream对消息中间件的进一步封装，可以做到代码层面对中间件的无感知，甚至于动态的切换中间件（rabbitMQ切换为Kafka），使得微服务开发的高度解耦，服务可以关注更多自己的业务流程。结构图如下： 组成 说明 Middleware 中间件，支持市场上多种主流的MQ中间件 Binder Binder是应用与消息中间件之间的封装。通过Binder可以很方便地连接中间件，可以动态地改变消息类型（对应于Kafka的topic，RabbitMQ的exchange），这些都可以通过配置文件来实现 @Input 注解标识输入通道，通过该输入通道接收到的信息进入应用程序 @Output 注解标识输出通道，发布的消息将通过该通道离开应用程序 @StreamListener 监听队列，用于消费者队列的消息接收 @EnableBinding 指信道channel和exchange绑定在一起 消息驱动入门案例​ 现在通过一个入门案例来演示通过stream整合RabbitMQ来实现消息的异步通信的效果。首先是先安装部署RabbitMQ，具体方法自行百度。我这边是用docker安装的RabbitMQ，参考的是这篇文章：Docker 安装部署RabbitMQ。 ​ RabbitMQ安装好之后，就开始我们的代码了。首先先创建SpringCloud的一个父工程，然后在父工程下面新建两个服务： cloud-stream-producer-rabbitmq：作为一个发布者，将消息推动到RabbitMQ cloud-stream-consumer-rabbitmq：消费者消费信息 ​ 首先是添加依赖，其中最主要的是spring cloud stream的RabbitMQ依赖，还有就是为了使用spring cloud stream，我们还要引入spring cloud依赖，整个pom文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;cloud-stream-producer-rabbitmq&lt;/module&gt; &lt;module&gt;cloud-stream-consumer-rabbitmq&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.springcloudstream&lt;/groupId&gt; &lt;artifactId&gt;rabbitmqdemo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmqdemo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-test-support&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 创建生产者​ 如前所述，将消息从发布者传递到队列的整个过程是通过通道Channel完成的，因此，我们创建一个HelloBinding接口，其中包含我们自定义的消息信道greetingChannel。 12345public interface HelloBinding &#123; @Output("greetingChannel") MessageChannel greeting();&#125; ​ 因为这个是要发布消息的，所以我们使用@Output注解，方法名可以是我们想要的任何名称，当然，我们可以在一个接口中有多个Channel（通道）。 ​ 现在，我们创建一个Controller，它将消息推动到这个Channel（通道） 12345678910111213141516@RestControllerpublic class ProducerController &#123; private MessageChannel greet; public ProducerController(HelloBinding binding) &#123; greet = binding.greeting(); &#125; @GetMapping("/greet/&#123;name&#125;") public void publish(@PathVariable String name) &#123; String greeting = "hello " + name + "!"; Message&lt;String&gt; msg = MessageBuilder.withPayload(greeting).build(); this.greet.send(msg); &#125;&#125; ​ 上面我们创建了一个ProducerController类，它有一个MessageChannel类型的属性，这是我们通过我们前面声明的方法在构造函数中初始化的。然后，我们有一个简单的Restful接口， 它接收PathVariable的name，并使用MessageBuilder创建一个String类型的消息。最后，我们使用MessageChannel上的.send()方法来发布消息。 ​ 现在,我们将在的主类中添加@EnableBinding注解，传入HelloBinding告诉Spring加载。 12345678@EnableBinding(HelloBinding.class)@SpringBootApplicationpublic class ProducerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProducerApplication.class, args); &#125;&#125; ​ 最后，我们必须告诉Spring如何连接到RabbitMQ，并将greetingChannel连接到一可用的消费这。而这些都是在application.properties配置文件中定义的。 123456789spring.rabbitmq.addresses=47.105.176.129spring.rabbitmq.username=rootspring.rabbitmq.password=xxxspring.rabbitmq.port=5672spring.rabbitmq.virtual-host=my_vhostspring.rabbitmq.publisher-confirms=truespring.cloud.stream.bindings.greetingChannel.destination=greetingsserver.port=8080 ​ 其中，spring.cloud.stream.bindings.greetingChannel.destination的意思是greetingChannel这个通道的目的地，类似于Kafka的Topic和RabbitMQ的队列的概念 。后面的消费者也是通过这个去配置消费者去相同的Channel中取数据。另外一个配置spring.rabbitmq.virtual-host，是配置当前用户的权限，这个我们可以通过RabbitMQ的管理界面去确定这个配置的内容： 创建消费者​ 现在，我们需要监听之前创建的通道greetingChannel。让我们创建一个绑定，为了区分，消费者的Channel我们命名为helloChannel。 1234567public interface HelloBinding &#123; String GERRTING = "helloChannel"; @Input(GERRTING) SubscribableChannel greeting();&#125; ​ 与生产者绑定的两个非常明显的区别。因为我们是要消费信息，所以我们使用SubscribableChannel和@Input标识它为消费者。消息推送将被推送到这里。 ​ 现在，我们创建处理数据的方法： 12345678@EnableBinding(HelloBinding.class)public class HelloListener &#123; @StreamListener(target = HelloBinding.GERRTING) public void processHelloChannelGreeting(String msg) &#123; System.out.println(msg); &#125;&#125; ​ 在这里，我们创建一个HelloListener类，在processHelloChannelGreeting方法上添加@StreamListener注解，这个方法需要一个字符串作为参数。我们还在类添加@EnableBinding启用了HelloBinding。 ​ 注意，我们在这里使用@EnableBinding，而不是主类，我们的主类，其实是没有任何修改的： 123456@SpringBootApplicationpublic class ConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class, args); &#125;&#125; ​ 最后，我们修改消费者的配置文件： 123456789spring.rabbitmq.addresses=47.105.176.129spring.rabbitmq.username=rootspring.rabbitmq.password=xxxspring.rabbitmq.port=5672spring.rabbitmq.virtual-host=my_vhostspring.rabbitmq.publisher-confirms=truespring.cloud.stream.bindings.helloChannel.destination=greetingsserver.port=9090 ​ 其中，spring.cloud.stream.bindings.helloChannel.destination的意思是helloChannel这个通道的目的地是greetings，这个跟生产者是一样的，从而让消费者指向了跟生产者一样的目的地。 测试​ 我们同时启动生产者和消费者，通过浏览器或postman访问http://localhost:8080/greet/ckin来生产消息，可以在打印台中看到看到消息内容： ​ 现在我们启动另一个消费者服务。端口号为9091，当我们点击生产者的REST端点生产消息时，我们看到两个消费者都收到了消息： ​ 如果我们只想让一个消费者消费一条消息的话，我们可以在application.properties中创建一个消费者组。消费者的文件如下： 1spring.cloud.stream.bindings.greetingChannel.group = greetings-group ​ 相关代码已上传到github，需要的可以去下载。 参考资料Spring Cloud Stream入门介绍 消息驱动式微服务：Spring Cloud Stream &amp; RabbitMQ]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之垃圾回收器]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F23%2FJVM%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[​ 在新生代和老年代进行垃圾回收的时候，都是要用垃圾回收器进行回收的，不同的区域用不同的垃圾回收器。常用的垃圾回收机有一下几种： Serial和Serial Old垃圾回收器：分别用来回收新生代和老年代的垃圾对象。工作原理就是单线程运行，垃圾回收的时候会停止我们自己写的系统的其他工作线程，让我们系统直接卡死不动，然后让他们垃圾回收，这个现在一般写后台Java系统几乎不用。 ParNew和CMS垃圾回收器：ParNew现在一般都是用在新生代的垃圾回收器，CMS是用在老年代的垃圾回收器，他们都是多线程并发的机制，性能更好，现在一般是线上生产系统的标配组合。 G1垃圾回收器：统一收集新生代和老年代，采用了更加优秀的算法和设计机制。下面会详细介绍这个G1垃圾回收器。 GC的大概流程​ 看下图，新生代的内存一般都是分为一个Eden和两个Survivor ​ 此时系统不停的运行，然后把Eden给塞满了，此时就会触发Minor GC。进行垃圾回收时有专门的垃圾回收线程的，而且对不同的内存区域会有不同的垃圾回收器。相当于垃圾回收线程和垃圾回收器配合起来，使用自己的垃圾回收算法，对指定的内存区域进行垃圾回收。 ​ 由上图可知，垃圾回收会通过一个后台运行的垃圾回收线程来执行它具体的一个逻辑。比如针对新声代我们会用ParNew垃圾回收器进行回收，然后ParNew垃圾回收器针对新生代采用的就是复制算法来垃圾回收。 GC的时候还能继续创建新的对象吗​ 我们写好的Java系统在运行期间能不能继续在新生代里创建新的对象？假设一个场景，如下图： ​ 如图所示，如果一边垃圾回收器在想办法把Eden和Survivor2里的存活对象标记出来转移到Survivor2去，然后还在想办法把Eden和Survivor2的垃圾对象清理掉，结果这个时候系统程序还在不停的在Eden里创建新的对象。而这些新的对象很快就成了垃圾对象，有的还有人引用是存活对象。这样子就会全部乱套了，对于程序新创建的这些对象，你怎么让垃圾回收器去持续追踪这些新对象的新状态？所以，在垃圾回收过程中，同时还允许我们写的Java系统不停的运行在Eden里持续创建新的对象，目前来看是不合适的。 Stop the World​ 由上述可知，平时使用的JVM最大的痛点，就是在垃圾回收的这个过程。因为在垃圾回收的时候，尽可能让垃圾回收器专心致志的干活，不能随便让我们写的Java系统继续创建对象了，所以此时JVM会在后台直接进入“stop the World”状态。即，它会直接停止我们写的Java系统的所有工作线程，让我们写的代码不再运行，然后让垃圾回收线程可以专心致志地进行垃圾回收的工作。 ​ 这样的话，就可以让我们的系统暂停运行，然后不再创建新的对象，同时让垃圾回收线程尽快完成垃圾回收的工作，就是标记和转移Eden和Survivor2的存活对象到Survivor1中去，然后尽快一次性地回收掉Eden和Survivor2中的垃圾对象。一旦垃圾回收完毕，既可以继续恢复我们写的Java系统的工作线程了，然后我们的那些代码就可以继续运行，继续在Eden中创建新的对象。 Stop the World造成的系统停顿​ 现在大家清楚了“Stop the World”对系统造成的影响了，假设我们的Minor GC要运行100ms，那么可能会导致我们系统直接停顿100ms不能处理任何请求。如果因为内存分配不合理，导致对象频繁进入老年代，平均七八分钟一次Full GC，而Full GC是最慢的，有的时候弄不好一次回收要运行几秒钟，甚至是几分钟都是有可能的。 ​ 因此，无论是新生代GC还是老年代GC，都尽量不要让频率过高，也避免持续时间过长，避免影响系统正常运行，这也是使用JVM过程中一个最需要优化的地方，也是最大的一个痛点。 新生代垃圾回收器：ParNew​ 一般来说，假设没有最新的G1垃圾回收器的话，大家线上系统都是ParNew垃圾回收器作为新生代的垃圾回收器。 ​ 新生代的ParNew垃圾回收器主打的是多线程垃圾回收机制。另外一种Serial垃圾回收器主打的是单线程垃圾回收，他们两都是回收新生代的，唯一的区别就是单线程和多线程的区别，但是垃圾回收算法都是一致的。 ​ 如下图，ParNew垃圾回收器如果一旦在合适的时期执行Minor GC的时候，就会把系统程序的工作线程全部停掉，禁止程序继续运行创建新的对象，然后自己就用多个垃圾回收线程去进行垃圾回收，回收的机制和算法跟之前是一样的。 为线上系统指定使用ParNew垃圾回收器​ 线上系统，如果部署到Tomcat时可以在Tomcat的catalina.sh中设置Tomcat的JVM参数，使用Spring Boot也可以在启动时指定JVM参数。 ​ 在启动系统的时候，使用-XX:+UseParNewGC选项，就可以对系统指定使用ParNew垃圾回收器。那么Minor GC的时机，检查机制，包括垃圾回收的具体过程，以及对象升入老年代的机制，都是我们之前说的那套原理了，只不过，ParNew会使用多个线程来进行垃圾回收。 ParNew垃圾回收器默认情况下的线程数量​ 因为现在一般我们部署系统的服务器都是多核CPU，所以为了在垃圾回收的时候充分利用多核CPU的资源，一旦我们指定了使用ParNew垃圾回收器之后，他默认给自己设置的垃圾回收线程的数量就是跟CPU的核数是一样的。 ​ 比如我们线上机器假设用的是4核CPU或者8核CPU，那么此时ParNew的垃圾回收线程数就会分别是4个线程、8个线程。 ​ 这个东西一般不用我们手动去调节，因为跟CPU核数一致的线程数量，是可以充分进行并行处理的。如果要调节ParNew的垃圾回收线程数量，可以使用-XX:ParallelGCThreads参数即可。但是一般不建议随意动这个参数。 老年代垃圾回收器：CMS​ 一般老年代我们选择的垃圾回收器是CMS，他采用的是标记整理算法，其实非常简单，就是先用之前讲过的标记方法区标记出哪些对象是垃圾对象，然后把这些垃圾对象清理掉。 先Stop the World，再垃圾回收？​ 如果先Stop the World，然后再采用“标记-整理”算法去回收垃圾。会造成系统卡死时间过长，很多相应无法处理。所以CMS垃圾回收器采取的是垃圾回收线程和系统工作线程尽量同时执行的模式来处理的。 CMS的垃圾回收过程​ CMS在执行一次垃圾回收的过程一共分为4个阶段： 初始标记 并发标记 重新标记 并发清理 初始标记​ 首先，CMS要进行垃圾回收，会先执行初始标记阶段，这个阶段会让系统的工作线程全部停止，进入“Stop the World”状态。而所谓的“初始标记”，就是标记出来所有GC Roots直接引用的对象。例如下面的代码： 12345678public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125;public class ReplicaManager &#123; private ReplicaFetcher replicaFetcher = new ReplicaFetcher();&#125; ​ 在初始标记阶段，仅仅过通过“replicaManager”这个类的静态变量代表的GC Roots，去标记出他直接引用的ReplicaManager对象，这就是初始标记的过程。它不会去管ReplicaFetcher这种对象，因为ReplicaFetcher对象是被ReplicaManager类的“replicaFetcher”实例变量引用的。之前说过，方法的局部变量和类的静态变量是GC Roots。但类的实例变量不是GC Roots。 ​ 所以第一个阶段，初始标记，虽然要造成“Stop the World”暂停一切工作线程，但是其实影响并不大，因为他的速度很快，仅仅标记GC Roots直接引用的那些对象而已。 并发标记​ 第二个阶段是并发标记，这个阶段会让系统线程可以随意创建各种对象，继续运行。在运行期间可能会创建新的存活对象，有可能让部分存活对象失去引用，变成垃圾对象。在这个过程中，会尽可能地对已有的对象进行GC Roots追踪。 ​ 所谓进行GC Roots追踪，意思就是对类似“ReplicaFetcher”之类的全部老年代里的对象，看它被谁引用了。比如这里是被“ReplicaManager”对象的实例变量引用了，接着会看，“ReplicaManager”对象被谁引用了，会发现被“Kafka”类的静态变量引用了。那么此时可以认定“ReplicaFetcher”对象是被GC Roots间接引用的，因此此时就不需要回收它。但是在这个过程，在进行并发标记的时候，系统程序会不停的工作，它可能会创建出新的对象，部分对象可能变成为垃圾，如下图： ​ 第二个阶段，就是标记出 GC roots 关联到的对象的引用对象有哪些。比如说 A -&gt; B (A 引用 B，假设 A 是 GC Roots 关联到的对象)，那么这个阶段就是标记出 B 对象， A 对象会在初始标记中标记出来。 这个阶段其实是最耗时的，但是这个最耗时的阶段，是跟系统并发运行的，所以这个阶段不会对系统运行造成影响。 重新标记​ 在第二阶段并发标记中，因为一边标记存活对象和垃圾对象，一边系统不停运行创建对象，让老对象变成垃圾。所以第二阶段结束之后，会有很多存活对象和垃圾对象，是之前第二阶段没标记出来的。所以此时进入第三阶段，要继续让系统程序停下来，再次进入“Stop the World”状态。然后重新标记下在第二阶段里创建的一些对象，还有一些已有对象可能失去引用变成垃圾的情况。 ​ 重新标记的阶段，速度是很快的。因为它其实就是对在第二阶段中被系统程序运行变动过的少数对象进行标记，所以运行速度很快。 并发清理​ 这个阶段就是让系统程序随意运行，然后它来清理之前标记为垃圾的对象即可。这个阶段其实也很耗时，因为需要进行对象的清理，但是它也是跟随系统程序并发运行的，所以也不影响系统的执行。 CMS的垃圾回收机制性能分析​ 从上述我们知道CMS的垃圾回收机制已经尽可能地进行了性能优化。其中最耗时的，就是对老年代全部对相关进行GC Roots追踪，标记出来哪些可以回收，然后就是对各种垃圾对象从内存里清理掉。 ​ 但是他的第二和第四阶段，即并发标记和并发清理，都是和系统程序并发执行的，所以基本对性能影响不大。只有第一和第三阶段是需要“Stop the World”的，但是这两个阶段都是简单的标记而已，速度非常快，所以基本上对系统运行影响也不大。 CMS的一些细节并发回收垃圾导致CPU资源紧张​ CMS垃圾回收器有一个问题，虽然能在垃圾回收的同事让系统同事工作，但在并发标记和并发清理两个最耗时的阶段，垃圾回收线程和系统工作线程同时工作，会导致有限的CPU资源被垃圾回收线程占用了一部分。CMS默认启动的垃圾会回收线程的数量是（CPU核数 + 3）/ 4。假设是2核CPU，那么CMS会有（2 + 3）/ 4 = 1个垃圾回收线程，去占用一个CPU。所以CMS这个并发垃圾回收机制，第一个问题就是会消耗CPU资源。 Concurrent Mode Failure问题​ 在并发清理阶段，CMS只不过是回收之前标记好的垃圾对象。但是这个阶段系统一直在运行，可能会随着系统运行让一些对象进入老年代，同时还变成垃圾对象，这种垃圾对象被称为为“浮动垃圾”。 ​ 虽然它成为了垃圾，但是CMS只能回收之前标记出来的垃圾对象，不会回收它们，需要等待到下一次GC的时候才会回收它们。所以为了保证CMS垃圾回收期间，还有一定的内存空间让一些对象可以进入老年代，一般会预留一些空间。CMS垃圾回收的触发时机，其中有一个就是当老年代内存占用达到一定比例了，就会自动执行GC。 ​ -XX:CMSInitiatingOccupancyFaction参数可以用来设置老年代占用多少比例的时候触发CMS垃圾回收，JDK1.6默认的值是92%。即老年代占用了92%的空间了，就自动进行CMS垃圾回收，预留8%的空间给并发回收期间，系统程序把一些新对象放入老年代中。 ​ 如果CMS垃圾回收期间，系统程序要放入老年代的对象大于可用内存空间，这个时候，会发生Concurrent Mode Failure，就是说并发垃圾回收失败了，我一边回收，你一边把对象放入老年代，内存都不够了。 ​ 此时就会自动用“Serial Old”垃圾回收器替代CMS，就是直接把系统程序“Stop the World”，重新进行长时间的GC Roots追踪，标记出全部垃圾对象，不允许新的对象产生，然后一次性把垃圾对象都回收掉，完事了再恢复系统线程。 ​ 所以在生产实践中，这个自动触发CMS垃圾回收的比例需要合理优化一下，避免“Concurrent Mode Failure”问题。 内存碎片问题​ 老年代的CMS采用“标记-清理”算法，每次都是标记出来垃圾对象，然后一次性回收掉。这样会导致大量的内存碎片产生。如果内存碎片太多，会导致后续对象进入老年代找不到可用的连续内存空间，然后就触发Full GC。所以CMS不是完全仅仅用“标记-清理”算法的，因为太多的内存碎片实际上会导致更加频繁的Full GC。 ​ CMS有一个参数是-XX:+UseCMSCompactAtFullCollection，默认是打开的，意思是在Full GC之后要再次进入“Stop the World”，停止工作线程，然后进行碎片整理，就是把存活对象挪到一起，空出来大片连续内存空间，避免内存碎片。还有一个参数时-XX:CMSFullGCsBeforeCompaction,这个意思是执行多少次Full GC之后再执行一次内存碎片整理的工作，默认是0，意思是每次Full GC之后都会进行一次内存整理。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之垃圾回收]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F18%2FJVM%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 在Java中，平时我们系统运行创建的对象都是优先分配在新生代里的。如果新生代里的对象越来越多，都快满了，此时就会触发垃圾回收，把新生代没有引用的对象给回收掉，从而释放内存空间。现在我们来看看，JVM是按照什么规则来回收垃圾对象的。 哪些引用对象不能被回收​ JVM中使用了可达性分析算法来判定哪些对象是可以被回收的。这个算法的意思是，对每个对象，都分析一下有谁在引用他，然后一层一层往上去判断，看是否有一个GC Roots。其中方法的局部变量、类的静态变量都可以看做是一种GC Roots。 案例​ 如下一段代码，就是在一个方法中创建了一个对象，然后有一个局部变量引用了这个对象。 12345678910public class Kafka &#123; public static void main(String[] args) &#123; loadReplicaFromDisk(); &#125; public static void loadReplicaFromDisk() &#123; ReplicaManager replicaManager = new ReplicaManager(); &#125;&#125; ​ 分析代码可知，“main()”方法的桢栈入栈，然后调用“loadReplicaFromDisk()”方法，桢栈入栈，接着让局部变量“replicaManager”引用堆内存里的“ReplicaManager”实例对象，如下图： ​ 现在上图中“ReplicaManager”对象被局部变量给引用了，此时一旦新生代满了，发生垃圾回收，就会分析这个“ReplicaManager”对象的可达性。此时会发现它是不能被回收的，因为它被人引用了，而且是局部变量“replicaManager”引用的。 ​ 只要一个对象被局部变量引用了，那么说明它有一个GC Roots，此时就不能被回收了。 ​ 另外一种情况，如下面代码： 1234public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125; ​ 跟上面的那个一样，一分析，发现“ReplicaManager”对象被Kafka类的一个静态变量”replicaManager”给引用了，此时就不会去回收它。 ​ 总结：只要你的对象被方法的局部变量、类的静态变量给引用了，就不会回收它们。 Java中对象不同的引用类型​ 关于引用和垃圾回收的关系，我们要有一个概念，就是Java里有不同的引用类型。分别是强引用、软引用、弱引用和虚引用。 强引用​ 强引用，就是类似下面的代码： 1234public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125; ​ 这个就是最普通的代码，一个变量引用一个对象。只要是强引用的类型，那么垃圾回收的时候就绝对不会去回收这个对象的。 软引用​ 软引用，类似下面的代码： 12345public class Kafka &#123; public static SoftReference&lt;ReplicaManager&gt; replicaManager = new SoftReference&lt;ReplicaManager&gt;(new ReplicaManager());&#125; ​ 就是把“ReplicaManager”实例对象用一个“SoftReference”软引用类型的对象给包裹起来，此时这个“replicaManager”变量对“ReplicaManager”对象的引用就是软引用了。 ​ 正常情况下垃圾回收时不会回收软引用对象的，但是如果进行垃圾回收之后，发现内存空间还不不够存放新的对象，此时就会把这些软引用对象给回收了。即便它被变量引用了，但是因为它是软引用，所以还是可以回收的。 弱引用​ 弱引用，类似下面代码： 12345public class Kafka &#123; public static WeakReference&lt;ReplicaManager&gt; replicaManager = new WeakReference&lt;ReplicaManager&gt;(new ReplicaManager());&#125; ​ 弱引用就跟没有引用是类似的，如果发生垃圾回收，就会把这个对象回收掉。 虚引用​ 虚引用，正如其名，对一个对象而言，这个引用形同虚设，有和没有一样。此外，虚引用必须和引用队列一起使用。 finalize()方法的作用​ 从上面可知，有GC Roots引用的对象不能回收，没有GC Roots引用的对象可以别回收。如果有GC Roots引用，但是引用时软引用或者弱引用，也有可能被回收。 ​ 但是没有GC Roots引用的对象，一定会被立马回收吗？其实并不是，这里有一个finalize()方法可以抢救一下。如下代码： 123456789public class ReplicaManager &#123; public static ReplicaManager instance; @Override protected void finalize() throws Throwable &#123; ReplicaManager.instance = this; &#125;&#125; ​ 如果有一个ReplicaManager对象要被垃圾回收了，那么假如这个对象重写了Object类中的finalize()方法。此时会先尝试调用它的finalize方法，看是否把这个实例对象给了某个GC Roots变量，比如上面代码就给了ReplicaManager类的静态变量。这样就重新让某个GC Roots变量引用了自己，那么就不用被垃圾回收了。 垃圾回收算法标记-清除算法​ 改算法会从每个GC Roots出发，依次标记没有引用关系的对象，最后将没有被标记的对象清除。但是这种算法会带来大量的空间碎片，导致需要分配一个较大连续空间时容易触发full GC. 标记-整理算法​ 为了解决“标记-清除”算法导致的大量内存碎片问题，又提出了“标记-整理算法”。改算法类似计算机的磁盘整理，首先会从GC Roots出发标记存活的对象，然后将存活的对象整理到内存空间的一端，形成连续的已使用空间，最后把已使用空间之外的部分全部清除掉，这样就不会产生空间碎片的问题。 复制算法​ 为了能够并行地标记和整理，将空间分为两块，每次只激活其中一块，垃圾回收时只需把存活的对象复制到另一块未激活的空间上，将未激活空间标记为已激活，将已激活空间标记为未激活，然后清除原空间中的原对象。两块空间就这么重复循环使用。复制算法现作为主流的YGC算法进行新生代的垃圾回收。 JVM中对复制算法的优化​ 在实际真正的复制算法中，把新生代内存区域划分为三块：1个Eden区，2个Survivor区。其中Eden区占80%内存空间，每一块Survivor区各占10%内存空间。平时可以使用的，就是Eden区和其中一块Survivor区。但是刚开始对象都是分配在Eden区的，如果Eden区满了吗，此时就会触发YGC。 ​ 此时就会把Eden区中的存活对象都一次性转移到空着的Survivor区，接着Eden区就会被清空，然后再次分配新对象到Eden区。这就就会变成Eden区和Survivor区里都是有对象的，其中Survivor区里放的是上一个YGC存活后的对象。 ​ 这么设计会始终保持一个Survivor区的空着的，就这样一直循环只用这三块内存区域。这么最最大的好处是，只有10%的空间时被闲置的，90%的内存都被用上了。 老年代和新生代怎样变成老年代​ 对象一般都先分配在新生代，但什么情况下新生代会变成老年代呢？ 躲过15次GC之后进入老年代​ 一般情况下，我们系统刚启动的时候，创建的各种各样的对象，都是分配在新生代里的。然后系统跑着跑着，新生代就满了，此时就会触发Minor GC，可能就是1%的少量存活对象转移到空着的Survivor区中。然后系统继续运行，继续在Eden区了分配各种对象。大概就是这个流程。 ​ 但那些每次在新生代里躲过一次GC被转移到一块Survivor区域中，它的年龄就会增长一岁。默认情况下，当对象的年龄达到15岁时，也就是躲过15次GC的时候，它就会转移到老年代里去。具体是多少岁进入老年代，可以通过参数-XX:MaxTenuringThreshold来设置，默认是15岁。 动态对象年龄判断​ 这里跟这个对象年龄有另外一个规则可以让对象进入老年代，不用等待15次GC过后才可以。大致的规则是：假如当前放对象的Survivor区域里，一批对象的总大小大于了这块区域的内存大小的50%，那么此时大于等于这批对象年龄的对象，就可以直接进入老年代了。 ​ 假设图里的Survivor2区有两个对象，这两对象的年龄一样，都是2岁。然后这两对象加起来超过了50MB，超过了Survivor2区的100MB内存的一半了，这个时候，Survivor2区里的大于等于2岁的对象，就要全部进入老年代里去。 ​ 这就是所谓的动态年龄判断的规则。实际上这个规则运行的时候是如下的逻辑：年龄1 + 年龄2 + 年龄n的多个年龄对象总和超过了Survivor区域的50%，此时就会把年龄n以上的对象都放入老年代。 大对象直接进入老年代​ 有一个JVM参数，就是-XX:PretenureSizeThreshold，可以把他的值设置为字节数，比如“1048576”，就是1MB。它的意思是，如果你要创建一个大于等于这个大小的对象，比如一个超大的数组，此时就直接把这个大对象放到老年代去，不会经过新生代。 ​ 这么做的原因，就是要避免新生代里出现那种大对象，然后屡次躲过GC，还得把它在两个Survivor区域里来回复制多次之后才能进入老年代，那么大的对象在内存里来回复制，浪费时间。 Minor GC后的对象太多无法放入Survivor区怎么办​ 如果Minor GC后的对象太多无法放入Survivor，那么这个时候就必须把这些对象直接转移到老年代中去。 老年代空间分配担保规则 在执行任何一次Minor GC之前，JVM会先检查一下老年代可用的内存空间，是否大于新生代所有对象的总大小。为什么检查这个，因为极端情况下，可能新生代Minor GC过后，所有对象都存活下来。 如果老年代的内存大小是大于新生代所有对象的，此时就可以放心大胆的对新生代发起一次Minor GC。因此即使Minor GC之后所有对象存活，Survivor区放不下，也可以转移到老年代去。 如果老年代的可用内存已经小于新生代的全部对象了，就去看-XX:-HandlePromotionFailure参数是否设置。 如果设置了，就看老年代的内存大小，是否大于之前每一次Minor GC后进入老年代的对象的平均大小。例如，之前每次Minor GC后，平均都有10MB左右的对象会进入老年代，那么此时老年代可用内存大于10MB。很可能这次Minor GC过后也是差不多10MB左右的对象会进入老年代，此时老年代空间是够的。 如果判断失败，或者是-XX:-HandlePromotionFailure参数没设置，此时就会触发一次“Full GC”，就是对老年代进行垃圾回收，尽量腾出一些内存空间，然后再执行Minor GC。 如果上面两个步骤都判断成功了，那就可以冒风险尝试一下Minor GC。此时进行Minor GC有几种可能。 第一种可能，Minor GC过后，剩余存活的对象的大小小于Survivor区的大小，那么此时存活对象进入Survivor区域即可。 第二种可能，Minor GC过后，剩余的存活对象的大小，大于Survivor区域的大小，但是小于老年代可用内存大小，此时直接进入老年代。 第三种可能，Minor GC过后，剩余的存活对象的大小，大于Survivor区域的大小，也大于老年代可用内存的大小。此时老年代都放不下这些存活对象了，就会发生“Handle Promotion Failure”的情况，这个时候就会触发一次“Full GC”。Full GC就是对老年代进行垃圾回收，同时一般也会对新生代进行垃圾回收。 如果Full GC之后，老年代还是没有足够的空间存放Minor GC过后的剩余存活对象，那么此时就会导致所谓的“OOM”内存溢出。 老年代垃圾回收算法​ 通过上面的内容，可以总结一句话：对老年代触发垃圾回收时机，一般就是两个： 在Minor GC之前，检查发现很可能Minor GC之后要进入老年代的对象太多了，老年代放不下，此时需要提前触发Full GC然后再带着进行Minor GC。 在Minor GC之后，发现剩余对象太多，老年代内存不够。 ​ 那么对老年代进行垃圾回收采用的是什么算法呢？简单地说，就是上面提到过的标记-整理算法。但是，这个老年代的垃圾回收算法的速度比新生代的垃圾回收算法的速度慢10倍。如果系统频繁出现老年代的Full GC，会导致系统性能被严重影响，出现频繁卡顿的情况。 ​ 其实， 所谓JVM优化，就是尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列之RocketMQ]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F10%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B9%8BRocketMQ%2F</url>
    <content type="text"><![CDATA[​ RocketMQ是阿里开源并贡献给Apache基金会的一款分布式消息平台，具有低延迟。高性能和可靠性、万亿级容量和灵活的可伸缩性的特点。单机也可以支持亿级的消息堆积能力、单机写入TPS单实例越7万条/秒，单机部署3个Broker，最高可以跑到12万条/秒。 RocketMQ的基本构成​ 整个RocketMQ消息系统主要由4个部分组成。 ​ 从中间件服务角度来看整个RocketMQ消息系统（服务端）主要分为：NameSrv和Broker两个部分。 NameSrv​ 在RocketMQ分布式消息系统中，NameSrv主要提供两个功能： 提供服务发现和注册。这里主要是管理Broker，NameSrv接受来自Broker的注册，并通过心跳机制来检测Broker服务的健康性。 提供路由功能。集群（这里是指以集群方式部署的NameSrv）中的每个NameSrv都保存了Broker集群（这是是指以集群方式部署的Broker）中整个的路由信息和队列信息。这里需要注意，在NameSrv集群中，每个NameSrv都是相互独立的，所以每个Broker需要连接所有的NameSrv，每创建一个新的topic都要同步到所有的NameSrv上。 Broker​ 主要是负责消息的存储、传递、查询以及高可用（HA）保证等。其由如下几个子模块构成： remoting：是Broker的服务入口，负责客户端的接入（Producer和Consumer）和请求处理。 client：管理客户端和维护消费者对于Topic的订阅。 store：提供针对存储和消息查询的简单的API（数据存储在物理磁盘）。 HA：提供数据在主从节点间同步的功能特性。 Index：通过特定的key构建消息索引，并提供快速的索引查询服务。 ​ 而从客户端的角度看主要有：Producer、Consumer两个部分。 Producer​ 消息的生产者，由用户进行分布式部署，消息有Producer通过多种负载均衡模式发送到Broker集群，发送低延时，支持快速失败。 Consumer​ 消息的消费者，也有用户部署，支持PUSH和PULL两种消费模式，支持集群消费和广播消费，提供实时的消息订阅机制，满足大多数消费场景。 RocketMQ的其他概念Producer Group​ 相同角色的生产者被组织到一起。在事务提交后，生产组中不同实例都可以连接broker执行提交或回滚事务，以防原生产者在提交后就挂掉。 Consumer Group​ 具有完全相同角色的消费者被组合在一起并命名为消费者组，消费群体是一个很好的概念，它在消费信息方面实现负载平衡和容错目标是非常容易的。另外，消费者组的消费者实例必须具有完全相同的主题订阅。 Topic​ 主题是生产者提供消息和消费者提取消息的类别。主题与生产者和消费者的关系非常松散，具体而言，一个主题可能有零个，一个或多个向其发送消息的生产者；相反，生产者可以发送不同主题的信息。从消费者的角度来看，一个主题可能有零个，一个或多个消费者群体订阅。同样，一个消费群体可以订阅一个或多个主题，只要这个群体的实例保持其订阅的一致性即可。 Message​ 消息是要传递的信息。一条信息必须要有一个主题，可以将其解释为要发送给您的信件的地址。一条消息也可能有一个可选标签和额外的键值对。例如，你可以为消息设置业务密钥，并在Broker上查找消息以在开发期间诊断问题。 Message Queue​ 主题被划分为一个或多个子主题，这就是消息队列。 Tag​ 标签可以理解为更细一级的主题，为使用者提供更灵活的查找。使用标签，来自同一业务模块的具有不同目的消息可能就有相同的主题和不同的标签。标签将有助于保持代码的清洁和一致性，并且标签还可以方便RocketMQ提供的查询系统。 Message Order​ 当使用DefaultMQPushConsumer时，你可能需要决定消费是顺序的还是并发的。 Orderly（顺序）：有序的消息意味着消息的使用顺序与生产者为每个消息队列发送的顺序相同。如果你的使用场景要求是必须顺序的，你要确保只用一个队列存放消息。如果消费顺序被指定，最大的消费并发数就是这个消费者组的消息队列的订阅数。 Concurrently（并发）：并发使用消息时，消费消息的最大并发性仅受限于为每个消费者客户端指定的线程池。 安装RocketMQ1、下载Apache最新rocketmq二进制压缩文件​ 可以到官网下载后上传到服务器上，也可以用wget命令。 1wget https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.5.2/rocketmq-all-4.5.2-bin-release.zip/ 2、解压安装​ 使用unzip命令进行解压。 1unzip -d /usr/local rocketmq-all-4.5.2-bin-release.zip 3、环境变量​ 配置环境变量 vi /etc/profile。添加如下代码： 1export NAMESRV_ADDR=127.0.0.1:9876 4、启动RocketMQ​ 进入rocketmq的bin目录，修改runserver.sh，如下代码： 1JAVA_OPT="$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m" ​ 主要根据自己机器内存酌情修改-Xms -Xmx -Xmn这几个参数的内存。 ​ 同理修改bin目录下的runbroker.sh的JVM参数。 ​ 进入conf目录，修改broker.conf，新增一行： 1brokerIP1=xx.xx.xx.xx # 你的公网IP ​ 然后开始启动mqnamesrv，进入到rocket目录，执行nohup sh bin/mqnamesrv &amp;启动namesrv，然后再执行nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf &amp;启动broker。 ​ 执行jps，看namesrv和broker是否启动成功，如果没成功。可以通过执行tail -f ~/logs/rocketmqlogs/namesrv.log和tail -f ~/logs/rocketmqlogs/broker.log查看相应日志。 RocketMQ集群模式​ RocketMQ集群部署有多种方式，对于NameSrv来说可以同时部署多个节点，并且这些节点间也不需要有任何的信息同步，因为这里每个NameSrv节点都会存储全量路由信息。在NameSrv集群模式下，每个Broker都需要同时向集群中的每个NameSrv节点发送注册信息，所以这里对于NameSrv的集群部署来说并不需要做什么额外的设置。 ​ 而对于Broker集群来说就有多种模式了，主要有如下几个模式： 单个Master模式​ 一个Broker作为主服务，不设置任何Slave，这种方式风险比较大，存在单节点故障会导致整个基于消息的服务挂掉，所以生产环境不可能采用这种模式。 多Master模式​ 这种模式的Broker集群，全是Master，没有Slave。 优点​ 配置会比较简单一些，如果单个Master挂掉或重启维护的话对应用是没有什么影响的。如果磁盘配置为RAID10（服务器的磁盘阵列模式）的话，即使在机器宕机不可恢复的情况下，由于RAID10磁盘本身的可靠性，消息也不会丢失（异步刷盘丢失少量消息，同步刷盘一条不丢），这个Broker的集群模式性能相对来说是最高的。 缺点​ 在单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前是不可以进行消息订阅的，这对消息的实时性有一些影响。 多Master多Slave模式（异步复制）​ 这种模式下的Broker集群存在多个Master节点，并且每个Master节点都会对应一个Slave节点，有多对Master-Slave，HA（高可用）之间采用异步复制的方式进行信息同步，在这种方式下主从之间会有短暂的毫秒级的消息延迟。 优点​ 这种模式下即使磁盘损坏了，消息丢失的情况也非常少，因为主从之间有消息备份。并且，这种模式下的实时性也不会受影响，因为Master宕机后Slave可以自动切换为Master模式，这样Consumer仍然可以通过Slave进行消息消费，而这个过程对应用来说是完全透明的，并不需要人工干预。另外，这种模式的性能与多Master模式几乎差不多。 缺点​ 如果Master宕机，并且在磁盘损坏的情况下，会丢失少量的消息。 多Master多Slave模式（同步复制）​ 这种模式与上面那个差不多，只是HA采用的是同步双写的方式，即主备都写成功后，才会向应用返回成功。 优点​ 这种模式下数据与服务不存在单点的情况，在Master宕机的情况下，消息也没有延迟，服务的可用性以及数据的可用性都非常高。 缺点​ 性能相比于异步复制略低一些（大约10%）。 SpringBoot整合RocketMQ​ 这里主要讲解一下生产者和消费者的代码，完整的项目代码已上传到github上。 消息生产者RocketMQProvider​ 以顺序发消息为例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.example.rocketmqDemo.rocketmq;import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.client.producer.MessageQueueSelector;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.common.message.Message;import org.apache.rocketmq.common.message.MessageQueue;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Service;import org.springframework.util.StopWatch;import java.util.List;@Servicepublic class RocketMQProvider &#123; @Value("$&#123;apache.rocketmq.producer.producerGroup&#125;") private String producerGroup; @Value("$&#123;apache.rocketmq.namesrvAddr&#125;") private String namesrvAddr; public void defaultMQProducer() &#123; //生产组的名称 DefaultMQProducer producer = new DefaultMQProducer(producerGroup); //指定NameServer地址，多个地址以;隔开 producer.setNamesrvAddr(namesrvAddr); try &#123; //Producer对象在使用之前必须要调用start初始化，初始化一次即可 //注意：切记不可以在每次发送消息时，都调用start方法 producer.start(); //创建一个消息实例，包含topic、tag和消息体 //如下：topic为"TopicTest"，tag为"push" Message message = new Message("TopicTest", "push", "发送消息----".getBytes()); StopWatch stop = new StopWatch(); stop.start(); for(int i = 0; i &lt; 10; i++) &#123; SendResult result = producer.send(message, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, 1); System.out.println("发送相应：MsgId: " + result.getMsgId() + ".发送状态: " + result.getSendStatus()); &#125; stop.stop(); System.out.println("-----------------------发送十条消息耗时：" + stop.getTotalTimeMillis()); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; producer.shutdown(); &#125; &#125;&#125; ​ 一般消息时通过轮询所有队列来发送的（负载均衡策略），顺序消息可以根据业务发送到同一个队列。比如将订单号相同的消息发送到同一个队列。下面的代码中指定了1,1处这个值相同的获取到的队列是同一个队列。 12345678SendResult result = producer.send(message, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125;&#125;, 1); 消息消费者RocketMQConsumer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.example.rocketmqDemo.rocketmq;import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.common.consumer.ConsumeFromWhere;import org.apache.rocketmq.common.message.MessageExt;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.CommandLineRunner;import org.springframework.stereotype.Service;@Servicepublic class RocketMQConsumer implements CommandLineRunner &#123; //消费者的组名 @Value("$&#123;apache.rocketmq.consumer.PushConsumer&#125;") private String consumerGroup; @Value("$&#123;apache.rocketmq.namesrvAddr&#125;") private String namesrvAddr; public void defaultMQPushConsumer() &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(consumerGroup); consumer.setNamesrvAddr(namesrvAddr); try &#123; //订阅PushTopic下Tag为push的消息 consumer.subscribe("TopicTest", "push"); //设置Consumer第一次启动是从头部开始消费还是队列尾部开始消费 //如果非第一次启动，那么按照上次消费的位置继续消费 consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.registerMessageListener((MessageListenerConcurrently)(list, context)-&gt; &#123; try &#123; for(MessageExt messageExt : list) &#123; //输出消息内容 System.out.println("messageExt: " + messageExt); String messageBody = new String(messageExt.getBody()); //输出消息内容 System.out.println("消费响应：msgId : " + messageExt.getMsgId() + ", msgBody : " + messageBody); &#125; &#125;catch (Exception e) &#123; e.printStackTrace(); //稍后重试 return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; //消费成功 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;); consumer.start(); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run(String... args) throws Exception &#123; this.defaultMQPushConsumer(); &#125;&#125; ​ 消费者中我们实现了CommandLineRunner接口。它的作用是让消费者在springboot启动时执行。具体可以参考CommandLineRunnable详解。 ​ 项目成功启动后，测试的结果应该是： 123456789101112131415161718192021222324252627282930313233342019-10-11 17:13:50.785 INFO 12872 --- [nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'2019-10-11 17:13:50.785 INFO 12872 --- [nio-8080-exec-2] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'2019-10-11 17:13:50.793 INFO 12872 --- [nio-8080-exec-2] o.s.web.servlet.DispatcherServlet : Completed initialization in 8 ms发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OK发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=51, sysFlag=0, bornTimestamp=1570785233301, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231900, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEAFFF, commitLogOffset=28225535, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=52, CONSUME_START_TIME=1570785233370, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]messageExt: MessageExt [queueId=1, storeSize=178, queueOffset=50, sysFlag=0, bornTimestamp=1570785233233, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231856, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEAF4D, commitLogOffset=28225357, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=52, CONSUME_START_TIME=1570785233370, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=52, sysFlag=0, bornTimestamp=1570785233346, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231943, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB0B1, commitLogOffset=28225713, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=53, CONSUME_START_TIME=1570785233411, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=53, sysFlag=0, bornTimestamp=1570785233387, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231986, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB163, commitLogOffset=28225891, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=54, CONSUME_START_TIME=1570785233453, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=54, sysFlag=0, bornTimestamp=1570785233430, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232028, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB215, commitLogOffset=28226069, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=55, CONSUME_START_TIME=1570785233495, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=55, sysFlag=0, bornTimestamp=1570785233472, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232071, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB2C7, commitLogOffset=28226247, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=56, CONSUME_START_TIME=1570785233538, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=56, sysFlag=0, bornTimestamp=1570785233516, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232114, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB379, commitLogOffset=28226425, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=57, CONSUME_START_TIME=1570785233580, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=57, sysFlag=0, bornTimestamp=1570785233557, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232156, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB42B, commitLogOffset=28226603, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=58, CONSUME_START_TIME=1570785233622, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=58, sysFlag=0, bornTimestamp=1570785233600, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232199, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB4DD, commitLogOffset=28226781, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=59, CONSUME_START_TIME=1570785233665, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OK-----------------------发送十条消息耗时：1479messageExt: MessageExt [queueId=1, storeSize=178, queueOffset=59, sysFlag=0, bornTimestamp=1570785233642, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232241, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB58F, commitLogOffset=28226959, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=60, CONSUME_START_TIME=1570785233707, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息---- 参考资料Centos7下安装Rocket RocketMQ连接异常 基于RocketMQ搭建生产级消息集群]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[外观模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F08%2F%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ 在软件开发中，有时候为了完成一项较为复杂的功能，一个类需要和多个其他业务类交互，而这些需要交互的业务类经常会作为一个完整的整体出现，由于涉及的类比较多，导致使用时代码较为复杂，此时，需要一个类似服务员一样的角色，由它来负责和多个业务类进行交互，而使用这些业务类的类只需和该类交互即可。外观模式通过引入一个新的外观类来实现该功能，外观类充当了软件系统中的“服务员”，它为多个业务类的调用提供了一个统一的入口，简化了类与类之间的交互。 外观模式定义​ 外观模式要求一个子系统的外部与其内部的通信通过一个统一的外观角色进行，外观角色将客户端与子系统的内部复杂性分隔开，使得客户端只需要与外观角色打交道，而不需要与子系统内部的很多对象打交道，其定义如下： ​ 外部与一个子系统的通信通过一个统一的外观角色进行，为子系统中的一组接口提供一个一致的入口，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。外观模式又称为门面模式，它是一种对象结构型模式。 外观模式结构图 ​ 在外观模式结构图中包含以下两种角色： Facade（外观角色）：在客户端可以调用这个角色的方法，在外观角色中可以知道相关的（一个或者多个）子系统的功能和责任，在正常情况下，它将所有从客户端发来的请求委派到相应的子系统中去，传递给相应的子系统对象处理。 SubSystem（子系统角色）：在软件系统中可以有一个或者多个子系统角色，每一个子系统可以不是一个单独的类，而是一个类的集合，它实现子系统的功能，每一个子系统都可以被客户端直接调用，或者被外观角色调用，它处理由外观类传过来的请求；子系统并不知道外观的存在，对于子系统而言，外观角色仅仅是另外一个客户端而已。 案例​ 某软件公司欲开发一个可应用与多个软件的文件加密模块，改模块可以对文件中的数据进行加密并将加密之后的数据存储在一个新文件中，具体流程包括三个部分，分别是读取源文件、加密、保存加密之后的文件。其中，读取文件和保存文件使用流来实现，加密操作通过求模运算来实现。这三个操作相互独立，为了实现代码的独立重用，让设计更符合单一职责原则，这3个操作的业务代码封装在3个不同的类中。 ​ 相关代码已上传至github上。 抽象外观类的引入​ 在标准的外观模式中，如果需要增加、删除或更换与外观类交互的子系统类，必须修改外观类或客户端的源代码，这将违背开闭原则，因此可以通过引入抽象外观类来对系统进行改进，在一定程度上解决该问题。在引入抽象外观类之后，客户端可以针对抽象外观类进行编程，对于新的业务需求，不需要修改原有外观类，而对应增加一个新的具体外观类，由新的具体外观类来关联新的子系统对象，同时通过修改配置文件来达到不修改任何源代码并更换外观类的目的。 ​ 如在上面的案例中，如果要更换原有的加密方式，换成新的加密方式。那么相应的解决思路如下图： 外观模式主要优缺点主要优点 对客户端屏蔽了子系统组件，减少了客户端所需处理的对象数目并使得子系统使用起来更加容易。通过引入外观模式，客户端代码变得很简单，与之关联的对象也很少。 实现了子系统与客户端之间的松耦合关系，这使得子系统的变化不会影响到调用它的客户端，只需要调整外观类即可。 一个子系统的修改对其他子系统没有任何影响，而且子系统内部变化也不会影响到外观对象。 只是提供了一个访问子系统的统一入口，并不影响客户端直接使用子系统类。 主要缺点 不能很好地限制客户端直接使用子系统类，如果对客户端访问子系统类做太多的限制则减少了可变性和灵活性。 如果设计不当，当增加新的子系统可能需要修改外观类的源代码，这违背了开闭原则。 外观模式适用场景 当要为访问一系列复杂的子系统提供一个简单入口时可以使用外观模式。 客户端程序与多个子系统之间存在很大的依赖。引入外挂类可以将子系统与客户端解耦，从而提供子系统的独立性和可移植性。 在层次化结构中，可以使用外观模式定义系统中每一层的入口，层与层之间不直接产生联系，而通过外观类建立联系，降低层之间的耦合度。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列之RabbitMQ]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F07%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B9%8BRabbitMQ%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ RabbitMQ是一个消息代理，一个消息系统的媒介。它可以为你的应用提供一个通用的消息发送和接收平台，并且保证消息在传输过程中的安全。 基础概念​ RabbitMQ中除了正常的生产者消费者之外，还有一些其他的概念来支撑这样一个复杂的消息队列。 Broker​ Broker是消息服务中间件的一个服务节点，大部分情况下可以把一个Broker看成一个RabbitMQ的服务器。 ​ 上图可以看出Broker相当于一个消息服务的中央节点，而我们的消息队列核心功能也就在Broker上。 队列​ 消息都存储在队列中，下图是一个简单的模型。实际上，一个简单的消息队列服务只要有生成者、消费者和存储单元组成队列即可。 Exchange​ 交换机（Exchange）在RabbitMQ中承担了一些队列的逻辑处理功能。一般来说，对于生产者，我们只知道把产生的内容丢到MQ当中，但是发到哪个队列中，这一点对于生产者来说是无感知的，也不知道目前对列的状况如何。而Exchange就承担了发到哪个队列中的职责，用几种路由策略来决定如何分发给不同的队列。 Connection和Channel​ 每一个Connection是一条TCP连接，理论上而言每一个消费者和生产者都需要一条Connection，但是TCP连接的开销很大，所以我们会使用Channel来进行TCP复用，减少性能的开销。 Exchange类型fanout​ 我们比较常用的一种Exchange类型，它会把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。 direct​ 把消息路由到binding 可以和routing key完全匹配的队列中。 ​ binding key和routing key基本上可以理解为对一个Queue的称呼。 ​ 图中Queue1叫warning，Queue2可以叫info，warning或者debug，那样Exchange叫了声warning的时候会有两个Queue过来拿数据，而info只有Queue2会回应。 topic​ direct类型太过严格，大部分我们都用不上这么严格的规则，因此有了topic。topic可以看做是一种正则表达式规则，满足正则表达式的规则就会进入队列。 headers​ 这种类型根据发送信息中的header来匹配，性能差，基本没用。 死信队列​ DLX（Dead-Letter-Exchanage）。利用DLX，当消息在一个对列中变成死信之后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。消息变成死信一般有以下几种情况： 消息被拒绝（basic.reject/basic.nack）并且不再重新投递 require = false 消息过期（rabbitmq Time-To-Live -&gt; messageProperties.setExpiration()） 队列达到最长长度 ​ 当一个消息变成死信导致队列无法处理的时候，开启死信队列，使得消息不会堆积在队列中，而换到死信队列被消费。在RabbitMQ中开启死信队列非常简单，只要配置为DLX即可。 公用Connection而不是Channel​ 公用Connection的理由在上面已经提过，那为什么不建议公用Channel呢？ ​ 计算机网络传输信息的时候，本质上都是二进制传输，而传输的数据经过一定的处理，最终变成我们可读可处理的数据，Channel已经是复用了TCP连接的，此时如果我们再进行并行的数据传输，很有可能会导致某一帧数据的异常。 RabbitMQ的高可用性​ RabbitMQ是基于主从做高可用性的。一般来说，RabbitMQ有三种模式：单机模式、普通集群模式和镜像集群模式。 单机模式​ 单机模式，就是Demo级别的，一般就是你本地启动了做做demo，基本没人生产用单机模式。 普通集群模式（无高可用性）​ 普通集群模式，意思就是在多台机器上启动多个RabbitMQ实例，每个机器启动一个。你创建的queue，只会放在一个RabbitMQ实例上，但是每个实例都同步queue的元数据（元数据可以认为是queue的一些配置信息，通过元数据，可以找到queue所在实例）。你消费的时候，实际上如果连接到了另一个实例，那么那个实例会从queue所在实例上拉取数据过来。 ​ 这种方式不仅麻烦，而且也没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。 ​ 而且如果那个放queue的实例宕机了，会导致接下来其他实例无法从那个实例拉取数据。如果你开启了消息持久化，让RabbitMQ落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。 ​ 因此这个方案主要是用来提供吞吐量的，就是让集群中多个节点来服务某个queue的读写操作，没有所谓的高可用性。 镜像集群模式（高可用性）​ 这种模式，才是所谓的RabbitMQ的高可用模式。跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，就是说，每个RabbitMQ节点都有这个queue的一个完成镜像，包含queue的全部数据的意思。然后你每次写消息到queue的时候，都会自动把消息同步到多个实例的queue上。 ​ 如何开启镜像集群模式？RabbitMQ有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求同步指定数据的节点，再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。 ​ 这样处理，好处在于任何一个机器宕机了，其他机器还包含了这个queue的完整数据，别的consumer都可以到其他节点上去消费数据。坏处在于：第一，性能开销太大，消息需要同步到所有机器上，导致网络带宽压力和消耗都重；第二，这样处理并不是分布式的，没有扩展性可言，如果某个queue负载很重，你加机器，新的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue。 RabbitMQ的可靠性传输​ 数据的丢失问题，可能出现在生产者、MQ、消费者中，如下图： 生产者弄丢了数据​ 生产者将数据发送到RabbitMQ的时候，因为网络问题或其他情况，导致数据在半路就搞丢了。 事务机制​ 此时可以选择用RabbitMQ提供的事务功能，就是生产者发送数据之前开启RabbitMQ事务channel.txSelect，然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息，如果收到了消息，那么可以提交事务channel.txCommit。 123456789101112// 开启事务channel.txSelecttry &#123; // 这里发送消息&#125; catch (Exception e) &#123; channel.txRollback // 这里再次重发这条消息&#125;// 提交事务channel.txCommit ​ 但是问题是，这样会导致吞吐量下来，因为太耗性能。 confirm机制​ 因此一般情况下，要确保RabbitMQ的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ中，RabbitMQ会给你回传一个ack消息，告诉你这个消息OK了，如果RabbitMQ没能处理这个消息，会回调你的一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。 两个机制的区别​ 事务机制和confirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息RabbitMQ接收了之后会异步回调你的一个接口通知你这个消息接收到了。所以一般在生产者这块避免数据丢失，都是用confirm机制。 RabbitMQ弄丢了数据​ 即使RabbitMQ自己弄丢了数据，这个你必须开启RabbitMQ的持久化，就是消息写入之后会持久化到磁盘，哪怕是RabbitMQ自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非RabbitMQ还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率比较小。 ​ 设置持久化有两个步骤： 创建queue的时候将其设置为持久化，这样就可以保证RabbitMQ持久化queue的元数据，但是它不会持久化queue里的数据。 第二是是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上去。 ​ 必须要同时设置这两个持久化才行，这样RabbitMQ哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。 ​ 但是哪怕是你给RabbitMQ开启了持久化机制，也有一种可能，就是这个消息写到了RabbitMQ中，但是还没来得及持久化到磁盘上，结果RabbitMQ挂了，就会导师内存里的一点点数据丢失。所以，持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产这ack了。这样即便是持久化到磁盘之前，RabbitMQ挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。 消费端弄丢了数据​ 如果消费端刚消费到消息，但还没处理，结果进程挂了，这样就尴尬了。RabbitMQ认为你都消费了，这数据也就丢了。 ​ 这个时候可以用RabbitMQ提供的ack机制，即，你必须关闭RabbitMQ的自动ack,可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里ack一把。这样的话，如果你还没处理完，就没有ack,RabbitMQ就认为你还没处理完，这个时候RabbitMQ会把这个消费分配给别的consumer去处理，消息是不会丢的。 RabbitMQ的消息顺序性​ 举个例子，一个mysql binlog同步的系统，日同步数据要达到上亿，就是说数据从一个mysql库原封不动同步到另一个mysql库里面去（mysql -&gt; mysql）。然后你在mysql里增删改一条数据，对应出来增删改3条binlog日志，接着这三条binlog发送到MQ里面，再消费出来依次执行，要保证是按顺序执行的。否则本来是：增加、修改、删除，最后换了顺序给执行成删除、修改、增加。这就错了。 ​ 先看看RabbitMQ消息会错乱的场景：在RabbitMQ中，一个queue，多个consumer、比如生产者向RabbitMQ里发送了三条数据，顺序依次是data1/data2/data3，压入的是RabbitMQ的一个内存队列。有三个消费者分别从MQ中消费这三条数据中的一条，结果消费者2先执行完操作，把data2存入数据库，然后是data1/data3，这样就乱了。 解决方案​ 拆分多个queue，每个queue一个consumer，就是多一些queue而已；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然胡分发给不同的worker来处理。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis在实践中的一些常见问题与优化思路]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F06%2FRedis%E5%9C%A8%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E4%B8%8E%E4%BC%98%E5%8C%96%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[fork耗时操作导致高并发请求延时​ Redis在开启RDB和AOF持久化机制的时候，会有生成RDB快照，AOF rewrite等耗费磁盘IO的操作，此时主进程会fork子进程去执行。fork的时候，子进程需要拷贝父进程的空间内存页表的，这个也会耗费一定的时间。一般来说，如果父进程内存有1个G的数据，那么fork可能会耗费20ms左右，如果是10G30G，那么就会耗费200600ms，也就是几百毫秒的时间。可以在redis中执行info stats，其中的latest_fork_usec，可以看到最近一次form的时长。 ​ 如果redis单机QPS是几万，fork可能一下子就会拖慢几万条操作的请求时长。 优化思路​ fork耗时跟redis主进程的内存有关系，一般控制redis的内存在10GB以内。 AOF的阻塞问题​ redis将数据写入AOF缓冲区，然后会每秒做一次fsync。但是redis主线程会检查两次fsync的时间，如果距离上次fsync时间超过了2秒，那么写请求就会阻塞。这样可以保证redis最多丢失2秒的数据，但一旦fsync超过2秒的延时，整个redis就会被拖慢。 优化思路​ 优化硬盘写入速度，建议采用SSD，不要用普通的机械硬盘。 主从复制延迟问题​ 主从复制可能会超时严重，这个时候需要良好的监控和报警机制，在redis中执行info replication，可以见到master和slave复制的offset，做一个差值就可以看到对应的延迟量，如果延迟过多，那么久进行报警。 主从复制风暴问题​ 如果一下子让多个slave从master去执行全量复制，一份大的RDB同时发送到多个slave，会导致网络带宽被严重占用。如果一个master需要挂载很多个slave，那么尽量用树状结构，不要用星型结构。 Linux系统内核的优化​ 不同版本的Linux系统设置可能不一样，以下的内容只是提供一个思路，具体命令请根据不同的版本号自行百度。 vm.overcommit_memory​ 执行cat /proc/sys/vm/overcommit_memory，默认情况会返回0。这些数字代表的意义如下： 0：检查有没有足够内存，没有的话申请内存失败 1：允许使用内存直到用完为止 2：内存地址空间不能超过swap + 50% ​ 如果是0的话，可能导致类似fork等操作执行失败，申请不到足够的内存空间。可以将该参数设置为1。可以先后执行echo &quot;vm.overcommit_memory=1&quot; &gt;&gt; /etc/sysctl.conf和sysctl vm.overcommit_memory=1。 swapiness​ 执行cat /proc/version，查看系统内核版本。 ​ 如果Linux内核版本&lt;3.5，那么swapiness设置为0，这样系统宁愿swap也不会oom killer（杀掉进程） ​ 如果Linux内核版本&gt;=3.5，那么swapiness设置为1，这样系统宁愿swap也不会oom killer。 ​ 这样可以保证redis不会被杀掉。 12echo 0 &gt; /proc/sys/vm/swappinessecho vm.swapiness=0 &gt;&gt; /etc/sysctl.conf 最大打开文件句柄​ ulimit -n 10032 10032 tcp backlog​ 开始之前我们先回忆一下TCP建立连接的三次握手： Client发出一个数据包并将SYN置1，表示希望建立连接。这个包中的序列号假设是x。并将状态修改为SYN_SENT。 Server抽到Client发过来的数据包后，通过SYN得知这是一个建立连接的请求。于是发送一个响应包并将SYN和ACK都置1。假设这个包中的序列号是y，而确认序列号必须是x+1，表示收到了A发过来的SYN。并将自己的状态修改为SYN_RCVD，并把该请求放到syns queue队里中。 Client收到Server的响应包后进行确认，确认包中将ACK置1，并将确认序列号设置为y+1，表示收到了B的SYN。此时将状态修改为ESTABLISHED Server收到ACK后，将状态修改为ESTABLISHED，并把该请求从syns queue中放到accept queue。 ​ 在Linux系统内核中维护了两个队列：sync queue和accept queue。 sync queue：用于保存半连接状态的请求，其大小通过/proc/sys/net/ipv4/tcp_max_syn_backlog指定，一般默认值是512，不过这个设置有效的前提是系统的syncookies功能被禁用。互联网常见的TCP SYN FLOOD恶意DOS攻击方式就是建立大量的半连接状态的请求，然后丢弃，导致syns queue不能保存其它正常的请求。 accept queue：用于保存全连接状态的请求，其大小通过/proc/sys/net/core/somaxconn指定，在使用listen函数时，内核会根据传入的backlog参数与系统参数somaxconn，取二者的较小值。 如果accpet queue队列满了，server将发送一个ECONNREFUSED错误信息Connection refused到client。 ​ 这个方案就是调大accept queue的大小，其默认值是128，我们可以将其设置为511. 12cat /proc/sys/net/core/somaxconnecho 511 &gt; /proc/sys/net/core/somaxconn]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零开始搭建Redis集群]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F06%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BARedis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[​ Redis Cluster集群，要求至少3个master去组成一个高可用，健壮的分布式的集群，每个master都建议至少给一个slave，因此，最少要求3个master，3个slave。在正式环境中，建议在6台机器上搭建。也可是3台，但要保证每个master都跟自己的slave不在同一台机器上。 搭建Redis​ 搭建Redis Cluster之前，我们需要先搭建redis。先去官网中下载一个redis，目前稳定版本是redis-5.0.5。下载完后将其上传到Linux系统上，我一般放在/usr/local目录中。 上传完成后，执行tar -zxvf redis-5.0.5.tar.gz解压 执行cd redis-5.0.5/进入redis目录 执行make &amp;&amp; make test &amp;&amp; make install 编译过程中会报一个错误You need tcl 8.5 or newer in order to run the Redis test，说明我们需要安装tcl才能安装redis。执行yum install tcl进行安装 安装好之后再次执行make &amp;&amp; make test &amp;&amp; make install进行编译，需要等待一定的时间。等他编译好之后，有可能会报一个warning，这个可以不用管它。 这样我们就把redis装好了。执行ls查看redis文件夹下的文件 生产环境的redis启动方案​ 在生产环境中，要把redis作为一个系统的daemon进程去执行，每次系统启动，redis进程也一起启动。 在redis_util目录中，有个redis_init_scipt脚本。将这个脚本拷贝到Linux的/etc/init.d目录中，将redis_init_script重命名为redis_6379,6379使我们希望这个redis实例监听的端口号。cp redis_init_script /etc/init.d/redis_6379 修改redis_6379脚本的REDISPORT，设置为6379（默认就是6379）。 创建两个目录：/etc/redis（存放redis的配置文件），/var/redis/6379（存放redis的持久化文件）。 修改redis配置文件，默认在根目录下，拷贝到/etc/redis目录中，修改名称为6379.conf。 修改redis.conf的部分配置： daemonize yes pidfile /var/run/redis_6379.pid # 设置redis的pid文件位置 port 6379 #设置redis的监听端口号 dir /var/redis/6379 #设置持久化文件的存储位置 启动redis 分别执行以下语句 cd /etc/init.d、chmod 777 redis_6379、./redis_6379 start 执行ps -ef | grep redis确认redis进程是否启动。 在redis跟随系统启动自动启动。在redis_6379脚本中的上面，加入两行注释，然后执行chkconfig redis_6379 on。 123# chkconfig: 2345 90 10# description: Redis is a persistent key-value database 搭建Redis Cluster​ 现在开始搭建redis集群。这个案例模拟的是在三台服务器上搭建redis cluster。在搭建redis集群的时候先关闭所有的redis实例。在搭建之前，先了解几个redis cluster的重要配置： cluster-enabled &lt;yes/no&gt; cluster-config-file 这是指定一个文件，供cluster模式下的redis实例将集群状态保存在那里，包括集群中其他机器的信息，比如节点的上线和下线，故障转移。这个不是我们去维护，只是给它指定一个文件，让redis自己去维护。 cluster-node-time 节点存活超时时长，超过一定时长，认为节点宕机，master宕机的话就会触发主备切换，salve宕机就不会提供服务。 开始搭建redis cluster 先在三台服务器上安装redis。我们需要在三个服务器上搭建六个redis实例，端口号分别为7001、7002、7003、7004、7005和7006 先在三个服务器上建两个文件件mkdir -p /etc/redis-cluster 、mkdir -p /var/log/redis，然后在服务器1建立mkdir -p /var/redis/7001和mkdir -p /var/redis/7002文件夹，再在服务器2和服务器3分别建立7003、7004和7005、7006文件夹。 修改redis的配置文件。举一个例子，将上面的6379.conf配置文件复制一份并修改为7001.conf。重点修改一下几个配置： 12345678910port 7001cluster-enabled yescluster-config-file /etc/redis-cluster/node-7001.confcluster-node-timeout 15000daemonize yes pidfile /var/run/redis_7001.pid dir /var/redis/7001 logfile /var/log/redis/7001.logbind 192.168.31.187 appendonly yes 然后再接着生成并修改7002 7003 7004 7005 7006.conf配置文件，并放在相应的服务器中。 准备生产环境的启动脚本。在服务器1中，在/etc/init.d目录下，将redis_6379启动启动脚本复制一份并命名为redis_7001，并修改里面的端口号。同样的生成7002 7003 7004 7005 7006的启动脚本，并放在相应服务器的/etc/init.d目录下。 分别在3台服务器上，启动6个redis实例。 创建集群​ 6个redis实例启动后，就开始创建集群。 随便选中一台服务器，开始安装ruby。执行yum install -y ruby yum install -y rubygems gem install redis。 安装完成后，将redis-5.0.5目录中的src目录下的redis-trib.rb拷贝到/usr/local/bin中。cp /usr/local/redis-3.2.8/src/redis-trib.rb /usr/local/bin 执行redis-trib.rb create --replicas 1 192.168.0.112:7001 192.168.0.112:7002 192.168.0.113:7003 192.168.0.113:7004 192.168.0.114:7005 192.168.0.114:7006。其中上面的IP地址就是你的机器地址。 执行后会报下面的错误，这是因为yum安装的ruby的版本太低的缘故，可以执行ruby -v查看相应的版本。 1234567redis-trib.rb:6: odd number list for Hash white: 29, ^ redis-trib.rb:6: syntax error, unexpected &apos;:&apos;, expecting &apos;&#125;&apos; white: 29, ^ redis-trib.rb:7: syntax error, unexpected &apos;,&apos;, expecting kEND 执行yum remove -y ruby和yum remove -y rubygems 从官网下载最新的ruby压缩包，上传到服务器上 解压tar -zxvf ruby-2.6.5.tar.gz，解压后进入到相应目录中，开始编译。执行./configure 、make 、 make install，并等待一段时间。 执行ruby -v查看是否安装成功。 再次执行 redis-trib.rb create --replicas 1 192.168.0.112:7001 192.168.0.112:7002 192.168.0.113:7003 192.168.0.113:7004 192.168.0.114:7005 192.168.0.114:7006。此时会抱一个WARNING。 12345678910111213141516WARNING: redis-trib.rb is not longer available! You should use redis-cli instead. All commands and features belonging to redis-trib.rb have been moved to redis-cli. In order to use them you should call redis-cli with the --cluster option followed by the subcommand name, arguments and options. Use the following syntax: redis-cli --cluster SUBCOMMAND [ARGUMENTS] [OPTIONS] Example: redis-cli --cluster create 127.0.0.1:30001 127.0.0.1:30002 127.0.0.1:30003 127.0.0.1:30004 127.0.0.1:30005 127.0.0.1:30006 --cluster-replicas 1 To get help about all subcommands, type: redis-cli --cluster help 按照example执行以下命令redis-cli --cluster create 192.168.0.112:7001 192.168.0.112:7002 192.168.0.113:7003 192.168.0.113:7004 192.168.0.114:7005 192.168.0.114:7006 --cluster-replicas 1 这样就创建好集群了，它会帮你指定好谁当master谁当slave。你查看后觉得没问题就输入yes即可。 节点的增加与删除增加master节点 先按照上述操作，新建一个端口号为7007的redis实例，并启动。 在7001服务器上执行redis-cli --cluster add-node 192.168.0.114:7007 192.168.0.112:7001，将新增的7007redis实例增加到redis cluster中。 执行redis-cli --cluster check 192.168.0.114:7007查看redis cluster的情况，可以看到7007实例已经作为master新增到redis cluster中。但这个master只有0个hash slots，所以我们还要给他分配hash slots. 因为16364 / 4 = 4096，因此需要从其他三个master中迁移总共4096个节点到7007上。在任意一台服务器上执行redis-cli --cluster reshard 192.168.0.112 7001。执行后会出现How many slots do you want to move (from 1 to 16384)?，这是询问你要迁移多少slots，我们输入4096。执行后会出现What is the receiving node ID?这是询问你要迁移到哪里去，根据上图可知7007的ID是eb9267b3f16da7317e0f13f7f42fd2f2cf0857a1，输入进行执行。然后会出现Please enter all the source node IDs. Type &#39;all&#39; to use all the nodes as source nodes for the hash slots. Type &#39;done&#39; once you entered all the source nodes IDs.。这是让我们输入数据源的redis的ID，我们输入另外3个master的ID后输入done，之后再输入yes即可。 再次执行redis-cli --cluster check 192.168.0.114:7007查看redis cluster的情况。可以看到此时7007已经有4096个slots了。 增加slave节点 先按照上述操作，新建一个端口号为7008的redis实例，并启动。 执行redis-cli --cluster add-node 192.168.0.114:7008 192.168.0.112:7001 --cluster-slave --cluster-master-id f7b8e55612bce7574deecd57827e3b8203c1c9a6。其中的master-id是7004redis的ID。意思是将7008挂载为7004的slave。 执行redis-cli --cluster 192.168.0.113:7004查看7004的情况，可以看到7008已经是7004的slave了，但之前7001本来是7004的slave，却挂载到本来没有slave的7007master上，称为7007的slave。 删除节点 删除master之前。先用reshard将数据迁移到其他节点，确保node为空后，才能执行remove操作 假设我们要删除7007节点，先执行redis-cli --cluster reshard 192.168.0.112:7001，然后输入1365，将1365个slot迁移到其中一个master中。然后再依次迁移1365和1366个slot到另外两个master中。此时7007零个slots。 执行redis-cli --cluster del-node 192.168.0.112:7001 eb9267b3f16da7317e0f13f7f42fd2f2cf0857a1,，其中那串ID是7007的ID。当你清空了一个master的hashslot时，redis cluster就会自动将其slave挂载到其他master上去，这个时候就只要删除掉master就可以了。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[命令模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F29%2F%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ 在软件开发中有很多类似这样的一个场景：一个按钮，它可能是一个“关闭窗口”请求的发送者，而按钮点击事件处理类则是该请求的接收者。为了降低系统的耦合度，将请求的发送者和接收者解耦，可以使用一种被称之为命令模式的设计模式来设计系统。在命令模式中，发送者与接收者之间引入了新的命令对象，将发送者的请求封装在命令模式中，再通过命令对象来调用接收者的方法。 ​ 在软件开发中，经常需要向某些对象发送请求（调用其中的某个或某些方法），但是并不知道请求的接收者是谁，也不知道被请求的操作是哪个，此时，希望能以一种松耦合的方式来设计软件，使得请求发送者与请求接收者能够消除彼此之间的耦合，让对象之间的调用关系更加灵活。 ​ 命令模式可以将请求发送者和接收者完全解耦，发送者与接收者之间没有直接引用关系，发送请求的对象只需要知道如何发送请求，而不必知道如何完成请求。 命令模式定义​ 将一个请求封装为一个对象，从而可用不同的请求对客户进行参数化；对请求排队或者记录日志，以及支持可撤销的操作。命令模式是一种对象行为型模式，又称为动作模式或事物模式。 命令模式结构图​ 命令模式的核心在于引入了命令类，通过命令类来降低发送者和接收者的耦合度，请求发送者只需要指定一个命令对象，再通过命令对象来调动请求接收者的处理方法，其结果如下： ​ 由上图可知命令模式包含以下四个角色： Command（抽象命令类）：抽象命令类一般是一个抽象类或接口，在其中声明了用于执行请求execute()等方法，通过这些方法可以调用请求接收者的相关操作。 ConcreteCommand（具体命令类）：具体命令类是抽象命令类的子类，实现了在抽象命令类中声明的方法，它对应具体的接收者对象，将接收者对象的动作绑定在其中。在实现execute()方法时，将调用接收者对象的相关操作（Action）. Invoker（调用者）：调用者即请求发送者，它通过命令对象来执行请求。一个调用者并不需要在设计时确定其接收者，因此它只与抽象命令类之间存在关联关系。在程序运行时可以将一个具体命令对象注入其中，再调用具体命令对象的execute()方法，从而实现间接调用请求接收者的相关操作。 Receiver（接收者）：接收者执行与请求相关的操作，它具体实现对请求的业务处理。 具体案例​ 某公司开发人员为公司内部OA系统开发了一个桌面版应用程序，该应用程序为客户提供了一系列自定义功能键，用户可以通过这些功能键来实现一些快捷操作。产品人员通过分析，发现不同的用户可能有不同的使用习惯，在设置功能键的时候每个人都有自己的喜好，例如有人喜欢将第一个功能键设置为“打开帮助文档”，有的人则喜欢将该功能键设置为“最小化至托盘”。为了让用户能够灵活地进行功能键的设置,开发人员提供了一个“功能键设置”窗口,如图所示： ​ 通过这个窗口界面，用户可以将功能键和相应功能绑定在一起，还可以根据需要来修改功能键的设置，而且系统未来还可能增加一些新的功能或功能键。 ​ 该软件使用命令模式设计，结构图如下所示： ​ 相关代码已上传到github上。 命令队列的实现​ 有时候需要将多个请求排队，当一个请求发送者发送一个请求时，不止一个请求接收者产生响应，这些请求接收者将逐个执行业务方法，完成对请求的处理。此时，可以通过命令队列来实现。 ​ 命令队列的实现方法有多种形式，其中最常用、灵活性最好的一种方式是增加一个CommandQueue类，由该类来负责存储多个命令对象，而不同的命令对象可以对应不同的请求接收者。CommandQueue类的典型代码如下： 123456789101112131415161718192021222324package com.command;import java.util.ArrayList;public class CommandQueue &#123; //定义一个ArrayList来存储命令队列 private ArrayList&lt;Command&gt; commands = new ArrayList&lt;Command&gt;(); public void addCommand(Command command) &#123; commands.add(command); &#125; public void removeCommand(Command command) &#123; commands.remove(command); &#125; //循环调用每一个命令对象的execute()方法 public void execute() &#123; commands.stream().forEach(command -&gt; &#123; command.execute(); &#125;); &#125;&#125; ​ 在增加了命令队列类CommandQueue以后，请求发送者类Invoker将针对CommandQueue编程，代码如下： 123456789101112131415161718192021package com.command;public class Invoker &#123; //维持一个CommandQueue对象的引用 private CommandQueue commandQueue; public Invoker(CommandQueue commandQueue) &#123; this.commandQueue = commandQueue; &#125; //设值注入 public void setCommandQueue(CommandQueue commandQueue) &#123; this.commandQueue = commandQueue; &#125; //调用CommandQueue类的execute()方法 public void call() &#123; commandQueue.execute(); &#125;&#125; ​ 命令队列与批处理有点类似。批处理，意思就是可以对一组对象（命令）进行批量处理，当一个发送者发送请求后，将有一系列接收者对请求作出相应，命令对象可以用于设计批处理应用程序，如果请求接收者的接受次序没有严格的先后次序，还可以使用多线程技术来并发调用命令对象的execute()方法，从而提高程序的执行效率。 撤掉操作的实现​ 在命令模式中，可以通过调用一个命令对象的execute()方法来实现对请求的处理，如果需要撤销请求，可以通过在命令类中增加一个逆向操作来实现。此外，还可以通过保存对象的历史状态来实现撤销。 案例​ 某公司欲开发一个简易计算器，该计算器可以实现简单的数学运算，还可以对运算实施撤销操作和恢复操作。 ​ 本例完整代码已上传到github上 请求日志​ 请求日志就是将请求的历史记录保存下来，通常以日志文件的形式永久存储在计算机系统中。在实现请求日志时，可以将命令对象通过序列化写到日志文件中，此时命令类必须实现java.io.Serializable接口。 案例​ 某公司开发了一个网站配置文件管理工具，可以通过一个可视化界面对网站配置文件进行增删改等操作，该工具使用命令模式进行设计，结构如下所示。现在改公司开发人员希望对配置文件的操作请求记录在日志文件中，如果网站重新部署，主需要执行保存在日志文件中的命令对象即可修改配置文件。 ​ 该案例的相关代码已上传到github上。 命令模式主要优缺点主要优点 降低系统的耦合度。由于请求者与接收者之间不存在直接引用，因此请求者与接收者之间实现完全解耦，相同的请求者可以对应不同的接收者，同样，相同的接收者也可以供不同的请求者使用，两者之间具有良好的独立性。 新的命令可以很容易地加入到系统中。由于增加新的具体命令类不会影响到其他类，因此增加新的具体命令类很容易，无须修改原有系统源代码甚至客户类代码，满足开闭原则。 可以比较容易地设计一个命令队列或宏命令。 为请求的撤销和恢复操作提供了一种设计和实现方案。 主要缺点​ 主要缺点是：使用命令模式可能会导致某些系统有过多的具体命令类。因为针对每一个请求接收者的调用操作都需要设计一个具体命令类，因此在某些系统中可能需要提供大量的具体命令类，这将影响命令模式的使用。 命令模式使用场景 系统需要将请求调用者和请求接收者解耦，使得调用者和接收者不直接交互。请求调用者无须知道接收者的存在，也无须知道接收者是谁，接收者也无须关心何时被调用。 系统需要在不同的时间指定请求、将请求排队和执行请求。一个命令对象和请求的初始调用者可以有不同的生命期。即，最初的请求发出者可能已经不在了，而命令对象本身仍然是活动的，可以通过该命令对象去调用请求接收者，而无须关系请求调用者的存在性，可以通过请求日志文件等机制来具体实现。 系统需要支持命令的撤销操作和恢复操作。 系统需要将一组操作组合在一起形成宏命令。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F25%2F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ 在软件开发中，常常会遇到这种情况：实现某个功能有多条途径，每一条途径对应一种算法，此时可以使用一种设计模式来实现灵活地选择解决途径，也能够方便地增加新的解决途径。那就是策略模式。 ​ 在策略模式中，可以定义一些独立的类来封装不同的算法，每一个类封装一种具体的算法。在这里，每一个封装算法的类都可以称之为一种策略，为了保证这些策略在使用时具有一致性，一般会提供一个抽象的策略来做规则的定义，而每种算法则对应一个具体策略类。 ​ 策略模式的主要目的是将算法的定义与使用分开，也就是将算法的行为和环境分开，将算法的定义放在专门的策略类中，每一个策略类封装了一种实现算法，使用算法的环境类针对抽象策略类进行编程，符合依赖倒转原则。在出现新的算法时，只需要增加一个新的实现了抽象策略类的具体策略类即可。 策略模式定义​ 定义了一系列算法类，将每一个算法封装起来，并让他们可以互相替换。策略模式让算法独立于使用它的客户而变化，也称为政策模式。策略模式是一种对象行为型模式。 策略模式结构图 ​ 由结构图可以看到包含以下3个角色： Context（环境类）：环境类是使用算法的角色，它在解决某个问题（即实现某个方法）时可以采用多种策略。在环境类中维持一个对抽象策略类的引用实例，用于定义所采用的策略。 Strategy（抽象类）：它为所支持的算法声明了抽象方法，是所有策略类的父类，它可以是抽象类或具体类，也可以是接口。环境类通过抽象策略中声明的方法在运行时调用具体策略类中实现的算法。 ConcreteStrategy（具体策略类）：它实现了在抽象策略类中声明的算法，在运行时，具体策略类将覆盖在环境类中定义的抽象策略类对象，使用一种具体的算法实现某个业务处理。 策略模式主要优缺点主要优点 策略模式提供了对开闭原则的完美支持，用户可以在不修改原有系统的基础上选择算法或行为，也可以灵活地增加新的算法或行为。 策略模式提供了管理相关的算法族的办法，策略类的等级结构定义了一个算法或行为族，恰当使用继承可以把公共的代码移到抽象策略类中，从而避免重复的代码。 策略模式提供了一种可以替换继承关系的办法。如果不使用策略模式，那么使用算法的环境类就可能会有一些子类，每个子类提供一种不同的算法。但是，这样一来算法的使用就和算法本身混在一起，不符合单一职责原则，决定使用哪一种算法的逻辑和该算法本身混合在一起，从而不可能再独立演化；而且使用继承无法实现算法或行为在程序运行时的动态切换。 使用策略模式可以避免多重条件选择语句。多重条件选择语句不易维护，它把采取哪一种算法或行为的逻辑与算法或行为本身的实现逻辑混合在一起，将他们全部硬编码在一个庞大的多重条件选择语句中，比直接集成环境类的办法还要原始和落后。 策略模式提供了一种算法的复用机制，由于将算法单独提取出来封装在策略类中，因此不同的环境类可以方便地复用这些策略类。 主要缺点 客户端必须知道所有的策略类，并且自行决定使用哪一个策略类。这就意味着客户端必要理解这些算法的区别，以便实时选择恰当的算法。换言之，策略模式只适用于客户端知道所有的算法或行为的情况。 策略模式将造成系统产生很多具体策略类，任何细小的变化都将导致系统要增加一个新的具体策略类。 无法同时在客户端使用多个策略类，也就是说，在使用策略模式时，客户端每次只能使用一个策略类，不支持使用一个策略类完成部分功能后再使用另一个策略类来完成剩余功能的情况。 策略模式适用场景​ 在以下情况下可以考虑使用策略模式： 一个系统需要动态地在几种算法中选择一种，那么可以将这些算法封装到一个个的具体算法类中，而这些算法类都是一个抽象算法类的子类。换言之，这些具体算法类均有统一的接口，根据里氏代换原则和面向对象的多态性，客户端可以选择使用任何一个具体算法类，并且只要维持一个数据类型是抽象算法类的对象。 一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重条件选择语句来实现。此时，使用策略模式，把这些行为转移到相应的具体策略类里面，就可以避免使用难以维护的多重条件选择语句。 不希望客户端知道复制的、与算法相关的数据结构，在具体策略类中封装算法与相关的数据结构，可以提高算法的保密性与安全性。 具体事例案例1​ Sunny软件公司为某电影院开发了一套影院售票系统，在改系统中需要为不同类型的用户提供不同的电影票打折方式，具体打折方案如下： 学生凭学生证可以享受8折优惠。 年龄在10周岁及以下的儿童可享受每张票减免10元的优惠（原始票价需大于等于20元） 影院VIP用户除享受票价半价优惠外还可以积累积分，积分累计到一定额度可以兑换电影院赠送的奖品。 ​ 改系统在将来可能还需要个根据需要引入新的打折方式。 传统的实现方案大概会如下： 123456789101112131415161718192021222324public double calculate() &#123; //学生票折后票价计算 if(this.type.equalsIgnoreCase("student")) &#123; System.out.println("学生票： "); return this.price * 0.8; &#125; //儿童票折后票价计算 else if(this.type.equalsIgnoreCase("children") &amp;&amp; this.price &gt;= 20) &#123; System.out.println("儿童票："); return this.price - 10; &#125; //VIP票折价后票价计算 else if(this.type.equalsIgnoreCase("vip")) &#123; System.out.println("VIP票："); System.out.println("增加积分！"); return this.price * 0.5; &#125; else &#123; return this.price; &#125; &#125; ​ 使用策略模式实现的代码已上传至github上。 案例2​ 使用策略模式和自定义注解去掉大量的if-else https://mp.weixin.qq.com/s/sa_MMAzYg6jpy9s_rtvcCQ]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产环境中redis的数据备份和灾难恢复策略]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F22%2F%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%ADredis%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E5%92%8C%E7%81%BE%E9%9A%BE%E6%81%A2%E5%A4%8D%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[本节思维导图 ![生产环境中的数据 备份和灾难恢复](生产环境中redis的数据备份和灾难恢复策略/生产环境中的数据 备份和灾难恢复.png) ​ 我们生产环境中redis的数据备份和灾难恢复策略简单地说就是：开启AOF机制，并用RDB做冷备。 数据备份方案​ 具体的数据备份方案如下： 写crontab定时调度脚本去做数据备份。 每小时都备份一份rdb，可以copy到一个目录中去，并且只保留最近48小时的备份。 每天都保留一份当日的rdb备份到一个目录中去，仅仅保留最近一个月的备份。 每次copy备份的时候，把最旧的备份删掉。 每天晚上将当前服务器上所有的数据备份，发送一份到远程的云服务上去。 ​ 首先先创建一个目录，/usr/local/redis，然后在redis的目录中创建copy文件夹，用来存储复制快照文件的脚本。然后在redis目录中创建snapshotting文件夹，用来存储备份的rdb快照。 ​ 执行vi redis_rdb_copy_hourly.sh，编写每小时复制一份rdb的shell脚本。 123456789#!/bin/sh cur_date=`date +%Y%m%d%k`rm -rf /usr/local/redis/snapshotting/$cur_datemkdir /usr/local/redis/snapshotting/$cur_datecp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_datedel_date=`date -d -48hour +%Y%m%d%k`rm -rf /usr/local/redis/snapshotting/$del_date ​ 执行vi redis_rdb_copy_daily.sh，编写每天复制一份rdb的shell脚本。 123456789#!/bin/sh cur_date=`date +%Y%m%d`rm -rf /usr/local/redis/snapshotting/$cur_datemkdir /usr/local/redis/snapshotting/$cur_datecp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_datedel_date=`date -d -1month +%Y%m%d`rm -rf /usr/local/redis/snapshotting/$del_date ​ 上面cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date中的/var/redis/6379/dump.rdb是redis生成的快照文件的存储地址，可以根据具体情况进行修改。 ​ 最后再执行crontab -e新建调度任务，命令如下： 120 * * * * sh /usr/local/redis/copy/redis_rdb_copy_hourly.sh0 0 * * * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh ​ 然后再每天一次将所有的数据上传一次到远程的云服务器上去，这样一个数据备份方案就算完成了。 数据恢复方案 如果是redis进程挂掉了，那么重启redis进程即可，直接基于AOF日志文件恢复数据。 如果是redis进程所在机器宕机了，那么重启机器后，尝试重启redis进程，尝试直接基于AOF日志文件进行数据恢复。如果AOF没有破损，那么久直接基于AOF恢复，如果AOF文件损坏，那么用redis-check-aof fix修复日志文件。 如果redis当前最新的AOF文件和RDB文件出现了丢失，那么可以尝试基于该机器上当前的某个最新的RDB数据副本进行数据恢复。具体操作步骤为：停掉redis，关闭AOF，拷贝AOF备份，重启redis，确认数据恢复，直接在命令行热修改redis配置，即在redis-cli中执行config set appendonly yes打开AOF。这个时候redis就会将内存中的数据对应的日志，写入AOF文件中，此时AOF和RDB两份数据文件的数据就同步了。用redis config set热修改配置参数，可能配置文件中的实际参数没有被持久化的修改，需要再停止redis，手动修改配置文件，打开AOF，然后再重启redis。 如果当前机器上的所有RDB文件全部损坏，那么从远程的云服务上拉取最新的RDB快照来恢复数据。 如果是发现有重大的数据错误，比如某个小时上线的程序一下子将数据全部污染了，数据全错了，那么可以选择某个更早的时间点，对数据进行恢复 举个例子，12点上线了代码，发现代码有bug，导致代码生成的所有的缓存数据，写入redis，全部错了 找到一份11点的rdb的冷备，然后按照上面的步骤，去恢复到11点的数据，就可以了。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM中的一些参数介绍]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F16%2FJVM%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[JVM配置常用参数堆参数 参数 描述 -Xms 设置JVM启动时堆内存的初始化大小 -Xmx 设置堆内存最大值 -Xmn 设置年轻代的空间大小，剩下的为老年代的空间大小 -XX:PermGen 设置永久代内存的初始化大小（JDK1.8开始废弃了永久代） -XX:MaxPermGen 设置永久代的最大值 -XX:SurvivorRatio 设置Eden区和Survivor区的空间比例：Eden/S0 = Eden/S1 默认为8 -XX:NewRatio 设置老年代与年轻代的比例大小，默认值为2 回收器参数 参数 描述 -XX:+UseSerialGC 串行，Young区和Old区都使用串行，使用复制算法回收，逻辑简单高效，无线程切换开销 -XX:+UseParallelGC 并行，Young区：使用Parallel scavenge回收算法，会产生多个线程并行回收。通过-XX:ParallelGCThreads=n参数指定有线程数，默认是CPU核数；Old区：单线程 -XX:+UseParallelOldGC 并行，和UseParallelGCC一样，Young区和Old区的垃圾回收时都使用多线程手机 -XX:+UseConcMarkSweepGC 并发，短暂停顿的并发收集。Young区：可以使用普通的或者parallel垃圾回收算法，由参数 -XX:+UseParNewGC来控制；Old区：只能使用Concurrent Mark Sweep -XX:+UseG1GC 并行的、并发的和增量式压缩短暂停顿的垃圾收集器。不区分Young区和Old区空间。它把堆空间划分为多个大小相等的区域。当进行垃圾收集时，它会优先收集存活对象较少的区域，因此叫“Garbage First” ​ 如上表所示，目前主要有串行、并行和并发三种。对于大内存的应用而言，串行的性能太低，因此使用到的主要是并行和并发两种。并行和并发GC的策略通过UseParallelGCC和UseCon从MarkSweepGC来指定，还有一些细节的配置参数用来配置策略的执行。例如：XX:ParallelGCThreads、XX:CMSInitiatingOccupancyFraction等。通常：Young区对象回收只可选择并行（耗时间），Old区选择并发（耗CPU）。 项目中常用配置 参数设置 描述 -Xms4800m 初始化堆空间大小 -Xmx4800m 最大堆空间大小 -Xmn1800m 年轻代的空间大小 -Xss512k 设置线程栈空间大小 -XX:PermSize=256m 永久区空间大小（jdk1.8开始废弃了永久代） -XX:MaxPermSize=256m 最大永久区空间大小 -XX:+UseStringCache 默认开启，启用缓存常用的字符串 -XX:+UseConcMarkSewwpGC 老年代使用CMS收集器 -XX:UseParNewGC 新生代使用并行收集器 -XX:ParallelGCThreads=4 并行线程数量4 -XX:+CMSClassUnloadingEnabled 允许对类的元数据进行清理 XX:+DisableExplicitGC 禁止显示的GC -XX:+UseCMSInitiatingOccupancyOnly 表示只有达到阈值之后才进行CMS回收 -XX:CMSInitiatingOccupancyFraction=68 设置CMS在老年代回收的阈值为68% -verbose:gc 输出虚拟机GC详情 -XX:+PrintGCDetails 打印GC详情日志 -XX:+PrintGCDataStamps 打印GC的耗时 -XX:+PrintTenuringDistribution 打印Tenuring年龄信息 -XX:+HeapDumpOnOutOfMemoryError 当抛出OOM时进行HeapDump -XX:HeapDumpPath=/home/admin/logs 指定HeapDump的文件路径或目录 常用组合 Young Old JVM Options Serial Serial -XX:+UseSerialGC Parallel scavenge Parallel Old/Serial -XX:+UseParallelGC-XX:+UseParallelOldGC Serial/Parallel scavenge CMS -XX:+UseParNewGC-XX:+UseConcMarkSweepGC G1 -XX:+UseG1GC 常用GC调优策略GC调优原则​ 在调优之前，我们需要记住下面的原则： 多数的Java应用不需要在服务器上进行GC优化。 多数导致GC问题的Java应用，都不是因为我们参数设置错误，而是代码问题。 在应用上线之前，先考虑将机器的JVM参数设置到最优（最适合）。 减少创建对象的数量。 减少使用全局变量和大对象。 GC优化是到最后不得已才 采用的手段。 在实际使用中，分析GC情况优化代码比优化GC参数要多得多。 GC调优目的 将转移到老年代的对象数量降低到最小。 减少GC的执行时间 GC调优策略 策略1：将新对象预留在新生代，由于Full GC的成本远高于Minor GC，因此尽可能将对象分配在新生代是明智的做法，实际项目中根据GC日志分析新生代空间大小分配是否合理，适当通过“-Xmn”命令调节新生代大小，最低限度降低新对象直接进入老年代的情况。 策略2：大对象进入老年代，虽然在大部分情况下，将对象分配在新生代是合理的。但是对于大对象这种做法却值得商榷，大对象如果首次在新生代分配可能会出现空间不足导致很多年龄不够的小对象被分配到老年代，破坏新生代的对象结构，可能会出现频繁的full gc。因此，对于大对象，可以设置直接进入老年代（当然短命的大对象对于垃圾回收来说就是噩梦）。-XX:PretenureSizeThreshold可以设置直接进入老年代的对象大小。 策略3：合理设置进入老年代对象的年龄，-XX:MaxTenuingThreshold设置对象进入老年代的年龄大小，减少老年代的内存占用，降低full GC发送的频率。 策略4：设置稳定的堆大小，堆打下设置有两个参数：-Xms初始化堆大小，-Xms最大堆大小。 策略5：如果满足下面的指标，则一般不需要进行GC优化： MinorGC执行时间不到50ms MinorGC执行不频繁，约10秒一次 Full GC执行时间不到1s Full GC执行频率不算频繁，不低于10分钟1次。 参考资料Java应用如何调优]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何保证MQ的高可用]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F15%2F%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81MQ%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[RabbitMQ 的高可用RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用的。 RabbitMQ 有三种模式：单机模式、普通集群模式和镜像集群模式 单机模式单机模式，就是 Demo 级别的，一般就是你自己启动做做 Demo，很少生产使用单机模式 普通集群模式（无高可用性）普通集群模式，就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来 这种方式并没有做到所谓的分布式，就是个普通的集群。因为这导致你要么消费者每次随机连接到一个实例然后拉取数据，要么固定连接那个 queue 所在实例消费数据。前者有数据拉取的开销，后者导致单实例性能瓶颈 而且如果那个放 queue 的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让 RabbitMQ 落地存储消息的话，消息不一定会丢，得等这个实例恢复了，才可以继续从这个 queue 拉取数据 所以这个模式没有所谓的高可用性，这方案主要是提高吞吐量的，就是让集群多个节点来服务某个 queue 的读写操作 镜像集群模式（高可用）这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 你的消息都会存在于多个实例上。就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上 那么如何开启这个镜像集群模式呢？其实很简单，RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了 这样的话，好处在于，你任何一个机器宕机了，其他机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其他节点上去消费数据。 坏处在于，第一，性能开销太大，消息需要同步到所有机器上，导致网络带宽压力和消耗很重；第二，不是分布式的，没有扩展性可言。如果某个 queue 负载很重，你加机器，新增的机器也包含了这个 queue 的所有数据，并没有办法线性扩展你的 queue。如果你的 queue 的数据量很大，达到这个机器上的容量无法容纳了，此时怎么办？ Kafka 的高可用性Kafka 一个最基本的架构认识：有多个 broker 组成，每个 broker 是一个节点；你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据 这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散在多个机器上的，每个机器就放一部分数据 实际上 RabbitMQ 之类的，并不是天然的分布式消息队列，它就是传统的消息队列，只不过提供了一些集群、HA（高可用性）的机制而已，无论怎么玩，RabbitMQ 一个 queue 的数据都是放在一个节点里，镜像集群下，也是每个节点都放这个 queue 的完整数据 Kafka 0.8 以前，是没有 HA 机制的，就是任何一个 broker 宕机了，那个 broker 上的 partition 就废了，没法写也没法读，没有什么高可用性可言 例如，我们创建了一个 topic，指定其 partition 数量是 3 个，分别在三台机器上。但是，如果第二台机器宕机了，会导致这个 topic 的三分之一的数据就丢失了，因此这个是做不到高可用的 Kafka 0.8 以后，提供了 HA 机制，就是 replica（复制品）副本机制。每个 partition 的数据都会同步到其它机器上，形成自己的多个 replica 副本。所有 replica 会选举一个 leader 出来，那么生产和消费都跟这个 leader 打交道，然后其它 replica 就是 follow 写的时候，leader 会负责把数据同步到所有 follow 上去，读的时候就直接读 leader 上的数据即可。只能读写 leader？要是你可以随意读写每个 follow，那么就要关心数据一致性的问题，系统复杂度太高，很容易出问题。Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性 这样，就有高可用性了，因为如果某个 broker 宕机了，那个 broker 上面的 partition 在其他机器上都有副本的。如果这个宕机的 broker 上面有某个 partition 的 leader，那么此时会从 follower 中重新选举一个新的 leader 出来，大家继续读写那个新的 leader 即可。 写数据的时候，生产这就写 leader，然后 leader 将数据落地写本地磁盘，接着其他 follower 自己主动从 leader 来 pull 数据。一旦所有 follower 同步好数据，就会发送 ack 给 leader，leader 接收到所有 follower 的 ack 之后，就会返回写成功的消息给生产者（当然，这只是其中一种模式，还可以适当调整这个行为） 消费的时候，只会从 leader 去读，但是只有当一个消息已经被所有 follower 都不同成功返回 ack 的时候，这个消息才会被消费者读到]]></content>
      <categories>
        <category>消息队列</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL读写分离]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F15%2FMySQL%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 当并发量到达一定程度后，一般都是要做读写分离的。因为大部分情况下都是读多写少。所以针对这个情况，都是写一个主库，但是主库挂多个从库，然后从多个从库读数据，就可以支撑更高的读并发压力了。 如何实现MySQL的读写分离​ 基于主从架构。简单来说就是搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。 MySQL主从复制的原理​ 主库将变更写入binlog日志，然后从库连接到主库之后，从库会有一个IO线程，将主库的binlog日志拷贝到自己本地，写入一个relay中继日志。接着从库中有一个SQL线程会从中继日志读取binlog，然后执行binlog日志中的内容，也就是在自己本地在执行一遍SQL，这样就可以保证自己跟主库的数据是一样的。 ​ 这里需要特别注意的是，从库同步主库数据的过程是串行化的，即主库上并行的操作，在从库会串行执行。所以这是一个非常重要的点，由于从库从主库拷贝日志以及串行执行SQL的特点，在高并发场景下，从库的数据一定会比主库慢一些，是有延时的。所以经常出现，刚写入主库的数据可能是读取不到的，要过几十毫秒，甚至于几百毫秒才能读到。 ​ 而且如果主库突然宕机，然后恰好数据还没同步到从库，那么有些数据可能在从库上时没有的，有些数据就可能丢失了。 ​ 所以MySQL实际上这一块有两个机制，一个是半同步复制，用来解决主库数据丢失问题；一个是并行复制，用来解决主从同步延时问题。 ​ 半同步复制，也叫semi-sync复制，指的就是主库写入binlog日志之后，就会强制此时立即将数据同步到从库，从库将日志写入本地的relay log之后，接着会返回一个ack给主库，主库接到至少一个从库的ack之后才会认为写操作完成。 ​ 并行复制，指的是从库开启多个线程，并行读取relay log中不同库的日志，然后并行重放不同库的日志，这是库级别的并行。 MySQL主从同步延时问题​ 假设这么一个场景，一段代码逻辑是这样的：先插入一条数据，再把他查出来，然后更新这条数据。在生产高峰期，写并发达到2000/s，这个时候主从复制的延时大概是在小几十毫秒。线上会发现，每天总有一些数据，我们期望更新的一些重要数据的状态，在高峰期时却没有更新。 ​ 可以通过MySQL命令show status查看Second_Behind_Master，可以看到从库复制主库的数据落到了多少ms。 ​ 一般来说，如果主从延迟比较严重，有以下解决方案： 分库，将一个主库拆分为多个从库，每个主库的写并发就减少了几倍，此时主从延时可以忽略不计 打开MySQL支持的并行复制，多个库并行复制。但如果某个库的写入并发特别高，单库写并发达到了2000/s，并行复制还是没有意义 重写代码。写代码是要考虑插入数据时立马查询数据有可能查询不到 如果确实是存在必须先插入，立马要求立刻查询到，然后再执行一些操作，对这个查询设置直连主库，不推荐这种方法。这么处理，读写分离的意义就丧失了。]]></content>
      <categories>
        <category>数据库</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分库分表后的主键ID如何生成]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F15%2F%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E5%90%8E%E7%9A%84%E4%B8%BB%E9%94%AEID%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 分库分表后，主键ID的生成就成了一个问题，我们需要生成一个全局唯一的ID来支持。有以下方法来生成全局唯一的ID主键 数据库自增ID​ 这个就是说你的系统里每次得到一个ID，都是往一个库的一个表里插入一条没什么业务含义的数据，用于专门生成主键ID。然后获取到相应的ID后，就往对应的分库分表里去写入。 优缺点​ 这个方案的好处就是方便简单，缺点就是单库生成自增ID，要是高并发的话，就会有瓶颈；可以改进一下，就是专门开一个服务出来，这个服务每次就拿到当前ID最大值，然后自己递增几个ID，一次性返回一批ID，然后再把当前最大ID修改成递增几个ID之后的一个值，但是无论如何都是基于单个数据库。 适合场景​ 一般来说，分表分库就两个原因，要不就是单库并发太高，要不就是单库数据量太大。除非你并发不高，但是数据量太大导致的分库分表扩容，你就可以用这个方案，因为每秒最高并发最多也就几百，那么就走单独的一个库和表生成自增主键即可。 UUID​ 好处就是本地生成，不用基于数据库来了；不好就是，UUID太长，占用空间太大，作为主键性能太差了；更重要的是，UUID不就有有序性，会导致B+数索引在写的时候有过多的随机写操作（连续的ID可以产生部分顺序写），还有，由于在写的时候不能产生有顺序的append操作，而需要进行insert操作，将会读取整个B+数节点到内存，在插入这条记录后再将这个节点写会磁盘，这种操作在记录占用空间比较大的情况下，性能下降明显。 适用场景​ 要是随机生成文件名、编号之类的，可以用UUID，但是作为主键是不能用UUID的。 获取系统当前时间​ 这个就是获取当前时间即可，但是当并发很高时，比如一秒并发几千，会有重复的情况，这个肯定是不合适的。 适用场景​ 一般如果用这个方案，就是将当前时间跟很多其他的业务字段拼接起来，作为一个ID。如果业务上就觉得可以接受，那么也是可以的。你可以将别的业务字段跟当前时间拼接起来，组成一个全局唯一的编号。 snowflake算法​ snowflake算法是Twitter开源的分布式ID生成算法，采用Scala语言实现，是把一个64位的long型的ID。其中一个bit的不用的，用其中的41bit作为毫米数，用10bit作为工作机器id，12bit作为序列号。 1bit：第一个bit统一都是0，因为我们生成的ID都是正数 41bit：表示的是时间戳，单位是毫秒。41bit可以表示的数字多达2^41-1，也就是可以标识2^41-1个毫秒值，换算成年就是表示69年的时间 10bit：记录工作机器ID，代表的是这个服务最多可以部署在2^10台机器上，也就是1024台机器。但是10bit里5个bit代表机房ID，5个bit代表机器ID。意思就是最多代表2^5个机房（32个机房），每个机房里可以代表30台机器。 12bit：这个是用来记录同一个毫秒内产生的不同ID，12bit可以代表的最大整数是2^12=4096，也就是说可以用这个12bit代表的数字来区分同一个毫秒内的4096个不同的ID。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187package com.leyou.utils;import java.lang.management.ManagementFactory;import java.net.InetAddress;import java.net.NetworkInterface;/** * &lt;p&gt;名称：IdWorker.java&lt;/p&gt; * &lt;p&gt;描述：分布式自增长ID&lt;/p&gt; * &lt;pre&gt; * Twitter的 Snowflake JAVA实现方案 * &lt;/pre&gt; * 核心代码为其IdWorker这个类实现，其原理结构如下，我分别用一个0表示一位，用—分割开部分的作用： * 1||0---0000000000 0000000000 0000000000 0000000000 0 --- 00000 ---00000 ---000000000000 * 在上面的字符串中，第一位为未使用（实际上也可作为long的符号位），接下来的41位为毫秒级时间， * 然后5位datacenter标识位，5位机器ID（并不算标识符，实际是为线程标识）， * 然后12位该毫秒内的当前毫秒内的计数，加起来刚好64位，为一个Long型。 * 这样的好处是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞（由datacenter和机器ID作区分）， * 并且效率较高，经测试，snowflake每秒能够产生26万ID左右，完全满足需要。 * &lt;p&gt; * 64位ID (42(毫秒)+5(机器ID)+5(业务编码)+12(重复累加)) * * @author Polim */public class IdWorker &#123; /** * 时间起始标记点，作为基准，一般取系统的最近时间（一旦确定不能变动） */ private final static long twepoch = 1288834974657L; /** * 机器标识位数 */ private final static long workerIdBits = 5L; /** * 数据中心标识位数 */ private final static long datacenterIdBits = 5L; /** * 机器ID最大值 */ private final static long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); /** * 数据中心ID最大值 */ private final static long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); /** * 毫秒内自增位 */ private final static long sequenceBits = 12L; /** * 机器ID偏左移12位 */ private final static long workerIdShift = sequenceBits; /** * 数据中心ID左移17位 */ private final static long datacenterIdShift = sequenceBits + workerIdBits; /** * 时间毫秒左移22位 */ private final static long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; private final static long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); /** * 上次生产id时间戳 */ private static long lastTimestamp = -1L; /** * 并发控制 */ private long sequence = 0L; private final long workerId; /** * 数据标识id部分 */ private final long datacenterId; public IdWorker()&#123; this.datacenterId = getDatacenterId(maxDatacenterId); this.workerId = getMaxWorkerId(datacenterId, maxWorkerId); &#125; /** * @param workerId * 工作机器ID * @param datacenterId * 序列号 */ public IdWorker(long workerId, long datacenterId) &#123; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format("worker Id can't be greater than %d or less than 0", maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format("datacenter Id can't be greater than %d or less than 0", maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; &#125; /** * 获取下一个ID * * @return */ public synchronized long nextId() &#123; long timestamp = timeGen(); if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException(String.format("Clock moved backwards. Refusing to generate id for %d milliseconds", lastTimestamp - timestamp)); &#125; if (lastTimestamp == timestamp) &#123; // 当前毫秒内，则+1 sequence = (sequence + 1) &amp; sequenceMask; if (sequence == 0) &#123; // 当前毫秒内计数满了，则等待下一秒 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; else &#123; sequence = 0L; &#125; lastTimestamp = timestamp; // ID偏移组合生成最终的ID，并返回ID long nextId = ((timestamp - twepoch) &lt;&lt; timestampLeftShift) | (datacenterId &lt;&lt; datacenterIdShift) | (workerId &lt;&lt; workerIdShift) | sequence; return nextId; &#125; private long tilNextMillis(final long lastTimestamp) &#123; long timestamp = this.timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = this.timeGen(); &#125; return timestamp; &#125; private long timeGen() &#123; return System.currentTimeMillis(); &#125; /** * &lt;p&gt; * 获取 maxWorkerId * &lt;/p&gt; */ protected static long getMaxWorkerId(long datacenterId, long maxWorkerId) &#123; StringBuffer mpid = new StringBuffer(); mpid.append(datacenterId); String name = ManagementFactory.getRuntimeMXBean().getName(); if (!name.isEmpty()) &#123; /* * GET jvmPid */ mpid.append(name.split("@")[0]); &#125; /* * MAC + PID 的 hashcode 获取16个低位 */ return (mpid.toString().hashCode() &amp; 0xffff) % (maxWorkerId + 1); &#125; /** * &lt;p&gt; * 数据标识id部分 * &lt;/p&gt; */ protected static long getDatacenterId(long maxDatacenterId) &#123; long id = 0L; try &#123; InetAddress ip = InetAddress.getLocalHost(); NetworkInterface network = NetworkInterface.getByInetAddress(ip); if (network == null) &#123; id = 1L; &#125; else &#123; byte[] mac = network.getHardwareAddress(); id = ((0x000000FF &amp; (long) mac[mac.length - 1]) | (0x0000FF00 &amp; (((long) mac[mac.length - 2]) &lt;&lt; 8))) &gt;&gt; 6; id = id % (maxDatacenterId + 1); &#125; &#125; catch (Exception e) &#123; System.out.println(" getDatacenterId: " + e.getMessage()); &#125; return id; &#125;&#125; ​ 利用这个 snowflake 算法，你可以开发自己公司的服务，甚至对于机房 id 和机器 id，反正给你预留了 5 bit + 5 bit，你换成别的有业务含义的东西也可以的。 ​ 这个 snowflake 算法相对来说还是比较靠谱的，所以你要真是搞分布式 id 生成，如果是高并发啥的，那么用这个应该性能比较好，一般每秒几万并发的场景，也足够你用了。]]></content>
      <categories>
        <category>数据库</category>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单讲一下分库分表]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F10%2F%E7%AE%80%E5%8D%95%E8%AE%B2%E4%B8%80%E4%B8%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[分库分表​ 分库分表是两回事，可能是光分库不分表，也可能是光分表不分库，都有可能。 分表​ 如果你单表都几千万数据了，单表数据量太大，会极大影响你的Sql执行的性能，到了后面sql可能就跑的很慢了。一般来说，单表到了几百万的时候，性能就会相对差一些，你就得分表了。 ​ 分表，就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户ID来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就可以了。这样可以控制每个表的数据量在可控的方范围内，比如每个表就固定在200万以内。 分库​ 分库，就是一般而言我们一个库，最多支撑到2000并发，就一定要扩容了，而且一个健康的单库并发值最好保持在每秒1000左右，不要太大。可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。 分库分表前 分库分表后 并发支撑情况 MySQL单机部署，扛不住高并发 MySQL从单机到多机，能承受的并发增加了多倍 磁盘使用情况 MySQL单机磁盘容量几乎撑满 拆分为多个库，数据库服务器磁盘使用率大大降低 SQL执行性能 单表数据量太大，SQL越跑越慢 单表数据库量减少，SQL执行效率明显提升 分库分表的中间件​ 比较常见的分库分表的中间件包括： Cobar TDDL Atlas Sharding-jdbc Mycat ​ 目前市场上比较主流的就是sharding-jdbc和Mycat，这两个都可以考虑去使用。Sharding-jdbc这种属于Client层方案，优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合Sharding-jdbc的依赖。Mycat属于proxy层方案，缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间间那里处理即可。 ​ 通常来说，这两个方案其实都可以选用，但是大佬建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。 如何对数据库进行水平拆分和垂直拆分水平拆分​ 水平拆分，就是把一个表的数据弄个多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的表里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。 垂直拆分​ 垂直拆分，就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。 ​ 还有表层面的拆分，就是分表，将一个表变成N个表，就是让每个表的数据量控制在一定范围内，保证SQL的性能。否则单表的数据量越大，SQL性能就越差。 ​ 无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，中间件可以根据你指定的某个字段值，比如说 userid，自动路由到对应的库上去，然后再自动路由到对应的表里去。 ​ 你就得考虑一下，你的项目里该如何分库分表？一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。 ​ 有两种分库分表的方式： 按照range来分，就是每个库一段连续的数据，这个一般是按照，例如时间范围来的。但是这种一般较少使用，因为很容易产生热点问题，大量的流量都打在最新的数据上了 按照某个子段hash一下均匀分散，这个较为常用。 ​ range来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。 ​ hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。]]></content>
      <categories>
        <category>分布式</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[保证缓存与数据库双写的一致性]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F08%2F%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%2F</url>
    <content type="text"><![CDATA[本节思维导图 Cache Aside Pattern​ 最经典的缓存+ 数据库读写的模式，就是这个Cache Aside Pattern 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回请求。 更新的时候，先更新数据库，然后再删除缓存。（这个方案并不靠谱，原因下面有讲） ​ 至于为什么是删除缓存，而不是更新缓存。原因在于在复杂的缓存场景，缓存不单单是数据库中直接拉取出来的值。比如更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据进行运算，才能计算出缓存最新的值的。 ​ 而且更新缓存的代价有时候是很高的。对于复杂的缓存数据计算场景，如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新，但这个数据有可能只需要被访问一次呢？例如一个缓存涉及的表的字段，在一分钟内就修改了一百次，而缓存也更新了一百次，但是这个缓存在一分钟内只被读取一次，有大量的冷数据。如果只是删除缓存的话，那么在1分钟内，这个缓存也就重新计算一次，大幅度降低开销。用到缓存才去算缓存。 最初级的缓存不一致问题及解决方案​ 如果先更新数据库，在删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。 解决思路​ 先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存是空的，那么数据不会不一致。因为读的时候缓存没有了，所以读了数据库中的旧数据，然后更新到缓存中。 高并发场景下数据不一致问题分析​ 数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改，一个请求过来，先去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。这样就会发生数据库与缓存的数据不一致了。 什么场景下会发生上述情况​ 只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。如果并发量很低的话，特别是读并发很低，每天访问量就一万，那么很少的情况才会出现上述情况。如果每天是上亿的流量，每秒并发读是几万，每秒只要有数据更新的情况，就可坑出现上述的数据库和缓存不一致的情况。 解决方案​ 更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据 + 更新缓存的操作，根据唯一标识路由之后，也发到同一个jvm内部队列中。 ​ 一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没有完成更新。此时如果一个读请求过来，没有读到缓存，可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。 ​ 这里有一个可以优化的地方。一个队列中，多个更新缓存请求串在一起是没意义的。可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新缓存的请求操作进去，直接等前面的更新操作请求完成即可。 ​ 等那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库读取最新的值，然后写入缓存中。 ​ 如果请求还在等待时间范围内，不断轮询，发现可以取到值了，那么久直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。 存在的问题 读请求长时阻塞 由于读请求进行了非常轻度的异步化，所以要注意读超时的问题，每个读请求必须在超时时间范围内返回。 ​ 解决方案，或者最大的风险点在于可能数据更新很频繁。导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库。因此务必通过一些模拟真实的测试，看看数据更新的频率是怎样的。 ​ 另外，因为一个队列中，可能会积压对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务。每个服务分摊一些数据的更新操作。如果一个内存队列路积压100个商品的库存修改操作，每个库存修改操作需要耗费10ms去完成，那么最后一个商品的读请求，可能等待10 * 100ms = 1s，才能得到数据，这个时候就导致读请求的长时阻塞。 读请求并发量过大 ​ 这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时hang在服务上，看服务能不能抗的住，需要多少机器才能抗住最大的极限情况的峰值。 ​ 但是因为不是所有的数据都在同一时间更新，缓存也不会再同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。 多服务实例部署的请求路由 ​ 可能这个服务部署了多个实例，那么必须保证，执行数据更新操作，以及执行缓存更新操作的请求，都通过Nginx服务器路由到相同的服务实例上。 ​ 例如对同一个商品的读写请求，全部路由到同一台服务器上。可以自己去做服务间的按照某个请求参数的hash路由，也可以用Nginx的hash路由功能等。 热点商品的路由问题，导致请求的倾斜 ​ 如果某个商品的读写请求特别高，全部打到相同机器相同的队列里，可能会造成某台机器的压力过大。就是说，因为只有在商品更新的时候才会清空缓存，然后才会导致读写并发。所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响不是特别大，但是的确可能某些机器的负载会高一些。 总结​ 一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说系统不是严格要求“缓存 + 数据库”必须保持一致性的话，最好不要做“读请求和写请求串行化”，串到一个内存队列里去。 ​ 串行化可以保证一定不会出现不一致的情况，但是它会导致系统的吞吐量大幅度降低。]]></content>
      <categories>
        <category>分布式</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis集群]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F04%2FRedis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[本节思维导图 ![Redis Cluster](Redis集群/Redis Cluster.png) ​ Redis cluster，主要是针对海量数据 + 高并发 + 高可用的场景。Redis cluster支撑N个redis master node，每个master node都可以挂载多个slave node。这样整个redis就可以横向扩容了。如果要支撑更大数据量的缓存，那就横向扩容更多的master节点。 Redis cluster介绍 自动将数据进行分片，每个master上放一部分数据 提供内置的高可用支持，部分master不可用时，还是可以继续工作的 ​ 在redis cluster架构下，每个redis要开放两个端口号，比如一个是6379，另一个就是加1W的端口号，比如16379. ​ 16379端口号是用来进行节点间通信的，也就是cluster bus的东西。cluster bus的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus使用一种二进制的协议，gossip协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。 节点间的内部通信机制基本通信原理​ 集群元数据的维护有两种方式：集中式。Gossip协议。redis cluster节点间采用gossip协议进行通信。 ​ 集中式是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于ZooKeeper（分布式协调的中间件）对所有元数据进行存储维护。 ​ redis维护集群元数据采用另一个方式，gossip协议，所有节点都持有一份元数据，不同节点如果出现了元数据的变更，就不断将元数据发送给其他的节点，让其他节点也进行元数据的并更。 ​ 集中式的好处在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其他节点读取的时候就可以感知到；不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。 ​ gossip好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆续打到所有节点上去更新，降低了压力；缺点是元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。 1000端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+ 10000。每个节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几个节点接收到ping之后返回pong。 交换的信息：信息包括故障信息，节点的增加和删除，hash slot信息等等。 gossip协议​ gossip协议包含多种消息，包含ping、pong、meet、fail等等。 meet：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信。 1redis-trib.rb add-node 其实内部就是发送了一个gossip meet消息给新加入的节点，通知那个节点去加入我们的集群。 ping：每个节点都会频繁给其它节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据。 pong：返回ping和meet，包含自己的状态和其它信息，也用于消息广播和更新。 fail：某个节点判断另一个节点fail之后，就发送fail给其它节点，通知其它节点某个节点宕机了。 ping消息深入​ ping时要携带一些元数据，如果很频繁，可能会加重网络负担。 ​ 每个节点每秒会执行10次ping，每次会选择5个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了cluster_node_timeout / 2，那么立即发送ping，避免数据交换延时过长，落后的时间过长。例如，两个节点之间都10分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以cluster_node_timeout可以调节，如果调的比较大，那么会降低ping的频率。 ​ 每次ping，都会带上自己节点的信息，还有就是带上1/10其它节点的信息，发送出去，进行交换。至少包含3个其它节点的信息，最多包含总结点减2个其它节点的信息。 分布式寻址算法 hash算法 一致性hash算法（自动缓存迁移） + 虚拟节点（自动负载均衡） redis cluster的hash slot算法 hash算法​ 来了一个key，首先计算hash值，然后对节点数取模。然后打在不同的master节点上，一旦某一个master节点宕机，所有请求过来，都会基于最新的master节点数去取模，尝试去取数据。这会导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库。 一致性hash算法​ 一致性hash算法将整个hash值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织。下一步将各个master节点（使用服务器的ip或主机名）进行hash。这样就能确定每个节点在其哈希环上的位置。 ​ 来了一个key，首先计算hash值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，遇到的第一个master节点就是可以所在位置。 ​ 在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其他不收影响，增加一个节点也同理。 ​ 但是如果一致性哈希算法在节点太少是，容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性hash算法引入了虚拟节点机制，即对每一个节点计算多个hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。 redis cluster的hash slot算法​ redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot。 ​ redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot。hash slot让node的增加和移除都很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去。移动hash slot的成本是非常低的。客户端的API，可以对指定的数据，让他们走同一个hash slot，同时hash tag来实现。 ​ 任何一台机器宕机，redis的寻址都不受影响。因为key找的是hash slot，不是机器。 ![hash slot](Redis集群/hash slot.png) Redis Cluster的高可用与主备切换原理​ redis cluster的高可用的原理，几乎跟哨兵是类似的。 判断节点宕机​ 如果一个节点认为另一个节点宕机，那么就是pfail，主观宕机。如果多个节点都认为一个节点宕机了，那么就是fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown。 ​ 在cluster-node-timeout内，某个节点一直没有返回pong，那么就会认为fail。 ​ 如果一个节点认为某个节点fail，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，那么就会变成fail. 从节点过滤​ 对宕机的master node，从其所有的slave node中，选择一个切换成master node。 ​ 检查每个slave node与master node断开连接的时间，如果超过了cluster-node-timeout * cluster-salve-validity-factor，那么就没有资格切换成master。 从节点选举​ 每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。 ​ 所有的master node开始slave选举投票，给要进行选举的slave进行投票，如果大部分master node (N / 2 + 1)都投票给某个从节点，那么选举通过，那个从节点 可以切换成master。 ​ 从节点执行主备切换，从节点切换为主节点。 与哨兵比较​ 整个流程跟哨兵相比，非常类似。所以redis cluster相当于直接集成了replication和sentinel的功能。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F01%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ Redis持久化的意义在于数据备份和灾难恢复。Redis如果仅仅只是将数据缓存在内存里面，如果Redis宕机了再重启，内存里的数据就全部弄丢了。所以得用Redis的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行持久化。如果Redis宕机重启，自动从磁盘上加载之前持久化的一些数据即可，也许会丢失少许数据，但是至少不会将所有数据都弄丢。 Redis持久化的两种方式 RDB：RDB持久化机制，是对Redis中的数据进行周期性的持久化。 AOF：AOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在Redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集。 ​ 通过RDB或AOF，都可以将Redis内存中的数据持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如阿里云等云服务等。 ​ 如果同时使用RDB和AOF两种持久化机制，那么redis重启的时候，会使用AOF来重构新数据，因为AOF中的数据更加完整。 RDB优缺点 RDB会生成多个数据文件，每个数据文件都代表某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完备的数据文件发送到一些远程的安全存储上去，比如国内的阿里云的ODPS分布式存储上，以预定好的备份策略来定期备份redis中的数据。 RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可。 相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速。 如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，一般都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据。 RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。 AOF优缺点 AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。 AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使尾部破损，也很容易修复。 AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewritelog的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后日志文件ready的时候，再交换新老日志文件即可。 AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急操作。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据。 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大。 AOF开启后，支持的QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然每秒一次fsync性能也还是很高的。但如果实时写入，那么QPS会大降，redis性能会大大降低。 以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据。因此，类似AOF这种较为复杂的基于命令/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免 rewrite 过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge，而是基于当时内存中的数据进行指令的重新构建，这样健壮性好很多。 补充：rewrite类似于普通数据库管理系统日志恢复点，当AOF文件随着写命令的运行膨胀时，当文件大小触碰到临界时，rewrite会被运行。 rewrite会像replication一样，fork出一个子进程，创建一个临时文件，遍历数据库，将每个key、value对输出到临时文件。输出格式就是Redis的命令，但是为了减小文件大小，会将多个key、value对集合起来用一条命令表达。在rewrite期间的写操作会保存在内存的rewrite buffer中，rewrite成功后这些操作也会复制到临时文件中，在最后临时文件会代替AOF文件。 RDB和AOF到底该如何选择 不要仅仅使用RDB，因为那样会导致你丢失很多数据。 也不要仅仅使用AOF，因为那样有两个问题：第一，通过AOF做冷备，没有RDB做冷备来得恢复速度更快；第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug； redis支持同时开启两种持久化方式，我们可以综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择，用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复。 如何配置RDB持久化的配置​ 打开redis的配置文件，搜索save，如图所示： ​ save 60 10000表示，每隔60秒，如果有超过10000个key发生了变化，那么就生成一个新的dump.rdb文件，就是当前redis内存中完整的数据快照，这个操作也被称为snapshotting。save可以设置多个，就是多个snapshotting检查点，每到一个检查点，就会去check一下，是否有指定的key数量发生了变更，如果有，就生成一个新的dump。 ​ 也可以手动调用save或者bgsave命令，同步或异步执行rdb快照生成。 ​ 如果你通过redis-cli SHUTDOWN的方式去停掉redis，这其实是一种安全退出的模式，redis在退出的时候会将内存中的数据立即生成一份完整的快照。如果用kill -9粗暴杀死redis进程，则相当于redis故障异常退出，不会生成dump快照文件。 AOF持久化的配置​ AOF持久化默认是关闭的，默认是打开RDB持久化。要开启AOF持久化配置，在redis配置文件中搜索appendonly，如下所示，将no改为yes即可。打开AOF持久化机制之后，redis每收到一条写指令，就会写入日志文件中。会先写入os cache，然后每隔一定时间再fsync一下。 ​ AOF的fsync总共有三种策略： appendfsync always：每次写入一条数据，立即将这个数据对应的写日志fsync到磁盘上去，性能很差，吞吐量很低，但确保了redis里的数据一条不丢。 appendfsync everysec：每秒执行一次fsync。这个最常用，生产环境一般这么配置，性能很高，QPS可以上万。 appendfsync no：不主动执行fsync，由操作系统自行判断。不可控。 AOF rewrite的配置​ 这里主要讲两个rewrite的配置 12auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 举个例子，比如上一次AOF rewrite之后，日志大小是128MB。此时就会接着128MB继续写AOF日志，如果发现增长的比例已经超过了之前的100%，256MB，就可能会去触发一次rewrite。但是此时还要去跟min-size， 64mb去比较，256 &gt; 64时，才会触发rewrite。 AOF破损文件的修复如果redis在append数据到AOF文件时，机器宕机了，可能会导致AOF文件破损 用redis-check-aof –fix命令来修复破损的AOF文件]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计核心接口的防重幂等性]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A0%B8%E5%BF%83%E6%8E%A5%E5%8F%A3%E7%9A%84%E9%98%B2%E9%87%8D%E5%B9%82%E7%AD%89%E6%80%A7%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 在分布式系统中，一般都会有重试机制。但重复机制又有一定几率出现重复的数据。例如订单系统消费了消息，但是由于网络等问题消息系统未收到反馈是否已成功处理，此时消息系统会根据配置的规则隔断时间就retry一次。但如果此时网络恢复正常，我第一次收到的消息成功处理了，这是又收到一条消息，如果没有防护措施，就有可能出现重复数据。 接口幂等性​ 幂等性指任意多次执行所产生的影响均与一次执行的影响相同。多次调用对系统的产生的影响是一样的，即对资源的作用是一样的，但是返回值允许不同。在我们编程中主要操作就是CURD，其中读取（Retrieve）操作和删除（Delete）操作是天然幂等的，受影响的就是创建（Create）、更新（Update）。 对于业务中需要考虑幂等性的地方一般都是接口的重复请求，重复请求是指同一个请求因为某些原因被多次提交。导致这个情况会有几种场景： 前端重复提交：提交订单，用户快速重复点击多次，造成后端生成多个内容重复的订单。 接口超时重试：对于给第三方调用的接口，为了防止网络抖动或其他原因造成请求丢失，这样的接口一般都会设计成超时重试多次。 消息重复消费：MQ消息中间件，消息重复消费。 幂等性实现方式Token机制 服务端提供了发送token的接口，我们在分析业务的时候，哪些是存在幂等问题的，就必须在执行业务前，前去获取token，服务器会把token保存到redis中； 然后调用业务接口请求时，把token携带过去，一般反正请求头部； 服务器判断token是否存在redis中，存在表示第一次请求，可以继续执行业务，业务完成后，需要把redis中的token删掉； 如果判断token不存在redis中，就表示是重复操作，直接返回重复标记给client，这样就保证了业务代码，不被重复执行。 这就是token+redis的幂等方案。适用于绝大部分场景。主要针对前端重复连续多次点击的情况，网上也有另一个版本的Token方案，不同的地方是：网上方案检验token存在后，就立刻删除token，再进行业务处理。而上面的方式是检验token存在后，先进行业务处理，再删除token。 网上方案的缺点是先删除token，这是出现系统问题导致业务处理出现异常，业务处理没有成功，接口调用方也没有获取到明确的结果，然后进行重试，但token已经删除掉了，服务端判断token不存在，认为是重复请求，就直接返回了，无法进行业务处理了。 而上面的方案后删除token也是会存在问题的，如果进行业务处理成功后，删除redis中的token失败了，这样就导致了有可能会发生重复请求，因为token没有被删除。 token机制缺点业务请求每次请求，都会有额外的请求（一次获取token请求、判断token是否存在的业务）。其实真实的生产环境中，1万请求也许只会存在10个左右的请求会发生重试，为了这10个请求，我们让9990个请求都发生了额外的请求。（当然redis性能很好，耗时不会太明显） 去重表机制往去重表里插入数据的时候，利用数据库的唯一索引特性，保证唯一的逻辑。唯一序列号可以是一个字段，也可以是多字段的唯一性组合。 这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。 另外，使用数据库防重表的方式它有个严重的缺点，那就是系统容错性不高，如果幂等表所在的数据库连接异常或所在的服务器异常，则会导致整个系统幂等性校验出问题。 乐观锁机制乐观锁解决了计算赋值型的修改场景。例如： 123456update user set point = point + 20, version = version + 1 whereuserid=1 and version=1 加上了版本号后，就让此计算赋值型业务，具备了幂等性。 乐观锁缺点在操作业务前，需要先查询出当前的version版本。 唯一主键机制这个机制是利用了数据库的主键唯一约束的特性，解决了在insert场景时幂等问题。但主键的要求不是自增的主键，这样就需要业务生成全局唯一的主键，之前老顾的文章也介绍过分布式唯一主键ID的生成，可自行查阅。如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。因为对主键有一定的要求，这个方案就跟业务有点耦合了，无法用自增主键了。 Redis实现Redis实现的方式就是将唯一序列号作为Key，唯一序列号可以拿几个字段MD5加密生产的密文，value可以是你想填的任何信息。唯一序列号也可以是一个字段，例如订单的订单号，也可以是多字段的唯一性组合。当然这里需要设置一个 key 的过期时间，否则 Redis 中会存在过多的 key。 状态机对于很多业务有一个业务流转状态的，每个状态都有前置状态和后置状态，以及最后的结束状态。例如流程的待审批，审批中，驳回，重新发起，审批通过，审批拒绝。订单的待提交，待支付，已支付，取消。 以订单为例，已支付的状态的前置状态只能是待支付，而取消状态的前置状态只能是待支付，通过这种状态机的流转我们就可以控制请求的幂等。 123456789101112131415161718192021222324252627public enum OrderStatusEnum &#123; UN_SUBMIT(0, 0, "待提交"), UN_PADING(0, 1, "待支付"), PAYED(1, 2, "已支付待发货"), DELIVERING(2, 3, "已发货"), COMPLETE(3, 4, "已完成"), CANCEL(0, 5, "已取消"), ; //前置状态 private int preStatus; //状态值 private int status; //状态描述 private String desc; OrderStatusEnum(int preStatus, int status, String desc) &#123; this.preStatus = preStatus; this.status = status; this.desc = desc; &#125; //...&#125; 假设当前状态是已支付，如果支付接口又收到了支付请求，则会抛出异常会拒绝此处处理。 参考资料https://juejin.im/post/5ceb4c4f51882572a206d174 https://juejin.im/post/5d1e01aaf265da1bbc6ff400]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud生产环境配置服务的配置超时和重试参数]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F26%2FSpringCloud%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%85%8D%E7%BD%AE%E8%B6%85%E6%97%B6%E5%92%8C%E9%87%8D%E8%AF%95%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[启动Ribbon的饥饿加载​ 在生产环境中，系统第一次启动时，调用其他服务经常会出现timeout，经过查阅资料得知：每个服务第一次被请求的时候，他会去初始化一个Ribbon的组件，初始化这些组件需要耗费一定的时间，所以很容易会导致timeout问题。解决方案是让每个服务启动的时候直接初始化Ribbon相关的组件，避免第一次请求的时候初始化。 123ribbon: eager-load: enabled: true ​ 上面只是解决了内部服务之间的调用，但还有一个问题就是：网关到内部服务的访问。由于Spring Cloud Zuul的路由转发也是通过Ribbon实现负载均衡的，所以也会存在第一次调用时比较慢的情况。 ​ 此时可以通过以下配置 12345zuul: ignored-services: '*' ribbon: eager-load: enabled: true ​ Spring Cloud Zuul的饥饿加载中没有设计专门的参数来配置，而是直接采用了读取路由配置来进行饥饿加载的做法。所以，如果我们使用默认路由，而没有通过配置的方式制定具体路由规则，那么zuul.ribbon.eager-load.enabled=true的配置就没有作用了。 ​ 因此，在真正使用的时候，可以通过zuul.ignored-services=*来忽略所有的默认路由，让所有的路由配置均维护在配置文件中，以达到网关启动时就默认初始化好各个路由转发的负载均衡对象。 Ribbon配置超时和重试参数​ 以下配置是用来配置Ribbon的超时时间和重试次数的： 12345678910111213ribbon: ConnectTimeout: 250 # 连接超时时间(ms) ReadTimeout: 2000 # 通信超时时间(ms) OkToRetryOnAllOperations: true # 是否对所有操作重试 MaxAutoRetriesNextServer: 1 # 同一服务不同实例的重试次数 MaxAutoRetries: 1 # 同一实例的重试次数hystrix: command: default: execution: isolation: thread: timeoutInMillisecond: 10000 # 熔断超时时长：10000ms ​ 假设在网关Zuul配置了以上参数，MaxAutoRetriesNextServer和MaxAutoRetries的意思是如果Zuul认为某个服务超时了，此时会先重试一下该服务对应的这台机器，如果还是不行就会重试一下该服务的其他机器。 ​ 重试机制除了上面的参数配置的方式之外，还可以使用Spring-Retry实现。相比配置参数配置的方式，灵活性和扩展性更强。详情可以看大佬的这一篇Spring Retry重试机制]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里分布式事务框架seata的使用和介绍]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F24%2F%E9%98%BF%E9%87%8C%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%A1%86%E6%9E%B6seata%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[​ 在分布式系统中，分布式事务是一个必须要解决的问题，目前使用较多的是最终一致性方案。自年初阿里开源了Fescar（四月初更名为Seata）后，该项目受到了极大的关注，目前已接近 8000 Star。Seata以高性能和零侵入的特性为目标解决微服务领域的分布式事务难题，目前正处于快速迭代中。 seata的几个概念​ 在讲解seata的原理之前，我们先了解几个Seata的相关概念。 XID：全局事务的唯一标识，由 ip:port:sequence 组成； Transaction Coordinator (TC)：事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚； Transaction Manager (TM )：控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议； Resource Manager (RM)：控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚； seata的简单使用​ 本文主要基于springcloud + Eureka + mysql + seata的结构搭建一个分布式系统的demo。具体步骤如下： 下载Eureka的demo https://github.com/seata/seata-samples/tree/master/springcloud-eureka-seata 下载seata-server 0.8.0 https://github.com/seata/seata/releases 创建数据库fescar，并用Navicat执行一个SQL文件创建相应测试用的表格和数据，内容如下：（这一步其实可以省略，demo中配置文件的数据库地址其实是有效的） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/* Navicat Premium Data Transfer Source Server : seata Source Server Type : MySQL Source Server Version : 50616 Source Host : 47.95.78.215:3306 Source Schema : fescar Target Server Type : MySQL Target Server Version : 50616 File Encoding : 65001 Date: 23/08/2019 11:22:20*/SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for account_tbl-- ----------------------------DROP TABLE IF EXISTS `account_tbl`;CREATE TABLE `account_tbl` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `money` int(11) NULL DEFAULT 0, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 214 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Records of account_tbl-- ----------------------------INSERT INTO `account_tbl` VALUES (213, &apos;U100000&apos;, 10000);-- ------------------------------ Table structure for order_tbl-- ----------------------------DROP TABLE IF EXISTS `order_tbl`;CREATE TABLE `order_tbl` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `commodity_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `count` int(11) NULL DEFAULT 0, `money` int(11) NULL DEFAULT 0, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 247 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Table structure for storage_tbl-- ----------------------------DROP TABLE IF EXISTS `storage_tbl`;CREATE TABLE `storage_tbl` ( `id` int(11) NOT NULL AUTO_INCREMENT, `commodity_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `count` int(11) NULL DEFAULT 0, PRIMARY KEY (`id`) USING BTREE, UNIQUE INDEX `commodity_code`(`commodity_code`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 1135 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Records of storage_tbl-- ----------------------------INSERT INTO `storage_tbl` VALUES (1134, &apos;C100000&apos;, 200);-- ------------------------------ Table structure for undo_log-- ----------------------------DROP TABLE IF EXISTS `undo_log`;CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `context` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime(0) NOT NULL, `log_modified` datetime(0) NOT NULL, `ext` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE, UNIQUE INDEX `ux_undo_log`(`xid`, `branch_id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 619 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;SET FOREIGN_KEY_CHECKS = 1; 修改demo中配置文件中数据库的账号和密码（这一步其实也可以省略，理由同上） 修改seata-server中的配置文件registry.conf，将registry的方式type改为“euraka”。如果有需要，你可以在下面修改eureka的配置，指定相应的serviceUrl和application。 修改demo中所有服务resources文件夹下的registry.conf，将注册方式type改为“file”。 先运行demo中的eureka服务，然后在seata-server的bin文件下运行命令seata-server.bat -h 127.0.0.1 -p 8091 -m file启动seata-server，然后再运行demo中的其他服务。若无明显错误信息，则启动成功。 测试demo的分布式事务功能，主要的事务发起者是business-service，测试地址如下： 提交：http://localhost:8084/purchase/commit 回滚：http://localhost:8084/purchase/rollback 修改后的源码下载地址：https://github.com/GD-CKING/demo demo解析引入依赖​ 通过分析demo，如果要使用分布式事务架构Seata，在需要引入seata的服务中引入以下依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-seata&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt;&lt;/dependency&gt; ​ demo中除了eureka之外其他服务都引入了这些依赖。 配置文件​ seata的配置文件主要有两个：registry.conf和file.conf。其中registry.conf是seata的配置入口文件。在registry中可以指定具体配置的形式，默认使用file类型，在file.conf配置文件中有一下配置内容： transport​ transport部分的配置对用NettyServerConfig类，用于定义Netty相关的参数。TM、RM和seata-server之间使用Netty进行通信。 service​ service中主要要注意service.vgroup_mapping这个配置，service.vgroup_mapping后面跟的内容要跟在配置文件中的spring.cloud.alibaba.seata.tx-service-group设置的属性一致，否则会提示no available server to connect.这个属性主要是为了定义一个tx-server-group名称 ，这个名称就是file.conf中的service.vgroup_mapping.${spring.cloud.alibaba.seata.tx-service-group}。 ​ 而file.conf中vgroup_mapping.my_test_tx_group = &quot;default&quot;指定seata-server的地址是下面default.grouplist设定的地址： 12345678910service &#123; #vgroup-&gt;rgroup #配置Client连接TC的地址 vgroup_mapping.my_test_tx_group = "default" default.grouplist = "127.0.0.1:8091" #degrade current not support enableDegrade = false #disable 是否启用seata的分布式事务 disableGlobalTransaction = false &#125; client1234567client &#123; #RM接收TC的commit通知后缓冲上限 async.commit.buffer.limit = 10000 lock &#123; retry.internal = 10 retry.times = 30 &#125; &#125; 表undo-log​ 要使用seata必须创建一个undo-log表。undo_log 是需要在业务库上创建的一个表，seata 依赖该表记录每笔分支事务的状态及二阶段 rollback 的回放数据。不用担心该表的数据量过大形成单点问题，在全局事务 commit 的场景下事务对应的 undo_log 会异步删除。 123456789101112CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, `ext` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 使用@GlobalTransactional开启事务​ 是开启分布式事务非常简单，只需要在要开启事务的业务方式上加上@GlobalTransactional注解开启事务即可。Seata 会将事务的 xid 通过拦截器添加到调用其他服务的请求中，实现分布式事务 TM处理流程​ 在本例中，TM 的角色是 business-service, BusinessService 的 purchase 方法标注了 @GlobalTransactional 注解。 ​ 方法调用后将会创建一个全局事务，首先关注 @GlobalTransactional 注解的作用，在GlobalTransactionalInterceptor中被拦截处理。 ​ 全局事务创建后，就开始执行 business.execute()，即业务代码storageFeignClient.deduct(commodityCode, orderCount)进入 RM 处理流程，此处的业务逻辑为调用 storage-service 的扣减库存接口。 RM处理流程 获取business-service传来的XID 绑定XID到当前上下文中 执行业务逻辑sql 向TC创建本次RM的Netty连接 向TC发送分支事务的相关信息 获得TC返回的branchId 记录Undo Log数据 向TC发送本次事务PhaseOne阶段的处理结果 从当前上下文中解绑XID 事务提交​ 各分支事务执行完成后，TC 对各 RM 的汇报结果进行汇总，给各 RM 发送 commit 或 rollback 的指令。 ​ 对于commit动作的处理，RM只需删除xid、branchId对应的undo_log即可。 事务回滚​ 对于rollback场景的触发有两种情况 分支事务处理异常，即ConnectionProxy中report(false)的情况。 TM捕获到下游系统上抛的异常，即发起全局事务标有@GlobalTransactional注解的方法捕获到的异常。在前面TransactionalTemplate类的execute模版方法中，对business.execute()的调用进行了catch，catch后会调用rollback，由TM通知TC对应XID需要回滚事务。 参考资料https://zhuanlan.zhihu.com/p/63381854]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的主从复制架构]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F22%2FRedis%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[本节思维导图 Redis主从架构​ 单机的Redis，能够承载的QPS大概在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构设计成主从（master-slave）架构，一主多从，主负责写，并且将数据复制到其他的slave节点，从节点复制读。所有的读请求全部走从节点。这样也可以轻松实现水平扩容，支撑读高并发。 ​ redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发 redis replication的核心机制 redis采用异步方式复制数据到slave节点，不过redis2.8开始，slave node会周期性地确认自己每次复制的数据量 一个master node是可以配置多个slave node的 slave node也可以连接其他的slave node slave node做复制的时候，不会block master node的正常工作 slave node做复制的时候，也不会block对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候会暂停对外服务了 slave node主要用来进行横向扩容，做读写分离，扩容的slave node可以提高读的吞吐量 ​ 如果采用了主从架构，那么建议必须开启master nod的持久化，不建议用slave node作为master node的数据热备，因为那样的话，你关掉了master的持久化，可能在master宕机重启的时候数据是空的，然后可能一经过复制，slave node的数据也丢了。 ​ 另外，master的各种备份方案 也需要做。如果本地的所有文件丢弃，从备份中挑选一份rdb去恢复master，这样才能确保启动的时候，是有数据的。即使采用了高可用机制，slave node可以自动接管master node，但也可能哨兵（sentinel）还没检测到masterfailure，master node自动重启了，还是可能导致上面的slave node数据被清空。 redis主从复制的核心原理​ 当启动一个slave node的时候，它会发送一个PSYNC命令给master node。 ​ 如果是slave node初次连接到master node，那么会触发一次full resynchronization全量复制。此时master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端新收到的所有命令缓存在内存中。RDB文件生产完毕后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着master会将内存中缓存的命令发送给slave，slave也会同步这些数据。slave node如果跟master node有网络故障，断开了连接，会自动重连，连接之后master node仅会复制给slave部分缺失的数据。 主从复制的断点续传​ 从redis2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么就可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。 ​ master node会在内存中维护一个backlog，master和slave都会保存一个replica offset，还有一个master run id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制，如果没有找到对应的offset，就会执行一次resynchronization。 ​ 使用master run id，是为了定位到上次传输数据的master。如果是根据host + ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分。 无磁盘化复制​ master在内存中直接创建RDB，然后发送给slave，不会在本地落地磁盘。要想开启这个功能，只需要在配置文件中国开启repl-diskless-syc yes即可。 1234repl-diskless-sync yes# 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来repl-diskless-sync-delay 5 过期key处理​ slave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。 复制的完整流程​ slave node启动时，会在自己本地保存master node的信息，包括master node的host和ip，但是复制流程没开始。 ​ slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接。然后master node发送ping命令给master node。如果master设置了requirepass，那么slave node必须发送masterauth的口令过去进行认证。master node第一次执行全量复制，将所有数据发送给slave node，而在后续，master node持续将写命令，异步复制给slave node。 数据同步相关的核心机制​ 数据同步相关的核心机制指的就是第一次slave连接master的时候，执行的全量复制，这个过程里面的一些细节的机制。 master和slave都会维护一个offset​ master会在自身不断累加offset，slave也会在自身不断累加offset。slave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset。 ​ 这个不是特定就用在全量复制的，主要是master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况。 backlog​ master node有一个backlog，默认是1MB大小。master node在给slave node复制数据时，也会将数据在backlog中同步写一份。backlog主要是用来做全量复制中断开后的增量复制的。 master run id​ info server可以看到master run id。 ​ 上面说过，根据host+ip定位master node是不靠谱的，如果master node重启或者数据发生了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制。如果需要不更改run id重启redis，可以使用redis-cli debug reload命令。 psync​ 从节点使用psync从master node进行复制，psync runid offset ​ master node会根据自身的情况返回相应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制。 全量复制 master执行bgsave，在本地生成一份RDB快照文件 master node将RDB快照文件发送给slave node，如果RDB复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调大这个参数。 master node在生成RDB时，会将所有新的写命令缓存在内存中，在slave node保存了RDB之后，再将新的写命令复制给slave node 如果在复制期间，内存缓冲区持续消耗超过64MB，会在一次性超过256MB，那么停止复制，复制失败。 1client-output-buffer-limit slave 256MB 64MB 60 slave node接收到RDB之后，清空自己的旧数据，然后重新加载RDB到自己内存中，同时基于旧的数据版本对外提供服务。 如果slave node开启了AOF，那么会立即执行BGREWAITEAOF，重写AOF 增量复制 如果全量复制过程中，master-slave网络连接断掉了，那么slave重新连接master时，会触发增量复制 master会直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB master就是根据slave发送的psync中的offset来从backlog中获取数据的。 heartbeat​ 主从节点互相都会发送heartbeat信息 ​ master默认每隔10秒发送一次heartbeat，slave node每隔1秒发送一个heartbeat。 异步复制​ master每次接收到写命令之后，现在内部写入数据，然后异步发送给slave node redis如何才能做到高可用​ 一个slave故障了，并不会影响可用性，还有其他的slave在提供服务。但master node死掉了，会导致无法写数据。没有master可以写数据，slave也就没用了，系统就不可用了。 ​ redis的高可用架构，叫做failover故障转移，也可以叫做主备切换。 ​ master node在故障时，自动检测，并且将某个slave node自动切换为master node的过程，叫做主备切换。这个过程就实现了redis的主从架构下的高可用。 主从复制的配置​ 讲了那么多，我们来看看如何配置，从而实现主从架构。 ​ 首先先配置从节点: 打开从节点的配置文件，搜索replicaof （低版本的有些是slaveof），去配置从节点要连接的主节点。如replicaof 192.168.1.1 6379，其中192.168.1.1是我们主节点的IP地址。 在配置文件中搜索replica-read-only（低版本的有些是slave-read-only），将该属性配置为也是：replica-read-only yes，这样就开启了只读redis从节点，它会拒绝所有的写操作，这样可以强制搭建读写分离的架构，从而实现读写分离。 在配置文件中搜索masterauth，来配置主节点redis的连接口令。如masterauth redis-pass，其中redis-pass就是主节点的认证口令。 在配置文件中搜索bind，将bind 127.0.0.1改成bind 自己的IP地址。bind 127.0.0.1是本地的开发调式的模式，就只有127.0.0.1本地才能访问到6379的端口。 强制开启6379端口iptables -A INPUT -ptcp --dport 6379 -j ACCEPT。（这一步有时可以省略） ​ 配置主节点： 打开主节点的配置文件，搜索requirepass，配置主节点的认证口令，使其与从节点配置的masterauth保持一致。 在配置文件中搜索bind，将bind 127.0.0.1改成bind 自己的IP地址。 强制开启6379端口iptables -A INPUT -ptcp --dport 6379 -j ACCEPT。（这一步有时可以省略） ​ 这样主从架构就配置好了，我们测试一下，先启动主节点，再启动从节点。进入主节点的redis中，执行info replication查看相关信息 ​ 同样的，进入从节点的redis，执行info replication查看相关信息]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的线程模型及和mencached的区别]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F20%2FRedis%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%92%8Cmencached%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[本节思维导图 Redis和Memcached的区别Redis支持复杂的数据结构​ redis相比于memcached来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作，redis相对来说比较好。 Redis原生支持集群模式​ redis 3.X便能支持cluster模式，而memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。 性能对比​ 由于redis只使用单核，而memcached可以使用多核，所以平均每一个核上redis存储小数据时比memcached性能更高。而在100K以上的数据中，memcached性能要高于redis。 Redis的线程模型​ redis内部使用文件事件处理器file event handler，这个文件事件处理器是单线程的，所以redis才叫做单线程的模型。它采用IO多路复用机制同时监听多个socket，将产生事件的socket压入内存队列中，事件分派器根据socket上的事件类型来选择对应的事件处理器进行处理。 ​ 文件事件处理器的结构包含4个部分： 多个socket IO多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 客户端与redis的一次通信过程如下： 首先，redis服务端进程初始化的时候，会将server socket的AE_READABLE事件与连接应答处理器关联。 ​ 客户端socket01向redis进程的server socket请求建立连接，此时server socket会产生一个AE_READABLE事件，IO多路复用程序监听到server socket产生的事件后，将该socket压入队列中。文件事件分派器从队列中获取socket，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的socket01，并将该socket01的AE_READABLE事件与命令请求处理器关联。 ​ 假设客户端发送了一个set key value请求，此时redis中的socket01会产生AE_READABLE事件，IO多路复用程序将socket01压入队列，此时事件分派器从队列中获取到socket01产生的AE_READABLE事件，由于前面的socket01的AE_READABLE事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取socket01的key value并在自己内存中完成key value的设置，操作完成后，它会将socket01的AE_WRITABLE事件与命令回复处理器关联。 ​ 如果此时客户端准备好接受返回结果了，那么redis中的socket01会产生一个AE_WRITABLE事件，同样压入队列，事件分派器找到相关联的命令回复处理器，由命令回复处理器对socket01输入本次操作的一个结果，之后解除socket01的AE_WRITABLE事件与命令回复处理器的关联。 Redis单线程效率高的原因 纯内存操作 核心是基于非阻塞的IO多路复用机制 C语言实现，一般来说，C语言实现的程序更接近操作系统，执行速度相对会快 单线程反而避免了多线程的频繁上下文切换，预防了多线程可能产生的竞争问题]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zuul-实现灰度发布]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F20%2FZuul-%E5%AE%9E%E7%8E%B0%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[​ 一般情况下，我们要发布新版本了，在不确定正确性的情况下，我们会选择先部分节点升级，然后再让一些特定的流量进入到这些新节点，完成测试后再全量发布。这就是灰度发布。 ​ 在Eureka中注册多个服务后，如果一个服务有多个实例，那么默认会走ribbon的软负载均衡来进行分发请求。而要完成灰度发布，要做的就是修改ribbon的负载策略。在SpringCloud体系中，完成这件事，一般都是根据Eureka的metadata进行自定义元数据，然后修改Ribbon的规则。 ​ 我们可以用数据库来动态开启灰度发布和指定灰度发布的请求，当然你也可以用Apollo配置中心、Redis、ZooKeeper，其实都可以。先创建一个灰度发布启用表： 1234567CREATE TABLE `gray_release_config` ( `id` int(11) NOT NULL AUTO_INCREMENT, `service_id` varchar(255) DEFAULT NULL, `path` varchar(255) DEFAULT NULL, `enable_gray_release` int(11) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ​ 其中“enable_gray_release”表示是否启用灰度发布，默认数字0是不启动，1启动。然后插入一条数据，方便我们测试： 1INSERT INTO gray_release_config VALUES(1, 'order-service', '/order', 0) ​ 首先，我们需要在Zuul项目里添加依赖： 12345&lt;dependency&gt; &lt;groupId&gt;io.jmnarloch&lt;/groupId&gt; &lt;artifactId&gt;ribbon-discovery-filter-spring-cloud-starter&lt;/artifactId&gt; version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; ​ 接着在网关中新建给表的实体类： 1234567891011121314151617181920212223242526272829303132333435package com.zhss.demo.zuul.gateway;public class GrayReleaseConfig &#123; private int id; private String serviceId; private String path; private int enableGrayRelease; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getServiceId() &#123; return serviceId; &#125; public void setServiceId(String serviceId) &#123; this.serviceId = serviceId; &#125; public String getPath() &#123; return path; &#125; public void setPath(String path) &#123; this.path = path; &#125; public int getEnableGrayRelease() &#123; return enableGrayRelease; &#125; public void setEnableGrayRelease(int enableGrayRelease) &#123; this.enableGrayRelease = enableGrayRelease; &#125; &#125; ​ 然后我们可以编写一个定时器，定时获取灰度表的信息，看哪些服务需要灰度发布，新建类GrayReleaseConfigManager： 1234567891011121314151617181920212223242526272829303132333435363738394041package com.zhss.demo.zuul.gateway;import java.util.List;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.core.BeanPropertyRowMapper;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.scheduling.annotation.EnableScheduling;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component;@Component@Configuration @EnableScheduling public class GrayReleaseConfigManager &#123; private Map&lt;String, GrayReleaseConfig&gt; grayReleaseConfigs = new ConcurrentHashMap&lt;String, GrayReleaseConfig&gt;(); @Autowired private JdbcTemplate jdbcTemplate; @Scheduled(fixedRate = 1000) private void refreshRoute() &#123; List&lt;GrayReleaseConfig&gt; results = jdbcTemplate.query( "select * from gray_release_config", new BeanPropertyRowMapper&lt;&gt;(GrayReleaseConfig.class)); for(GrayReleaseConfig grayReleaseConfig : results) &#123; grayReleaseConfigs.put(grayReleaseConfig.getPath(), grayReleaseConfig); &#125; &#125; public Map&lt;String, GrayReleaseConfig&gt; getGrayReleaseConfigs() &#123; return grayReleaseConfigs; &#125;&#125; ​ 然后再编写一个Zuul的过滤器，实现灰度发布的逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100package com.zhss.demo.zuul.gateway;import org.springframework.context.annotation.Configuration;import com.netflix.zuul.ZuulFilter;import com.netflix.zuul.context.RequestContext;import io.jmnarloch.spring.cloud.ribbon.support.RibbonFilterContextHolder;import static org.springframework.cloud.netflix.zuul.filters.support.FilterConstants.*;import java.util.Map;import java.util.Random;import javax.annotation.Resource;import javax.servlet.http.HttpServletRequest;@SuppressWarnings("unused")@Configurationpublic class GrayReleaseFilter extends ZuulFilter &#123; @Resource private GrayReleaseConfigManager grayReleaseConfigManager; /** * 过滤的优先级，数字越大，级别越低 * @return */ @Override public int filterOrder() &#123; return PRE_DECORATION_FILTER_ORDER - 1; &#125; @Override public String filterType() &#123; return PRE_TYPE; &#125; /** * 是否执行该过滤器 * @return */ @Override public boolean shouldFilter() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); String requestURI = request.getRequestURI(); // http://localhost:9000/order/order?xxxx Map&lt;String, GrayReleaseConfig&gt; grayReleaseConfigs = grayReleaseConfigManager.getGrayReleaseConfigs(); for(String path : grayReleaseConfigs.keySet()) &#123; if(requestURI.contains(path)) &#123; GrayReleaseConfig grayReleaseConfig = grayReleaseConfigs.get(path); if(grayReleaseConfig.getEnableGrayRelease() == 1) &#123; System.out.println("启用灰度发布功能"); return true; &#125; &#125; &#125; System.out.println("不启用灰度发布功能"); return false; &#125; /** * 过滤器的具体逻辑 * @return */ @Override public Object run() &#123;// RequestContext ctx = RequestContext.getCurrentContext();// HttpServletRequest request = ctx.getRequest();// String gray = request.getParameter("gray");//// if("true".equals(gray)) &#123;// RibbonFilterContextHolder.getCurrentContext().add("version", "new");// &#125; else &#123;// RibbonFilterContextHolder.getCurrentContext().add("version", "current");// &#125; Random random = new Random(); int seed = random.nextInt(100); if (seed == 50) &#123; // put the serviceId in `RequestContext` RibbonFilterContextHolder.getCurrentContext() .add("version", "new"); &#125; else &#123; RibbonFilterContextHolder.getCurrentContext() .add("version", "old"); &#125; return null; &#125;&#125; ​ 上面的代码主要还是看run()方法的实现。注释掉的代码是通过判断请求连接中是否包含“gray”参数，如果包含gray参数并且它的值为“true”，则将流量引到新的节点。而没有注释的代码则是根据随机数seed的值来引流。当你希望有10%的流量引到新节点时，可以将if(seed == 50)改成 seed &gt;= 90或者其他。 ​ 最后，就是在要升级的服务配置上增加metadata的自定义数据即可，根据上述的代码，我们应该在要升级的服务的配置文件中增加：eureka: instance: metadata-map: version: new。在没升级的服务的配置文件中增加：eureka: instance: metadata-map: version: old ​ 这样，基于Zuul的灰度发布功能就实现了。当然，基于灰度发布这块，国内有了更强大的开源框架Nepxion Discovery。Nepxion Discovery是一款对Spring Cloud Discovery服务注册发现、Ribbon负载均衡、Feign和RestTemplate调用的增强中间件，感兴趣的朋友可以去官方的github上查看：https://github.com/Nepxion/Discovery]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis分布式锁的实现原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F20%2FRedis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 目前基于Redis实现的分布式锁常用的框架是Redisson,它的使用比较简单，在项目中引入Redisson的依赖，然后基于Redis实现分布式锁的加锁与释放锁，如下所示： ​ 接下来我们就说一下Redisson这个框架对于Redis分布式锁的实现原理。 Redis分布式锁的底层原理​ Redisson这个框架对Redis分布式锁的实现原理图如下： 加锁机制​ 某个客户端要加锁。如果该客户端面对的是一个Redis Cluster集群，它首先会根据hash节点选择一台机器，这里注意，仅仅只是选择一台机器。紧接着就会发送一段lua脚本到redis上，lua脚本如下所示： ​ 使用lua脚本，可以把一大堆业务逻辑通过封装在lua脚本发送给redis，保证这段赋值业务逻辑执行的原子性。在这段脚本中，这里KEYS[1]代表的是你加锁的那个key，比如说：RLock lock = redisson.getLock(“myLock”);这里你自己设置了加锁的那个锁key就是“myLock”。 ​ ARGV[1]代表的就是锁key的默认生存时间，默认30秒。ARGV[2]代表的是加锁的客户端的ID，类似于下面这样：8743c9c0-0795-4907-87fd-6c719a6b4586:1。 ​ 脚本的意思大概是：第一段if判断语句，就是用“exists myLock”命令判断一下，如果你要加锁的那个key不存在，就可以进行加锁。加锁就是用“hset myLock 8743c9c0-0795-4907-87fd-6c719a6b4586:1 1”命令。通过这个命令设置一个hash数据结构，这个命令执行后，会出现一个类似下面的数据结构： ​ 上述就代表“8743c9c0-0795-4907-87fd-6c719a6b4586:1”这个客户端对“myLock”这个锁key完成了加锁。接着会执行“pexpire myLock 30000”命令，设置myLock这个锁key的生存时间是30秒。好了，到此为止，ok，加锁完成了。 锁互斥机制​ 如果这个时候客户端B来尝试加锁，执行了同样的一段lua脚本。第一个if判断会执行“exists myLock”，发现myLock这个锁key已经存在。接着第二个if判断，判断myLock锁key的hash数据结构中，是否包含客户端B的ID，但明显没有，那么客户端B会获取到pttl myLock返回的一个数字，代表myLock这个锁key的剩余生存时间。此时客户端B会进入一个while循环，不听的尝试加锁。 watch dog自动延期机制​ 客户端A加锁的锁key默认生存时间只有30秒，如果超过了30秒，客户端A还想一直持有这把锁，怎么办？其实只要客户端A一旦加锁成功，就会启动一个watch dog看门狗，它是一个后台线程，会每隔10秒检查一下，如果客户端A还持有锁key，那么就会不断的延长锁key的生存时间。 可重入加锁机制​ 客户端A已经持有锁了，然后可重入加锁，如下代码所示： ​ 这个时候lua脚本是这样执行的：第一个if判断不成立，“exists myLock”会显示锁key已经存在了。第二个if判断会成立，因为myLock的hash数据结构中包含的那个ID，就是客户端A的ID，此时就会执行可重入加锁的逻辑，它会用“incrby myLock 8743c9c0-0795-4907-87fd-6c71a6b4586:1 1 ”这个命令对客户端A的加锁次数，累加1，此时myLock的数据结构变成下面这样： ​ 即myLock的hash数据结构中的那个客户端ID，就对应着加锁的次数。 释放锁机制​ 执行lock.unlock()，就可以释放分布式锁。释放逻辑是：每次对myLock数据结构中的那个加锁次数减1，如果加锁次数为0了，说明客户端已经不再持有锁了，此时就会用“del MyLock”命令，从redis里删除了这个key。然后另外的客户端B就可以尝试完成加锁了。 上述Redis分布式锁的缺点​ 上面方案的最大问题，就是如果你对某个redis master实例，写入了myLock这种锁key的value，此时会异步复制给对应的master slave实例，但是这个过程中如果发送redis master宕机，主备切换，redis slave变为了redis master。 ​ 这就会导致客户端B来尝试加锁的时候，在新的redis master上完成了加锁，而客户端A也以为自己成功加了锁，此时就会导致多个客户端对一个分布式锁完成了加锁。这时就会导致各种脏数据的产生。 ​ 所以这个就是redis cluster，或者是redis master-slave架构的主从异步复制导致的redis分布式锁的最大缺陷：在redis master实例宕机的时候，可能导致多个客户端同时完成加锁。]]></content>
      <categories>
        <category>分布式</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper分布式锁的实现原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F19%2FZooKeeper%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[ZooKeeper分布式锁机制​ 本文将基于常用的ZooKeeper分布锁实现框架–Curator，说一下这个框架对ZooKeeper分布式锁的实现。 ​ 首先模拟一下两个客户端一起争抢ZK上的一把分布式锁的场景： ​ ZK里有一把锁，这个锁就是ZK上的一个节点。然后两个客户端都要来获取这个锁。假设客户端A抢先一步，对ZK发起了加分布式锁的请求，这个加锁请求是用到了ZK的“临时顺序节点”。简答来说就是直接在“my_lock”这个锁节点下，创建一个顺序节点，这个节点有ZK内部自行维护的一个节点序号。 ​ 例如第一个客户端来搞一个顺序节点，ZK内部会起个名字叫xxx-00001。然后第二个客户端搞一个顺序节点，ZK可能会起个名字叫xxx-00002。规律就是最后一个数字都是依次递增的，从1开始递增，ZK会维护这个顺序。 ​ 所以这个时候，假如客户端A先发起请求，就会搞出一个顺序节点，如图所示： ​ 客户端A发起一个加锁请求，先会在你要加锁的node下搞一个临时顺序节点，节点名字由Curator框架自己生成出来，但最后一个数字是“1”，因为客户端是第一个发起请求的。 ​ 客户端A常见完一个节点后，它会查一下“my_lock”这个锁节点下的所有子节点，并且这些子节点都是按照序号排序的，这个时候他大概会拿到一个集合： ​ 接着客户端A会走一个关键性的判断：我创建的那个顺序节点，是不是排在第一个？如果是的话，那我就可以加锁了。因为我是第一个创建顺序节点的人，所以我是第一个尝试加分布式锁的人。 ​ 客户端A加完锁了，客户端B过来想要加锁，这时它会先在“my_lock”这个锁节点下创建一个临时顺序节点，此时名字大概会是“xxx-00002” ​ 客户端B因为是第二个来创建顺序节点的，所以ZK内部会维护序号为“2”。接着客户端B会走加锁判断逻辑，查询“my_lock”锁节点下的所有子节点，按照顺序排列，类似于： ​ 同时检查自己创建的顺序节点，是不是集合中的第一个？如果不是，那就加锁失败。失败之后，客户端B就会通过ZK的API对他的顺序节点的上一个顺序节点加一个监听器 ​ 接着，客户端A加锁之后，逻辑处理完后就会释放锁，释放锁实际就是把ZK里创建的顺序节点“xxx-00001”给删除掉。删除了节点之后，ZK会负责通知监听这个节点的监听器，也就是客户端B的监听器说锁释放了。 ​ 此时客户端B的监听器感知到了上一个顺序节点被删除，也就是排在他之前的某个客户单释放了锁，此时客户端B重新尝试去获取锁，也就是获取“my_lock”节点下的子节点集合： ​ 然后客户端B判断自己是否是集合中的第一个顺序节点，如果是，直接完成加锁，运行完业务代码后，再次释放锁。 总结​ 总结一下多个客户端争抢一个ZK分布式锁的原理： 客户端上来直接创建一个锁节点下的一个接一个的临时顺序节点 如果自己不是第一个节点，就对自己上一个节点加监听器 只要上一个节点释放锁，自己就排到前面去，相当于一个排队机制。 ​ 而且用临时加节点的另一个好处就是，如果某个客户端创建临时顺序节点之后，自己宕机了也没关系，ZK感知到那个客户端宕机，会自动删除对应的临时顺序节点，相当于自动释放锁。 ​ 最后看一下用Curator框架进行加锁和释放锁的一个过程：]]></content>
      <categories>
        <category>分布式</category>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单了解ZooKeeper]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F19%2F%E7%AE%80%E5%8D%95%E4%BA%86%E8%A7%A3ZooKeeper%2F</url>
    <content type="text"><![CDATA[本节思维导图 ZooKeeper的数据结构​ ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗树，每个节点叫做ZNode，每一个节点可以通过路径来标识： ​ ZooKeeper的节点我们称之为ZNode，ZNode分为两种类型： 短暂/临时：当客户端和服务端断开连接后，所创建的ZNode（节点）会自动删除 持久：当客户端和服务端断开连接后，所创建的ZNode不会删除 ​ 这些节点由可以分成另外两种类型： 普通节点 带顺序号节点 监听器​ ZooKeeper之所以能实现那么多功能，最主要还是配合了监听器。 ​ 常见的监听器有以下两个功能： 监听ZNode节点的数据变化 监听子节点的增减变化 ​ 通过监听+ZNode节点，Zookeeper就可以实现比较多的功能了 ZooKeeper的作用统一配置管理​ 比如现在有三个系统A、B、C，他们有三份配置ASystem.yml、BSystem.yml、CSystem.yml，然后，这三份配置又非常类似，很多配置项几乎一样。此时如果我们要改变其中一份配置项的信息，很可能另外两份都要改，并且改了配置项的系统很能就要重启系统。 ​ 于是我们希望把ASystem.yml、BSystem.yml、CSystem.yml相同的配置项抽取出来成一份公用的配置common.yml，并且即使common.yml改了，也不需要系统A、B、C重启。 ​ 解决方案是我们可以把common.yml这份配置放在ZooKeeper的ZNode节点中，系统A B C监听这个节点有无变更，变更了就及时响应。 ​ 具体实现可以大佬写的 基于zookeeper实现统一配置管理 统一命名服务​ 统一命名服务的理解其实跟域名一样，是我们为这某一部分的资源给它取另一个名字，别人通过这个名字就可以拿到对应的资源。 ​ 例如我们有一个域名叫www.test.com。但这个域名下有多台机器： 192.168.1.1 192.168.1.2 192.168.1.3 192.168.1.4 别人访问www.test.com即可访问到我的机器，而不是通过IP去访问。 分布式锁​ 详情请参考这篇 ZooKeeper的分布式锁的实现原理 集群管理​ 还是以三个系统A B C为例，在ZooKeeper中创建临时节点即可， ​ 只要系统A挂了，那么/groupMember/A这个节点就会删除，通过监听groupMember下的子节点，系统B和C就能感知到系统A挂了，新增也是同理。 ​ 除了能感知节点的上下线变化，Zookeeper还可以实现动态选举Master的功能（如果集群是主从结构模式下）。原理也很简单，如果想要实现这个功能，只要ZNode节点的类型是带顺序号的临时节点就好了。ZooKeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的ZNode节点就会删除，然后让新的最小编号作为Master，这样就可以实现动态选举的功能。]]></content>
      <categories>
        <category>分布式</category>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务方案]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F16%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[本节思维导图 目前分布式事务的实现方案主要有以下5种： XA方案 TCC方案 本地消息表 可靠消息最终一致性方案 最大努力通知方案 两阶段提交方案/XA方案​ 所谓的XA方案，就是两阶段提交。有一个事务管理器的概念，负责协调多个数据库（资源管理器）的事务，事务管理器先询问各个数据库是否准备好了，如果数据库都准备好了，就正式提交事务，在各个数据库上执行。如果任何其中一个数据库回答不OK，那么就回滚事务。 ​ 这种分布式方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复制的事务，效率很低。绝对不适合高并发的场景。如果要实现，可以基于Spring+JTA就可以实现。 ​ 这个方案，一般很少用。一般来说某个系统内部如果出现跨多个库的操作，是不合规的。即便是现在的微服务，一个大的系统分成十几个甚至几百个服务。一般来说，都是要求每个服务只能操作自己对应的一个数据库。如果要操作别的服务对应的库，不允许直接连接，违反微服务架构的规范，你随便交叉胡乱访问，几百个服务的话，全体乱套，这样的一套服务是没法管理的，没法治理的，可能会出现数据被别人改错，自己的库被别人写挂等情况。 如果你要操作别人的服务的库，你必须是通过调用别的服务的接口来实现，绝对不允许交叉访问别人的数据库。 TCC方案​ tcc全称是：try、confirm、cancel Try阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预定。 Confirm：这个阶段说的是在各个服务中执行实际的操作。 Cancel：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）。 ​ 这种方案也用的比较少，但是也有使用的场景。因为这个事务回滚实际上是严重依赖于自己写的代码来回滚和补偿的，会造成补偿代码巨大。一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，会使用TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性。而且最好是你的各个业务执行的时间都比较短。但是一般情况下尽量不要使用TCC方案，自己手写回滚逻辑或者是补偿代码，都是很恶心的，业务代码很难维护。 本地消息表 本地消息表的大概意思如下： A系统在自己本地一个事务里操作同时，插入一条数据到消息表； 接着A系统将这个消息发送到MQ中去； B系统接收到消息之后，在一个事务里，往自己本地消息表插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过，那么此时这个事务会回滚，这样保证不会重复处理消息； B系统执行成功之后，就会更新自己本地信息表的状态以及A系统信息表的状态； 如果B系统处理失败，那么就不会更新信息表状态，那么此时A系统会定时扫描自己的消息表，如果有未处理的消息，则会发送到MQ中去，让B再次处理； 这个方案保证了最终一致性，哪怕B事务失败了，但是A会不断重发信息一致到B那边成功为止。 这个方案最大的问题是就是严重依赖于数据库的消息表来管理事务，如果是高并发场景，很难扩展，所以一般比较少用。 可靠消息最终一致性方案​ 这个的意思，就是干脆不用本地消息表了，直接基于MQ来实现事务，比如阿里的RocketMQ就支持消息事务，大概的思路如下： A系统先发送一个prepared消息到mq，如果这个prepared消息发送失败那么就直接取消操作别执行了； 如果这个消息发送成功了，那么接着执行本地事务，如果成功就告诉MQ发送确认信息，如果失败就告诉mq回滚消息； 如果发送了确认消息，那么此时B系统会接收到确认信息，然后执行本地事务； MQ会自动定时轮询所有prepared消息回调你的接口，问你这个消息是不是本地事务处理失败了，所有没发送确认消息的信息，是继续重试还是回滚？一般来说这里你就可以查下数据库之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。 这个方案里，要是系统B的事务失败了，那就重试，自动不断地重试直到成功，如果实在不行，那就针对重要的资金业务进行回滚，比如B系统本地回滚后，想办法通知系统A也回滚，或者是发送警报由人工来手工回滚和补偿 ​ 这个方案还是比较合适的，目前国内的互联网公司大部分都是这样设计。你可以使用RocketMQ，也可以使用其他消息队列封装一套类似的逻辑出来。 最大努力通知方案​ 这个方案的大概思路就是： 系统A本地事务执行完之后，发送个消息到MQ； 这里会有个专门消费MQ的最大努力通知服务，这个服务会消费MQ然后写入数据中记录下来，或者是放入个内存队列里，接着调用系统B的接口； 要是系统B执行成功就OK了，要是系统B执行失败了，那么最大努力同时服务就定时尝试重新调用系统B，反复N次，最后还是不行就放弃。 总结​ 基本上，一些特别严格的场景，用的是TCC来保证强一致性，例如严格要求资金绝对不能错的场景；其他的一些场景基于阿里的RocketMQ来实现分布式事务，例如一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么敏感，可以用可靠消息最终一致性方案。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设计一个能抗住上万服务实例的注册中心]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F15%2F%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E8%83%BD%E6%8A%97%E4%BD%8F%E4%B8%8A%E4%B8%87%E6%9C%8D%E5%8A%A1%E5%AE%9E%E4%BE%8B%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[​ 之前说过ZooKeeper和Eureka由于自己的特性，都不太适合支撑大规模的服务实例。Eureka是peer-to-peer模式，每台机器都是高并发请求的话会有瓶颈。而ZooKeeper是每次服务上下线，就会全量通知其他服务，导致网络宽带被打满，这也是一个瓶颈。具体可以查看服务注册中心的选型调研这篇文章。那么怎样才能实现一个能抗住上万服务实例的注册中心呢？ ​ 目前大公司的服务注册中心为了能支撑大规模的服务实例，基本都是自研服务注册中心。基本的思路就是实现一个分布式服务注册中心。主要设计逻辑包括：分片存储服务注册表、支持横向扩容、每台机器均摊高并发请求、各个服务主动拉取注册表信息，避免方向通知网卡被打爆等等。 ​ 简单的原理图如下所示：]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zuul-实现动态路由]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F13%2FZuul-%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1%2F</url>
    <content type="text"><![CDATA[​ 一般情况下，Zuul需要在配置文件里写好路由信息，这样zuul才可以通过这些路由信息根据连接转发到相应的服务上去。但每增加一个服务，就需要停下网关去重新编写配置文件，这样就比较麻烦了。因此，就有人提出了动态路由的方法。 ​ 动态路由有很多方式实现，这里主要讲一下用数据库去实现动态路由。 ​ 首先，先创建一个表，用于存储路由信息： 1234567891011CREATE TABLE `gateway_api_route` ( `id` varchar(50) NOT NULL, `path` varchar(255) NOT NULL, `service_id` varchar(50) DEFAULT NULL, `url` varchar(255) DEFAULT NULL, `retryable` tinyint(1) DEFAULT NULL, `enabled` tinyint(1) NOT NULL, `strip_prefix` int(11) DEFAULT NULL, `api_name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ​ 该表结构主要是按照Zuul的ZuulProperties.ZuulRoute类设计的： ​ 插入一条数据，方便测试： 1INSERT INTO gateway_api_route (id, path, service_id, retryable, strip_prefix, url, enabled) VALUES ('order-service', '/order/**', 'order-service',0,1, NULL, 1); ​ 然后编写表gateway_api_route相应的实体类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class GatewayApiRoute &#123; private String id; private String path; private String serviceId; private String url; private boolean stripPrefix = true; private Boolean retryable; private Boolean enabled; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getPath() &#123; return path; &#125; public void setPath(String path) &#123; this.path = path; &#125; public String getServiceId() &#123; return serviceId; &#125; public void setServiceId(String serviceId) &#123; this.serviceId = serviceId; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public boolean isStripPrefix() &#123; return stripPrefix; &#125; public void setStripPrefix(boolean stripPrefix) &#123; this.stripPrefix = stripPrefix; &#125; public Boolean getRetryable() &#123; return retryable; &#125; public void setRetryable(Boolean retryable) &#123; this.retryable = retryable; &#125; public Boolean getEnabled() &#123; return enabled; &#125; public void setEnabled(Boolean enabled) &#123; this.enabled = enabled; &#125; &#125; ​ 接下来就开始编写动态路由的实现逻辑，其实基本逻辑就是从数据库里取出路由数据，然后封装成ZuulProperties.ZuulRoute。主要代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.zhss.demo.zuul.gateway;import org.springframework.beans.BeanUtils;import org.springframework.cloud.netflix.zuul.filters.RefreshableRouteLocator;import org.springframework.cloud.netflix.zuul.filters.SimpleRouteLocator;import org.springframework.cloud.netflix.zuul.filters.ZuulProperties;import org.springframework.jdbc.core.BeanPropertyRowMapper;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.util.StringUtils; import java.util.LinkedHashMap;import java.util.List;import java.util.Map;public class DynamicRouteLocator extends SimpleRouteLocator implements RefreshableRouteLocator &#123; private JdbcTemplate jdbcTemplate; private ZuulProperties properties; public void setJdbcTemplate(JdbcTemplate jdbcTemplate) &#123; this.jdbcTemplate = jdbcTemplate; &#125; public DynamicRouteLocator(String servletPath, ZuulProperties properties) &#123; super(servletPath, properties); this.properties = properties; &#125; @Override public void refresh() &#123; doRefresh(); &#125; @Override protected Map&lt;String, ZuulProperties.ZuulRoute&gt; locateRoutes() &#123; LinkedHashMap&lt;String, ZuulProperties.ZuulRoute&gt; routesMap = new LinkedHashMap&lt;String, ZuulProperties.ZuulRoute&gt;(); // 加载application.yml中的路由表 routesMap.putAll(super.locateRoutes()); // 加载db中的路由表 routesMap.putAll(locateRoutesFromDB()); // 统一处理一下路由path的格式 LinkedHashMap&lt;String, ZuulProperties.ZuulRoute&gt; values = new LinkedHashMap&lt;&gt;(); for (Map.Entry&lt;String, ZuulProperties.ZuulRoute&gt; entry : routesMap.entrySet()) &#123; String path = entry.getKey(); if (!path.startsWith("/")) &#123; path = "/" + path; &#125; if (StringUtils.hasText(this.properties.getPrefix())) &#123; path = this.properties.getPrefix() + path; if (!path.startsWith("/")) &#123; path = "/" + path; &#125; &#125; values.put(path, entry.getValue()); &#125; System.out.println("路由表：" + values); return values; &#125; private Map&lt;String, ZuulProperties.ZuulRoute&gt; locateRoutesFromDB() &#123; Map&lt;String, ZuulProperties.ZuulRoute&gt; routes = new LinkedHashMap&lt;&gt;(); List&lt;GatewayApiRoute&gt; results = jdbcTemplate.query( "select * from gateway_api_route where enabled = true ", new BeanPropertyRowMapper&lt;&gt;(GatewayApiRoute.class)); for (GatewayApiRoute result : results) &#123; if (StringUtils.isEmpty(result.getPath()) ) &#123; continue; &#125; if (StringUtils.isEmpty(result.getServiceId()) &amp;&amp; StringUtils.isEmpty(result.getUrl())) &#123; continue; &#125; ZuulProperties.ZuulRoute zuulRoute = new ZuulProperties.ZuulRoute(); try &#123; BeanUtils.copyProperties(result, zuulRoute); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; routes.put(zuulRoute.getPath(), zuulRoute); &#125; return routes; &#125; &#125; 然后在新建一个配置类DynamicRouteConfiguration 12345678910111213141516171819202122232425262728package com.zhss.demo.zuul.gateway;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.web.ServerProperties;import org.springframework.cloud.netflix.zuul.filters.ZuulProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.core.JdbcTemplate; @Configurationpublic class DynamicRouteConfiguration &#123; @Autowired private ZuulProperties zuulProperties; @Autowired private ServerProperties server; @Autowired private JdbcTemplate jdbcTemplate; @Bean public DynamicRouteLocator routeLocator() &#123; DynamicRouteLocator routeLocator = new DynamicRouteLocator( this.server.getServletPrefix(), this.zuulProperties); routeLocator.setJdbcTemplate(jdbcTemplate); return routeLocator; &#125; &#125; 这样就差不多，最后再实现一个定时器，定时刷新路由信息： 1234567891011121314151617181920212223242526272829package com.zhss.demo.zuul.gateway;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.cloud.netflix.zuul.RoutesRefreshedEvent;import org.springframework.cloud.netflix.zuul.filters.RouteLocator;import org.springframework.context.ApplicationEventPublisher;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.EnableScheduling;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component;@Component@Configuration @EnableScheduling public class RefreshRouteTask &#123; @Autowired private ApplicationEventPublisher publisher; @Autowired private RouteLocator routeLocator; @Scheduled(fixedRate = 5000) private void refreshRoute() &#123; System.out.println("定时刷新路由表"); RoutesRefreshedEvent routesRefreshedEvent = new RoutesRefreshedEvent(routeLocator); publisher.publishEvent(routesRefreshedEvent); &#125; &#125; 这样一个基于zuul的动态路由功能就完成了，代码跑起来后，可以看到定时器在工作，定数刷新路由信息：]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eureka的一些参数配置优化]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F13%2FEureka%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ Eureka的默认配置是比较糟糕的，一般服务的上线和下线极端情况下需要一分多钟才能感知到，服务故障极端情况下需要两到三分钟才能感知到，这相对于ZooKeeper的秒级感知来说实在是太慢了。因此我们可以通过修改Eureka的一些配置参数来达到秒级通知的效果。 Eureka-Server端的配置eureka.server.responseCacheUpdateIntervalMs​ 这个参数表示的是Eureka中ReadWriteCacheMap的缓存数据多久会更新到ReadOnlyCacheMap中去，应为Eureka-Client是从ReadOnlyCacheMap拉取数据的。这个参数默认是30秒更新一次ReadOnlyCacheMap，我们可以改为3秒更新一次：eureka.server.response-cache-update-interval-ms = 3000 eureka.server.evictionIntervalTimerInMs​ 这个参数表示的是Eureka-Server中的缓存数据每隔多少秒主动失效。默认是60秒主动清空服务列表，我们可以改为6秒：eureka.server.eviction-interval-timer-in-ms = 6000 eureka.instance.leaseExpirationDurationInSeconds​ 服务过期时间配置，超过这个时间没有接收到心跳就会认为该服务实例已经挂了。并将该服务实例从注册表中剔除掉。默认情况下是90秒，我们可以设置为9秒：eureka.instance.lease-expiration-duration-in-seconds = 9 Eureka-Client端的配置eureka.client.registryFetchIntervalSeconds​ 这个参数表示的是Eureka-Client拉取数据，刷新本地缓存的时间，默认是每30秒拉取一次数据，我们可以将速度提高10倍，改为3秒：eureka.client.registry-fetch-interval-seconds = 3 eureka.instant.leaseRenewalIntervalInSeconds​ 这个参数表示的是Eureka-Client每隔多久发送一次心跳，默认是30秒发送一次心跳到Eureka-Server上。我们可以改成3秒：eureka.instant.lease-renewal-interval-in-seconds = 30]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务注册中心的选型调研]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F11%2F%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E7%9A%84%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 目前市场上使用最多的服务注册中心应该是Eureka和Zookeeper，当然Consul和Nacos，也在慢慢崛起。本文主要从集群模式、一致性保障、时效性和容量这几个角度来讨论Eureka和ZooKeeper的区别。 服务注册发现的集群模式Eureka​ Eureka的集群模式，简单地说就是peer-to-peer。部署一个集群，但是集群里每个机器的地位是对等的，各个服务可以向任何一个Eureka实例进行服务注册和发现，集群里的任何一个Eureka实例收到请求后，会自动同步给其他所有的Eureka实例。除了注册信息，服务发送的心跳信息也会同步到其他Eureka实例上。如图所示： ZooKeeper​ ZooKeeper的集群模式，简单就是Leader+Follower，其中只有Leader可以负责写，即服务注册，领完，它还负责把数据同步给Follow。服务发现的时候，Leader/Follow都可以读。 一致性保障：CP or AP​ CAP原则包含如下三个元素： C（Consistency）：一致性。在分布式系统中的所有数据备份，在同一时刻具有同样的值，所有节点在同一时刻读取的数据都是最新的数据副本。 A（Availability）：可用性。好的相应性能。完全的可用性指的是在任何故障模型下，服务都会在有限的时间内处理完成并进行相应。 P（Partition tolerance）：分区容错性。尽管网络上有部分消息丢失，但系统仍然可以继续工作。 CAP原理证明，任何分布式系统只可同时满足以上两点，无法三者兼顾。由于关系型数据库是单节点无复制的，因此不具有分区容忍性，但是具有一致性和可用性；而分布式的服务化系统都需要满足分区容忍性，那么我们必须在一致性和可用性之间进行权衡。 Eureka​ Eureka是AP模式的，即它牺牲了一致性，而实现可用性和分区容错性。因为Eureka是peer-to-peer模式，可能数据还没有同步互过去，自己就挂掉了，但服务实例依然可以从别的Eureka实例上拉去注册表，但是看到的数据就不是最新的收据了。但Eureka保证了最终一致性。例如服务A除了注册服务之外还会发送心跳信息，当服务A发现Eureka1实例挂掉之后，会向另一个活着的Eureka2实例发送心跳信息，Eureka2就能感知到服务A的存在并更新注册表的数据，从而实现最终一致性。 ZooKeeper​ ZooKeeper是CP模式的。ZooKeeper是有一个Leader节点会接收数据，然后同步其他节点，一旦Leader挂掉了，就要重新选举Leader，这个过程为了一致性，就会牺牲看可用性，会不可用一段时间，那么就可以继续写数据了，保证了一致性。即ZooKeeper是同步数据期间和Leader选举期间，都处于不可用阶段，等结束之后就可以继续使用，但这样却保证了强一致性。 服务注册发现的时效性​ ZooKeeper的时效性更好，注册或者是挂了，一般秒级就能感知到。 ​ Eureka，默认配置非常糟糕。服务发现感知要到几十秒，甚至分钟级别。上线一个新的服务，到其他服务可以发现它，极端情况下可能要一分钟的时间。（30秒ReadWriteCache更新ReadOnlyCacheMap数据，再30秒服务实例去拉取ReadOnlyCacheMap的数据）。 ​ 在默认情况下，服务故障，隔60秒才去检查心跳，发现这个服务上一次心跳是在30秒之前。在隔60秒去检查心跳，超过90秒没有心跳，才会认为这个服务已经挂了，这样子就已经过去两分钟了。 ​ 因此极端情况下，你的服务挂掉了，到其他服务感知到，可能需要两三分钟时间，比较漫长。 容量​ Eureka很难支撑大规模的服务实例，因为每个Eureka实例都要接受所有服务的注册请求信息和心跳信息，实例多了压力太大扛不住，很难做到几千服务实例。比如服务实例太多，达到上千个，每秒钟的有上千个心跳信息，那要同时同步到其余心跳信息。压力会比较大。 ​ ZooKeeper同样不适合大规模的服务实例，因为服务上线的时候，需要瞬间推送数据通知到所有的其他服务实例，所以一旦服务规模太大，到了几千个服务实例的时候，会导致网络带宽被大量占用。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>服务注册</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud常用组件原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F11%2FSpringCloud%E5%B8%B8%E7%94%A8%E7%BB%84%E4%BB%B6%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[​ Spring Cloud是一个全家桶式的技术栈，包含了很多组件。本文主要简单介绍下最核心的几个组件的底层原理。包括Eureka、Ribbon、Feign、Hystrix和Zuul这几个组件。 业务场景介绍​ 文章先假定一个业务场景：现在开发一个电商系统，要实现支付订单的功能，流程如下： 创建一个订单之后，如果用户立刻支付了这个订单，我们需要将订单状态更新为“已支付” 扣减相应的商品库存 通知仓储中心，进行发货 给用户的这次购物增加相应的积分 针对上述流程，我们需要有订单服务、库存服务、仓储服务、积分服务。整个流程的大体思路如下： 用户针对一个订单完成支付之后，就会去找订单服务，更新订单状态 订单服务调用库存服务，完成相应功能 订单服务调用仓储服务，完成相应功能 订单服务调用积分服务，完成相应功能 如图所示： SpringCloud核心组件：Eureka​ Eureka是微服务架构中的注册中心，主要功能是服务注册与发现和心跳检测与故障。在上述场景中，订单服务不知道其他其他服务在哪台机器上，此时就需要一个注册中心，来管理各个服务的地址，如图所示： ​ 如上图所示，所有服务都有一个Eureka Client组件，这个组件专门负责将这个服务的信息注册到Eureka Server中，也就相当于告诉了Eureka Server自己在哪台服务器上，监听这哪个端口。而Eureka中维护了一个注册表，保存着各个服务的机器和端口号。 ​ 新增服务、下线服务都是直接操作Eureka-Server的注册表的，而注册表变更时为了并发安全是会加锁操作的（使用ReentrantReadWriteLock）然后注册表一变更，立刻清楚掉ReadWrite缓存的数据，并重新写入新数据。服务从ReadOnlyCache上拉取服务 ，并缓存到本地。而Eureka-Server采用两个缓存，是为了避免并发冲突。 ​ 假设没有ReadOnlyCacheMap，万一刚好注册表发生变更的时候，ReadWriteCacheMap会被失效掉，所以客户端的请求也就直接来读注册表了，会涉及到锁的操作，弄了个ReadOnlyCacheMap可以大大减少锁操作发生的概率。 ​ 假设没有ReadWriteCacheMap，那么ReadOnlyCacheMap每隔30秒刷新的时候就只能跟注册表比较了，如果此时注册表也发生了变更，也会涉及到锁的操作，因为ReadWriteCacheMap的存在（因为ReadWriteCacheMap是每隔180秒才会主动失效一次）也可以大大减少这个锁操作发生的概率。 ​ 除了服务注册与发现之外，Eureka还有检测心跳的功能，以此来判断那台机器出现故障。Eureka-Client默认每30秒想Eureka发送一次心跳，而Eureka-Server会有专门的线程来检测心跳。 ​ 总结一下：Eureka拥有服务注册与发现、心跳检测与故障等功能。其中： Eureka-Client：负责将这个服务的信息注册到Eureka Server中 Eureka-Server：注册中心，里面有注册表和两个缓存，保存了各个服务所在的机器和端口。 SpringCloud核心组件：Feign​ 通过Eureka我们知道了各个服务在哪里，但如何向其他服务发起请求呢，这个就是Feign的作用。如下所示： 1234567@Component@FeignClient("tensquare-user")public interface UserClient &#123; @RequestMapping(value = "/user/incfollow/&#123;userid&#125;/&#123;x&#125;", method = RequestMethod.POST) public void incFollowcount(@PathVariable("userid")String userid, @PathVariable("x") int x);&#125; ​ 通过使用Feign，直接就是用注解定义一个FeignClient接口，然后调用那个接口就可以了，FeignClient会在底层根据你的注解，跟你指定的服务建立连接、构造请求、发起请求、获取响应、解析响应等等。 ​ 而Feign之所以能实现这些功能，关键的机制是使用了动态代理。我们根据下图来分析： 首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理 接着你要是调用按个接口，本质上就是调用Feign创建的动态代理，这是核心中的核心 Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的地址。 最后针对这个地址，发起请求，解析响应 SpringCloud核心组件：Ribbon​ 如果库存系统部署子在了五台机器上，Feign怎么知道该请求哪台机器呢。这时SpringCloud Ribbon就派上永用处了。它的作用是负载均衡，会帮你在每次请求时选择一台机器，均匀的把请求分发到各个机器上。 ​ Ribbon的负载均衡默认使用的是Round Robin轮询算法。就是说如果订单服务对库存系统发起10次请求，那就先让你请求第1台机器。然后是第2台、第3台，第4、第5，然后再来一个循环，第1、第2。。。以此类推。 ​ 此外，Ribbon和Feign以及Eureka紧密协作而完成工作的，具体如下： 首先Ribbon会从Eureka-Client获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口。 然后Ribbon就可以使用默认的Round Robin算法，从中选择一台。 Feign就会针对这台机器，构造并发起请求。 SpringCloud核心组件：Hystrix​ 在微服务架构里，一个系统会有很多的服务，以本文的业务场景为例：订单服务在一个业务流程里需要调用三个服务。现在假设订单服务有100个线程可以处理请求，然后积分服务不幸挂了，每次订单服务调用积分服务的时候，都会卡住几秒，然后抛出一个超时异常。这样会导致几个问题： 1、如果系统处于高并发的场景下，大量请求涌过来的时候，订单服务的100个线程都会卡在请求积分这块，导致订单服务没有一个线程可以处理请求。 2、然后就会导致别人请求订单服务的时候，发现订单服务也挂了，不响应任何请求了。 这就是微服务架构中的服务雪崩问题。这么多服务互相调用，要是不做任何保护的话，某一个服务挂了，就会引起连锁反应，导致别的服务也挂了。 ​ 但就算积分系统挂了，订单服务也可以不用挂啊。结合业务来看，支付订单的时候，只要把库存减了，然后通知仓库发货就可以了；如果积分系统挂了，大不了恢复之后，再手工恢复数据，不应该因为一个积分服务挂了，就直接导致订单服务也挂了。 ​ 这个时候就要使用Hystrix了。Hystrix是隔离、熔断以及降级的一个框架。就是Hystrix会搞很多个小小的线程池，例如订单服务请求库存服务是一个线程池，请求仓储服务是一个线程池，请求积分服务是一个线程池，每个线程池里的线程就仅仅用于请求哪个服务。 ​ 比如积分系统挂了，会导致订单服务里的那个调用积分服务的线程都卡死不能工作了，但是由于订单服务调用库存系统、仓储系统的这两个线程池都是正常工作的，所以这两个服务不会受到任何影响。 ​ 这个时候如果别人请求订单服务，订单服务还是可以正常调用库存服务扣减库存，调用仓储服务通知发货。只不过调用积分服务的时候，每次都会报错。但是如果积分服务都挂了，每次调用都要去卡住几秒钟干啥呢？有意义吗？当然没有！所以我们直接对积分服务熔断不就得了，比如在5分钟内请求积分服务直接就返回了，不要去走网络请求卡住几秒钟，这个过程，就是所谓的熔断！ ​ 而且积分系统挂了，我们还可以来个降级：每次调用积分服务，你就在数据库里记录一条消息，说给某某用户增加了多少积分，因为积分服务挂了，导致没增加成功！这样等积分服务恢复了，你可以根据这些记录手工加一下积分。这个过程，就是所谓的降级。 SpringCloud的核心组件：Zuul​ 说完了Hystrix，接着给大家说说最后一个组件：Zuul，也就是微服务网关。这个组件是负责网络路由的。不懂网络路由？行，那我给你说说，如果没有Zuul的日常工作会怎样？ ​ 假设你后台部署了几百个服务，现在有个前端兄弟，人家请求是直接从浏览器那儿发过来的。打个比方：人家要请求一下库存服务，你难道还让人家记着这服务的名字叫做inventory-service？部署在5台机器上？就算人家肯记住这一个，你后台可有几百个服务的名称和地址呢？难不成人家请求一个，就得记住一个？你要这样玩儿，那真是友谊的小船，说翻就翻！ ​ 上面这种情况，压根儿是不现实的。所以一般微服务架构中都必然会设计一个网关在里面，像android、ios、pc前端、微信小程序、H5等等，不用去关心后端有几百个服务，就知道有一个网关，所有请求都往网关走，网关会根据请求中的一些特征，将请求转发给后端的各个服务。 ​ 而且有一个网关之后，还有很多好处，比如可以做统一的降级、限流、认证授权、安全，等等。 总结最后再来总结一下，上述几个Spring Cloud核心组件，在微服务架构中，分别扮演的角色： Eureka：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里 Ribbon：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台 Feign：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求 Hystrix：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题 Zuul：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存区域]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F09%2FJVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[JVM内存布局 存放类的方法区​ 这个方法区是在JDK1.8以前的版本里，代表JVM中的一块区域。主要是放从“.class”文件里加载进来的类，还会有一些类似常量池的东西放在这个区域。JDK1.8以后，这个区域改了名字，叫“Metaspace”，也叫“元空间”。 ​ 还是拿之前的代码举例，如下： 123456public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); &#125;&#125; ​ 这两个类加载后，就会放在这个方法区中， 执行代码指令用的程序计数器​ 假设我们的代码是这样： 1234567public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125; ​ 实际上这段代码先存在于“.java”后缀的文件里，但为了能让计算机看懂这段代码，需要将这个文件经过编译器编译，把“.java”后缀的源文件编译为“.class”后缀的字节码文件。这个“.class”后缀的字节码文件里，存放的就是编译好的字节码了，字节码才是计算机可以理解的一种语言。字节码大概如下： ​ 所以首先明白一点：我们写好的Java代码会被翻译成字节码，对应各种字节码指令 ​ 现在Java代码通过JVM跑起来的第一件事情就确定了，首先Java代码被编译成字节码指令，然后字节码指令一定会被一条一条地执行，这样才能实现我们写好的代码执行的效果。当JVM加载类信息到内存之后，实际就会使用自己的字节码执行引擎，去执行我们写的代码编译出来的代码指令，那么在执行字节码指令的时候，JVM就需要一个特殊的内存区域，“程序计数器”。它是用来记录当前的字节码指令位置的，也就是记录目前执行到了哪一条字节码指令。 ​ JVM是支持多个线程的，所以你写好的代码可能会开启多个线程并发执行不同的代码，所以就会有各个线程来并发的执行不同的代码指令，因此每个线程都会有自己的一个程序计数器，专门记录当前这个线程目前执行到了哪一条字节码指令。 Java虚拟机栈​ Java代码在执行的时候，一定是线程来执行某个方法中的代码，即使是下面的代码，也会有一个main线程来执行main()方法里的代码。在main线程执行main()方法的代码指令的时候，就会通过main线程对应的程序计数器记录自己执行的指令位置。 1234567public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125; ​ 但在方法里，一般会定义一些方法内的局部变量，例如上面的代码中就有一个“replicaManager”局部变量。因此JVM必须有一块保存每个方法内的局部变量等数据的，这个区域就是Java虚拟机栈。每个线程都有自己的Java虚拟机栈，比如这里的main线程就会有自己的一个Java虚拟机栈，用来存放自己执行的那些方法的局部变量。 ​ 如果线程执行了一个方法，就会对这个方法调用创建对应的一个栈帧。栈帧就有这个方法的局部变量表、操作数栈。动态链接、方法出口等信息。 ​ 比如main线程执行了main()方法，那么就会给main()方法创建一个栈帧，压入main线程的Java虚拟机栈，同时在main()方法的栈帧里，存放对应的“replicaManager”局部变量。 ​ 然后假设main()线程继续执行ReplicaManager对象里的方法，比如下面，就在“loadReplicasFromDisk”方法里定义了一个局部变量：“hasFinishedLoad”。 123456public class ReplicaManager &#123; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; &#125;&#125; ​ 那么main线程执行上面的“loadReplicasFromDish”方法时，就会为“loadReplicasFromDish”方法创建一个栈帧压入线程自己的Java虚拟机栈里面去。 ​ 接着如果“loadReplicasFromDish”方法调用了另外一个“isLocalDataCorrupt()”方法，这个方法里也有自己的局部变量，如下： 123456789101112131415public class ReplicaManager &#123; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; if(isLocalDataCorrupt()) &#123; &#125; &#125; public Boolean isLocalDataCorrupt() &#123; Boolean isCorrupt = false; return isCorrupt &#125;&#125; ​ 这个时候会给“isLocalDataCorrupt”方法又创建一个栈帧，压入线程的Java虚拟机里，而且“isLocalDataCorrupt”方法的栈帧的局部变量表里会有一个“isCorrupt”变量，这个“isLocalDataCorrupt”的局部变量，整个过程如下： ​ 接着如果“isLocalDataCorrupt”方法执行完毕，就会把“isLocalDataCorrupt”方法对应的栈帧从Java虚拟机栈里出栈；然后如果“loadReplicasFromDisk”方法也执行完毕，就会把“loadReplicasFromDisk”方法也从Java虚拟机栈里出栈、 ​ “JAVA虚拟机栈”这个组件的作用：调用执行任何方法时，都会给方法创建栈帧然后入栈，在栈帧里存放了这个方法对应的局部变量之类的数据，包括这个方法执行的其他相关信息，方法执行完毕之后出栈。 Java堆内存​ Java堆主要是存放我们在代码中创建的各种对象。 1234567public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125; ​ 上面的“new ReplicaManager()”这个代码就是创建了一个ReplicaManager类的对象实例，这个对象实例里面会包含一些数据，如下代码所示：这个“ReplicaManager”类里的“replicaCount”就是属于这个对象实例的一个数据。而类似ReplicaManager这样的对象实例就会存放在Java堆内存里。 12345678910111213141516public class ReplicaManager &#123; private long replicaCount; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; if(isLocalDataCorrupt()) &#123; &#125; &#125; public Boolean isLocalDataCorrupt() &#123; Boolean isCorrupt = false; return isCorrupt &#125;&#125; ​ Java堆内存区域里会放入类似ReplicaManager的对象，然后我们因为在main方法里创建了ReplicaManager对象，那么在线程执行main方法代码的时候，就会在main方法对应的栈帧的局部变量表里，让一个引用类型的“replicaManager”局部变量来存放ReplicaManager对象的地址。 ​ 相当于你可以认为局部变量表的“replicaManager”指向了Java堆内存里的ReplicaManager对象。 核心内存区域的全流程串讲​ 123456789101112131415161718192021222324public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125;public class ReplicaManager &#123; private long replicaCount; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; if(isLocalDataCorrupt()) &#123; &#125; &#125; public Boolean isLocalDataCorrupt() &#123; Boolean isCorrupt = false; return isCorrupt &#125;&#125; ​ 首先，你的JVM进程会启动，就会先加载Test类到内存里，然后有一个main线程，开始执行你的Test中的main()方法。main线程是关联了一个程序计数器的，他执行到哪一行指令，就会记录在这里。 ​ 其次，就是main线程执行main()方法的时候，会在main线程相关的Java虚拟机栈里，压入一个main()方法的栈帧，接着会发现需要创建一个ReplicaManager类的实例对象，此时会加载ReplicaManager类到内存里来。 ​ 然后会创建一个ReplicaManager的对象实例分配在堆内存里，并且在main()方法的栈帧里的局部变量表引入一个“replicaManager”变量，让他引用ReplicaManager对象在Java堆内存中的地址。 ​ 接着，main线程开始执行ReplicaManager对象中的方法，会依次把自己执行到的方法对应的栈帧压入自己的Java虚拟机栈。 ​ 执行完方法之后再把方法对应的栈帧从Java虚拟机栈里出栈。 其他内存区域​ 在JDK很多底层API里，比如IO相关、网络Socket相关的，很多地方都不是JAVA代码了，而是走的native方法去调用本地操作系统里面的一些方法，可能调用的都是C语言写的方法，或者一些底层类库。在调用这种native方法时，就会有线程对应的本地方法栈，这个跟Java虚拟机栈类似的，也是存放各种native方法的局部变量表之类的信息。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM类加载机制]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F07%2FJVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 JVM什么情况下会加载一个类​ 首先，我们应该清楚一个类从加载到使用，一般会经过加载–&gt;链接–&gt;初始化–&gt;使用–&gt;卸载这几个过程，其实链接阶段又可以细分为三个：验证–&gt;准备–&gt;解析。所以首先要明白的一个问题就是，JVM在执行我们代码的时候，什么时候去加载一个类呢？即什么时间会从“.class”字节码文件中加载这个类到JVM内存中？ ​ 答案就是你的代码中用到这个类的时候。 ​ 比如下面有一个类，里面有一个“main()”方法作为入口，那么一旦你的JVM进程启动之后，它一定会先把这个类加载到内存里，然后从main()方法入口的代码开始执行。 12345public class Test &#123; public static void main(String[] args) &#123; &#125;&#125; 接着上面的代码中，出现了这么一行代码： 123456public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); &#125;&#125; 这个时候，你的代码中明显需要使用“ReplicaManager”这个对象，因此会从“ReplicaManager.class”字节码中加载对应的类到内存中使用。 简单概括就是：首先你的代码中包含“main()”方法的主类一定会在JVM启动后加载到内存中，开始执行你的“main()”方法中的代码，接着遇到你使用了别的类，此时就会从对应的“.class”字节码文件中加载对应的类到内存里来。 从使用角度出发，来看验证、准备和初始化的过程1、验证阶段​ 简单来说，这一步即使根据JAVA虚拟机规范，来检验你加载进来的“.class”文件中的内容，是否符合指定的规范。 2、准备阶段​ 一般情况下，我们写好的类，都有一些类变量，如下： 1234public class ReplicaManager &#123; public static int flushInterval;&#125; ​ 假设有这么一个类“ReplicaManager”，它的“ReplicaManager.class”，刚被加载到内存之后，会被进行验证，确认这个验证码是符合规范的。接着就会进行准备工作。这个准备工作，就是给这个“ReplicaManager”类分配一定的内存空间，然后给他里面的类变量（也就是static修饰的变量）分配内存空间，来一个默认的初始值。比如上面的“flushInterval”这个类变量分配的内存空间，会给一个“0”初始值。 3、解析阶段​ 这个阶段，实际上就是把符合引用替换为直接引用的过程 4、三个阶段的小结​ 这三个阶段中，最核心的就是“准备阶段”，这个阶段是给加载进来的类分配好了内存空间，类变量也分配好了内存空间，并且给了默认的初始值。 核心阶段：初始化​ 上面说过，在准备阶段，会把我们的“ReplicaManager”类给分配好内存空间。另外的一个类变量“flushInterval”也会给一个默认的初始值“0”。那么接下来，在初始化阶段，就会正式执行我们的类初始化的代码了。 ​ 那什么是类初始化代码呢？看看以下代码 12345public class ReplicaManager &#123; public static int flushInterval = Configuration.getInt("replica.flush.interval");&#125; 通过以上代码我们可以知道，这个类变量，我们是通过Configuration.getInt(“replica.flush.interval”)这段代码来获取一个值，并且赋值给他的。但是这个赋值逻辑并不在准备阶段执行，在准备阶段，仅仅是给这个类变量开辟一个内存空间，然后给个初始值“0”而已。 ​ 而这段赋值的代码，则是在“初始化”阶段来执行。在该阶段，代码Configuration.getInt(“replica.flush.interval”)会在这里执行，完成一个配置项的读取，然后赋值给这个类变量“flushInterval”。 另外比如下面的static静态代码块，也会在这个阶段执行。 123456789101112131415public class ReplicaManager &#123; public static int flushInterval = Configuration.getInt("replica.flush.interval"); private static Map&lt;String, Object&gt; replicas; static &#123; loadReplicaFromDish(); &#125; public static void loadReplicaFromDish() &#123; this.replicas = new HashMap&lt;String, Object&gt;(); &#125;&#125; 什么时候会初始化一个类​ 一般来说有一下时机：比如“new ReplicaManager()”来实例化类的对象，此时就会触发类的加载到初始化全过程，把这个类准备好，然后再实例化一个对象出来； ​ 或者是包含“main”方法的主类，必须是立马初始化的。 ​ 这里还有一个非常重要的规则，就是如果初始化一个类的时候，发现它的父类还没初始化，那么先必须初始化它的父类。 类加载器和双亲委派机制​ 上述的过程中，都必须依赖类加载器来实现，Java里主要有几种类加载器 1、启动类加载器（Bootstrap ClassLoader）​ 它主要负责加载我们机器上安装的java目录下的核心类，比如Object、System、String等。 2、扩展类加载器（Extension ClassLoader）​ 用于加载一些扩展的系统类，比如XML、加密、压缩相关的功能类等。JDK9之后变成了平台类加载器，即Platform ClassLoader。 3、应用类加载器（Application ClassLoader）​ 主要是加载用户定义的CLASSPATH路径下的类。 4、自定义类加载器​ 除了上面几种之外，还可以自定义类加载器，去根据你自己的需求加载你的类。 双亲委派机制​ 低层次的当前类加载器，不能覆盖更高层次类加载器已经加载的类。如果低层次的类加载器想加载一个未知类，要礼貌地向上级询问：“请问这个类已经加载了吗”？被询问的高层次类加载器会自问两个问题：第一，我是否已加载过此类？第二，如果没有，是否可以加载此类？只有当所有高层次类加载器在两个问题上的答案均为“否”时，才可以让当前类加载器加载这个未知类。 ​ 简单地讲，所谓的双亲委派模型：先找父亲去加载，不行的话再由儿子来加载。 最后总结]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo的负载均衡策略、集群容错策略和动态代理策略]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F07%2Fdubbo%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5%E5%92%8C%E9%9B%86%E7%BE%A4%E5%AE%B9%E9%94%99%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[本节思维导图 dubbo的负载均衡策略random loadbalance​ 随机调用实现负载均衡。这是dubbo默认的负载均衡策略。可以对provider设置不同的权重，会按照权重来负载均衡，权重大分配流量越高。一般使用这个策略即可。 roundrobin loadbalance​ 均匀地将流量打到各个机器上，但如果各个机器性能不一样，容易导致性能差的机器负载过高，所以此时需要调整权重，让性能差的机器承载比较小的流量。 leastactive loadbalance​ 这个就是自动感知一下，某个机器的性能越差，接收的流量就越小，就越不活跃，此时就会给不活跃性能差的机器更小的请求。 consistentHash loadbalance​ 一致性哈希算法，相同参数的请求一定分发到一个provider上去，provider挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。如果你需要的不是随机负载均衡，是要一类请求都到一个节点，那就使用这个一致性哈希算法。 dubbo集群容错策略failover cluster模式失败自动切换，自动重试其他机器，默认使用这个，常见于读操作。（失败重试其他机器） 可以通过以下几种方式配置重试次数： 1&lt;dubbo:service retries="2" /&gt; 或者 1&lt;dubbo:reference retries="2" /&gt; 或者 123&lt;dubbo:reference&gt; &lt;dubbo:method name="findFoo" retries="2" /&gt;&lt;/dubbo:reference&gt; failfast cluster模式一次调用失败就立即失败，常用与非幂等性的写操作，比如新增一条记录（调用失败就立即失败） failsafe cluster模式出现异常时忽略掉，常用与不重要的接口调用，比如日志记录。 配置示例如下： 1&lt;dubbo:service cluster="failsafe" /&gt; failsafe cluster模式 或者 1&lt;dubbo:reference cluster="failsafe" /&gt; failback cluster模式失败了后台自动记录请求，然后定时重发，比较适合于写消息队列。 forking cluster模式并行调用多个provider，只要一个成功立即返回，常用于实时性要求比较高的读操作，但是会浪费更多的服务资源，可以通过forks=”2”来设置最大并行数。 broadcast cluster模式逐个调用所有的provider，任何一个provider出错则报错。通用用于通知所有provider更新缓存或日志等本地资源信息。 dubbo动态代理策略默认使用javassist动态字节码生成，创建代理类。但是可以通过spi扩展机制配置自己的动态代理策略。]]></content>
      <categories>
        <category>分布式</category>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo支持的通信协议、序列化协议以及hession的数据结构]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F06%2Fdubbo%E6%94%AF%E6%8C%81%E7%9A%84%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E3%80%81%E5%BA%8F%E5%88%97%E5%8C%96%E5%8D%8F%E8%AE%AE%E4%BB%A5%E5%8F%8Ahession%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[本节思维导图 dubbo支持的通信协议dubbo协议​ 默认就是走dubbo协议，单一长连接，进行的是NIO异步通信，基于hession作为序列化协议。使用的场景是：传输数据量小（每次请求在100kb以内），但是并发量高。 ​ 为了支持高并发场景，一般是服务提供者就几台机器，但是服务消费者有上百台，可能每天调用量达到上亿次，此时用长连接是最合适的，就是跟每个服务消费者维持一个长连接即可，可能总共就100个连接，然后后面直接基于长连接NIO异步通信，可以支撑高并发请求。 ​ 长连接，通俗讲就是建立连接后可以持续发送请求，无须再建立连接。 ​ 而短连接，每次要发送请求之前，需要先重新建立一次连接。 rmi协议​ 走JAVA二进制序列化，多个短连接，适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。 hession协议​ 走hession序列化协议，多个短连接，适用于提供者数量比消费者数量还多的情况，适用于文件传输，一般较少用。 http协议​ 走JSON序列化 webService​ 走SOAP文本序列化 dubbo支持的序列化协议​ dubbo默认的序列化协议是hession序列化协议，除此之外还支持java二进制协议、json和SOAP文本序列化等多种序列化协议。 hession数据结构​ hession的数据结构可以分为三类型：8种基本原始类型、3种递归类型和1中特殊类型 8种基本原始类型 原始二进制数据 64-bit date（64位毫秒值日期） 64-bit double 64–bit long 32-bit int boolean null UTF-8 编码的string 3种递归类型 list for lists and arrays map for maps and dictionaries object for objects 1种特殊类型 ref：用于表示对共享对象的引用 为什么PB的效率是最高的​ protocol buffer是Google出品的一种轻量并且高效的结构化数据存储格式，性能要比JSON和XML高得多。它性能高主要有两个原因：一是，它使用protocol编译器，自动进行序列化和反序列化，速度非常快，差不多比XML和JSON快上了20~100倍；第二，它的数据压缩效果好，它序列化后的数据量体积小，因为体积小，传输起来带宽和速度上会有优化。]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的缓存穿透、缓存击穿、缓存雪崩、热点数据失效问题及解决方案]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F05%2FRedis%E7%9A%84%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 在我们的平常的项目中多多少少都会使用到缓存，因为一些数据我们没有必要每次查询的时候都去查询到数据库。特别是高 QPS 的系统，每次都去查询数据库，对于你的数据库来说将是灾难。但缓存使用不当，也会引起灾难。 缓存穿透什么是缓存穿透​ 正常情况下，我们去查询的数据都是存在。但如果请求去查询一条数据库根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。这种查询不存在数据的现象称为缓存穿透。 缓存穿透带来的问题​ 如果有黑客对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库中，可能会导致你的数据库由于压力太大而宕机。 解决方案1、缓存空值​ 之所以会穿透，是因为缓存中没有存储这些空数据的key，从而导致每次查询都到数据库去了。因此我们可以为这些key对应的值设置null丢到缓存里面去，后面再出现查询这个key的请求的时候，就直接返回null。不过要设置过期时间。 2、布隆过滤器​ 这种方式在大数据场景应用比较多，比如Hbase中使用它去判断数据是否在磁盘上，还有在爬虫场景判断URL是否已经被爬取。 ​ 这种方案可以加在第一种方案中，在缓存之前再加一层布隆过滤器，在查询的时候先去布隆过滤器查询key是否存在，如果不存在就直接返回，存在再走查缓存和数据库。 3、用户鉴权​ 这种情况有可能是黑客进行恶意攻击，因此我们可以在系统中增加用户鉴权校验或者在接口层增加校验，直接拦截不正常的请求。 方案选择​ 对于一些恶意攻击，攻击带过来的大量的key是不存在的，那么我们采用第一种方案就会缓存大量不存在key的数据，此时第一种方案就不合适了，我们可以先使用第二种方案过滤掉这些key。即针对这种key异常多、请求重复率比较低的数据，我们没有必要进行缓存，使用第二种方案直接过滤掉。 缓存击穿什么是缓存击穿​ 在平常高并发的系统中，大量的请求同时查询一个key时，此时这个key刚好失效了，就会导致大量的请求打到数据库上面去，这种现象我们成为缓存击穿。 缓存击穿带来的问题​ 会造成某一时刻数据库请求里过大，压力剧增。 解决方案1、设置热点数据永不过期2、加互斥锁​ 多个线程同时去查询数据库的这条数据时，我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它，其他线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来了，就可以直接走缓存了。 缓存雪崩什么是缓存雪崩​ 缓存雪崩的情况是，在某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上。结果就是DB撑不住宕机了。 解决方案1、事前，使用集群缓存，保证缓存服务的高可用​ 这种方案是在发生雪崩前对缓存集群实现高可用，如果是使用Redis，可以使用 主从+哨兵或者Redis Cluster来避免Redis全盘崩溃的情况。 2、事中：ehcache本地缓存 + Hystrix限流&amp;降级，避免数据库被打死​ 使用ehcache本地缓存的目的也是考虑在Redis Cluster完全不可用的时候，ehcache本地缓存可以支撑一阵。 ​ 使用Hystrix进行限流&amp;降级，例如一秒来了3000个请求，我们可以设置只能有一秒1000个请求能通过这个组件，那么其他剩余的2000请求就会走限流逻辑。然后去调用我们自己开发的降级组件，比如设置一些默认值之类的，以此来保护数据库不会被大量的请求给打死。 3、事后：开启Redis持久化机制，尽快恢复缓存集群​ 一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。 解决热点数据集中失效问题什么是热点数据集中失效​ 我们在设置缓存的时候，一般会给缓存设置一个失效时间，过了这个时间，缓存就失效。对于一些热点的数据来说，当缓存失效以后会存在大量的请求过来，然后打到数据库中去，从而可能导致数据库崩溃的情况。 解决方案1、设置不同的过期时间​ 为了避免这些热点数据集中失效，那么我们在设置缓存过期时间的时候，尽量让他们失效的时间错开。例如在一个基础的时间上加上或减去一个范围内的随机值。 2、互斥锁​ 结合上面击穿的情况，在第一个请求去查询数据库的时候加一个互斥锁，其余的查询都会被阻塞住，知道锁释放，从而保护数据库。 ​ 但是因为它会阻塞其他线程，此时系统吞吐量会下降，需要结合实际的业务去考虑是否要这么做。 参考资料https://juejin.im/post/5c9a67ac6fb9a070cb24bf34]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的IO模型]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F02%2FJava%E7%9A%84IO%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[本节思维导图 同步和异步的概念：针对接口调用，API调用，服务调用等。同步调用者必须等待这个接口的磁盘读写或网络通信的操作执行完毕，调用者才可以返回，如图所示： 异步调用者调用接口后，直接就返回，不用等待磁盘读写或网络通信操作完成，而是可以去做其他事情。而这个接口如果干完了某件事，会反过来通知调用者，之前的调用成功了。这个可以通过内部机制来通知，或者通过回调函数来通知。 阻塞和非阻塞：针对的是底层底层IO操作阻塞比如我们的程序现在想要通过网络读取数据，如果是阻塞IO模式，一旦发起请求到操作系统内核去从网络中读取数据，就会阻塞在那里，必须等待网络中的数据到达之后，才能从网络中读取数据到内核，再从内核返回给程序。 非阻塞程序发送请求给内核要从网络读取数据，但是此时网络中的数据还没到，此时不会阻塞住，内核会返回一个异常信息给程序，程序可以干别的，然后不断去轮询去访问内核，看请求的数据是否读取到了。如图所示： BIO，NIO，多路复用IO，信号驱动式IO和AIOBIO​ 主要是同步阻塞IO模型，在JAVA里叫做BIO，在JDK1.4之前，在JAVA代码里调用IO相关接口，发起IO操作之后，JAVA程序就会同步等待，这个同步指的是JAVA程序调用IO API接口的层面而言。 ​ 而IO API在底层的IO操作是基于阻塞IO来的，向操作系统内核发起IO请求，系统内核会等待数据就位之后，才会执行IO操作，执行完毕了才会返回。 NIO​ 在JDK1.4之后提供了NIO，他的概念是同步非阻塞，也就是说如果你调用NIO接口去执行IO操作，其实还是同步等待，但是在底层的IO操作上，会对系统内核发起非阻塞IO请求，以非阻塞的形式来执行IO。 ​ 也就是说，如果底层数据没到位，那么内核会返回异常信息，不会阻塞住，但是NIO接口内部会采用非阻塞方式过一会儿再次调用内核发起IO请求，知道成功为止。 ​ 之所以说是同步非阻塞的，这里的“同步”指的就是因为在你的JAVA代码调用NIO接口层面是同步的，你还是要同步等待底层IO操作真正完成了才可以返回，只不过在执行底层IO的时候采用了非阻塞的方式来执行罢了。 IO多路复用模型​ 实际上，如果基于NIO进行网络通信，采取的就是多路复用的IO模型，这个多路复用IO模型针对的是网络通信中的IO场景来说的。就是在基于Socket进行网络通信的时候，如果有多个客户端跟你的服务端建立了Socket连接，你就需要维护多个Socket连接。而所谓的多路复用IO模型，就是说你的JAVA代码直接通过一个select函数（一般都是系统内核级别的函数，除此还有poll,epoll）调用，直接进入一个同步等待的状态。 ​ 这也是为什么说NIO一定是“同步”的，因为你必须在这里同步等待某个Socket连接有请求到来。接着你就要同步等着select函数去对底层的多个Socket连接进行轮询，不断地查看各个Socket连接谁有请求到达，就可以让select函数返回，交给我们的java程序处理。 ​ select函数在底层会通过非阻塞的方式轮询各个Socket，任何一个Socket如果没有数据到达，那么非阻塞的特性会立即返回一个信息。然后select函数可以轮询下一个Socket，不会阻塞在某个Socket上，所以底层是基于这种非阻塞的模式来“监视”各个Socket谁有数据到达的。 ​ 这就是所谓的“同步非阻塞”，但是因为操作系统把上述工作都封装在一个select函数调用里，可以对多路Socket连接同时进行监控，所以就把这种模型称为“IO多路复用”模型。 ​ 通过这个模型，就可以用一个线程，调用一个select函数，然后监视大量的客户端连接，如下图： 信号驱动式IO​ 首先我们允许Socket进行信号驱动IO，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，会收到一个SIGIO信号，可以在信号处理函数中调用IO操作函数处理数据，如下图所示： ​ 相比于非阻塞式IO的轮询方式，信号驱动IO的CPU利用率更高。 AIO​ 在JDK1.7之后，又支持了AIO，也就做NIO2.0，他就支持异步IO模型。 ​ 异步IO模型，就是你的Java程序可以基于AIO API发起一个请求，比如接收网络数据，AIO API底层会基于异步IO模型来调用操作系统内核。此时不惜要去管这个IO是否成功，AIO接口会直接返回，你的Java程序也会直接返回。然后，你的Java程序就可以去干别的事情了。 ​ BIO，NIO都是同步的，你发起IO请求，都必须同步等待IO操作完成，但是这里你发起一个请求，直接AIO接口就返回了，你可以干别的事情了，纯异步方法，不过需要你提供一个回调函数给AIO接口，一旦底层系统内核完成了具体的IO请求，比如网络读写之类的，就会回调你提供的回调函数。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo工作原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F31%2Fdubbo%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[本节思维导图 dubbo工作原理 第一层：service层，接口层：有服务提供者和服务消费者实现 第二层：config层，配置层：主要对dubbo进行各种配置 第三层：proxy层，服务代理层，为provider、consumer生成代理，代理之间进行网络通信 第四层：registry层，服务注册层，负责服务的注册与发现 第五层：cluster层，集群层，封装多个服务提供者的路由和负载均衡，将多个实例组合成一个服务 第六层：monitor层，监控层，对rpc接口的调用时间和调用次数进行监控 第七层：protocal层，远程调用层，封装rpc调用 第八层：exchange层，信息交换层，封装请求相应模式，同步转异步 第九层：transport层，网络传输层，抽象mina和Netty为统一接口 第十层：serialize层，数据序列化层 工作流程 第一步：provider向注册中心注册 第二步：consumer从注册中心订阅服务，注册中心通知consumer注册好的服务 第三步：consumer调用provider 第四步：consumer和provider都异步通知监控中心 dubbo架构图 注册中心挂了可以继续通信吗可以，因为刚开始初始化的时候，消费者会将提供服务的地址信息拉取到本地缓存，所以注册中心挂了可以继续通信]]></content>
      <categories>
        <category>分布式</category>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F30%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ “红灯停，绿灯行”。在这个过程中，信号灯是汽车的观察目标，汽车是观察者。随着信号灯的变化，汽车的行为也随着变化。在软件系统中，一个对象的状态或行为的变化将导致其他对象的行为或状态也发生改变，它们之间将产生联动。为了更好地描述对象之间存在的这种一对多（包括一对一）的联动，观察者模式应运而生。 ​ 观察者模式是使用频率最高的设计模式之一，用于建立一种对象与对象之间的依赖关系，一个对象发生改变时将自动通知其他对象，其他对象将相应作出反应。在观察者模式中，发生改变的对象成为观察目标，而被通知的对象成为观察者。这些观察者之间可以没有任何相互联系，可以根据需要增加和删除观察者，使得系统更易于扩展。 观察者模式定义：观察者模式：定义对象之间的一种一对多依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象皆得到通知并被自动更新。观察者模式的别名包括发布-订阅（Publish/Subscribe）模式、模型-视图（Model/View）模式、源-监听器（Source/Listener）模式或从属者（Dependents）模式。观察者模式是一种对象行为型模式。 观察者模式结构图： 在结构图中包含以下四个角色： （1）Subject（目标）：目标又称为主题，它是指被观察的对象。在目标中定义了一个观察者集合，一个观察目标可以接受任意数量的观察者来观察，它提供一系列方法来增加和删除观察者对象，同时定义了通知方法notify()。目标类可以是接口，也可以是抽象类或具体类。 （2）ConcreteSubject（具体目标）：具体目标是目标类的子类，通常包含有经常发生改变的数据，当他的状态改变时，向其各个观察者发出通知；同时它还实现了在目标类中定义的抽象业务逻辑方法（如果有的话）。如果无须扩展目标类，则目标具体类可以省略。 （3）Observer（观察者）：观察者将对观察目标的改变做出反应，观察者一般定义为接口，改接口声明了更新数据的方法update()，因此又称为抽象观察者。 （4）ConcreteObserver（具体观察者）：在具体观察者中维护一个指向具体目标对象的引用，它存储具体观察者的有关状态，这些状态需要和具体目标的状态保持一致。它实现了在抽象观察者Observer中声明的update()方法。通常在实现时，可以调用具体的目标类的attach()方法将自己添加到目标类的集合或通过detach()方法将自己从目标类的集合中删除。 观察者模式主要优缺点：1、主要优点（1）观察者模式可以实现表示层和数据逻辑层的分离，定义了稳定的消息更新传递机制，并抽象了更新接口，使得可以有各种各样不同的表示层充当具体观察者角色。 （2）观察者模式在观察目标和观察者之间建立一个抽象的耦合。观察目标只需要维持一个抽象观察者的集合，无须了解其具体观察者。由于观察目标和观察者没有紧密地耦合在一起，因此它们可以不同的抽象化层次。 （3）观察者支持广播通信，观察目标会向所有已注册的观察者对象发送通知，简化了一对多系统设计的难度。 （4）观察者模式满足开闭原则的要求，增加新的具体观察者无须修改原有系统代码，在具体观察者与观察目标之间不存在关联关系的情况下，增加新的观察目标也很方便。 2、主要缺点（1）如果一个观察目标对象有很多直接或间接观察者，将所有的观察者都通知到会花费很多时间 （2）如果在观察者和观察目标之间存在循环依赖，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 （3）观察者模式没有相应的机制让观察者知道所观察的目标是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 观察者模式使用场景：（1）一个抽象模型有两个方面，其中一个方面依赖于另一个方面，将这两个方面封装在独立的对象中使它们可以各自独立地改变和复用。 （2）一个对象的改变将导致一个或多个其他对象也发生改变，而并不知道具体有多少对象将发生改变，也不知道这些对象是谁。 （3）需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 观察者模式与MVC的关系：​ MVC是一种架构模式，它包含3个角色：模型（Model）、视图（View）和控制器（Controller）。其中，模型可应对于观察者模式中的观察目标，而视图对应于观察者，控制器可充当两者之间的中介者，当模型层的数据发生改变时，视图层将自动显示内容。 案例​ Sunny软件公司欲开发一款多人联机对战游戏（类似魔兽世界），在该游戏中，多个玩家可以加入同一战队组成联盟，当战队中某一成员受到敌人攻击时将给所有其他盟友通知，盟友收到通知后将做出响应。 ​ Sunny公司通过对系统功能需求进行分析，发现在改系统中战队成员之间的联动过程可以简单描述如下：联盟成员受到攻击–&gt;发送通知给盟友–&gt;盟友做出响应。如果按照此思路来设计系统，因为成员在受到攻击时需要通知他的每位盟友，所以每个成员都需要持有其他所有盟友的信息，这将导致系统开销较大。因此开发人员决定引入一个新的角色–“战队控制中心”来负责维护和管理每个战队所有成员的信息。当一个成员受到攻击时，向相应的战队控制中心发送求助信息，战队控制中心再逐一通知每个盟友，盟友再做出相应。如图所示： 为了实现对象之间的联动，Sunny公司决定使用观察者模式来进行多人联机对战游戏的设计，其基本结构图如图所示： 相关代码实现已上传]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis哨兵集群实现高可用]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F29%2FRedis%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[哨兵的介绍sentinel，也叫哨兵。哨兵是Redis集群机构中非常重要的一个组件，有以下功能： 集群监控：负责监控redis master和slave进程是否正常工作。 消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障转移：如果master node挂掉了，会自动转移到slave node上。 配置中心：如果故障转移发生了，通知client客户端新的master地址。 ​ 哨兵用于实现Redis集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。 故障转移时，判断一个master node是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。 即使部分哨兵节点挂掉了，哨兵集群还是能正常工作。 哨兵的核心知识sdown和odown转换机制 sdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，那么就是主观宕机。 odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机。 sdown达成的条件比较简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机了；如果一个哨兵在指定的时间内，收到了quorum数量的其他哨兵也认为那个master是sdown，那么就认为是odown。 quorum（法定人数）和majority​ 每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到majority哨兵的授权，才能正式执行切换。 ​ 如果quorum &lt; majority，比如5个哨兵，majority就是3， quorum设置为2，那么就需要3个哨兵授权就可以执行切换。 ​ 如果quorum &gt;= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换。 核心知识 哨兵至少需要3个实例，来保证自己的健壮性。 哨兵 + Redis主从的部署架构，是不保证数据零丢失的，只能保证redis集群的高可用性。 对于哨兵 + redis主从这种复制的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。 哨兵集群必须部署2个以上节点，如果哨兵集群仅仅部署了2个哨兵实例，quorum = 1。 ​ 配置quorum = 1，如果master宕机，两个哨兵只要有1个哨兵认为master宕机了，就可以进行切换，同时会选举出一个哨兵来执行故障转移，但是同时这个时候，需要majority个哨兵，也就是大多数哨兵是运行的。 123452 个哨兵，majority=23 个哨兵，majority=24 个哨兵，majority=25 个哨兵，majority=3... ​ 如果此时只是Master宕机，哨兵1正常运行，那么故障转移时OK的，如果是Master和哨兵1运行的机器宕机了，那么哨兵只有一个，此时就没有majority数量个哨兵来执行故障转移，虽然另外一台机器上还有一个哨兵，但是故障转移不会执行。 ​ 经典的3节点哨兵集群是这样的： ​ 配置quorum = 2，如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机了，然后选举一个来执行故障转移，同时3个哨兵的majority是2，所以还剩下2个哨兵运行着，就可以允许执行故障转移。 Redis哨兵主备切换的数据丢失问题异步复制导致的数据丢失​ 因为master -&gt; slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这部分数据就丢失了。 脑裂导致的数据丢失​ 脑裂，即某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着，此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master。这个时候，集群里就会有两个master，这就是所谓的脑裂。 ​ 此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续向旧的master写数据。因此旧master再次恢复的时候，会被作为一个master挂到新的master上去，自己的数据会清空，重新从新的master复制数据，而新的master并没有后来client写入的数据，因此这部分数据也就丢失了。 数据丢失问题的解决方案可行进行如下配置： 12min-slaves-to-write 1min-slaves-max-lag 10 表示，要求至少有1个slave，数据复制和同步的延迟不能超过10秒。 减少异步复制数据的丢失 ​ 有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低到可控范围内。 减少脑裂的数据丢失 ​ 如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定的slave发送数据，而且slave超过了10秒没有给自己（master）ack消息，那么就直接拒绝客户端的写请求，因此在脑裂的情况下，最多就丢失10秒的数据。 哨兵集群的自动发现机制​ 哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往_sentine__:hello这个channel里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知其他哨兵的存在。 ​ 每隔两秒钟，每个哨兵都会往自己监控的某个maser + slave对应的_sentinel__:hellochannel里发送一个消息，内容是自己的Host、ip和runid还有对这个master的监控配置。 ​ 每个哨兵也会去监听自己监控的每个 master+slaves 对应的 __sentinel__:hello channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。 ​ 每个哨兵还会跟其他哨兵交换对 master 的监控配置，互相进行监控配置的同步。 slave配置的自动纠正​ 哨兵会负责自动纠正slave的一些配置，比如slave如果要成为潜在的master候选人，哨兵会确保复制现有的master数据；如果slave连接到了一个错误的master上。比如故障转移后，那么哨兵会确保它们连接到正确的master上。 slave -&gt; master选举算法​ 如果一个master被认为odown，而且majority数量的哨兵都允许主备切换，那么某个哨兵就会执行住别切换操作，此时需要选举一个slave来当master，会考虑slave的一些信息： 跟master断开连接的时长 slave优先级 复制offset run id ​ 如果一个slave跟master断开连接的时间已经超过了down-after-milliseconds的10倍，外加master的宕机的时长，那么slave就被认为不适合选举为master 1(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state ​ 接下来会对slave进行排序： 按照slave优先级进行排序，slave priority越低，优先级越高。 如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高。 如果上面两个条件都相同，那么选一个run id比较小的那个。 configuration epoch​ 哨兵会对一套redis master + slaves进行监控，有相应的监控配置。 ​ 执行切换的那个哨兵，会从要切换到新的master（slave -&gt; master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一。 ​ 如果第一个选举出的哨兵切换失败，那么其他哨兵，就会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号。 configuration传播​ 哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前说的pub/sub消息机制。 ​ 这里之前的version号就很重要了，以为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的。其他的哨兵都是根据版本号的大小来跟新自己的master配置的。]]></content>
      <categories>
        <category>分布式</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UML之类之间的关系]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F27%2FUML%E4%B9%8B%E7%B1%BB%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[​ 在软件系统中国，类并不是孤立存在的，类与类之间存在各种关系，对于不同类型的关系，UML提供了不同的表示方式。 关联关系​ 关联关系是类与类之间最常用的一种关系，它是一种结构化关系，用于表示一类对象与另一类对象之间有联系，如汽车和轮胎，师傅和徒弟，班级和学生等。在UML类图中，用实现连接有关联关系的对象所对应的类。 ​ 例如现在一个登陆界面类LoginForm中包含一个JButton类型的注册按钮loginButton，它们之间可以表示为关联关系，代码实现时可以在LoginForm中定义一个名为loginButton的属性对象，其类型为JButton，如图所示： 对应的JAVA代码片段如下： 1234567891011public class LoginForm &#123; //定义成员变量 private JButton loginButton; ...&#125;public class JButton &#123; ...&#125; ​ 在UML中，关联关系又包含如下几种形式。 双向关联​ 默认情况下，关联是双向的。例如顾客购买商品并拥有商品，反之，卖出的商品总有某个顾客与之关联。因此，Customer类和Product类之间具有双向关联关系，如图所示： ​ 对应的代码片段如下： 123456789101112public class Customer &#123; private Product[] products; ...&#125;public class Product &#123; private Customer customer; ...&#125; 单向关联​ 类的关联关系也可以是单向的，在UML中单向关联关系用带箭头的实线表示。例如，顾客拥有地址，则Customer类与Address类具有单向关联关系，如图所示： ​ 对应的代码如下： 1234567891011public class Customer &#123; private Address address; ...&#125;public class Address &#123; ...&#125; 自关联​ 在系统中可能会存在一些类的属性对象类型为该类本身，这种特殊的关联关系成为自关联。例如，一个节点类（Node）的成员又是节点Node类型的对象，如图所示： ​ 对应的代码如下： 123456public class Node &#123; private Node subNode; ...&#125; 多重性关联​ 多重性关联关系又称为重数性（Multiplicity）关联关系，表示两个关联对象在数量上的对应关系。在UML中，对象之间的多重性可以直接在关联直线上用一个数字或一个数字范围表示。 ​ 对象之间可以存在多种多重关联惯性，常见的多重性表示方法如下表： 表示方式 多重性说明 1.. 1 表示另一个类的一个对象只与改类的一个对象有关系 0.. * 表示另一个类的一个对象与该类的零个或多个对象有关系 1.. * 表示另一个类的一个对象与该类的一个或多个对象有关系 0.. 1 表示另一个类的一个对象没有或只与改类的一个对象有关系 m.. n 表示另一个类的一个对象与该类最少m，最多n个对象有关系（m &lt;= n） ​ 例如，一个界面可以拥有零个或多个按钮，但是一个按钮只能属于一个界面。因此，一个Form类的对象可以与零个或多个Button类的对象相关联，但一个Button类的对象只能与一个Form类的对象关联，如图所示： ​ 对应的代码如下： 123456789101112public class Form &#123; //定义一个集合对象 private Button[] buttons; ...&#125;public class Button &#123; ...&#125; 聚合关系​ 聚合关系表示整体与部分的关系。在聚合关系中，成员对象是整体对象的一部分，但是成员对象可以脱离整体对象独立存在。在UML中，聚合关系用带空心菱形的直线表示。例如，汽车发送机是汽车的组成部分，但是汽车发送机可以独立存在，因此，汽车和发送机是聚合关系，如图所示： ​ 在代码实现聚合关系时，成员对象通常作为构造方法、Setter方法或业务方法的参数注入到整体对象中，如下所示： 123456789101112131415161718192021public class Car &#123; private Engine engine; //构造注入 public Car(Engine engine) &#123; this.engine = engine; &#125; //设值注入 public void setEngine(Engine engine) &#123; this.engine = engine; &#125; ...&#125;public class Engine &#123; ...&#125; 组合关系​ 组合关系也表示类之间整体和部分的关系，但是在组合关系中整体对象可以控制成员对象的生命周期，一旦整体对象不存在，成员对象也将不存在，成员对象与整体对象之间具有同生共死的关系。在UML中，组合关系用带实心菱形的直线表示。例如，人的头（Head）与嘴巴（Mouth），嘴巴是头的组成部分之一，而且如果头没了，嘴巴也就没了，因此头和嘴巴是组合关系，如图所示： ​ 在代码实现组合关系时，通常在整体类的构造方法中直接实例化成员类，如下所示： 123456789101112131415public class Head &#123; private Mouth mouth; public Head() &#123; mouth = new Mouth(); &#125; ...&#125;public class Mouth &#123; ...&#125; 依赖关系​ 依赖关系是一种使用关系，特定事物的改变有可能会影响到使用该事物的其他的事物，在需要表示一个事物使用另一个事物时使用依赖关系。大多数情况下，依赖关系体现在某个类的方法使用另一个类的对象作为参数。在UML中，依赖关系用带箭头的虚线表示，由依赖的一方指向被依赖的一方。例如，驾驶员开车，在Driver类的drive()方法中将Car类型的对象作为一个参数传递，以便在drive()方法中能调用Car类的move()方法，且驾驶员的drive()方法依赖车的move()方法，因此类Drive依赖类Car，如图所示： ​ 在系统实施阶段，依赖关系通常通过3种方式来实现。第1种也是最常用的一种方式是上面讲的将一个类的对象作为另一个类中方法的参数；第2种方式是在一个类的方法中将另一个类的对象作为其局部变量；第3种方式是在一个类的方法中调用另一个类的静态方法。 ​ 相应的代码如下： 12345678910111213141516public class Driver &#123; public void drive(Car car) &#123; car.move(); &#125; ...&#125;public class Car &#123; public void move() &#123; ... &#125; ...&#125; 泛化关系​ 泛化关系也就是继承关系,用于描述父类与子类之间的关系，父类又称作基类或超类，子类又称作派生类。在UML中,泛化关系用带空心三角形的直线来表示。在代码实现时,使用面向对象的继承机制来实现泛化关系，如在Java语言中使用extends关键字、在C++/C#中使用冒号“:”来实现。 ​ 相应的代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637//父类public class Person &#123; protected String name; protected int age; public void move() &#123; ... &#125; public void say() &#123; ... &#125;&#125;//子类public class Student extends Person &#123; private String stuedentNo; public void study() &#123; ... &#125;&#125;//子类public class Teacher extends Person&#123; private String teacherNo; public void teach() &#123; ... &#125;&#125; 接口与实现关系​ 在很多面向对象语言中都引人了接口的概念，如Java、C#等。在接口中,通常没有属性，而且所有的操作都是抽象的，只有操作的声明，没有操作的实现。UML中用与类的表示法类似的方式表示接口，接口之间也可以有与类之间关系类似的继承关系和依赖关系，但是接口和类之间还存在一种实现(Realization)关系。在这种关系中，类实现了接口，类中的操作实现了接口中所声明的操作。在UML中,类与接口之间的实现关系用带空心三角形的虚线来表示。 ​ 相应的代码如下所示： 1234567891011121314151617public interface Vehicle &#123; public void move();&#125;public class Ship implements Vehicle &#123; public void move() &#123; ... &#125;&#125;public class Car implements Vehicle &#123; public void move() &#123; ... &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP的基础概念]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F25%2FHTTP%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[本节思维导图 URIURI(Uniform Resource Identifier)统一资源标识符，其中包括两个部分：URL(Uniform Resource Locator)统一资源定位符和URN(Uniform Resource Name)统一资源名称。 HTTP方法客户端发送的请求报文的第一行为请求行，包含了方法字段。 GET 获取资源 HEAD 获取报文首部 和GET方法类似，但不返回报文实体主体部分。主要用于确认URL的有效性和资源更新的日期时间等。 POST 传输实体主体 POST主要用来传输数据，GET只要用来获取资源 PUT 上传文件 由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法 PATCH 对资源进行部分修改 PUT也可以用于修改资源，但是只能完全替代原始资源，PATCH允许部分修改。 DELETE 删除文件 与PUT功能相反，并且同样不带验证机制 OPTIONS 查询支持的方法 查询指定的URL能够支持的方法。会返回Allow:GET, POST, HEAD, OPTIONS 这样的内容 CONNECT TRACE]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hello</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列优缺点]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F24%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%BC%98%E7%BC%BA%E7%82%B9%2F</url>
    <content type="text"><![CDATA[本节思维导图 消息队列的优点消息队列主要有三个优点：解耦、异步和削峰 削峰假设一个业务场景如图所示，A系统分别发送信息给B C D系统，此时系统的耦合性比较高，当需求改变要求不给D系统发送消息，或者增加一个E系统也需要A系统发送数据，那么我们就不得不去修改A系统的代码。除此之外如果其他系统挂了，同样也会影响到A系统，如果引入MQ，那么A系统就只需要把数据放进MQ中，由需要这个数据的系统去订阅这个MQ，这样就可以实现系统解耦。这样A系统不仅不需关系哪个系统需要这个消息，也不需要关心消息发送失败或者超时等情况。 总结：通过MQ，Pub/Sub发布订阅消息模型，A系统就跟其他系统解耦了。 异步业务场景如图所示，用户向A系统发起请求，需要在本地写数据库，还需要在B C D系统写数据库，假设本地写耗时10ms，如下图需要10+20+30+40共100ms。那么这样相对来说比较慢。 但如果引入MQ，假设将消息放入MQ耗时5ms，那么总共需要15ms，极大提高了响应速度。 削峰假设每天0:00-12:00系统每秒并发请求数量只有十几个，但过了12点之后，请求数量猛增到几千个，而且数据库系统是mysql，每秒最多也就执行一千多条SQL语句，这样导致mysql崩溃，但过了高峰期之后并发请求又恢复到了相对比较低的水平，对整个系统又没啥压力了。 引入MQ之后，A系统每秒中只能处理一千个SQL，那就从MQ中取出一千个SQL去处理，这样即使在高峰的时候，A系统也不会崩溃，而在高峰期间MQ可能会有几百万的请求积压在MQ中，但这个短暂的高峰的积压是允许，等高峰期一过，MQ积压的数据就能够迅速被处理。 消息队列的缺点缺点有以下几个： 系统可用性降低引入的外部依赖越多，风险就越高。本来只是调用几个系统的接口就可以了，现在引入MQ之后，如果MQ挂了，整个系统就崩溃了。 系统复杂性提高引入MQ之后，需要考虑很多问题。例如如何保证消息传递的顺序，保证消息没有重复消费和怎么处理消息丢失的情况。 数据一致性问题A系统将数据放到MQ将返回成功了，但如果B系统数据丢失了，那就会造出数据不一致了。 ActiveMQ、RabbitMQ、RocketMQ和kafka有什么优缺点 特性 ActiveMQ RabbitMQ RocketMQ kafka 单机吞吐量 万级，比RocketMQ、kafka低一级 同ActiveMQ 10万级，支撑高吞吐 10万级，高吞吐，一般配合大数据类的系统机型实时数据计算，日志采集等场景 topic数量对吞吐量的影响 topic可以达到几百/几千的级别，这是RocketMQ的优势，在同等机器下，可以支撑大量的topic topic从几十到几百个左右的时候，吞吐量会大幅度下降，kafka尽量保证topic数量不要过多，如果要支撑大规模的topic，需要增加更多的机器资源 时效性 ms级 微秒级，这是RabbitMQ的一大特点，延迟最低 ms级 延迟在ms级以内 可用性 高，基于主从架构实现高可用 同ActiveMQ 非常高，分布式架构 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 基本不丢 经过参数优化配置，可以做到0丢失 同RocketMQ 功能支持 MQ领域的功能极其完备 基于erlang开发，并发能力很强，性能极好，延时很低 MQ功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用 综上，各种对比之后，有如下建议： 一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了； 后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高； 不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的过期策略和内存淘汰机制]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F21%2FRedis%E7%9A%84%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E5%92%8C%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ redis主要是基于内存来进行高性能、高并发的读写操作的。但既然内存是有限的，例如redis就只能使用10G，你写入了20G。这个时候就需要清理掉10G数据，保留10G数据。那应该保留哪些数据，清除哪些数据，为什么有些数据明明过期了，怎么还占用着内存？这都是由redis的过期策略来决定的。 redis过期策略​ redis的过期策略就是：定期删除 + 惰性删除。 ​ 定期删除，指的是redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查是否过期，如果过期就删除。 ​ 假设redis里放了10W个key，都设置了过期时间，你每隔几百毫秒就检查全部的key，那redis很有可能就挂了，CPU负载会很高，都消耗在检查过期的key上。注意，这里不是每隔100ms就遍历所有设置过期时间的key，那样就是一场性能灾难。实际上redis是每隔100ms就随机抽取一些key来检查和删除的。 ​ 定期删除可能会导致很多过期的key到了时间并没有被删除掉。这个时候就可以用到惰性删除了。惰性删除是指在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间并且已经过期了，此时就会删除，不会给你返回任何东西。 ​ 但即使是这样，依旧有问题。如果定期删除漏掉了很多过期的key，然后你也没及时去查，也就没走惰性删除。此时依旧有可能大量过期的key堆积在内存里，导致内存耗尽。 ​ 这个时候就需要内存淘汰机制了。 内存淘汰机制​ redis内存淘汰机制有以下几个： noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。这个一般很少用。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key，这个是最常用的。 allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。 LRU算法​ 上面的内存淘汰机制中，用到的是LRU算法。什么是LRU算法？LRU算法其实就是上面说的最近最少使用策略。实现LRU算法，大概的思路如下： ​ 维护一个有序单链表，越靠近链表尾部的节点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表： 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的节点，并将其从原来的位置删除，然后再插入到链表的头部。 如果此数据没有在缓存链表中，又可以分为两种情况： 如果此时缓存未满，则将此节点直接插入到链表的头部； 如果此时缓存已满，则链表尾节点删除，将新的数据节点插入链表的头部。 ​ 这就就实现了LRU算法。 ​ 当然我们也可以基于Java现有的数据结构LinkedHashMap手撸一个。LinkHashMap本质上是一个Map与双向链表的结合，比起上述的单链表，效率更高。代码如下： 1234567891011121314151617181920class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int CACHE_SIZE; /** * 传递进来最多能缓存多少数据 * * @param cacheSize 缓存大小 */ public LRUCache(int cacheSize) &#123; // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。 super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true); CACHE_SIZE = cacheSize; &#125; @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。 return size() &gt; CACHE_SIZE; &#125;&#125;]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的数据结构及其应用场景]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F21%2FRedis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[本节思维导图 redis主要有以下几种数据类型： string hash list set sorted set string这是最简单的类型，就是普通的set和get，做简单的KV缓存 1set college gpnu hash这个是类似map的一种结构，一般是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他对象）给缓存在redis里，然后每次读写缓存的时候，就可以操作hash里的某个字段。 1234hset person name bingohset person age 20hset person id 1hget person name 12345person = &#123; "name": "bingo", "age": 20, "id": 1&#125; listlist是有序列表。可以通过list存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的。 还可以通过lrange命令，读取某个闭区间内的元素，可以基于list实现分页查询，基于redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走 12# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。lrange mylist 0 -1 123456lpush mylist 1lpush mylist 2lpush mylist 3 4 5# 1rpop mylist setset是无序集合，自动去重。 直接基于set将系统里需要去重的数据扔进去，自动就去去重了。如果你需要对一些数据进行快速的全局去重，如果是单机系统就可以基于Java的HashSet进行去重，如果你的某个系统部署在多台机器上，就可以基于redis进行全局的set去重。 可以基于set玩交集、并集、差集的操作。比如交集，可以把两个人的粉丝列表整一个交集，看看两人的共同好友是谁。或者把两个大V的粉丝放在两个set中，对两个set做交集。 1234567891011121314151617181920212223242526272829303132#-------操作一个set-------# 添加元素sadd mySet 1# 查看全部元素smembers mySet# 判断是否包含某个值sismember mySet 3# 删除某个/些元素srem mySet 1srem mySet 2 4# 查看元素个数scard mySet# 随机删除一个元素spop mySet#-------操作多个set-------# 将一个set的元素移动到另外一个setsmove yourSet mySet 2# 求两set的交集sinter yourSet mySet# 求两set的并集sunion yourSet mySet# 求在yourSet中而不在mySet中的元素sdiff yourSet mySet sorted setsorted set是排序的set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序 12345678910zadd board 85 zhangsanzadd board 72 lisizadd board 96 wangwuzadd board 63 zhaoliu# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）zrevrange board 0 3# 获取某用户的排名zrank board zhaoliu]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
</search>
