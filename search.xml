<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[RocketMQ 的一些特殊场景解决方案]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F24%2FRocketMQ-%E7%9A%84%E4%B8%80%E4%BA%9B%E7%89%B9%E6%AE%8A%E5%9C%BA%E6%99%AF%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[RocketMQ 百万消息积压问题有一个系统，它是由生产者系统和消费者系统两个环节组成的，生产者系统会负责不停地把消息写入 RocketMQ 里去，然后消费者系统就是负责从 RocketMQ 里消费消息。这个系统是有高峰和低谷的，在晚上几个小时的高峰期内，大概会有 100 多万条消息进入 RocketMQ，然后消费者系统从 RocketMQ 里获取到消息之后，会依赖一些 NoSQL 数据库去进行一些业务逻辑的实现。 然后有一天晚上出现了一个问题，消费者系统依赖的 NoSQL 数据库挂掉了，导致消费者系统自己也没法运作，此时就没法继续从 RocketMQ 里消费数据和处理了，消费者系统几乎就处于停滞不动的状态。然后生产者系统在晚上几个小时的高峰期内，往 MQ 里写入了 100 多万的消息，此时都积压在 MQ 里了，没人消费和处理。 针对这种情况，一般来说有几种方案可以快速搞定。如果这些消息你是允许丢失的，那么此时你就可以紧急修改消费者系统的代码，在代码里对所有的消息都获取到就直接丢弃，不做任何的处理，这样可以迅速地让积压在 MQ 里的百万消息被处理掉，只不过处理方式是全部丢弃而已。 但是对很多系统而言，不能简单粗暴地丢弃这些消息，所以最常见的方法，还是先等待消费者系统底层依赖的 NoSQL 数据库先恢复了。恢复之后，就可以根据你的线上 Topic 的 MessageQueue 的数量来看看如何后续处理。 加入你的 Topic 有 20 个 MessageQueue，然后你只有 4 个消费者系统在消费，那么每个消费者系统会从 5 个 MessageQueue 里获取消息。所以此时你仅仅依靠 4 个消费者系统是不够的，毕竟 MQ 了积压了百万消息了。所以此时你可以临时申请 16 台机器多部署 16 个消费者系统的实例，然后 20 个消费者系统同时消费，每个人消费一个 MessageQueue 的消息。此时你消费的速度提高了 5 被，很快积压的百万消息也会被处理掉。 但是这里你同时要考虑到你的消费者系统底层依赖的 NoSQL 数据库必须要能抗住临时增加了 5 倍的读写压力，因为原来就 4 个消费者系统在读写 NoSQL，现在临时变成了 20 个消费者系统了。当你处理完百万积压的消息之后，就可以下线多余的 16 台机器了。 那如果你的 Topic 总共就只有 4 个 MessageQueue，然后你就只有 4 个消费者系统呢？这个时候就没办法扩容消费者系统了，因为你加再多的消费者系统，还是只有 4 个 MessageQueue，没法进行消费。 所以此时往往是临时修改那 4 个消费者系统的代码，让他们获取到消息然后不写入 NoSQL，而是直接把消息写入一个新的 Topic，这个速度是很快的，因为仅仅是读写 MQ 而已。然后新的 Topic 有 20 个 MessageQueue，然后再部署 20 台临时增加的消费者系统，去消费新的 Topic 后写入数据到 NoSQL 里去，这样子也可以迅速地增加消费者系统的并行处理能力，使用一个新的 Topic 来运行更多的消费者并行处理。 金融级的系统针对 RocketMQ 集群崩溃设计高可用方案金融级的系统中如果依赖了 RocketMQ 集群，那么在 RocketMQ 集群彻底崩溃的时候，我们应该如何设计它的高可用方案？比如跟金钱相关的一些系统，它可能需要依赖 MQ 去传递消息，如果你 MQ 崩溃了，可能导致很多跟钱相关的东西就会出问题。 类似的场景有很多，针对这种场景，我们通常会在你发送消息到 MQ 的那个系统中设计高可用的降级方案。这个降级方案通常的思路是，你需要在你发送消息到 MQ 代码里去 try catch 捕获异常，如果你发送发送消息到 MQ 有异常，此时你需要进行重试。 如果你发现连续重试了比如超过 3 次还是失败了，说明此时可能就是你的 MQ 集群彻底崩溃了，此时你必须把这条重要消息写入到本地存储中去，可以是数据库，也可以是写入到本地磁盘文件里去，或者是 NoSQL 存储中去。具体要根据你们的具体情况来决定。 之后你要不停地尝试发送消息到 MQ 去，一旦发现 MQ 集群恢复了，你必须有一个后台线程可以把之前持久化存储的消息都查询出来，然后依次按照顺序发送到 MQ 集群里去，这样才能保证你的消息不会因为 MQ 彻底崩溃而丢失。 这里有一个很关键的点，就是你把消息写入存储中暂存时，一定要保证它的顺序，比如按照顺序一条一条的写入本地磁盘文件去暂存消息。而且一旦 MQ 集群故障了，你后续的所有写消息的代码必须严格按照顺序把消息写入到本地磁盘文件去暂存，这个顺序性是要严格保证的。 只要有这个方案在，那么哪怕你的 MQ 集群突然崩溃了，你的系统也是不会丢失消息的，对于一些跟金钱相关的金融系统，广告系统来说，这种高可用的方案设计，是非常有必要的。 Kafka 到 RocketMQ 的双写 + 双读技术方案，实现无缝迁移假设你们公司本来线上的 MQ 用的主要是 Kafka，现在要从 Kafka 迁移到 RocketMQ 去，那么这个迁移的过程该怎么做？这里给大家介绍一个 MQ 集群迁移过程中的双写 + 双读技术方案。 简单来说，如果你要做 MQ 集群迁移，是不可能那么简单粗暴的，因为你不可能说在某一个时间点突然之间说把所有的 Producer 系统都停机，然后更新它的代码，接着全部上线，然后所有 Producer 系统都把消息写入到 RocketMQ 去了。 一般来说，首先你要做到双写，也就是说，在你所有的 Producer 系统中，要引入一个双写的代码，让它同时往 Kafka 和 RocketMQ 中去写入消息，然后多写几天，起码双写要持续一周左右，因为 MQ 一般都是实时数据，里面的数据也就最多保留一周。当你的双写持续一周后，你会发现你的 Kafka 和 RocketMQ 里的数据看起来几乎是一模一样，因为 MQ 反正也就保留最近几天的数据，当你双写持续超过一周过后，你会发现 Kafka 和 RocketMQ 里的数据几乎一模一样了 但是光是双写还是不够的，还需要同时进行双读，也就是说在你双写的同时，你所有的 Consumer 系统都需要同时从 Kafka 和 RocketMQ 里获取消息，分别用一模一样的逻辑处理一遍。只不过从 Kafka 里获取到的消息还是走核心逻辑去处理，然后可以落入数据库或者别的存储之类的，但是对月 RocketMQ 里获取到的消息，你可以用一样的逻辑处理，但是不能把处理结果具体的地落入数据库之类的地方 你的 Consumer 系统在同时从 Kafka 到 RocketMQ 进行消息读取的时候，你需要统计每个 MQ 当日读取和处理的消息的数量，这点非常重要，同时对于 RocketMQ 读取到的消息处理之后的结果，可以写入一个临时的存储中。 同时你要观察一段时间，当你发现坚持双写和双读一段时间之后，如果所有的 Consumer 系统通过对比发现，从 Kafka 和 RocketMQ 读取和处理的消息数量一致，同时处理之后得到的结果也是一致的，此时就可以判断说当前 Kafka 和 RocketMQ 里的消息是一致的，而且计算出来的结果也是一致的。 这个时候就可以实施正式的切换了，你可以停机 Producer 系统，再重修修改后上线，全部修改为仅仅写 RocketMQ，这个时候它数据不会丢，因为之前已经双写了一段时间了，然后所有的 Consumer 系统可以全部下线后修改代码再上线，全部基于 RocketMQ 来获取消息，计算和处理，结果写入存储中。 基本上对于类似的一些重要中间件的迁移，往往都会采取双写的方法，双写一段时间，然后观察两个方案的结果都一致了，你再正式下线旧的一套东西]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 实践经验]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F22%2FRocketMQ-%E5%AE%9E%E8%B7%B5%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[灵活地运用 tags 来过滤数据之前我们讲解过基于 tags 来过滤数据的功能，其实在真正的生产项目中，建议大家合理地规划 Topic 和里面的 tags。一个 Topic 代表了一类业务消息数据，然后对于这类业务消息数据，如果你希望继续划分一些类别的话，可以在发送消息的时候设置 tags 例如，我们知道现在常见的外卖平台有美团外卖。饿了么和其他一些外卖，假设你现在一个系统要发送外卖订单数据到 MQ 里去，就可以针对性地设置 tags。比如不同的外卖数据都到一个 “WaimaiOrderTopic” 里去，但是不同类型的外卖可有不不同的 tags：”meituan_waimai”，”eleme_waimai”，”other_waimai” 等等。然后你对消费 “WaimaiOrderTopic” 的系统，可以根据 tags 来筛选，可能你就需要某一种类别的外卖数据而已。 基于消息 key 来定位消息是否丢失在消息零丢失方案中，可能要解决的消息是否丢失的问题，那么如果消息真的丢失了，我们就需要排查，需要从 MQ 里查一下，这个小时是否丢失了 那怎么从 MQ 里查消息是否丢失？可以基于消息 key 来实现。比如通过这样的方式设置一个消息的 key为订单 id：message.setKeys(orderId)，这样这个消息就具备一个 key 了。接着这个消息到 Broker 上，会基于 key 构建 hash 索引，这个 hash 索引就存放在 IndexFile 索引文件里。然后后续我们可以通过 MQ 提供的命令去根据 key 查询这个消息，类似下面这样： 1mqadmin queryMsgByKey -n 127.0.0.1:9876 -t SCANRECORD -k orderId 具体的命令，可以去查官方手册 消息零丢失方案的补充之前有讲过零丢失方案，其实在消息零丢失方案还有一个问题，就是 MQ 集群彻底故障，此时就是不可用了，那这么处理？ 其实对于一些金融级的系统，或者跟钱相关的支付系统，或者是广告系统，类似这样的系统，都必须有超高级别的高可用保障机制，一般假设 MQ 集群彻底崩溃了，你生产者就应该把消息写入到本地磁盘里去进行持久化，或者写入数据库里去暂存起来，等待 MQ 恢复之后，然后再把持久化的消息继续投递到 MQ 里去。 提高消费者的吞吐量如果消费的时候发现消费地比较慢，那么可以提高消费者的并行度，常见的就是部署更多的 consumer 机器。但是这里要注意，你的 Topic 的 MessageQueue 得是有对应的增加，因为如果你的 consumer 机器有 5 台，然后 MessageQueue 只有 4 个，那么意味着有一个 consume 机器是获取不到消息的。 然后就是可以增加 consumer 的线程数量，可以设置 consumer 端的参数：consumeThreadMin、consumeThreadMax，这样一台 consumer 机器上的消费线程越多，消费的速度就越快。 此外，还可以开启消费者的批量消费功能，就是设置 consumeMessageBatchMaxSize 参数，它默认是 1，但是你可以设置的多一些，那么一次就会交给你的回调函数一批消息给你处理，此时你可以通过 SQL 一次性批量处理一批数据。比如：update xxx set xxx where id in(xx,xx,xx) 企业级的 RocketMQ 集群进行权限机制的控制如果一个公司有很多技术团队，每个技术团队都会使用 RocketMQ 集群中的部分 Topic，那么此时可能就会有一个问题，如果订单团队使用的 Topic，被商品团队不小心写入了错误的脏数据，怎么办？可能导致订单团队的 Topic 里的数据出错了。 此时就需要在 RocketMQ 中引入权限功能，也就是说规定好订单团队的用户，只能使用 OrderTopic，然后商品团队的用户只能使用 ProductTopic，大家互相之间不能混乱地使用别人的 Topic。要在 RocketMQ 中实现权限控制也不难，首先我们需要在 Broker 端放一个额外的 ACK 权限控制配置文件，里面需要规定好权限，包括什么用户对哪些 Topic 有什么操作权限，这样的话，各个 Broker 才知道你每个用户的权限。 首先在每个 Broker 的配置文件里需要设置 aclEnable = true 这个配置，开启权限控制。其次，在每个 Broker 部署机器的 ${ROCKETMQ_HOME}/store/config 目录下，可以放一个 plain_acl.yml 的配置文件，这个里面就可以进行权限配置，类似下面这样子： 123456789101112131415161718192021222324252627282930313233343536373839# 这个参数就是全局性的白名单# 这个定义的 ip 地址，都是可以访问 Topic 的globalWhiteRemoteAddresses:- 10.10.15.*- 192.168.0.*# 这个 accounts 就是说，你在这里可以定义很多账号accounts:# 这是 AccessKey 就是用户名的意思，比如我们这里叫做 “订单技术团队”- accessKey: OrderTeam# 这个 secretKey 就是这个用户名的密码 secretKey: 123456# 下面这个是当前这个用户名下哪些机器要加入白名单 whiteRemoteAddress:# admin 指的是这个账号是不是管理员账号 admin: false# 这个指的是默认情况下这个账号的 Topic 权限和 ConsumerGroup 权限 defaultTopicPerm: DENY defaultGroupPerm: SUB# 这个就是这个账号具体的一些账号的权限# 下面就是说当前这个账号对应两个 Topic，都具备 PUB|SUB 权限，就是发布和订阅的权限# PUB 就是发布消息的权限，SUB 就是订阅消息的权限# DENY 就是拒绝你这个账号访问这个 Topic topicPerms: - topicA=DENY - CreateOrderInformTopic=PUB|SUB - PaySuccessInformTopic=SUB|SUB# 下面就是对 ConsumerGroup 的权限，也是同理的 groupPerms: - groupA=DENY - groupB=PUB|SUB - groupC=SUB# 下面就是另一个账号了，比如是商品技术团队的账号- accessKey: ProductTeam secretKey: 12345678 whiteRemoteAddress: 192.168.1.* # 如果设置为 true，就是具备一切权限 admin: true 上面配置中，需要注意一点，就是如果你一个账号没有对某个 Topic 显式地指定权限，那么就是会采用默认 Topic 权限。 接着我们看看你的生产者和消费者里，如何指定你的团队分配到的 RocketMQ 的账号。当你使用一个账号的时候，就只能访问你有权限的 Topic 1234DefaultMQProducer producer = new DefaultMQProducer( "OrderProducerGroup", new AclClientRPCHook(new SessionCredentials("OrderTeam", "123456")) ); 上面的代码中就是在创建 Producer 的时候，传入进去一个 AclClientRPHook，里面就可以设置你这个 Producer 的账号密码。对于创建 Consumer 也是同理的，通过这样的方式，就可以在 Broker 端设置好每个账号对 Topic 的访问权限，然后你不同的技术团队就用不同的账号就可以了。 RocketMQ 集群进行消息轨迹的追踪如何在生产环境里查询一条消息的轨迹？即，对于一个消息，我想要知道，这个消息是什么时候从哪个 Producer 发送出来？它在 Broker 端是进入到了 哪个 Topic 里去的？它在消费者层面是被 哪个 Consumer 什么时候消费出来的？ 我们有时候对于一条消息的丢失，可能就想要了解到这样的一个消息轨迹，协助我们去进行线上问题的排查，所以此时就可以使用 RocketMQ 支持的消息轨迹功能，我们看下面的配置过程。 首先需要在 Broker 的配置文件里开启 traceTopicEnable = true 这个选项，此时就会开启消息轨迹追踪的功能。接着当我们开启了上述的选项之后，我们启动这个 Broker 的时候会自动创建一个内部的 Topic，就是 RMQ_SYS_TRACE_TOPIC，这个 Topic 就是用来存储所有的消息轨迹追踪的数据的。 接着做好上述一切事情之后，我们需要在发送消息的时候开启消息轨迹，此时创建 Producer 的时候要用如下的方式，下面构造函数中的第二个参数，就是 enableMsgTrace 参数，它设置为 true，就是说可以对消息开启轨迹追踪。 12DefaultMQProducer producer = new DefaultMQProducer(&quot;TestProducerGroup&quot;, true); 在订阅消息的时候，对于 Consumer 也是同理的，在构造函数的第二个参数设置为 true，就是开启了消费时候的轨迹追踪。 其实，一旦我们在 Broker、Producer、Consumer 都配置好了轨迹追踪之后，其实 Producer 在发送消息的时候，就会上报这个消息的一些数据到内置的 RMQ_SYS_TRACE_TOPIC 里去。此时会上报如下的一些数据：Producer 的消息、发送消息的时间、消息是否发送成功、发送消息的耗时。 接着消息到 Broker 端之后，Broker 端也会记录消息的轨迹数据，包括如下：消息存储的 Topic、消息存储的位置、消息的 key、消息的 tags。然后消息被消费到 Consumer 端之后，它也会上报一些轨迹数据到内置的 RMA_SYS_TRACE_TOPIC 里去，包括如下一些东西：Consumer 的消息、投递消息的时间、这是第几轮投递消息、消息消费是否成功，消费这条消息的耗时。 接着如果我们想要查询消息轨迹，也很简单。在 RocketMQ 控制台里，在导航栏里就有一个消息轨迹，在里面可以创建任务，你可以根据 messageId、message key 或者 Topic 来查询，查询任务执行完毕之后，就可以看到消息轨迹的界面了。 在消息轨迹的界面就会展示出来刚才说的 Producer、Broker、Consumer 上报的一些轨迹数据了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次系统 OOM]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F21%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%B3%BB%E7%BB%9F-OOM%2F</url>
    <content type="text"><![CDATA[由此系统因为 OOM 问题而挂掉了，当时我们就登录到线上系统去下载日志，并在日志中发现类似这么一句话： 1Exception in thread "http-nio-8080-exec-1089" java.lang.OutOfMemoryError: Java heap space 日志中，http-nio-8080-exec 1089 说的其实是 Tomcat 的工作线程，而后面的 java.lang.OutOfMemoryError: Java heap space 指的就是堆内存溢出的问题，所以连起来看，这段日志的意思是 Tomcat 的工作线程在处理请求的时候需要在堆内存里分配对象，但是发现堆内存塞满了，而且根本没办法回收多余的对象，堆内存已经放不下更多对象了，就报了这个异常。 简单说说 Tomcat 的底层原理讲到这，我们看看 Tomcat 的基本工作原理，以及发生这个 OOM 异常的基本原因。首先，我们写的系统一般都是部署在 Tomcat 中的。最早我们会在 Eclipse / IDEA 开发工具上写一堆 Servlet，然后打包放入 Tomcat，再启动 Tomcat。接着我们访问 Tomcat 监听的一个端口号（一般是 8080），然后系统的功能就可以运行起来了。 后来随着技术的发展，我们不再写 Servlet 这么原始的东西，有一些类似 Spring MVC 之类的框架把 Servlet 封装起来，我们就基于 Spring MVC 之类的框架去开发。再后面，出现了 SpringBoot，我们可以把 Tomcat 之类的 Web 容器都内嵌在系统里。 Tomcat 会监听一个默认的 8080 端口号，然后我们就通过浏览器可以对这个机器上的 Tomcat 发起请求，类似下面的请求： 1http://192.168.200.15:8080/order?userid=100 接着 Tomcat 会监听 8080 端口收到这个请求，通常来说它会把请求交给 Spring Web MVC 之类的框架去处理，这类框架一般底层都封装了 Servlet / Filter 之类的组件，它也是用这类组件去处理请求的，如图： 然后类似 Spring MVC 的框架的 Servlet 组件，就会根据你的请求路径，比如 /order 这种东西，去找到你代码中用来处理这个请求的 Controller 组件。那我们来思考一个问题，Tomcat是个什么东西？ 如果我们是把写好的系统放入 Tomcat 目录中，然后启动 Tomcat，此时我们启动的 Tomcat 本身就是一个 JVM 进程，因为 Tomcat 自己也是 Java 写的。所以要明确一个概念，就是 Tomcat 自己就是一个 JVM 进程，我们写好的系统只不过是一些代码而已，这些代码时一个一个的类，这些类被 Tomcat 加载到内存里去，然后由 Tomcat 来执行我们写的类。 既然如此，Tomcat 本身是如何去监听 8080 端口上收到的请求？其实，Tomcat 有自己的工作线程，大家要对 Tomcat 的工作线程这个概念有一个认识，即 Tomcat 有很多自己的工作线程，少则一两百个，多则三四百个也是可以的。 然后从 8080 端口上收到的请求都会均匀地分配给这些工作线程去处理，而这些工作线程收到请求之后，就负责调用 Spring MVC 框架的代码，Spring MVC 框架有负责调用我们自己写的代码，比如 Controller 之类的。所以最终运行起来原理如下图： 再回顾异常日志接着我们回过头看当时在线上系统的日志中发现的异常： 1Exception in thread "http-nio-8080-exec-1089" java.lang.OutOfMemoryError: Java heap space 这个时候理解起来就很简单了，http-nio-8080-exec-1089 这个说白了就是上图中的 Tomcat 工作线程，因为它是负责调用 Spring MVC 以及我们写的 Controller、Service、DAO 等一大堆的代码的，所以它发现运行的时候堆内存不够了，就会抛出堆内存溢出的异常了。 一个关键的 JVM 参数一旦我们发现线上系统发生了内存溢出的异常，第一步是看日志，具体看两点： 看是堆内存溢出，还是栈内存溢出，或者是 Metaspace 内存溢出。首先得确定一下具体的溢出类型 看是哪个线程代码运行的时候内存溢出了，因为 Tomcat 运行的时候不光有自己的工作线程，我们写的代码也可能创建一些线程出来 看完这两个东西之后，就得记得每个系统上线，必须设置一个参数：-XX:+HeapDumpOnOutOfMemoryError。这个参数会在系统内存溢出的时候导出来一份内存快照到我们指定的位置，接着排查和定位内存溢出问题，主要就得依托这个自动导出来的内存快照了。 对内存快照进行分析一般我们都是用 MAT 来分析内存快照，主要就是通过 MAT 来找到那些占据内存最大的对象。 通过内存快照分析我们发现占据内存最大的是大量的 byte[] 数组，一大堆 byte[] 数组就占据了大约 8G 左右的内存空间，而我们当时线上机器给 Tomcat 的 JVM 堆内存分配的也就是 8G 左右的内存而已。因此我们可以直接得出第一个结论：Tomcat 工作线程在处理请求的时候会创建大量的 byte[] 数组，大约有 8G 左右，直接把 JVM 堆内存占满了。 接着我们想知道到底是哪些 byte[] 数组在这里，因此我们通过 MAT 深入查看，发现大概是类似下面的一大堆 byte[] 数组： byte[10008192] @ 0x7aa800000 GET /order/v2 HTTP/1.0-forward… byte[10008192] @ 0x7aa800000 GET /order/v2 HTTP/1.0-forward… byte[10008192] @ 0x7aa800000 GET /order/v2 HTTP/1.0-forward… 当时看到了很多类似这样的数组，而且数组大小都是一致的 10MB，大概清点了一下，类似上面那样的数据，大概有 800 个左右，也就对应了 8G 的空间。 那这些数组时谁创建的？我们在 MAT 上可以继续查看一下这个数组时谁引用的，大致可以发现是 Tomcat 的类引用的，具体来说是类似下面这个类： 1org.apache.tomcat.util.threads.TaskThread 这个一看就是 Tomcat 自己的线程类，因此可以认为是 Tomcat 的线程创建了大量的 byte[] 数组，占据了 8G 的内存空间。 而我们发现 Tomcat 的工作线程大致有 400 个左右，也就是说每个 Tomcat 的工作线程都会创建 2 个 byte[] 数组，每个 byte[] 数组是 10MB 左右，最终就是 400 个 Tomcat 工作线程同时在处理请求，结果创建出来了 8G 内存的 byte[] 数组，进而导致了内存溢出。如图： 系统每秒的 QPS根据上面的分析，有可能一秒钟之内瞬间来了 400 个请求，导致 Tomcat 的 400 个工作线程全部上阵处理，每个工作线程在处理一个请求的时候，会创建 2 个数组，每个数组是 10MB，结果导致瞬间让 8G 的内存空间被占满。 但我们检查了系统的监控，发现每秒的请求并不是 400，而是 100。那么出现这种情况只有一种可能，就是每个请求处理需要 4 秒钟的时间。如果每秒来 100 个请求，但是每个请求处理完毕需要 4 秒钟的时间，那么在 4 秒内会导致有 400 个请求同时在处理，也就会导致 Tomcat 的 400 个工作线程都在工作，接着就会导致上述的情况。 另外，为什么 Tomcat 工作线程在处理一个请求的额时候会创建 2 个 10MB 的数组？通过检查 Tomcat 的配置文件，发现了一个配置 max-http-header-size: 10000000。有了这个东西，导致 Tomcat 工作线程在处理请求的时候会创建 2 个数组，每个数组的大小如上面配置就是 10MB。 为什么处理一个请求需要 4 秒钟为什么处理一个请求需要 4 秒钟。经过咨询得知这个问题是偶发性，不是每次处理请求都这样，平时处理一个请求也就几百毫秒的时间而已。这样就只能在日志里去找问题了，继续翻看事故发生的日志，发现日志中除了 OOM 以外，还有大量的服务请求超时的异常，类似下面： 1Timeout Exception.... 即，我们系统在调用其他系统的时候出现了大量的请求超时，看了一下调用超时的配置，发现负责这个系统的工程师将服务调用超时的时间设置为了刚好是 4 秒！也就是说，在这个时间里，远程服务自己故障了，导致我们的系统调用其他服务的时候是访问不通的，然后就会在配置好的 4 秒超时时间之后抛出异常，在这 4 秒钟内，工作线程会直接卡死在无效的网络访问上。 上图可以清楚看到，之所以每个请求需要处理 4 秒钟，是因为下游服务故障了，网络请求都是失败的，此时会按照设置好的 4 秒钟时间一直卡住 4 秒之后才会抛出 Timeout 异常，然后请求处理结束。这就是一个请求处理需要 4 秒钟的根本原因，进而导致 100 个请求的压力下，4 秒内积压 400 个请求同时在处理，导致 400 个工作线程创建了 800 个数组，每个数组 10MB 内存，耗尽了 8G 的内存，最终导致内存溢出。 对系统进行优化要解决上述问题，分析清楚原因之后，对症下药即可。 最核心的问题就是那个超时时间设置太长了，因此将超时时间改为 1 秒即可。这样的话，每秒 100 个请求过来，也就只有 200 个数组，占据 2G 内存，远远不会把堆内存塞满，然后 1 秒内这 100 个请求会全部超时，请求就处理结束了。下一秒再来 100 个请求又是新的一轮处理，不会每秒积压 100 个请求，4 秒积压 400 个请求同时处理了 另外，对 Tomcat 的那个参数，max-http-header-size，可以适当调节地小一些就可以了，这样 Tomcat 工作线程自身为请求创建的数组，不会占据太大的内存空间的。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 内存溢出的解决方案]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F20%2FJVM-%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[对于内存溢出，我们需要生成并分析一下 GC 日志，然后再让 JVM 自动 dump 出来内存快照，最后用 MAT 来分析一下这份内存快照，从内存快照里去找到内存溢出的原因。 Metaspace 内存区域溢出首先我们先看下面的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class Demo1 &#123; public static void main(String[] args) &#123; long counter = 0; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Car.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; if(method.getName().equals("run")) &#123; System.out.println("启动汽车之前，先进行自动的安全检查。。。。。。"); return methodProxy.invokeSuper(o, objects); &#125;else&#123; return methodProxy.invokeSuper(o, objects); &#125; &#125; &#125;); Car car = (Car) enhancer.create(); car.run(); System.out.println("目前创建了 " + (++counter) + " 个Car类的子类了"); &#125; &#125; static class Car &#123; public void run() &#123; System.out.println("汽车启动，开始行使。。。。。。"); &#125; &#125; static class SafeCar extends Car &#123; @Override public void run() &#123; System.out.println("汽车启动，开始行使。。。。。。"); super.run(); &#125; &#125;&#125; 我们用上面的代码来说明，不过需要在 JVM 参数中加入一些东西，以为我们要看一下 GC 日志和导出内存快照，如下： 1-XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m -XX:PrintGCDetails -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./ 注意，上面那个 HeapDumpPath 参数我给调整为当前项目的根目录下了，这样我们看的时候方便一些。 分析 GC 日志我们用上述 JVM 参数运行这段程序，项目下面会多了两个文件，一个是 gc.log，还有一个是 java_pid16056.hrof。当然不同的机器运行生成的 hrof 文件的名字是不太一样的，因为它会用你的 PID 进程 id 作为文件名字。 接着我们先来分析一下这个 gc.log，看一下它是如何往 Metaspace 区域里放入大量生成的类，然后出发 Full GC，接着回收 Metaspace 区域，回收后还是无法放下更多的类，接着才会抛出内存溢出的异常。然后我们再用 MAT 分析一下 OOM 的时候的内存快照，找 Metaspace 内存溢出的原因。 首先看下面一段 GC 日志： 10.716: [GC (Allocation Failure) 0.717: [ParNew: 139776K-&gt; 2677K(157248K), 0.0038770 secs] 139776K-&gt; 2677K(506816K),0.0041376 secs] [Times: user=0.03 sys=0.01, real=0.00 secs] 上面那段日志，这是第一次 GC，它本身是一个 Allocation Failure 的问题。即，它是在 Eden 区中分配对象时，发现 Eden 区内存不足，于是触发了一次 ygc。那这个对象是什么对象？ 回顾我们的代码，Enhancer 本身是一个对象，它是用来生成类的，Enhancer enhancer = new Enhancer()。接着我们基于每次 Enhancer 生成的类还会生成那个类的对象：Car car = (Car) enhancer.create()。因此上述代码不光是动态生成类，本身它也是对应很多对象的，因此你在 while(true) 循环里不停地创建对象，当然也会塞满 Eden 区。 上述日志中：[ParNew: 139776K -&gt; 2677K(157248K), 0.0038770 secs]，就是说在默认的内存分配下，年轻代一共可用空间是 150MB 左右，然后还包含了一点 Survivor 区域的大小。然后大概用到了 140MB 左右了，也就是 Eden 区塞满了，此时就触发 Allocation Failure，没 Eden 区的空间分配对象了，此时就触发 ygc 了。 接着下面这段日志： 10.771: [Full GC (Metadata GC Threshold) 0.771: [CMS: 0K-&gt; 2161 K(349568K), 0.0721349 secs] 20290K-&gt;2161 K(506816K),[Metaspace: 9201K-&gt;9201K(105881 6K)], 0.0722612 secs] [Times: user=0.12 sys=0.03, real=0.08 secs] 这就是 Full GC，而且通过 “Metadata GC Threshold” 清楚看到，是 Metaspace 区域满了，所以触发了 Full GC。这个时候继续看日志：20290K -&gt; 2161K(506816K)，这个就是说堆内存（年轻代 + 老年代）一共是 500MB 左右，然后有 20 MB 左右的内存被使用了，这个是年轻代用的。 然后 Full GC 会带着一次 Young GC，因此这次 Full GC 其实是执行了 ygc，所以回收了很多对象，剩下了 2161KB 的对象，这个大概就是 JVM 的一些内置对象了。然后直接就把这些对象放入老年代了：[CMS: 0K -&gt; 2161K(349568K), 0.0721349 secs]。这里明显说了，Full GC 带着 CMS 进行了老年代的 Old GC，结果人家本来是 0KB，然后从年轻代转移来了 2161KB 的对象，所以老年代变成 2161KB 了。 接着看日志：[Metaspace: 9201K -&gt; 9201K(1058816K)]。此时 Metaspace 区域已经使用了差不多 9MB 左右的内存了，此时明显离我们限制的 10MB 内存很接近了，所以触发了 Full GC，但是对 Metaspace GC 后发现类全部存活，因此还是剩余 9MB 左右的类在 Metaspace 里。 接着看下面的日志： 120.843: [Full GC (Last ditch collection) 0.843: [CMS: 2161K-&gt; 1217K(349568K), 0.01 64047 secs] 2161K-&gt; 1217K(506944K),0.843: [Full GC (Last ditch collection) 0.843: [CMS: 2161K-&gt; 1217K(349568K), 0.01 64047 secs] 2161K-&gt; 1217K(506944K),[Metaspace: 9201K-&gt; 9201K(105881 6K)], 0.0165055 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 这个又是一个 Full GC，注意这个 Last ditch collection。就是说，最后一次拯救机会了，因为之前 Metaspace 回收了一次但是没有类可以回收，所以新的类无法放入 Metaspace 了。所以最后试一试 Full GC，结果如下：[Metaspace: 9201K -&gt; 9201K(1058816K), 0.0165055 secs]。Metaspace 区域还是无法回收掉任何的类，几乎还是占满了我们设置的 10MB 左右。 12345678910111213140.860: [GC (CMS Initial Mark) [1 CMS-initial-mark: 1217K(349568K)] 1217K(506944K), 0.0002251 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]0.860: [CMS-concurrent-mark-start]0.878: [CMS-concurrent-mark: 0.003/0.018 secs] [Times: user=0.05 sys =0.01, real=0.02 secs]0.878: [CMS-concurrent- preclean-start]Heappar new generation total 157376K, used 6183K [0x0000005ffe00000, 0x000000060a8c0000, 0x0000000643790000)eden space 139904K，4% used [00000005f00000, 0x0000000600409d48, 0x00000006086a0000)from space 17472K，0% used [000000006086a0000, 0x00000006086a0000, 0x00000006097b0000)to space 17472K，0% used [00000006097b0000, 0x00000006097b0000, 000000060a8c0000)concurrent mark- sweep generation total 349568K, used 1217K [0000000643790000, 0000000658c0000,0x00000007ffe00000)Metaspaceused 9229K, capacity 10146K, committed 10240K, reserved 1058816Kclass space used 794K, capacity 841K, committed 896K, reserved 1048576K 接着 JVM 就退出了，退出的时候就打印出了当前内存的一个情况，年轻代和老年代几乎没占用，但是 Metaspace 的 capacity 是 10MB，使用了 9MB，无法再继续使用，所以触发了内存溢出。此时就会在控制台打印出如下的一些东西： 1234Caused by: java.lang.OutOfMemoryError: Metaspaceat java.lang.ClassLoader.defineClass1(Native Method)at java.lang.ClassLoader.defineClass(ClassLoaderjava:763)...11 more 明确抛出异常，说 OutOfMemoryError，原因就是 Metaspace 区域满了导致的。 分析内存快照当我们知道是 Metaspace 引发的内存溢出之后，可以把内存快照文件从线上机器拷回本地电脑，打开 MAT 工具进行分析，如下： 从这里可以看到实例最多的就是 AppClassLoader。为啥有这么多的 ClassLoader？一看就是 CGLIB 之类的东西在动态生成类的时候搞出来的，我们点击上图的 Detail 进去看看 为什么这里有一堆自己的 Demo1 中动态生成出来的 Car$$EnhancerByCGLIB 的类呢？看到这里就真相大白了，上图告诉了我们，是我们自己的哪个类搞出来了一大堆的动态生成的类，所以填满了 Metaspace 区域。所以此时直接去代码里排查动态生成类即可。 解决这个问题的办法也很简单，直接对 Enhancer 做一个缓存，只有一个，不要无限制地去生成类即可。 1234567891011121314151617181920212223private volatile Enhancer enhancer = null;public void doSomething() &#123; if(enhancer == null) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Car.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; if (method.getName().equals("run")) &#123; System.out.println("启动汽车之前，先进行自动的安全检查。。。。。。"); return methodProxy.invokeSuper(o, objects); &#125; else &#123; return methodProxy.invokeSuper(o, objects); &#125; &#125; &#125;); &#125; Car car = (Car) enhancer.create(); car.run();&#125; 栈内存溢出首先，栈内存溢出能根据之前的方法解决吗？其实，栈内存溢出跟堆内存是没有关系的，因为它的本质是一个线程的栈压入了过多方法调用的栈帧，比如几千次方法调用的几千个栈帧，此时就导致线程的堆内存不足，无法放入更多栈帧了。所以 GC 日志对你有用吗？ 没用。因为 GC 日志主要是分析堆内存和 Metaspace 区域的一些 GC 情况的，就线程的栈内存而言，它们不存在所谓的 GC。因为调用一个方法时在栈里压入栈帧，接着执行完整的方法，栈帧从栈里出来，然后一个线程运行完毕时，它的栈内存就没了。所以本身这块内存不存在所谓的 GC 和回收，调用方法就给栈分配内存，执行完方法就回收掉那个栈帧的内存。 内存快照呢？内存快照主要是分析一些内存占用的，同样是针对堆内存和 Metaspace 的，所以对线程的栈内存而言，也不需要借助这个东西。 示例代码12345678910111213public class Demo2 &#123; public static long counter = 0; public static void main(String[] args) &#123; work(); &#125; public static void work() &#123; System.out.println("目前是第 " + (++counter) + " 次调用方法"); work(); &#125;&#125; 使用的 JVM 参数如下： -XX:ThreadStackSize=1m -XX:+PrintGCDetails -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./ -XX:+UseParNewGC -XX:+UseConcMarkSweepGC 运行代码后分析异常报错信息的调用栈接着我们运行代码让它产生栈内存溢出的保存，如下： 实际上我们会在这里看到大段如上所示的异常，即，它会直接告诉你这个栈内存溢出的问题，是因为你拼命地调用 Demo2 这个类的 work() 方式时发生的。因此就定位栈内存溢出而言，我们定位和解决问题非常简单，你只要把所有的异常都写入本地日志文件，那么当你发现系统崩溃时，第一步就去日志里定位一下异常信息就知道了 堆内存溢出我们看下面的示例代码： 123456789101112public class Demo3 &#123; public static void main(String[] args) &#123; Long counter = 0L; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new Object()); System.out.println("当前创建了第" + (++counter) + "个对象"); &#125; &#125;&#125; 采用的 JVM 参数如下： -Xms10m -Xmx10m -XX:+PrintGCDetails -Xloggc:gc.log -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./ -XX:+UseParNewGC -XX:+UseConcMarkSweepGC 接着我们运行上述程序。 运行后的观察其实堆内存溢出的现象也是很简单的，在系统运行一段时间之后，直接会发现系统崩溃了，然后登陆到线上机器检查日志文件，先看为什么崩溃。 这就告诉我们是 Java 堆内存溢出了，而且他还给我们导出了一份内存快照。所以我们 GC 日志都不用分析了，因为堆内存往往对应着大量的 GC 日志，所以分析起来很麻烦。此时直接将线上自动导出的内存快照拷贝会本地电脑，用 MAT 分析即可。 用 MAT 分析内存快照使用 MAT 打开内存快照之后会看到下图： 这次 MAT 比较简单，直接在内存泄露报告中告诉我们内存溢出原因只有一个，只有上面哪一个问题，因为它没提示任何其他的问题。 我们看这句：The thread java.lang.Thread @ 0x7bf6a9a98 main keeps local variables with total size 7203536(92.03%) bytes。这个意思就是 main 线程通过局部变量引用了 7203536 个字节对象，大概是 7MB左右。考虑到我们总共就给堆内存 10MB，所以 7MB 基本上就已经到极限了，是差不多的。 接着看：The memory is accumulated in one instance of &quot;java.lang.Object[]&quot; loaded by &quot;&lt; system class loader &gt;&quot;。这句话的意思就是内存都被一个对象占用了，就是 java.lang.Object[]。我们不知道这个是什么东西，所以点击 Details 继续往下看： 在 Details 里我们能看到这个东西，也就是占用了 7MB 内存的 java.lang.Object[]，它里面的每个元素在这里都有，我们看到的是一大堆的 java.lang.Object。这些 java.lang.Object 不就是我们在代码里创建的吗？至此就很清楚了，我们知道是一大堆 Object 对象占用了 7MB 的内存导致了内存溢出。 接着就是要知道这些对象是怎么创建出来的，我们看下图： 这个是说可以看看创建那么多对象的线程，它的一个执行栈，这样我们就知道这个线程执行什么方法的时候创建了一大堆的对象。 大家看上面的调用栈，在 Demo3.main() 方法中，一直在调用 ArrayList.add() 方法，然后此时直接引发了内存溢出。所以我们只要在对应代码里看一下，立马就知道怎么回事了。接下来优化对应的代码即可，就不会发生内存溢出了。 总结堆内存溢出的问题如何分析和定位？一个是必须在 JVM 参数中加入自动导出内存快照，一个是到线上看一下日志文件里的报错，如果是堆溢出，立马用 MAT 分析内存快照。 MAT 分析的时候，先看占用内存最多的对象是谁，然后分析那个线程的调用栈，接着就可以看到是哪个方法引发的内存溢出了，接着优化代码即可。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ - 基于延迟消息机制的大量订单的定时退款扫描]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F18%2FRocketMQ-%E5%9F%BA%E4%BA%8E%E5%BB%B6%E8%BF%9F%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6%E7%9A%84%E5%A4%A7%E9%87%8F%E8%AE%A2%E5%8D%95%E7%9A%84%E5%AE%9A%E6%97%B6%E9%80%80%E6%AC%BE%E6%89%AB%E6%8F%8F%2F</url>
    <content type="text"><![CDATA[我们来看一个订单退款扫描的问题。一个正常的电商购物流程，一般来说我们现在作为用户在一个电商 APP 上都会选择一些商品加入购物车，然后对购物车里选择的一些商品统一下一个订单，此时后台的订单系统会在订单数据库中创建一个订单。 但是我们下了一个订单之后，虽然订单数据库里会有一个订单，订单的状态却是 “待支付” 状态，因此此时你还没有支付这个订单，我们的订单系统其实也在等待用户完成这个订单的支付 这里就有两种可能了，一种可能是用户下单之后立马就支付掉了，那么接着订单系统可以走后续的流程，比如通过 MQ 发送消息通知优惠券系统给用户发优惠券，通知仓储系统进行调度发货等等。另外一种可能就是用户下单之后，没有支付订单。在实际情况中，APP 的大量用户每天会下很多订单，但是不少订单可能是一直没有进行支付的，可能它下单之后犹豫了，也可能是忘记支付了。 所以一般订单系统都必须设置一个规则，当一个订单下单之后，超过一定时间，比如 30 分钟没有支付，那么久必须订单系统自动关闭这个订单，后续你如果要购买这个订单里的商品，就得重新下单。 可能你的订单系统就需要有一个后台线程，不停地扫描订单数据库里所有的未支付状态的订单，如果它超过 30 分钟还没支付，那么就必须自动把订单状态更新为 “已关闭” 但是这里就出现了一个问题，就是订单系统的后台线程必须要不停地扫描各种未支付的订单，这种实现方式并不是很好。一个原因是未支付订单状态的订单可能是比较多的，然后你需要不停地扫描它们，可能每个未支付状态的订单要被扫描 N 多遍，才会发现它已经超过 30 分钟没支付了。 另一个是很难去分布式并行扫描你的订单。因为假设你的订单数据特别多，然后你打算用多台机器部署订单扫描服务，但是每天机器扫描哪些订单？怎么扫描？什么时候扫描？都是一系列的麻烦问题 因此针对这种场景，MQ 里的延迟消息就登场了。它特别适合在这种场景里使用，而且再实际项目中，MQ 的延迟消息使用的往往是很多的。 所谓的延迟消息，意思是我们订单系统在创建了一个订单之后，可以发送一条消息到 MQ 里去，我们指定这条消息是延迟消息，比如要等到 30 分钟之后，才能被订单扫描服务给消费到。 这样当订单扫描服务在 30 分钟后消费到了一条消息之后，就可以针对这条消息的信息，去订单数据库里查询这个订单，看看它在创建过后都过了 30 分钟了，此时它是否还是未支付状态？如果此时订单还是未支付状态，那么就可以关闭它，否则订单如果已经支付了，就什么都不用做了。如图： 这种方式就比你用后台线程扫描订单的方式要好得多，一个是对每个订单你只会在它创建 30 分钟后查询它一次而已，不会反复扫描订单多次。另外就是如果你的订单数量很多，你完全可以让订单扫描服务多部署几台机器，然后对 MQ 中的 Topic 可以多指定一个 Mess阿甘Q，这样每个订单扫描服务的机器作为一个 Consumer 都会处理一部分订单的查询任务。 所以 MQ 的延迟消息，是非常常用并且实用的一个功能。 RocketMQ 的延迟消息的代码实现接下来我们看一下 RocketMQ 中对延迟消息的代码实现。其实 RocketMQ 对延迟消息的支持是很好的，实现起来也非常容易，我们先看发送延迟消息的代码示例： 1234567891011121314151617181920212223public class ScheduledMessageProducer &#123; public static void main(String[] args) throws Exception &#123; // 这是订单系统的生产者 DefaultMQProducer producer = new DefaultMQProducer("OrderSystemProducerGroup");\ // 启动生产者 producer.start(); Message message = new Message( "CreateOrderInformTopic", // 这是创建订单通知 Topic orderInfoJSON.getBytes() // 这是订单信息的 json 串 ); // 这里设置了消息为延迟消息，延迟级别为 3 message.setDelayTimeLevel(3); // 发送消息 producer.send(message); &#125;&#125; 大家看上面的代码，其实发送延迟消息的核心，就是设置消息的 delayTimeLevel，也就是延迟级别。 RocketMQ 默认支持一些延迟级别如下： 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 所以上面代码中设置延迟级别为 3，意思就是延迟 10s，你发送出去的消息，会过 10s 被消费者获取到。那么如果是订单延迟扫描场景，可以设置级别为 16，也就是对应上面的 30 分钟 接着我们看看一个消费者，比如订单扫描服务，正常它会对每个订单创建的消息，在 30 分钟以后才获取到，然后去查询订单状态，判断是否是未支付的订单，就自动关闭这个订单。 12345678910111213141516171819202122232425262728293031323334public class ScheduledMessageConsumer &#123; public static void main(String[] args) throws Exception &#123; // 这里扫描服务的消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("OrderScanServiceConsumer"); // 订阅订单创建通知 Topic consumer.subscribe("CreateOrderInformTopic", "*"); // 注册消息监听者 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage( List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context) &#123; for(MessageExt message : messages) &#123; // 这里打印一下消息的存储时间到消费时间的差值 // 大概就是我们设置的延迟级别的时间 System.out.println("Receive message[msgId" + message.getMsgId() + "]" + (System.currentTimeMills() - message.getStoreTimestamp()) + "ms later"); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者 consumer.start(); &#125;&#125; 把延迟消息的使用搞明白之后，大家以后再自己的系统中就可以使用延迟消息去支持一些特殊的业务场景了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ - 消息乱序]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F16%2FRocketMQ-%E6%B6%88%E6%81%AF%E4%B9%B1%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[案例分析大数据团队需要获取订单数据库中的全部数据，然后将订单数据保存一份在自己的大数据存储系统中，比如 HDFS、Hive、HBASE 等。接着基于大数据技术对这些数据进行计算。 如果让大数据系统自己跑负责的大 SQL 在订单系统的数据库上来出一些数据报表，是会严重影响订单系统的性能的，所有采用了基于 canal 这样的中间件去监听订单数据库的 binlog，就是一些增删改查的日志，然后把这些 binlog 发送到 MQ 里去。接着大数据系统自己从 MQ 里获取 binlog，落地到自己的大数据存储中去，然后对自己的存储中的数据进行计算得到数据报表即可。如图： 大数据团队遇到的问题：数据指标错误这个方案运行一段时间后遇到了一些奇怪的问题。他们通过这个方案计算出来的数据报表，被发现很多数据指标都是错误的。于是他们就展开了排查，在对自己的大数据存储中的订单数据与订单数据库中的订单数据进行了一次比对之后，发现他们那儿的一些订单数据是不对的。比如在订单数据库中一个订单的字段 A 的值是 100，结果在大数据存储中的一个订单的字段 A 的值是 0 如果两边的订单数据的字段值不一致的话，必然导致最终计算出来的数据报表的指标是错误的。 订单数据库的 binlog 消息乱序针对这个问题，在系统中打印了很多的日志，观察了几天，发现订单数据库的 binlog 在通过 MQ 同步的过程中，出现了奇怪的消息乱序的现象。 比如订单系统在更新订单数据库的时候，有两条 SQL 语句： 12insert into order values(xx, 0);update order set xxvalue = 100 where id = xxx; 就是先插入一条数据，刚开始它一个字段的值是 0，接着更新它的一个字段的值是 100。然后这两条SQL 语句是对应是两个 binlog，也就是两个更新日志，一个 binlog 是 insert 语句的，一个 binlog 是 update 语句的，这个 binlog 会进入到 MQ 中去，然后大数据系统从 MQ 获取出来 binlog 的时候，居然是先获取出来了 update 语句的 binlog，然后再获取了 insert 语句的 binlog。 即，这个时候会先执行更新操作，但是此时数据根本不存在，没法进行更新，接着执行插入操作，也就是插入一条字段值为 0 的订单数据进去，最后大数据存储中的订单记录的字段值就是0 正是这个消息乱序的原因，导致了大数据存储中的数据都错乱了。 基于 MQ 来传输数据为什么会出现消息乱序这个原因很简单。我们之前讲过，可以给每个 Topic 指定多个 MessageQueue，然后你写入消息的时候，其实是会把消息均匀分发给不同的 MessageQueue 的。 比如我们在写入 binlog 到 MQ 的时候，可能会把 insert binlog 写入到一个 MessageQueue 里去，update binlog 写入到另外一个 MessageQueue 里去。 接着大数据系统在获取 binlog 的时候，可能会部署多台机器组成一个 Consumer Group，对于 Consumer Group 中的每台机器都会负责消费一部分 MessageQueue 的消息，所以可能一台机器上 ConsumeQueue01 中获取 insert binlog，一台机器从 ConsumeQueue02 中获取 update binlog。 上图中，是两台机器上的大数据系统并行地去获取 binlog，所以完全有可能是其中一个大数据系统先获取到了 update binlog 去执行，此时存储中没有数据，自然是没法更新的。然后另外一个大数据系统再获取到 insert binlog 去执行插入操作，最终导入只有一个字段值为 0 的订单数据。 消息乱序实际上，在使用 MQ 的时候出现消息乱序是非常正常的一个问题，因为我们原本有顺序的消息，完全有可能分发到不同的 MessageQueue 中去，然后不同的机器上部署的 Consumer 可能会用混乱的顺序从不同的 MessageQueue 里获取消息然后处理。所以在实际使用 MQ 的时候，我们必须要考虑到这个问题。 解决消息乱序问题上面我们分析了订单数据库同步过程中的消息乱序问题产生的根本原因，最关键的是，属于同一个订单的 binlog 进入不同的 MessageQueue，进而导致一个订单的 binlog 被不同机器上的 Consumer 来获取和处理。 让属于同一个订单的 binlog 进入一个 MessageQueue所以要解决这个消息乱序的问题，就得想办法让一个订单的 binlog 进入到一个 MessageQueue 里去。 举个例子，比如对一个订单，我们先后执行了 insert、update 两条 SQL 语句，也对对应了 2 个 binlog。那么我们就要想办法让这个订单的 2 个 binlog 都直接进入到 Topic 下的一个 MessageQueue 里去。我们可以怎么做？可以根据订单 id 来进行判断，我们可以往 MQ 里发送 binlog 的时候，根据订单 id 来判断一下，如果订单 id 相同，你必须保证它进入同一个 MessageQueue 我们可以采用取模的方法。比如有一个订单 id 是 1100，那么他可能有 2 个 binlog，对着两个 binlog，我们用订单 id = 1100 对 MessageQueue 的数量进行取模，比如 MessageQueue 一共有 15 个，那么此时 1100 对 15 取模，就是 5。即，凡是订单 id = 1100 的binlog，都应该进入位置为 5 的 MessageQueue 中去。 通过这个方法，我们就可以让一个订单的 binlog 都按照顺序进入到一个 MessageQueue 中去。如图： 获取 binlog 的时候也要有序接着，只要一个订单的 binlog 都进入一个 MessageQueue 就搞定这个问题了吗？显示不是的，我么要考虑一个问题，就是我们的 MySQL 的数据库的 binlog 是有顺序的。 比如，订单系统对订单数据执行两条 SQL，先是 insert 语句，然后是 update 语句，那么此时 MySQL 数据库自己必然是在磁盘文件里按照顺序写入 insert 语句的 binlog，然后写入 update 语句的 binlog。当我们从 MySQL 数据中获取它的 binlog 的时候，此时也必须是按照 binlog 的顺序来获取的，也就是说比如 Canal 作为一个中间件从 MySQL 那里监听和获取 binlog，那么当 binlog 传输到 Cancel 的时候，也必然是有先后顺序的 接着我们将 binlog 发送给 MQ 的时候，必须将一个订单的 binlog 都发送到一个 MessageQueue 里去，而且发送过去的时候，也必须是严格按照顺序来发送的。只有这样，最终才能让一个订单的 binlog 进入同一个 MessageQueue，而且还是有序的。如图： Consumer 有序处理一个订单的 binlog接着，一个 Consumer 可以处理多个 MessageQueue 的消息，但是一个 MessageQueue 只能交给一个 Consumer 来进行处理，所以一个订单的 binlog 只会有序地交给一个 Consumer 来进行处理。如图： 消息处理失败这样就万事大吉了吗？绝对不是，这样说过，在 Consumer 处理消息的时候，可能会因为底层存储挂了导致消息处理失败，此时可以返回 RECONSUME_LATER 状态，然后 Broker 会过一会自动给我们重试。但是这个方案是绝对不可以用在我们的有序消息中的。因为如果你的 consumer 获取到订单的一个 insert binlog，结果处理失败了，此时返回 RECONSUME_LATER，那么这条消息会进入重试队列，过一会才会交给你重试。 但是此时 Broker 会直接把下一条消息，也就是订单的 update binlog 交给你处理，此时万一你执行成功了，就根本没有数据可以更新。又会出现消息乱序的问题。 所以对于有序消息的方案中，如果你遇到消息处理失败的场景，就必须返回 SUSPEND_CURRENT_QUEUE_A_MOMENT 这个状态，意思是先等一会，一会再继续处理这批消息，而不能把这批消息放入重试队列去，然后直接处理下一批消息。 有序消息方案与其他消息方案的结合如果你一定要求消息是有序的，那么必须得用上述的有序消息方案，同时对这个方案，如果你要确保消息不丢失，那么可以和消息零丢失方案结合起来。如果你要避免消息重复处理，还需要在消费者那里处理消息的时候，去看一下，消息如果已经存在就不能重复插入等等。 同时还需要设计自己的消息处理失败的方案，也就是不能让消息进入重试队列，而是暂停等待一会，继续处理这批消息。 RocketMQ 的顺序消息机制的伪代码实现首先要实现消息顺序，必须让一个订单的 binlog 都进入一个 MessageQueue 中，此时我们可以写如下的代码： 12345678910111213141516SendResult sendResult = producer.send( message, new MessageQueueSelector() &#123; @Override public MessageQueue select( List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Long orderId = (Long) arg; // 根据订单id选择发送queue long index = id % mqs.size(); // 用订单id对MessageQueue 数量取模 return mqs.get((int) index); //返回一个MessageQueue &#125; &#125;, orderId //这里传入订单id); 上面代码中，我们看到关键因素有两个，一个是发送消息的时候传入一个 MessageQueueSelector，在里面你要根据订单 id 和 MessageQueue 数量去选择这个订单 id 的数据进入哪个 MessageQueue。同时在发送消息的时候除了带上消息自己以外，还要带上订单 id，然后 MessageQueueSelector 就会根据订单 id 去选择一个 MessageQueue 发送过去，这样的话，就可以保证一个订单的多个 binlog 都会进入一个 MessageQueue 中去。 消费者如何保证按顺序来获取一个 MessageQueue 中的消息接着，就是消费者如何按照顺序，来获取一个 MessageQueue 中的消息。 12345678910111213141516171819202122consumer.registerMessageListener( new MessageListenerOrderly() &#123; @Override public ConsumeOrderlyStatus consumeMessage( List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); try &#123; for(MessageExt msg : msgs) &#123; // 对有序的消息进行处理 &#125; return ConsumerOrderlyStatus.SUCCESS; &#125;catch(Exception e) &#123; // 如果消息处理有问题 // 返回一个状态，让它暂停一会再继续处理这批消息 return SUSPEND_CURRENT_QUEUE_A_MOMENT; &#125; &#125; &#125;); 在上面的代码中，有一个点要注意一下。我们使用的是 MessageListenerOrderly 这个东西，它里面有 Orderly 这个名词，也就是说，Consumer 会对每一个 ConsumeQueue，都仅仅用一个线程来处理其中的消息。 比如对 ConsumeQueue01 中的订单 id = 1100 的多个 binlog，会交给一个线程来按照 binlog 顺序依次处理。否则如果 ConsumeQueue01 中的订单 id = 1100 的多个 binlog 交给 Consumer 的多个线程来处理的话，那还是会有消息打乱的问题。 基于 RocketMQ 的数据过滤机制，提升订单数据库同步的处理效率我们讲完了消息顺序方案，现在我们基于订单数据库同步的这个场景，来简单看一下如何对混杂在一起的数据进行过滤的方案。 我们都知道，一个数据库可能包含很多表的数据，比如订单数据库，它里面除了订单信息表以外，可能还包含很多其他的表。所以我们在进行数据库 binlog 同步的时候，很可能是把一个数据库里所有表的 binlog 都推送到 MQ 里去的。 所以在 MQ 的某个 Topic 中，可能是混杂了订单数据的几个甚至十几个表的 binlog 数据，不一定仅仅包含我们想要的表的 binlog 数据。 处理不关注的表 binlog，是很浪费时间的此时假设我们的大数据系统仅仅关注订单数据库中的表 A 的 binlog，并不关注其它表的 binlog，那么大数据系统可能需要在获取到所有表的 binlog 之后，对每一条 binlog 判断一下，是否是表 A 的binlog？如果不是表 A 的binlog，就直接丢弃不处理；如果是表 A 的binlog，才会去进行处理。 但是这样，必然会导致大数据系统处理很多不关注的表的 binlog，也会很浪费时间，降低效率。 发送消息的时候，给消息设置 tag 和属性针对这个问题你，我们可以采用 RocketMQ 支持的数据过滤机制，来让大数据系统仅仅关注它想要的表的 binlog 数据即可。 我们在发送消息的时候，可以给消息设置 tag 和属性，如下： 123456789Message msg = new Message( "TopicOrderDbData", // 这是我们订单数据库写入的 Topic "TableA", // 这是这条数据的 tab，可以是表的名字 ("binlog").getBytes(RemotingHelper.DEFAULT_CHARSET) // 这是一条 binlog 数据);// 我们可以给一条消息设置一些属性msg.putUserProperty("a", 10);msg.putUserProperty("b", "abc"); 上面的代码清晰地展示了我们发送消息的时候，其实是可以给消息设置 tag、属性等多个附加的消息的。 消费数据的时候根据 tag 和属性进行过滤接着我们可以在消费的时候根据 tag 和 属性进行过滤，比如我们可以通过下面的代码去指定，我们只要 tag = TableA 和 tag = TableB 的数据。 1consumer.subscribe("TopicOrderDbData", "TableA || TableB"); 或者我们也可以通过下面的语法去指定，我们要根据每条消息的属性的值进行过滤，此时可以支持一些语法，比如： 12consumer.subscribe("TopicOrderDbData", MessageSelector.bySql("a &gt; 5 AND b = 'abc'")); RocketMQ 还是支持比较丰富的数据过滤语法的，如下： 数值比较，比如：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，= 字符比较，比如：=，&lt;&gt;，IN IS NULL 或者 IS NOT NULL 逻辑符号 AND，OR，NOT 数值，比如：123，3.1415 字符，比如：’abc’，必须用单引号包裹起来 NULL，特殊的常量 布尔值，TRUE 或 FLASE 基于数据过滤减轻 Consumer 负担在使用 MQ 的时候，如果 MQ 里混杂了大量的数据，可能 Consumer 仅仅对其中一部分数据感兴趣，此时可以在 Consumer 端使用 tag 等数据过滤语法，过滤出自己感兴趣的数据来消费。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ-重发机制]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F15%2FRocketMQ-%E9%87%8D%E5%8F%91%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[背景示例今天客户给技术团队反馈了一个问题，说是有用户在支付一个订单之后，一下子收到了多个优惠券，本来按照规则只应该有一个优惠券的。也就是说，我们给用户重复发放了一个优惠券 优惠券系统重复消费了一条消息目前订单系统已经跟各个系统进行了解耦，也就是说当订单支付成功之后，会发送一条消息到 MQ 里去，然后红包系统从里面获取消息派发红包，优惠券系统从里面获取消息派发优惠券，其他系统也是同理。 通过查看日志发现，优惠券系统对同一个订单支付成功的消息处理了两次，就导致给用户重复发放了两张优惠券。为什么优惠券会对同一个消息重复处理两次？ 订单系统发送消息到 MQ 的时候会重复吗首先，我们的订单系统在收到一个支付成功的通知之后，它在发送消息到 MQ 的时候，会重发把一个消息发送两次吗？这是有可能的。 首先，假设用户在支付成功之后，我们的订单系统收到了一个支付成功的通知，接着它就向 MQ 发送了一条订单支付成功的消息。但是可能因为不知道什么原因，你的订单系统处理的速度有点慢。然后可能因为你的订单系统处理的速度有点慢，这就导致支付系统跟你订单系统之间的请求出现了超时，此时有可能支付系统再次重试调用了你订单系统的接口去通知了，然后你的订单系统这个时候可能有一次推送了一条消息到 MQ 里去，相当于是一个订单支付成功的消息，你重复推送了两次到 MQ。 此时相当于是 MQ 里就会对一个订单的支付成功消息，总共有两条。 如果订单系统重复推送了两次支付成功消息的 MQ，MQ 里对一个订单有两条重复的支付成功消息，优惠券必然会消费到一个订单的两条重复的支付成功消息，也会针对这个订单用户重复地派发两个优惠券。 因此，如果出现了接口超时等问题，可能会导致上游的支付系统重试调用订单系统的接口，进而导致订单系统对一个消息重复发送两条到 MQ 里去。 订单系统自己重复发送消息假设支付系统没有对一个订单重复调用你的订单系统的接口，而是你订单系统自己可能就重复发送消息到 MQ 里去。假设我们的订单系统为了保证消息一定能投递到 MQ 里去，因此采用了重试的代码，如下面的代码片段，如果发现 MQ 发送有异常，则会进行几次重试。 12345678910111213try &#123; // 执行订单本地事务 orderService.finishOrderPay(); // 发送消息到 MQ 去 producer.sendMessage();&#125;catch(Exception e) &#123; // 如果发送消息失败了，进行重试 for(int i = 0; i &lt; 3; i++) &#123; // 重试发送消息 &#125; // 如果多次充实发送消息之后，还是不行，回滚本地订单事务 orderService.rollbackOrderPay();&#125; 但是这种重试的方式 ，其实是一把双刃剑，因为正是这个重试可能导致消息重复发送。我们来考虑一个情况，假设你发送一条消息到 MQ 了，其实 MQ 是已经收到这条消息了，结果 MQ 返回响应给你的时候，网络有问题了超时了，就是你没能及时收到 MQ 返回给你的响应。但是，此时 MQ 里其实是已经有你发送过去的消息了，只不过它返回给你的响应没能给到你而已。 这个时候，你的代码里可能会发现一个网络超时的异常，然后你就会进行重试再次发送这个消息到 MQ 去，然后 MQ 会收到一条一模一样的消息，进而导致你的消息重复发送了。 所以这种重试代码大家在使用的时候要小心，因为它还是有一定的概率会导致你重发消息的。 优惠券系统重复消费一条消息接着我们继续，即使你没有重复发送消息到 MQ，哪怕 MQ 里就一条消息，优惠券系统也有可能会重复进行消费。 假设你的优惠券系统拿到一条订单支付成功的消息，然后都已经进行处理了，也就是说都已经对这个订单发了一张优惠券了，这个时候它应该返回一个 CONSUME_SUCCESS 的状态，然后提交消费进度 offset 到 broker 的。 但是，你刚发完优惠券，还没来得及提交消息 offset 到 broker，优惠券系统就进行了一次重启，这是因为你没提交这条消息的 offset 给 broker，broker 并不知道你已经处理了这条消息，然后优惠券系统重启之后，broker 就会再次把这条消息交给你，让你再一次进行处理，然后你会再一次发送一张优惠券，导致重复发送了两次优惠券。 消息重复问题实际上，对类似优惠券系统这样的业务系统，一般会频繁地更新代码，可能每隔几天就需要重启一次系统进行代码的更新。所以你重启优惠券系统的时候，可能有一批消息刚处理完，还没来得及提交 offset 给 broker，然后你重启之后就会再一次重复处理这批数据，这种情况是比较常见的。 另外就是对于系统之间的调用，有的时候出现超时和重试的情况也是很常见的，所以你负责发消息到 MQ 的系统，很可能时不时地出现一次超时，然后被别人重试调用你的接口，你可能会重复发送一条消息到 MQ 里去，这也是很常见的。 引入幂等性机制要解决上述问题，我们就要先引入一个概念，叫做幂等性机制。这个幂等性机制，就是用来避免对同一个请求或者同一条消息进行重复处理的机制。幂等，就是比如你有一个接口，然后如果别人对一次请求重试了多次，来调用你的接口，你必须保证自己系统的数据是正常的，不能多出来一些重复的数据，这就是幂等性的意思。 发送消息到 MQ 的时候如何保证幂等性当我们的订单系统发送消息到 MQ 的时候需要保证幂等性吗？订单系统的接口有可能被重复调用导致发送重复的消息到 MQ 去，也可能有重试机制导致发送重复的消息到 MQ。那我们应该怎样避免这种情况？ 业务判断法业务判断法。也就是说你的订单系统必须要知道自己到底是否发送过消息到 MQ 去，消息到底是否已经在 MQ 里了。 例如，当支付系统重试调用你的订单系统的接口时，你需要发送一个请求到 MQ 去，查询一下当前 MQ 里是否存在针对这个订单的支付消息？如果 MQ 告诉你，针对 id = 1000 这个订单的支付成功消息，MQ 已经有了，那么订单系统可以不要再次发送这条消息到 MQ 去了。 这个业务判断法的核心在于，你的消息肯定是存在于 MQ 里的，到底发没发送过，只有 MQ 知道，如果没发送过这个消息，MQ 肯定没有这个消息，如果发送过这个消息，MQ 里就有这个消息。 所以当你的订单系统的接口被重试调用的时候，你这个接口上来就应该发送请求到 MQ 里查询一下，如果在 MQ 中已经存在，那就不再重复发送消息了。 基于 Redis 缓存的幂等性机制第二种方法，就是状态判断法。 这个方法的核心在于，你需要引入一个 Redis 缓存来存储你是否发送过消息的状态，如果你成功发送了一个消息到 MQ 里去，你得在 Redis 缓存里写一条数据，标记这个消息已经发送过。 那么当你的订单接口被重读调用的时候，你只要根据订单 id 去 Redis 缓存里查询一下，这个订单的支付消息是否已经发送给 MQ 了，如果发送过了，就别再次发送了。 其实两种幂等性机制都是很常用的，但是，基于 Redis 的状态判断法，有可能没办法完全做到幂等性。例如，你的支付系统发送请求给订单系统，然后已经发送消息到 MQ 去了，但是此时订单系统突然崩溃了，没来得及把消息发送的状态写入 Redis。这个时候如果你的订单系统在其他机器上部署了，或者是它重启了，那么这个时候订单系统被重试调用的时候，它去找 Redis 查询消息发送状态，会以为消息没发送过，然后会再次发送重复消息到 MQ 去。 有没有必要在订单系统环节保证消息不重复发送在我们这个场景中，如果在订单系统要保证消息不重复发送，上面讲的两种方案，其实都不是太好。因为 RocketMQ 虽然是支持你查询某个消息是否存在，但是在这个环节你直接从 MQ 查询消息是没这个必要的，它的性能也不是太好，会影响你的接口的性能。 另外基于 Redis 的消息发送状态的方案，在极端情况下还是没法 100% 保证幂等性，所以也不是特别好的一个方案。所以在这里建议是不用在这个环节保证幂等性，也就是我们可以默许它可能会发送重复的消息到 MQ 里去。 优惠券系统如何保证消息处理的幂等性接着我们来看优惠券系统假设会拿到重复的消息，那么如何保证消息处理的幂等性？这个就比较简单了，直接基于业务判断法就可以了，因为优惠券每次拿到一条消息后会给用户发一张优惠券，实际上核心就是在数据库里给用户插入一条优惠券记录。 那么如果优惠券系统从 MQ 那里拿到一个订单的两条重复支付成功消息，这个时候它只要先去优惠券数据库中查询一下，比如对订单 id = 1000 的订单，是否已经发放过优惠券了，如果有的话，就不要重复发券了。通过这个业务判断的方法，就可以简单高效地避免消息的重复处理了。 MQ 消息幂等性的方案总结一般来说，对于 MQ 的重复消息问题而言，我们往 MQ 里重复发送一些消息其实还是可以接收的，因为 MQ 里有许多条重复消息，它不会对系统的核心数据直接造成影响，但是我们关键要保证的，是你从 MQ 里获取消息进行处理的时候，必须保证消息不能重复处理。 要保证消息的幂等性，优先推荐的其实还是业务判断法，直接根据你的数据存储中的记录来判断这个消息是否已经处理过，如果处理过，就不需要再处理了。因为，基于 Redis 的消息发送状态的方案，在一些极端情况下还是无法保证幂等性的。 死信队列解决数据库宕机问题上述我们已经分析和解决了 MQ 实践使用过程中可能存在的消息丢失问题和消息重复问题，现在假设我们可以基本确保 MQ 的消息不丢失，同时不会对消息进行重复处理，在正常流程下，基本没啥问题。 假设我们的 MQ 使用过程中都没问题，但是如果我们的优惠券系统的数据库宕机了呢？这个时候，就会导致我们从 MQ 里获取到消息之后是没办法进行处理的。现在我们对这个实际的生产场景进行分析。 数据库宕机的时候，可以返回 CONSUME_SUCCESS 吗我们看下面的代码片段，可以看到，我们注册了一个监听器回调函数，当 Consumer 获取到消息之后，就会交给我们的函数来处理。 123456789consumer.registerMessageListener(new MessageListenerConcurrently() &#123; public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; // 在这里对获取到的 msgs 订单消息进行处理 // 比如增加积分，发送优惠券，通知发货等等 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;) 上述代码返回 CONSUME_SUCCESS，那么 Consumer 就知道这批消息处理完成了，就会提交这批消息的 offset 到 broker 去，然后下次就会继续从 broker 获取下一批消息来处理。 但是如果此时我们在上面的回调函数中，对一批消息发优惠券的时候，因为数据库宕机了，导致优惠券发放逻辑无法完成，此时我们还能返回 CONSUME_SUCCESS 状态码？如果你返回的话，下一次就会处理下一批消息，但是这批消息其实没处理成功，此时必然导致这批消息就丢失了。 消息处理有异常，可以返回 RECONSUME_LATER 状态实际上如果我们因为数据库宕机等问题，对这批消息的处理是异常的，此时没法处理这批消息，我们就应该返回一个 RECONSUME_LATER 状态。它的意思是，我现在没法完成这批消息的处理，你稍后过段时间再次给我这批消息让我重试一下。 所以，我们应该改成如下的代码： 123456789101112131415consumer.registerMessageListener(new MessageListenerConcurrently() &#123; public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; try &#123; // 在这里对获取到的 msgs 订单消息进行处理 // 比如增加积分，发送优惠券，通知发货等等 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; catch(Exception e) &#123; // 如果因为数据库宕机等问题，对消息处理失败了 // 此时返回一个稍后重试消费的状态 return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; &#125;&#125;) RocketMQ 是如何让你进行消费重试的RocketMQ 在收到你返回的 RECONSUME_LATER 状态之后，是如何让你进行消费重试的？简单说，RocketMQ 会有一个针对你这个 ConsumerGroup 的重试队列。如果你返回了 RECONSUME_LATER 状态，它会把你这批消息放到你这个消费组的重试队列中去。 比如你的消费组的名称是 “VoucherConsumerGroup”，意思是优惠券系统的消费组，那么它会有一个 “%RETRY%VoucherConsumerGroup” 这个名字的重试队列。如图： 然后过一段时间之后，重试队列中的消息会再次发送给我们，让我们进行处理。如果再次失败，又返回了 RECONSUME_LATER，那么会再过一段时间让我们来处理，默认最多是重试 16 次。每次重试之间的间隔时间是不一样的，这个间隔时间可以进行如下配置： 1messageDelayLevel = 1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h 上面这段配置的意思是，第一次重试是 1秒 后，第二次重试是 5秒 后，第三次重试是 10秒 后，第四次重试是 30秒 后，第五次重试是 1分钟 后，以此类推，最多重试 16 次。 连续重试 16 次还是无法处理消息如果在 16次 重试范围内消息处理成功了，自然没问题，但是如果你对一批消息重试了 16 次还是无法成功处理，这个时候就需要另外一个队列了，叫死信队列。所谓的死信队列，就是死掉的消息就放进这个队列里。 什么是死掉的消息？就是一批消息交给你处理，你重试了 16 次还是一直没处理成功，就不要继续重试这批消息了，你就认为他们死掉了就可以了。然后这批消息就会自动进入死信队列。死信队列的名字是 “%DLQ%VoucherConsumerGroup”。我们在 RocketMQ 的管理后台上是可以看到的。如图： 那么我们对死信队列中的消息我们怎么处理？其实这个就看你的使用场景了，比如我们可以专门开一个后台线程，就是订阅 “%DLQ%VoucherConsumerGroup” 这个队列，对死信队列中的消息，还是一直不停地重试。 总结这一次我们搞清楚了另外一个生产环境下的问题，就是消费者底层的一些依赖可能有故障，比如数据库宕机，缓存宕机之类的，此时就就没办法完成消息的处理了，那么可以通过一些返回状态去让消息进入 RocketMQ 自带的重试队列，如果反复重试还是不行，可以让消息进入 RocketMQ 自带的死信队列，后续针对死信队列中的消息进行单独的处理就可以了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见的网络攻击]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F12%2F%E5%B8%B8%E8%A7%81%E7%9A%84%E7%BD%91%E7%BB%9C%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[XSS 攻击XSS 的全称是 Cross Site Script，就是跨站点脚本攻击，意思就是，黑客恶意篡改你的网页的前端代码，在里面注入一些它自己的 html + JavaScript 的脚本和代码，然后在你访问那个网站的网页的时候，他注入的那些恶意脚本就会运行。恶意脚本运行的时候就会控制你的浏览器，这个时候它的脚本就可以做很多的事情了。 XSS 反射性攻击第一种 XSS 攻击是反射性攻击，它主要是想办法让你点击一个 URL 链接，在这个 URL 链接里就嵌入它自己的恶意脚本，你点击那个 URL 链接之后，那个 URL 指向的是黑客自己服务器上的一段恶意脚本。 它可能给你展示的是一个图片，或者是一个 flash 动图，亦或是一个小视频的东西，引诱你去点击，然后恶意脚本被返回到你的浏览器里运行，就可以控制你的浏览器里的行为了。这个控制行为就很恐怖了，它可以干很多事情，比如说脚本可以让你自动关注某个用户 id，然后控制你发自动发布一个带有病毒的微博，这是比较简单的。 实际上，一段恶意的 JS 脚本，几乎是无恶不作的。因为它一旦控制你的浏览器就可以得到大量的东西。浏览器一般包含了你的一些 cookie，有的浏览器还可能存储了你的密码，通过知道你的 cookie，就可以利用 cookie 伪造你的用户登录的 session 状态，以你的名义去干一些事情。 XSS 持久型攻击另一种 XSS 攻击是叫持久型攻击。举个例子，例如一个论坛，或者社交网站之类的系统，你可以发布一些帖子，或者是评论啥的内容，此时黑客就可以在里面写一段恶意脚本，然后把恶意脚本混杂在评论内容里提交到你的网站数据库里去。 然后后面其他用户在社交网站里浏览到你的评论，评论内容会被返回到浏览器里去，此时评论内容是包含恶意 JS 脚本的。恶意脚本一运行，又可以干坏事了。 解决方案消毒机制。就是说，如果黑客在一些评论之类的内容里混入恶意脚本，那么你的代码必须对内容进行消毒，就是进行一些转义。这样就可以把恶意脚本里的 HTML 标签，JS 代码之类的东西，给转义掉，让这些恶意脚本失效。 HttpOnly 方式。如果你在浏览器里存放 cookie 的时候，可以设置一个 HttpOnly 属性，比如存放用户加密认证消息的 cookie，这样的话，在浏览器里运行的 JS 脚本是被禁止访问这些 HttpOnly cookie 的。他就无法窃取你在浏览器里存储的 cookie 了。 SQL 注入系统在数据库里执行 SQL 语句的时候，可能也存在漏洞，导致黑客把一些恶意的 SQL 语句注入进去，让你的系统在你的数据库里执行。例如下面这么一个请求： 1http://www.xxx.com/goods?goodsSkuNo=xxxxx 通过前端传递 goodsSkuNo 的数据 “xxxxx”，然后在后台执行这么一条 SQL 语句来查询数据： 1SELECT * FROM eshop_goods_sku WHERE goods_sku_no = 'xxxxx' 但是如果后台的 SQL 语句是手动拼接的，那前端传过来的数据有可能就会拼接成如下的 SQL 语句： 1SELECT * FROM eshop_goods_sku WHERE goods_sku_no = 'xxxxx'; drop table eshop_goods_sku;--'; 这样就直接恶意给你造成删库跑路的效果了。这还不算什么，关键是这种 SQL 语句里可以拼接进入各种支持的 SQL 语法，包括对数据库施加的命令，甚至通过附加一些脚本直接窃取你的数据，都是有可能的。 但是如果要给你搞 SQL 注入，其实也不是那么容易的，因为必须要知道你的数据库表结构才行。一般获取数据库表结构的方式就下面几种： 如果你使用的是开源软件，比如开源的博客系统，论坛系统，或者别的什么系统，那么人家自然知道你的表结构了。这种情况是比较少见的。 错误回显。就是有时候把系统跑在 web 服务器里，然后程序报错了，结果直接在浏览器页面上显示出来你的异常堆栈信息，包括有错误的 SQL 语句。这就尴尬了，通过这个，黑客就知道你的表结构了。 根据你的请求参数的名称，大致推测你的数据库表结构。这个一般不现实。 所以要防止 SQL 注入，一个是别让人家知道你的数据表结构，关闭 web 服务器的错误回显，显示一个 400,500 之类的就可以了。另外，就是要用预编译的方式。现在 mybatis、hibernate 都是支持预编译的。 预编译，放到底层的 JDBC 里，就是 PrepareStatement 对SQL 进行预编译。如果你给 SQL 的某个参数传入进去的是一个恶意 SQL 语句，人家预编译过后，会让你的恶意 SQL 语句是无法执行的，所以千万不要直接自己用字符串去拼接 SQL 语句。 例如 INSERT INTO xxx_table(xx, xxx, xx) VALUES(?, ?, ?) 对这个 SQL 进行预编译，然后把里面各个参数设置进去，此时参数里如果带有恶意 SQL 是不会作为 SQL 去执行的。 在 Mybatis 中。对这个方法比如传进去一个 map 或者是对象，mybatis 会根据你的占位符的变量名字，从你的 map 里或者是对象里提取出来一个一个的参数的值，进行预编译 SQL 的参数值的设置。 1INSERT INTO xxx_table(xx, xxx,xx) VALUES(#&#123;xx&#125;, #&#123;xxx&#125;, #&#123;xx&#125;) 这个预编译，就是说把黑客在参数里混进来的 SQL 语句当做一个参数，而绝对不会作为独立的 SQL 语句去执行，这就避免了 SQL 注入攻击了。 CSRF 攻击CSRF（Cross Site Request Forgery），跨站点请求伪造。这个就是黑客想办法去伪造你这个用户发送请求到某个系统上去，然后查询你的数据，或者进行转账交易之类的。伪装成你，有很多办法，比如利用 XSS 搞一个恶意脚本让你执行，然后盗取你的浏览器里的 cookie，利用你的 cookie 伪装成你登录的状态，然后去执行一些请求。 防御 CSRF 的方法主要是以下几种： 防止 cookie 被窃取：最根本的，还是防止 cookie 被窃取，可以给你的网站的cookie 设置 HttpOnly 属性，禁止别别人的 script 脚本窃取，那么别人就无法伪造用户登录请求了。 随机 token：每次返回一个页面给你的时候，都生成一个随机 token 附加在页面的随机元素里，同时可以在你的 redis 里可以存一下，然后页面发送请求的时候附加随机 token，验证过来才能执行请求，黑客要是用 postman 构造请求就不知道随机 token 是什么了 验证码：页面提交搞一个验证码，那种图形的。现在比较流行的还有拖动一个拼图什么的，必须验证码通过了才能执行你的请求，避免黑客直接伪造请求发送过来，这个其实是比较常见的，最好是在用户进行支付交易的时候，要求必须在页面上拖拽一个拼图验证码 Referer请求头：这个是 http 请求里有一个 referer 请求头，带有这个请求头的来源，你可以验证一下这个请求是不是从自己的页面里来的，如果是的话才执行，否则就不要执行。 文件上传可以遭受的攻击很多时候我们的网站允许别人上传文件，那么文件可能是可执行的脚本，可能是病毒或者木马文件，这个是非常危险的。如果是脚本的话，可能在服务器执行，搞很多破坏，比如黑客黑掉你的服务器，勒索你给他比特币之类的。他们会把自己的文件后缀改成 .jpg、.txt 之类的来上传，其实本质上是病毒文件。 对于文件上传这块，核心就是要进行白名单校验，限制上传文件的类型，而且要限制文件的大小，还要对文件重命名。限制文件类型不能简单地根据后缀来判断，要根据文件二进制数据的开头几个字节代表的 magic number 来判断文件的类型。例如 JPEG 的魔数是 FFD8FF；PNG 的魔数是 89504E47。以此类推。 网上可以查到完整的 magic number 列表，根据这个限制一下，哪些文件可以上传，这样就避免木马、病毒之类的可执行文件被上传了。 另外，最好对文件进行一定的压缩，这样可以破坏原来的 文件结构，避免文件在服务器执行。利用 imagemagick 这种开源包，可以很方便进行文件缩放。 DDoSDDoS，distributed denial of service，分布式拒绝服务攻击。可以把你的网站、APP、系统搞瘫痪了。DDos 攻击，就是说黑客知道你的服务器地址了，然后你的系统假设每秒就抗 1000 请求，黑客就以每秒 1000 请求访问你，你的服务器线程资源全部打满，正常用户根本无法发送请求，你的网站就宕机了。甚至他以每秒 1万 请求攻击你的服务器，那你的系统机器就挂了。 Dos 攻击是一对一的，就是黑客搞一台高性能服务器，拼命发送请求给你的一台服务器，但是如果你的服务器配置超高，每秒抗 1万 请求，结果黑客的机器才每秒 5000 请求，那么就没用了。 DDos 意思就是黑客控制大量的机器，比如普通人的电脑，或者是一些公司的服务器，被他的一些木马植入给控制了，就是所谓的 “肉鸡”，然后黑客下达指令，让所有肉鸡一起发送请求给攻击目标，直接搞瘫你的服务器。 如何防御 DDoS 攻击？如果只靠自己还是挺难的，这其实是非常专业的一种攻击手段，通常我们可以采购云厂商的安全服务，比如 DDoS 高防 IP，可以把攻击流量到导入到云厂商的高防 IP 的服务器上去，他们有专业的技术方案和算法来防御。 基于 SYN Flood 模式的 DDoS 攻击我们简单说一下 TCP 三次握手： 客户端发送一个 SYN 请求，指明客户端的端口号以及 TCP 连接的初始序列号 服务器收到 SYN 后，返回一个 SYN + ACK，表示请求被接收，TCP 序列号加 1 客户端收到服务器的 SYN + ACK 后，返回一个 ACK 给服务器，TCP 序列号加 1，连接建立完毕，接着可以通信了。 如果服务器没有收到第三步的 ACK，会重试返回 SYN + ACK 给客户端，同时处于 SYN_RECV 状态，把客户端放入等待列表，重试会 3 ~ 5 次，每隔 30 秒重试一次，遍历等待列表，再次重试发送 SYN + ACK]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ - 事务消息机制的底层原理]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F09%2FRocketMQ-%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%E6%9C%BA%E5%88%B6%E7%9A%84%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[half 消息的实现我们之前已经说过了 RocketMQ 事务消息的全流程。在这个流程中，第一步就是要由订单系统去支付一个 half 消息给 MQ。当时我们说过，对于这个 half 消息，红包系统这个时候是看不到它的，没法消费这条消息去处理，那这个 half 消息是如何做到的？ 其实 RocketMQ 底层采取了一个巧妙的设计。举个例子，订单系统发送了一个 half 状态的订单支付消息到 “OrderPaySuccessTopic” 里去，这是一个 Topic。然后，红包系统也是订阅了这个 “OrderPaySuccessTopic” 从里面获取消息的。 之前我们有讲过，写入一个 Topic，最终是定位到这个 Topic 的某个 MessageQueue，然后定位到一台 Broker 机器上去，然后写入的是 Broker 上的 CommitLog 文件，同时将消费索引写入 MessageQueue 对应的 ConsumeQueue 文件。所以你写入一条 half 消息到 “OrderPaySuccessTopic” 里去，会定位到这个 Topic 的一个 MessageQueue，然后定位到 RocketMQ 的一台机器上去，按理说，消息会写入 CommitLog。 同时消息的 offset 会写入 MessageQueue 对应的 ConsumeQueue，这个 ConsumeQueue 是属于 OrderPaySuccessTopic 的，然后红包系统按理说会从这个 ConsumeQueue 里获取到你写入的这个 half 消息。但是实际上红包系统却没法看到这条消息，原因就是 RocketMQ 一旦发现你发送的是一个 half 消息，它不会把这个 half 消息的 offset 写入 OrderPaySuccessTopic 的 ConsumeQueue 里去。 它会把这条 half 消息写入到自己内部的 “RMQ_SYS_TRANS_HALF_TOPIC” 这个 Topic 对应的一个 ConsumeQueue 里去。如图： 真相大白了，所以对于事务消息机制之下的 half 消息，RocketMQ 是写入内部的 Topic 的 ConsumeQueue 的，不是写入你指定的 OrderPaySuccessTopic 的 ConsumeQueue 的。 什么情况下订单系统会收到 half 消息成功的响应接着，在什么情况下订单系统会收到 half 消息成功的响应呢？结合上面的内容，可以判断出，必须要 half 消息进入到 RocketMQ 内部的 RMQ_SYS_TRANS_HALF_TOPIC 的 ConsumeQueue 文件了，此时就会认为 half 消息写入成功了，然后就会返回响应给订单系统。 所以这个时候，一旦你的订单系统收到这个 half 消息写入成功的响应，就知道这个 half 消息已经在 RocketMQ 内部了。 没有执行 rollback 或者 commit 会怎样接着，如果因为网络故障，订单系统没有收到 half 消息的响应，或者说自己发送的 rollback/commit 请求失败了，那么 RocketMQ 会干什么？其实这个时候它会在后台有定时任务，定时任务会去扫描 RMQ_SYS_TRANS_HALF_TOPIC 中的 half 消息，如果你超过一定时间还是 half 消息，它会回调订单系统的接口，让你判断这个 half 消息是要 rollback 还是 commit。如图： 执行 rollback，如何标记消息回滚假设我们的订单系统执行了 rollback 请求，那么此时就需要对消息进行回滚。之前我们说过，RocketMQ 会把这个 half 消息给删除，但是大家觉得删除消息是真的会在磁盘文件里删除吗？ 显然不是的，因为 RocketMQ 都是顺序把消息写入磁盘文件的，所以在这里如果你执行 rollback，它的本质就是用一个 OP 操作来标记 half 消息的状态。RocketMQ 内部有一个 OP_TOPIC，此时你可以写一条 rollback OP 记录到这个 topic 里，标记某个 half 消息是 rollback 了。如图： 另外，假设你一直没有执行 commit/rollback，RocketMQ 会回调订单系统的接口去判断 half 消息的状态，但是它最多就是回调 15 次，如果 15 次之后你没法告知它 half 消息的状态，就自动把消息标记为 rollback。 执行 commit 操作，如何让消息对系统可见最后，如果订单系统执行了 commit 操作，如何让消息对这个红包系统可见？其实也简单，你执行 commit 之后，RocketMQ 就会在 OP_TOPIC 里写入一条记录，标记 half 消息已经是 commit 状态了。接着需要把放在 RMQ_SYS_TRANS_HALF_TOPIC 中的 half 消息写入到 OrderPaySuccessTopic 的 ConsumeQueue 里去，然后我们的红包系统就可以看到这条消息进行消费了。 总结看到这里，大家对事务消息机制的底层原理应该比较了解了。其实它的本质都是基于 CommitLog、ConsumeQueue 这套存储机制来做的，只不过中间有一些 Topic 的变换，half 消息可能就是写入内部 Topic 的。 Broker 消息零丢失方案：同步刷盘 + Raft 协议主从同步如果我们在生产消息的时候用了事务消息之后，就可以保证数据不会丢失吗？假设我们现在订单系统已经通过事务消息的机制，通过 half 消息 + commit 的方式，把消息在 MQ 里提交了。也就是说，现在对于 MQ 而言，那条消息已经进入它的存储层了，可以被红包系统看到了。 但是，你的这条消息在 commit 之后，会从 half topic 里进入 OrderPaySuccessTopic 中，但是此时仅仅是消息进入了这个你预定的 Topic 而已，仅仅是可以被红包系统看到而已，此时可能你的红包系统还没来得及去获取这条消息。 然后恰巧这个时候，你的这条消息仅仅停留在 os cache 中，还没有进入到 ConsumeQueue 磁盘文件里，然后此时这台机器突然宕机了，os cache 中的数据全部丢失了，此时会导致你的消息丢失，红包系统再没机会读到这条消息了。 接着，就算我们运气好，消息已经进入 OrderPaySuccessTopic 的 ConsumeQueue 磁盘文件了，不是停留在 os cache 里，此时消息就一定不会丢失吗？这也未必，即使消息已经进入磁盘文件了，但是这个时候红包系统还没来得及消费这条消息，然后此时这台机器的磁盘突然坏了，就会一样导致消息丢失，而且可能消息再也找不回来了，同样丢失数据。 保证消息写入 MQ 不代表不丢失所以，我们要明确一个前提，哪怕我们确保消息已经写入 MQ 成功了，此时也未必消息就不会丢失了。因为即使你写入 MQ 成功了，这条消息也大概率是仅仅停留在 MQ 机器的 os cache 中，一旦机器宕机内存里的数据都会丢失。即使消息已经写入了 MQ 机器的磁盘文件里，但是磁盘一旦坏了，消息也会丢失。 异步刷盘 VS 同步刷盘到底怎么去确保消息写入 MQ 之后，MQ 自己不要随便丢失数据呢？解决这个问题的第一个关键点，就是将异步刷盘调整为同步刷盘。所谓的异步刷盘，即使之前我们一直说的那种模式，即，你的消息即使成功写入了 MQ，它也就在机器的 os cache 中，没有进入磁盘里，要过一会等操作系统自己把 os cache 里的数据实际刷入磁盘文件中。 所以在异步刷盘的模式下，我们的写入消息的吞吐量肯定是极高的，毕竟消息只要进入 os cache 这个内存就可以了，写消息的性能就是写内存的性能，那每秒钟可以写入的消息数量肯定更多了，但是这个情况下，可能会导致数据的丢失。 所以如果一定要保证数据零丢失的话，可以调整 MQ 的刷盘策略，我们需要调整 Broker 的配置文件，将其中的 flushDiskType 配置设置为 SYNC_FLUSH，默认它的值是 ASYNC_FLUSH，即默认是异步刷盘的。 如果调整为同步刷盘之后，只要 MQ 返回响应式 half 消息发送成功了，那么就说明消息已经进入磁盘文件了，不会停留在 os cache 里。如图： 通过主从架构模式避免磁盘故障导致的数据丢失接着，如何避免磁盘故障导致的数据丢失？其实道理也很简单，我们必须要对 Broker 使用主从架构模式。也就是说，必须让一个 Master Broker 有一个 Slave Broker 去同步它的数据，而且你一条消息写入成功，必须是让 Slave Broker 也写入成功，保证数据有多个副本的冗余。如图： 这样一来，你一条消息写入成功，此时主从两个 Broker 上都有这条数据了，此时如果你的 Master Broker 的磁盘坏了，但是 Slave Broker 上至少还是有数据的，数据不会因为磁盘故障而丢失的。 对于主从架构，如果你是基于 Dledger 技术和 Raft 协议的主从同步架构，对于你所有的消息写入，只要它写入成功，那就一定会通过 Raft 协议同步给其他的 Broker 机器。 Consumer 消息零丢失方案：手动提交 offset + 自动故障转移通过上面，我们知道了如果确保订单系统发送出去的消息一定会到达 MQ 中，而且也能确保了如果消息到达了 MQ，如果确保一定不会丢失。现在的问题在于，即使红包系统拿到了这条消息，就一定可以成功的派发红包吗？ 答案是未必。如果红包系统已经拿到了这条消息，但是消息目前还在它的内存里，还没执行派发红包的逻辑，此时它就直接提交了这条消息的 offset 到 Broker 去说自己已经处理过了。如图： 接着红包系统在上图这个状态的时候就直接崩溃了，内存里的消息就没了，红包也没派发出去。结果 Broker 已经收到它提交的消息 offset 了，以为它 处理完这个消息了。等红包系统重启的时候，就不会再次消费这条消息了。 所以，即使保证发送消息到 MQ 的时候绝不会丢失，而且 MQ 收到消息之后一定不会把消息搞丢，但是你的红包系统在获取到消息之后还是可能会搞丢。 RocketMQ 消费者的处理方式我们看一下下面的 RocketMQ 消费者的代码，如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class RocketMQConsumer &#123; public static void start() &#123; new Thread() &#123; @SneakyThrows @Override public void run() &#123; // 这是 RocketMQ 消费者实例对象 // "credit_group" 之类的就是消费者分组 // 一般来说比如积分系统就用 "credit_consumer_group" // 比如营销系统就用 "marketing_consumer_group" // 以此类推，不同的系统给自己取不同的消费者名字 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("credit_group"); // 这是给消费者设置 NameServer 的地址 // 这样就可以拉取到路由信息，知道 Topic 的数据在哪些 Broker 上 // 然后可以从对应的 Broker 上拉取数据 consumer.setNamesrvAddr("localhost:9876"); // 选择订阅 "TopicOrderPaySuccess" 的消息 // 这样就会从这个 Topic 的 Broker 机器上拉取订单消息过来 consumer.subscribe("TopicOrderPaySuccess", "tags"); // 注册消息监听器来处理拉取到的订单消息 // 如果 consumer 拉取到了订单消息，就会回到这个方法交给处理 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; // 在这里对获取到的 msgs 订单消息进入处理 // 比如增加积分、发送优惠券、通知发货等等 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者实例 consumer.start(); System.out.println("Consumer Stratd. %n"); while (true) &#123; // 别让线程退出，就让创建好的 consumer 不停消费数据 Thread.sleep(1000); &#125; &#125; &#125;.start(); &#125;&#125; 其中我们重点看下面这段代码： 12345678consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; // 在这里对获取到的 msgs 订单消息进入处理 // 比如增加积分、发送优惠券、通知发货等等 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); RocketMQ 的消费者中会注册一个监听器，就是上面小块代码中的 MessageListen而Concurrently 这个东西，当你的消费者获取到一批消息之后，就会回调你的这个监听器函数，让你来处理一批消息。当你处理完毕之后，你才会返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 作为消费成功的示意，告诉 RocketMQ，这批消息我已经处理完毕了。 所以对于 RocketMQ 而言，其实只要你的红包系统是在这个监听器的函数中先处理一批消息，基于这批消息都派发完了红包，然后返回了这个消费成功的状态，接着才会去提交这批消息的 offset 到 Broker 去。所以这这个情况下，如果你对一批消息都处理完毕了，然后再提交消息的 offset 给 Broker，接着红包系统崩溃了，此时是不会丢失消息的。 如果是红包系统获取到一批消息之后，还没处理完，也没返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 这个状态，自然美提交这批消息的 offset 给 Broker，此时红包系统突然挂了，会怎么样？ 其实在这种情况下，你对一批消息都没提交它的 offset 给 Broker 的话，Broker 不会认为你已经处理完了这批消息，此时你突然红包系统的一台机器宕机了，它其实会感知到你的红包系统的一台机器作为一个 Consume 挂了。接着它会把还没处理完的那批消息交给红包系统的其他机器去进行处理。所以这种情况下，消息也是不会丢失的。 需要警惕的地方：不能异步消费消息在默认的 Consumer 的消费模式之下，必须是你处理完一批消息之后，才会返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 这个状态标识消息都处理结束了，才提交 offset 到 Broker 去。在这种情况下，正常来说是不会丢失消息的，即使你一个 Consumer 宕机了，它会把你还没处理完的消息交给其他 Consumer 去处理。 但是我们要警惕一点，就是我们不能再代码中对消息进行异步的处理。如下错误的示范，我们开启了一个子线程去处理这笔消息，然后启动线程之后，就直接返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 状态了。 12345678910111213consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; // 开启一个子线程处理这批数据 new Thread() &#123; @Override public void run() &#123; // 处理消息 &#125; &#125;.start(); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); 如果要是用这种方式来处理消息的话，那可能就会出现你开启的子线程还没处理完消息，你就已经返回 ConsumeConcurrentlyStatus.CONSUME_SUCCESS 状态了，就可能提交这批消息的 offset 给 Broker 了，认为已经处理结束了。然后此时你红包系统突然宕机，就会导致你的消息丢失了。 因此在 RocketMQ 的场景下，如果要保证消费数据的时候别丢失，你就老老实实在回调函数里处理消息，处理完了你再返回 ConsumeConcurrentlyStatus.COMSUME_SUCCESS 状态表明你处理完毕了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 的事务消息]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F08%2FRocketMQ-%E7%9A%84%E4%BA%8B%E5%8A%A1%E6%B6%88%E6%81%AF%2F</url>
    <content type="text"><![CDATA[示例背景在一个电商系统中，按照规则在支付之后可以拿到一个现金红包的，但是在支付了一个订单之后，却没有收到这个现金红包。这是怎么回事？ 经过一通排查，找了系统中打印的很多日志之后，发现了一个奇怪的现象。按理来说，订单系统在完成支付之后，会推送一条消息到 RocketMQ 里去，然后红包系统会从 RocketMQ 里接收那条消息去给用户发现金红包：如图： 但是从订单系统和红包系统当天那个时间段的日志来看，只看到了订单系统有推送消息到 RocketMQ 的日志，但是并没有看到红包系统从 RocketMQ 中接收消息以及发现金红包的日志。 大家推测可能问题就出在这，有可能支付订单系统在传输的过程中丢失了，导致现金红包没有派发出去。 订单系统推送消息到 MQ 的过程会丢失消息首先，订单系统在接收到订单支付成功的通知之后，会去推动一条订单支付成功的消息到 MQ 的，那么这个过程中，会出现丢失消息的问题吗？当然有可能。例如，订单系统在推送消息到 RocketMQ 的过程中，是通过网络去进行传输的，但是这个时候恰巧网络发送了抖动，也就是网络突然出了问题，导致这次网络通信失败了，于是这个消息就没有成功投递给 MQ。 除此之外，还有其他情况。例如 MQ 的确收到消息了，但是它的网络通信模块的代码出现了异常，可能是它内部的网络通信的 bug，导致消息没成功处理；或者是你在写消息到 RocketMQ 的过程中，刚好遇到了某个 Leader Broker 自身故障，其他的 Follower Broker 正在尝试切换为 Leader Broker，这个过程中也可能有异常等等。 因为我们在使用任何一个 MQ 的时候，无论是 RocketMQ、还是 RabbitMQ 或者 Kafka，都要明确一点：不一定你发送消息出去就一定会成功，有可能就会失败，此时你的代码里可能会抛出异常，也可能不会抛出异常，这都不好说，要具体看什么原因导致的消息推送失败。 消息到达 MQ 后，MQ 自己丢失信息接下来，假设我们的订单系统成功地把消息写入了 MQ，此时我们可以认为你写成功了，此时消息有可能丢失吗？这也是有可能的。通过之前的 RocketMQ 的底层原理的分析，我们知道一点，就是你的消息写入 MQ 之后，其实 MQ 可能仅仅把这个消息给写入 page cache 里，也就是操作系统自己管理的一个缓冲区，这本质也是内存。如图： 可能你认为写成功了一个消息，但是此时仅仅进入了 os cache，还没有写入磁盘。然后这个时候，假如出现了 Broker 机器的崩溃，机器宕机了，是不是 os cache 内存中的数据就没了？ 消息进入磁盘，真的万无一失吗之前说过，Broker 把消息写入 os cache 之后，其实操作系统自己在一段不太确定的时间之后，它自己是会把数据从内存刷入磁盘文件里的。假设我们写入 MQ 的一条消息已经稳稳进入 Broker 所在机器的磁盘文件里了，这个时候数据一定不会丢失吗？ 答案是不，因为如果你的磁盘出现故障，你上面的存储的数据还是会丢失。之前就有互联网公司把数据存储在服务器的磁盘上，但是因为没有做完善的冗余备份，结果机器磁盘故障导致公司运营几年的核心数据没了。所以如果消息进入 Broker 机器的磁盘之后，赶上机器刚好磁盘坏了，可能上面的消息也就都丢失了。 红包系统拿到消息，就不会丢失吗接着，假设红包系统这个时候顺利从 MQ 里拿到了一条消息，然后它就能安稳地把现金红包发出去吗？这也是未必的，要解释这个问题，就需要牵扯到消息的 offset 这个概念了。 之前已经在底层原理分析的部分解释了 MQ 底层的存储结构，包括消息的 offset 的概念，说白了，offset 就是代表了一个消息的标识，代表了它的位置。 假设现在有两个消息，offset 分别为 1 和 2，现在我们假设红包系统已经获取到了消息 1 了，然后消息 1 此时就在它的内存里，正准备运行代码去派发现金红包，但是要注意，此时还没发红包。如图： 默认情况下，MQ 的消费者有可能会自动提交已经消费的 offset，如果此时你还没处理这个消息派发红包的情况下，MQ 的消费者可能直接给你提交这个消息 1 的 offset 到 Broker 去了，标识为你已经成功处理了这个消息。接着恰巧在这个时候，我们的红包系统突然宕机了，或者是可能在派发红包的时候更新数据库失败了，总之就是它突然故障了，然后此时内存里的消息 1 必然丢失了，而且红包也没发出去。 总结红包为什么没发出去？原因有很多，比如订单系统推送消息到 MQ 就失败了，压根就没推送出去；或者是消息确实推送到 MQ 了，但是结果 MQ 自己机器故障，把消息搞丢了；或者是红包系统拿到了消息，但是它把消息搞丢了，红包也没来得及发。 发送消息零丢失方案：RocketMQ 的事务消息我们明确了消息在基于 MQ 传输的过程中可能丢失的几个地方，那么我们就要一步一步考虑如何去解决各个环节丢失信息的问题。 首先要解决的第一个问题，就是订单系统推送消息到 MQ 的过程中，可能消息就丢失了。在 RocketMQ 中，有一个非常牛逼的功能，就是事务消息功能。凭借这个事务级的消息机制，就可以让我们确保订单系统推送出去的消息一定会成功写入 MQ 里，不会半路就搞丢了。 发送 half 消息到 MQ 去，试探 MQ 是否正常作为订单系统而言，假设它收到了一个订单支付成功的通知之后，它必然是需要在自己的订单数据库里做一些增删改操作的，比如更新订单状态之类的。可能有些人会认为，订单系统不就是在自己数据库里做一些增删改操作，然后直接发个消息到 MQ 去，让其他关注这个订单支付成功消息的系统从 MQ 获取消息做对应的处理就行了么？ 其实并不会这么简单。在基于 RocketMQ 的事务消息机制中，我们先让订单系统发送一条 half 消息到 MQ 去。这个 half 消息本质就是一个订单支付成功的消息，只不过你可以理解为这个 half 消息的状态是 half 状态，这个时候红包系统是看不见这个 half 消息的。然后我们去等待接收这个 half 消息写入成功的响应通知。如图： 发送这个 half 消息有什么用？假设你二话不说就让订单系统直接做了本地的数据库操作，比如订单状态都更新为了已完成，然后你再发送消息给 MQ，结果报出一堆异常，发现 MQ 挂了。这个时候，会导致你没法通过消息通知到红包系统去派发红包，那用户一定会发现自己订单支付了，结果红包没收到。 所以，这里我们第一件事，不是先让订单系统做一些增删改操作，而是先发一个 half 消息给 MQ 以及收到它的成功的相应，初步先跟 MQ 做个联系和沟通。 half 消息写入失败如果 half 消息写入失败，例如 MQ 挂了，或者网络故障了，总之你现在没法跟 MQ 通信了。这个时候你的订单系统就应该执行一系列回滚操作，比如对一个订单状态做一个更新，让状态变成 “关闭交易”，同时通知支付系统自动进行退款，这才是正确的做法。 因为你订单虽然支付了，但是派发红包、发送优惠券之类的后续操作是无法执行的，所以此时必须把钱款退还给用户，说交易失败了。 half 消息成功之后，订单系统完成自己的任务接着，如果你的 half 消息写成功了，这个时候你的订单系统就应该在自己的本地数据库里执行一些增删改操作了，因为一旦 half 消息写成功了，就说明 MQ 肯定已经收到这条消息了，MQ 还活着，而且目前你是可以跟 MQ 正常沟通的。 订单系统的本地事务执行失败接着上面的情况，如果订单更新自己的数据库失败了怎么办？比如订单系统的数据当时也有网络异常，或者数据库挂了等等。这个时候也简单，就是让订单系统发送一个 rollback 请求给 MQ 就可以了。意思是说，你可以把之前我发送给你的 half 消息给删除掉了，因为我自己出现问题了，已经没办法跟你继续后续的流程了。 当然你发送 rollback 请求给 MQ 删除那个 half 消息之后，你的订单系统就必须走后续的回退流程了，就是通知支付系统退款。当然这里可能还有一些订单系统自己的高可用降级的机制需要考虑，比如数据库无法更新了，此时你可能需要在机器本地磁盘文件里写入订单支付失败的记录，然后你可以开一个后台线程在 MySQL 数据库恢复之后，把订单状态更新为 “已关闭”。 订单完成本地事务之后如果订单系统成功完成了本地的事务操作，此时你就可以发送一个 commit 请求给 MQ，要求让 MQ 对之前的 half 消息进行 commit 操作，让红包系统可以看见这个订单支付成功消息。 之前我们说过，half 消息实际就是订单支付成功的消息，只不过它的状态是 half，红包系统是看不见它的，没法获取这条消息，必须等到订单系统指定 commit 请求，消息比 commit 之后，红包系统才可以看到和获取这条消息进行后续操作。 half 消息发送成功，但没有收到响应大致的事务流程是讲完了。但是接着我们进行比较严谨的分析。如果我们把 half 消息发送给 MQ，MQ 给保存下来了，但是 MQ 返回给我们的响应我们没收到呢？此时会发生什么？ 这个时候我们没收到响应，有可能是网络超时报错，或者是其他的异常错误，这个时候订单系统会误以为是发送 half 消息到 MQ 失败，订单系统会直接执行退款流程，订单状态也会标记为 “已关闭”。 但这个时候 MQ 已经存储下来一条 half 消息了，那这个消息怎么处理？其实 RocketMQ 这里有一个补偿流程，它会去扫描自己处于 half 状态的消息，如果我们一直没有对这个消息执行 commit/half 操作，超过了一定的时间，它就会回调你的订单系统的一个接口。 它会询问这个消息是打算 commit 还是 rollback，这个时候订单系统就得去查一下数据库，查询订单的状态，发现状态是 “已关闭”，就得发送 rollback 请求给 MQ 去删除之前那个 half 消息了。 rollback 或者 commit 发送失败如果订单系统是收到 half 消息写入成功的相应了，同时尝试对自己的数据库更新了，然后根据失败或者成功去执行了 rollback 或者 commit 请求，发送给 MQ 了，结果因为网络故障，导致 rollback 或者 commit 请求发送失败了。这时候要怎么处理？ 其他也简单，因为 MQ 里的消息一直是 half 状态，所以说它过了一定的超时时间会发现这个 half 消息有问题，它会回调你的订单系统的接口，此时你要判断一下，这个订单的状态如果更新为了 “已完成”，那你就得再次执行 commit 请求，反之则再次执行 rollback 请求。 本质这个 MQ 的回调就是一个补偿机制，如果你的 half 消息响应没收到，或者 rollback、commit 请求没发送成功，它都会来找你询问 half 消息后续如何处理。 如果订单系统收到了 half 消息写入成功的相应了，同时尝试对自己的数据库更新了，然后根据失败或者成功去执行了 rollback 或者 commit 请求，发送给 MQ 了。但 MQ 在这个时候挂掉了，导致 rollback 或者 commit 请求发送失败。如果是这种情况，那就等 MQ 自己重启了，重启之后它会扫描 half 消息，然后还是通过上面说到的补偿机制，去回调你的接口。 总结上面的流程意义是什么？其实，如果你的 MQ 有问题或者网络有问题，half 消息根本都发布出去，此时 half 消息肯定是失败的，那么订单系统就不会执行后续流程了。 如果 half 消息发送出去了，但是 half 消息的响应没收到，然后执行了退款流程，那 MQ 会有补偿机制来回调你询问要 commit 还是 rollback，此时你选择 rollback 删除消息就可以了，不会执行后续流程。 如果订单系统收到 half 消息响应了，但是订单系统自己更新数据库失败了，那他它也不会执行后续流程了。如果它更新数据库成功了，订单状态是 “已完成”，此时就会发送 commit 请求给 MQ，一旦消息 commit 了，那么可以保证红包系统可以收到这个消息。 而且即使你 commit 请求发送失败了，MQ 也会有补偿机制，回调你接口让你判断是否重新发送 commit 请求。 总之，就是你的订单系统只要成功了，那么必然要保证 MQ 里的消息是 commit 了，可以让红包系统看到它。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[硬件层面聊聊可见性和有序性]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F06%2F%E7%A1%AC%E4%BB%B6%E5%B1%82%E9%9D%A2%E8%81%8A%E8%81%8A%E5%8F%AF%E8%A7%81%E6%80%A7%E5%92%8C%E6%9C%89%E5%BA%8F%E6%80%A7%2F</url>
    <content type="text"><![CDATA[高速缓存的数据结构处理器高速缓存的底层数据结构实际上一个拉链散列表的结构，就是有很多个 bucket，每个 bucket 挂了很多的 cache entry，每个 cache entry 由三个部分组成：tag、cache line 和 flag，其中的 cache line 就是缓存的数据；tag 指向了这个缓存数据在主内存中的数据地址，flag 标识了缓存行的状态。另外需要注意的一点是，cache line 中可以包含多个变量的值 处理器会操作一些变量，那怎么在高速缓存里定位到这个变量呢？其实处理器在读写高速缓存的时候，实际上会根据变量名执行一个内存地址解码的操作，解析出 3 个东西：index、tag 和 offset。index 用于定位到拉链散列表中的某个 bucket，tag 是用于定位 cache entry，offset 是用于定位一个变量时在 cache line 中的位置。 如果说可以成功定位到一个高速缓存中的数据，而且 flag 还标志着有效，则缓存命中；否则不满足上述条件，就是缓存未命中。如果是读数据未命中的话，会从主内存重新加载数据到高速缓存中。现在处理器一般都有三级高速缓存：L1、L2 和 L3，越靠前面的缓存读写速度越快。 缓存一致性协议（MESI 协议）因为有高速缓存的存在，所以就导致各个处理器可能对一个变量会在自己的高速缓存里有自己的副本，这样一个处理器修改了变量值，别的处理器是看不到的。为了解决这个问题，引入了缓存一致性协议（MESI 协议） MESI 协议规定：对一个共享变量的读操作可以是多个处理器并发执行的，但是对于一个共享变量的写操作，只有一个处理器可以执行。其实也会通过排他锁的机制保证就一个处理器能写。 之前说过那个 cache entry 的 flag 代表了缓数据的状态，MESI 协议中划分为： invalid：无效的。标记为 I。这个意思是当前 cache entry 无效，里面的数据不能使用 shared：共享的。标记为 S。这个意思是当前 cache entry 有效，而且里面的数据在各个处理器都有各自的副本，但是这些副本的值跟主内存的值是一样的，各个处理器就是并发地在读而已 exclusive：独占的。标记为 E。这个意思就是当前处理器对这个数据独占了，只有它可以有这个副本，其它的处理器都不能包含这个副本 modified：修改的。标记为 M。只能有一个处理器对共享数据更新，所以只有更新数据的处理器的 cache entry，才是 exclusive 状态。表明当前线程更新了这个数据，这个副本的数据跟主内存是不一样的。 MESI 协议规定了一组消息，就是各个处理器在操作内存数据的时候，都会往总线发送消息，而且各个处理器还会不停地从总线嗅探最新的消息，通过这个总线的消息传递来保证各个处理器的协作。 下面来详细地图解 MESI 协议的工作原理，处理器0 读取某个变量的数据时，首先会根据 index、tag 和 offset 从高速缓存的拉链散列表读取数据，如果发现状态为 I，也就是无效的，此时就会发送 read 消息到总线。 接着主内存会返回对应的数据给 处理器0，处理器0 就会把数据放到高速缓存里，同时 cache entry 的 flag 状态为 S。 在 处理器0 对一个数据进行更新的时候，如果数据状态是 S，则此时就需要发送一个 invalidate 消息到总线，尝试让其他的处理器的高速缓存的 cache entry 全部变为 I，以获得数据的独占锁。其他的 处理器1 会从总线嗅探到 invalidate 消息，此时就会把自己的 cache entry 设置为 I，也就是过期掉自己本地的缓存，然后就是返回 invalidate ack 消息到总线，传递回 处理器0，处理器0 必须收到所有处理器返回的 ack 消息 接着 处理器0 就会将 cache entry 先设置为 E，独占这条数据，在独占期间，别的处理器就不能修改数据了，因为别的处理器此时发出 invalidate 消息，这个 处理器0 是不会返回 invalidate ack 消息的，除非它先修改完再说 接着 处理器0 就修改这条数据，接着将数据设置为 M，也有可能是把数据此时强制写会到主内存中，具体看底层硬件实现 然后其他处理器此时这条数据的状态都是 I 了，如果要读的话，全部都需要重新发送 read 消息，从出内存（或者是其他处理器）来加载，这个具体怎么实现看底层的硬件，都有可能的 这套机制其实就是缓存一致性在硬件缓存模型下的完整执行原理。 采用写缓冲器和无效队列优化 MESI 协议MESI 协议如果每次写数据的时候都要发送 invalidate 消息等待所有处理器返回 ack，然后获取独占锁后才能写入数据，那可能就会导致性能很差了。因为对这个共享变量的写操作，实际上在硬件级别变成串行的。所以为了解决这个问题，硬件层面引入了写缓冲器和无效队列。 写缓冲器的作用是，一个处理器写数据的时候，直接把数据写入缓冲器，同时发送 invalidate 消息，然后就认为写操作完成了，接着就干别的事情，不会阻塞在这里。接着这个处理器如果收到其他处理器的 ack 消息之后，才会把写缓冲器中的写结果拿出来，通过堆 cache entry 设置为 E 加独占锁，同时修改数据，然后设置为 M。 其实写缓冲器的作用，就是处理器写数据的时候直接写入缓冲器，不需要同步阻塞等待其他处理器的 invalidate ack 返回，这就大大提升了硬件层面的执行效率了。包括查询数据的时候，会先从写缓冲器里查，因为有可能刚修改的值在这里，然后才会从高速缓存里查，这个就是存储转发。 引入无效队列，就是说其他处理器在接收到 invalidate 消息之后，不需要立马过期本地缓存，直接把消息放入无效队列，就返回 ack 给那个写处理器了，这就进一步加速了性能，然后之后从无效队列里取出消息，过期本地缓存即可 通过引入写缓冲器和无效队列，一个处理器要写数据的话，这个性能是很高的，它直接写数据到写缓冲器，发送一个 invalidate 消息出去，就立马返回，执行别的操作了；其他处理器收到 invalidate 消息之后直接放入无效队列，立马就返回 invalidate ack 硬件层面的 MESI 协议引发有序性和可见性的问题通过上面的讲解，MESI 协议在硬件层面的原理大家应该清晰了。现在就讲讲 MESI 协议引发的可见性和有序性问题。 可见性可见性是写缓冲器和无效队列导入的。写数据不一定立马写入自己的高速缓存（或者主内存），有可能写入了写缓冲器，导致其他处理器读不到最新的值；读数据不一定立马从别人的高速缓存（或者主内存）刷新最新的值过来，invalidate 消息还无效队列里面，高速缓存还保留着未被无效化的旧值，处理器会在自己的高速缓冲中读取旧值。 有序性StoreLoad 重排序1234567int a = 0;int c = 1;线程1:a = 1;int b = c; 上面线程 1 的代码，第一个是 Store，第二个是 Load。但是可能处理器对 store 操作先写入了写缓冲器，此时这个写操作相当于没执行，然后就执行第二行代码，第二行代码的 b 是局部变量，那这个操作等于是读取 c 的值，是 load 操作。这就导致了好像第二行代码的 load 先执行了，第一行代码的 store 后执行 第一个 store 操作写到写缓冲器里去了，导致其他的线程是读取不到的，看不到的，好像是第一个写操作没执行一样，而第二个 load 操作是成功地执行了。 StoreStore 重排序12resource = loadResource();loaded = true; 上面两个写操作，但是可能第一个写操作写入了写缓冲器，然后第二个写操作是直接修改的高速缓存，这个时候不久导致了两个写操作顺序颠倒了？ 诸如此类的重排序，都可能因为 MESI 的机制发生。可见性问题也是一样的，写入写缓冲器之后，没输入高速缓存，导致别人读不到；读数据的时候，可能 invalidate 消息在无效队列里，导致没法立马感知到过期的缓存，立马加载最新的数据 内存屏障在硬件层面的实现以及问题解决解决可见性问题，可以通过 Store 屏障 + Load 屏障。 如果加了 Store 屏障之后，就会强制性要求你对一个写操作必须阻塞等待到其他的处理器返回 invalidate ack 之后，对数据加锁，然后修改到高速缓存中，在写数据之后，必须强制执行 flush 操作。它的效果，是要求一个写操作必须刷到高速缓存（或者主内存），不能停留在写缓冲器里。 如果加了 Load 屏障之后，就从高速缓存读取数据的时候，如果发现无效队列里有一个 invalidate 消息，此时会立马强制那个 invalidate 消息把自己本地缓存的数据过期掉（设置为 I），然后就可以强制从其他处理器的高速缓存中加载最新的值了，这就是 refresh 操作。 为了解决有序性问题，可以通过内存屏障。通过使用 Acquire 屏障（StoreStore 屏障）、Release 屏障（StoreLoad 屏障），可以避免重排序 StoreStore 屏障，会强制让写数据的操作全部按照顺序写入写缓冲器里，不会让你第一个写到写缓冲器里去，第二个直接修改高速缓存了。 12345resource = loadResource();StoreStore 屏障loaded = true; StoreLoad 屏障，它会强制先将写缓冲器里的数据写入高速缓存中，接着读数据的时候强制清空无效队列，对里面的 invalidate 消息全部过期掉高速缓存中的条目，然后强制从主内存里重新加载数据。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 杂记之消费者]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F02%2FRocketMQ-%E6%9D%82%E8%AE%B0%E4%B9%8B%E6%B6%88%E8%B4%B9%E8%80%85%2F</url>
    <content type="text"><![CDATA[消费者如何获取消息处理以及进行 ACK消费者组首先，我们需要了解一个概念，就是消费者组。消费者组的意思，就是你给一组消费者起一个名字。比如我们有一个 Topic 叫 “TopicOrderPaySuccess”，然后假设有库存系统、积分系统、营销系统、仓储系统他们都要去消费这个 Topic 中的数据。此时我们应该给那四个系统分别起一个消费组的名字，比如： stock_consumer_group，marketing_consumer_group，credit_consumer_group，wms_consumer_group。 设置消费组的方式是在代码里进行的，如下： 12DefaultMQPushConsumer consumer = new DefaultMQPushConsumer("stock_consumer_group") 比如说库存系统部署了 4 台机器，每台机器上的消费者组的名字都是 “stock_consumer_group”，那么这 4 台机器就同属于一个消费者组。以此类推，每个系统的几台机器都是属于各自的消费者组的。 然后跟大家说一下不同消费者之间的关系，假设库存系统和营销系统作为两个消费者组，都订阅了 “TopicOrderPaySuccess” 这个订单支付成功信息的 Topic，此时假设订单系统作为生产者发送了一条消息到这个 Topic。如图： 此时这条消息这么被消费呢？正常情况下，这条消息进入 Broker 之后，库存系统和营销系统作为两个消费组，每个组都会拉取到这条消息。也就是说这个订单支付成功的消息，库存系统会获取一条，营销系统也会获取到一条，他们都会获取到这条消息。 但是，库存系统这个消费组组里有两台机器，是两台机器都获取到这条消息，还是说只有一台机器会获取到这条消息？正常情况下，库存系统的两台机器只有一台会获取到这条消息，营销系统也是同理。如图： 这就是在消费的时候我们要注意的一点，不同的系统应该设置不同的消费组，如果不同的消费组订阅了同一个 Topic，对 Topic 里的一条消息，每个消费组都会获取到这条消息。 集群模式消费 VS 广播模式消费接着，对于一个消费组而言，它获取到一条消息之后，如果消费组内部有多台机器，到底是只有一台机器可以获取到这个消息，还是每台机器都可以获取到这个消息。这个就是集群模式和广播模式的区别。 默认情况下都是集群模式，即一个消费组获取到一条消息，只会交给组内的一台机器去处理，不是每台机器都可以获取到这条消息的。但是我们可以通过如下设置来改变为广播模式： 1consumer.setMessageModel(MessageModel.BROADCASTING) 如果修改为广播模式，那么对于消费者组获取到的一条消息，组内每台机器都可以获取到这条消息。但是相对而言广播模式其实用的很少，常见基本上都是使用集群模式来进行消费的。 重温 MessageQueue、CommitLog、ConsumeQueue 之间的联系接着我们来看一下 MessageQueue 与消费者的关系。通过之前的文章我们知道，一个 Topic 在创建的时候我们是要设置它有多少个 MessageQueue 的，而且我们也知道，在 Broker 上 MessageQueue 是如何跟 ConsumeQueue 对应起来的。 根据之前的文章，我们大致可以如此理解，Topic 中的多个 MessageQueue 会分散在多个 Broker 上，每个 Broker 机器上，一个 MessageQueue 就对应了一个 ConsumeQueue，当然在物理磁盘上其实是对应了多个 ConsumeQueue 文件的，但是我们也大致理解为一一对应的关系。 但是对于一个 Broker 机器而言，存储在它上面的所有 Topic 以及 MessageQueue 的消息数据都是写入一个统一的 CommitLog 的，然后对于 Topic 的MessageQueue 而言，就是通过各个 ConsumeQueue 文件来存储属于 MessageQueue 的消息在 CommitLog 文件中的物理位置，就是一个 offset 偏移量。如图： MessageQueue 与消费者的关系对于一个 Topic 上的多个 MessageQueue，是如何由一个消费者中的多台机器来进行消费的？其实这里的源码实现细节较为复杂，我们可以简单理解为，它会均匀的将 MessageQueue 分配给消费者的多台机器来消费。 例如，假设我们的 “TopicOrderPaySuccess” 里有 4 个 MessageQueue，这 4 个 MessageQueue 分布在两个 Master Broker 上，每个 Master Broker 上有 2 个 MessageQueue。然后库存系统作为一个消费者组里有两台机器，那么正常情况下，当然最好的就是让这两台机器每个都负责 2 个 MessageQueue 的消费了。 比如库存系统的 机器01 从 Master Broker01 上消费 2 个 MessageQueue，然后库存系统的 机器02 从 Master Broker02 上消费 2 个 MessageQueue，这就就把消费的负载均摊到两台 Maser Broker 上去了。 所以你大致可以认为一个 Topic 的多个 MessageQueue 会均匀分摊给消费组内的多个机器去消费，这里的一个原则就是：一个 MessageQueue 只能被一个消费者机器去处理，但是一台消费者机器可以负责多个 MessageQueue 的消息处理。 Push 模式 VS Pull 模式我们已经知道了一个消费组内的多台机器是分别负责一部分 MessageQueue 的消费的，那么既然如此，每台机器就必须去连接到对应的 Broker，尝试消费里面的 MessageQueue 对应的消息。此时就涉及到两种消费模式了，一个是 Push，一个是 Pull。实际上，这两个消费模式本质是一样的，都是消费者机器主动发送请求到 Broker 机器去拉取一批消息下来。 Push 消费模式本质也是基于这种消费者主动拉取到的模式来实现的，只不过它的名字叫 Push 而已，意思是 Broker 会尽可能实时的把新消息交给消费者机器来进行处理，它的消息时效性会更好。一般我们使用 RocketMQ 的时候，消费模式通常都是基于它的 Push 模式来做的，因为 Pull 模式的代码写起来更加的复杂和繁琐，而且 Push 模式底层是基于消息拉取的方式来做的，只不过时效性更好而已。 Push 模式的实现思路简单说一下：当消费者发送请求到 Broker 去拉取消息的时候，如果有新的消息可以消费那么就会立马返回一批消息到消费机器去处理，处理完之后会接着立刻发送请求到 Broker 机器去拉取下一批消息。所以消费机器在 Push 模式下会处理完一批消息，立马发起请求拉取下一批消息，消息处理的时效性非常好，看起来就跟 Broker 一直不停地推送消息到消费者一样。 另外 Push 模式下有一个请求挂起和长轮询的机制，也简单说一下。当你的请求发送到 Broker，结果发现没有新的消息给你处理的时候，就会让请求线程挂起，默认是挂起 15秒，然后这个期间它会有后台线程每隔一会就去检查一下是否有新的消息给你。另外如果在这个挂起过程中，如果有新的消息到达了会主动唤醒挂起的线程，然后把消费返回给你。 Broker 如何将消息读取出来返回给消费机器Broker 在收到消费机器的拉取请求之后，如何将消息读取出来返回给消费机器？其实这里涉及到两个概念，分别是 ConsumeQueue 和 CommitLog。 假设一个消费者机器发送了拉取请求到 Broker 了，它说这次要拉取 MessageQueue0 中的消息，然后我之前都没拉取过消息，所以就从这个 MessageQueue0 中的第一条消息开始拉取就好了。于是，Broker 就会找到 MessageQueue0 对应的 ConsumeQueue0，从里面找到第一条消息的 offset。 接着 Broker 就需要根据 ConsumeQueue0 中找打的第一条消息的地址，去 CommitLog 中根据这个 offset 地址去读取这条消息的数据，然后把这条消息的数据返回给消费者机器。 所以其实消费信息的时候，本质上就是根据你要消费的 MessageQueue 以及开始消费的位置，去找到对应的 ConsumeQueue 读取里面对应位置的消息在 CommitLog 中的物理 offset 偏移量，然后到 CommitLog 中根据 offset 读取消息数据，返回给消费者机器。 消费者机器处理消息、进行 ACK 以及提交消费进度接着消费者机器拉取到一批消息之后，就会将这批消息回调我们注册的一个函数，如下面： 123456789consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage( List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; // 处理信息 // 标记改消息已经被成功消费 return ConsumerConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;) 当我们处理完这批消息之后，消费者机器就会提交我们目前的一个消费进度到 Broker 上，然后 Broker 就会存储我们的消费进度。 比如我们现在对 ConsumeQueue0 的消费进度假设就是在 offset = 1 的位置，那么它会记录下来一个 ConsumeOffset 的东西去标记我们的消费进度，如图： 那么下次这个消费组想要再次拉取这个 ConsumeQueue 的消息，就可以从 Broker 记录的消费位置开始拉取，不用重头开始拉取了。 消费组中出现机器宕机或者机器扩容最后，如果消费组中出现机器宕机或者扩容机器的情况，会怎么处理？ 这个时候会进入一个 rebalance 的环节，也就是重新给各个消费机器分配它们要处理的 MessageQueue。 例如现在 机器01 负责 MessageQueue0 和 Message1，机器02 负责 MessageQueue2 和 MessageQueue3，现在 机器02 宕机了，那么 机器01 就会接管 机器02 之前负责的 MessageQueue2 和 MessageQueue3；或者如果此时消费组加入了一台 机器03，此时就可以把 机器02 之前负责的 MessageQueue3 转移给 机器03，然后 机器02 就只负责一个 MessageQueue2 的消费了。这就是负载重平衡的概念。 消费者根据什么策略从 Master 或 Slave 上拉取消息Broker 实现高可用架构的时候是有主从之分的，消费者消费消息，可以从 Master Broker 拉取，也可以从 Slave Broker 拉取，具体是要看机器负载来定。所以，到底什么时候从 Master Broker 拉取，什么时候从 Slave Broker 拉取？ 我们先来简单回顾一下，之前我们对 Broker 的读写分离架构师怎样描述的。之前说过，刚开始消费者都是连接到 Master Broker 机器去拉取消息，然后如果 Master Broker 机器觉得自己负载比较高，就会告诉消费者机器，下次可以从 Slave Broker 机器去拉取。 CommitLog 基于 os cache 提升写性能上面我们说过，拉取消息的时候必然会先读取 ConsumeQueue 文件，这个 ConsumeQueue 文件的读取时如何优化的？要搞明白这个，就要回顾一下之前说过的 CommitLog 文件写入的优化原理，其实本质就是基于 os cache 来进行优化的。也就是说，Broker 收到一条消息，会写入 CommitLog 文件，但是会先把 CommitLog 文件中的数据写入 os cache（操作系统管理的缓存）中去，然后 os 自己有后台线程，过一段时间会异步把 os cache 缓存中的 CommitLog 文件的数据刷入磁盘中去。 就是依靠这个写入 CommitLog 时先进入 os cache 缓存，而不是直接进入磁盘的机制，就可以实现 Broker 写 CommitLog 文件的性能是内存写级别的，这才能实现 Broker 超高的消息接入吞吐量。 ConsumeQueue 文件也是基于 os cache 的接下来一个关键的问题，就是 ConsumeQueue 会被大量的消费者发送的请求给高并发地读取，所以 ConsumeQueue 文件的读操作是非常频繁的，而且同时会极大地影响到消费者进行消息拉取的性能和消费吞吐量。 所以实际上 Broker 对 ConsumeQueue 文件同样也是基于 os cache 来进行优化的。即，对于 Broker 机器的磁盘上的大量 ConsumeQueue 文件，在写入的时候也都是优先进入 os cache 中的。而且 os 自己有一个优化机制，就是读取一个磁盘文件的时候，它会自动把磁盘文件的一些数据缓存到 os cache 中。而且 ConsumeQueue 文件主要是存放消息的 offset，所以每个文件很小，30万 条消息的 offset 就只有 5.72MB 而已。所以实际上 ConsumeQueue 文件们不占多多少磁盘空间，它们整体数据量很小，几乎可以被 os 缓存在内存 cache 里。 所以实际上消费者拉取消息的时候，第一步大量地频繁读取 ConsumeQueue 文件，几乎可以说就是跟读内存里的数据的性能是一样的，通过这个就可以保证数据消费的高性能以及高吞吐。 CommitLog 是基于 os cache + 磁盘一起读取的接下来看第二个关键的问题，在进行消息拉取的时候，先读 os cache 里的少量 ConsumeQueue 的数据，这个性能是极高的，然后第二步就是根据你读取到的 offset 去 CommitLog 里读取消息的完整数据了。所以，这个从 CommitLog 里读取消息完整数据是如何读取的？是从 os cache 里读取？还是从磁盘里读取？ 答案是，两者都有。因为 CommitLog 是用来存放消息的完整数据的，所以容量是很大的，毕竟它一个文件就要 1GB，所以整体完全有可能多达几个 TB。这么多数据，不可能都放在 os cache 里。因为 os cache 用的也是机器的内存，一般多也就是几十个 GB 而已，何况 Broker 自身的 JVM 也要用一些内存，留给 os cache 的内存只是一部分而已，比如 10GB ~ 20GB。所以 os cache 对于 CommitLog 而言，无法把它全部数据放在里面给你读取的。 即，os cache 对于 CommitLog 而言，主要是提升文件写入性能，当你不停地写入的时候，很多最新写入的数据都会先停留在 os cache 里，比如这可能有 10GB ~ 20GB 的数据。之后 os 会自动把 cache 里的比较旧的数据刷入磁盘里，腾出来空间给更新写入的数据放在 os cache 里，所以大部分数据可能多达几个 TB 都是在磁盘上的。 所以，当你拉取消息的时候，可以轻松从 os cache 里读取少量的 ConsumeQueue 文件里的 offset，这个性能是极高的，但是当你去 CommitLog 文件里读取完整消息数据的时候，会有两种情况： 如果你读取的是那种刚刚写入 CommitLog 的数据，那么大概率它们还停留在 os cache 中，此时你可以顺利地直接从 os cache 里读取 CommitLog 中的数据，这个就是内存读取，性能是很高的。 你读取的是比较早之前写入 CommitLog 的数据，那些数据早就被刷入磁盘了，已经不再 os cache 里了，那么此时你就只能从磁盘上的文件读取了，这个性能是比较差一些的。 什么时候从 os cache 读？什么时候从磁盘读如果你的消费者机器一直快速地在拉取和消费处理，紧紧地跟上了生产者写入 Broker 的消息速率，那么你每次拉取几乎都是在拉取最近人家刚写入 CommitLog 的数据，那几乎都在 os cache 里。但是如果 Broker 的负载很高，导致你拉取消息的速度很慢，或者是你自己的消费者机器拉取到一批消息之后处理的性能很低，处理的速度很慢，这都会导致你跟不上生产者的写入速率。 比如人家到写入 10万 条数据了，而你才拉取了 2万 条数据，此时有 5万 条最新的数据是在 os cache 里，有 3万 条你还没拉取的数据是在磁盘里，那么后续当你再拉取的时候，必然很大概率是从磁盘里读取早就刷入磁盘的 3万 条数据。 接着之前再 os cache 里的 5万 条数据可能又被刷入磁盘了，取而代之的是更新的几万条数据在 os cache 里，然后你再次拉取的时候，又会从磁盘里读取刷入磁盘里的 5万 条数据，相当你每次都在从磁盘里读取数据了。 Master Broker 什么时候会让你从 Slave Broker 拉取数据那到底什么时候 Master Broker 会让你从 Slave Broker 拉取数据？假设此时你的 Broker 里已经写入了 10万 条数据，但是你仅仅拉取了 2万 条数据，下次你拉取的时候，是从第 2万 零 1 条数据开始继续往后拉，也就是说，此时你有 8万 条数据是没有拉取的。 然后 Broker 自己是知道机器上当前的整体物理内存有多大的，而且它知道自己可用的最大空间占里面的比例，它是知道自己的消息最多可以在内存里放多少的。比如它知道它最多在内存里存放 5万 条消息而已。然后这个时候你过来拉取消息，它发现你还有 8万 条消息没有拉取，这个 8万 条消息它发现是大于最多存放的 5万 条消息的，那么此时就说明，肯定有 3万 条消息目前是在磁盘上的，不在 os cache 内存里。 所以经过上述判断，会发现此时你很大概率会从磁盘里加载 3万 条消息出来，他会认为，出现这种情况，很可能是因为自己作为 Master Broker 负载太高，导致没法及时把消息给你，所以你落后的进度比较多。这个时候，它会告诉你，我这次给你从磁盘里读取 3万 条消息，但是下次你还是从 Slave Broker 去拉取吧。 以上就是对这个关键问题的解答，本质是对你当前没有拉取消息的数量和大小，以及最多可以存放在 os cache 内存的消息的大小，如果你没拉取的消息超过了最大能使用的内存的量，那么说明你后续会频繁从磁盘加载数据，此时就让你从 Slave Broker 去加载数据了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ - 基于 DLedger 技术的 Broker 主从同步班原理]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F02%2FRocket-%E5%9F%BA%E4%BA%8E-DLedger-%E6%8A%80%E6%9C%AF%E7%9A%84-Broker-%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%8F%AD%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[之前有跟大家说过 Broker 的数据存储原理，接下来我们就说说 Broker 接收到数据写入之后，是如何同步给其他的 Broker 做多副本冗余的。这里就会牵扯到 DLedger 是个什么东西，因为我们是基于 DLedger 实现 Broker 多副本高可用的。 首先，我们回顾一下，producer 写入消息到 broker 之后，broker 会将消息写入本地 CommitLog 磁盘文件中，然后还有一些 ConsumeQueue 会存储 Topic 下各个 MessageQueue 的消息的物理位置。而且，要让 Broker 实现高可用，那么必须有一个 Broker 组，里面有一个是 Leader Broker 可以写入数据，然后让 Leader Broker 接收到数据之后，直接把数据同步给其他的 Follower Broker。如图： 这样的话，一条数据就会在三个 Broker 上有三份副本，此时如果 Leader Broker 宕机，那么就直接让其它的 Follower Broker 自动切换为新的 Leader Broker，继续接收客户端的额数据写入就可以了。 基于 DLedger 技术替换 Broker 的 CommitLog首先，Broker 上述高可用架构就是基于 Dledger 技术来实现的，所以，我们要先知道 DLedger 技术可以干什么。 DLedger 技术实际上它自己就有一个 CommitLog 机制，你把数据交给它，它会写入 CommitLog 磁盘文件里去，这是它干的第一件事。如图，如果基于 DLedger 技术来实现 Broker 高可用架构，实际上就是用 DLedger 先替换原来 Broker 自己管理的 CommitLog，由 DLedger 来管理 CommitLog。 所以第一步，我们需要使用 DLedger 来管理 CommitLog，然后 Broker 还是可以基于 DLedger 管理的 CommitLog 去构建机器上的各个 ConsumeQueue 磁盘文件。 DLedger 基于 Raft 协议选举 Leader Broker我们知道首先基于 Dledger 替换各个 Broker 上的 CommitLog 管理组件了，那么就是每个 Broker 上都有一个 Dledger 组件了。接着我们思考一下，如果我们配置了一组 Broker，比如有 3 台机器，Dledger 是如何从 3 台机器里选举出一个 Leader 的？ 实际上 Dledger 是基于 Raft 协议来进行 Leader Broker 选举的，那么 Raft 协议中是如何进行多台机器的 Leader 选举的？ 这需要发起一轮一轮的投票，通过三台机器互相投票选出来一个人作为 Leader。简单来说，三台 Broker 机器启动的时候，他们会投票自己作为 Leader，然后把这个投票发送给其他 Broker。例如，Broker01 是投票给自己的，Broker02 是投给自己的，Broker03 是投给自己的，他们把自己的投票发送给了别人。 此时在第一轮的选举中，Broker01 会收到别人的投票，它发现自己是投给自己的，其他人也是投给自己的，所以第一轮选举是失败的。因为大家都投票给自己，是选举不出一个 Leader 的。 接着每个 Broker 会进入一个随机的休眠，比如 Broker01 休眠 3 秒，Broker02 休眠 5 秒，Broker03 休眠 4 秒。此时 Broker01 必然是先苏醒过来，它苏醒之后，会继续尝试投票给自己，并且发送自己的选票给别人。 接着 Broker03 休眠 4 秒过后苏醒，它发现 Broker01 已经发送来了一个选票是投给 Broker01 自己的，此时它因为自己没投票，随意会尊重别人的选择，直接把票投给 Broker01了，同时把自己的投票发送给别人。 接着 Broker02 苏醒了，它收到了 Broker01 投票给 Broker01 自己，Broker03 也投票给了 Broker01，此时它自己因为没投票，也会尊重别人的选择，直接把票投给 Broker01 了，并且把自己的投票发送给别人。 此时所有 Broker 都会收到三张投票，都是投给 Broker01 的，那么 Broker01 就会当选为 Leader。气质只要有 （3 台机器 / 2）+ 1 个人投票给某人，就会选举它当 Leader，这个 （机器数量 / 2）+ 1 就是大多数的意思。 这就是 Raft 协议中选举 Leader 算法的简单描述，简单来说，它确保有人可以成为 Leader 的核心机制就是一轮选举不出来 Leader 的话，就让大家随机休眠一下，先苏醒过来的人会投票给自己，其他人苏醒过后发现自己收到选票了，就会直接投票给那个人。依靠这个随机休眠的机制，基本上几轮投票过后，一般都是可以快速选举出来一个 Leader。 因此，在三台 Broker 机器刚刚启动的时候，就是靠这个 Dledger 基于 Raft 协议实现的 Leader 选举机制，互相投票选举出一个 Leader，其他人就是 Follower，然后只有 Leader 可以接收数据写入，Follower 只能接收 Leader 同步过来的数据。 Dledger 是如何基于 Raft 协议进行多副本同步的接下来，Leader Broker 收到消息之后，是怎么基于 DLedger 把数据同步给其他 Broker 的。Dledger 在进行同步的时候是采用 Raft 协议进行多副本同步的，我们接下来就说说 Raft 协议中的多副本同步机制。 简单来说，数据同步会分为两个阶段，一个 uncommitted 阶段，一个是 committed 阶段。 首先 Leader Broker 上的 DLedger 收到一条数据之后，会标记为 uncommitted 状态，然后它会通过自己的 DLedgerServer 组件把这个 uncommitted 数据发送给 Follower Broker 的 DLedgerServer。如图： 接着 Follower Broker 的 DLedgerServer 收到 uncommitted 消息之后，必须返回一个 ack 给 Leader Broker 的 DLedgerServer，然后如果 Leader Broker 收到超过半数的 Follower Broker 返回 ack之后，就会将消息标记为 committed 状态。然后 Leader Broker 上的 DLedgerServer 就会发送 committed 消息给 Follower Broker 机器的 DLedgerServer，让它们也把消息标记为 committed 状态。 这个就是基于 Raft 协议实现的两阶段完成的数据同步机制。 Leader Broker 崩溃了怎么办通过上面分析我们知道，对于高可用 Broker 架构而言，无论是 CommitLog 写入，还是多副本同步，都是基于 DLedger 来实现的。那么，如果 Leader Broker 挂了怎么办。 如果 Leader Broker 挂了，此时剩下的两个 Follower Broker 就会重新发起选举，它们会基于 DLedger 采用 Raft 协议的算法，去选举一个新的 Leader Broker 继续对外提供服务，而且会对没有完成的数据同步进行一些恢复性的操作，保证数据不会丢失。 如下图就是示意 Leader Broker 挂了之后，Follower Broker 称为了新的 Leader Broker，然后生产者吸入新的 Leader Broker 的一个过程。新选举出来的 Leader 会把数据通过 DLedger 同步给剩下的一个 Follower Broker。 总结今天我们讲了基于 DLedger 技术的高可用 Broker 集群是如何运行的，包含了一下的一些内容： Broker 高可用架构原理回滚：多副本同步 + Leader 自动切换 基于 DLedger 基础管理 CommitLog Broker 集群启动时，基于 DLedger 技术和 Raft 协议完成 Leader 选举 Leader Broker 写入之后，基于 DLedger 技术和 Raft 协议同步给 Follower Broker 如果 Leader Broker 崩溃，则基于 DLedger 和 Raft 协议重新选举 Leader]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadLocal]]></title>
    <url>%2FCKING.github.io%2F2020%2F04%2F01%2FThreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocal 用在什么地方讨论 ThreadLocal 用在什么地方之前，我们先明确下，如果仅仅只有一个线程，都不用谈 ThreadLocal 了，因为 ThreadLocal 是用在多线程的场景的！！ ThreadLocal 归纳下来就 2 类用途： 保存线程上下文信息，在任意需要的地方可以获取 线程安全的，避免某些情况需要考虑线程安全必须同步带来的性能损失 保存线程上下文信息，在任意需要的地方可以获取由于 ThreadLocal 的特性，同一线程在某地方进行设置，在随后的任意地方都可以获取到，从而可以用来保存线程上下文信息。 常用的比如每个请求怎么把一串后续关联起来，就可以用 ThreadLocal 进行 set，在后续的任意需要记录日志额的方法里进行 get 获取到请求 id，从而把整个请求串起来。还有比如 Spring 的事务管理，用 ThreadLocal 存储 Connection，从而各个 DAO 可以获取同一个 Connection，可以进行事务回滚，提交等操作。 备注：ThreadLocal 的这种用处，很多时候是用在一些优秀的框架里面的，一般我们很少接触，反而下面的场景我们接触的更多一些 线程安全，避免某些情况需要考虑线程安全必须同步带来的性能损失ThreadLocal 为解决多线程程序的并发问题提供了一种新的思路，但是 ThreadLocal 也有局限性，我们来看看阿里的规范： 【参考】ThreadLocal 无法解决共享对象的更新问题，ThreadLocal 对象建议使用 static 修饰。这个变量时针对一个线程内所有操作共享的，所以设置为静态变量，所有此类实例共享次静态变量，也就是说在类第一次被使用时装载，只分配一块存储空间，所有此类的对象（主要是这个线程内定义的）都可以操控这个变量。 每个线程往 ThreadLocal 中读写数据是线程隔离，互相之间不会影响的，所以 ThreadLocal 无法解决共享对象的更新问题。 由于不需要共享信息，自然就不存在竞争问题，从而保证了某些情况下线程的安全，以及避免了某些情况需要考虑线程安全必须同步带来的性能损失。 这类场景阿里规范也提到了： ThreadLocal 一些细节ThreadLocal 使用示例代码： 12345678910111213141516171819202122232425262728293031323334353637public class ThreadLocalTest &#123; private static ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;&gt;(); public static void main(String[] args) &#123; new Thread(() -&gt; &#123; try &#123; for (int i = 0; i &lt; 100; i++) &#123; threadLocal.set(i); System.out.println(Thread.currentThread().getName() + "===" + threadLocal.get()); try&#123; Thread.sleep(200); &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; finally &#123; threadLocal.remove(); &#125; &#125;, "threadLocal1").start(); new Thread(() -&gt; &#123; try &#123; for(int i = 0; i &lt; 100; i++) &#123; System.out.println(Thread.currentThread().getName() + "===" + threadLocal.get()); try &#123; Thread.sleep(200); &#125;catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; finally &#123; threadLocal.remove(); &#125; &#125;, "threadLocal2").start(); &#125;&#125; 代码运行结果： 从运行的结果我们可以看到 ThreadLocal1 进行 set 值对 ThreadLocal2 没有任何影响 Thread、ThreadLocalMap、ThreadLocal 总览图： Thread 类有属性变量 threadLocals（类型是 ThreadLocal.ThreadLocalMap），也就是说每个线程有一个自己的 ThreadLocalMap，所以每个线程往这个 ThreadLocal 中读写隔离的，并且是互相不会影响的。 一个 ThreadLocal 只能存储一个 Object 对象，如果需要存储多个 Object 对象那么就需要多个 ThreadLocal。如图： 看到上面的几个图，大概思路应该都清晰了，我们 Entry 的 key 指向 ThreadLocal 用虚线表示弱引用，下面我们看看 ThreadLocalMap： java 对象的引用包括：强引用、软引用、弱引用、虚引用。因为这里涉及到弱引用，简单说明下，弱引用也是用来描述非必需对象的，当 JVM 进行垃圾回收时，无论内存是否充足，该对象仅仅被弱引用关联，那么就会被回收。 当仅仅只有 ThreadLocalMap 中的 Entry 的 key 指向 ThreadLocal 的时候，ThreadLocal 会进行回收的。ThreadLocal 被垃圾回收后，在 ThreadLocalMap 里对应的 Entry 的 key 值会变成 null，但是 Entry 是强引用，那么 Entry 里面存储的 Object，并没有办法进行回收。所以，ThreadLocal 做了一些额外的回收工作。 虽然做了但是也会存在内存泄露风险，所以后面会提到 ThreadLocal 最佳实践 ThreadLocal 的最佳实践ThreadLocal 被垃圾回收后，在 ThreadLocalMap 里对应的 Entry 的键值会变成 null，但是 Entry 是强引用，那么 Entry 里面存储的 Object，并没有办法进行回收，所以，ThreadLocalMap 做了一些额外的回收工作。 备注：很多时候，我们都是用在线程池的场景，程序不停止，线程基本不会销毁 由于线程的生命周期很长，如果我们往 ThreadLocal 里面 set 了很大很大的 Object 对象，虽然 set、get 等等方法在特定的条件会调用进行额外的清理，但是 ThreadLocal 被垃圾回收后，在 ThreadLocalMap 里对应的 Entry 的键值会变成 null，但是后续也没有操作 set、get 等方法了。 所以最佳实现，应该在我们不使用的时候，主动调用 remove 方法进行清理。 【参考】ThreadLocal 无法解决共享对象的更新问题，ThreadLocal 对象建议使用 static 修饰。这个变量时针对一个线程内所有操作共享的，所以设置为静态变量，所有次类实例共享次静态变量，也就是说再类第一次被使用时装载，只分配一块存储空间，所有此类的对象（只要是这个线程内定义的）都可以操控这个变量。 这里把 ThreadLocal 定义为 static 还有一个好处是，由于 ThreadLocal 里有强引用在，那么在 ThreadLocalMap 里对应的 Entry 的键也会永远存在，那么执行 remove 的时候就可以正确进行定位并且删除。 所以最佳实践做法应该为： 参考资料ThreadLocal]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Synchronized 和 volatile]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F30%2FSynchronized-%E5%92%8C-volatile%2F</url>
    <content type="text"><![CDATA[Synchronized 关键字Synchronized 关键字，可以同时保证原子性、可见性以及有序性 原子性层面而言，它加了 synchronized 之后，就有一个加锁和释放锁的机制。加锁之后，同一段代码就只有它可以执行了 可见性，它会通过加入一些内存屏障，使得它在同步代码块中对变量做的写操作，都会在释放锁的时候，全部强制执行 flush 操作；在进入同步代码块的时候，对变量的读操作，全部会强制执行 refresh 操作。这样那些更新了的数据，别的线程只要进入代码块，就可以读到 有序性，synchronized 关键字，它会通过加各种各样的内存屏障，来解决 LoadLoad、StoreStore 等重排序。 Synchronized 通过加锁保证原子性之前有跟简单说过 synchronized 加锁的原理，说白了，就是在进入加锁代码块的时候加一个 monitorenter 的指令，然后针对锁对象关联的 monitor 累加加锁计数器，同时标识自己这个线程加了锁。通过 monitor 里的加锁计数器可以实现可重入的加锁。 在出锁代码块的时候，加一个 monitorexit 的指令，然后递减锁计数器。如果锁计数为 0，就会标志当前线程不持有锁，从而释放锁。 另外，wait 和 notify 关键字的实现也是依托于 monitor 实现的。在线程执行 wait 之后，自己会加入一个 waitset 中等待唤醒获取锁。notifyall 操作会从 monitor 的 waitset 中唤醒所有的线程，让他们竞争获取锁。 我们看如下的代码： 12345MyObject lock = new MyObject();synchronized(lock)&#123;&#125; Java 对象都是分为对象头和实例变量两块的，其中实例变量就是平时看到的对象里的那些变量数据。然后对象头包含了两块东西，一个是 Mark Word（包含了 hashCode、锁数据、GC 数据等等），另一个是 Class Metadata Address（包含了指向类的元数据的指针） 在 Mark Word 里就有一个指针，是指向了这个对象实例关联的 monitor 的地址，这个 monitor 是 c++ 实现的，不是 Java 实现的。这个 monitor 实际上就是 c++ 实现的一个 ObjectMonitor 对象，里面包含了一个 _owmer 指针，指向了持有锁的线程 ObjectMonitor 里还有一个 entrylist，想要加锁的线程全部先进入这个 entrylist 等待获取机会尝试加锁，有机会加锁的线程，就会设置 _owner 指针指向自己，然后对 _count 计数器累加 1 次。 各个线程尝试竞争进行加锁，此时竞争加锁是在 JDK1.6 以后优化成了基于 CAS 来进行加锁，理解为跟之前的 Lock API 的加锁机制是类似的。通过 CAS 操作，操作 _count 计数器，例如将 _count 值尝试从 0 变为 1 如果成功了，那么执行加锁成功，如果失败了，那么加锁就失败了 然后释放锁的时候，先是对 _count 计数器递减 1，如果为 0 了就会设置 _owner 为 null，不再指向自己，代表自己彻底释放锁。 如果获取锁的线程执行 wait，就会将计数器递减，同时 _owner 设置为 null，然后自己进入 waitset 中等待唤醒，别人获取了锁执行 notify 的时候就会唤醒 waitset 中的线程竞争尝试获取锁。 这里需要注意的是，尝试加锁这个过程，也就是对 _count 计数器累加操作。如何保证多线程并发安全的原子性？就如上面说的，在 JDK1.6 之后，对 synchronized 内的加锁机制做了大量的优化，这里就是优化为 CAS 加锁的。 Synchronized 使用内存屏障保证可见性和有序性Java 的并发技术底层很多都对应了内存屏障的使用，包括 synchronized，它底层也是依托于各种不同的内存屏障来保证可见性和有序性的。 按照可见性来划分的话，内存屏障可以分为 Load 屏障和 Store 屏障。 Load 屏障的作用是执行 refresh 处理器缓存的操作。说白了就是对别的处理器更新过的值，从其他处理器的高速缓存（或者主内存）加载数据到自己的高速缓存来，确保自己看到的是最新的数据。 Store 屏障的作用是执行 flush 处理器缓存的操作，就是把自己当前处理器更新的变量的值，都刷到高速缓存（或者主内存）里去。 在 monitorexit 指令之后，会有一个 Store 屏障，让线程把自己在同步代码块里修改的变量的值都执行 flush 处理器缓存的操作，刷到高速缓存（或者主内存）里去；然后在 monitorenter 指令之后会加一个 Load 屏障，执行 refresh 处理器缓存的操作，把别的处理器修改过的最新值加载到自己高速缓存里来。 所以说，通过 Load 屏障和 Store 屏障，就可以让 synchronized 保证可见性 123456789101112int b = 0;int c = 0;synchronized(this) &#123; -&gt; monitorenter Load 内存屏障 int a = b; c = 1; // synchronized 代码块里还是可能发生指令重排&#125; -&gt; monitorexitStore 内存屏障 按照有序性保障来划分的话，还可以分为 Acquire 屏障和 Release 屏障 在 monitorenter 指令之后，Load 屏障之后，会加一个 Acquire 屏障，这个屏障的作用是禁止读操作和读写操作之间发生指令重排序；在 monitorexit 指令之前，会加一个 Release 屏障，这个屏障的作用是禁止写操作和读写操作之间发生重排序。 所以说，通过 Acquire 屏障和 Release 屏障，就可以让 synchronized 保证有序性，只有 synchronized 内部的指令可以重排序，但是绝对不会跟外部的指令发生重排序。 1234567891011121314151617int b = 0;int c = 0;synchronized(this) &#123; -&gt; monitorenter Load 内存屏障 Acquire 内存屏障 int a = b; c = 1; // synchronized 代码块里还是可能发生指令重排 Release 内存屏障 &#125; -&gt; monitorexitStore 内存屏障 总结： 原子性：通过加锁和释放锁来保证原子性 可见性：加了 Load 屏障和 Store 屏障，释放锁 flush 数据，加锁会 refresh 数据 有序性：Acquire 屏障和 Release 屏障，保证同步代码块内部的指令可以重排，但是同步代码块内部的指令和外面的指令是不能重排的。 Volatilevolatile 对原子性的保证是非常有限的，其实主要是 32 位 JVM 中的 long/double 类型变量的赋值操作是不具备原子性的，加上 volatile 就可以保证原子性了。 在 volatile 变量写操作的前面会加一个 Release 屏障，然后在之后会加入一个 Store 屏障，这样就可以保证 volatile 写跟 Release 屏障之前的任何读写操作都不会指令重排。然后 Store 屏障保证了，写完数据之后，立马会执行 flush 处理器缓存的操作。 在 volatile 变量读操作的前面会加入一个 Load 屏障，这样就可以保证对这个变量的读取时，如果被别的处理器修改过了，必须得从其他处理器的高速缓存（或者主内存）中加载到自己本地高速缓存里，保证读到的是最新的数据。之后会加入一个 Acquire 屏障，禁止 volatile 读操作之后的任何读写操作会跟 volatile 读指令重排序。 那个 Acquire 屏障其实就是 LoadLoad 屏障 + LoadStore 屏障，Release 屏障就是 StoreLoad 屏障 + StoreStore 屏障 1234567线程1:Release 屏障isRunning = false;Store 屏障 123456789线程2:Load 屏障while(isRunning) &#123; Acquire 屏障 // 代码逻辑&#125; 总结volatile 和 synchronized 保证可见性和有序性，原来都是通过各种内存屏障来实现的，因为加了内存屏障，就会有一些特殊的指令和实现，就可以保证可见性和有序性了。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再谈原子性、可见性和有序性]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F26%2F%E5%86%8D%E8%B0%88%E5%8E%9F%E5%AD%90%E6%80%A7%E3%80%81%E5%8F%AF%E8%A7%81%E6%80%A7%E5%92%8C%E6%9C%89%E5%BA%8F%E6%80%A7%2F</url>
    <content type="text"><![CDATA[思维导图 原子性Java 语言规范里，int i = 0、resource = loadResources、flag = true，各种变量的简单赋值操作，规定都是原子的，包括引用类型的变量的赋值操作，也是原子的。 但是很多复杂的操作，例如 i++，先读取 i 的值，再更新 i 的值。还有 i = y + 2，先读取 y 的值，再更新 i 的值，这种复杂操作，不是简单赋值写，它是有计算的过程在里面的，此时 Java 语言规范默认是不保证原子性的。 volatile 关键字，保证了可见性和有序性，但不保证原子性。像上面的 i++，i = y + 2，volatile都是不保证原子性的。 赋值写操作中不保证原子性的特例原子性这块，在 32 位虚拟机里的 long/double 类型的变量的简单赋值写操作，不是原子的。例如 long i = 30、double c = 45.0，在 32 位虚拟机里就不是原子的，因为 long 和 double 是 64 位的。 如果多个线程同时并发执行 long i = 30，long 是 64 位的，就会导致有的线程在修改 i 的高 32 位，有的线程在修改 i 的低 32 位，多线程并发给 long 类型的变量进行赋值操作，在 32 位的虚拟机下，是有问题的。可能会导致多线程给 long i = 30 赋值之后，导致 i 的值不是 30，可能是 -3333334429 乱码一样的数字，就是因为高低 32 位赋值错了，就导致二进制数字转换为十进制之后是一个很奇怪的数字。 volatile 保证原子性的特例volatile 对原子性保证的语义，在 Java 里是很有限的，几乎可以忽略不计。32 位的 Java 虚拟机里面，对 long/double 变量的赋值写是不原子的，此时如果对变量加上了 volatile，就可以保证在 32 位 Java 虚拟机里面，对 long/double 变量的赋值是原子的了。 硬件级别思考可见性的问题每个处理器都有自己的寄存器（register），所以多个处理器各自运行一个线程的时候，可能导致某个变量给放到寄存器里去，接着就会导致各个线程没法看到其他处理器寄存器里的变量的值修改了。可见性的第一个问题，就有可能在寄存器的级别，导致变量副本的更新，无法让其他处理器看到。 然后处理器运行的线程对变量的操作都是针对写缓冲来的（store buffer），并不是直接更新主内存，所以很可能导致一个线程更新了变量，但是仅仅是在写缓冲区而已，没有更新到主内存里去。这个时候，其他处理器的线程是没法读到它的写缓冲区的变量值的，所以此时会有可见性的问题，这是第二个可见性发生的场景。 然后即使这个时候一个处理器的线程更新了写缓冲区之后，将更新同步到了自己高速缓存里（cache，或者是主内存），然后还把这个更新通知给了其他的处理器，但是其他处理器可能就是把这个更新放到无效队列里，没有更新它的高速缓存。此时其他处理器的线程从高速缓存里读数据的时候，读到的还是过时的旧值。 MESI协议如果要实现可见性，其中一个方法就是通过 MESI 协议。这个 MESI 协议实际上有很多种不同的实现，因为它不过就是一个协议，具体的实现机制要考具体底层的系统如何实现。根据具体底层硬件的不同，MESI 协议的实现是有区别的。 比如说 MESI 协议有一种实现，就是一个处理器将另外一个处理器的高速缓存中的更新后的数据拿到自己的高速缓存中更新一下，这样大家的缓存不就实现同步了，然后各个处理器的线程看到的数据就一样了。 为了实现 MESI 协议，有两个配套的专业机制需要说一下：flush 处理器缓存、refresh 处理器缓存。 flush 处理器缓存，它的意思是把自己更新的值刷新到高速缓存里去（或者是主内存），因为必须要刷到高速缓存（或者是主内存）里，才有可能在后续通过一些特殊的机制让其他的处理器从自己的高速缓存（或者是主内存）里读取到更新的值。 除了 flush 以外，它还会发送一个消息到总线（bus），通知其他处理器，某个变量的值被它修改了。 refresh 处理器缓存，它的意思就是说再读取一个变量的值的时候，如果发现其他处理器的线程更新了变量的值，必须从其他处理器的高速缓存（或者是主内存）里，读取这个最新的值，更新到自己的高速缓存中。 所以，为了保证可见性，在底层是通过 MESI 协议、flush 处理器缓存和 refresh 处理器缓存，这一整套机制来保障的。要记住，flush 和 refresh 这两个操作，flush 是强制刷新数据到高速缓存（或主内存），不要仅仅停留在写缓冲器里面；refresh，是从总线嗅探发现某个变量被修改，必须强制从其他处理器的高速缓存加载变量的最新值到自己的高速缓存里去。 内存屏障的使用，在底层硬件级别的原理，其实就是在执行 flush 和 refresh。还有 volatile 关键字： 1volatile boolean isRunning = true; 当执行 isRunning = false 时，就是写 volatile 变量，就会通过执行一个内存屏障，在底层触发 flush 处理器缓存的操作；while(isRunnig) {}，读 volatile 变量，也会通过执行一个内存屏障，在底层触发 refresh 操作。 一个变量加了 volatile 修饰之后，对这个变量的写操作，会执行 flush 处理器缓存，把数据刷到高速缓存（或者是主内存）中，然后对这个变量的读操作，会执行 refresh 处理器缓存，从其他处理器的高速缓存中，读取最新的值。 有序性Java 程序运行过程中发生指令重排的几个地方我们写好的代码在实际执行的时候那个顺序可能在很多环节都会被人给重排序，一旦重排序之后，在多线程并发的场景下，就有可能出现一些问题。 1、自己写的源代码中的执行顺序，这个是我们自己写的代码，一般来说就是按照我们自己脑子里想的那样来写。 2、编译后的代码的执行顺序。java 里有两种编译器，一个是静态编译器（javac），一个是动态编译器（JIT）。javac 负责把 .java 文件中的源代码编译为 .class 文件中的字节码，这个一般是程序写好之后进行编译的。JIT 负责把 .class 文件中的字节码编译为 JVM 所在操作系统支持的机器码，一般在程序运行过程中进行编译。 在这个编译的过程中，编译器是很有可能调整代码的执行顺序的，为了调高代码的执行效率，很可能调整代码的执行顺序。JIT 编译器对指令重排的还是挺多的。 3、处理器的执行顺序。哪怕你给处理器一个代码的执行顺序，但是处理器还是可能会重排代码，更换一种执行顺序。JIT 编译好的指令，还是可能会被处理器调整顺序 4、内存重排序。有可能你这个处理器在执行指令的时候，在高速缓存和写缓冲器、无效队列等等硬件层面的组件，也可能导致你的指令的执行看起来的顺序跟想象的不太一样。 上述就是我们在写好 java 代码之后，从编译到执行的过程中，代码的执行顺序可能有指令重排的地方，只要有指令重排就有一定可能造成程序执行异常。 但是编译器和处理器不是胡乱地重排序，他们会遵循一个关键的规则，就是数据依赖规则。如果说一个变量的结果依赖于之前的代码执行结果，那么就不能随意进行重排序，要遵循数据的依赖。例如： 123int a = 3;int b = 5;int c = a * b; 那第三行代码依赖于上面两行代码，第一行和第二行代码可以重排序，但是第三行代码必须放在最下面。 此外还有 happens-before 原则，就是有一些基本的规则是要遵守的，不会让你胡乱地重排序。在遵守一定的规则的前提下，有好几个层面的代码和指令都可能出现重排序。 JIT编译器指令重排的例子JIT 动态编译的时候，有可能造成一个非常经典的指令重排。 1234567891011121314public class MyObject &#123; private Resource resource; public MyObject() &#123; // 从配置文件里加载数据构造 Resource 对象 this.resource = loadResource(); &#125; public void execute() &#123; this.resource.execute(); &#125;&#125; 假设线程 1 执行我们写的这么一行代码： 1MyObject myObj = new MyObject(); 而线程 2 执行下面这行代码： 1myObj.execute(); 首先，我们要知道 new Object() 是如何创建一个 MyObject 对象实例的。 步骤1：以 MyObject 类作为原型，给它的对象实例分配一块内存空间。objRef 就是指向了分配好的内存空间的地址的引用。 1objRef = allocate(MyObject.class); 步骤2：就是针对分配好内存空间的一个对象实例，执行它的构造函数，对这个对象进行初始化的操作，执行我们自己写的构造函数里的一些代码，对各个实例变量赋值，执行初始化的逻辑。 1invokeConstructor(objRef); 步骤3：上面两个步骤搞定之后，一个对象实例就算创建完成。此时就是把 objRef 指针指向的内存地址，赋值给我们自己的引用类型的变量，myObj 就可以作为一个类似指针的概念指向了 MyObject 对象实例的内存地址。 1myObj = objRef; 有可能 JIT 动态编译为了加速程序的执行速度，因为步骤 2 是在初始化一个对象实例，这个步骤是有可能很耗时的，比如说你可能会在这里执行一些网络的通信，磁盘文件的读写等等。而 JIT 为了加速程序的执行性能和效率，就可能发生指令重排，把顺序排为：步骤 1 -&gt; 步骤 3 -&gt; 步骤 2 此时线程 1 刚好执行完了 步骤 1 和步骤 3，步骤 2 还没执行，此时 myObj 已经不是 null 了，但是 MyObject 对象实例内部的 resource 还是 null。而线程 2 直接调用 myObj.execute 方法，此时内部会调用 resource.execute() 方法。但因为 resource 还是 null，直接导致空指针错误。 double check 单例模式里面，就是可能会出现这样的 JIT 指令重排。如果你不加 volatile 关键字，会导致一些问题的发生。volatile 可以避免出现 步骤1、步骤3、步骤2 这样的重排序。 现代处理器为了提升性能的指令乱序和猜测执行机制指令乱序机制指令不一定说是拿到了一个指令立马可以执行的，比如有的指令是要进行网络通信、磁盘读写、获取锁等等，因此有的指令不是立马就绪可以执行的。为了调高效率，在现代处理器里面都是走的指令的乱序执行机制。 把编译好的指令一条一条读取到处理器里，但是哪个指令先就绪可以执行，就先执行，不是按照代码顺序来的。每个指令的结果放到一个重排序处理器中，重排序处理器把各个指令的结果按照代码顺序应用到主内存或者写缓冲器里。 这就导致处理器可能在乱序执行我们代码编译后的指令。 猜测执行机制还有一个猜测执行。比如一个 if 判断有一堆代码，很可能先去执行 if 的代码算出来结果，然后再来判断 if 是否成立。 123456int sum = 0;if(flag) &#123; for(int i = 0; i &lt; 10; i++) &#123; &#125;&#125; 内存重排序处理器会将数据写入写缓冲器，这个过程是 store；从高速缓存里读数据，这个过程是 load。写缓冲器和高速缓存执行 load 和 store 的过程，都是按照处理器指示的顺序来的，处理器的重排处理器也是按照程序顺序来 load 和 store 的。 但是有个问题，就是在其他的处理器看到的一个视觉假象而言，有可能会出现看到的 load 和 store 是重排序的，也就是内存重排序。 处理器的乱序执行和猜测执行，都是指令重排序，这次说的是内存重排序，因为都是发生在内存层面的写缓冲器和高速缓存中的。 这个内存重排序，有 4 种可能性： LoadLoad 重排序：一个处理器先执行一个 L1 读操作，再执行一个 L2 读操作。但是另外一个处理器看到的是先 L2 再 L1 StoreStore 重排序：一个处理器先执行一个 W1 写操作，再执行一个 W2 写操作。但是另外一个处理器看到的是先 W2 再 W1 LoadStore 重排序：一个处理器先执行一个 L1 读操作，再执行一个 W2 写操作。但是另外一个处理器看到的是 W2 在 L1 StoreLoad 重排序：一个处理器先执行一个 W1 写操作，再执行一个 L2 读操作。但是另外一个处理器看到的是先 L2 在 W1 例如，一个处理器向写缓冲器先后写入 W1 W2 的指令。但写缓冲器在内部进行了 指令重排，变成 W2 W1 的顺序写入到高速缓冲中。此时其他处理器看到的顺序就是 W2 再 W1了，这就是 StoreStore 重排序。 再比如，看下面的代码： 12345678910111213141516171819// 共享变量Resource resource = null;Boolean resourceLoaded = false;// 处理器0resource = loadResourceFromDish();resourceLoaded = true;// 处理器1while(!resourceLoaded) &#123; try&#123; Thread.sleep(1000); &#125;catch(Exception e) &#123; &#125;&#125;resource.execute(); 类似上面的代码，很可能处理器 0 先写了 resource，再写了 resourceLoaded。结果写缓冲器进行内存重排序，先落地了 resourceLoaded = true，此时 resource 还是 null。此时处理器 1 就会看到 resourceLoaded = true，就会对 resource 对象执行了 execute() 方法，此时就会有空指针异常的问题。 总之，高速缓存和写缓冲器都可以自己对 Load 和 Store 操作的结果落地到内存进行各种不同的重排序，进而造成上述 4 种内存重排序问题的发生。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 锁]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F26%2FMySQL-%E9%94%81%2F</url>
    <content type="text"><![CDATA[MySQL 的锁类型，一般就是表锁、行锁和页锁。 MyIsam一般 MyIsam 会加表锁。就是在 MyIsam 引擎下，执行查询的时候，会默认加个表共享锁，也就是表读锁，这个时候别人只能来查，不能写数据。当 MyIsam 写的时候，也会加个表独占锁，也就是写表锁，别人不能读也不能写。 InnoDBInnoDB 引擎一般用行锁，但是也有表锁。 InnoDB 的行锁有共享锁（S）和排它锁（X）。共享锁就是，多个事务可以加共享读锁读同一行数据，但是别的事务不能写这行数据；排它锁，就是一个事务只能写这行数据，别的事务只能读，不能写。 InnoDB 的表锁，分成意向共享锁，就是说加共享行锁的时候，必须先加这个共享表锁；还有一个意向排他锁，就是说，给某行加排他锁的时候，必须先给表加排他锁。这个表锁，是 InnoDB 引擎自动加的，不用你自己去加。 对于 insert、update、delete，InnoDB 会自动给那一行加行级排他锁。而对于 select，InnoDB 啥锁都不加，因为 InnoDB 默认实现了可重复读，也就是 mvcc 机制，所以多个事务随便读一个数据，一般不会有冲突，大家就读自己那个快读照就可以了，不涉及到什么锁的问题。 但是 InnoDB 从来不会自己主动加这个共享锁的，除非你用下面的语句自己手动加个锁： 手动加共享锁：SELECT * FROM table WHERE id = 1 LOCK IN SHARE MODE，那你就给那一行加了个共享锁，其他事务就不能来修改这行数据了。 手动加排他锁：SELECT * FROM tabel WHERE id = 1 FOR UPDATE，那你就给那一行加了个排他锁，意思是你准备修改，别的事务就不能修改了。别的事务会 hang 住。这个要慎用，一般我们线上系统不用这个，容易搞出问题。 所以，MySQL 的默认数据库的锁机制，就是：对一行数据，如果有人在修改，会加个排他锁，然后你不能修改，只能等着获取这把锁，但是这个时候你可以随便 select，就是查询你的事务开始之前那行数据的某个版本而已。然后你修改某行数据，会同时拿这个表的排他锁，但是，如果不同的事务修改不同的行，会拿不同行的行级排他锁，但是大家都会拿一个表的排他锁。实际上，InnoDB 的表级排他锁可以随便拿，这个是没有冲突的。 这就是 MySQL InnoDB 存储引擎默认的锁模式。相当于就是一行数据，同一个时刻只能一个人在修改，但是别人修改，你可以随便读，读的都是读某个版本的，走 mvcc 机制。 悲观锁和乐观锁MySQL 里的悲观锁是走 SELECT * FROM table WHERE id = 1 FOR UPDATE。意思是我很悲观，我担心自己拿不到这把锁，我必须先锁死，然后就我一个人可以搞事情，别人都不行，不能加共享锁，也不能加排他锁。 乐观锁，就是我觉得应该没啥问题，我修改的时候感觉差不多可以获取到锁，不需要提前搞一把锁，我就先查出来某个数据，SELECT id, name, version FROM table WHERE id = 1，接着再执行各种业务逻辑之后再修改， UPDATE table SET name = &#39;新值&#39;, version = version + 1 WEHRE id = 1 AND version = 1。就是说每次修改，比较一下这条数据的当前版本号跟我之前查出来的版本号是不是不一样。如果是一样的就修改然后把版本号加 1，否则就不会更新任何一行数据，此时就重新查询后再次更新。 一般悲观锁什么时候用？比如你查出来了一条数据，要在内存中修改后再更新到数据库中去，但是如果这个过程中数据被别人更新了，你是不能直接干这个操作的。这个时候，你就得走上面那个操作，查询之后就不能让别人更新了。 但是真有这种场景，推荐还是用乐观锁。悲观锁实现简单一点，但是太有风险了，很容易死锁。比如事务 A 拿了数据 1 的锁，事务 B 拿了数据 2 的锁，然后事务 A 又要获取数据 2 的锁就会等待，事务 B 又要获取数据 1 的锁，也会等待。此时就会造成死锁，互相等待，永不释放。 死锁事务 A： SELECT * FROM table WHERE id = 1 FOR UPDATE 事务 B： SELECT * FROM table WHERE id = 2 FOR UPDATE 事务 A： SELECT * FROM table WHERE id = 2 FOR UPDATE 事务 B： SELECT * FROM table WHERE id = 1 FOR UPDATE 常见的死锁就是类似上面那种，给大家说过了，分别都持有一个锁，结果还去请求别人的那把锁，结果就是谁也出不来，死锁了。 情况太多，不一一列举了，就说一下发现死锁的时候怎么排查。 其实就是看死锁日志就可以了，然后根据对应的 SQL，找一下对应的代码，具体判断一下为啥死锁了。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ 杂记]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F13%2FRocketMQ-%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[RocketMQ 生产者工作原理MessageQueue要清楚生产者的工作原理，就需要明白一个概念：MessageQueue。而要明白 MessageQueue 是什么，就必须把它跟 Topic 以及 Broker 综合起来看。 如果我们要使用 RocketMQ，要先部署一套 RocketMQ集群，在有了集群之后，就要根据你的业务去创建一些 Topic。比如说创建一个 “TopicOrderPaySuccess” 的 Topic 去存放订单支付成功的消息。像这些 Topic 就可以在 RocketMQ 可视化工作台里去创建，在里面就可以创建一个 Topic 出来，在创建 Topic的时候需要制定一个很关键的参数，就是 MessageQueue。 简单来说，就是要走指定你的 Topic 对应了多少个队列，也就是多少个 MessageQueue。 Topic、MessageQueue 以及 Broker之间是什么关系其实 Topic、MessageQueue 以及 Broker 之间是有关系的。比如你现在有一个 Topic，我们为它指定 4 个 MessageQueue，那么这个 Topic 的数据在 Broker 集群中是如何分布的？ 其实，每个 Topic 的数据都是分布式存储在多个 Broker 中的，如图： 但是我们如何决定这个 Topic 的哪些数据放在这个 Broker 上，哪些数据放在另一个 Broker 上？所以在这里引入了 MessageQueue 的概念，本质上就是一个数据分片的机制。 在这个机制中，假设你的 Topic 有 1 万条数据，然后你的 Topic 有 4 个 MessageQueue，那么大致可以认为在每个 MessageQueue 中放入 2500 条数据。当然，这个不是绝对的，有可能有的 MessageQueue 的数据多，有的数据少，要根据你的消息写入 MessageQueue 的策略来定。 我们先假定在每个 MessageQueue 中会平均分配 Topic 的数据吧。那么，我们有 4 个 MessageQueue 平均分配了 Topic 的数据，这些 MessageQueue 放在哪里？当然是 Broker 上了。可能就是在 2 个 Broker 上，每个 Broker 放两个 MessageQueue。如图： 所以 MessageQueue 是 RocketMQ 中非常关键的一个数据分片机制，它通过 MessageQueue 将一个 Topic 的数据拆分成了很多个数据分片，然后再每个 Broker 机器上存储一些 MessageQueue。通过这个方法，就可以实现 Topic 数据的分布式存储。 生产者发送消息的时候写入哪个 MessageQueue生产者在发送消息的时候，会写入哪个 MessageQueue 中？其实，生产者会跟 NameServer 进行通信获取 Topic 的路由数据。所以生产者从 NameServer 中就会知道，一个 Topic 有几个 MessageQueue，哪些 MessageQueue 在哪台机器上。 然后呢，我们暂时先认为生产者会均匀地把消息写入各个 MessageQueue。比如生产者发送出去了 20 条数据，那么 4 个 MessageQueue 就会每个写入 5 条数据。如图： 通过这个方法，就可以让生产者把写入请求分散给多个 Broker，让每个Broker 都均匀分摊到一定的写入请求压力。假设单个 Broker 可以抗每秒 7 万并发，那么两个 Broker 可以抗每秒 14 万并发，可以实现 RocketMQ 集群每秒 10万+ 超高并发的场景了。 另外通过这个方法，可以让一个 Topic 的数据分散在多个 MessageQueue 中，进而分散在多个 Broker 机器上，就可以实现 RocketMQ 集群分布式存储海量的消息数据了。 某个 Broker 出现故障如果某个 Broker 临时出现故障了，此时正在等待其它 Slave Broker 自动切换为 Master Broker，那么这个时候这一组 Broker 就没有 Master Broker 可以写入了。 如果还是按照之前的策略来均匀把数据写入各个 Broker 上的 MessageQueue，那么会导致你在一段时间内，每次访问到这个挂掉的 Master Broker 都会访问失败，这不是我们想要的。 对于这个问题。建议大家在 Producer 中开启一个开关，就是 sendLatencyFaultEnable。一旦打开了这个开关，那么它会有一个容错机制，例如如果某次访问一个 Broker 发现网络延迟有 500ms，然后还无法访问，那么就会自动回避访问这个 Broker 一段时间，比如接下来 300ms 内，就不会访问这个 Broker 了。 这样的话，就可以避免一个 Broker 故障之后，短时间内生产者频繁地发送消息到这个故障的 Broker 上，出现较多次数的异常。而是在一个 Broker 故障之后，自动回避一段时间不要访问这个 Broker，过段时间访问它。 RocketMQ 如何持久化存储消息首先我们要明确一点，Broker 数据存储是最重要的一个环节。实际上类似 RocketMQ，Kafka、RabbitMQ 的消息中间件系统，它们不只是让你写入消息和获取消息，它们本身最重要的是提供强大的数据存储能力，可以把亿万级的海量消息存储在自己的服务器的磁盘上。 这样的话，各种不同的系统从 MQ 中消费消息的时候，才可以从 MQ 服务器的磁盘中读取到自己需要的消息。否则如果 MQ 不在机器磁盘上存储大量的消息，都放在自己的内存里，一个是内存很可能放不下，另外一个是可能你机器重启，内存里的消息就会全部丢失了。 所以，Broker 数据存储实际上才是一个 MQ 最核心的环节。它决定生产者消息写入的吞吐量，决定了消息不能丢失，决定了消费者获取消息的吞吐量。所以，我们来说一下 Broker 的数据存储机制。 CommitLog 消息顺序写入机制当生产者的消息发送到一个 Broker 上的时候，它会把这个消息写入磁盘的一个日志文件，叫做 commitLog，直接顺序写入这个文件。 这个 CommitLog 文件是很多磁盘文件，每个文件限定最多 1GB，Broker 收到消息之后就直接追加写入这个文件的末尾，就跟上图一样。如果一个 CommitLog 写满了 1GB，就会创建一个新的 CommitLog 文件。 MessageQueue 在数据存储中体现在哪我们写入 Broker 的消息都是进入到 CommitLog 中去存储的，那么 MessageQueue 是体现在哪里的？其实在 Broker 中，对 Topic 下的每个 MessageQueue 都会有一系列的 ConsumeQueue 文件。 什么意思？就是在 Broker 的磁盘上，会有下面这种格式的一系列文件： $HOME/store/consumequeue/{topic}/{queueId}/{fileName} 上面的那一串是什么意思？其实，每个 Topic 在这台 Broker 上都会有一些 MessageQueue，所以，{topic} 指代的就是某个 Topic，{queueId} 指代的就是某个 MessageQueue。然后对存储在这台 Broker 机器上的 Topic 下的一个 MessageQueue，它有很多的 ConsumeQueue 文件，这个 ConsumeQueue 文件里存储的是一条消息对应在 CommitLog 文件中的 offset 偏移量。 例如，有一个 Topic，它有 4 个 MessageQueue，然后在两台 Broker 机器上，每台 Broker 机器会存储两个 MessageQueue。此时假设生产者选择对其中一个 MessageQueue 写入一条消息，此时消息会发送到 Broker 上。然后 Broker 会把这个消息写入自己的 CommitLog 文件中。 如下图，我在图里加入了两个 ConsumeQueue，分别叫做 ConsumeQueue0 和 ConsumeQueue1，分别对应着 Topic 里的 MessageQueue0 和 MessageQueue1。 即，Topic 下的 MessageQueue0 和 MessageQueue1 就放在这个 Broker 机器上，而且它们每个 MessageQueue 目前在磁盘上对应了一个 ConsumeQueue。即 MessageQueue0 对应着 Broker 磁盘上的 ConsumeQueue0，MessageQueue1 对应着磁盘上的 ConsumeQueue1。 假设 Queue 的名字叫做 TopicOrderPaySuccess，那么此时在 Broker 磁盘上应该有如下两个路径的文件： $HOME/store/consumequeue/TopicOrderPaySuccess/MessageQueue0/ConsumeQueue0 磁盘文件 $HOME/store/consumequeue/TopicOrderPaySuccess/MessageQueue1/ConsumeQueue1 磁盘文件 然后，当你的 Broker 收到一条消息写入 CommitLog 之后，它会同时将这条消息在 CommitLog 中的物理位置，也就是一个文件偏移量，就是一个 offset，写入到这条信息所属的 MessageQueue 对应的 ConsumeQueue 文件中去。 比如现在这条消息在生产者发送的时候是发送给 MessageQueue0 的，那么此时 Broker 就会将这条消息在 CommitLog 中 offset 偏移量，写入到 MessageQueue 对应的 ConsumeQueue0 中去。所以实际上，ConsumeQueue0 中存储的是一个一个消息在 CommitLog 文件中的物理位置，也就是 offset。 如下图，图里展示出来的是 ConsumeQueue 中的一个物理位置其实是对 CommitLog 文件中一个消息的引用。 实际上在 ConsumeQueue 中存储的每条数据不只是消息在 CommitLog 中的 offset 偏移量，还包含了消息的长度，以及 tag hashcode，一条数据是 20 个字节，每个 ConsumeQueue 文件保存 30万 条数据，大概每个文件是 5.72MB 所以 Topic 的每个 MessageQueue 都对应了 Broker 机器上的多个 ConsumeQueue 文件，保存了这个 MessageQueue 的所有消息在 CommitLog 文件中的物理位置，也就是偏移量。 如何让消息写入 CommitLog 文件近乎内存写性能对于生产者把消息写入到 Broker 时，Broker 会直接把消息写入 CommitLog 文件，那么 Broker 是如何提升整个过程的性能的。因为这个部分的性能提升会直接提升 Broker 处理消息写入的吞吐量，比如你写入一条消息到 CommitLog 磁盘文件假设需要 10ms，那么每个线程每秒可以处理 100个 写入消息，100个 线程每秒只能处理 1万 个写入消息请求。 但是把消息写入 CommitLog 磁盘文件的性能优化为只需要 1ms，那么每个线程每秒可以处理 1000个 消息写入，此时 100个 线程可以处理 10万 个写入消息请求。所以，Broker 把接收到的消息写入 CommitLog 磁盘文件的性能，对它的 TPS 有很大的影响。 所以，Broker 是基于 OS 操作系统的 PageCache 和 顺序写 两个机制，来提升写入 CommitLog 文件的性能的。 首先 Broker 是以顺序的方式将消息写入 CommitLog 磁盘文件的，也就是每次写入就是在文件末尾加一条数据即可，对文件进行顺序写的性能比对文件随机写的性能提升很多。 另外，数据写入 CommitLog 文件的时候，其实不是直接写入底层的物理磁盘文件的，而是先进入 OS 的 PageCache 内存缓存中，然后后续由 OS 的后台线程选一个时间，异步化地将 OS PageCache 内存缓冲中的数据刷入底层的磁盘文件。如图： 这样的优化下，采用 磁盘文件顺序写 + OS PageCache 写入 + OS 异步刷盘 的策略，基本上可以让消息吸入 CommitLog 的性能跟你直接写入内存里是差不多的，所以正是如此，才可以让 Broker 高吞吐地处理每秒大量的消息写入。 同步刷盘与异步刷盘上述的模式，其实就是异步刷盘模式。在异步刷盘模式下，生产者把消息发送给 Broker，Broker 将消息写入 OS PageCache 中，就直接返回 ACK 给生产者了。此时生产者就认为消息写入成功了，那么会有什么问题？ 问题是有的。如果生产者认为消息写入成功了，但是实际上那条消息此时是在 Broker 机器上的 OS cache 中的，如果此时 Broker 直接宕机，那么 os cache 中的这条数据就会丢失。所以异步刷盘的策略下，可以让消息写入吞吐量非常高，但是有数据丢失的风险，这个是需要清楚的。 另外一种模式叫同步刷盘。如果你使用同步刷盘，那么生产者发送一条消息出去，Broker 收到了消息，必须直接强制把这个消息刷入底层的物理磁盘文件中，然后才返回 ack 给 producer，此时你才知道消息写入成功了。 只要消息进入了物理磁盘上，除非是你的物理磁盘坏了导致数据丢失，否则正常情况下数据就不会丢失了。如果 Broker 还没来得及把数据同步刷入磁盘，然后它自己挂了，那么此时对生产者来说会感知到消息发送失败了，然后只要不停地重试发送就可以了，直到有 slave broker 切换成 master broker 重新让你可以写入信息，此时可以保证数据是不会丢的。 但是如果你强制每次消息写入都要直接进入磁盘中，必然导致每条消息写入性能急剧下降，导致消息写入吞吐量下降，但是可以保证数据不会丢失]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单说说秒杀系统的技术难点]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F11%2F%E7%AE%80%E5%8D%95%E8%AF%B4%E8%AF%B4%E7%A7%92%E6%9D%80%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8A%80%E6%9C%AF%E9%9A%BE%E7%82%B9%2F</url>
    <content type="text"><![CDATA[思维导图 秒杀活动压力过大怎么办秒杀活动压力过大，是否能通过堆机器解决？比如说给订单系统部署更多的机器，是不是可以抗下更高的并发？这个是没问题的，订单系统可以通过部署更多的机器机型线性扩展。 那数据库呢？是否也要部署更多的服务器，进行分库分表，然后让更多的数据库服务器来抗更高的数据库高并发访问？大概思路是这样，所谓分库分表，就是把目前的一台数据库服务器变成多台数据库服务器，然后把一张订单表变成多张订单表。 例如，假设订单表里有 1200 万条数据，然后有一台数据库服务器，如果我们现在变成 3 台数据库服务器，那么可以在每台数据库服务器里放 400 万订单数据，这就是所谓的分库分表。这样的好处是什么呢？如果未来订单系统的整体访问压力达到了每秒 3 万请求了，此时订单系统通过扩容可以部署更多机器，然后其中每台数据库服务器承受 1 万的请求，如图： 这样不就可以通过增加更多的数据库服务器来抗下更高的并发请求了吗？但其实这不太靠谱。除非是技术能力比较弱的公司，没有厉害的架构师去利用已有的技术合理设计优秀的架构，才会用这种堆机器的方式简单地抗下超高的并发。 如果用堆机器的方式来解决这个问题，必然存在一个问题，就是随着你的用户量越来越大，你的并发请求越来越多，会导致你要不停地增加更多的机器。所以解决问题不能用这种简单粗暴堆机器的方案。 高并发的商品详情页请求秒杀活动主要涉及到的并发压力有两块：一个是高并发地读，一个是高并发地写。 首先思考一下，平时大量的用户是怎么参与到秒杀活动里来的？往往是这样。假设每天晚上 8:30 有一波秒杀商品开始售卖，因为每次到了晚上 8:30 之前，就有很多用户会登陆 APP，然后再 APP 前坐等秒杀特价商品。 所以这个时候，必然会出现一种场景，就是首先大量用户会拿着 APP 不停地刷新一个秒杀商品的页面。那么这些秒杀商品页面是从哪儿加载出来的？本质上来说从商品技术团队负责的商品详情页加载出来的，如图，引入了一个商品详情页系统的概念，它负责提供我们看到的各种秒杀商品页面。 所以这个商品详情页系统就是在秒杀活动开始之前最先被大量用户高并发访问的一个系统了。如果没有秒杀活动的时候，其实大量的用户是分散在不同的时间段来逛 APP 的，并且逛的是不同的人会看不同的商品的页面。 但是在秒杀活动的时候，面临的第一个问题是，可能几十万人会同一时间频繁地访问同一个秒杀商品的页面，对商品详情页系统造成巨大的访问压力。 商品团队的秒杀架构优化：页面数据静态化为了解决商品详情页系统的技术难点，一般采取的是 页面数据静态化 + 多级缓存 的方案。 首先第一步，秒杀商品页面必须是将其数据做到静态化，这是什么意思呢？ 如果让秒杀商品页面是动态化的，那么每次一个用户只要访问这个商品详情页，就必须发送一次请求到后端的商品详情页来获取数据。比如商品的标题、副标题、价格、优惠策略、库存、大量的图片、商品详情说明。售后政策等等，这都是商品详情页的数据。 那么你可以选择让用户浏览这个秒杀商品的时候，每次都发送请求到后台去加载这些数据过来，然后渲染出来给用户看这个商品页面，这就是所谓的动态模式。 如果这商品详情页里的大量数据都是存储在商品团队里的数据库里的，那么岂不是大量用户同时频繁访问这个商品详情页，会直接导致商品详情页系统承受高并发的访问？同时导致商品数据库承受高并发的访问？ 所以首先需要将这个秒杀活动的商品详情页里的数据做成静态化的，也就是提前就从数据库里把这个页面需要的数据都提取出来组装成一份静态数据放在别的地方，避免每次访问这个页面都要访问后端数据库。 商品团队的秒杀架构优化：多级缓存接着就是多级缓存的架构，我们会使用 CDN + Nginx + Redis 的多级缓存架构。 比如说秒杀商品详情页的数据，首先会放一份在离用户地理位置比较近的 CDN 上。CDN 你大致可以这么理解，比如你们公司的机房在广州，系统也部署在广州，那么对于陕西的用户，我们可以将一份静态化好的数据放在陕西的一个 CDN 上。然后不同地方的用户在加载这个秒杀商品的详情页数据时，就是从附近的 CDN 上加载的，不需要每次请求都发送到我们公司在广州的机房去。 这个 CDN 缓存就是我们多级缓存架构里的第一级缓存。那如果因为缓存过期之类的问题，CDN 上没有用户要加载的商品详情页数据，此时用户就会发送请求到我们公司的机房里的机器上去请求加载这个商品的数据了，这个时候我们需要在 Nginx 这样的服务器里做一级缓存。 在 Nginx 中是可以基于 Lua 脚本实现本地缓存的，我们可以提前把秒杀商品详情页的数据放到 Nginx 中进行缓存，如果请求发送过来，我们可以从 Nginx 中直接加载缓存数据，不需要把请求转发到我们商品系统上去。 这个时候如果在 Nginx 服务器上也没加载到秒杀商品的数据呢？此时就可以由 Nginx 中的 Lua 脚本发送请求去 Redis 集群中加载我们提前放进去的秒杀商品数据。 如果在 Redis 中还是没有找到，那么就由 Nginx 中的 Lua 脚本直接把请求转发到商品详情页系统里去加载就可以了，此时就会直接从数据库中加载数据出来。但是一般来说数据是可以从 CDN、Nginx、Redis 中加载到的，可能只有极少的请求会直接访问到商品系统去从数据库里加载商品页数据。 通过这样的一套方案。我们就可以把用于秒杀活动的商品详情页数据进行静态化，然后把静态化以后的一串商品数据（例如 JSON 串）放到 CDN、Nginx、Redis 组成的多级缓存里去，这样大量的用户同时访问这个商品页面对我们系统本身就没什么压力了。 订单方面的优化用答题的方式避免作弊软件抢购以及延缓下单首先我们要防止有人写一个抢购的脚本或者作弊软件，疯狂地发送请求去抢商品，所以一般来说，现在你要参与抢购，都会让你点击按钮之后先进行答题，就是说先弹出一个框，让你回答一个问题，回答正确了你才能发起抢购的请求。 这个办法是非常有效的，因为首先它避免了一些作弊软件去发送抢购请求，另外就是不同的人答题的速度是不一样的，所以可以通过这个答题让不同的人发送请求的时间错开，不会在一个时间点发起请求。如图： 为秒杀独立出来一套订单系统接着用户下单抢购的请求发送出去之后，会达到我们的后台系统，对于后台系统而言，我们需要思考，是否直接用我们目前已有的订单系统去抗所有的请求？ 答案是否定的。假设你有 100 万用户在这个时间段很活跃来购买物品，但是可能只有其中 50 万用户在参与秒杀活动，同一时间发送了大量的抢购请求到后台系统，但是同时还有很多其它的用户这个时候并不在参与秒杀系统，他们在进行其它商品的常规性浏览和下单。 如果你让秒杀下单和普通下单请求都由一套订单系统来承载，那么可能会导致秒杀下单请求耗尽了订单系统的资源，或者导致系统不稳定，然后导致其他普通下单请求也出现问题，没有办法完成下单。所以我们一般会对订单系统部署两个集群，一个集群是秒杀订单系统集群，一个集群是普通订单系统集群。如图： 基于 Redis 实现下单时精准扣减库存在后台系统中首先要做的一个事情，就是扣减库存。秒杀商品一般是有数量限制的，所以当大量的请求到达后台系统之后，第一步，就是先去扣减库存。 在秒杀场景下，一般会将每个商品的库存提前写入 Redis 中，然后当请求到来之后，就直接对 Redis 中的库存进行扣减。Redis 是可以轻松用单机抗每秒几万高并发的，因此这里就可以抗下高并发额库存扣减。比如我们总共就 1 万件秒杀商品，其实最多就是前 1 万个到达的请求可以成功从 Redis 中扣减库存，抢购到这个商品，接着后续的请求从 Redis 里扣减库存的时候，都会发现库存已经没有了，无法抢购商品了。 抢购完毕之后提前过滤无效请求在 Redis 中的库存被扣减完之后，就说明后续其他的请求都没有必要发送到秒杀系统了，此时我们一颗让 Nginx 在接收到后续请求之后，直接就把后续请求过滤掉。 比如一旦商品请购完毕，可以在 ZooKeeper 中写入一个秒杀完毕的标志位，然后 ZK 会反向通知 Nginx 中我们自己写的 Lua 脚本，通过 Lua 脚本后续在请求后来的时候直接过滤掉，不要向后转发了。这样就可以最大幅度削减对后端秒杀系统的请求压力。 瞬时高并发下单请求进入 MQ 进行削峰接着我们来思考下，即使是有 1 万件商品同时被 1 万人秒杀成功了，那么可能瞬间会有 1 万请求涌入正常的订单系统进行后续的处理，此时可能还是会有瞬间上万请求访问到订单数据库中创建订单。这个时候，完全可以引入 MQ 进行削峰处理。 对于秒杀系统而言，如果发现通过 Redis 完成了库存扣减，并且此时库存还大于 0，说明秒杀成功了需要生成订单，此时就直接发送一个消息到 MQ 中即可，然后普通订单系统熊 MQ 中消费秒杀成功的消息进行常规化的流程处理即可，比如创建订单等等。 这样的话，瞬间上万并发的压力会被 MQ 轻松抗下来，然后普通的订单系统可以根据自己的工作负载慢慢地从 MQ 中拉取秒杀成功的消息，然后进行后续操作即可，不会对订单数据造成过大的压力。否则如果你让瞬间产生的一万或者几万的订单请求直接访问订单数据库，必然还是会让它压力过大，需要额外增加机器，这就没有必要了。 因此这里利用 MQ 抗下每秒几万并发的下单请求，然后让订单系统已每秒几千的速率慢慢处理即可，也就是延迟可能几十秒，这些下单请求就会处理完毕。如图： 秒杀架构的核心要点通过这篇文章的思路，就会清晰地看到，对于一个秒杀系统而言，比较重要的一下几点： 在前端/客户端通过设置秒杀答题，错开大量下单的时间，组织作弊器刷点 独立出来一套秒杀系统，专门负责处理秒杀请求 优先基于 Redis 进行高并发的库存扣减，一旦库存扣减完则秒杀结束 秒杀结束后，Nginx 层过滤掉无效的请求，大幅度削减转发到后端的流量 瞬时生成的大量下单请求直接进入 MQ 进行削峰，订单系统慢慢拉取消息完成下单操作]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 事务]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F09%2FMySQL-%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[MySQL 的特性 — ACIDMySQL 的特性，就是大家常常听到的 ACID。 Atomic：原子性。就是一堆SQL，要么一起成功，要么一起失败。不允许某个 SQL 执行成功了，某个 SQL 却失败了。这样就不是原子性了。 Consistency：一致性。这个是针对数据一致性来说的，就是一组 SQL 执行之前，数据必须是准确的，执行之后，数据也必须是准确的。别搞了半天，执行完 SQL，结果 SQL 对应的数据修改没执行，这就很坑爹了。 Isolation：隔离性。这个就是说多个事务在跑的时候不能互相干扰。不能事务 A 操作个数据，弄到一半还没弄好，结果事务 B 来改了这个数据，导致事务 A 的操作出错了。 Durability：持久性。事务成功了，就必须永久对数据的修改是有效的，别过来一会数据自己不见了。 MySQL 事务隔离级别MySQL 的事务隔离级别主要有 读未提交、读已提交（不可重复读）、可重复读和串行化四种。 1、读未提交，Read UnCommitted。这个很坑爹，就是说某个事务还没提交的时候，修改了数据，就让别的事务给读到了。这很容易导致出错，这个也叫做脏读。 2、读已提交，Read Committed（不可重复度）。这个比上面那个好一点，但是也比较尴尬。 就是说事务 A 在跑的时候，先查询了一个数据的值是 1，然后过了断时间，事务 B 把那个数据给修改了还提交了。此时事务 A 再次查询这个数据就变成了值 2 了，这是读了人家事务提交的数据了，所以是读已提交。 这个也叫不可重复读，就是所谓的一个事务内对一个数据两次读，可能会读到不一样的值。如图： 3、可重复读，Read Repeatable。这个比上面那个再好一点。就是说事务 A 在执行的过程中，对某个数据的值，无论读多少次都是值 1。哪怕这个过程中事务 B 修改了数据的值还提交了，但是事务 A 读到的还是自己事务开始时这个数据的值。如图： 幻读，不可重复读和可重复都是针对两个事物同时对某条数据在修改，但是幻读针对的是插入。比如某个事物把所有行的某个字段都修改为了 2，结果另一个事务插入了一条数据，那个字段的值是 1。然后就尴尬了，第一个事务会突然发现多出来一条数据，那个数据的字段是 1。 幻读会带来什么问题？在此隔离级别下，例如，事务 1 要插入一条数据，我先查询一下有没有相同的数据，但是这时事务 2 添加了这条数据，这就会导致事务 1 插入失败，并且它就算再一次查询，也无法查询到与其插入相冲突的数据，同时自身死活都插入不了。 4、串行化，如果要解决幻读，就需要使用串行化级别的隔离级别，所有事务都串行起来，不允许多个事务并行操作。 MySQL 的默认隔离级别是 Read Repeatable，就是可重复读，就是说每个事务都会开启一个自己要操作的某个数据的快照，事务期间，读到的都是这个数据的快照而已，对一个数据的多次读都是一样的。 MySQL 中的隔离级别的实现上面的内容解释了一些数据库理论的概念，但是在 MySQL、Oracle 这样的数据库中，为了性能的考虑并不是完全按照上面的理论来实现的。 MVCCMVCC，全称 Multi-Version Concurrency Control。是 MySQL 中基于乐观锁理论实现可重复读隔离级别的方式。 这里先引入两个概念： 系统版本号：一个递增的数字，每开始一个新的事务，系统版本号就会自动递增。 事务版本号：事务开始时的系统版本号。 在 MySQL 中，会在表中每一条数据后面添加两个字段： 创建版本号：创建一行数据时，将当前系统版本号作为创建版本号赋值。 删除版本号：删除一行数据时，将当前系统版本号作为删除版本号赋值。 SELECTselect 时读取数据的规则为：创建版本号 &lt;= 当前事务版本号，删除版本号为空或 &gt; 当前事务版本号。 创建版本号 &lt;= 当前事务版本号保证取出的数据不会有后启动的事务中创建的数据；而删除版本号为空或 &gt; 当前事务版本号保证了至少在改事务开启之前数据没有被删除，是应该被查出来的数据。 INSERTinsert 时将当前的系统版本号赋值给创建版本号字段。 UPDATE插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行，实际上这里的更新是通过 delete 和 insert 实现的。 DELETE删除时将当前的系统版本号赋值给删除版本号字段，标识该行数据在哪一个事务中会被删除，即使实际上在 commit 时该数据没有被删除，根据 select 的规则后开启数据也不会查询该数据。 示例假设现在有这么一个表，如下： id name 创建事务id 删除事务id 1 张三 120 122 2 李四 119 空 事务 id = 121 的事务，查询 id = 1 的这一行的时候，一定会找到创建事务 id &lt;= 当前事务 id 的那一行。所以 SELECT * FROM table WHERE id = 1 就可以查到上面那一行。 事务 id = 122 的事务，将 id = 1 的这一行给删除了，此时就会将 id = 1 的行的删除事务 id 设置为 122。当事务 id = 121 的事务，再次查询 id = 1 的那一行，是可以查到的。因为创建事务 id &lt;= 当前事务 id，且 当前事务 id &lt; 删除id。 如果某个事务执行期间，别的事务更新了一条数据呢？这个很关键的一个实现，其实在 InnoDB 中，就是插入了一行记录，然后将新插入的记录的创建事务 id 设置为新的事务的 id，同时将这条记录之前的那个版本的删除 id 设置成新的事务 id。 id name 创建事务id 删除事务id 1 张三 120 122 2 李四 119 空 2 小李四 122 122 事务 id = 121 的事务，查询 id = 2 的那一行，查到 name = 李四。事务 id = 122 的事务，将 id = 2 的那一行的 name 修改成 name = 小李四。事务 id = 121 的事务，查询 id = 2 的那一行，只能查询到 李四。因为创建事务 id &lt;= 当前事务 id，当前事务 id &lt; 删除 id。 快照读和当前读select 快照读当执行 select 操作时，InnoDB 默认会执行快照读，会记录下这次 select 后的结果，之后 select 的时候就会返回这次快照的数据，即使其他事务提交了不会影响当前 select 的数据，这就实现了可重复读了。快照的生成当在第一次执行 select 的时候，也就是说假设当事务 A 开启了事务，然后没有执行任何操作，这时候事务 B insert 了一条数据然后 commit，这时候 A 执行 select，那么返回的数据中就会有 B 添加的那条数据。之后无论有其他事务 commit 都没有关系，因为快照已经生成了，后面的 select 都是根据快照来的。 当前读对于会对数据修改的操作（update、insert、delete）都是采用当前读的模式。在执行这几个操作的时候会读取最新的记录，即使是别的事务提交的数据也可以查询到。假设要 update 一条记录，但是在另一个事务中已经 delete掉这条数据并且 commit 了。如果 update 就会产生冲突，所以在 update 的时候需要知道最新的数据。 select 的当前读需要手动地加锁： 12SELECT * FROM table WHERE ? LOCK IN SHARE MODE;SELECT * FROM table WHERE ? FOR UPDATE 参考资料MySQL的可重复读级别能解决幻读吗 事务的几个特性和隔离方式]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解 MySQL 中的 Buffer Pool]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F04%2F%E8%AF%A6%E8%A7%A3-MySQL-%E4%B8%AD%E7%9A%84-Buffer-Pool%2F</url>
    <content type="text"><![CDATA[思维导图 配置 Buffer Pool 的大小Buffer Pool 本质上是数据库的一个内存组件，你可以理解它就是一片内存数据结构，所以这个内存数据结构肯定是有一定大小的，不可能是无限大的。这个 Buffer Pool 默认情况下是 128MB，还是有一点偏小的，我们实际生产环境可以对 Buffer Pool 进行调整。 比我我们数据库如果是 16 核 32G 的机器，那么你可以给 Buffer Pool 分配 2GB 的内存，使用下面的配置就可以了。 12[server]innodb_buffer_pool_size = 2147483648 Buffer Pool 的数据结构数据页：MySQL 中抽象出来的数据单位假设我们的数据库中有一片内存区域是 Buffer Pool 了，那么我们的数据如何放在 Buffer Pool 中？我们都知道数据库的核心数据模型就是表 + 字段 + 行的概念，即我们都知道数据库里有一个个表，一个表有很多字段，然后每个表里有许多行数据，每行数据都有自己的字段值。所以我们的数据是一行一行放在 Buffer Pool 里面的吗？ 当然不是，实际上 MySQL 对数据抽象出来了一个数据页的概念，它是把很多行数据放在一个数据页里，也就是说我们的磁盘文件中会有很多的数据页，每一页数据放了很多行数据。所以实际上假设我们要更新一行数据，此时数据库会找到这行数据所在的数据页，然后从磁盘文件里把这行数据所在的数据页直接加载到 Buffer Pool 里去。也就是说，Buffer Pool 中存放的是一个一个的数据页。如图： 磁盘上的数据文件和 Buffer Pool 中的缓存页如何对应起来实际上默认情况下，磁盘中存放的数据页的大小是 16KB，即，一页数据包含了 16KB 的内容。而 Buffer Pool 中存放的一个一个的数据页，我们通常叫做缓存页，因为 Buffer Pool 是一个缓冲池，里面的数据都是从磁盘缓存到内存去的。 而 Buffer Pool 中默认情况下，一个缓存页的大小和磁盘上的一个数据页的大小是一一对应起来的，都是 16KB。 缓存页对应的描述信息我们要知道一个概念，对于每个缓存页，它实际上都会有一个描述信息，这个描述信息大体可以认为是用来描述这个缓存页的。比如包含如下的一些东西：这个数据页所属的表空间、数据页的编号、这个缓存页在 Buffer Pool 中的地址以及别的一些东西。 每个缓存页都会对应一个描述信息，这个描述信息本身也是一块数据，在 Buffer Pool 中，每个缓存页的描述数据放在最前面，然后各个缓存页放在后面。所以，Buffer Pool 实际看起来大概长这个样子： 这里我们要注意一点，Buffer Pool 中的描述信息大概相当于缓存页大小的 5% 左右，也就是每个描述数据大概是 800 个字节左右的大小，然后假设你设置的 buffer pool 大小是 128MB，实际上 Buffer Pool 真正的最终大小会超出一些，可能有 130 多 MB 的样子，因为它里面还要存放每个缓存页的描述数据。 Buffer Pool 中的 free 链表通过上面的讲解我们大概知道 MySQL 中的 Buffer Pool 到底长什么样，那么在数据库启动的时候，它是如何初始化 Buffer Pool 的呢？ 其实很简单，数据库只要一启动，就会按照你设置的 Buffer Pool 大小，稍微再加大一点，去找操作系统申请一块内存区域，作为 Buffer Pool 的内存区域。然后当内存区域申请完毕之后，数据库就会按照默认的缓存页的 16KB 的大小以及对应的 800 个字节左右的描述数据的大小，在 Buffer Pool 中划分出来一个一个的缓存页和一个一个它们对应的描述数据。 当数据库把 Buffer Pool 划分完毕之后，看起来就是上面的那张图。只不过这个时候，Buffer Pool 中的一个一个的缓存页都是空的，里面什么都没有，要等数据运行起来之后，当我们要对数据进行增删改查的操作的时候，才会把数据对应的页从磁盘文件里读取出来，放入 Buffer Pool 中的缓存页中。 哪些缓存页是空闲的当数据库运行起来之后，随着增删改查操作的执行，此时就需要不停地从磁盘上读取一个一个的数据页放入 Buffer Pool 中对应的缓存页里去，把数据缓存起来，那么以后就可以对这个数据在内存里执行相应操作了。 但是此时在磁盘上读取数据页放入 Buffer Pool 中的缓存页的时候，会涉及到一个问题：哪些缓存页是空闲的。因为默认情况下磁盘上的数据页和缓存页是一一对应起来的吗，都是 16KB，所以我们要知道 Buffer Pool 中哪些缓存页是空闲的状态。 所以数据库会为 Buffer Pool 设计一个 free 链表，它是一个双向链表数据结构。这个 free 链表里，每个节点就是一个空闲的缓存页的描述数据块的地址。也就是说，只要你一个缓存页是空闲的，那么它的描述数据块就会被放入这个 free 链表中。 刚开始数据库启动的时候，可能所有的缓存都是空闲的，因此此时可能是一个空的数据库，一条数据都没有，所以此时所有缓存页的描述数据块，都会被放入这个 free 链表中。 这个 free 链表里面就是各个缓存页的描述数据块，只要缓存页是空闲的，那么它们对应的描述数据块就会加入到这个 free 链表，每个节点都会双向链接自己的前后节点，组成一个双向链表。另外，这个 free 链表有一个基础节点，它会引用链表的头结点和尾节点，里面还存储了链表中有多少个描述数据块的节点，也就是有多少个空闲的缓存页。 free 链表占用多少内存空间可能有人会以为这个描述数据块，在 Buffer Pool 里有一份，在 free 链表里也有一份，好像在内存里有两个一模一样的描述数据块。其实这个是错误的，这个 free 表，它本身就是由 Buffer Pool 里的描述数据块组成的，你可以认为是每个描述数据块里都有两个指针，一个是 free_pre，一个是 free_next，分别指向自己的上一个 free 链表的节点，以及下一个 free 链表的节点。 通过 Buffer Pool 中的描述数据块的 free_pre 和 free_next 两个指针，就可以把所有的描述数据块串成一个 free 链表。上面为了画图需要，所以把描述数据块单独画了一份出来，表示他们之间的指针引用关系。 对于 free 链表而已，只有一个基础节点是不属于 Buffer Pool 的，它是 40 字节大小的一个节点，里面存放了 free 链表的头结点的地址，尾结点的地址，还有 free 链表里当前有多少个节点。 如何将磁盘上的页读取到 Buffer Pool 的缓存页中去当你想要把磁盘上的数据页读取到 Buffer Pool 中的缓存页里去的时候，要怎么做？其实有了 free 链表之后，这就很简单了。 首先，我们需要从 free 链表里获取一个描述数据块，然后就可以对应的获取这个描述数据块对应的空间缓存页。接着我们就可以把磁盘上的数据页读取到对应的缓存页里去，同时把相关的一些描述数据写入到缓存页的描述数据块里去，比如这个数据页所属的表空间之类的信息，最后把那个描述数据块从 free 链表里去除就可以了。 如何知道数据页有没有被缓存我们在执行增删改查的时候，肯定是先看看这个数据页有没有被缓存，如果没被缓存就走上面的逻辑，从 free 链表中找到一个空闲的缓存页，从磁盘上读取数据页写入缓存页，写入描述数据，从链表中移除这个描述数据块。但是如果数据页已经被缓存了，那么就会直接使用了。 所以其实数据库还会有一个哈希表数据结构，它会用表空间号 + 数据页号，作为一个 key，然后缓存页的地址作为 value。当你要使用一个数据页的时候，通过 “表空间号 + 数据页号” 作为 key 去哈希表里查一下，如果没有就读取数据页，如果已经有了，就说明数据页已经被缓存了。 Buffer Pool 中的 flush 链表脏缓存页你在执行增删改的时候，如果发现数据页没缓存，那么会基于 free 链表找到一个空闲的缓存页，然后读取到缓存页里去，但是如果已经缓存了，那么下一次就必然会直接使用缓存页。即，你要更新的数据页都会在 Buffer Pool 的缓存页里，供你在内存页中直接执行增删改的操作。 接着你去更新 Buffer Pool 的缓存页中的数据，此时一旦你更新了缓存页中的数据，那么缓存页里的数据和磁盘上的数据页里的数据，就不一致了。这个时候，我们就说缓存页是脏数据，脏页。 哪些缓存页是脏页上面说的那些在内存里更新的脏页的数据，都是要被刷新会磁盘文件的。但就有一个问题，不可能所有的缓存页都刷回磁盘的，因为有的缓存页可能是因为查询的时候被读取到 Buffer Pool 里的，可能根本没有修改过！ 所以数据库在这里引入了另外一个跟 free 链表类似的 flush 链表，这个 flush 链表本质也是通过缓存页的描述数据块中的两个指针，让被修改过的缓存页的描述数据块，组成一个双向链表。凡是被修改过的缓存页，都会把它的描述数据块加入到 flush 链表中去，flush 的意思就是这些都是脏页，后续都是要 flush 刷新到磁盘上的。 所以 flush 链表的结果跟 free 链表几乎是一样的，如图： Buffer Pool 中的缓存页不够时，基于 LRU 算法淘汰部分缓存当我们执行 CRUD 操作的时候，无论是查询数据，还是修改数据，都会把磁盘上的数据页加载到缓存页里来。那么在加载数据到缓存页的时候，必然是要加载到空闲的缓存页里去的，所以必须要从 free 链表中找一个空闲的缓存页，然后把磁盘上的数据页加载到空闲的缓存页里去。 随着不停地把磁盘上的数据页加载到空闲的缓存页里去，free 链表中的空闲缓存页也会越来越少，当你不停地把磁盘上的数据页加载到空闲缓存页里去，free 链表中不停地移除空闲缓存页，迟早有那么一个瞬间，free 链表已经没有空闲缓存页了。 淘汰掉一些缓存数据如果所有的缓存页都被塞了数据，此时无法从磁盘上加载新的数据页到缓存页里去了，此时只有一个办法，就是淘汰掉一些缓存页。所谓的淘汰缓存页，就是把一个缓存页里修改过的数据，给刷到磁盘上的数据页里去，然后这个数据页就可以清空了，让它重新变成一个空闲的缓存页。接着你再把磁盘上需要的新的数据页加载到这个腾出来的空闲缓存页中去。 那要把一个缓存页里的数据刷入磁盘，腾出来一个空闲缓存页，那应该把哪个缓存页的数据给刷入磁盘呢？ 缓存命中率这里我们先提一个概念，叫缓存命中率。假设现在有两个缓存页，一个缓存页的数据，经常会被修改和查询，比如在 100 次请求中，有 30 次都是在查询和修改这个缓存页里的数据，那么此时我们可以说这种情况下，缓存命中率很高。 另外一个缓存页里的数据，就是刚从磁盘加载到缓存页之后，就修改和查询过一次，之后100 次中没有一次是修改和查询这个缓存页的数据的，那么我们就说缓存命中率有点低。因为大部分请求可能还需奥走磁盘查询数据，它们要操作的数据不在缓存中。 一般来说我们都是优先淘汰缓存命中率低的缓存页。 引入 LRU 链表来判断哪些缓存页是不常用的接下来我们就要知道，哪些缓存页是经常被访问，哪些缓存页是很少被访问的。此时就要引入一个新的 LRU 链表了。这个所谓的 LRU 就是 Least Recently Used，最近最少使用的意思。 这个 LRU 链表的工作原理是什么？简单说就是，我们从磁盘加载一个数据页到缓存页的时候，就把缓存页的描述数据块放到 LRU 表头部去，那么只要有数据的缓存页，它都会在 LRU 里了，而且最近被加载数据的缓存页，都会放到 LRU 链表的头部去。 然后假设某个缓存页的描述数据块本来在 LRU 链表的尾部，后续只要你查询或者修改这个缓存页的数据，也要把这个缓存页挪动到 LRU 链表的头部去，也就是说最近被访问过的缓存页，一定在 LRU 链表的头部。 那样的话，当你的缓存页没有一个空闲的时候，你是不是要找出来那个最近最少被访问的缓存页去刷入磁盘？此时你就直接在 LRU 链表的尾部找到一个缓存页，它一定是最近最少被访问的那个缓存页。 然后你就把 LRU 链表尾部的那个缓存页刷入到磁盘中，然后把你需要的磁盘数据页加载到腾出来的空闲缓存页就可以了。 简单的 LRU 链表在 Buffer Pool 实际运行中可能导致的问题上面说的那个 LRU 机制在实际运行过程中，是存在巨大的隐患的。首先会带来隐患的就是 MySQL 的预读机制。这个所谓的预读机制，就是当你从磁盘上加载一个数据页的时候，它可能会连带着把这个数据页相邻的其他数据页，也加载到缓存里去。 例如，现在有两个空闲的缓存页，然后在加载一个数据页的时候，连带着把它的一个相邻的数据页也加载到缓存里去了。但是，实际上只有一个缓存页是被访问了，另外一个通过预读机制加载的缓存页，其实没人访问，此时这两个缓存页都在 LRU 链表的前面。如图： 例如上面的情景，前两个缓存页都是刚加载进来的，但是此时第二个缓存页是通过预读机制连到这加载进来的，它也被放到了链表的前面，但实际上没人访问它。 除此之外还有尾巴上的两个缓存页，都是一直有人访问的缓存页，只不过上图代表的是刚刚把头部两个缓存页加载进来的时候的一个 LRU 链表当时的情况。这个时候，如果空闲页没有了，此时要加载新的数据页了，是不是就要从 LRU 链表的尾部把所谓的 “最近最少使用的一个缓存页” 给刷入磁盘，腾出一个空闲缓存页出来？ 这个是不合理的。最后一个之前一直频繁被人访问，只不过在这一个瞬间，被新加载进来的两个缓存页给占据了 LRU 链表前面的位置，尤其是第二个缓存页，还是通过预读机制加载进来的。根本没人访问。所以最合理的应该是把上图中第二个通过预读机制加载进来的缓存页给输入磁盘和清空。 哪些情况会触发 MySQL 的预读机制以下情况会触发 MySQL 的预读机制： 有一个参数是 innodb_read_ahead_threshold，它的默认值是 56，意思是如果顺序访问了一个区里的多个数据页，访问的数据页的数量超过了这个阈值，此时就会触发预读机制，把下一个相邻区的所有数据页都加载到缓存里去。 如果 Buffer Pool 里缓存了一个区里的 13 个连续的数据页，而且这些数据页都是比较频繁会被访问的，此时就会直接触发预读机制，把这个区里的其他的数据页都加载到缓存里去。这个机制是 innodb_random_read_ahead 来控制的，它默认是 OFF，也就是关闭的。 所以默认情况下，主要是第一个规则可能触发预读机制，一下子就把很多相邻区里的数据页加载到缓存里去，这些缓存页如果一下子都放在 LRU 链表的前面，而且没什么人会访问的话，就会跟上图一样，导致本来就在缓存里的一些频繁被访问的缓存页在 LRU 链表的尾部。 另外一种可能导致频繁被访问的缓存页被淘汰的场景另外一种可能，就是全表扫描。 例如 SELECT * FROM users。它没加任何一个 where 条件，会导致它直接一下子把这个表里所有的数据页，都从磁盘加载到 Buffer Pool 里去。这个时候它可能会一下子就把这个表的所有数据页都一一装入各个缓存页里去，此时可能 LRU 链表中排在前面的一大串缓存页，都是全表扫描加载进来的缓存页。如果这次全表扫描过后，后续几乎没用到这个表的数据呢？ 此时 LRU 链表的尾部，可能全部都是之前一直被频繁访问的那些缓存页。然后当你要淘汰一些缓存页腾出空间的时候，就会把 LRU 链表尾部一直被频繁访问的缓存页给淘汰掉，而留下了之前全表扫描加载进来的大量不经常访问的缓存页。 基于冷热数据分离的思想设计 LRU 链表为了解决上面说的简单 LRU 链表的问题，真正 MySQL 在设计 LRU 链表的时候，采取的是冷热数据分离的思想。真正的 LRU 链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据。这个冷热数据的比例是由 innodb_old_blocks_pct 参数控制的，默认是 37，也就说冷数据占比 37%。如图： 数据页第一次被加载到缓存的时候既然 LRU 链表已经按照比例拆分成了冷热两块区域，那么在运行期间，冷热两个区域是如何使用的。 首先数据页第一次被加载到缓存的时候，缓存页会被放在冷数据区域的链表头部。 冷数据区域的缓存页何时被放入热数据区域接着下一个问题。冷数据区域的缓存页什么时候会放到热数据区域呢？MySQL 设计了一个柜子，它设计了 innodb_old_blocks_time 参数，默认值是 1000，也就是 1000 毫秒。即，必须是一个数据页被加载到缓存页之后，在 1s 之后，你访问这个缓存页，它才被挪动到热数据区域的链表头部去。 因为假设你加载了一个数据页到缓存区，然后过了 1s 之后你还访问了这个缓存页，说明你后续很可能会经常访问它。这个时间限制就是 1s，只有了 1s 后访问了这个缓存页，它才会把缓存页放到热数据区域的链表头部去。 如何用冷热数据分离 LRU 链表解决简单 LRU链表带来的隐患预读以及全表扫描加载进来的一大堆缓存页在基于冷热数据分离的 LRU 链表的方案下，预读机制以及全表扫描加载进来的一大堆缓存页，他们会放在哪里？明显是放在 LRU 链表的冷数据区域的前面。 假设这个时候热数据区域已经有很多被频发访问的缓存页了，你会发现热数据区域还是存放被频发访问的缓存页，只要热数据区域有缓存页被访问，它还是会被移动到热数据区域的链表头部去。 所以，预读机制和全表扫描加载进来的一大堆缓存页，此时都在冷数据区域里，跟热数据区域里的频繁访问的缓存页，是没有关系的。 预读机制和全表扫描加载进来的缓存页，何时进热数据区域如果你仅仅是一个全表扫描的查询，此时肯定是在 1s 内就把一大堆缓存页加载进来，然后就访问了这些缓存页一下，通常这些操作 1s 内就结束了。 所以基于目前的一个机制，可以确定的是，这种情况下，那么缓存页是不会从冷数据区域转移到热数据区域的。除非你在冷数据区域里的缓存页，在 1s 之后还被人访问了，那么此时它们就会判定未来可能会被频繁访问的缓存页，然后移动到热数据区域的链表头部去。 如何淘汰一些缓存假设此时缓存页不够了，需要淘汰一些缓存页，要怎么处理？ 方法时直接可以找到 LRU 链表中的冷数据区域的尾部的缓存页，他们肯定是之前就被加载进来的，而且加载进来 1s 过后都没人访问过，说明这个缓存页是冷数据。所以此时就直接淘汰冷数据区域的尾部缓存页，刷入磁盘，就可以了。 LRU 链表热数据区域的优化接着我们看一下 LRU 链表的热数据区域的一个性能优化的点，就是，在热数据区域中，如果你访问了一个缓存页，是否应该要把它立刻移动到热数据区域的链表头部去？ 这个是没必要的。因为热数据区域里的缓存页可能是经常被访问的，所以这么频繁地进行移动性能也不是太好，也没必要。 因此，LRU 链表的热数据区域的访问规则被优化了一下，即你只有在热数据区域的后 3/4 部分的缓存页被访问了，才会给你移动到链表头部去。如果你是热数据区域的前面 1/4 的缓存页被访问了，它是不会被移动到链表头部的。 例如，假设热数据区域的链表里有 100 个缓存页，那么排在前面的 25 个缓存页，即使被访问了，也不会移动到链表头部去。但是对于后面的 75 个缓存页，只要被访问，就会移动到链表头部去。 对于 LRU 链表中尾部的缓存页，如何淘汰他们刷入磁盘Buffer Pool 在运行过程中被使用的时候，实际上会频繁地从磁盘上加载数据页到它的缓存页里去，然后 free 链表、flush 链表、lru 链表都会在使用的使用同时被使用。 比如数据加载到一个缓存页，free 链表里会移除这个缓存页，然后 lru 链表的冷数据区域的头部会放入这个缓存页。 然后如果你修改了一个缓存页，那么 flush 链表中会记录这个脏页，lru 链表还可能会把你从冷数据区域移动到热数据区域的头部去。 总之，MySQL 在执行 CRUD 的时候，首先是大量的操作缓存页以及对应的几个链表。然后再缓存页都满的时候，必然要想办法把一些缓存页给刷入磁盘，然后清空这几个缓存页，接着把需要的数据页加载到缓存里去。我们已经知道它是根据 LRU 链表去淘汰缓存页的，那么它到底什么时候把 LRU 链表的冷数据区域中的缓存页刷入到磁盘呢？ 定时把 LRU 尾部的部分缓存刷入磁盘首先第一个时机，并不是在缓存页满的时候，才会挑选 LRU 冷数据区域尾部的几个缓存页刷入磁盘，而是有一个后台线程，它会运行一个定时任务，这个定时任务每隔一段时间就会把 LRU 链表的冷数据区域的尾部一些缓存页，刷入磁盘里去，清空这几个缓存页，把他们加入回 free 链表去。 所以实际上在缓存页没用完的时候，可能就会清空一些缓存页了。 所以，只要有这个后台线程定时运行，可能你的缓存还没用完，人家就把一批冷数据的缓存页刷入磁盘，清空出一批缓存页了，那么你就多了一批可以使用的缓存页了。只要有缓存页被刷入磁盘，那么这个缓存页必然会加入到 free 链表，从 flush 链表中移除，从 lru 链表中移除。 把 flush 链表中的一些缓存页定时刷入磁盘如果仅仅把 LRU 链表中的冷数据区域的缓存页刷入磁盘，明显是不够的，因为在 LRU 链表的热数据区域里很多缓存页可能也会被频繁地修改，难道它们永远都不刷入磁盘中了吗？ 所以这个后台线程同时也会在 MySQL 不那么繁忙的时候，找个时间把 flush 链表中的缓存页都刷入磁盘中，这样被你修改过的数据，迟早都会刷入磁盘的。 只要 flush 链表中的一波缓存页被刷入磁盘，那么这些缓存页也会从 flush 链表和 LRU 链表中移除，然后加入到 free 链表中去。 可以理解为，你一边不停地加载数据到缓存页里去，不停地查询和修改缓存数据，然后 free 链表页不停地减少，flush 链表中的缓存页不停地在增加，lru 链表中的缓存页不停地在增加和移动；另外一边，你的后台线程不停地把 LRU 链表的冷数据区域的缓存页以及 flush 链表的缓存页，刷入磁盘中来清空缓存页，然后 flush 链表和 LRU 链表中的缓存页不断减少，free 链表中的缓存页不断增加。 这就是一个动态运行起来的效果！ 实在没有空闲缓存页怎么办如果实在没有空闲缓存页了怎么办？此时可能所有的 free 链表都被使用了，然后 flush 链表中有一大堆被修改过的缓存页，LRU 链表中有一大堆的缓存页，根据冷热数据进行了分离，大致是如此的效果。 这个时候如果要从磁盘加载数据页到一个空闲缓存页中，此时就会从 LRU 链表的冷数据区域的尾部找到一个缓存页，它一定是最不经常使用的缓存页。然后把它刷入磁盘和清空，然后把数据页加载到这个腾出来的空闲缓存页里去。 这就是 MySQL 的 Buffer Pool 缓存机制的一整套运行原理。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模拟 JVM 内存溢出]]></title>
    <url>%2FCKING.github.io%2F2020%2F03%2F02%2F%E6%A8%A1%E6%8B%9F-JVM-%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[模拟 Metaspace 内存溢出Metaspace 区域发生内存溢出的一个场景，就是如果我们在程序里不停地动态生成类，就会导致不停地加载类到 Metaspace 区域里去，而且这些动态生成的类必须还是不能被回收的。接着一旦 Metaspace 区域满了，就会触发 Full GC 连带着回收 Metaspace 中的类，但是此时大量的类是不能被回收的。 因此即使触发过 Full GC 过后，Metaspace 区域几乎还是不能放下任何一个类，此时必然会触发 Metaspace 区域的内存溢出。 CGLIB 动态生成类的代码示例以下代码时用 Maven 来进行项目构建的，如果要用 CGLIB 来动态生成一些类，那么必须在你项目的 pom.xml 中引入以下的一些依赖 12345&lt;dependency&gt; &lt;groupId&gt;cblib&lt;/gruopId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.3.0&lt;/version&gt;&lt;/dependency&gt; 接着就可以使用 CGLIB 来动态生成类了，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;public class Demo1 &#123; public static void main(String[] args) &#123; long counter = 0; while (true) &#123; System.out.println("目前创建了 " + (++counter) + " 个Car类的子类了"); Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(Car.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; if(method.getName().equals("run")) &#123; System.out.println("启动汽车之前，先进行自动的安全检查。。。。。"); return methodProxy.invokeSuper(o, objects); &#125;else &#123; return methodProxy.invokeSuper(o, objects); &#125; &#125; &#125;); Car car = (Car) enhancer.create(); car.run(); &#125; &#125; static class Car &#123; public void run() &#123; System.out.println("汽车启动，开始行使。。。。。。"); &#125; &#125;&#125; 跟大家解释以下上面的代码。首先我们可以看到我们在这里定义了一个类，代表了一个汽车，它有一个 run() 方法，执行的时候就会启动汽车，开始让汽车行驶，如下： 12345static class Car &#123; public void run() &#123; System.out.println("汽车启动，开始行使。。。。。。"); &#125;&#125; 接着我们看下面的代码片段，我们通过 CGLIB 的 Enhancer 类生成一个 Car 类的子类。从这里开始，就动态生成类了，如下： 123Enhancer enhancer = new Enhancer();enhancer.setSuperclass(Car.class);enhancer.setUseCache(false); 你权且当做 Enhancer 是用来生成类的一个 API，代码中的 enhancer.setSuperclass(Car.class); 的意思是说 Enhancer 生成的类是 Car 类的子类，Car 类是生成类的父类。至于那个 UseCache 是什么意思，就先别管了。 既然 Enhancer 动态生成的类是 Car 的子类，那么子类也会有 Car 的 run() 方法，而且我们在调用子类的 run() 方法的时候可以做点手脚，如下： 123456789101112enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; if(method.getName().equals("run")) &#123; System.out.println("启动汽车之前，先进行自动的安全检查。。。。。"); return methodProxy.invokeSuper(o, objects); &#125;else &#123; return methodProxy.invokeSuper(o, objects); &#125; &#125;&#125;); 这个片段的意思是，如果你调用子类对象的 run() 方法，会先被这里的 MethodInterceptor 拦截一下，如果判断了一下，如果你调用的 Method 是 run 方法，那么就先对汽车做一下安全检查。安全检查做完之后，再通过 “methodProxy.invokeSuper(o, objects)” 调用父类 Car 的 run() 方法，去启动汽车，这行代码就会执行到 Car 类的 run() 方法。 到此为止，我们就已经通过 CGLIB 的 Enhancer 生成了一个 Car 类的子类了，而且定义好了对这个子类调用继承自父类的 run() 方法的时候，先干点别的，再调用父类的 run() 方法。 这样子，就跟下面手写的一个 Car 子类是类似的 12345678static class SafeCar extends Car &#123; @Override public void run() &#123; System.out.println("汽车启动，开始行使。。。。。。"); super.run(); &#125;&#125; 限制 Metaspace 大小看内存溢出效果接着我们可以设置一下这个程序的 JVM 参数，限制它的 Metaspace 区域小一点。例如我们用 -XX:MetaspaceSize=10m -XX:MaxMetaspaceSize=10m。接着我们可以在上述代码中做一下修改。大家看到上面的代码时有一个 while 循环的，所以它会不停地创建 Car 类的子类，我们在里面可以加一个计数器，就是看看当前创建了多少个 Car 的子类，如下： 1234long counter = 0;while(true) &#123; System.out.println("目前创建了" + (++counter) + "个 Car 类的子类了");&#125; 接着用上述 JVM参数来运行这个程序即可，如图： 模拟 JVM 栈内存溢出Metaspace 区域我们一般会设置为 512MB 左右的大小，这个大小只要你代码里没有自己胡乱生成类，一般都是够你存放一个系统运行时需要的类的。堆内存的大小，一般分配在机器内存的一半就差不多了，毕竟还要考虑其他对内存的使用。 最后一个内存区域就是栈内存区域。在一个基本的线上机器配置，比如 4 核 8G 的线上机器，其中 512M 给了 Metaspace，4G 给了堆内存（其中包括了年轻代和老年代），剩余只有 3G 左右的内存了，要考虑到操作系统自己也会用掉一些内存。那么剩余你就认为有一两个 GB 的内存可以留给栈内存好了。 通常来讲，我们会设置每个线程的栈内存为 1MB，假设你一个 JVM 进程内包括它自带的后台线程，你依赖的第三方组件的后台线程，加上你的核心工作线程（比如你部署在 Tomcat 中，那就是 Tomcat 的工作线程），还有你自己可能额外创建的一些线程，可能要你一个 JVM 中有 1000 个线程。那么 1000 个线程就需要 1GB 的栈内存空间，每个线程有 1MB 的空间。 所以 Metaspace 区域 + 堆内存 + 几百个线程的栈内存，就是 JVM 一共对机器上的内存资源的一个消耗，所以你也能理解这么一个道理：你要是给每个线程的栈内存分配过大的空间，那么会导致机器上能创建的线程数量变少，要是给每个线程的栈内存相对较小，能创建的线程就会比较多一些。当然，现在都建议给栈内存 1MB 就可以了。 示范栈内存溢出先看一段代码： 12345678910111213public class Demo2 &#123; public static long counter = 0; public static void main(String[] args) &#123; work(); &#125; public static void work() &#123; System.out.println("目前是第 " + (++counter) + " 次调用方法"); work(); &#125;&#125; 上面的代码就是 work() 方法调用自己，进入一个无限制的递归调用，陷入死循环，也就是在 main 线程的栈中，会不停地压入 work() 方法调用的栈帧，知道 1MB 的内存空间耗尽。 另外需要设置这个程序的 JVM 参数：-XX:ThreadStackSize=1m。通过这个参数设置 JVM 的栈内存为 1MB。接着运行代码，就会看到如下： 12目前是第 6203 次调用方法Exception in thread "main" java.lang.StackOverflowError 也就是说，当这个线程调用了 6203 次方法之后，它的栈里压入了 6203 个栈帧，最终把 1MB 的栈内存给塞满了，引发了栈内存的溢出。 模拟 JVM 堆内存溢出之前已经讲过堆内存溢出的原理，现在用代码给大家演示一下： 123456789101112public class Demo3 &#123; public static void main(String[] args) &#123; Long counter = 0L; List&lt;Object&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new Object()); System.out.println("当前创建了第" + (++counter) + "个对象"); &#125; &#125;&#125; 代码很简单，就是在一个 while 循环里不停地创建对象，而且对象全部都是放在 List 里面被引用的，也就是不能回收的。 如果你不停地创建对象，Eden 区满了，它们全部存活的话就会转移到老年代，反复几次之后老年代满了，然后 Eden 区再次满了，ygc 后存活对象再次进入老年代，此时老年代先 full gc，但是回收不了任何对象，因此 ygc 后的存活对象就一定是无法进入老年代的。 所以我们用 -Xms10m -Xmx10m 限制了堆内存大小总共就只有 10m，这样可以尽快触发堆内存的溢出。我们可以在控制台打印的信息看到如下： 12当前创建了第360145个对象Exception in thread "main" java.lang.OutOfMemoryError: Java heap space 从这里看出，在 10M 的堆内存中，用最简单的 Object 对象搞到老年代被塞满大概需要 36 万个对象，然后堆内存实战放不下任何对象，此时就会 OutOfMemory 了，而且告诉你是 Java heap space，也就是堆空间发生了内存溢出。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OOM 内存溢出]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F28%2FOOM-%E5%86%85%E5%AD%98%E6%BA%A2%E5%87%BA%2F</url>
    <content type="text"><![CDATA[系统 OOM作为 Java 程序员而言，先不考虑自己系统外部依赖的缓存、消息队列、数据库等服务挂掉。就我们本身系统而言，最常见挂掉的原因是什么？就是系统 OOM，也就是所谓的内存溢出。那什么是内存溢出？简单说就是你的 JVM 内存就这么点，结果你拼命往里面塞东西，结果内存塞不下了，就直接溢出了。 那有哪些情况会导致系统发生 OOM 内存溢出？我们从 JVM 的核心原理出发，给大家讲讲哪些地方可能会发生内存溢出。 运行一个 Java 系统首先我们要明白一个事情，就是我们平时启动一个 Java 系统，本质上就是启动一个 JVM 进程。我们用最基本的情况来演示一下，比如下面的代码： 1234567public class HelloWorld &#123; public static void main(String[] args) &#123; String message = "Hello World"; System.out.println(message); &#125;&#125; 当我们在 Eclipse 或者 Intelij IDEA 中写好这个代码，然后通过 IDE 来运行这个代码时，会发生哪些事情？ 首先，我们写好的代码都是后缀为 “.java” 的源代码，这个代码时不能运行的。所以第一步就是将这份 “.java” 源代码文件编译成一个 “.class” 字节码文件，这个字节码才是可以运行的。 对于这种编译好的字节码文件，比如 HelloWorld.class，如果里面包含了 main 方法。接下来我们就可以用 “java 命令” 来执行这个字节码文件了。实际上一旦你执行 “java 命令”，相当于就会启动一个 JVM 进程，这个 JVM 进程就会负责执行你写好的那些代码。 所以要知道一点，运行一个 Java 系统，本质上就是启动一个 JVM 进程，这个 JVM 进程负责来执行你写好的一大堆代码。只要你的 Java 系统中包含一个 main 方法，JVM 进程就会从你指定的这个 main 方法入手，开始执行你写的代码。 JVM 加载你写的类接下来，JVM 进程怎么执行你写的那些代码？Java 是一个面向对象的语言，所以最基本的代码组成单元就是一个一个的类，平时我们写的 Java 代码，不就是写一个一个的类吗？然后再类里我们会定义各种变量、方法、数据结构，通过 if else 之类的语法，写出各种各样的系统业务逻辑，这就是所谓的编程了。 所以 JVM 要执行你的代码，首先要把你写好的代码加载到内存里来。在 JVM 的内存区域里，有一块内存区域叫做永久代，当然 JDK 1.8 以后都叫做 Metaspace 了，这块内存就是用来存放你系统里的各种类的信息，包括 JDK 自身内置的一些类的信息，都在这块区域里。 JVM 有类加载器和一套类加载的机制，包括 加载、验证、准备、解析、初始化、使用、卸载这几个阶段，详细内容可以查看这篇文章，这里不再赘述。他会负责把我们写好的类从编译好的 “.class” 字节码文件里加载到内存里来。如图： 既然有这么一块 Metaspace 区域是用来存放类信息的，那就有可能在这个 Metaspace 区域里发生 OOM。 Java 虚拟机栈：让线程执行各种方法一般情况下，我们写好的那些 Java 代码虽然是一个一个的类，但是核心的代码逻辑一般是封装在类里面的各种方法中的。比如 JVM 已经加装了我们写好的 HelloWorld 类到内存里，接着要怎么执行它里面的代码呢？ Java 语言中的一个通用规则，就是一个 JVM 进程总是从 main 方法开始执行的，所以我们既然在 HelloWorld 中写了一个 mian() 方法，那么就得执行这个方法中的代码了。 那谁去执行 main() 方法的代码？其实我们所有的方法执行，都依赖于 JVM 进程中的某个线程去执行，你可以理解为线程才是执行我们写的代码的核心主体。JVM 进程启动之后默认就会有一个 main 线程，这个 main 线程就是专门负责执行 main() 方法的。 还有一个问题，在 main() 方法中定义了一个局部变量 message，一般情况下，这些方法里的局部可能会有很多，那么这些局部变量放在哪里呢？其实，每个线程都有一个自己的虚拟机栈，就是所谓的栈内存。然后这个线程只要执行一个方法，就会为方法创建一个栈帧，将栈帧放入自己的虚拟机栈里，然后这个栈帧放入方法中定义的各种局部变量。如图： 我们可以通过一个 JVM 参数来设置每个线程中的虚拟机栈的内存大小，一般是设置为 1 MB。那么既然每个线程的虚拟机栈的内存大小是固定的，那么第二块可能发生 OOM 的区域，就是每个线程的虚拟机栈内存。 堆内存：存放我们创建的各种对象最后，在我们写好的代码里，特别在一些方法中，可能会频繁地创建各种各样的对象，这些对象都是放在堆内存里的。如图： 而且，通常我们在 JVM 中分配给堆内存的空间其实是固定的。既然如此，我们还不停在堆内存里创建对象，那堆内存也是有可能会发生内存溢出。 Metaspace 区域因类太多而发生内存溢出在启用一个 JVM 时可以设置很多参数，其中一些参数是专门用来设置 Metaspace 区域的内存大小的。就是 -XX:MetaspaceSize=512m -XX:MaxMetaspaceSize=512m 这两个。所以实际上来说，在一个 JVM 中，Metaspace 区域的大小是固定的，比如 512MB。 那么一旦 JVM 不停地加载类，加载了很多的类，然后 Metaspace 区域放满了，就会触发 Full GC。Full GC 会回收老年代和年轻代，当然也会尝试着回收 Metaspace 区域中的类。 那什么样的类才可以被回收呢？这个条件是相当苛刻的，包括不限于以下一些：比如这个类的类加载器先要被回收，比如这个类的所有对象实例都要被回收等等。所以一旦你的 Metaspace 区域满了，未必能回收掉里面很多的类。 那么一旦回收不了多少类，此时 JVM 还在拼命地加载类放到 Metaspace 里去，一旦塞满 Metaspace 区域，就会引发内存溢出的问题，因为此时 Metaspace 区域的内存空间不够了。 什么情况会发生 Metaspace 内存溢出一般情况，Metaspace 这块区域一般很少发生内存溢出，如果发送内存溢出一般都是因为这两个原因： 第一种原因，很多工程师不懂 JVM 的运行原理，在上线时对 Metaspace 区域直接用默认的参数，即根本不设置其大小。这会导致默认的 Metaspace 区域可能才几十 MB 而已，此时对于稍微大型一点的系统，因为它自己有很多类，还依赖了很多外部的 jar 包的类，几十 MB 的Metaspace 很容易就不够了。 第二种原因，很多人写系统的时候会用 cglib 之类的技术动态生成一些类，一旦代码没有控制好，导致你生成的类过于多的时候，就很容易把 Metaspace 给塞满，进而引发内存溢出。 对于第一种问题，只要在系统上线的时候设置好对应的 Metaspace 大小就可以了。推荐 512MB 第二种情况，稍微我们会用模拟代码给大家演示那种不停的生成大量的类的情况。 无限制地调用方法让线程的栈内存溢出我们先看下面的代码： 1234567891011public class HelloWorld &#123; public static void main(String[] args) &#123; String message = "Hello World"; System.out.println(message); sayHello("ckin"); &#125; public static void sayHello(String name) &#123; System.out.println("你好，" + name); &#125;&#125; 按照之前说的，JVM 启动之后，HelloWorld 类被加载到了内存里来，然后会通过 main 线程执 main() 方法。此时在 main 线程的虚拟机栈里，就会压入 main() 方法对应的栈帧，里面就会放入 main() 方法中的局部变量。 而且，我们是可以手动设置每个线程的虚拟机栈的内存大小的，一般来说现在默认都是给 1MB。所以 main 线程的虚拟机栈内存大小一般也是固定的。现在看上面的代码，代码中的 main() 方法中又继续调用一个 sayHello() 方法，而且 sayHello() 方法中也有自己的局部变量，所以此时会继续将 sayHello() 方法的栈帧压入到 main 线程的虚拟机栈中去，如图： 接着 sayHello() 方法如果运行完毕之后，就不需要为这个方法在内存中保存它的一些局部变量之类的东西了，此时就会将 sayHello() 方法对应的栈帧从 main 线程的虚拟机栈里出栈，再接着，一旦 main() 方法自己本身也运行完毕，自然会将 main() 方法对应的栈帧也从 main 线程的虚拟机栈里出栈。这个我们就不在图里表示了。 一个重要的概念：每次方法调用的栈帧都是占用内存的在这里要跟大家说一个概念，就是每个线程的虚拟机栈的大小是固定的，比如就 1MB，然后每次这个线程调用一个方法，都会将方法调用的栈帧压入虚拟机栈里，这个栈帧是有方法的局部变量的。 虽然一些变量和其他的一些数据占用不了太大的内存，但是要注意，每次方法调用的栈帧实际上也是会占用内存的。这是非常关键的一点，哪怕一个方法调用的栈帧就占用几百个字节的内存，那也是内存占用。 什么情况会导致 JVM 中的栈内存溢出既然明确了上述前提之后，那到底什么情况下 JVM 中的栈内存会溢出呢？既然一个线程的虚拟机内存大小是有限的，比如 1MB，那么假设你不停地让这个线程去调用各种方法，然后不停地把方法调用的栈帧压入栈中，此时终有一个时刻，大量的栈帧就会消耗完毕这个 1MB 的线程栈内存，最终就会导致出现栈内存溢出的情况。 通常而言，哪怕你的线程的虚拟机栈内存就 128KB，或者 256KB，通常都是足够进行一定深度的方法调用的，但是如果你要是走一个递归方法调用，那就不一定了，例如下面代码： 123public static void sayHello(String name) &#123; sayHello(name);&#125; 一旦出现上述代码，一个线程就会不停地调用同一个方法，即使是同一个方法，每次方法调用也会产生一个栈帧压入栈里，例如对 sayHello() 进行 100 次调用，那么就会有 100 个栈帧压入栈中。所以如果疯狂地运行上述代码，就会不停地将 sayHello() 方法的栈帧压入栈里，最终一定会消耗掉线程的栈内存，引发内存溢出。 所以一般来说，引发栈内存溢出，往往都是代码里写了些 bug 才会导致的，正常情况下发生的比较少。 对象太多导致的堆内存溢出如果要把大量的对象是如何导致堆内存溢出的说清楚，那就要从系统运行，在 Eden 区创建对象开始讲起。之前我们说过，平时系统运行的时候一直不停地创建对象，然后大量的对象会填满 Eden 区，一旦 Eden 区满之后，就会触发一次 Young GC，然后存活对象进入 S 区。 高并发场景下导致 ygc 后存活对象太多当然因为各种各样的情况，一旦出现了高并发场景，导致 ygc 后很多请求还没处理完毕，存活对象太多，可能就在 Survivor 区域放不下了，此时只能进入到老年代里去了，老年代很快会填满。一旦老年代放满了就会触发 Full GC，如图所示： 我们假设 ygc 过后有一批存活对象，Survivor 放不下，此时就等着要进入老年代里，然后老年代也满了，就等着老年代进行 CMS GC，必须回收掉一批对象，才能让年轻代里存活下来的一批对象。但是，如果 Full GC 之后还是存活了很多的对象，如果这时候年轻代还有一批对象等着放进老年代，人家 GC 过后空间还是不足，就只能内存溢出了。 什么时候会发生堆内存的溢出发生堆内存溢出的原因总结下来就是，有限的内存中存放了过多的对象，而且大多数都是存活的，此时即使 GC 过后还是大部分都存活吗，所以要继续放入更多对象已经不可能了，此时只能引发内存溢出问题。 所以一般来说发生内存溢出有两种情况： 系统承载高并发请求，因为请求量过大，导致大量对象都是存活的，所以要继续放入新的对象实在是不行了，此时就会引发 OOM 系统崩溃。 系统有内存泄露问题，就是莫名其妙弄了很多的对象，结果对象都是存活的，没有及时取消对他们的引用，导致触发 GC 还是无法回收，此时只能引发内存溢出。 因此总结起来，一般引发 OOM，一是系统负载过高，二是有内存泄露问题。这个 OOM 问题，一旦你的代码写的不太好，或者设计有缺陷，还是比较容易引发的。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[元数据区导致的频繁 Full GC]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F18%2F%E5%85%83%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%AF%BC%E8%87%B4%E7%9A%84%E9%A2%91%E7%B9%81-Full-GC%2F</url>
    <content type="text"><![CDATA[场景一个新手工程师在网上看了某个 JVM 参数，在测试环境部署系统的时候，设置了一个 JVM 参数。由于测试环境有接触 Zabbix 监控系统，可以让你的系统进去，在上面可以看到每台机器的 CPU、磁盘、内存和网络的一些负载。 那个工程师设置了一个 JVM 参数之后，直接导致线上系统频繁接到 JVM 的 Full GC 的报警。于是就开始排查那个系统了。 查看 GC 日志之前有说过如果在系统启动的时候让他输出 GC 日志，所以一旦发现报警，直接登录到线上机器，然后就可以看到对应的 GC 日志了。 在日志里，看到了一个 Metadata GC Threshold 的字样，类似于如下位置： 1[Full GC (Metadata GC Threshold) xxxxx, xxxxx] 从这里就可以看出，这频繁的 Full GC，实际上是 JDK1.8 以后的 Metadata 元数据区导致的，也就是类似我们之前说的永久代。 这个 Metadata 区域一般是放一些加载到 JVM 里去的类，所以此时就很奇怪了，为什么会因为 Metadata 区域频繁地被塞满，进而触发 Full GC？而且 Full GC 会带动 CMS 回收老年代，还会回收 Metadata 区域本身。如图： 查看 Metaspace 内存占用情况接着我们看一下 Metaspace 区域的内存占用情况，简单点你可以通过 jstat 来观察。如果有监控系统，它会给你展示出来一个 Metaspace 内存区域占用的波动曲线图，类似下面： 看起来 Metaspace 区域的内存呈现一个波动的状态，它总是会先不断增加，达到一个顶点之后，就会把 Metaspace 区域给占满，然后自然就会触发一次 Full GC，Full GC 会带着 Metaspace 区域的垃圾回收，所以接下来 Metaspace 区域的内存占用又变得很小了。 一个综合性的分析思路看到这里，相信大家肯定有一点感觉了。这个明显是系统在运行过程中，不停地有新的类产生被加载到 Metaspace 区域里去，然后不停地把 Metaspace 区域占满，接着触发一次 Full GC 回收掉 Metaspace 区域中的部分类。然后这个过程反复不断地循环，进而造成 Metaspace 区域反复被占满，然后反复导致 Full GC 的发生，如图： 到底是什么类不停地被加载那到底是什么类不停地被加载到 JVM 的 Metaspace 区域里去？这个时候就要在 JVM 启动参数中加入这个参数了：-XX:TraceClassLoading -XX:TraceClassUnloading。 这两个参数，顾名思义，就是追踪类加载和类卸载的情况，它会通过日志打印出来 JVM 中加载了哪些类，卸载了哪些类。加入这两个参数后，我们就可以看到 JVM 日志文件中，输出流一堆日志，里面显示如下的内容： 1[Loaded sun.reflect.GeneratedSerializationConstructorAccessor from _JVM Defined_Class] 明显可以看到，JVM 在运行期间不停地加载了大量的所谓 “GeneratedSerializationConstructorAccessor” 类到了 Metaspace 区域里去。就是因为 JVM 运行期间不停地加载这种奇怪的类，然后不停地把 Metaspace 区域占满，才会引发不停地执行 Full GC。 这是一个非常实用的技巧。频繁 Full GC 不光是老年嗲触发的，有时候也会因为 Metaspace 区域的类太多而触发。 为什么会频繁加载奇怪的类接着遇到类似这种情况，通过 Google 发现，那个类大概是你使用 Java 中的反射加载的，所谓反射代码类似如下： 12Method method = XXX.class.getDeclareMethod(xx, xx);method.invoke(target, params); 简单来说就是通过 XXX.class 获取到某个类，然后通过 getDeclaredMethod 获取到那个类的方法。这个方法就是一个 Method 对象，接着通过 Method.invoke 可以去调用那个类的某个对象的方法，大概就这个意思。 在执行这种反射的时候，JVM会在你反射调用一定次数之后就动态生成一些类，就是我们之前看到的那种莫名其妙的类。下次你再次执行反射的时候，就是调用这些类的方法，这是 JVM 的一个底层优化。 看到这，是不是有点懵。这个倒无所谓，不影响你进行 JVM 的优化。你只需要记住一个结论：如果你在代码里大量用了类似上面反射的东西，那么 JVM 就是会动态地去生成一些类放入 Metaspace 区域里的。所以上面看到的那些奇怪的类，就是由于不停地执行反射的代码才生成的。如图： JVM 创建的奇怪类有什么玄机那么 JVM 为什么要不停地创建那些奇怪的类然后放入 Metaspace 中去？其实这要从一个点入手来分析一下了，因为上面说的那种 JVM 自己创建的奇怪的类，它们的 Class 对象都是 SoftReference，也就是软引用。 可能有人不知道类的 Class 是什么。简单来说，每个类本身自己也是一个 Class，就是一个 Class 对象，一个 Class 对象就代表了一个类。同时这个 Class 对象代表的类，可以派生出很多实例对象。例如，Class Student，这就是一个类，它本身是由一个 Class 类型的对象表示的。但是如果你走一个 Student student = new Student()，这就是实例化了这个 Student 类的一个对象，这是一个 Student 类型的实例对象。 所以我们这里说的 Class 对象，就是 JVM 在反射过程中动态生成的类的 Class 对象，它们都是 SoftReference 软引用的。所谓的软引用，正常情况下不会回收，但是如果内存比较紧张的时候就会回收这些对象。 那么 SoftReference 对象到底在 GC 的时候要不要回收是通过什么来判断的呢？就是这么一个公式： clock - timestamp &lt;= freespace * SoftRefLRURPolicyMSPerMB 这个意思是，clock - timestamp 代表了一个软引用对象它有多久没被访问过了，freespace 代表了 JVM 中的空闲内存空间，SoftRefLRUPolicyMSPerMB 代表每一 MB 空闲内存空间可以允许 SoftReference 对象存活多久。 举个例子，加入说现在 JVM 创建了一大堆的奇怪的类出来，这些类本身的 Class 对象都是被 SoftReference 软引用的。然后新增 JVM 的内存空间有 3000 MB，SoftRefLRURPolicyMSPerMB 默认值是 1000 毫秒，那么就意味着，此时那些奇怪的 SoftReference 软引用的 Class 对象，可以存活 3000 * 1000 = 3000 秒，就是 50 分钟左右。 当然上面也只是举例子。正常情况下，发生 GC 时，其实 JVM 内部或多或少都有一些空间内存的，所以基本上如果不是快要发生 OOM 内存溢出了，一般软引用也不会被回收了。所以正常情况下，JVM 会随着反射代码的执行，动态地创建一些奇怪的类，它们的 Class 对象都是软引用，正常情况下不会被回收，但是也不应该快速增长才对。 为什么 JVM 创建的奇怪的类会不停地变多那为什么 JVM 创建的那些奇怪的类会不停地变多呢？原因是，文章开头的新手工程师不知道从哪里扒出来了 SoftRefLRUPolicyMSPerMB 这个JVM 启动参数，它直接把这个参数设置为 0 了。他想的是，一旦这个参数设置为 0，任何软引用对象就可以尽快释放掉，不用留存，尽量给内存释放空间出来，这样就可以提高内存利用率了。 实际上一旦这个参数设置为 0 之后，直接导致 clock - timestamp &lt;= freespace * SoftLRUPolicyMSPerMB 这个公式的右半边是 0，就导致所有的软引用对象，比如 JVM 生成的那些奇怪的 Class 对象，刚创建出来就可能被一次 Young GC 给带着立马回收掉了。 比如 JVM 给你弄出 100 个奇怪的类，结果你瞎设置软引用的参数，导致突然一次 GC 就给你回收掉几十个类。接着 JVM 在反射代码执行的过程中，就会继续创建这种奇怪的类，这 JVM 的机制之下，会导致这种奇怪的类越来越多。 也许下一次 GC 又会回收掉一些奇怪的类，但是马上 JVM 还会继续生成这种类，最终导致 Metaspace 区域就被放满了，一旦 Metaspace 区域放满了，就会触发 Full GC，然后回收掉很多类，接着再次重复上述循环。 为什么软引用的类因为错误的参数设置被快速回收之后，就会导致 JVM 不停创建更多的新的类呢？其实大家不用去扣这里的细节，这里有大量的底层 JDK 源码的实现，异常复杂，大家只要记住这个结论就好。 如何解决这个问题虽然底层 JDK 的一些实现细节没分析，但是大致梳理出来了一个思路，大家也清楚问题所在和原因了。解决方案很简单，在有大量反射代码的场景下，主要把 -XX:SoftRefLRUPolicyMSPerMB = 0 这个参数设置大一些即可。千万不要设置为 0，可以设置个 1000,2000，或者 5000 毫秒。 提高这个数值，就是让反射过程中 JVM 自动创建的软引用的一些类的 Class 对象不要被随便回收。当我们优化这个参数之后，就可以看到系统稳定运行了，基本上 Metaspace 区域的内存占用是稳定的，不会来回大幅度波动了。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[企业级 JVM 参数模板]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F16%2F%E4%BC%81%E4%B8%9A%E7%BA%A7-JVM-%E5%8F%82%E6%95%B0%E6%A8%A1%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[在一些微小型创业公司中，虽然有少数几个比较好的架构师，但是架构师往往没那么大精力把控到特别细节的地方。如果一些一线普通工程师对 JVM 那么快没有那么的精通，在开发完一个系统之后，部署生产环境的时候没有对 JVM 进行什么参数设置的时候，可能很多时候就是用一些默认的 JVM 参数。 默认的 JVM 参数绝对是系统负载逐渐增高的时候一个最大的问题。如果你不设置 -Xms、-Xmx 之类的堆内存大小的话，你启动一个系统，可能默认就给你几百 MB 的堆内存大小，新生代和老年代可能都是几百 MB 的样子。 新生代内存过小，会导致 Survivor 区域内存过小，同时 Eden 区域也很小。Eden 区域过小，自然会频繁地触发 Young GC，Survivor 区域过小，自然会导致经常在 Young GC 之后存活对象其实也没多少，但就是 Survivor 区域放不下。此时必然会导致对象经常进入老年代中，因此也必然会导致老年代过一段时间就被放慢，然后就会触发 Full GC。 Full GC 一般在正常情况下，都是以天为单位发生的，比如每天发生一次，或者是几天发生一次 Full GC。要是每小时都发生几次 Full GC，那么就会导致系统每小时都卡顿几次，这个时候肯定是不行的。在大部分工程师都对 JVM 优化不是很精通的情况下，通过推行一个 JVM 参数模板，可以让各个系统短时间内迅速就优化了 JVM 的性能。 企业级的 JVM 参数模板假设在一台 4 核 8 G 的机器上部署项目，那么我们的 JVM 参数可以这么设置： 1-Xms4096M -Xmx4096M -Xmn3072M -Xss1M -XX:PermSize=256M -XX:MaxPermSize=256M -XX:+UseParNewGc -XX:+UseConMarkSweepGC -XX:CMSInitiatingOccupancyFraction=92 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 为什么要这样定制 JVM 参数模板？首先，8G 的机器上给 JVM 堆内存分配 4G 就差不多了。毕竟可能还有其他进程会使用内存，一般别让 JVM 堆内存把机器内存给占满。然后年轻代给到 3G，之所以给到 3G 的内存时间，就是因为让年轻代尽量大一些，进而让每个 Survivor 区域都打到 300MB 左右。 根据当时对公司某个业务系统的分析，假设使用默认的 JVM 参数，可能年轻代就几百 MB 的内存，Survivor 区域就几十 MB 的内存。那么每次垃圾回收过后存活对象可能会有几十 MB，这是因为在垃圾回收的一瞬间可能有部分请求没处理完毕，此时会有几十 MB 对象式存活的，很容易触发动态年龄判定规则，让部分对象进入老年代。 所以在分析过后，给年轻代更大内存空间，让 Survivor 空间更大，这样在 Young GC 的时候，这一瞬间可能有部分请求没处理完毕，有几十 MB 的存活对象，这个时候再几百 MB 的 Survivor 空间中，可以轻松放下，不会进入老年代。 不同的系统运行时的情况略有不同，但是基本上都是在每次 Young GC 过后存活几 MB ~ 几十 MB，所以此时在这个参数下，都可以抗住。 这里有几个参数要简单介绍一下。-XX:CMSInitiatingOccupancyFraction=92 是指 CMS 垃圾回收器，当老年代达到 92% 时，触发 CMS 垃圾回收。而 -XX:+UseCMSCompactAtCollection -XX:+CMSFullGCsBeforeCompaction=0 则表示每次 Full GC 后都整理一下内存碎片。否则如果每次 Full GC 过后，都造成老年代里很多内存碎片，那么必然导致下一次 Full GC 更快到来，因为内存碎片会导致老年代可用内存变少。 如何优化每次 Full GC 的性能这里再介绍一下当时做优化调整的另外两个参数，这两个参数可以帮助优化 Full GC 的性能，把每次 Full GC 的时间进一步降低一些。一个参数是 -XX:+CMSParallelInitalMarkEnable，这个参数会在 CMS 垃圾回收器的 “初始标记” 的阶段开启多线程并发执行。 在初始标记阶段，是会进行 Stop the World 的，会导致系统停顿，所以这个阶段开启多线程并发之后，可以尽可能优化这个阶段的性能，较少 Stop the world 的时间。 另一个参数是 -XX:+CMSScavengeBeforeRemark，这个参数会在 CMS 重新标记之前阶段之前，先尽量执行一次 Young GC。因为 CMS 的重新标记也是会 Stop the World 的，所以如果在重新标记之前，先执行一次 Young GC，就会回收掉一些年轻代里没有引用的对象。 所以如果提前先回收掉一些对象，那么在 CMS 重新标记阶段就可以少扫描一些对象，此时就可以提升 CMS 重新标记阶段的性能，较少它的消耗。 所以在 JVM 参数模板中，同样也加入了这两个参数： 1-Xms4096M -Xmx4096M -Xmn3072M -Xss1M -XX:PermSize=256M -XX:MaxPermSize=256M -XX:+UseParNewGc -XX:+UseConMarkSweepGC -XX:CMSInitiatingOccupancyFraction=92 -XX:+UseCMSCompactAtFullCollection -XX:CMSFullGCsBeforeCompaction=0 -XX:CMSParallelInitalMarkEnable -XX:+CMSScavengeBeforeRemark]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 和 HTTPS]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F13%2FHTTP-%E5%92%8C-HTTPS%2F</url>
    <content type="text"><![CDATA[HTTPHTTP 1.0互联网初期，一般一个网页几乎没什么图片，当时就是挂一些文字，一个网页里就是一堆文字。那个时候使用的是 HTTP 1.0 版本。HTTP 1.0 要指定 keep-alive 来开启持久连接，默认是短连接，就是浏览器每次请求都要重新建立一次 tcp 连接，完了就释放 tcp 连接。早期的网页都比较简单，没什么东西，就一些文字，当时你打开一个网页，就是现场底层 tcp 三次握手，跟网站建立一个 tcp 连接，然后通过这个 tcp 连接，发送一次 http 请求，网站返回一个 http 响应（网页的 html，里面有一大段文字），浏览器收到 html 渲染成网页，浏览器就走 tcp 四次挥手，跟网站断开连接了。 到了后面，网页发展很迅猛，一个网页包含着大量的 css、js、图片等资源。比如你请求一个网页，这个网页的 html 先过来。过来之后，浏览器再次发起大量的请求去加载 css、js、图片。打开一个网页可能浏览器要对网站服务器发送几十次请求。 而这时候使用 HTTP 1.0 的短连接是不合适的，几十次频繁的建立 tcp 连接以及释放 tcp 资源，是非常慢的。最慢的不是发送请求和获取响应，而是打开和释放连接，这都是很重的过程。 HTTP 1.1http 1.1 默认支持长连接，就是说，浏览器打开一个网页之后，底层的 tcp 连接就保持着，不会立马断开。之后加载 css、js 之类的请求，都会基于这个 tcp 连接来走。http 1.1 还支持 host 头，也就可以支持虚拟主机；而且对断电续传有支持。 浏览器，第一次请求去一个网站的一个页面的时候，就会打开一个 tcp 连接，接着会在一段时间内不关闭。然后接下来这个网页加载 css、js、图片大量的请求全部走同一个 tcp 连接，频繁的发送请求和获取响应，等过了一段时间，这些事情都处理完了，然后才会去释放那一个 tcp 连接。这样可以大幅度提升网页的打开的速度和性能。 HTTP 2.0http 2.0 支持多路复用，基于一个 tcp 连接并行发送多个请求以及接收响应，解决了 http 1.1 对同一个时间同一个域名的请求有限制的问题。而且还支持二进制分帧，将传输数据拆分为更小的帧（数据包），提高了性能，实现低延迟高吞吐。 HTTPShttp 协议都是明文的，是没有加密的，所以其实现在一般大部分应用都是 https 协议的。HTTPS，是以安全为目标的 HTTPS 通道，简单讲是 HTTP 的安全版。之前是基于 SSL 协议对 http 进行加密，后来又升级到了 TSL 协议来加密。现在我们来看一下HTTPS 的原理。 HTTPS 故事讲解为了更好的了解 HTTPS 的原理，我们用一个故事来讲解。 序言来自中国的张大胖和位于美国的 Bill 进行通信。 总有一种被偷看的感觉由于张大胖和 Bill 都是使用 HTTP 进行通信，HTTP 是明文的，所以他们的聊天都是可被窥视的。于是，二人想要改变现状，所以 HTTP 首先要解决的问题就是要保证传输的内容只有两个人能看懂。 方法一：使用对称秘钥 两人商量了一下，可以使用对称秘钥进行加密。（对称秘钥就是加密和解密使用的是同一个秘钥）但是问题又来了，既然网络是不安全的，那么最开始的时候怎么将这个对称秘钥发送出去呢？如果对称秘钥在发送的时候就已经被拦截了，那么发送的消息还是会被篡改和窥视。 所以这种对称秘钥的弊端就是，可能被中间人拦截，这样中间人就可以获取到秘钥，就可以对传输的信息进行窥视和篡改。 方式二：使用非对称秘钥 RSA（非对称加密算法）：双方必须协商一对秘钥，一个私钥一个公钥。用私钥加密的数据，只有对应的公钥才能解密；用公钥加密的数据，只有对应的私钥才能解密。 有了这两个漂亮的特性，当张大胖给 Bill 发消息的时候，就可以先用 Bill 的公钥加密（反正 Bill 的公钥是公开的，地球人都知道），等到消息被 Bill 收到后，他就可以用自己的私钥去解密了（只有 Bill 才能解开，私钥是保密的） 返过来也是如此，当 Bill 想给张大胖发送消息的时候，就用张大胖的公钥加密，张大胖收到后，就用紫的私钥解密。这样一来，通信安全就固若金汤了。 但是这样有个弊端：RSA 算法很慢。为了解决这个问题，我们使用非对称 + 对称秘钥结合的方式。 方法三：非对称秘钥 + 对称秘钥使用对称秘钥的好处时速度比较快，使用非对称的好处是可以使得传输的内容不能被破解，因为就算你拦截到了数据，但是没有 Bill 的私钥，也是不能破解内容的。就好像你抢了一个保险柜，但是没有保险柜的钥匙也不能打开保险柜。 所以我们要结合两者的优点，使用 RSA 的算法将加密算法的秘钥发送过去，之后就可以使用这个秘钥，利用对称秘钥来通信了。 中间人攻击还有一个问题就是在使用非对称秘钥的时候，首先要将 Bill 的公钥给张大胖，那么在这个过程中，安全是没有保证的，中间人可以拦截到 Bill 的公钥，就可以对拦截到的公钥进行篡改。就相当于我有手机号，虽然是公开的，谁都可以给我打电话，但是你一开始并不知道我的手机号，我需要将我的手机号发给你。在我发给你手机号的时候，被中间人拦截了，然后将我正确的手机号改成了错误的手机号，但你并不知道这是错误的手机号。如果你一打电话，那就尴尬了。 确认身份—数据证书所以以上的步骤都是可行的，只需要最后一点就可以了，要确定 Bill 给张大胖的公钥确实是 Bill 的公钥，而不是别人，那怎么确认 Bill 给张大胖的公钥确实是 Bill 的呢？ 这个时候就需要公证处的存在 了。也就是说我需要先将我的电话号码到公证处去公证一下，然后我将电话号码传给你，你再将你收到的电话号码和公证处的对比下，就知道是不是我的了。 对应到计算机世界，那就是数字签名。 简单来讲是这样的，Bill 可以把他的公钥和个人信息用一个 Hash 算法生成一个消息摘要，这个 Hash 算法有个极好的特性，主要输入数据有一点点变化，那生成的消息摘要就会有巨变，这样可以防止别人修改原始内容。 这个时候黑客虽然没办法该公钥，但是可以把整个原始信息都替换了，生成一个新的消息摘要，从而来混淆我们。这个时候，我们就需要有公信力的认证中心（简称 CA）用它的私钥对消息摘要加密，形成签名： 这还不算，还要把原始信息和数据签名合并，形成一个全新的东西，叫做 “数字证书“ 当 Bill 把他的证书发给张大胖的时候，就用同样的 Hash 算法，再次生产消息摘要，然后用 CA 的公钥对数字签名解密，的到 CA 创建的消息摘要，两者一比，就知道有没有人篡改了。 这样子已经算是相当安全了。但是，CA 的这个公钥要怎么拿到？难道不怕攻击者在传输 CA 公钥的时候发起攻击吗？如果攻击者成功的伪装成了 CA，这一套体系就彻底玩完了。 所以折腾了半天，又回到了公钥安全传输的问题。不过要解决鸡生蛋，蛋生鸡的问题，就必须得打破这个怪圈。我必须得信任 CA，并且通过安全的方式获取他们的公钥。 注：这些 CA 本身也有证书来证明自己的身份，并且 CA 的信用是像树一样分级的，高层的 CA 给底层的 CA 做信用背书，而操作系统 / 浏览器会内置一些顶层的 CA 证书，相当于你自动信任了他们。这些顶层的 CA 证书一定得安全地放入操作系统 / 浏览器当中。 HTTPS 工作原理HTTPS 的工作原理大概是这样的： 浏览器请求服务端的时候，把自己支持的加密规则发送给网站 服务端从这套加密规则里选出来一套加密算法和 hash 算法，然后把自己的身份信息用数字证书的方式发回给浏览器。证书里有服务端地址、加密公钥、证书颁发结构等。 浏览器验证数字证书的合法性，接着浏览器会生成一个随机密码（就是公钥），然后用证书里的公钥进行加密，这块走的是非对称加密。用约定好的 hash 算法生成握手消息的 hash 值，然后用随机生成的公钥对消息进行加密，然后再把所有的东西都发送给服务端。 服务端从消息里面取出来浏览器用服务端公钥加密后的随机密码，然后后自己的私钥解密取出来密码。然后后密码解密浏览器发来的握手消息，计算握手消息的 hash 值，并验证与浏览器发送过来的 hash 值是否一致，最后用这个随机密码加密一段握手信息，发给浏览器 浏览器解密握手消息，然后计算消息的 hash 值。如果跟网站发来的 hash 一样，握手就结束，之后所有的数据都会由之前浏览器生成的随机密码，用对称加密的方法来进行加密。 参考资料码农翻身公众号]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP 的三次握手和四次挥手]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F11%2FTCP-%E7%9A%84%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%2F</url>
    <content type="text"><![CDATA[TCP 三次握手客户端与服务端通过传输层的 tcp 协议建立网络连接的时候，其实走的是三次握手的过程。建立三次握手的时候，TCP 报头用到了 ACK、SYN 这几个标志。 第一次握手，客户端发送连接请求报文，此时 SYN = 1、ACK = 0，这就是说这是个连接请求，seq = x，接着客户端处于 SYN_SEND 状态，等待服务器响应。 第二次握手，服务端收到 SYN = 1 的请求报文，需要返回一个确认报文，ack = x + 1、SYN = 1、ACK = 1、seq = y，发送给客户端，自己处于 SYN_RECV 的状态。 第三次握手，客户端收到了报文，将 ack = y + 1、ACK = 1、seq = x + 1 发送给服务端。 这三次握手，说白了，就是来回来去三次请求，每次请求带上一堆 TCP 报文，根据报文是否正确来建立连接。 为什么是 3 次握手而不是 2 次 或者 4 次3 次握手，是为了确认客户端和服务端都能正常的发送和接受信息所需的最少次数。 我们用 SEND 和 ACCEPT 来标志发送信息和接收信息的能力。 第一次握手，客户端并不知道自己是否能正常发送信息，有可能网络不通或者其他原因导致信息丢失。此时它 C_SEND = 0、C_ACCEPT = 0。当服务端接收到数据的时候，那么可以肯定的是服务端能正常接收信息，此时 S_ACCEPT = 1，而S_SEND = 0 第二次握手，服务端发送信息给客户端，同样服务端不知道自己能否正常发送信息，数据能否正确抵达客户端，所以它的 S_SEND = 0。而当客户端收到服务端的响应后，说明自己能正常接收信息，C_ACCEPT = 1，而服务端能返回响应给我，说明第一次的消息发送是正常的，那么也表示客户端发送信息的能力没问题，C_SEND = 1 第三次握手，服务端收到信息，说明第二次握手的时候发送的信息能正常到达客户端，说明服务端的发送信息的能力也没问题。S_SEND = 1 至此，就能确认客户端和服务端都能正常的发送和接收信息。 假设两次握手就 OK 了。如果客户端第一次握手过去，结果卡在了某个地方，没到服务端。超过一定时间，客户端再次重新发送了第一次握手过去，服务端收到了，服务端在发送一个响应正常到达客户端，OK 了，连接建立了。 然后尴尬的事情发生了，之前卡在某个地方的旧的第一次握手终于到达了服务端，然后服务端就直接返回了第二次握手，这个时候服务器开辟了资源准备接收客户端发送数据，但是客户端不会理睬这个第二次握手，因为之前都通信过了。这样就会浪费服务端的资源。 但是如果是三次握手，那个二次握手发回去，客户端发现不对，就会发送个复位的报文过去，让服务端撤销开辟的资源。 至于为什么不是 4 次握手，因为 3 次握手就够了，就不需要 4 次或者 5 次浪费资源了。 TCP 断开连接的 4 次挥手第一次挥手，客户端发送报文，FIN = 1、seq = u，此时进入 FIN-WAIT-1 状态 第二次挥手，服务端收到报文，此时进入 CLOSE_WAIT 状态，返回一个报文，ACK = 1、ack = u + 1、seq = v。客户端收到这个报文之后，直接进入 FIN-WAIT-2 状态，此时客户端到服务端的连接就释放了。 第三次挥手，服务端发送连接释放报文，FIN = 1、ack = u + 1、seq = w，服务端进入 LAST_ACK 状态。 第四次挥手，客户端收到连接释放报文之后，发应答报文，ACK = 1、ack = w + 1、seq = u + 1，进入 TIME_WAIT 状态，等待一会儿客户端进入 CLOSED 状态，服务端收到报文之后就进入 CLOSED 状态。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器请求一个网址时，都干了什么]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F11%2F%E6%B5%8F%E8%A7%88%E5%99%A8%E8%AF%B7%E6%B1%82%E4%B8%80%E4%B8%AA%E7%BD%91%E5%9D%80%E6%97%B6%EF%BC%8C%E9%83%BD%E5%B9%B2%E4%BA%86%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[首先我们假设，我们给电脑设置了几个东西： ip 地址：192.168.31.37 子网掩码：255.255.255.0 网关地址：192.468.32.1 DNS 地址：8.8.8.8 这时我们打开一个浏览器，请求 www.baidu.com 地址时，这个时候找 DNS 服务器，DNS 服务器解析域名之后，返回一个 ip 地址，比如 172.194.26.108 接着会判断两个 ip 地址是不是一个子网的，用子网掩码 255.255.255.0，对两个 ip 地址做与运算，拿到 192.168.31.1 和 172.194.26.0，明显不是一个子网的。如图： 那就得发送一个数据包给网关，其实你就认为是我们的路由器吧，就是 192.168.31.1，而且我们是可以拿到网关 ip 地址的 mac 地址的。现在我们从应用层出发，通过浏览器访问一个网站，是走应用层的 http 协议的，并且要把浏览器发出的请求打包成数据包。要把哪些东西放到数据包中去呢？ http 协议分为几个部分：请求方法 + URL 地址 + http 版本 比如： GET http://172.194.26.108/test HTTP/1.1 类似这种请求头，类似下面这种请求体 Host:upload,jiangsu.io Proxy-Connection:keep-alive User-Agent:Mozilla/5.0 等等。。。 比如常见的可以放一个 json，这就构成了一个 http 请求报文。浏览器请求一个地址，先按照应用层的 http 协议，封装一个应用层数据包，数据包里就存放了 http 请求报文，这个时候会将这个 http 请求报文打包成一个数据包，仅仅只是数据包的数据部分，此时数据包是没有头的。上面根据 http 协议弄一个 http 请求报文，然后弄一个数据包出来，就是网络模型中的应用层干的事情。 接着就跑传输层来了。这个层是 TCP 协议，这个 tcp 协议会让你设置一个端口，接收方的端口一般是默认的 80 端口。这个时候，会把应用层数据包给封装到 tcp 数据包中去，而且会加一个 tcp 头，这个 tcp 数据包是对应一个 tcp 头的，这个 tcp 头里就存放了端口号信息。如图： 接着跑到网络层来了，走 ip 协议。这个时候会把 tcp 头和 tcp 数据包，放到 ip 数据包里去，然后再搞一个 ip 头，ip 头里有本机和目标机器的 ip 地址。 这里本机地址是 192.168.31.37 目标机器地址是 172.194.26.108 因为，通过 ip 协议，可以判断说，两个 ip 地址不是在一个子网内的，所以此时只能将数据包先通过以太网协议广播到网关上去，通过网关再给它发送出去。如图： 接着是数据链路层，这块走以太网协议，这里是把 ip 头和 ip 数据包封到以太网数据包里去，然后再加一个以太网数据包里的头，头里放了本机网卡 mac 地址和网关的 mac 地址。但是以太网数据包的限制是 1500 个字节，而此时假设这个 ip 数据包都 5000 个字节了，那么久需要将 ip 数据包切割一下。 这个时候一个以太网数据包要切割为 4 个数据包，每个数据包包含了以太网头、ip 头和切割后的 ip 数据包。4 个数据包的大小分别是 1500, 1500, 1500, 500 个字节。ip 头里包含了每个数据包的序号。如图： 这 4 个以太网数据包都会通过交换机发送到你的网关上，然后你的路由器是可以联通别的子网的，这个时候你的路由器就会转发到别的子网的可能也是某个路由器里去，然后依次类推，N 多个路由器或者你叫网关也行，N 多个网关转发之后，就会跑到百度的某台服务器，接收到 4 个以太网的数据包。 百度服务器接收到 4 个以太网数据包以后，根据 ip 头的序号，把 4 个以太网数据包里的 ip 数据包给拼起来，就还原成一个完整的 ip 数据包了。接着就从 ip 数据包里面拿出来 tcp 数据包，再从 tcp 数据包里取出 http 数据包，读取出来 http 数据包里的各种协议内容，接着就是做一些处理，然后再把相应结果封装成 http 相应报文，封装在 http 数据包里，再一样的过程，封装 tcp 数据包，封装 ip 数据包，封装以太网数据包，接着通过网关给发回去。如图： 参考资料https://mp.weixin.qq.com/s/rqa_YoBkkavJ12GAXZHTYA]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP/IP 四层网络模型和 OSI 七层网络模型]]></title>
    <url>%2FCKING.github.io%2F2020%2F02%2F09%2FTCP-IP-%E5%9B%9B%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%92%8C-OSI-%E4%B8%83%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[其实，四层模型和七层模型，是可以一块儿讲的。首先先思考一个问题，为什么要有协议？ 如果各个电脑厂商，像 IBM，苹果和联想，都弄自己的协议，结果就是苹果电脑和苹果电脑可以通信，但和其它厂商的电脑就可能无法通信，因为各自的协议不一样。所以就弄了一个国际通行的协议，大家都按照这个来，所有电脑就可以通信了。 此时就要搞一个标准的网络模型出来，大家都按照这个来走，都遵守统一的规范。这就是所谓的 OSI 七层模型。它们分别是：物理层、数据链路层、网络层、传输层、会话层、表示层、应用层。在这个基础上，又简化出了 TCP/IP 四层模型：数据链路层、网络层、传输层、应用层。 从底向上的网络分层物理层如果电脑要联网，怎么联？可以在电脑上插根网线，或者联个 WIFI，就可以上网。往大了说就还有中国和美国之间的海底光缆。所以物理层指的就是这个，就是怎么把各个电脑联结起来，形成一个网络，这就是物理层的含义。物理层复制传输 0 和 1 的电路信号，因为计算机最底层都是用 0 1 来表示数据的。 数据链路层物理层将各个电脑连接起来了，还传输最底层的 0 和 1 电路信号。但这样还不行。你得定义清楚哪些 0 和 1 分为一组，这些信号啥意思，这样才能进行通信、所以数据链路层就是做这种事，定义一下电路信号怎么分组。例如： 00000011（从电脑 1 出发，要到电脑 2 去） 00101（从电脑 1 出发，要到电脑 3 去） 以前，每个公司都定义自己的电路信号分组方式，但是后来出来了以太网协议。以太网，一组电路信号就是一个数据包，叫一个帧（frame），每个帧分为两个部分，标头（head）和数据（data），标头包含一些说明性的东西，比如发送者、接受者和数据类型之类的。 每台电脑要往另一台电脑发送数据，一堆 0/1 信号，封装成数据包，包含头和数据，头里包含了从哪儿来到哪儿去，必须从一台电脑的一个网卡，发送到另外一个电脑的一个网卡，所以以太网的数据包必须指定目标电脑的 mac 地址。 以太网规定了，每个网卡必须包含一个 mac 地址，mac 地址就是这个网卡的唯一标识。接入网络里的所有设备，都得有个网卡。以太网协议里的那个数据包，在数据链路层传输的数据包，必须从一个电脑的网卡传输到另外一个电脑的网卡，而这个网卡的地址就叫 mac 地址。 每个网卡出厂的时候，就有一个唯一的 mac 地址，48 位的二进制，但是一般使用 12 个 16 进制数字表示，前 6 个 16 进制是厂商编号，后 6 个 16 进制是网卡的流水号。在 Windows 系统中，可以通过命令 ipconfig /all 查看物理地址，就是 mac 地址。 所以在以太网里传输数据包的时候，必须指定接受者的 mac 地址才能传输数据。但是以太网的数据包怎么从一个 mac 地址发送到另一个 mac 地址？这个不是精准推送的。以太网里面，如果一个电脑发个数据包出去，会广播给局域网内的所有电脑设备的网卡，然后每台电脑都从数据包里获取接收者的 mac 地址，跟自己的 mac 地址对比一下，如果一样，就说明这是给自己的数据包。 但是上面这种广播的方式。仅仅针对一个子网（局域网）内的电脑才会广播，否则一个电脑不能广播数据包给全世界所有的其他电脑吧，仅仅只是广播给一个子网里面的电脑。 网络层上面说到，子网内的电脑，通过以太网发个数据包，对局域网内的电脑，是广播出去的。那么怎么知道哪些电脑在一个子网内呢？这就得靠网络层了，这里有一套 IP 地址，IP 地址就可以让我们区分哪些电脑是一个子网的。 网络层里有个 IP 协议，IP协议定义的地址就叫做 IP 地址。IP地址有 IPv4 和 IPv6 两个版本，目前广泛使用的是 IPv4，是 32 个二进制数字组成的，但是一般用 4 个十进制数字表示，范围从 0.0.0.0 到 255.255.255.255 之间。 每台计算机，都会分配一个 ip 地址，ip 地址的前 24 位（就是前面 3 个十进制数字），代表了网络，后 8 位（最后 1 个十进制数字），代表了主机。如果几台电脑是一个子网的，那么前面的 3 个十进制数字一定是一样的。举个例子，像平时我们在自己 Windows 上开几个 Linux 虚拟机，你会发现，Win 上的 ip 地址可能是 192.168.0.103，然后几个虚拟机的 ip 地址是 192.168.0.182，192.168.0.125 类似这样的。 这个 Win 机器和几个虚拟机，前面 3 个十进制数字都是 192.168.0，就代表大家是一个子网内的，最后一个数字是这个子网的不同主机的编号。但是实际上这就是举个例子，单单从 ip 地址是看不出哪些机器是一个子网的，因为从 10 进制是判断不出来的，需要通过 ip 地址的二进制来判断，结合一个概念来判断，叫做：子网掩码。 比如说 ip 地址是 192.168.56.1，子网掩码是 255.255.255.0。知道子网掩码之后，如果要判断两个 ip 地址是不是一个子网的，就分别把两个 ip 地址和自己的子网掩码进行二进制的与运算，与运算之后，比较一下代表网络的那部分。 例如 192.168.53.1 和 192.168.32.7，判断是不是一个子网的，拿子网掩码 255.255.255.0，跟两个 ip 地址的二进制做与运算，通过二进制来比较网络部分的地址是不是一模一样的。 11000000.10101000.00111000.00000001 11111111.11111111.11111111.00000000 有了网络层的 ip 地址之后，两台在子网内的电脑终于可以通过广播 + mac 地址判断来传输数据包进行通信 了。但是如果发现要接收数据包的计算机不在子网内，那么就不能通过广播来发送数据包，需要通过路由来发送数据包。 看到路由，就想到了路由器。说到路由器，相信大家会比较熟悉，基本家里上网都会弄个路由器。路由器负责将多个子网进行连接，因为你在自己家里，其实你就只是你自己的一个子网，你要是访问网站啥的，是跟那个网站机器所在的子网进行通信。 每个电脑都可以有多个网卡，不是只有一个网卡。一般笔记本都会有以太网网卡和 WiFi 网卡，发送数据包的时候决定走哪个网卡。路由器，其实就是配置了多个网卡的一个专用设备，可以通过不同的网卡接入不同的网络。 网关其实就是路由器的一种，运作在网络层，这个概念不多解释，大家看可以把路由器上的 ip 地址认为是网关。路由器上每个网卡都有 mac 地址和对应的 ip 地址，路由器虽然有 mac 地址，但是不能通过 mac 地址寻址，必须通过 ip 地址寻址，所以路由器其实是工作在网络层的设置。 网络交换机，也是一种设备，是工作在数据链路层的，路由器是工作在网络层的。网络交换机是通过 mac 地址来寻址和传输数据包的；但是路由器是通过 ip 地址寻址和传输数据包的。网络交换机用在局域网的通信，一般你架设一个局域网，里面的电脑通信是通过数据链路层发送数据包，通过 mac 地址来广播的，广播的时候就是通过网络交换机这个设备来把数据广播到局域网内的其他机器上去的。而路由器一般用来让你连入英特网。 LAN，就是 local area network，就是局域网；WAN，就是 wide area network，就是广域网。WLAN 是 wireless local area network，就是无限局域网，也就是 WiFi，在局域网内，可以直接通过 WiFi 无线联网。家里的路由器就是包含了交换机和路由的两个功能，如果是连接到局域网内的设备就把线插到 LAN 那儿，如果是连接到因特网，就把线插在 WAN 上。 举个例子，就是两个局域网之间，如果是通过一个路由器进行通信的话，要怎么进行。大概过程就是，路由器配置了两块网卡，每个网卡可以连到一个局域网内。局域网 1 内的电脑，要发送数据包到局域网 2 内的电脑，在数据包上写上自己的 ip 地址和对方的 ip 地址。但是它们不在一个局域网内，于是局域网 1 内的电脑，先通过交换机将数据包发送到路由器，这个过程需要将路由器的一块网卡的 ip 地址对应的 mac 地址写到数据包的头部，然后才能通过交换机广播出去，路由器接收到之后比较自己一块网卡的 mac 地址，就知道是来找自己的。 接着路由器收到数据包之后，就会在局域网 2 内，将目标机器的 ip 地址对应的 mac 地址写入头部，接着再次通过交换机发送广播通知，发送给局域网 2 的电脑。 一个局域网内的每台机器都有自己的 ARP cache，这个 ARP 就是用来在一个局域网内让各个设备都知道每个设备的 ip 地址和 mac 地址的对应关系的，一般就是某个机器发送广播通知自己的 ip 地址和 mac 地址的对应关系，然后每个机器给他一个回应。以此类推，大家都互相这样广播一把，ip 地址和 mac 地址的对应关系，大家就都知道了。 总结来说就是，一个子网内的机器之间通信，就是在数据包里写上对方的 mac 地址，然后交换机广播出去就 OK 了；但是如果是跨子网的通信，就是写上对方的 ip 地址，然后先通过 mac 地址广播到路由器，让路由器再根据另外一个子网的 ip 地址转换为 mac 地址，通过另外一个子网的交换机广播过去。 传输层上面我们大概明白了通过网络层的 ip地址怎么划分出一个一个的子网，然后在子网内部怎么通过 mac 地址广播通信；跨子网的时候，怎么通过 ip 地址 -&gt; mac 地址 -&gt; 交换机 -&gt; 路由器 -&gt; ip 地址 -&gt; mac 地址 -&gt; 交换机的形式来通过路由器进行通信。 但是还有一个问题，就是一台机器上，是很多程序用一个网卡进行网络通信的，比如说浏览器、QQ、视频直播等等，这些软件都用了一个网卡往外面发送数据，然后从网卡接收数据。 所以还需要一个端口号的概念，就是你得发送数据包到某个机器的一个网卡的某个端口号上去，然后那个机器上监听那个端口的程序，就可以提取发送到这个端口的数据，知道是自己的数据。端口号是 0 ~ 65536 的范围内，其中 0 ~ 1023 被系统占用，别的应用程序就用 1024 以上的端口号。 电脑 1，是在端口号 48632 监听的，通过网卡发送了一条数据 -&gt; 电脑 2 的 ip 地址的 20386 这个端口 -&gt; 电脑 2 的上面的某个 QQ，监听着 20386 的端口 -&gt; 电脑 2 的网卡接收到一条数据之后，发现人家找的是 20386 这个端口，就去找谁在监听 203836，发现 QQ 在监听，我就把这个网卡过来的数据，传递给 QQ，通过端口知道，哪条数据是给你的。 所以大家会发现，网络层，是基于 ip 协议，进行主机和主机间的寻址和通信的，然后传输层，是建立某个主机的某个端口，到另外一个主机的某个端口的连接和通信的。这个通信，就是通过 socket 来实现的，通过 socket 就可以基于 tcp/ip 协议完成上面说的一系列的比如基于 ip 寻址 和 mac 地址转换和寻址，通过路由通信之类的，而且会建立一个端口到另外一个端口的连接。 UDP 和 TCP 都是传输层的协议，作用就是在数据包里加入端口号，可以通过端口号进行点对点的通信了。UDP 是不可靠的，发出去人家收到没有就不知道了；TCP 协议是可靠的，要求三次握手，而且要求人家接收到数据必须回复你。 传输层的 TCP 协议，仅仅只是规定了一套基于端口的点对点的通信协议，包括如何建立连接，如果发送和读取消息，但是实际上如果你要基于 TCP 协议来开发，一般使用 socket，java socket，netty开进行网络编程。 应用层通过传输层的 TCP 协议可以传输数据，但是人家收到数据之后，怎么来解释？比如收到个邮件你要怎么处理，收到个网页呢。所以针对不同的应用，邮件、网页之类的，都是定义不同的应用层协议的。这个应用层，我们就假设综合了会话层、表示层和应用层了。比如最常见的，应用层的协议就是 HTTP 协议。 电脑 1 走 TCP 协议发送了一段东西过来，发送到电脑 2 的 20386 端口： 1234GET http://localhost:8080/ http/1.1key:value1key:value 电脑 2 走 TCP 协议读取到了属于自己这个 20386 端口的一段数据，并发送了一段相应 1234200key:valuekey:value 又是通过底层的 TCP 发了出去，电脑 1 的 30987 端口，ip 电脑 1，网卡，走以太网协议收到一个数据包 1234200key:valuekey:value 总结我们看一下自己的网络设置，一般包含了 ip 地址、子网掩码、网关地址、DNS 地址。前面 3 个我们都知道什么意思了。ip 地址和子网掩码用来划分子网的，判断哪些 ip 地址在一个子网内，同时你的 ip 地址和 mac 地址关联起来，唯一定位了你的网关。网关地址，你就认为是路由器上的那个网卡的 ip 地址吧。路由器的网卡也有 mac 地址，mac 地址对应一个 ip 地址。 DNS地址是啥呢？Domain Name System。因为我们一般定位是通过ip地址+mac地址+端口号来定位一个通信目标的，但是如果在浏览器上输入一个www.baidu.com，咋整？这个时候是先把www.baidu.com发给DNS服务器，然后DNS服务器告诉你www.baidu.com对应的ip地址的 参考资料 网络模型]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 之 jstat 案例分析 - Full GC]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F31%2FJVM-%E4%B9%8B-jstat-%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-Full-GC%2F</url>
    <content type="text"><![CDATA[案例分析日处理上亿数据的计算系统假设有这么一个数据计算系统，日处理数据量在上亿的规模。简单来说，这个系统就是会不停地从 MySQL 数据库以及其他数据源里大量地加载数据到自己的 JVM 内存里来进行计算，一般情况下的生产负载是每分钟大概需要执行 500 次数据提取和计算的任务。 但这是一套分布式运行的系统，所以生产环境部署了多台机器，每台机器大概每分钟负责执行 100 次数据提取和计算的任务，每次会提取大概 1 万条左右的数据到内存里来计算，平均每次计算大概需要耗费 10 秒左右的时间。然后每台机器是 4 核 8G 的配置，JVM 内存给了 4G，其中新生代和老年代分别是 1.5G 的内存空间。如图： 这个系统何时塞满新生代既然这个系统每台机器上部署的实例，每分钟会执行 100 次数据计算任务，每次是 1 万条数据计算需要计算 10 秒的时间，那么每次 1 万条数据大概会占用多大的内存空间呢？ 假设平均每条数据在 1KB 左右的大小，那么每次计算任务的 1 万条数据就对应了 10MB 的大小。如果新生代是按照 8 : 1 : 1 的比例来分配 Eden 和两块 Survivor 的区域，那么大体上来说，Eden 区就是 1.2GB，每块 Survivor 区域在 100MB 左右。如图： 按照上面的内存大小，基本执行一个计算任务，就会在 Eden 区里分配 10MB 左右的对象，一分钟大概对应 100 次计算，基本上一分钟过后，Eden 区里就全是对象，基本就全满了。 触发 Minor GC 的时候会有多少对象进入老年代此时假设新声代的 Eden 区在 1 分钟后都塞满对象了，然后接着继续执行计算任务的时候，势必会导致需要进行 Minor GC 回收一部分的垃圾对象。 之前说过执行 Minor GC 之前会先进行检查。那么首先第一步，先看看老年代的可用内存空间是否大于新生代。此时老年代是空的，大概有 1.5G 的可用内存空间，新生代的 Eden 区大概算他有 1.2G 的对象好了，此时会发现老年代的可用内存空间有 1.5GB，新生代的对象总共有 1.2GB，即使一次 Minor GC 过后，全部对象都存活，老年代也能放得下，那么此时就直接执行 Minor GC 了。 之前说过每个计算任务 1 万条数据需要计算 10 秒钟，所以假设此时的 80 个计算任务都执行结束了，但是还有 20 个计算任务共计 200MB 的数据还在计算中，那么此时就是 200MB 的对象是存活的，不能被垃圾回收掉，然后有 1GB 的对象是可以垃圾回收的。 但是因为剩余的存活对象 200MB 大于 Survivor 区的 100MB 的空间。此时就会通过空间担保机制，让这 200MB 直接进入老年代去，占用里面 200MB 内存空间，然后 Eden就清空了。 系统运行多久，老年代大概会填满按照上述计算，每分钟都是一个轮回，大概算下来是每分钟都会把新生代的 Eden 区填满，然后触发一次 Minor GC，然后大概会有 200MB 左右的数据进入老年代。假设现在 2 分钟运行过去了，此时老年代已经有 400MB 内存被占用，只有 1.1GB 的内存可用，此时如果第 3 分钟运行完毕，又要进行 Minor GC 会做什么检查呢？ 此时会先检查老年代可用空间是否大于新生代全部对象，此时老年代可用空间 1.1GB，新生代对象有 1.2GB，那么此时假设一次 Minor GC 过后新生代对象全部存活，老年代是放不下的，那么此时就得看另一个参数是否打开了。 如果 -XX:-HandlePromotionFailure 参数被打开了，此时会进入第二步检查，就是看看老年代可用空间是否大于历次 Minor GC 过后进入老年代的对象的平均大小。我们己经计算过了，每次大概 200MB 对象进入老年代。 那么此时老年代是 1.1GB 空间，是大于每次 Minor GC 后平均 200MB 对象进入老年代的大小的，所以基本可以推测，本次 Minor GC 后大概率还是有 200MB 对象进入老年代，1.1G 可用空间是足够的。所以此时就会放心执行一次 Minor GC，然后又是 200MB 对象进入老年代。 转折点大概在运行了 7 分钟后，7 次 Minor GC 执行过后，大概 1.4G 对象进入老年代，老年代空间就不到 100MB了，几乎快满了。 这个系统运行多久会触发一次 Full GC大概在第 8 分钟运行结束的时候，新生代又满了，执行 Minor GC 之前进行检查，此时发现老年代只有 100MB 内存空间了，比之前每次 Minor GC 后进入老年代的 200MB 要小，此时就会触发一次 Full GC。Full GC 会把老年代的垃圾对象都回收了，假设此时老年代被占据的 1.4G 空间里，全部都是可以回收的对象，那么此时一次性就会把这些对象都给回收了。 然后接着就会执行 Minor GC，此时 Eden 区情况，200MB 对象再次进入老年代，之前的 Full GC 就是为这些新生代本次 Minor GC 要进入老年代的对象准备的。如图： 按照这个运行模型，基本上平均就是七八分钟一次 Full GC，这个频率就相当高了，因为每次 Full GC 速度都是很慢的，性能很差。 该案例如何进行 JVM 优化这个系统，其实要优化也是很简单的，因为这个系统是数据计算系统，每次 Minor GC 的时候，必然会有一批数据没计算完毕，但是按照现有的内存模型，最大的问题，就是每次 Survivor 区域放不下存活对象。 所以可以这么优化，增加新生代的内存比例，3GB 左右的堆内存，其中 2GB 分配给新生代，1GB 留给老年代。这样 Survivor 区大概就是 200MB，每次刚好能放得下 Minor GC 过后存活的对象。 只要每次 Minor GC 过后 200MB 存活对象可以放 Survivor 区域，那么等下一次 Minor GC 的时候，这个 Survivor 区的对象对应的计算任务早就结束了，都是可以回收的了。例如此时 Eden 区里的 1.6GB 空间被占满了，然后 Survivor1 区里有 200MB 上一轮 Minor GC 后存活的对象吗，如图： 此时执行 Minor GC，就会把 Eden 区里 1.4GB 对象回收掉，Survivor1 区里的 200MB 对象也会回收掉，然后 Eden 区里剩余的 200MB 存活对象会放入 Survivor2 区里，如图： 以此类推，基本上就很少对象会进入老年代中，老年代里的对象也不会太多。通过分析和优化，我们成功把系统的老年代 Full GC 的频率从几分钟一次降低到了几个小时一次，大幅度提升了系统的性能，避免了频繁 Full GC 对系统运行的影响。 代码示例运行程序用的示例 JVM 参数使用下面的 JVM 参数运行程序： 1-XX:NewSize=104857600 -XX:MaxNewSize=104857600 -XX:InitialHeapSize=209715200 -XX:MaxHeapSize=209715200 -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=20971520 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimesStamps -Xloggc:gc.log 上面的参数需要注意的是 -XX:PretenureSizeThreshold，把大对象阈值修改为了 20MB，避免我们程序里分配的大对象直接进入老年代。 示例程序12345678910111213141516171819202122232425public class Demo1 &#123; public static void main(String[] args) throws Exception &#123; Thread.sleep(30000); while(true) &#123; loadData(); &#125; &#125; private static void loadData() throws Exception &#123; byte[] data = null; for(int i = 0; i &lt; 4; i++) &#123; data = new byte[10 * 1024 * 1024]; &#125; data = null; byte[] data1 = new byte[10 * 1204 * 1024]; byte[] data2 = new byte[10 * 1024 * 1024]; byte[] data3 = new byte[10 * 1024 * 1024]; data3 = new byte[10 * 1024 * 1024]; Thread.sleep(1000); &#125;&#125; j简单解释上面的程序，大概意思就是，每秒钟都会执行一次 loadData() 方法，它会分配 4 个 10MB 的数组，但是都立马成了垃圾。但是会有 data1 和 data2 两个 10MB 的数组时被变量引用必须存活的，此时 Eden 区已经占用了六七十 MB 空间了，接着是 data3 变量依次指向了两个 10MB 的数组，这是为了在 1s 内触发 Young GC 的。 基于 jstat 分析程序运行的状态接着我们基于 jstat 分析程序运行的状态，启动程序后立马采用 jstat 监控其运行状态可以看到如下的信息： 我们一点一点来分析这个 JVM 的运行状态。首先先看如下这一行截图： 在这里的最后一行，可以看到，程序运行起来之后，在一秒内就发生一次 Young GC，因为按照我们上述的代码，它一定会在一秒内触发一次 Young GC 的。 Young GC 过后，我们发现 S1U，也就是一个 Survivor 区中有 587KB 的存活对象，这应该就是那些未知对象了。然后我们明显看到在 OU 中多出来了 30MB 左右的对象，因此可以确定，在这次 Young GC 的时候，有 30MB 的对象存活了，此时因为 Survivor 区域放不下，所以直接进入老年代了。 接着看下面的图： 看红圈的部分，很明显每秒会发生一次 Young GC，都是导致 20MB ~ 30MB 左右的对象进入老年代。因为每次 Young GC 都会存活下来这么多对象，但是 Survivor 区域是放不下的，所以会直接进入老年代。此时看到老年代的对象占用从 30KB 一路到 60MB 左右，此时突然在 60MB 之后下一秒，明显发生了一次 Full GC，对老年代进行了垃圾回收，因为此时老年代重新变成了 30MB 了。 为什么会这样？因为老年代总共就 100MB 左右，已经占用了 60MB 了，此时如果发生一次 Young GC，有 30MB 存活对象要进入老年代的话。此时会进行 Full GC，回收掉之前那 60MB，然后再放进去新的 30MB 对象。 所以按照我们的这段代码，几乎是每秒新增 80MB 左右，触发每秒 1 次 Young GC，每次 Young GC 后存活下来 20MB ~ 30MB 的对象，老年代每秒新增 20MB ~ 30MB 的对象，触发老年代几乎三秒一次 Full GC，是不是跟我们上面的案例分析的场景很类似？Young GC 太频繁了，而且每次 GC 后存活对象太多，频繁进入老年代，频繁触发 Full GC。 继续看下图： 大家看上图，发现 28 次 Young GC，结果耗费了 180 毫秒，平均下来一次 Young GC 要 6 毫秒左右。但是 14 次 Full GC 才耗费 34 毫秒，平均下来一次 Full GC 才耗费两三毫秒。这是为什么？道理是这样，按照上述程序，每次 Full GC 都是由 Young GC 触发的，因为 Young GC 过后存活对象太多要放入老年代，老年代内存不够触发 Full GC，所以必须等 Full GC 执行完毕了，Young GC 才能把存活对象放入老年代才算结束。这就导致 Young GC 也是速度非常慢。 对 JVM 性能进行优化我们只需要调大年轻代的内存空间，增加 Survivor 的内存即可。看如下参数： 1-XX:NewSize=209715200 -XX:MaxNewSize=209715200 -XX:InitialHeapSize=314572800 -XX:MaxHeapSize=314572800 -XX:SurvivorRatio=2 -XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=20971520 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log 我们把堆大小调整为 300MB，年轻代给了 200MB，同时 -XX:SurvivorRatio=2 表明，Eden : Survivor 的比例为 2 : 1 : 1，所以 Eden 区是 100MB，每个 Survivor 区是 50MB，老年代是 100MB。 接着我们用这个 JVM 参数运行程序，用 jstat 来监控其运行状态如下： 在上图可以看到，每秒的 Young GC 过后，都会有 20MB 左右的存活对象进入 Survivor，但是每个 Survivor 区都是 50MB 的大小，因此可以轻松容纳，而且一般不会超过 50% 的动态年龄判定的阈值。 我们可以清楚地看到每秒触发 Young GC 过后，几乎就没有对象会进入老年代，最终 600KB 的对象进入了老年代里。在看下面的截图： 我们可以看到，只有 Young GC，没有 Full GC，而且 11 次 Young GC 才不过 9 毫秒，平均一次 GC 1 毫秒都不到，没有 Full GC 干扰之后，Young GC 的性能极高。 所以这个案例的优化就成功了，同样的程序，仅仅是调整了内存分配比例，立马就大幅度提升了 JVM 的性能，几乎把 Full GC 消灭了。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 杂记]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F27%2FSpring-%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Bean 的生命周期Spring Bean 的生命周期，大致上可以分为创建、使用、销毁三个阶段。具体由可以分为以下几个阶段： 实例化 Bean对于 BeanFactory 容器，当客户向容器请求一个尚未初始化的 bean 时，或初始化 bean 的时候需要注入另一个尚未初始化的依赖时，容器就会调用 createBean 进行实例化。对于 ApplicationContext 容器，当容器启动结束后，通过获取 BeanDefinition 对象中的信息，实例化所有的 bean。 容器在内部实现的时候，采用“策略模式”来决定采用何种方式初始化 bean 实例。通过，可以通过反射或者 CGLIB 动态字节码生成来初始化相应的 bean 实例或者动态生成其子类。 设置对象属性（依赖注入）实例化后的对象被封装在 BeanWrapper 对象中，紧接着，Spring 根据 BeanDefinition 中的信息以及通过 BeanWrapper 提供的设置属性的接口完成依赖注入。 说人话就是 spring 容器需要去看看这个 bean 依赖了谁，把你依赖的 bean 也创建出来，给你进行一个注入。比如说通过构造函数，setter 注入等等。如下代码： 123456789101112public class MyService &#123; private MyDao myDao; public MyService(MyDao myDao) &#123; this.myDao = myDao; &#125; public void setMyDao(MyDao myDao) &#123; this.myDao = myDao; &#125;&#125; 处理 Aware 接口接着，Spring 会检测该对象是否实现了 xxxAware 接口，并将相关的 xxxAware 实例注入给 Bean： 如果这个 Bean 已经实现了 BeanNameAware 接口，Spring 容器会调用这个 bean 实现的 setBeanName(String beanId) 方法，此处传递的就是 Spring 配置文件中 Bean 的 id 值。 如果这个 Bean 已经实现了 BeanFactoryAware 接口，Spring 容器会调用这个bean 实现的 setBeanFactory() 方法，传递的是 Spring 工厂自身。 如果这个 Bean 已经实现了 ApplicationContextAware 接口，Spring 容器会调用我们 bean 的 setApplicationContext(ApplicationContext ctx) 方法，传入 Spring 上下文，把 Spring 容器传递给这个 bean。 BeanPostProcessor如果我们想在 bean 实例构建好之后，此时想在这个时间点，如果想对这个 Bean 进行一些自定义的处理，那么可以让 Bean 实现 BeanPostProcessor 接口，那将会调用 postProcessBeforeInitialization(Object obj, String s)方法。 InitializingBean 与 init-method如果 Bean 在 Spring 配置文件中配置了 init-method 属性，则会自动调用其配置的初始化方法。 BeanPostProcessor如果这个 Bean 实现了 BeanPostProcessor 接口，将会调用 postProcessAfterInitialization(Object obj, String s)方法。这个方法是在 Bean 初始化结束时调用，所以可以被应用于内存或缓存技术。 以上几个步骤完成后，Bean 就已经被正确创建了，之后就可以使用这个 Bean 了。 DisposableBean当 Bean 不再需要时，会经过清理阶段，如果 Bean 实现了 DisposableBean 接口，会调用其实现的 destroy() 方法。 destroy-method最后，如果这个 Bean 的 Spring 配置中配置了 destroy-method 属性，会自动调用其配置的销毁方法。 Spring Web MVC 执行流程 客户端（浏览器）发送请求，直接请求到 DispatcherServlet。（请求 DispatcherServlet） DispatcherServlet 根据请求信息调用 HandlerMapping，解析请求对应的 Handler。（查找 @Controller） 解析到对应的 Handler 后，开始由 HandlerAdapter 适配器处理。（查找 @RequestMapping） HandlerAdapter 会根据 Handler 来调用真正的处理器开始处理请求，并处理相应的业务逻辑。（处理方法） 处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View。（返回处理结果） ViewResolver 会根据逻辑 View 查找实际的 View。（逻辑视图解析为真正的视图） DispatcherServlet 把返回的 Model 传给 View。（DispatcherServlet 视图渲染） 通过View 返回给请求者（浏览器） 将上面的内容应用到实际项目中，大概流程就是这样： Tomcat 的工作线程将请求转交给 Spring MVC 框架的 dispatcherServlet DispatcherServlet 查找 @Controller 注解的 controller。我们一般会给 controller 加上 @RequestMapping 的注解，标注说哪些 controller 用来处理哪些请求，此时根据请求的 URI，去定位到哪个 controller 来进行处理。 根据 @RequestMapping 去查找，使用这个 controller 内的哪个方法来进行请求的处理，对每个方法一般也会加 @RequestMapping 的注解。 直接调用我们 controller 里面的某个方法来进行请求的处理 我们的 controller 的方法会有一个返回值，以前的时候，一般来说还是走 jsp、模板技术，我们会把前端页面放在后端的工程里面，返回一个页面模板的名字，然后 spring MVC 的框架使用模板技术，对 HTML 页面做一个渲染。到了前后端分离，可能前端发送一个请求过来，我们只要返回json数据。 前端负责把 HTML 页面渲染给浏览器就可以了。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初步了解 InnoDB 存储引擎的架构设计]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F26%2F%E5%88%9D%E6%AD%A5%E4%BA%86%E8%A7%A3-InnoDB-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[我们知道，MySQL 最常用的就是 InnoDB 存储引擎，那么我们今天借助一条更新语句的执行，来初步地了解一下 InnoDB 存储引擎的架构设计。 首先假设我们一条 SQL 语句： 1UPDATE users SET name = &apos;xxx&apos; WHERE id = 10 首先我们的系统通过一个数据库连接发送到 MySQL 上，然后经过 SQL 接口、解析器、优化器、执行器几个环节，解析 SQL 语句，生成执行计划，接着由执行器去负责这个计划的执行，调用 InnoDB 存储引擎的接口去执行。所以如下图，大致会走下图的这个流程： 接下来我们看一下这个存储引擎里的架构设计，以及如何基于存储引擎完成一条更新语句的执行。 InnoDB 的重要内存结构：缓冲池InnoDB 存储引擎中有一个非常重要的放在内存里的组件，就是缓冲池（Buffer Pool），这里面会缓冲很多的数据，以便于以后在查询的时候，如果内存缓冲池里有数据，就可以不用去查磁盘了。 引擎执行更新语句的时候，比如对 “id = 10” 这一行数据，它其实会将 “id = 10” 这一行数据看看是否在缓冲池里，如果不在的话，那么会直接从磁盘里加载到缓冲池里来，而且接着会对这行记录加独占锁。因为在我们更新 “id = 10” 的这一行数据的时候，肯定是不允许别人同时更新的，所以必须要对这行记录加独占锁。 undo 日志文件：让你更新的数据可以回滚接着，假设 “id = 10” 这行数据的 name 原来是 “zhangsan”，现在我们要更新为 “xxx”，那么此时我们得先把要更新的原来的值 “zhangsan” 和 “id = 10” 这些信息，写入到 undo 日志文件中去。 如果之前有接触过数据库的话，我们应该知道，如果我们要执行一个更新语句，要是他是在一个事务里的话，那么事务提交之前我们都是可以对数据进行回滚的，也就是把你更新为 “xxx” 的值回滚到之前的 “zhangsan” 去。所以为了考虑到未来可能要回滚数据的需要，这里会把你更新前的值写入 undo 日志文件，如图： 更新 buffer pool 中的缓存数据当我们把要更新的那行记录从磁盘文件加载到缓冲池，同时对它加锁之后，而且还要把更新前的旧值写入 undo 日志文件之后，就可以正式更新这行数据了。更新的时候，先更新缓冲池中的记录，此时这个数据就是脏数据了。这里所谓的更新内存缓冲池里的数据，意思就是把内存里的 “id = 10” 这行数据的 name 字段修改为 “xxx”。 那为什么说此时这行数据是脏数据呢？因为这个时候磁盘上 “id = 10” 这行数据的 name 字段还是 “zhangsan” ，但是内存里这行数据已经被修改了，所以就会叫它是脏数据。如图： Redo Log Buffer：万一系统宕机，如何避免数据丢失接下来，按照上图的说明，现在已经把内存里的数据进行修改，但是磁盘上的数据还没修改。那么此时万一 MySQL 所在的机器宕机了，必然会导致内存里修改过的数据丢失，这怎么解决？这个时候，就必须把对内存所做的修改写入到一个 Redo Log Buffer 里去，这也是内存里的一个缓冲区，是用来存放 redo 日志的。 所谓的 redo 日志，就是记录下来你对数据做了什么修改，比如对 “id = 10” 这行数据修改了 name 字段的值为 “xxx”，这就是一个日志。 这个 redo 日志是用来在 MySQL 突然宕机的时候，用来恢复你更新过的数据的。 如果还没提交事务，MySQL 宕机了怎么办一般情况下，在数据库中，哪怕执行一条 SQL 语句，其实也可以是一个独立的事务，只有当你提交事务之后，SQL 语句才算执行结束。所以到目前为止，其实还没有提交事务，那么此时如果 MySQL 崩溃，必然导致内存里 Buffer Pool 中的修改过的数据丢失，同时你写入 Redo Log Buffer 中的 redo 日志也会丢失。 那么此时数据丢失要紧吗？其实不要紧，因为你一条更新语句，没提交事务，就代表它没执行成功，此时 MySQL 宕机虽然导致内存里的数据都丢失了，但是磁盘上的数据依然还停留在原样子。也就是说，”id = 1” 的那行数据的 name 字段的值还是老的值 “zhangsan”，所以此时你的这个事务就是执行失败了，没能成功完成更新，你会收到一个数据库的异常。然后当 mysql 重启之后，你会发现你的数据没有任何变化。 所以此时如果 MySQL 宕机，不会有任何问题。 提交事务的时候将 redo 日志写入磁盘中接着我们要提交一个事务了，此时就会根据一定的策略把 redo 日志从 redo log buffer 里刷入到磁盘文件里去。此时这个策略是通过 innodb_flush_log_at_trx_commit 来配置的，它又几个选项： 当这个参数的值为0时，你提交事务的时候，不会把 redo log buffer 里的数据刷入磁盘文件，此时可能你都提交事务了，结果 MySQL 宕机了，然后此时内存里的数据全部丢失。相当于你提交事务成功了，但是由于 MySQL 突然宕机了，导致内存中的数据和 redo 日志都丢失了。 当这个参数的值为1时，你提交事务的时候，就必须把 redo log 从内存刷入到磁盘文件里去，只要事务提交成功，那么 redo log 就必然在磁盘里了。 那么只要提交事务成功之后，redo 日志一定在磁盘文件里，此时你肯定会有一条 redo 日志说“我此时对哪个数据做了哪些修改，比如 name 字段 修改为了 xxx 了”。 然后哪怕此时 buffer pool 中更新过的数据还没刷新到磁盘里去，此时内存里的数据是已经更新过的 “name = xxx”，然后磁盘上的数据是还没更新的 “name = zhangsan”。然后此时 MySQL 系统突然崩溃了，此时会丢失数据吗？答案是不会，因为虽然内存里的修改成 name = xxx 的数据会丢失，但是 redo 日志里已经说了，对某某数据做了修改 name=xxx，所以此时 MySQL 重启之后，它可以根据 redo 日志去恢复之前做过的修改。 最后来看看，如果 innodb_flush_log_at_trx_commit 的值是 2，那么提交事务的时候，把redo 日志写入磁盘文件对应的 os cache 缓存里去，而不是直接进入磁盘文件，可能 1 秒后才会把 os cache 里的数据写入到磁盘文件里去。 这种模式下，你提交事务之后，redo log 可能仅仅停留在 os cache 内存缓存里，没实际进入磁盘文件，万一此时你要是机器宕机了，那么 os cache 里的 redo log 就会丢失，同样会让你感觉提交事务了，结果数据丢失了。 扩展：binlog首先，我们要知道 MySQL binlog 是个什么东西？实际上我们之前说的 redo log，它是一种偏向物理性质的重做日志，因为它里面记录的是类似这样的东西：“对哪个数据页中的什么记录，做了个什么修改”。而且 redo log 本身是属于 InnoDB 存储引擎特有的一个东西。而 binlog 叫做归档日志，它里面记录的是偏向于逻辑性的日志，类似于 “对 users 表中的 id= 10 的一行数据做了更新操作，更新以后的值是什么”。 binlog 不是 InnoDB 存储引擎特有的日志文件，是属于 MySQL Server 自己的日志文件。 提交日志的时候，同时写入 binlog在上面我们说到，在我们提交事务的时候，会把 redo log 日志写入磁盘文件中去。然后其实在提交事务的时候，我们同时还会把更新对应的 binlog 日志写入到磁盘文件中去。如图所示： 上图会有一些变化，就是把跟 InnoDB 存储引擎进行交互的组件加了之前说过的执行器。它会负责跟 InnoDB 进行交互，包括从磁盘里加载数据到 Buffer Pool 中进行缓存，包括写入 undo 日志，包括更新 Buffer Pool 里的数据，以及写入 redo log buffer，redo log 刷入磁盘，写binlog 等等。 实际上，执行器是一个非常核心的组件，负责跟存储引擎配合完成一个 SQL 语句在磁盘与内存层面的全部数据更新操作。而且我们在上图可以看到，我把一次更新语句的执行，拆分为了两个阶段，上图中的 1、2、3、4 几个步骤，本质上你执行这个更新语句的时候干的事。而 5、6 阶段，是从你提交事务开始的，属于提交事务的阶段了。 binlog 日志的刷盘策略分析对于 binlog 日志，也有不同的刷盘策略。有一个 sync_binlog 参数可以控制 binlog 的刷盘策略，它的默认值是 0，此时你把 binlog 写入磁盘的时候，其实不是直接写入磁盘文件，而是进入 os cache 内存缓存。所以跟之前分析的一样，如果此时机器宕机，那么你在 os cache 里的 binlog 日志是会丢失的。 如果把 sync_binlog 参数设置为 1 的话，那么此时会强制在提交事务的时候，把 binlog 直接写入到磁盘文件里去，那么这样提交事务之后，哪怕机器宕机了，磁盘上的 binlog 是不会丢失的。 基于 binlog 和 redo log 完成事务的提交当我们把 binlog 写入磁盘文件之后，接着就会完成最终的事务提交，此时会把本次更新对应的 binlog 文件名称和这次更新的 binlog 日志在文件里的位置，都写入到 redo log 日志文件里去，同时在 redo log 日志文件里写入一个 commit 标记。 在完成这个事情之后，才算最终完成率事务的提交，如图所示： redo 日志中写入 commit 标记的意义为什么最后要在 redo 日志中写入 commit 标记？它其实是用来保持 redo log 日志与 binlog 日志一致的。 举个例子，假设我们在提交事务的时候，一共有上图中的 5、6、7 三个步骤，必须是三个步骤都执行完毕，才算是提交了事务。如果我们刚完成步骤 5 的时候，也就是 redo log 刷入磁盘文件的时候，MySQL 宕机了，此时怎么办？ 这个时候因为没有最终 commit 标记在 redo 日志里，所以此次事务可以判定为不成功。不会说 redo 日志文件里有这次更新的日志，但是 binlog 日志文件里没有这次更新的日志，不会出现数据不一致的问题。 如果是完成步骤 6 的时候，也就是 binlog 写入磁盘了，但是 MySQL 宕机了，又如何？还是一样的，因为没有 redo log 中的最终 commit 标记，因此此时事务的提交也是失败的。必须是在 redo log 中写入最终的事务 commit 标记了，然后此时事务提交成功，而且 redo log 里有本次更新对应的日志，binlog 里也有本次更新对应的日志。最终redo log 和 binlog完全是一致的。 后台 IO 线程随机将内存更新后的脏数据刷回磁盘假设现在我们已经提交事务了，此时一次更新 UPDATE users SET name = &#39;xxx&#39; WHERE id = 10 它已经把内存里的 buffer pool 中的缓存数据更新了，同时磁盘里有 redo 日志和 binlog 日志，都记录了我们把指定的 “id = 10” 这行数据修改了 “name = xxx”。 此时会有一个问题，就是这个时候磁盘上的数据文件里的 “id = 10” 这行数据的 name 字段还是等于 zhangsan 这个旧值啊。所以MySQL 有一个后台的 IO 线程，会在之后某个时间里，随机的把内存 buffer pool 中的修改的脏数据给刷回磁盘上的数据文件里如。如下图： 当上图中的 IO 线程把 buffer pool 里的修改后的脏数据刷回磁盘后，磁盘上的数据才会跟内存里一样，都是 name = xxx 这个修改以后的值了。 在 IO 线程把脏数据刷回磁盘之前，哪怕 MySQL 宕机崩溃了也没关系，因为重启之后，会根据 redo 日志恢复我们之前提交事务做过的修改到内存里去，就是 id = 10 的数据的 name 修改为了 xxx，然后等适当时机，IO 线程自然还是会把这个修改后的数据刷到磁盘上的数据文件里去的。 总结通过一次更新数据的流程，可以清楚地看到，InnoDB 存储引擎主要就是包含了一些 buffer pool、redo log buffer 等内存里的缓存数据，同时还包含了一些 undo 日志文件、redo 日志文件等东西，同时 MySQL Server 自己还有 binlog 日志文件。 在你执行更新的时候，每条 SQL 语句，都会对应修改 buffer pool 里的缓存数据、写 undo 日志、写 redo log buffer 几个步骤。 但是当你提交事务的时候，一定会把 redo log 刷入磁盘，binlog 刷入磁盘，完成 redo log 中的事务 commit 标记，最后后台的 IO 线程会随机地把 buffer pool 里的脏数据刷入磁盘里去。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch 介绍]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F22%2FElasticsearch-%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[思维导图 Elasticsearch 简介Elasticsearch 是一个近实时的分布式存储、搜索、分析的引擎。它是专门做搜索的，接下来我们简单说说 Elasticsearch 的相关知识。 Elasticsearch 的数据结构一般来说，要想知道查询的时候大概花多少时间，就需要知道它的底层数据结构是怎么样的。例如： 树形的查找时间复杂度一般是 O(logn) 链表的查找时间复杂度一般是 O(n) 哈希表的查找时间复杂度一般是 O(1) 不同的数据结构所花的时间往往是不一样的，你要查找的时候快，就需要有底层的数据结构支持。而我们要想知道 Elasticsearch 为什么模糊查询速度快，就需要知道它的底层数据结构是什么。 倒排索引Elasticsearch 最强大的就是为每个字段提供了倒排索引，当查询的时候不用担心没有索引可以利用，什么是倒排索引，举个简单例子： 文档id 年龄 性别 1 25 女 2 32 女 3 25 男 每一行是一个文档（document），每个 document 都有一个文档 id，那么给这些文档建立的倒排索引就是： 年龄的索引： 年龄 文档 id 25 [1,3] 32 [2] 性别的索引： 性别 文档 id 女 [1,2] 男 [3] 可以看到，倒排索引是针对每个字段的，每个字段都有自己的倒排索引，25、32 这些叫做 term，[1,3] 这种叫做 posting list。 首先我们得知道为什么 Elasticsearch 为什么可以实现快速的“模糊查询”或者“相关性查询”，实际上是你写入数据到 Elasticsearch 的时候会进行分词。如图： 它会根据文档内容进行分词，上面是分成四个单词，并统计每个单词的个数以及位置。当然这只是一个例子，并不是 Elasticsearch 真正的原理。 我们都知道，世界上有很多语言，那 Elasticsearch 怎么切分这写词呢？其实 Elasticsearch 内置了一些分词器： Standard Analyzer：按词切分，将词小写 Simple Analyzer：按非字母过滤（符号被过滤掉），将词小写 WhitespaceAnalyzer：按照空格切分，不转小写 等等等。。。 Elasticsearch 分词器主要由三部分组成： Character Filter：文本过滤器，取出 HTML Tokenizer：按照规则切分，比如空格 TokenFilter：将切分后的词进行处理，比如转小写 Elasticsearch 内置的分词器都是英文类的，而我们用户搜索的时候往往搜的是中文，现在中文分词器用的最多的就是 IK。 说了那么多，那 Elasticsearch 的数据结构是怎么样的呢？如图： 我们输入一段文字，Elasticsearch 会根据分词器对我们的那段文字进行分词（也就是图上看到的 Ada/Allen/Sara..），这些分词汇总起来我们叫做 Term Dictionary，而我们需要通过分词找到对应的记录，这些文档 ID 保存在 PostingList 在 Term Dictionary 中的词由于是非常非常多的，所以我们会为其进行排序，等要查找的时候就可以通过二分来查，不需要遍历整个 Term Dictionary。由于 Term Dictionary 的词实在太多，不可能把 Term Dictionary 都放在内存中，于是 Elasticsearch 还抽了一层叫做 Term Index，这层只存储部分词的前缀，Term Index 会存在内存中，检索会特别快。 Term DictionaryElasticsearch 为了能快速找到某个 term，将所有的 term 进行了排序，然后二分查找 term，类似于上学时候老师教我们的翻新华字典的方式，所以叫做 Term Dictionary，这种查询方式其实和传统关系型数据库的 B-Tree 的方式很相近，所以这并不是 Elasticsearch 快的原因。 Term Index如果说 Term Dictionary 是直接去二分法翻字典，那么 Term Index 就是字典的目录页，当然这比我们真的去翻字典目录快多了，假设我们的 term 如果全是英文，那么 Term Index 就是 26 个字母表，但是通常 term 未必都是英文，而可以是任意的 byte 数组。因为就算 26 个英文字符也不一定都有对应的 term。例如，a 来头的 term 只有一个，c 开头的 term 有一百万个，x 开头的 term 一个也没有，这样查询到 c 的时候又会很慢了。所以通常情况下 term index 是包含 term 的一些前缀的一棵树，例如这样的一个 Term Index： 这样的情况下通过 term index 就可以根据快速定位到某个 offset（分支的开端），然后以此位置向下查找，再加上 FST（Finite-State-Transducer，Lucene4.0 开始使用该算法来查找 Term 在 Dictionary 中的位置）的压缩技术，将 Term Index 缓存到内存中，通过 Term Index 找到对应的 Term Dictionary 的 block，然后直接 去磁盘直接找到 term，减少磁盘的随机读写次数，大大地提升查询效率。 Posting List 压缩技术 Roaring Bitmap说到 roaring bitmaps 就要先了解 bitset 或者 bitmap。bitset 是一种数据结构，对应 posting list 如果是：[2, 3, 5, 7, 9]，那么对应的 bitset 就是：[0,1,1,0,1,0,1,0,1,0]。用 0 和 1 来表示该位置的数值的有无，这种做法就是一个 byte 可以代表 8 个文档。当大数据量时，仍然会消耗很多内存，所以直接将 bitset 结构存入内存不太理想。 Elasticsearch 不仅压缩了 Term Index，还对 posting list 进行了压缩。posting list 虽然只存储了文档 id，但是文档 id 很大的时候，可以达到 PB 级的数据，所以 Elasticsearch 对 posting List 的压缩做了两件事：排序和大数变小数。如图： 简单解读一下这种压缩技巧： step1：在对 posting list 进行压缩时进行了正序排序。 step2：通过增量将 73 后面的大数变成小数存储增量值。例如 300 - 73 = 227、302 - 300 = 2 step3：转换成二进制，取占最大位的数，227 占 8 位，前三个占八位，30 占五位，后三个数每个占五位。 从第三步可以看出，这种压缩方式仍然不够高效，所以 Lucene 使用的数据结构叫做 Roaring Bitmap，其压缩原理可以理解为：与其保存 100 个 0，占用 100 个 bit，还不如保存 0 一次，然后声明这个 0 有 100 个，它以两个自己可以表示的最大数 65535 为界，将 posting list 分块。比如第一块是 0 - 65535，第二块是 65535 - 131071，如图： 压缩技巧解读： step1：从小到大进行排序 step2：将大数除以 65536，用除得的结果和余数来表示这个大数 step3：以 65535 为界进行分块 Elasticsearch 的术语和架构在讲解 Elasticsearch 的架构之前，首先我们得了解一下 Elasticsearch 的一些常见术语： Index：Elasticsearch 的 Index 相当于数据库的 Table Type：这个在新的 Elasticsearch 版本已经废除（在以前的 Elasticsearch 版本，一个 Index 下支持多个 Type，有点类似消息队列一个 topic 下多个 group 的概念） Document：Document 相当于数据库的一行记录 Field：相当于数据库的 Column 的概念 Mapping：相当于数据库的 Schema 的概念 DSL：相当于数据库的 SQL（给我们读取 Elasticsearch 数据的 API） RDBMS Elasticsearch TABLE Index(Type) Row Document Column Field Schema Mapping SQL DSL 说完 Elasticsearch 的相关术语，我们看一下 Elasticsearch 的架构。一个 Elasticsearch 集群会有多个 Elasticsearch 节点，所谓节点实际上就是运行着 Elasticsearch 进程上的机器。 在众多节点中，会有一个 Master Node，它主要负责维护索引元数据、负责切换主分片和副分片本身等工作，如果主节点挂了，会选举出一个新的主节点。 Elasticsearch 最外层的是 Index（相当于数据库 表的概念），一个 Index 的数据我们可以分发到不同的 Node 上进行存储，这个操作就叫做分片。比如说我集群里有4个节点，我现在有一个 Index，想将这个 Index 在 4 个节点上存储，那我们可以设置 4 个分片，这 4 个分片的数据合起来就是 Index 的数据。 使用分片的原因： 如果一个 Index 的数据量太大，只有一个分片，那只会在一个节点上存储，随着数据量的增长，一个节点未必能把一个 Index 存储下来。 多个分片，在写入或查询的时候就可以进行并行操作，从各个节点中读写数据，提高吞吐量 如果某个节点挂了，那部分数据就丢了吗？为了解决这个问题，Elasticsearch 分片有主分片和副分片之分，为了实现高可用。数据写入的时候写到主分片，副本分片复制主分片的数据，读取的时候主分片和副本分片都可以读。 Index 需要分为多少个分片和副本分片都是可以 通过配置设置的。 如果某个节点挂了，Master Node 就会把对应的副本分片提拔为主分片，这样即便节点挂了，数据就不会丢失了。 Elasticsearch 写入流程上面我们说过当我们向 Elasticsearch 写入数据的时候，是写到主分片上的，我们可以了解更多的细节。 客户端写入一条数据，到 Elasticsearch 集群里边就是由节点来处理这次请求： 集群上的每个节点都是 coordinating node（协调节点），协调节点表明这个节点可以做路由。比如节点 1 收到了请求，但发现这个请求的数据应该是由节点 2 处理（因为主分片在节点 2 上），所以会把请求转发到节点 2 上。coordinate（协调）节点通过 hash 算法可以计算出在哪个主分片上，然后路由到对应的节点。shard = hash(document_id) % (num_of_primary_shards) 路由到对应的节点以及对应的主分片时，会做以下的事： 将数据写到内存缓冲区 然后将数据写到 translog 缓冲区. 每隔 1s 数据从 buffer 中 refresh 到 FileSystemCache 中，生成 segment 文件，一旦生成 segment 文件，就能通过索引查询到了 refresh 完，memory buffer 就清空了 每隔 5s，translog 从 buffer flush 到磁盘中 定期/定量 从 FileSystemCache 中，结合 translog 内容 flush index 到磁盘中 其中： Elasticsearch 会把数据先放入内存缓冲区，然后每隔 1s 刷新到文件系统缓存区（当数据被刷新到文件系统缓冲区以后，数据才可以被检索到）。所以，Elasticsearch 写入的数据需要 1s 才能查询到。 为了防止节点宕机，内存中的数据丢失，Elasticsearch 会另写一份数据到日志文件上。但最开始的还是写入到内存缓冲区，每隔 5s 才会将缓冲区的数据刷到磁盘中。所以，Elasticsearch 某个节点如果挂了，可能会造成 5s 的数据丢失。 等到磁盘上的 translog 文件打到一定程度或者超过了 30 分钟，会触发 commit 操作，将内存中的 segment 文件异步刷到磁盘中，完成持久化操作。 说白了就是，写内存缓冲区（定时去生成 segment，生成 translog），能够让数据被索引、被持久化。最后通过 commit 完成一次的持久化。 等主分片写完了以后，会将数据并行发送到副本节点上，等到所有的节点写入成功就返回 ack 给协调节点，协调节点返回 ack 给客户端，完成一次的写入。 Elasticsearch 更新和删除Elasticsearch 的更新和删除操作流程： 给对应的 doc 记录打上 .del 标识，如果是删除操作就打上 delete 状态，如果是更新操作就把原来的 doc 标志为 delete，然后重新写入一条数据。 前面讲到，每隔 1s 会生成一个 segment 文件，那 segment 文件会越来越多。Elasticsearch 会有一个 merge 任务，会将多个 segment 文件合并成一个 segment 文件。在合并的过程中，会把带有 delete 状态的 doc 给物理删除掉。 Elasticsearch 查询查询我们最简单的方式可以分为两种： 根据 ID 查询 doc 根据 query（搜索词）去查询匹配的 doc 根据 ID 去查询具体的 doc 的流程是： 检索内存的 Translog 文件 检索硬盘的 Translog 文件 检索硬盘的 Segment 文件 根据 query 去匹配 doc 的流程是：同时去查询内存和硬盘的 segment 文件 Elasticsearch 查询又可以分为五种搜索类型： QUERY_AND_FETCH：向索引的所有分片（shard）都发出请求，各分片返回的时候把文档（document）和计算后的排名信息一起返回。这种搜索方式是最快的。因为相比下面的几种搜索方式，这种查询方法只需要去 shard 查询一次。但是各个 shard 返回的结果的数量之和可能是用户要求的 size 的 n 倍。 QUERY_THEN_FETCH：如果你搜索时，没有指定搜索方式，那默认就是使用这种方式。这种搜索方式，大概分为两个步骤。第一步，先向所有的 shard 发出请求，各分片只返回排序和排名相关的信息（注意，不包括文档 document），然后按照各分片返回的分数进行重新排序和排名，取前 size 个文档。然后第二步，去相关的 shard 取 document。这种方式返回的 document 与用户要求的 size 是相等的。 DFS_QUERY_AND_FETCH：这种方式比第一步多了一个初始化散发（initial scatter）步骤。有这一步，可以更精确控制搜索打分和排名。 DFS_QUERY_THEN_FETCH：比第二种多了一个初始化散发步骤。 COUNT：这种一种特殊的搜索类型，只返回匹配查询的文档数目。 初始化散发其实就是在进行真正的查询之前，先把各个分片的词频率和文档频率收集一下，然后进行词搜索的时候，各分片依据全局的词频率和文档频率进行搜索和排名。显然如果使用 DFS_QUERY_THEN_FETCH 这种查询方式，效率是最低的，因为一个搜索，可能要查询 3 次分片，但使用 DFS 方法，搜索精度应该是最高的。 一般我们用得最多的就是 QUERY_THEN_FETCH，第一种查询完就返回这个 doc 内容（QUERY_AND_FETCH）只适合于只需要查一个分片的请求。 QUERY_THEN_FETCH 总体的流程大概是： 客户端请求发送到集群的某个节点上。集群上的每个节点都是 coordinate node（协调节点） 然后协调节点将搜索的请求转达到所有分片上（主分片和副本分片都行） 每个分片将自己搜索出的结果（doc id）返回给协调节点，由协调节点进行数据的合并、排序、分页等操作，产出最终结果。 接着由协调节点根据 doc id 去各个节点上拉取实际的 document 数据，最终返回给客户端。 Query Phase 时节点做的事： 协调节点向目标分片发送查询的命令（转发请求到主分片或者副本分片上） 数据节点（在每个分片内做过滤，排序等操作），返回 doc id 给协调节点 Fetch Phase 阶段时节点做的事： 协调节点得到数据节点返回的 doc id，对这些 doc id 做聚合，然后将目标数据分片发送抓取命令（希望拿到这个 doc 记录） 数据节点按照协调节点发送的 doc id，拉取实际需要的数据返回给协调节点 主流程其实说白了就是：由于 Elasticsearch 是分布式的，所以需要从各个节点都拉取对应的数据，然后最终统一合成给客户端。只是Elasticsearch 把这些活都干了，我们在使用的时候无感知而已。 参考资料扫盲–Elasticsearch Elasticsearch 原理]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 的架构设计]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F22%2FMySQL-%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[一般情况下，我们的系统采用数据库连接池的方法去并发访问数据库，然后数据库自己也会维护一个连接池，其中管理了各种系统跟这台数据库服务器建立的所有连接。 当我们的系统只要能从连接池获取到一个数据库连接之后，我们就可以执行增删改查的SQL语句了。但大部分人都停留在把 MySQL 当成一个黑盒的阶段，只知道执行相应的 SQL 语句就可以得到相应的结果，如果语句性能差了，就在表里建几个索引，完全当它是个黑盒子，来建表以及执行 SQL 语句。 接下来我们就要深入底层，去探索数据库的工作原理以及生产问题的优化手段。 网络连接必须让线程来处理假设我们的数据库服务器的连接池中的某个连接接收到了网络请求，假设就是一条 SQL 语句，那么由谁负责从这个连接中去监听网络请求？谁负责从网络连接里把请求数据读取出来？大家应该或多或少都知道一点，那就是网络连接必须得分配给一个线程去处理，由一个线程来监听请求以及读取请求数据，比如从网络连接中读取和解析出来一条我们的系统发送过去的 SQL 语句。如图： SQL 接口：负责处理接收到的 SQL 语句当 MySQL 内部的工作线程从一个网络连接中读取出来一个 SQL 语句之后，此时会如何执行这个 SQL 语句呢？为了执行这些 SQL 语句，去完成底层数据的增删改查，MySQL 内部提供了一个组件，就是 SQL 接口（SQL Interface），它是一套执行 SQL 语句的接口，专门用于执行我们发送给 MySQL 的那些增删改查的 SQL 语句。 因此 MySQL 的工作线程接收到 SQL 语句之后，就会转交给 SQL 接口去执行，如图： 查询解析器：让 MySQL 能看懂 SQL 语句当工作线程将 SQL 语句交给 SQL 接口去执行，那么 SQL 接口怎么执行 SQL 语句呢？直接把 SQL 语句交给 MySQL，它能看懂和理解这些 SQL 语句吗？ 例如有这么一个 SQL 语句： 1SELECT id, name, age FROM users WHERE id = 1 这个 SQL 语句，我们用人脑是直接就可以处理一下，只要懂 SQL 语法的人，一看就知道是什么意思。但是 MySQL 自己本身也是一个系统，是一个数据库管理系统，它没直接理解这些 SQL 语句。所以这就需要一个关键的组件：查询解析器 这个查询解析器就是负责对 SQL 语句进行解析的，比如上面的那个 SQL 语句进行一些拆解，拆解成以下几个部分： 我们现在要从 “users” 表里查询数据 查询 “id” 字段的值等于 1 的那行数据 对查出来的那行数据要提取里面的 “id, name, age” 三个字段 所谓的 SQL 解析，就是按照既定的 SQL 语法，对我们按照 SQL 语句规则编写的 SQL 语句进行解析，然后理解这个 SQL 语句要干什么事情，如图所示： 查询优化器：选择最优的查询路径当我们通过解析器理解了 SQL 语句要干什么时候，接着会找查询优化器来选择一个最优的查询路径。 什么叫做最优的查询路径？举个简单的例子，就拿上面的那个 SQL 语句，现在 SQL 要干这么一件事情：我们要从 “users” 表里查询数据，查询 “id” 字段的值等于 1 的那行数据，对查出来的那行数据要提取里面的 “id, name, age” 三个字段。那到底应该怎么来实现呢？ 假设要完成这件事有以下几个查询路径（只是用于大家理解的例子，不代表真实的 MySQL 原理，但是通过这个例子，能让大家理解最优查询路径的意思）： 直接定位到 “users” 表中的 “id” 字段等于 1 的一行数据，然后查出来那行数据的 “id, name, age” 三个字段的值就可以了 先把 “user” 表中的每一行数据的 “id, name, age” 三个字段的值都查出来，然后从这批数据里过滤出来 “id” 字段等于 1 的那行数据的 “id, name, age” 三个字段 上面就是那个 SQL 语句的两种实现路径，我们会发现，要完成这个 SQL 的目标，两个路径都可以做到，但很显然感觉上是第一种查询路径更好。 所以查询优化器大概就是干这个的，它会针对你编写的几十行、几百行复制 SQL 语句生成查询路径树，然后从里面选择一条最优的查询路径处理。相当于会告诉你，你应该按照一个什么样的步骤和顺序，去执行哪些操作，然后一步一步地把 SQL 语句给完成了。 调用存储引擎接口，真正执行 SQL 语句接下来，就是把查询优化器选择的最优查询路径，也就是你到底应该按照一个什么样的顺序和步骤去执行这个 SQL 语句的计划，把这个计划交给底层的存储引擎去真正的执行。这个存储引擎是 MySQL 的架构设计中很有特色的一个环节。 真正在执行 SQL 语句的时候，要不然是更新数据，要不是查询数据，那数据会放在哪里？说到底数据库也不是什么神秘莫测的东西，可以把它理解成一个类似你平时写的图书管理系统，电信计费系统之类的系统。 数据库自己本身就是一个编程语言写出来的系统而已，然后启动之后也是一个进程，执行它里面的各种代码。所以对数据库而言，我们的数据要不是放在内存里，要不就是放在磁盘文件里，没什么特殊的地方。假设我们的数据有的放在内存里，有的放在磁盘文件里，如图： 那么问题来了，我们已经知道一个 SQL 语句要如何执行了，但是我们现在要怎么知道哪些数据在内存里，哪些数据在磁盘里，我们执行的时候是更新内存的数据，还是更新磁盘的数据，我们如果更新磁盘的数据，是先查询哪个磁盘文件，再更新哪个磁盘文件？ 是不是感觉很懵逼。这个时候就需要存储引擎了。存储引擎其实就是执行 SQL 语句的，它会按照一定的步骤去查询内存缓存数据，更新磁盘数据，查询磁盘数据等等诸如一系列的操作。如图： MySQL 的架构设计中，SQL 接口、SQL 解析器、查询优化器其实都是通用的，它就是一套组件而已。但是存储引擎的话，它是支持各种各样的存储引擎的，比如我们常见的 InnoDB、MyISAM、Memory 等等，我们是可以选择使用哪种存储引擎来负责具体的 SQL 语句执行的。当然现在 MySQL 一般都是使用 InnoDB 存储引擎的。 执行器：根据执行计划调用存储引擎的接口看完存储引擎之后，我们回过头来思考一个问题，存储引擎可以帮助我们去访问内存以及磁盘上的数据，那么是谁来调用存储引擎的接口呢？ 其实我们还漏了一个执行器的概念，这个执行器会根据优化器选择的执行方案，去调用存储引擎的接口按照一定的顺序和步骤，把 SQL 语句的逻辑给执行了。 例如，执行器可能会先调用存储引擎的一个接口，去获取 “users” 表中的第一行数据，然后判断一下这个数据的 “id” 字段的值是否等于我们期望的一个值，如果不是的话，那就继续调用存储引擎的接口，去获取 “users” 表的下一行数据。 就是基于上述的思路，执行器就会根据我们的优化器生成的一套执行计划，然后不停地调用存储引擎的各种接口去完成 SQL 语句的执行计划，大致就是不停地更新或提取一些数据出来。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 的事务实现原理和传播机制]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F22%2FSpring-%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%92%8C%E4%BC%A0%E6%92%AD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 事务管理是应用系统开发中必不可少的一部分。Spring 为事务管理提供了丰富的功能支持。Spring 事务管理分为编程式和声明式两种。编程式事务指的是通过编码方式实现事务；声明式事务基于 AOP，将具体的逻辑与事务处理解耦。生命式事务管理使业务代码逻辑不受污染，因此实际使用中声明式事务用的比较多。 声明式事务有两种方式，一种是在配置文件（XML）中做相关的事务规则声明，另一种是基于 @Transactional 注解的方式。本文着重介绍基于 @Transactional 注解的事务管理。 需要明确几点： 默认配置下 Spring 只会回滚运行时、未检查异常（继承自 RuntimeException 的异常）或者 Error。 @Transactional 注解只能应用到 public 方法才有效。 事务的实现原理事务的实现原理。如果说你加了一个 @Transactional 注解，此时 Spring 会使用 AOP 思想，对你的这个方法在执行之前，先去开启一个事务。执行完毕之后，根据你的方法是否报错，来决定回滚还是提交事务。 @Transactional 注解的属性介绍下面分别介绍一下 @Transactional 的几个属性 value 和 transactionManager 属性它们两个是一样的意思。当配置了多个事务管理器时，可以使用该属性指定选择哪个事务管理器。 isolation 属性事务的隔离级别，默认值为 Isolation.DEFAULT。可选的值有 Isolation.DEFAULT：使用底层数据库默认的隔离级别 Isolation.READ_UNCOMMITTED：读取未提交数据（会出现脏读，不可重复读）基本不使用 Isolation.READ_COMMITTED：读取已提交数据（会出现不可重复读和幻读） Isolation.REPEATABLE_READ：可重复读（会出现幻读） Isolation.SERIALIZABLE：串行化 tip： MySQL 默认为 REPEATABLE_READ 级别 SQL_SERVER 默认为 READ_COMMITED 级别 脏读：一个事务读取到另一个事务未提交的更新数据 不可重复读：同一事务中，多次读取同一数据返回的结果有所不同，即，后续读取可以读到另一事务已提交的更新数据 可重复读：在同一事务中多次读取数据时，能够保证所读数据一样，也就是后续读取不能读到另一事务已提交的更新数据 幻读：一个事务读到另一个事务已提交的 insert 数据。 timeout 属性事务的超时时间，默认值为 -1。如果超过该时间限制但事务还没有完成，则自动回滚事务。 readOnly 属性指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true rollbackFor 属性用于指定能够触发事务回滚的异常类型，可以指定多个异常类型 noRollbackFor 属性抛出指定的异常类型，不会滚事务，也可以指定多个异常类型 propagation 属性事务的传播行为，默认值为 Propagation.REQUIRED。可选的值有： PROPAGATION.REQUIRED：如果当前没有事务，则创建一个新事务。如果当前存在事务，就加入该事务。该设置是最常用的设置。 PROPAGATION.SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务。如果当前不存在事务，就以非事务执行。 PROPAGATION.MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。 PROPAGATION.REQUIRE_NEW：创建新事务，无论当前存不存在事务，都创建新事务。 PROPAGATION.NOT_SUPPORTED：以非事务方式执行操作，如果当前事务存在，就把当前事务挂起。 PROPAGATION.NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION.NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按 REQUIRED 属性执行。 @Transactional 的 propagation 属性代码示例比如如下代码，save 方法首先调用 method1 方法，然后抛出了异常，就会导致事务回滚，如下两条数据都不会插入数据库。 1234567891011121314151617@Transactional(propagation = Propagation.REQUIRED)public void save() &#123; method1(); User user = new User("服部半藏"); userMapper.insertSelective(user); if(true) &#123; throw new RuntimeException("save 抛异常了"); &#125;&#125;public void method1() &#123; User user = new User("宫本武藏"); userMapper.insertSelective(user);&#125; 现在有需求如下，就算 save 方法的后面抛异常了，也不能影响 method1 方法的数据插入。一般方法时给 method1 加入一个新的事务，这样 method1 就会在这个新的事务中执行，原来的事务不会影响到新的事务。例如给 method1 加 propagation 属性为 Propagation.REQUIRES_NEW 的事务。 123456789101112131415161718@Transactional(propagation = Propagation.REQUIRED)public void save() &#123; method1(); User user = new User("服部半藏"); userMapper.insertSelective(user); if(true) &#123; throw new RuntimeException("save 抛异常了"); &#125;&#125;@Transactional(propagation = Propagation.REQUIRES_NEW)public void method1() &#123; User user = new User("宫本武藏"); userMapper.insertSelective(user);&#125; 运行之后，发现并没有起作用，数据也是没有插入数据库。通过查看日志发现，两个方法都是处于同一个事务中，method1 方法并没有创建一个新的事务。 通过 Spring 官方文档可以知道：在默认的代理模式下，只有目标方法由外部调用，才能被 Spring 的事务拦截器拦截。在同一个类中的两个方法直接调用，是不会被 Spring 的事务拦截器拦截，就像上面的 save 方法直接调用了同一个类中 method1 方法，method1 方法不会被 Spring 的事务拦截器拦截。可以使用 AspectJ 取代 Spring AOP 代理来解决这个问题。但是这里不展开。 为了解决这个问题，我们可以新建一个类： 123456789101112@Servicepublic class OtherServiceImpl implements OtherService &#123; @Autowired private UserMapper userMapper; @Transactional(propagation = Propagation.REQUIRES_NEW) public void method1() &#123; User user = new User("风魔小太郎"); userMapper.insertSelective(user); &#125;&#125; 然后再 save 方法中调用 otherService.method1 方法 12345678910111213141516@Autowiredprivate OtherService otherService;@Transactional(propagation = Propagation.REQUIRED)@Overridepublic void save() &#123; otherService.method1(); User user = new User("服部半藏"); userMapper.insertSelective(user); if (true) &#123; throw new RuntimeException("save 抛异常了"); &#125;&#125; 这下，otherService.method1 方法的数据插入成功，save 方法的数据未插入，事务回滚。继续查看日志： 从日志可以看出，首先创建了 save 方法的事务，由于 otherService.method1 方法的 @Transactional 的 propagation 属性为 Propagation.REQUIRES_NEW，所以接着暂停了 save 方法的事务，重新创建了 otherService.method1 方法的事务，接着 otherService.method1 方法的事务提交，接着 save 方法的事务回滚，这就印证了只有目标方法由外部调用，才能被 Spring 的事务拦截器拦截。 Spring 事务传播机制总结Spring 事务传播机制总共有 7 种，其中使用最多的应该是 PROPAGATION_REQUIRES、PROPAGATION_REQUIRES_NEW 和 PROPAGATION_NESTED。其中所谓的嵌套事务，是指外层的事务如果回滚，会导致内层的事务也回滚；但是内层的事务如果回滚，仅仅是滚回自己的代码。 比如现在有一段业务代码，方法 A 调用方法 B，我希望的是如果方法 A 出错了，此时仅仅回滚方法 A，不能回滚方法 B，这个时候可以给方法 B 使用 REQUIRES_NEW 传播机制，让他们两的事务是不同的。 如果方法 A 调用方法 B，如果出错，方法 B 只能回滚它自己，方法 A 可以带着方法 B 一起回滚。那这种情况可以给方法 B 加上 NESTED 嵌套事务。 参考资料Spring Boot 中使用 @Transactional 注解配置事务管理]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK 动态代理和 CGLIB 动态代理]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F10%2FJDK-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%92%8C-CGLIB-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[什么是动态代理动态代理即动态的代理模式，所谓动态，是指抽象类（即抽象角色）在编译期是未确定的，在运行期生成。相对的，静态代理中抽象类的行为是在编译期确定的。动态代理是 AOP（面向切面编程）常见的实现方式。 Spring 里使用 AOP，比如说你对一批和它们的方法做了一个切面，定义好了要在这些类的方法里的增强代码，那 Spring 要对那些类生成动态代理，在动态代理中去执行你定义的那些增强代码。 JDK 动态代理动态代理使用示例JDK 动态代理使用起来比较简单，只要我们掌握 Proxy.newProxyInstance 方法即可。Proxy。newProxyInstance 方法在 JDK 中定义如下： 1234567891011121314151617181920212223242526/** * 返回一个受调用处理器 (InvocationHandler) 管理，实现了指定接口的代理类的实例 * * @param loader 声明这个代理类的 ClassLoader * @param interfaces 代理类实现的接口列表 * @param h 处理代理类的调用的调用处理器 * @return 一个受调用处理器 (InvocationHandler) 管理，实现了指定接口的代理类的实例 * @throws IllegalArgumentException 违反了 getProxyClass 函数的参数限制条件 * @throws SecurityException 如果安全管理器存在并且下面的任意条件满足： * (1) 传入的 loader 是 null 且调用者的类加载器非空， * 使用 RuntimePermission("getClassLoader")权限 * 调用 SecurityManager#checkPermission禁止访问 * * (2) 对于每一个代理接口，调用者的类加载器与接口类加载器不同或不是其父类, * 并且调用 SecurityManager#checkPackageAccess 无权访问接口 * * (3) 所有传入的代理接口都是非公共的，且调用者类与非公共接口不在同一个包下， * 使用 ReflectPermission("newProxyInPackage.&#123;package name&#125;") 调用 * SecurityManager#checkPermission 无访问权限 * @throws NullPointerException interfaces 数组参数或其中的元素为 null，以及调用处理器 h 为 null */@CallerSensitivepublic static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException; 从 Javadoc 中我们可以获知，主需要传入相应的类加载器，接口，调用处理器即可产生一个代理实例，那么我们不熟悉的就是 InvocationHandler 类，我们看一下 InvocationHandler 类的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package java.lang.reflect;/*** InvocationHandler是代理实例的调用处理器实现的接口。* 每个代理实例都有一个关联的调用处理器。* 在调用代理实例的方法时，方法调用将被编码并分派给其调用处理程序的 invoke 方法。** @author Peter Jones* @see Proxy* @since 1.3*/public interface InvocationHandler &#123; /** * 在代理实例上处理方法调用并返回结果。当在与其关联的代理实例上调用 * 方法时，将调用处理期上的此方法。 * * @param proxy 该方法被调用的代理实例 * * @param method Method 对象将是代理接口声明的方法，它可能是代理 * 类继承方法的代理接口的超级接口。 * @param args 包含在代理实例的方法调用中传递的参数值的对象数组， * 如果interface方法不带参数，则为null。基本类型的参 * 数被封装在适当的基本封装类的实例中，比如 * java.lang.Integer 或者 java.lang.Boolean。 * @return 调用代理实例上的方法获得的返回值。如果接口方法的声明返 * 回类型是基本类型，则此方法返回的值必须是相应基本包装类 * 的实例;否则，它必须是转换为声明的返回类型的类型。如果 * 此方法返回的值为null，并且接口方法的返回类型为原始类型， * 则代理实例上的方法调用将引发NullPointerException。如果 * 此方法返回的值与上面所述的接口方法的声明返回类型不兼容， * 则将通过代理实例上的方法调用抛出ClassCastException。 * * @throws 抛出调用代理实例的方法时抛出的异常。异常的类型必须可以 * 转化为接口方法的 throws 子句中声明的异常类型，也可以分 * 配给不强制检查的异常类型 java.lang.RuntimeException 或 * java.lang.Error。如果这个方法抛出一个强制检查的异常， * 这个异常不能转化为接口方法的 throws 子句中声明的异常类 * 型，那么将会抛出包含这个异常的 * UndeclaredThrowableException 异常。 * * @see UndeclaredThrowableException */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; 从 Javadoc 中我们知道，通过调用 Proxy.newProxyInstance 方法创建的代理实例中的方法时，会执行传入的 InvocationHandler#invoke 方法，代理实例中方法返回值为 InvocationHandler#invoke 方法返回值。 我们做一个测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 代理接口 */public interface ITest &#123; String test(String val);&#125;/** * 代理实现类 */public class Test implements ITest &#123; @Override public String test(String val) &#123; return val + "我是Test"; &#125;&#125;/** * 调用处理器 */public class TestInvocationHandler implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(method); return args[0] + "我是TestProxy"; &#125;&#125;public class Main &#123; /** * 分别对正常实现的 ITest 实现类和动态代理实现类进行调用 * @param args */ public static void main(String[] args) &#123; ITest test = new Test(); ITest testProxy = (ITest) Proxy.newProxyInstance(test.getClass().getClassLoader(), new Class[] &#123;ITest.class&#125;, new TestInvocationHandler()); System.out.println(test.test("Hello，")); System.out.println("------------"); System.out.println(testProxy.test("Hello，")); &#125;&#125; 输出结果为： 1234Hello，我是Test----------public abstract java.lang.String com.example.demo.Main$ITest.test(java.lang.String)Hello，我是TestProxy 从测试例子中，我们可以看出两个特点： 实现了 ITest 接口的实现类并不需要我们手动写，是自动生成并实例化的。 调用自动生成的 ITest 代理类实例，将调用 InvocationHandler#invoke 方法。 不知各位使用 MyBatis 的时候有没有疑问，为什么可以直接调用接口？答案就在这里，事实上，MyBatis 使用类似的技术，帮我们实现了一个代理类，我们拿到的都是接口的代理类实例。 JDK动态代理实现原理为了突出重点，以下代码仅展示与主题相关的代码，防御性编程，异常处理等无关内容已被省略，完整实现请自寻 JDK 源码 那么 Java 的动态代理是怎样实现的呢？我们去 JDK 源码，查看 Proxy.newProxyInstance 的实现： 12345678910111213141516public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; final Class&lt;?&gt; intfs = interfaces.clone(); // 通过类加载器和接口使用 getProxyClass0 方法创建实现类 Class&lt;?&gt; c1 = getProxyClass0(loader, intfs); // 获得指定构造器 final Constructor&lt;?&gt; cons = c1.getConstructor(constructorParams); // 创建实例 return cons.newInstance(new Object[](h));&#125; 其中两句创建实例的过程都是常见的反射操作，这里不赘述。但是 getProxyClass0 方法是如何通过接口创建类的？我们继续跟进 getProxyClass0 方法的实现： 1234private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; return proxyClassCache.get(loader, interfaces);&#125; 我们跟进至 proxyClassCache.get 的实现，这应该是一个负责缓存管理的类： 123456public V get(K key, P parameter) &#123; // Cache 置换，检查等实现均已省略，已下是 Cache 未命中时，创建新实现类的代码 Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); V value = supplier.get(); return value;&#125; 我们跟进至 ProxyClassFactory#apply 的实现： 1234567891011public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt; interfaces) &#123; for(Class&lt;?&gt; intf : interfaces) &#123; interfaceClass = Class.forName(intf.getName(), false, loader); // 对 interfaceClass 进行了系列权限检查，实现略 &#125; // 根据 interfaces.accessFlags 产生名为 proxyName 的代理类字节码 byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interface, accessFlags); // 加载字节码，产生类对象 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length);&#125; 从代码中，可以看到： ProxyGenerator.generateProxyClass 用于产生代理类的字节码 defineClass0 用于加载字节码产生类对象 这里的 defineClass0 是一个 native 方法，我们不深究。ProxyGenerator.generateProxyClass 是对字节码进行操作。我们做一个小实验： 123456789101112131415161718public class Main2 &#123; /** * 代理接口 */ interface ITest &#123; String test(String val); &#125; public static void main(String[] args) throws IOException &#123; // 通过 ProxyGenerator.generateProxyClass 产生字节码 byte[] testProxyBytes = ProxyGenerator.generateProxyClass("TestProxy", new Class[]&#123;ITest.class&#125;); // 将字节码输出到文件，然后我们再反编译它，看看它的内容是什么 FileOutputStream fileOutputStream = new FileOutputStream("TestProxy.class"); fileOutputStream.write(testProxyBytes); fileOutputStream.flush(); fileOutputStream.close(); &#125;&#125; TestProxy.class 反编译后的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public final class TestProxy extends Proxy implements ITest &#123; private static Method m1; private static Method m2; private static Method m3; private static Method m0; public TestProxy(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final String test(String var1) throws &#123; try &#123; return (String)super.h.invoke(this, m3, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName("java.lang.Object").getMethod("equals", Class.forName("java.lang.Object")); m2 = Class.forName("java.lang.Object").getMethod("toString"); m3 = Class.forName("com.example.demo.Main2$ITest").getMethod("test", Class.forName("java.lang.String")); m0 = Class.forName("java.lang.Object").getMethod("hashCode"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 通过 ProxyGenerator.generatorProxyClass 生成的类字节码有以下特点： 该类继承了 Proxy 实现了传入接口类（ITest） 该类在 static 代码块中定义了所有该类包含的方法的 Method 实例。 该类有一个构造器 TestProxy(InvocationHandler var1) 传入调用处理器。 该类所有方法都执行 super.h.invoke 并返回结果。 那么这里的 super.h 是什么呢，我们看其父类 Proxy 的代码： 12345protected InvocationHandler h;protected Proxy(InvocationHandler h) &#123; Objects.requireNonNull(h); this.h = h;&#125; 恍然大悟！这里的 super.h 就是 TestProxy(InvocationHandler var1) 构造器中传入的h。 总结 用户通过 Proxy.newProxyInstance 方法传入类加载器、接口对象、调用处理器来创建代理类实例。 JDK 中通过 ProxyGenerator.generateProxyClass 方法根据传入接口类对象生成代理类的字节码，并加载字节码产生代理类对象。 生成的代理类继承了 Proxy 实现了传入接口类。 该类的每一个方法都会执行调用处理器的 invoke 方法，传入相应参数，返回 invoke 方法的返回值 CGLIB 动态代理CGLIB 是什么CGLIB（Code Generation Library）是一个开源项目，是一个强大的，高性能，高质量的 Code 生成类库，它可以在运行期扩展 Java 类与实现 Java 接口。CGLIB 是一个强大的高性能的代码生成包。它广泛地被许多 AOP 框架使用，例如 Spring AOP 和 dynaop。 CGLIB 实现动态代理先来个 service，注意没有接口 1234567891011121314151617181920public class CglibService &#123; public CglibService() &#123; System.out.println("CglibDao 构造方法"); &#125; /** * 该方法不能被子类覆盖，Cglib是无法代理final修饰的方法的 * @param name * @return */ final public String sayOthers(String name) &#123; System.out.println("CglibDao final sayOthers：" + name); return null; &#125; public void sayHello() &#123; System.out.println("CglibDao:syaHello"); &#125;&#125; 新建一个 Interceptor 实现 org.springframework.cglib.proxy.MethodInterceptor 123456789101112131415161718public class MyMethodInterceptor implements MethodInterceptor &#123; /** * * @param o 代理对象 * @param method 被代理的对象方法 * @param objects 方法入参 * @param methodProxy 代理方法 * @return * @throws Throwable */ @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("===========插入前通知==========="); Object object = methodProxy.invokeSuper(o, objects); System.out.println("===========插入后通知==========="); return object; &#125;&#125; 新建测试类 1234567891011121314151617public class cglibAgentTest &#123; public static void main(String[] args) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(CglibService.class); // 设置 enhancer 的回调对象 enhancer.setCallback(new MyMethodInterceptor()); // 创建代理对象 CglibService proxy = (CglibService) enhancer.create(); // 通过代理对象调用目标方法 proxy.sayHello(); proxy.sayOthers("小明"); &#125;&#125; 打印的值 12345CglibDao 构造方法======插入前置通知======CglibDao:sayHello======插入后置通知======CglibDao final sayOthers:小明 可以看出，会先执行它的构造方法，当调用 sayHello 时会先调用它们的代理方法，如果当方法为 final 修饰时，无法实现代理。 原理CGLIB 可以在运行时，动态生成一个代理类继承我们的目标类，并重写了目标方法，如下： 动态生成的代理类，在方法中调用了父类（目标类）的目标方法，并在调用前后做了一些处理。 总结如果你的类是实现了某个接口的，Spring AOP 会使用 JDK 动态代理，生成一个跟你实现同样接口的一个代理类，构造一个实例对象出来，JDK 动态代理，其实就是在你的类有接口的时候，就会来使用。 如果你的类是没有实现接口的，Spring AOP 会改用 cglib 来动态生成代理，它是生成你的类的一个子类，可以动态生成字节码，覆盖你的一些方法，在方法里加入增强的代理。 参考资料小豹子带你看源码：JDK 动态代理 CGLIB 动态代理]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IOC 和 Spring AOP]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F09%2FSpring-IOC-%E5%92%8C-Spring-AOP%2F</url>
    <content type="text"><![CDATA[Spring IOC在没有 Spring 之前，我们开发 Web 系统基本是使用 Servlet + Tomcat。就是 Tomcat 启动之后，它可以监听一个端口号的 http 请求，然后可以把情趣转交给你的 servlet，jsp 配合起来使用，由 servlet 处理请求。大概像下面的代码： 123456789101112131415public class MyServlet &#123; private MyService myService = new MyServiceImpl(); public void doPost(HttpServletRequest request) &#123; // 对请求一通处理 // 调用自己的业务逻辑组件 myService.doService(request); &#125;&#125;public interface MyService &#123;&#125;public class MyServiceImpl implements MyService &#123;&#125;public class NewServiceManagerImpl implements MyService &#123;&#125; 例如我们的一个 Tomcat + servlet 的这样的一个系统里，有几十个地方，都是直接用 MyService myService = new MyServiceImpl() 直接创建，引用和依赖了一个 MyServiceImpl 这样的一个类的对象。那么在这个系统里，就有几十个地方都跟 MyServiceImpl 类直接耦合在一起了。 如果现在不想用 MyServiceImpl 了，希望使用 NewServiceManagerImpl，同样也是 implements MyService 这个借口的。那么所有的实现逻辑都不同了，我们需要在这个系统的几十个地方，都去修改对应的 MyServiceImpl 这个类，切换为 NewServiceManagerImpl 这个类。这样就很麻烦。而且代码的改动成本很大，改动以后的测试成本很大，改动的过程可能会有点复杂，出现一些 bug。归根到底，代码里各种类之间完全耦合在一起，出现任何一丁点的变动，都需要改动大量的代码，重新测试，可能还有 bug。 这个时候，Spring IOC 框架就出场了。IOC（Inversion Of Control），中文翻译为“控制反转”，我们也叫依赖注入。之前是通过 XML 文件进行一个配置，现在可以基于注解来进行自动依赖注入。 1234567891011121314151617@Controllerpublic class MyController &#123; @Resource private MyService myService; public void doRequest(HttpServletRequest request) &#123; // 对请求一通处理 // 调用自己的业务逻辑组件，去执行一些业务逻辑 myService.doService(request); &#125;&#125;public class MyServiceImpl implements MyService &#123;&#125;@Servicepublic class NewServiceManagerImpl implements MyService &#123;&#125; 我们只要在这个工程里通过 maven 引入一些 spring 框架的依赖，就可以实现 IOC 的功能。 Tomcat 在启动的时候，会直接启动 spring 容器。而 spring 容器，会根据 XML 的配置，或者是你的注解，去实例化一些 bean 对象，然后根据 XML 配置或者注解，去对 bean 对象之间的引用关系，进行依赖注入，某个 bean 依赖了另一个 bean。而这底层的核心技术，就是反射。它会通过反射的技术，直接根据你的类去构建对应的对象出来。 Spring IOC，最大的好处就是让系统的类与类之间彻底的解耦合。 Spring AOPSpring AOP，又叫面向切面编程，可以应用于事务和日志等场景。拿事务举个例子，在数据库里，例如 MySQL，都提供一个事务机制，如果我们开启一个事务，在这个事务里执行多条增删改的 SQL 语句。在这个过程中，如果任何一个 SQL 语句失败了，会导致这个事务的回滚，把其他 SQL 做的数据更改都恢复回去。 在一个事务里的所有 SQL，要么一起成功，要么一起失败，事务功能可以保证我们的数据的一致性。我们可以在业务逻辑组件里加入这个事务。 123456789101112131415161718192021222324252627282930313233343536373839@Controllerpublic class MyController &#123; @Resource private MyService myServiceA; public void doRequest() &#123; myServiceA.doServiceA(); &#125;&#125;@Servicepublic class MyServiceAImpl implements MyServiceA &#123; public void doServiceA() &#123; // 开启事务 //insert语句 //update语句 //delete语句 //根据是否抛出异常，回滚事务 or 提交事务 &#125;&#125;@Servicepublic class MyServiceBImpl implements MyServiceB &#123; public void doServiceB() &#123; // 开启事务 // update语句 // update语句 // insert语句 //根据是否抛出异常，回滚事务 or 提交事务 &#125;&#125; 由上面的代码可以看出，所有的业务逻辑都有几段跟事务相关的代码。假设我们有几十个 Service 组件，类似一样的代码，重复的代码，必须在几十个地方都去写一样的东西，这就很难受了。这时候就轮到 Spring AOP 机制出马了。 AOP 作为一种编程范式，已经衍生出了属于它的一些先关术语。为了更好地理解如何在 Spring 中使用 AOP，我们必须对这些术语有一定的认知。 通知（Advice）Spring AOP 支持五种类型的通知，它们分别定义了切面在什么时候使用，以及定义了切面需要做些什么。 @Before 前置通知，目标方法被调用之前执行 @After 后置通知，目标方法完成之后执行 @AfterReturning 返回通知，目标方法执行成功（未抛出异常）之后执行 @AfterThrowing 异常通知，目标方法执行失败（抛出异常）之后执行 @Around 环绕通知，目标方法执行前后都会调用 连接点（JoinPoint）程序执行的某个特定位置：如类开始初始化前、类初始化后、类满足某个方法调用前、调用后、方法抛出异常后。一个类或一段程序代码拥有一些具有边界性质的特定点，这些点中的特定点就称为“连接点”。Spring 仅支持方法的连接点，即仅能在方法调用前、方法调用后、方法抛出异常时以及方法调用前后这些程序执行点织入增强。连接点由两个信息确定：第一是用方法表示的程序执行点，第二是用相对点表示的方位。 切点（Poincut）每个程序类都拥有多个连接点，如一个拥有两个方法的类，这两个方法都是连接点，即连接点是程序中客观存在的事物。AOP 通过“切点”定位特定的连接点。连接点相当于数据库中的记录，而切点相当于查询条件。切点和连接点不是一对一的关系，一个切点可以匹配多个连接点。在 Spring 中，切点通过 org.springframework.aop.Pointcut 接口进行描述，它使用类和方法作为连接点的查询条件，Spring AOP 的规则解析引擎负责切点所设定的查询条件，找打对应的连接点。其实确切地说，不能称之为查询连接点，因为连接点是方法执行前、执行后等包括方位信息的具体程序执行点，而切点只定位到某个方法上，所以如果希望定位到具体连接点上，还需要提供方位信息。 切面（Aspect）切面由切点和增强（引介）组成，它既包括了横切逻辑的定义，也包括了连接点的定义，Spring AOP 就是负责实施切面的框架，它将切面所定义的横切逻辑织入到切面所指定的连接点中。 引入（Introduction）引入使我们具备了为类添加一些属性和方法的能力。这样，即使一个业务类原本没有实现某个接口，通过 AOP 的引介功能，我们可以动态地为该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。 织入（weaving）织入是将增强添加对目标类具体连接点上的过程。AOP 像一台织布机，将目标类、增强或引介通过 AOP 这台织布机天衣无缝地编织到一起。根据不同的实现技术，AOP 有三种织入的方式：1. 编译期织入，这要求使用特殊的Java编译器。2. 类装载期织入，这要求使用特殊的类装载器。3. 动态代理织入，在运行期为目标类添加增强生成子类的方式。Spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装载期织入。 代理（Proxy） 一个类被 AOP 织入增强后，就产出了一个结果类，它是融合了原类和增强逻辑的代理类。根据不同的代理方式，代理类既可能是和原类具有相同接口的类，也可能就是原类的子类，所以我们可以采用调用原类相同的方式调用代理类。 一个切面，如何定义呢？例如 MyServiceImplXXXX 的这种类，在这些类的所有方法中，都去织入一些代码，在所有这些方法刚开始运行的时候，都先去开启一个事务，在所有这些方法执行完毕之后，去根据是否抛出异常来判断一下，如果抛出异常，就回滚事务，如果没有异常，就提交事务。 Spring 在运行的时候，会使用动态代理技术，这也是 AOP 的核心技术，来给你的那些类生成动态代理。 1234567891011public class ProxyMyServiceA implements MyServiceA &#123; private MyServiceA myServiceA; public void doServiceA() &#123; // 开启事务 // 直接去调用我依赖的MyServiceA对象的方法 myServiceA.doServiceA(); // 根据是否抛出异常，回滚事务 or 提交事务 &#125;&#125; 那么上面的代码就可以变成这样： 123456789101112131415161718192021@Controllerpublic class MyController &#123; @Resource private MyService myServiceA; // 注入的是动态代理的对象实例，ProxyMyServiceA public void doRequest() &#123; myServiceA.doServiceA(); // 直接调用到动态代理的对象实例的方法中去 &#125;&#125;@Servicepublic class MyServiceAImpl implements MyServiceA &#123; public void doServiceA() &#123; //insert语句 //update语句 //delete语句 &#125;&#125; 下面给个简单的AOP代码的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Aspect@Componentpublic class ApiIdempotentAop &#123; @Autowired private JedisUtil jedisUtil; @Pointcut("@annotation(com.example.midx.annotation.ApiIdempotent)") public void apiIdempotentPointCut() &#123; &#125; @Around("apiIdempotentPointCut()") public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; System.err.println("进来AOP了"); Object[] args = joinPoint.getArgs(); //获取request和response ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); HttpServletResponse response = attributes.getResponse(); String requestURI = request.getRequestURI(); MethodSignature signature = (MethodSignature) joinPoint.getSignature(); ApiIdempotent annotation = signature.getMethod().getAnnotation(ApiIdempotent.class); Object result; if(annotation != null) &#123; String token = request.getHeader("token"); if (StringUtils.isBlank(token)) &#123;// header中不存在token token = request.getParameter("token"); if (StringUtils.isBlank(token)) &#123;// parameter中也不存在token throw new ServiceException("参数不合法"); &#125; &#125; if (!jedisUtil.exists(token)) &#123; System.err.println("请勿重复操作"); throw new ServiceException("请勿重复操作"); &#125; result = joinPoint.proceed(); Long del = jedisUtil.del(token); if (del &lt;= 0) &#123; throw new ServiceException("请勿重复操作"); &#125; return result; &#125; return null; &#125; @Before("execution(* com.cdc.bdom.portal..*.mapper.*Mapper.select*(..)) || execution(* com.cdc.bdom.portal..*.mapper.*Mapper.get*(..)) || execution(* com.cdc.bdom.portal..*.mapper.*Mapper.find*(..))") public void setReadDataSourceType() &#123; logger.info("调用读数据库"); DataSourceContextHolder.read(); &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx详解]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F07%2FNginx%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Nginx 简介​ Nginx是一个免费、开源、高性能、轻量级的HTTP和反向代理服务器，也是一个电子邮件（IMAP/POP3）代理服务器，其特点是占有内存少，并发能力强。 ​ Nginx由内核和一系列模块组成，内核提供Web服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。 ​ Nginx的各种功能和操作都由模块来实现。Nginx的模块从结构上分为： 核心模块：HTTP模块、EVENT模块和MAIL模块。 基础模块：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块和HTTP Rewrite模块。 第三方模块：HTTP Upstream Request Hash模块、Notice模块和HTTP Access Key模块及用户自己开发的模块。 ​ 这样的设计使Nginx方便开发和扩展，也因此才使得Nginx功能如此强大。Nginx的模块默认编译进Nginx中，如果需要增加或删除模块，需要重新编译Nginx，这一点不如Apache的动态加载模块方便。如果有需要动态加载模块，可以使用由淘宝网发起的Web服务器Tengine，在Nginx的基础上增加了很多高特定，完全兼容Nginx，已被国内很多网站采用。Nginx有很多扩展版本： 开源版nginx.org 商业版NGINX Plus 淘宝网发起的Web服务器Tengine 基于Nginx和Lua的Web平台OpenResty Nginx 作为 Web 服务器​ Web服务器也称为WWW（World Wide Web）服务器，主要功能是提供网上信息浏览服务，常常以B/S（Browser/Server）方式提供服务： 应用层使用HTTP协议 HTML文档格式 浏览器统一资源定位器（URL） ​ Nginx可以作为静态页面的Web服务器，同时还支持CGI协议的动态语言，比如Perl、PHP等，但是不支持Java。Java程序一般都是通过与Tomcat配合完成，让我们看看Nginx和Tomcat的区别。 ​ Nginx、Apache和Tomcat： Nginx：由俄罗斯程序员lgor Sysoev所开发的轻量级，高并发HTTP服务器。 Apache HTTP Server Project：一个Apache基金会下的HTTP服务项目，和Nginx功能类似。 Apache Tomcat：是Apache基金会下的另外一个项目，是一个Application Server。更准确地说是一个Servlet应用容器，与Apache HTTP Server和Nginx相比，Tomcat能够动态生成资源并且返回到客户端。 ​ Apache HTTP Server和Nginx本身不支持生成动态页面，但它们可以通过其他模块来支持（例如通过Shell、PHP、Python脚本程序来动态生成内容）。 ​ 一个HTTP Server关心的是HTTP协议层面的传输和访问控制，所以在Apache/Nginx上你可以看到代理、负载均衡等功能。客户端通过HTTP Server访问服务器上存储的资源（HTML文件、图片文件等待）。通过CGI技术，也可以将处理过的内容通过HTTP Server分发，但是一个HTTP Server始终只是把服务器上的文件如实地通过HTTP协议传输给客户端。 ​ 而应用服务器，则是一个应用执行的容器。它首先需要支持开发语言的运行（对于Tomcat来说，就是Java），保证应用能够在应用服务器上正常运行。其次，需要支持应用相关的规范，例如类库、安全方面的特性。对于Tomcat来说，就是需要提供JSP/Servlet运行需要的标准库。Interface等。 ​ 为了方便，应用服务器往往也会集成HTTP Server的功能，但是不如专业的HTTP Server那么强大。所以应用服务器往往是运行在HTTP Server的背后，执行应用，将动态的内容转化为静态的内容之后，通过HTTP Server分发到客户端。 正向代理正向代理：如果把局域网外的Internet想象成一个巨大的资源库，则局域网中的客户端要访问Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理。 正向代理“代理”的是客户端。例如你想去YouTube看个动作片，可国内不允许啊，就需要找翻墙代理，这个就是所谓的“正向代理”。 反向代理与负载均衡反向代理与正向代理相反，反向代理是指以代理服务器来接收Internet上的连接请求，然后将请求转发到内部网络上的服务器，并将服务器上得到的结果返回给客户端。此时代理服务器对外表现就是一个服务器，客户端对代理是无感知的。反向代理“代理”的是服务端。 再比如，你想在“优酷”上看个综艺，youku.com 会把你的请求分发到存放视频的那台机器上，这就是所谓的“反向代理”。 为什么使用反向代理，原因如下： 保护和隐藏原始资源服务器 加密和SSL加速 通过缓存静态资源，加速Web请求 实现负载均衡 地址重定向：Nginx的Rewrite主要的功能就是实现URL重写，比如输入360.com跳转到360.cn。 动静分离为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度，降低原来单个服务器额的压力。 这里指的就是让动态程序（Java、PHP）去访问应用服务器，让缓存、图片、JS、CSS等去访问Nginx。 Nginx 安装​ 1、下载nginx 1wget http://nginx.org/download/nginx-1.16.1.tar.gz 2、安装需要编译的插件 用于编译C、C++代码的GCC 用C语言编写的正则表达式函数库Pcre（使用Rewrite模块） 用于数据压缩的函数库Zlib 安全套接字层密码库OpenSSL（启用SSL支持） 1234yum install gcc c++ yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel 3、解压、配置（nginx支持各种配置选项）。编译、安装Nginx 1234tar -zxvf nginx-1.15.tar.gz cd nginx-1.16.1cd nginx-1.16.1./configuremake &amp;&amp; sudo make install 4、启动、重启、关闭 123456789cd /usr/local/nginx/ cd sbin./nginx#关闭命令 ./nginx -s stop#重启，热部署./nginx -s reload#修改配置文件后也别嘚瑟，反正我会动不动就写错，检查修改的nginx.conf配置是否正确./nginx -t 5、验证（浏览器输入IP） 配置文件nginx.conf配置文件主要分为三部分： 全局块 Events 块 HTTPS 块 ​ Nginx配置语法： 配置文件由指令和指令块构成 每条指令以分号（;）结尾，指令和参数间以空格符分隔 指令块以大括号{}将多条指令组织在一起 include 语句允许组合多个配置文件以提高可维护性 使用#添加注释 使用$定义变量 部分指令的参数支持正则表达式 全局块全局配置部分用来配置对整个Server都有效的参数。主要会设置一些影响 Nginx 的服务器整体运行的配置指令，包括配置运行Nginx服务器的用户（组）、允许生成的 Work Process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。示例如下： 123user nobody;worker_processes 4;error_log /data/nginx/logs/error.log notice; Events 块Events块涉及的指令主要影响Nginx服务器与用户的网络连接，常用的设置包括是否开启对多 Work Process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 Work Process 可以同时支持的最大连接数等。 1234events &#123; #每个 work process 支持的最大连接数为 1024 work_connections 1024;&#125; HTTP 块这算是Nginx服务器配置中最频繁的部分。代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。需要注意的是：HTTP 块也可以包括 HTTP 全局快、Server 块。 HTTP 全局块HTTP 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求上限等。 123456http &#123; include mime.types; default_type application/octet-stream sendfile on; keepalive_timeout 65;&#125; Server 块这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。 每个 HTTP 块可以包括多个 Server 块，而每个 Server 块就相当于一个虚拟主机。而每个 Server 块也分为全局 Server 块，以及可以同时包含多个 Location 块。 全局 Server 块：也被叫做“ 虚拟服务器 ”部分，它描述的是一组根据不同 server_name 指令逻辑分割的资源，这些虚拟服务器响应 HTTP 请求，因此都包含在 HTTP 部分。最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置。 12345server &#123; listen 80; #server_name 也支持通配符，*.example.com、www.example.*、.example.com server_name localhost;&#125; Location 块：一个 Server 块可以配置多个 Location 块。 这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称（也可以是IP别名）之外的字符串（例如前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。 Location 指令说明：该指令用于匹配 URL。语法如下：location [ = | ~ | * | ^ ] uri {} =：该修饰符使用精确匹配并且终止搜索。 ~：该修饰符使用区分大小写的正则表达式匹配。 ~*：该修饰符使用不区分大小写的正则表达式匹配。 ^~：用于不含正则表达式的 URI 前，要求 Nginx 服务器找到表示 URI 和请求字符串匹配度最高的 Location 后，立即使用此 Location 处理请求，而不再使用 Location 块中的正则 URI 和请求字符串做匹配。 注意，如果 URI 包含正则表达式，则必须要有 ~ 或者 ~* 标识。 当一个请求进入时，URI 将会被检测匹配一个最佳的 Location： 没有正则表达式的 Location 被作为最佳的匹配，独立于含有正则表达式的 Location 顺序。 在配置文件中按照查找顺序进行正则表达式匹配。在查找到第一个正则表达式匹配之后结束查找。由这个最佳的 Location 提供请求处理。 1234location / &#123; root html; index index.html index.htm;&#125; nginx.conf 详细配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293#定义Nginx运行的用户和用户组uesr www www;#nginx进程数，通常设置成和cpu的数量相等work_processes 4;#全局错误日志定义类型，[debug | info | notice | warn | error | crit]#error_log /data/nginx/logs/error.log;#error_log /data/nginx/logs/error.log notice;#日志文件存放路径 access_log path [format [buffer=size | off]]access_log /data/nginx/logs/lazyegg.com/web/access/log combinedio;#进程pid文件#pid logs/nginx.pid;#指定进程可以打开的最大描述符：数目#工作模式与连接上限#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit - n）#与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit - n的值保持一致。这是因#为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可#能超过10240了，这时会返回502错误worker_rlimit_nofile 65535;################################# events ###############################events &#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll]; epoll模型 use epoll #单个进程最大连接数（最大连接数 = 连接数 + 进程数） worker_connections 1024; #keepalive 超时时间 keepalive_timeout 60; #客户端请求头部的缓冲区大小 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致， #inactive是指经过多少时间文件没被请求后删除缓存 open_file_cache max=65535 inactive=60s; #这个指多长时间检查一次缓存的有效信息 open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述 #符一直是在缓存中打开的。如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除 open_file_cache_min_uses 1; #语法：open_file_chche_errors on | off 默认值：open_file_cache_errors off 使用 #字段：http，server，location 这个指令指定是否在搜索一个文件是否记录cache错误 open_file_cache_errors on;&#125;############################## http ###################################设定http服务器，利用它的反向代理功能提供负载均衡支持http &#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 charset utf-8; #服务器名字的hash表大小 server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小 client_header_buffer_size 32k; #客户请求头缓冲大小 large_client_header_buffers 4 64k; #允许客户端请求的最大单个文件字节数 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用 #应该设置为on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理 #速度，降低系统的负载。注意：如果图片显示不正常把这个改成off sendfile on; #开启目录列表访问，适合下载服务器，默认关闭 autoindex on; #此选项允许或禁止使用socket的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩类型，默认就已经包含了textml，所以下面就不用再写了，写了也不会有问题，但是会有一个warn gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream lazyegg.net &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weight参数表示权值，权 #值越高被分配的几率越大 server 192.168.80.121:80 weigth=3; server 192.168.80.122:80 weigth=2; server 192.168.80.123:80 weigth=3; #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按照时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况 #例如： #upstream bakend &#123; # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #&#125; #3、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session问题 #例如： #upstream bakend &#123; # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #&#125; #4、fair（第三方） #按后端服务器的相应时间来分配请求，相应时间短的优先分配 #upstream backend &#123; # server server1; # server server2; # fair; #&#125; #5、uil_hash（第三方） #按访问URL的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效 #例：在upstream中加入hash语句，server语句中不能写入weight等其他参数，hash_method #是使用的hash算法 #upstream backend &#123; # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #&#125; #tips: #upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123; # ip_hash; # server 127.0.0.1:9090 down; # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # server 127.0.0.1:7070 backup; #&#125; #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为： #1、down表示单前的server暂时不参与负载 #2、weight为weight越大，负载的权重就越大 #3、max_fails：允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4、fail_timeout：max_fails次失败后，暂停的时间。 #5、backup：其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力最轻 #nginx支持同时设置多组的负载均衡，用来给不同的server使用 #client_body_in_file_only 设置为 on，可以将client post过来的数据记录到文件中用来做debug #client_body_temp_path 设置记录文件的目录，可以设置最多3层目录 #location对URL进行匹配，可以进行重定向或者进行新的代理，负载均衡 &#125; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name lazyegg.net; #默认入口文件名称 index index.html index.htm index.php; root /data/www/lazyegg; #对******进行复制均衡 location ~ .*.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址 #$remote_user：用来记录客户端用户名称 #$time_local：用来记录访问时间与时区 #$request：用来记录请求的url与http协议 #$status：用来记录请求状态，成功是200 #$body_bytes_sent：记录发送给客户端文件主体内容大小 #$http_referer：用来记录从哪个页面链接访问过来的 #$http_user_agent：记录客户浏览器的相关信息 #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_addr拿 #到的IP地址是反向代理服务器的ip地址。范子昂代理服务器在转发请求的http头信息中，可以增加 #x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址 log_format access '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" $http_x_forwarded_for'; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 "/connect-controller"启用反向代理 location /connect_controller &#123; proxy_pass http://127.0.0.1:88 #此处端口号不能与虚拟主机监听的端口号一样 proxy_redirect off; proxy_set_header X_Real_IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded-for; #以下是一些反向代理的配置，可选 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数 #如果把它设置为比较大的数值，例如256k，那么，无论使用Firefox还是IE浏览器，来提交 #任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size #设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了 #无论使用Firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候相应超时时间 #nginx跟后端服务器连接超时时间（代理连接超时） proxy_connect_timeout 90; #后端服务器数据回传时间（代理发送超时） #后端服务器数据回传时间，就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间（代理接收超时） #连接成功后，等待后端服务器相应时间，其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #proxy_buffer缓冲区，网页平均在32k一下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也认为页大小，根据操作系统的不同可能是4K或者是8K proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件是阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; #本地动静分离反向代理配置 #所有jsp页面均交由Tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X_Real_IP $remote_addr; proxy_set_header X-Forwarded_For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; &#125; &#125; Nginx 配置实例反向代理 Demo 1实现效果：使用 nginx 反向代理，访问 www.12345.com 直接跳转到自己的机器 127.0.0.1:8080。 1、创建一个SpringBoot项目，写一个简单的Controller。 12345678@RestControllerpublic class TestController &#123; @RequestMapping(method = &#123;RequestMethod.POST, RequestMethod.GET&#125;) public String helloWorld() &#123; return "Hello World"; &#125;&#125; 启动项目后，在浏览器访问 127.0.0.1:8080，出现如下界面： 2、通过修改本地Host文件（ C:\Windows\System32\drivers\etc ），添加 127.0.0.1 www.12345.com 将 www.12345.com 映射到自己的机器IP上。 3、配置完成之后，我们便可以通过 www.12345.com:8080 访问到第一步出现的界面。 那么如何主需要输入 www.12345.com 便可以跳转到初始界面呢？这是就可以用到 nginx 的反向代理 4、修改 nginx.conf 配置文件，增加如下配置 proxy_pass: 12345678server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://127.0.0.1:8080; &#125; 5、如上配置，我们监听 80 端口，访问域名为 www.12345.com，不加端口号时默认为 80 端口，故访问该域名时会跳转到 127.0.0.1:8080 路径上。 在浏览器输入 www.12345.com 结果如下： 反向代理 Demo 2实现效果：使用 Nginx 反向代理，根据访问的路径跳转到不同端口的服务中： 访问 http://127.0.0.1/java/ 直接跳转到 127.0.0.1:8080 访问 http://127.0.0.1/egg/ 直接跳转到 127.0.0.1:8081 先启动两个 springboot 项目，其中 8080 端口的项目返回 “Hello java”，8081 的端口返回 “Hello egg”。 修改 nginx.conf，在 HTTP 块中添加 server{} : 123456789101112server &#123; listen 80; server_name localhost; location ~ /java/ &#123; proxy_pass http://127.0.0.1:8080; &#125; location ~ /egg/ &#123; proxy_pass http://127.0.0.1:8081; &#125;&#125; 重启 nginx，验证结果： Nginx 配置：负载均衡随着互联网信息的爆炸性增长，负载均衡已经不再是一个陌生的话题。顾名思义，负载均衡是将负载分摊到不同的服务单元，既保证服务的可用性，又保证相应足够块，给用户很好的体验。Nginx 的负载均衡是 Proxy 模块和 Upstream 模块搭配实现的。Upstream 模块将会启用一个新的配置区段，在改区段定义了一组上游服务器。 实现效果：配置负载均衡还是使用上次两个 springboot 的项目，其中 8080 端口 返回 “Hello java”，而 8081 端口返回 “Hello egg”。 接着，修改 nginx.conf： 123456789101112http &#123; upstream myserver &#123; server localhost:8080; server localhost:8081; &#125; server &#123; listen 80; location / &#123; proxy_pass http://myserver; &#125; &#125;&#125; 重启 Nginx，验证结果（默认轮询的方式，每次打开新窗口，8080 和 8081 会交替出现，同一个窗口的话需要关闭浏览器缓存）。 Nginx 分配策略： 轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 Down 掉，能自动剔除。 Weight ：代表权重，默认为 1，权重越高被分配的客户端越多，指定轮询几率，Weight 和访问比率成正比，用于后端服务器性能不均的情况。例如： 1234upstream server_pool &#123; server 192.168.0.1 weight=10; server 192.168.0.2 weigth=10;&#125; ip_hash：每个请求按访问 IP 的 Hash 结构分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。例如： 12345upstream server_pool &#123; ip_hash; server 192.168.0.1:80; server 192.168.0.2:80;&#125; fair（第三方）：按后端服务器的相应时间来分配请求，相应时间短的优先分配。 12345upstream server_pool &#123; server 192.068.0.1:80; server 192.168.0.2:80; fair;&#125; Nginx 配置：动静分离Nginx 动静分离简单说就是把动态和静态请求分开，不能理解成只是单纯地把动态页面和静态页面物理分离。严格意义上说应该是动态跟静态请求分开，可以理解成使用 Nginx 处理静态页面，Tomcat 处理动态页面。 动静分离从目前实现角度来说大致分为两种： 纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案； 动态跟静态文件混合在一起发布，通过 Nginx 来分开。 通过 Location 指定不同的后缀名实现不同的请求转发。通过 Expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之间的请求和流量。 具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无须去服务端验证，直接通过浏览器自身确认是否过期，所以不会产生额外的流量。此种方法非常适合不经常变动的资源（如经常更新的文件，不建议使用 Expires 来缓存） 我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码 304，如果有修改，则直接从服务器重启下载，返回状态码 200。 服务器找个目录存放自己的静态文件： 配置 Nginx： 1234567891011121314151617181920212223242526272829303132333435363738server &#123; listen 80;#端口号 server_name localhost;#本机 charset utf-8; #access_log logs/host.access.log main; location ~ .*\.(gif|jpg|jpeg|png)$ &#123; expires 24h; root /usr/data/image/;#指定图片存放路径 access_log /usr/local/websrv/nginx-1.9.4/logs/images.log;#日志存放路径 proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path /usr/data/image/;#图片访问路径 proxy_redirect off; proxy_set_header Host 127.0.0.1; client_max_body_size 10m; client_body_buffer_size 1280k; proxy_connect_timeout 900; proxy_send_timeout 900; proxy_read_timeout 900; proxy_buffer_size 40k; proxy_buffers 40 320k; proxy_busy_buffers_size 640k; proxy_temp_file_write_size 640k; if ( !-e $request_filename) &#123; proxy_pass http://127.0.0.1;#默认80端口 &#125; &#125; location / &#123; root /home/html; #html访问路径 index index.html index2.htm; #html文件名称 &#125;&#125; 重启 Nginx，验证结果： Nginx 的 RewriteRewrite 是 Nginx 服务器提供的一个重要的功能，它可以实现 URL 重写和重定向功能。 场景如下： URL 访问跳转，支持开发设计。页面跳转、兼容性支持（新旧版本更迭）、展示效果（网址精简）等 SEO 优化（Nginx 伪静态的支持） 后台维护、流量转发 安全（动态界面进行伪装） 该指令是通过正则表达式的使用来改变 URI。可以同时存在一个或多个指令。需要按照顺序依次对 URI 进行匹配和处理。 采用反向代理 Demo2 中的例子，修改 nginx.conf（只多加一行 rewrite） 12345678910111213server &#123; listen 80; server_name localhost; location /java/ &#123; proxy_pass http://127.0.0.1:8080; rewrite ^/java /egg/ redirect; &#125; location /egg/ &#123; proxy_pass http://127.0.0.1:8081; &#125;&#125; 重启 nginx，验证结果（输入 ip/java/ 被重定向到 egg）： Rewrite 指令可以在 Server 块或 Location 块中配置，其基本语法结构如下： 1rewrite regex replacement [flag]; rewrite 的含义：该指令是实现 URL 重写的指令。 regex 的含义：用于匹配 URI 的正则表达式。 replacement：将 regex 正则匹配到的内容替换成 replacement。 flag：flag 标记 flag 有如下值： last：本条规则匹配完成后，继续向下匹配新的 Location URI 规则（不常用）。 break：本条规则匹配完成即终止，不再匹配后面的任何规则（不常用）。 redirect：返回 302 临时重定向，浏览器地址会显示新的 URL地址。 permanent：返回 301 永久重定向。浏览器会显示跳转新的 URL 地址。 1rewrite ^/(.*) http://www.360.cn/$1 permanent; Nginx 高可用如果将 Web 服务器集群当做一个城池，那么负载均衡服务器就相当于城门。如果“城门”关闭了，与外界的通道就断了。如果只有一台 Nginx 复制均衡器，当故障宕机的时候，就会导致整个网站无法访问。所以我们需要两台以上的 Nginx 来实现故障转移和高可用。那么如何实现？ 双机热备方案这种方案是国内企业中最为普遍的一种高可用方案，双机热备其实就是指一台服务器在提供服务，另一台为某服务的备用状态，当一台服务器不可用时另一台就会顶替上去。 Keepalived 是什么？Keepalived 软件起初是转为 LVS 负载均衡软件设计的，用来管理并监控 LVS 集群系统中各个服务节点的状态。后来又加入了可以实现高可用的 VRRP（Virtual Router Redundancy Protocol，虚拟路由器冗余协议）功能。因此，Keepalived 高可用服务之间的故障切换转移，是通过 VRRP 来实现的。 故障转移机制Keepalived 高可用服务之间的故障切换转移，是通过 VRRP 来实现的。 在 Keepalived 服务正常工作时，主 Master 节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉 Backup 节点自己还活着。 当主 Master 节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master 节点的心跳了，于是调用自身的接管程序，接管主 Master 节点的 IP 资源及服务。 而当主 Master 节点恢复时，背 Backup 节点又会释放主节点故障时自身接管的 IP 资源及服务，恢复到原来的备用角色。 实现方法如下： 准备两台安装 Nginx 和 Keepaliver（yum install keepalived -y）的服务器 修改两台服务器上的 /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526#主机#检测脚本vrrp_script chk_http_port &#123; script "/usr/local/src/check_nginx.sh" #心跳执行的脚本，检测nginx是否启动 interval 2 #（检测脚本执行的间隔，单位是秒） weight 2 #权重&#125;#vrrp 实例定义部分vrrp_instance VI_1 &#123; state MASTER # 指定keepalived的角色，MASTER为主，BACKUP为备 interface ens33 # 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡 virtual_router_id 66 # 虚拟路由编号，主从要一直 priority 100 # 优先级，数值越大，获取处理请求的优先级越高 advert_int 1 # 检查间隔，默认为1s(vrrp组播周期秒数) #授权访问 authentication &#123; auth_type PASS #设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信 auth_pass 1111 &#125; track_script &#123; chk_http_port #（调用检测脚本） &#125; virtual_ipaddress &#123; 192.168.16.150 # 定义虚拟ip(VIP)，可多设，每行一个 &#125;&#125; 1234567891011121314151617181920212223242526# 备机#检测脚本vrrp_script chk_http_port &#123; script "/usr/local/src/check_nginx.sh" #心跳执行的脚本，检测nginx是否启动 interval 2 #（检测脚本执行的间隔） weight 2 #权重&#125;#vrrp 实例定义部分vrrp_instance VI_1 &#123; state BACKUP # 指定keepalived的角色，MASTER为主，BACKUP为备 interface ens33 # 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡 virtual_router_id 66 # 虚拟路由编号，主从要一直 priority 99 # 优先级，数值越大，获取处理请求的优先级越高 advert_int 1 # 检查间隔，默认为1s(vrrp组播周期秒数) #授权访问 authentication &#123; auth_type PASS #设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信 auth_pass 1111 &#125; track_script &#123; chk_http_port #（调用检测脚本） &#125; virtual_ipaddress &#123; 192.168.16.150 # 定义虚拟ip(VIP)，可多设，每行一个 &#125;&#125; 新建检测脚本（chmod 775 check_nginx.sh）： 123456789#!/bin/bash#检测nginx是否启动了A=`ps -C nginx --no-header |wc -l` if [ $A -eq 0 ];then #如果nginx没有启动就启动nginx systemctl start nginx #重启nginx if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then #nginx重启失败，则停掉keepalived服务，进行VIP转移 killall keepalived fifi 启动 Nginx 和 Keepalived（systemctl start keepalived.service） 模拟 Nginx 故障（关闭主服务器 Nginx），验证，仍可以通过配置的虚拟 IP 访问，OK Nginx 原理与优化参数配置Nginx 默认采用多进程工作方式，Nginx 启动后，会运行一个 Master 进程和多个 Worker 进程。 其中 Master 充当整个进程组与用户的交互接口，同时对进程进行监护，管理 Worker 进程来实现重复服务、平滑升级、更护日志文件、配置文件实时生效等功能。 Worker 用来处理基本的网络事件，Worker 之间是平等的，他们共同竞争来处理来自客户端的请求。 master-worker 的机制的好处： 可以使用 nginx -s reload 热部署 每个 Worker是独立的进程，不需要加锁，省掉了锁带来的开销。采用独立的进程，可以让互相之间不会影响。一个进程退出后，其他进程还在工作，服务不会中断，Master 进程则很快启动新的 Worker 进程。 需要设置多少个 Worker？Nginx 同 Redis 类似都采用了 IO 多路复用机制，每个 Worker 都是独立的进程，但每个进程里只有一个主线程，通过异常非阻塞的方式来处理请求，即使是成千上万个请求也不在话下。 每个 Worker 的线程可以把一个 CPU 的性能发挥到极致。所以 Worker 数和服务器的 CPU 数相等是最为适宜的。设少了浪费 CPU，设多了会造成 CPU 频繁切换上下文带来的损耗。 123456#设置 worker 数量。 worker_processes 4 #work 绑定 cpu(4 work 绑定 4cpu)。 worker_cpu_affinity 0001 0010 0100 1000 #work 绑定 cpu (4 work 绑定 8cpu 中的 4 个) 。 worker_cpu_affinity 0000001 00000010 00000100 00001000 连接数 worker_connection：这个值是表示每个 Worker 进程所能建立连接的最大值。所以，一个 Nginx 能建立的最大连接数，应该是 worker_connections * worker_processes。 当然这里说的是最大连接数，对于 HTTP 请求本地资源来说，能够支持的最大并发数量是 worker_connections * worker_process，如果是支持 http1.1 的浏览器，每次访问要占两个连接，所以普通的静态访问最大并发数是：worker_connections * worker_processes / 2。 而如果是 HTTP 作为反向代理来说，最大并发数量应该是 worker_connections * worker_processes / 4，因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。 Nginx 总结Nginx 在项目中的作用反向代理服务器 实现负载均衡 做静态资源服务器 作为 HTTP Server Nginx 常用的命令1234567启动nginx ./sbin/nginx停止nginx ./sbin/nginx -s stop ./sbin/nginx -s quit重载配置 ./sbin/nginx -s reload(平滑重启) service nginx reload重载指定配置文件 ./sbin/nginx -c /usr/local/nginx/conf/nginx.conf查看nginx版本 ./sbin/nginx -v检查配置文件是否正确 ./sbin/nginx -t显示帮助信息 ./sbin/nginx -h Nginx 如何实现高并发Nginx 采用的是多进程（单线程）&amp; 多路 IO 复用模型，异步，非阻塞。 一个主进程 Master，多个工作进程 Worker，每个工作进程可以处理多个请求，Master 进程主要负责收集、分发请求。每当一个请求过来时，Master 就会拉起一个 Worker 进程负责处理这个请求。同时Master进程也复制监控Work的状态，保证高可用性。 在 Nginx 中的 Work 进程中，为了应对高并发场景，采取了 Reactor 模型（也就是 I/O 多路复用，NIO）。 I/O 多路复用模型：在 I/O 多路复用模型中，最重要的就是系统调用 Select 函数。该方法能够同时监控多个文件描述符的可读可写情况（每一个网络连接其实都对应一个文件描述符），当其中的某些文件描述符可读可写时，Select 方法就会返回可读以及可写的文件描述符个数。 Nginx Work 进程使用 I/O 多路复用模块同时监听多个 FD（文件描述符）。当 Accept、Read、Write 和 Close 事件产生时，操作系统就会回调 FD 绑定的事件处理器。这时候 Work 进程再去处理相应事件，而不是阻塞在某个请求连接上等待。这样就可以实现一个进程同时处理多个连接。每一个 Worker 进程通过 I/O 多路复用处理多个连接请求。 为了减少进程切换（需要系统调用）的性能损耗，一般设置 Worker 进程数量和 CPU 数量一致。 Nginx 和 Apache 的区别轻量级，同样是 Web 服务，比 Apache 占用更少的内存及资源抗并发，Nginx 处理请求是异步非阻塞的，而 Apache 则是阻塞型的。 在高并发下 Nginx 能保持低资源低消耗高性能高度模块化的设计，编写相对简单，最核心的区别在于 Apache 是同步多线程模型，一个连接对应一个进程；Nginx 是异步的，多个连接（万级别）可以对应一个进程。 Nginx 的 upstream 支持的负载均衡模式 轮询 weight：指定权重 ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访问固定访问一个后台服务器 第三方：fair、url_hash Nginx 常见的优化配置 调整 worker_processes：指 Nginx 要生成的 Worker 数量。最佳实践是每个 CPU 运行 1 个工作进程。 最大化 worker_connections。 启用 Gzip：压缩文件大小，减少客户端 HTTP 的传输带宽，因此提高了页面加载速度。 为静态文件启用缓存。 禁用 access_logs：访问日志记录，它记录每个 Nginx 请求，因此消耗了大量 CPU 资源，从而降低了 Nginx 性能。 参考资料Nginx 的这些妙用，你都 get 到了吗]]></content>
      <categories>
        <category>NGINX</category>
      </categories>
      <tags>
        <tag>NGINX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F06%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式的动机对于一个系统的某些类而言，无须创建多个实例。举个例子– Windows 任务管理器、在正常情况下，无论启动任务管理器多少次，Windows 系统始终只能弹出一个任务管理器窗口。也就是说，在一个Windows 系统中，任务管理器存在唯一性。这样设计有两个原因：第一，如果能弹出多个窗口，且这些窗口的内容完全一致，全部是重复对象，这势必会浪费系统资源（任务管理器需要获取系统运行时的诸多信息，这些信息的获取需要消耗一定的系统资源，包括 CPU 资源及内存资源等），而且根本没有必要显示多个内容完全相同的接口；第二，如果弹出的多个窗口不一致，问题就更加严重了，这意味着在某一瞬间系统资源使用情况和进程。服务等信息存在多个状态，例如任务管理器窗口 A 显示“CPU 使用率”为 10%，窗口B显示“CPU 使用率”为 15%，到底哪个才是正确的？这会给用户带来误解，更不可取。由此可见，确保 Windows 任务管理器在系统中有且仅有一个非常重要。 在实际开发中也经常遇到类似的情况，为了节约系统资源，有时需要确保系统中某个类只有唯一一个实例，当这个唯一实例创建成功之后，无法再创建一个同类型的其他对象，所有的操作都只能基于这个唯一实例。为了确保对象的唯一性，可以通过单例模式来实现，这就是单例模式的动机所在。 单例模式概述下面来模拟实现 Windows 任务管理器。假设任务管理器的类名为 TaskManager，在 TaskManager 类中包含了大量的成员方法，例如构造函数 TaskManager()，显示进程的方法 displayProcesses()，显示服务的方法 displayServices()等，该类的示意代码如下： 123456789101112131415161718class TaskManager&#123; // 初始化窗口 public TaskManager() &#123; ... &#125; // 显示进程 public void displayProcesses() &#123; ... &#125; // 显示服务 public void displayServices() &#123; ... &#125; ...&#125; 为了实现 Windows 任务管理器的唯一性，通过以下3步对TaskManager类进行重构： （1）由于每次使用 new 关键字来实例化 TaskManager 类时都将产生一个新对象，为了确保 TaskManager 实例的唯一性，需要禁止类的外部直接引用使用 new 来创建对象，因此需要将 TaskManager 的构造函数的可见性改为 private，如下 1private TaskManager() &#123; ... &#125; （2）将构造函数的可见性改为 private 后，虽然类的外部不能在使用 new 来创建对象，但是在 TaskManager 的内部还是可以创建对象的，可见性只对类外有效。因此，可以在 TaskManager 中创建并保存这个唯一实例。为了让外界可以访问这个唯一实例，需要在 TaskManager 中定义一个静态的 TaskManager 类型的私有变量，代码如下： 1private static TaskManager tm = null; （3）为了保证成员变量的封装性，将 TaskManager 类型的 tm 对象的可见性设置为 private，但外界该如何使用该成员变量并何时实例化该成员变量呢？答案是增加一个工友的静态方法，如下： 123456public static TaskManager getInstance() &#123; if (tm == null) &#123; tm = new TaskManager(); // 自行实例化 &#125; return tm;&#125; 在 getInstance() 方法中首选判断 tm 对象是否存在，如果不存在，则使用 new 关键字创建一个新的 TaskManager 类型的 tm 对象，再返回新创建的 tm 对象；否则直接返回已有的 tm 对象。需要注意的是 getInstance() 方法的修饰符。 首先它应该是一个 public 方法，以便外界其他对象使用；其次它使用了 static 关键字，即它是一个静态方法，在类外可以直接通过类名来访问，而无须创建 TaskManager 对象。事实上，在类外也无法创建 TaskManager 对象，因为构造函数是私有的。最终整合的代码如下： 12345678910111213class TaskManager &#123; private static TaskManager tm = null; private TaskManager() &#123; ... &#125; // 初始化窗口 public void displayProcesses() &#123; ... &#125; // 显示进程 public void displayServices() &#123; ... &#125; // 显示服务 public static TaskManager getInstance() &#123; if(tm === null) &#123; tm = new TaskManager(); &#125; return tm; &#125;&#125; 上述代码是单例模式的一种最典型实现方式，有了以上基础，理解单例模式的定义和结构就非常容易了。单例模式定义如下： 单例模式：确保某一个类只有一个实例，而且自行实例化并向这个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。单例模式是一种对象性创建模式。 单例模式有 3 个要点：（1）某个类只有有一个实例；（2）它必须自行创建这个实例；（3）它必须自行向整个系统提供这个实例。单例模式的结构图如图所示： 负载均衡器的设计Sunny 软件公司承接了一个服务器负载均衡（Load Balance）软件的开发工作，该软件运行在一台负载均衡服务器上，可以将并发访问和数据流量分发到服务器集群中的多台设备上进行并发处理，提高系统的整体处理能力。由于集群汇总的服务器需要动态删减，且客户端请求需要统一分发，因此需要确保负载均衡器的唯一性，即只能有一个负载均衡器来负责服务器的管理和请求的分发，否则会带来服务器状态的不一致以及请求分配冲突等问题。 Sunny 公司开发人员通过分析和权衡，决定使用单例模式来设计该负载均衡器。将负载均衡器 LoadBalancer 设计为单例类，其中包含一个存储服务器信息的集合 serverList，每次在 serverList 中随机选择一台服务器来相应客户端的请求，实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 负载均衡器 LoadBalancer:单例类，真实环境该类非常复杂，包括大量初始化的工作和 * 业务方法，考虑到代码的可读性和易理解性，只列出部分与模式相关的核心代码 */public class LoadBalancer &#123; // 私有静态成员变量，存储唯一实例 private static LoadBalancer instance = null; // 服务器集合 private List serverList = null; private LoadBalancer() &#123; serverList = new ArrayList(); &#125; public static LoadBalancer getLoadBalancer() &#123; if (instance == null) &#123; instance = new LoadBalancer(); &#125; return instance; &#125; /** * 增加服务器 * @param server */ public void addServer(String server) &#123; serverList.add(server); &#125; /** * 删除服务器 * @param server */ public void removeServer(String server) &#123; serverList.remove(server); &#125; /** * 使用 Random 类随机获取服务器 * @return */ public String getServer() &#123; Random random = new Random(); int i = random.nextInt(serverList.size()); return (String) serverList.get(i); &#125;&#125; 1234567891011121314151617181920212223242526272829public class Client &#123; public static void main(String[] args) &#123; // 创建 4 个 LoadBalancer 对象 LoadBalancer balancer1, balancer2, balancer3, balancer4; balancer1 = LoadBalancer.getLoadBalancer(); balancer2 = LoadBalancer.getLoadBalancer(); balancer3 = LoadBalancer.getLoadBalancer(); balancer4 = LoadBalancer.getLoadBalancer(); // 判断服务器复制均衡器是否相同 if (balancer1 == balancer2 &amp;&amp; balancer2 == balancer3 &amp;&amp; balancer3 == balancer4) &#123; System.out.println("服务器负载均衡器具有唯一性"); &#125; // 增加服务器 balancer1.addServer("Server 1"); balancer1.addServer("Server 2"); balancer1.addServer("Server 3"); balancer1.addServer("Server 4"); // 模拟客户端请求的分发 for(int i = 0; i &lt; 10; i++) &#123; String server = balancer1.getServer(); System.out.println("分发请求至服务器： " + server); &#125; &#125;&#125; 编译并运行程序，输出结果如下： 虽然创建了 4 个 LoadBalancer 对象，但是它们实际上是同一个对象，因此，通过使用单例模式可以确保 LoadBalancer 对象的唯一性。 饿汉式单例与懒汉式单例的讨论Sunny 公司开发人员使用了单例模式实现了负载均衡器的设计，但是在实际使用中出现了一个非常严重的问题，当负载均衡器在启动过程中用户再次启动负载均衡器时，系统无任何异常，但当客户端提交请求时出现请求分发失败，通过仔细分析发现原来系统中还是存在多个负载均衡器对象导致分发时目标服务器不一致，从而产生冲突。为什么会这样？ 现在对负载均衡器的实现代码进行再次分析，当第一次调用 getLoadBalancer() 方法创建并启动负载均衡器时， instance 对象为 null 值，因此系统将执行代码 instance = new LoadBalancer()，在此过程中，由于要对 LoadBalancer 进行大量初始化工作，需要一段时间来创建 LoadBalancer 对象。而在此时，如果再一次调用 getLoadBalancer() 方法（通常发生在多线程环境中），由于 instance 尚未创建成功，仍为 null 值，判断条件 instance == null 为真值，因此代码 instance = new LoadBalancer() 将再次执行，导致最终创建了多个 instance 对象，这违背了单例模式的初衷，也导致系统发生运行错误。 如何解决该问题？至少有两种解决方案，在此之前，先介绍一下单例类的两种不同实现方式—饿汉式单例类和懒汉式单例类 饿汉式单例类饿汉式单例类是实现起来最容易的单例类，其代码如下： 12345678class EagerSingleton &#123; private static final EagerSingleton instance = new EagerSingleton(); private EagerSingleton() &#123;&#125; public static EagerSingleton getInstance() &#123; return instance; &#125;&#125; 当类被加载时，静态变量 instance 会被初始化，此时类的私有构造函数会被调用，单例类的唯一实例将被创建。如果使用饿汉式单例类实现负责均衡器 LoadBalancer 类的设计，则不会创建出多个单例对象的情况，可确保单例对象的唯一性。 懒汉式单例类与线程锁定除了饿汉式单例，还有一种经典的懒汉式单例，就是前面的负载均衡器 LoadBalancer 类的实现方式。由之前的代码可以看出，懒汉式单例在第一次调用 getInstance() 方法时实例化，在类加载时并不自行实例化，这种技术又称为延迟加载技术，即需要的时候再加载实例，为了避免多个线程同时调用 getInstance() 方法，可以使用关键字 synchronized，代码如下： 123456789101112class LazySingleton &#123; private static LazySingleton instance = null; private LazySingleton() &#123;&#125; synchronized public static LazySingleton getInstance() &#123; if (instance == null) &#123; instance = new LazySingleton(); &#125; return instance; &#125;&#125; 该懒汉式单例类在 getInstance() 方法面前增加了关键字 synchronized 进行线程锁定，以处理多个线程同时访问的问题。上述代码虽然解决了线程安全问题，但是每次调用 getInstance() 时都需要进行线程锁定判断，在多线程高并发访问环境中，将会导致系统性能大大降低。继续对懒汉式单例进行改进，事实上，无须对整个 getInstance() 方法进行锁定，只需锁定代码 instance = new LazySingleton() 即可。如下： 12345678public static LazySingleton getInstance() &#123; if (instance == null) &#123; synchronized (LazySingleton.class) &#123; instance = new LazySingleton(); &#125; &#125; return instance;&#125; 其实这样子也没有解决问题。原因如下：如果某一瞬间线程 A 和线程 B 都在调用 getInstance() 方法，此时 instance 对象为 null 值，均能通过 instance == null 的判断，由于实现了 synchronized 加锁机制，线程 A进入synchronized 锁定的代码中执行实例创建代码。但当 A 执行完毕时，线程 B并不知道实例已经创建，将继续创建新的实例，导致产生多个单例对象，因此需要进一步改进，在synchronized 锁定代码中再进行一次 instance == null 判断，这种方式称为双重检查锁定。完整代码如下： 12345678910111213141516171819class LazySingleton &#123; private volatile static LazySinleton instance = null; private LazySingleton() &#123;&#125; public static LazySingleton getInstance() &#123; // 第一重判断 if (instance == null) &#123; // 锁定代码块 synchronized(LazySingleton.class) &#123; // 第二重判断 if (instance == null) &#123; instance = new LazySingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 需要注意的是，如果使用双重检查锁定来实现懒汉式单例类，需要在静态成员变量 instance 之前增加修饰符 volatile，被 volatile 修饰的成员变量可以确保多个线程都能够正确处理，且该代码只能在 JDK 1.5 及以上版本才能正确执行。由于 volatile 关键字会屏蔽 Java 虚拟机所做的一些代码优化，可能会导致系统运行效率降低，因此使用双重检查来实现单例模式也不是一种完美的实现方式。 饿汉式单例类与懒汉式单例类比较饿汉式单例类在类被加载时就将自己实例化，它的优点在于无须考虑多线程访问问题，可以确保实例的唯一性；从调用速度和反应时间来说，由于单例对象一开始就得以创建，因此要优于懒汉式单例。但是无论系统在运行时是否需要使用该单例对象，由于在类加载时该对象就需要创建，因此从资源利用效率角度来讲，饿汉式单例不及懒汉式单例，而且在系统加载时由于需要创建饿汉式单例对象，加载时间可能会比较长。 懒汉式单例类在第一次使用时创建，无须一直占用系统资源，实现了延迟加载，但是必须处理好多个线程同时访问的问题，特别是当单例类作为资源控制器，在实例化时必然涉及资源初始化，而资源初始化很有可能耗费大量时间，这意味着出现多线程同时首次引用此类的几率变得比较大，需要通过双重检查锁定机制进行控制，这将导致系统性能受到一定影响。 一种更好的单例实现方法饿汉式单例类不能实现延迟加载，不管将来用不用，它始终占据内存；懒汉式单例类线程安全控制烦琐，而且性能受影响。无论是饿汉式单例还是懒汉式单例都存在问题，接下来就介绍一种更好的方法，称之为 Initialization on Demand Holder（IoDH）。 实现 IoDH 时，需在单例类中增加一个静态内部类，在该内部类中创建单例对象，再将该单例对象通过 getInstance() 方法返回给外部使用，代码如下： 123456789101112131415161718192021class Singleton &#123; private Singleton() &#123; &#125; private static class HolderClass&#123; private static final Singleton instance = new Singleton(); &#125; public static Singleton getInstance() &#123; return HolderClass.instance; &#125; public static void main(String args[]) &#123; Singleton s1, s2; s1 = Singleton.getInstance(); s2 = Singleton.getInstance(); System.out.println(s1 == s2); &#125;&#125; 编译并运行上述代码，运行结果为 true，即创建的单例对象 s1 和 s2 为同一对象。由于静态单例对象没有作为 Singleton 的成员变量直接实例化，因此类加载时不会实例化 Singleton，第一次调用 getInstance() 时将加载内部类 HolderClass，在该内部类中定义了一个 static 类型的变量 instance，此时会首先初始化这个成员变量，由 Java 虚拟机来保证其线程安全性，确保该成员变量只能初始化一次。由于 getInstance() 方法没有任何线程锁定，因此其性能不会造成任何影响。 通过使用 IoDH，既可以实现延迟加载，又可以保证线程安全，不影响系统性能，因此，IoDH不失为一种比较好的 Java 语言单例模式实现方式；其缺点是与编程语言本身的特性相关，很多面向对象语言不支持 IoDH。 单例模式总结单例模式作为一种目标明确，结构简单，理解容易的设计模式，在软件开发中使用频率相当高，在很多应用软件和框架中得以广泛应用。 主要优点 单例模式提供了对唯一实例的受控访问。因为单例类封装了它的唯一实例，所以它可以严格控制客户怎样以及何时访问它。 由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象，单例模式无疑可以提高系统的性能。 允许可变数目的实例。基于单例模式，开发人员可以进行扩展，使用与控制单例对象相似的方法来获得指定个数的实例对象，既节省资源系统，又解决了由于单例对象共享过多有损性能的问题。 主要缺点 由于单例模式中没有抽象层，因此单例类的扩展有很大的困难。 单例类的职责过重，在一定程度上违背了单一原则。因为单例类既提供了业务方法，又提供了创建对象的方法（工厂方法），将对象的创建和对象本身的功能耦合在一起。 很多面向对象语言的运行环境都提供了自动垃圾回收技术，因此，如果实例化的共享对象长时间不被利用，系统会认为它是垃圾，会自动销毁并回收资源，下次利用时又将重新实例化，这将导致共享的单例对象状态的丢失。 使用场景 系统只需要一个实例对象。例如，系统要求提供一个唯一的序列号生成器或资源管理器，或者需要考虑资源消耗太大而只允许创建一个对象。 客户调用类的单个实例只允许使用一个公共访问点，除了该公共访问点，不能通过其他途径访问该实例。 参考资料《设计模式的艺术——软件开发人员内功修炼之道》 – 刘伟]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之jstat案例分析-Young GC]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F02%2FJVM%E4%B9%8Bjstat%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-Young-GC%2F</url>
    <content type="text"><![CDATA[百万级商机的BI系统​ 有这么一个场景，有一个服务于百万级商机的BI系统。所谓BI系统，简单来说，就是一个平台有数十万深圳上百万的商家在你的平台上做生意，会使用你的这个平台系统，此时会产生大量的数据。然后基于这些数据我们需要为商家提供一些数据报表，比如：每个商家每天有多少访客？有多少交易？付费转化率是多少？当然实际情况会比这个更复杂，这里只是说个概念。 ​ 此时就需要一套BI系统，所谓BI，全称是Business Intelligence，就是“商业智能”。就是把一些商家平时日常经营的数据收集起来进行分析，然后把各种数据报表展示给商家的一套系统。而所谓的商业智能，指的就是给你看一些数据报表，然后让你平时更好地了解自己的经营情况，然后让老板“智能”地去调整经营策略，提升业绩。 ​ 所以类似这样的一个BI系统，大致的运行逻辑如下所示： 首先，从我们提供给商家日常使用的一个平台上会采集出来很多商家日常经营的数据； 接着可以对这些经营数据依托各种大数据计算平台，比如Hadoop、Spark、Flink等技术进行海量数据的计算，计算出各种各样的数据报表； 然后我们需要将计算好的各种数据分析报表都放入一些存储中，比如MySQL、Elasticsearch、HBase都可以存放类似的数据； 最后，就是基于MySQL、HBase、Elasticsearch中存储的数据报表，基于Java开发出来一个BI系统，通过这个系统把各种存储好的数据暴露给前端，允许前端基于各种条件对存储的数据进行复杂的筛选和分析。 ​ 这个流程如图所示： 刚开始上线时的架构部署​ 我们这里重点作为案例分析的就是上述场景中的“BI系统”，其他环节都跟大数据相关的技术有关联的，暂时先不care。 ​ 刚开始的时候BI系统使用的商家是不多的，因为即使在一个庞大的互联网大厂里，虽然大厂本身积累了大量商家，但是要针对他们上线一个付费产品，刚开始未必所有人都买账，所以一开始系统上线就少数商家在使用，比如就几千个商家。 ​ 刚开始系统部署非常简单，就是用几台机器来部署上述的BI系统，机器都是普通的4核8G配置。在这个配置下，一般来说给堆内存中的新生代分配的内存都在1.5G左右，Eden区大概也就1G左右的空间，如图： 技术痛点：实时自动刷新报表 + 大数据量报表​ 刚开始，在少数商家的量级下，这个系统是没多大问题，运行的非常良好。但是问题恰恰就出在突然使用系统的商家数量开始暴涨的时候，突然使用系统的商家开始越来越多，例如，当商家的数量级达到几万的时候。此时要给大家说明一个此类BI系统的特点，就是在BI系统中有一种数据报表，它是支持前端页面有一个JS脚本，自动每隔几秒钟就发送请求到后台刷新一下数据的，这种报表称之为“实时数据报表” ​ 那么大家设想一下，假设仅仅就几万商家作为你的系统用户，很可能同一时间打开那个实时报表的商家就有几千个，然胡每个商家打开实时报表后，前端页面都会每隔几秒钟发送请求到后台加载最新数据，基本上会出现BI系统部署的每台机器每秒的请求会达到几百个，这里我们假设就是每秒500个请求吧。然后每个请求都会加载出来一张报表需要的大量数据，因为BI系统可能还需要针对那些数据进行内存中的现场计算加工一下，才能返回给前端页面展示，根据我们之前的测算，每个请求大概需要加载出来100KB的数据进行计算，因此每秒500个请求，就需要记载出来50MB的数据到内存中进行计算，如图： 没什么大影响的频繁Young GC​ 在上述系统运行模型下，基本上每秒会加载50MB的数据到Eden区中，只要区区20s，就会迅速填满Eden区，然后触发一次Young GC对新生代进行垃圾回收。当然1G左右的Eden进行Young GC速度相对是比较快的，可能也就几十ms的时间就可以搞定了。所以其实对系统性能影响并不大，而且上述BI系统场景下，基本上每次Young GC后存活对象可能就几十MB，甚至是几MB。 ​ 所以如果仅仅只是这样的话，那么大家可能会看到如下场景，BI系统运行20s过后，就会突然卡顿个10ms，但是对终端用户和系统性能几乎是没有影响的。 模拟频繁Young GC场景​ 接着我们会用一段程序来模拟上述BI系统那种频繁Young GC的一个场景，此时JVM参数如下所示： 1-XX:NewSize=104857600 -XX:MaxNewSize=104857600 -XX:InitialHeapSize=209715200 -XX:MaxHeapSize=209715200 -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=3145728 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log ​ 大家只要注意一下上述我们把堆内存设置为了200MB，把年轻代设置为了100MB，然后Eden区是80MB，每块Survivor区是10MB，老年代也是100MB。我们把案例中的内存大小适当缩小了一些，这样方便在本地电脑进行试验。 示例程序123456789101112131415161718public class Demo1 &#123; public static void main(String[] args) throws Exception &#123; Thread.sleep(30000); while (true) &#123; loadData(); &#125; &#125; private static void loadData() throws Exception &#123; byte[] data = null; for(int i = 0; i &lt; 50; i++) &#123; data = new byte[100 * 1024]; &#125; data = null; Thread.sleep(1000); &#125;&#125; ​ 针对这段示例程序给大家做一点说明。首先看第一行代码：Thread.sleep(30000);。这里刚开始休眠30s，是为了启动程序后，让我们找到这个程序的PID，也就是进行ID，然后再执行jstat命令来观察运行时的JVM的状态。 ​ 接着看loadData()方法内的代码，它会循环50次，模拟每秒50个请求，然后互每次请求都会分配一个100KB的数组，模拟每次请求会从存储中加载100KB的数据，接着会休眠1秒钟，模拟这一切都是发生在1秒内的。其实这些对象都是短生存周期的对象，所以方法运行结束直接对象都是垃圾，随时可以回收的。然后在main()方法里有一个while(true)循环，模拟系统按照每秒钟50个请求，每个请求加载100KB数据的方式不停地运行，除非我们手动终止程序，否则永不停歇。 通过jstat观察程序的运行状态​ 接着我们使用预定的JVM参数启动程序，此时程序会先进入一个30秒的休眠状态，此时尽快执行JPS命令，查看一下我们启动程序的进程ID，如下图： ​ 此时会发现我们运行的Demo1这个程序的JVM进程ID是51464，然后尽快执行下述jstat命令：jstat -gc 51464 1000 1000。它的意思是针对51464这个进程统计JVM运行状态，同时每隔1秒钟打印一次统计信息，连续打印1000次。然后我们就让jstat开始统计运行，每隔一秒它都会打印一行新的统计信息，过了几十秒后可以看到如下图所示的统计信息： ​ 接着我们一点点来分析这个图。首先我们先看如下图所示的一段信息： ​ 这个EU，就是之前我们所说的Eden区被使用的容量，可以发现它刚开始是3MB左右的内存使用量。接着从我们程序开始运行，会发现每秒钟都会有对象增长，从3MB左右到7MB左右，接着是12MB，17MB，22MB，每秒都会新增5MB左右的对象。这个跟我们写的代码是完全吻合的，我们就是每秒钟会增加5MB左右的对象。然后当Eden区使用量达到70多MB的时候，再要分配5MB的对象就失败了，此时就会触发一次Young GC，然后大家继续看下图： ![Young GC](JVM之jstat案例分析-Young-GC/Young GC.png) ​ 注意看上面红圈里的内容，大家会发现，Eden区的使用量从70多MB降低为1MB多，这就是因为一次Young GC直接回收掉了大部分对象。所以我们现在就知道了，针对这个代码示例，可以清晰地从jstat中看出来，对象增速大致为5MB每秒，大致在十几秒左右会触发一次Young GC。这就是Young GC的触发频率，以及每次Young GC的耗时。接着看下图： ​ 上图清晰告诉你，一次Young GC回收70多MB对象，大概就1毫秒，所以Young GC其实是很快的，即使回收800MB的对象，也就10毫秒那样。所以如果是线上系统，Eden区800MB的话，每秒新增对象50MB，十多秒一次Young GC，也就10毫秒左右，系统卡顿10毫秒，几乎没什么大影响。所以我们继续推论，在这个示例中，80MB的Eden区，每秒新增对象5MB，大概十多秒触发一次Young GC，每次Young GC耗时在1毫秒左右。 ​ 那么每次Young GC过后存活的对象呢？简单看上图，S1U就是Survivor中被使用的内存，之前一直都是0，在一次Young GC过后变成了675KB，所以一次Young GC后也就存活675KB的对象而已，轻松放入10MB的Survivor中。 ​ 而且大家注意上上图中的OU，那是老年代被使用的内存量，在Young GC前后都是0。说明这个系统运行良好，Young GC都不会导致对象进入老年代，这就几乎不需要什么优化了，因为几乎可以默认老年代对象增速为0，Full GC发生频率趋向于0，对系统无影响。 ​ 所以回顾一下，通过这个示例程序的运行，是不是可以通过jstat分析出来以下信息： 新生代对象增长的速率 Young GC的触发频率 Young GC的耗时 每次Young GC后有多少对象是存活下来的 每次Young GC过后有多少对象进入了老年代 老年代对象的增长速率 Full GC的触发频率 Full GC的耗时]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程杂记Ⅱ]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F02%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%9D%82%E8%AE%B0%E2%85%A1%2F</url>
    <content type="text"><![CDATA[Java内存模型​ Java线程之间的通信采用的是共享内存模型，这里提到的共享内存模型指的就是Java内存模型（Java Memory Model，简称JMM），JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量额的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓存区，寄存器以及其他的硬件和编译器优化。 ​ Java内存模型主要有read、load、use、assign、store、write这几个动作。举一个例子，下面这么一段代码： 12345678910111213141516171819202122232425262728293031323334public class HelloWorld &#123; private int data = 0; public void increment() &#123; data++; &#125; public int getData() &#123; return data; &#125; public static void main(String[] args) &#123; final HelloWorld helloWorld = new HelloWorld(); Thread thread1 = new Thread() &#123; @Override public void run() &#123; helloWorld.increment(); System.out.println("=====线程1：" + helloWorld.getData() + " ====="); &#125; &#125;; Thread thread2 = new Thread() &#123; @Override public void run() &#123; helloWorld.increment(); System.out.println("=====线程2：" + helloWorld.getData() + " ====="); &#125; &#125;; thread1.start(); thread2.start(); &#125;&#125; ​ 通过上面的代码，我们来梳理一下线程与共享变量之间的关系： Java并发之原子性、有序性和可见性原子性​ 原子性指的是一个或者多个操作在CPU执行的过程中不被中断的特性。 ​ 线程切换带来的原子性问题 ​ Java并发程序都是基于多线程的，操作系统为了充分利用CPU的资源，将CPU分成若干个时间片，在多线程环境下，线程会被操作系统调度进行任务切换。 ​ 为了直观了解什么是原子性，我们看下面哪些操作是原子性操作 123int count = 0;count++;int a = count; ​ 上面展示语句中，除了语句1是原子操作，其它两个语句都不是原子性操作，下面来分析一下语句2。其实语句2在执行的时候，包含三个指令操作： 指令1：首先。先把变量count从内存加载到CPU的寄存器 指令2：之后，在寄存器中执行 +1 操作 指令3：最后，将结果写入内存 ​ 对于上面的三条指令来说，如果线程A在指令1执行后做线程切换，线程A和线程B按照下图的序列执行，那么我们会发现两个线程都执行了count += 1的操作，但是得到的结果不是我们期待的2，而是1。 ​ 操作系统做任务切换，可以发生在任何一条CPU指令执行完 有序性​ 有序性指的是程序按照代码的先后顺序执行 ​ 编译优化带来的有序性问题 ​ 为了性能优化，编译器和处理器会进行指令重排序，有时候会改变程序中语句的先后顺序，比如程序： 12345678910flag = false;// 线程1prepare(); // 准备资源falg = true;// 线程2while(!flag) &#123; Thread.sleep(1000);&#125;execute(); // 基于准备好的资源执行操作 ​ 重排序之后，让flag = true先执行了，会导致线程2直接跳过while等待，执行某段代码，结果prepare()方法还没执行，资源还没准备好，此时就会导致代码逻辑出现异常。 ​ synchronized（具有有序性、原子性、可见性）表示锁在同一时刻中一个线程进行获取，当锁被占用后，其他线程只能等待。在单例模式的实现上有一种双重检验锁定的方式 1234567891011121314151617181920public class Singleton &#123; private Singleton() &#123; &#125; private volatile static Singleton instance = null; public static Singleton getInstance() &#123; if(instance == null) &#123; synchronized (Singleton.class) &#123; if(instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; ​ 我们先看instance = new Singleton()的未被编译器优化的操作： 指令1：分配一块内存M； 指令2：在内存M初始化Singleton对象； 指令3：然后M的地址赋值给instance变量； 编译器优化后的操作指令： 指令1：分配一块内存M； 指令2：将M的地址赋值给instance变量； 指令3：然后内存M上初始化Singleton对象。 ​ 现有A，B两个线程，我们假设线程A先执行了getInstance()方法，当执行编译器优化后的操作指令2时（此时未完成对象的初始化），这时发生了线程切换，那么线程B进入，刚好执行到第一次判断instance == null会发现instance不等于null了，所以直接返回instance，而此时的instance，是没有初始化过的。 可见性​ 可见性指的是当一个线程修改了共享变量后，其它线程能够立刻得知这个修改。 缓存导致的可见性问题 ​ 让我们回顾一下上面讲的java内存模型： 我们定义的所有变量都存储在主内存中。 每个线程都有自己独立的功能内存，里面保存该线程使用到的变量的副本（主内存中该变量的一份拷贝） 线程对共享变量所有的操作都必须在自己的工作内存中进行，不能直接从主内存中读写（不能越级） 不同线程之间也无法直接访问其他线程的工作内存中的变量，线程间变量值的传递需要通过主内存来进行。（同级之间不能相互访问） ​ 线程1对共享变量的修改要被线程2及时看到的话，要经过如下步骤： 把工作内存1中更新的变量刷新到主内存中； 把主内存中的变量的值更新到工作内存2中 我们可以使用synchronized、volatile、final来保证可见性 volatile​ volatile关键字是用来保证可见性和有序性，在有些罕见的条件下，可以有限的保证原子性，但它不是用来保证原子性的。基本原理是当一个线程对一个volatile修饰的共享变量进行修改后，会强制线程将这个修改后的副本刷入主内存，同时，让其他线程对这个共享变量的副本进行失效，让他们重新去主内存中读取数据，从而保证可见性。 ​ 那volatile是如何保证有序性的呢？它是如何避免指令重排的呢？这就涉及了Java中的一个原则，叫做happens-before原则。在编译器对代码进行代码重排序之前，要遵守happens-before原则。如果符合happens-before原则，那么就不能胡乱重排，如果不符合这些规则，那就可以自己排序。happens-before规则包括以下几个： 程序次序规则：一个线程内，按照代码顺序，书写前面的操作先行发生于书写后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。比如说在代码里对一个锁的lock.lock()、lock.unlock()、lock.lock()操作，第二个unlock操作要先行发生于第三个的lock操作，而不能重排序成lock.lock()、lock.lock()、lock.unlock()。 volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个volatile变量的读操作。volatile变量写，再读，必须保证是先写，再读。 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。例如thread.start()要先行发生于thread.interrupt()，而不能将thread.interrupt()重排序到thread.start()前面。 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。 线程终结原则：线程中所有的操作都先行发生于线程的终止检测。我们可以通过thread.join()方法结束、thread.isAlive()的返回值手段检测到线程已经终止执行。 对象终结规则：一个对象的初始化完成先行发生于它的finalize()方法的开始。 ​ 这8条规则是避免出现乱七八糟扰乱秩序的指令重排，要求是这几个重要的场景下，要按照顺序来执行。这8条规则之外，可以重排指令。这happens-before规则也说明了为什么volatile为什么能保证它的有序性。因为volatile要求的是，volatile前面的代码一定不能指令重排到volatile变量操作后面，volatile后面的代码也不能指令重排到volatile前面。 ​ volatile在底层是如何保证可见性和有序性的呢？ （1）lock指令：volatile保证可见性 ​ 对volatile修饰的变量，执行写操作的话，JVM会发送一条lock前缀指令给CPU，CPU在计算完之后会立即将这个值写会主内存，因为同时有MESI缓存一致性协议，所以各个CPU都会对总线进行嗅探，自己本地缓存中的数据是否被别人修改。 ​ 如果发现别人修改了某个缓存的数据，那么CPU就会将自己本地缓存的数据过期掉，然后这个CPU上执行的线程在读取这个变量的时候，就会从主内存重新加载最新的数据了。 ​ lock前缀指令+ MESI缓存一致性协议 （2）内存屏障：volatile禁止指令重排序 ​ 先简单了解两个指令： Store：将处理器缓存的数据刷新到内存中 Load：将内存存储的数据拷贝到处理器的缓存中 屏障类型 指令示例 说明 LoadLoad Load1;LoadLoad;Load2 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的操作 StoreStore Store1;StoreStore;Store2 该屏障确保Store立刻刷新数据到内存（使其对其它处理器可见）的操作先于Store2及其后所有存储指令的操作 LoadStore Load1;LoadStore;Store2 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作 StoreLoad Store1;StoreLoad;Load2 该屏障确保Store1立刻刷新到内存的操作先于Load2及其后所有装载指令的操作。它会使屏障之前的所有内存访问指令（存储指令和访问指令）完成之后，才执行改屏障之后的内存访问指令 1234Load1:int localVar = this.variableLoadLoad屏障int localVar = this.variable2 12345Store1:this.variable = 1StoreStore屏障Store2:this.variable = 2 ​ 那么volatile的作用是什么呢？ 123volatile variable = 1this.variable = 2 // store操作int localVariable = this.variable // load操作 ​ 每个volatile写操作前面，加StoreStore屏障，禁止上面的普通写和他重排；每个volatile写操作后面，加StoreLoad屏障，禁止跟下面的volatile读/写重排。 ​ 每个volatile读操作后面，加LoadLoad屏障，禁止下面的普通读和volatile读重排；每个volatile读操作后面，加LoadStore屏障，禁止下面的普通写和volatile读重排。 ​ volatile经常用于以下场景：状态标记变量、Double Check、一个线程写多个线程读。 参考资料 Java并发之原子性、有序性、可见性]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池杂记]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F27%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[简单说一下Java线程池的底层工作原理​ 一般情况下，系统是不会说无限制地创建大量的线程，会构建一个线程池，保持一定数量的线程，让他们执行各种各样的任务，线程执行完任务后，不要销毁自己，继续去等待执行下一个任务。这样可以避免频繁地创建线程和销毁线程。 12345678ExecutorService threadPool = Executors.newFixedThreadPool(3);threadPool.submit(new Callable&lt;Object&gt;() &#123; @Override public Object call() throws Exception &#123; return null; &#125;&#125;); ​ 大概流程是这样的：提交任务，先看一下线程池里的线程数量是否小于corePoolSize，也就是上面代码的3。如果小于，直接创建一个线程出来执行你的任务；执行完任务之后，这个线程是不会死掉的，它会尝试从一个无界的LinkedBlockingQueue里获取新的任务，如果没有新的任务，此时就会阻塞住，等待新的任务到来。 ​ 应用持续提交任务，上述流程反复执行，只要线程池的线程数量小于corePoolSize，都会直接创建新线程来执行这个任务，执行完了就尝试从无界队列里获取任务，知道线程里有corePoolSize个线程；接着再次提交任务，会发现线程数量已经跟corePoolSize一样大了，此时就会直接把任务放入队列中就可以了，线程会争取获取任务执行。如果所有人的线程此时都在执行任务，那么无界队列里的任务就可能会越来越多。 线程池的核心配置参数​ 上面的那段代码：Executors.newFixedThreadPool(3);，进去里面查看源码，是这样子的： 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; ​ 创建一个线程池就是这样子的。除了那个0L，参数依次是corePoolSize、maximumPoolSize，keepAliveTime，queue。如果你不用fixed之类的线程池，可以自己通过这个构造函数创建自己的线程池。 1234corePoolSize: 3maximumPoolSize: 200keepAliveTime: 60snew ArrayBlockingQueue&lt;Runnable&gt;(200) ​ 如果你把queue做成有界队列，比如上面的new ArrayBlockingQueue(200)，假设corePoolSize个线程都在繁忙地工作，大量的任务进入有界队列，队列满了，如果你的maximumPoolSize是比corePoolSize大的，此时会继续创建额外的线程放入线程池里，来处理这些任务，然后超过corePoolSize数量的线程如果处理完了一个任务也会尝试从队列里去获取任务来执行。 ​ 如果额外线程都创建完了去处理任务了，队列还是满了，此时还有新的任务，那该怎么办？只能reject掉。目前有几种reject策略，可以传入RejectExecutionHandler AbortPolicy DiscardPolicy DiscardOldestPolicy CallerRunsPolicy 自定义 ​ 如果后续队列里，慢慢没有任务了，线程空闲了，超过corePoolSize的线程会自动释放掉，在keepAliveTime之后就会释放。在具体场景中，我们可以根据上述原理定制自己的线程池，来考虑corePoolSize的数量、队列类型、最大线程数量、拒绝策略和线程释放时间等等。一般常用的是fixed线程。 线程池的队列满了之后会发生什么事情​ 这个要分情况考虑，如果maximumPoolSize是Integer.MAX_VALUE，那么线程池会创建无限多的线程，最终有可能导致内存溢出或者CPU负载过高而服务器挂掉。如果maximumPoolSize不是Integer.MAX_VALUE，而线程池的队列是无界队列，那么有可能系统会创建大量任务塞进队列中，最终导致内存溢出；如果队列是有界的，并且maximumPoolSize不是Integer.MAX_VALUE，那么有可能部分任务没被执行到而被reject掉。可以自定义一个reject策略，如果线程池无法执行更多的任务，此时建议可以把这个任务信息持久化写入到磁盘里去，后台专门启动一个线程，后续等待线程池的工作负载降低了，可以慢慢地从磁盘读取之前持久化的任务，重新提交到线程池里去执行。 线上机器突然宕机，如果处理线程池阻塞队列中的请求​ 服务器突然宕机，会导致线程池里积压的任务丢失。可以这么处理，如果你要提交一个任务到线程池里去，在提交之前，先在数据库里插入这个任务的信息，更新它的状态：未提交。已提交、已完成。提交成功之后，更新它的状态是已提交状态。 ​ 系统重启，后台线程去扫描数据库里的未提交和已提交状态的任务，可以把任务的信息读取出来，重新提交到线程池里去，继续执行。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程杂记]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F23%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[synchronized关键字的底层原理​ synchronized底层的原理，是跟jvm指令和monitor有关系的。你如果用到了synchronized关键字，在底层编译后的jvm指令中，会有monitorenter和monitorexit两个指令。 123monitorenter // 代码对应的指令monitorexit ​ 那么monitorenter指令执行的时候会干什么呢？每个对象都有一个关联的monitor。比如一个实例对象就有一个monitor，一个类的Class对象也有一个monitor，如果要对这个对象加锁，那么必须先获取这个对象关联的monitor的lock锁。 ​ 它的原理和思路大概是这样的：monitor里面有一个计数器，从0开始。如果一个线程要获取monitor的锁，就看看它的计数器是不是0，如果是0的话，那么说明没人获取锁，它就可以获取锁了，然后对计数器加1。 ​ 这个monitor的锁是支持重入加锁的，什么意思呢？好比下面的代码片段： 12345678synchronized(myObject) &#123; // 一大堆代码 synchronized(myObject) &#123; // 一堆代码 &#125;&#125; ​ 加锁，一般来说都是必须对同一个对象进行加锁。如果一个线程第一次synchronized那里，获取到了myObject对象的monitor的锁，计数器加1，然后第二次synchronized那里，会再次获取myObject对象的monitor的锁，这个就是重入加锁了，然后计数器会再次加1，变成2。 ​ 这个时候，其他的线程在第一次synchronized那里，会发现myObject对象的monitor锁的计数器是大于0的，意味着被别人加锁了，然后此时线程就会进入block阻塞状态，什么都干不了，就是等着获取锁。 ​ 接着如果出了synchronized修饰的代码片段的范围，就会有一个monitorexit指令在底层。此时获取锁的线程就会对那个对象的monitor的计数器减1，如果有多次重入加锁就会对应多次减1，直到最后计数器是0。然后后面block住阻塞的线程，会再次尝试获取锁，但是只有一个线程可以获取到锁。 CAS的理解及其底层实现原理​ 首先我们先看这一段代码： 12345678910111213141516public class MyObject &#123; int i = 0; // 在一个对象实例的方法上加上synchronized // 同一时间只有一个线程可以进入这个方法 public synchronized void increment() &#123; i++ &#125; public static void main(String[] args) &#123; // 第一个线程同时都基于myObject这一个对象，来执行increment()方法 MyObject myObject = new MyObject(); myObject.increment(); &#125;&#125; ​ 上面的代码中，synchronized的意思就是针对当前执行这个方法的myObject对象进行加锁，此时只有一个线程可以成功地对myObject加锁，可以对它关联的monitor的计数器加1.一旦多个线程并发的去执行synchronized加锁，这就会变成串行化，导致很多线程都要去排队去执行，效率并不是太高。 ​ 再来看下面的这段代码： 1234567891011public class MyObject &#123; // 底层就是基于CAS来进行实现的 AtomicInteger i = new AtomicInteger(0); // 多个线程此时执行这段代码 // 不需要synchronized加锁，也是线程安全的 public void increment() &#123; i.incrementAndGet(); &#125;&#125; ​ CAS（compare and set）。就是设值的时候先进行比较，如果当前的值等于之前获取到的旧值，就说明之前没有其他线程对这个值进行过修改，就可以将我们的新值设置给它。如果当前的值不等于我们之前获取的旧值，说明之前有线程对它进行过修改，那么就设置新值失败。 ​ CAS在底层的硬件级别给你保证一定是原子性的，同一时间只有一个线程可以执行CAS。先比较再设置，其他的线程的CAS同时间去执行就会失败。 ​ ConcurrentHashMap实现线程安全的底层原理​ 多个线程访问同一个数据，为了保证线程安全，可以synchronized加锁，或者CAS进行安全的累加，从而实现多线程场景下安全更新一个数据的效果。在比较多的情况下，可能就是多个线程同时读写一个HashMap。 ​ 为了保证线程安全，可以对HashMap进行synchronized，但没这个必要。HashMap的底层就是一个大的数组，假设多个线程过来，线程1要put的位置是数组[5]，线程2要put的位置是数组[21]，如果使用synchronized加锁，那么线程1跟线程2就要排队执行，但这明显不好，锁的粒度太粗，效率太低。除非是对同一个元素执行put操作，此时多线程才需要进行同步。 ​ 因此，JDK并发包里推出了一个ConcurrentHashMap，它默认实现了线程安全。在JDK1.7以及之前的版本，ConcurrentHashMap底层采取的是分段加锁来实现线程安全。ConcurrentHashMap本身是一个大数组，把它拆成多个数组：[数组1]，[数组2]，[数组3]…，每个数组都对应一个锁，这就是分段加锁。 ​ [数组1]，[数组2]，[数组3] -&gt; 每个数组都对应一个锁，分段加锁 ​ 当多个线程过来，线程1要put的位置是数组1的第五个位置[5]，线程2要put的位置是数组2的第21个位置[21]，那这样子两个线程就互不干扰，可以同时对ConcurrentHashMap赋值。 ​ JDK1.8以及之后，对ConcurrentHashMap做了一些优化和改进，就是细化锁的粒度。在JDK1.8及其之后，ConcurrentHashMap底层还是一个大的数组，但对数组每个元素进行put操作，都是有一个不同的锁。刚开始进行put的时候，如果两个线程都是在数组[5]这个位置进行put。这个时候，就是对数组[5]这个位置进行put的时候，采取的是CAS的策略。 ​ 同一时间，只有一个线程能成功执行这个CAS。就是说，它刚开始先获取一下数组[5]这个位置的值，为null，然后执行CAS，然后线程1比较当前还是null，就可以put进去我的这条数据。同时间，其他线程执行CAS，都会失败。 ​ 这其实也可以算是分段加锁，通过对数组每个元素执行CAS的策略。如果是很多线程对数组里不同的元素执行put，大家互不干扰，没有关系。如果其他线程失败了，发现数组[5]这个位置，已经别人放进去值了，就需要在这个位置基于链表+红黑树进行处理。就是synchronized(数组[5])进行加锁，然后基于链表或者红黑树在这个位置插进去自己的数据。所以说，如果你是对数组里同一个位置的元素进行操作，才会加锁进行串行化处理；如果是对数组不同位置的元素操作，那么此时大家可以并发执行。 ​ 总的来说，在JDK1.8之前，多个数组，分段加锁，一个数组一个锁。在JDK1.8之后，优化细粒度，一个数组，每个元素进行CAS，如果失败说明有人了，此时synchronized对数组元素进行加锁，基于链表+红黑树处理，对数组每个元素加锁。 简单说一下AQS​ AQS，全称Abstract Queue Synchronizer，中文名叫抽象队列同步器。java并发包中的Semahore和部分Lock底层的实现原理都是利用AQS，例如可重入锁ReentrantLock。现在简单说一下AQS的原理。 ​ AQS内部主要包含state变量，一个存储当前加锁线程的变量和一个等待队列。当多个线程访问时，先通过CAS尝试更新state的变量，如果成功了，将加锁线程的变量更改为自己，并进行后续操作。如果失败了，进入队列等待，等待拥有锁的线程释放锁后唤醒。大概如下图： ​ 接下来会涉及到公平锁和非公平锁。像ReentractLock，默认就是非公平锁。只有ReentrantLock lock = new ReentrantLock(true)时，才是公平锁。那什么是公平锁，什么是非公平锁。例如上面那个图，非公平锁就是，此时线程1释放了资源，唤醒线程2，但此时刚好线程3来进行CAS加锁等操作，并且成功了，那是此时就是线程3获取这个锁，而线程2继续回到等待队列。这就是非公平锁。 ​ 公平锁就是新的线程来获取锁时，会先看等待队列是否有其它线程，有的话就进入等待队列。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[捋一遍MySQL索引结构]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F18%2F%E6%8D%8B%E4%B8%80%E9%81%8DMySQL%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[从一个简单的表开始​ 首先我们先建一个表，语句如下： 1234567create table user( id int primary key, age int, height int, weight int, name varchar(32))engine = innoDb; ​ 然后往这个表中插入一些数据： 12345INSERT INTO user(id,age,height,weight,name)VALUES(2,1,2,7,'小吉');INSERT INTO user(id,age,height,weight,name)VALUES(5,2,1,8,'小尼');INSERT INTO user(id,age,height,weight,name)VALUES(1,4,3,1,'小泰');INSERT INTO user(id,age,height,weight,name)VALUES(4,1,5,2,'小美');INSERT INTO user(id,age,height,weight,name)VALUES(3,5,6,7,'小蔡'); ​ 最后，我们查一下这些数据是否已经放入表中 1select * from user; ​ 结果如下： ​ 可以看到，数据已经完整地放到我们创建的user表中。但是有一个地方需要注意：我们插入的数据都是乱序的，但MySQL好像按照id给我们的数据排了序。为什么会出现MySQL在我们没有显式排序的情况下，默默帮我们排序了？它是在什么时候进行排序的？ 页的引入​ 在操作系统的概念中，当我们往磁盘中取数据，假设要取出的数据的大小是1KB，但是操作系统并不会只取出这1KB的数据，而是会取出4KB的数据，因为操作系统的一个页表项的大小是4KB。那为什么我们只需要1KB的数据，但是操作系统要取出4KB的数据呢？ ​ 这就涉及到一个程序局部性的概念，大概就是“一个程序在访问了一条数据之后，在之后会有极大可能再次访问这条数据和访问这条数据的相邻数据”。所以索性直接加载4KB的数据到内存，下次要访问这一页的数据时，直接从内存中找，可以减少磁盘IO次数。因此磁盘IO是影响程序性能主要的因素，因为磁盘IO和内存IO的速度是不可同日而语的。 ​ 我们回到数据库层面中，重新理解页的概念。假设还是我们刚才插入的那些数据，我们现在要找id=5的数据，依照最原始的方式，我们一定会想到的就是遍历。这也是我们刚开始学计算机的时候最常用的寻找数据的方式。我们来看看，以遍历的方式，我们找到id=5的数据，需要经历几次磁盘IO。 ​ 首先，我们得先从id=1的数据开始读起，然后判断是否是我们需要的数据，如果不是，就再取id=2的数据，再进行判断，循环往复。在MySQL帮我们排好序之后，我们需要经历五次磁盘IO，才能将5号数据找到并读出来。 ​ 如果引入页的概念后，我们是如何读取数据的。 ​ 在引入页的概念后，MySQL会将多条数据存入一个叫“页”的数据结构中，当MySQL读取id=1的数据时，会将id=1数据所在的页整页读到内存中，然后在内存中进行遍历判断，由于内存的IO速度比磁盘高很多，所以相对于磁盘IO，几乎可以忽略不计。 ​ 假设一页可以存4条数据，那么我们第一次读取id=1的数据，并且将id=1到id=4的数据全部读到内存中，这是第一次磁盘IO。第二次将读取id=5的数据到内存中，这是第二次磁盘IO。我们只需要经历2次磁盘IO就可以找到id=5的这条数据。 ​ 但其实，在MySQL的InnoDB引擎中，页的大小是16KB，是操作系统的4倍，而int类型的数据是4个字节，其他类型的数据的字节数通常也在4000字节以内，所以一页是可以存放很多条数据的。而MySQL的数据正是以页为基本单位组合而成的。 ​ 上图是我们目前为止所理解的页的结构，它包含我们的多条数据。另外，MySQL的数据以页组成，那么它有指向下一页的指针和指向上一页的指针。 ​ 到这里，可以回答第一个问题。MySQL实际上就是在我们插入数据的时候，就帮我们在页中排好了序。至于为什么排序，接着往下看。 排序对性能的影响​ 上面我们提了一个问题，为什么数据库再插入数据时要对其进行排序呢？这就涉及到一个数据库查询流程的问题了。无论如何，我们是绝对不会平白无故地在插入数据时增加一个操作让流程复杂化的，所以插入数据时排序一定有其目的，就是优化查询的效率。而我们不难看出，页内部存放数据的模块，实质上就是一个链表结构，链表的特点就是增删快，查询慢。所以优化查询的效率是必须的。 基于单页模式存储的查询流程​ 还是基于上面的那张页图来说，我们插入了五条数据，id分别是从1-5，那么假设我要找一个表中不存在的id，假设id = -1，那么查询的流程就是： ​ 将id=1的这一整页数据取出，进行逐个比对，那么当我们找到id=1的这条数据时，发现这个id大于我们所需要找的那个id。由于数据库再插入数据时，已经进行过排序了，那么在id=1的数据后面，都是id &gt; 1的数据，所以我们就不需要再继续往下找了。 ​ 如果在插入时没有进行排序，那我们需要在继续往下寻找，逐条查找直到结尾也没有找到这条数据，才能返回不存在这条数据。当然，这只是排序优化的冰山一角。 上述页模式可能带来的问题​ 说完了排序，我们就分析一下上面的那张页图，对于大数据量下有什么弊端，或者说，我们可以怎么对这个模式进行优化。 ​ 不难看出，现阶段我们了解的页模式中，只有一个功能，就是在查询某条数据的时候直接将一整页的数据加载到内存中，以较少磁盘IO次数，从而提高性能。但是，我们也可以看到，现在的页模式内部，实际上是采用了链表的结构，前一条数据指向后一条数据，本质上还是通过数据的逐条比较来取出特定的数据。 ​ 如果这一页中有一百万条数据，我们要查的数据正好在最后一个，那么我们是不是一定要从前往后找到这一条数据呢r？如果是这样，我们需要查找的次数就达到了一百万次，即使是在内存中查找，这个效率也是不高的。那么有什么办法来优化这种情况下的查找效率呢？ 页目录的引入​ 打个比方，我们在看书的时候，如果要找到某一节，而这一节我们并不知道在哪一页，我们不需要从前往后，一节一节寻找我们需要的内容。以为在书的前面，存在目录，它会告诉你这一节在哪一页。在数据库的页中，实际上也使用了这种目录的结构，这就是页目录。 ​ 在引入页目录之后，我们所理解的页结构，就变成了这样： ​ 分析下这张图，实际上页目录就像是我们在看书的时候书本的目录一样，目录项1就相当于第一节，目录项2就相当于第二节，而每一条数据就相当于书本的每一页，这张图就可以解释成：第一节从第一页开始，第二节从第三页开始。而实际上，每个目录项会存放自己这个目录项当中最小的id，也就是说，目录项1中会存放1，而目录项2会存放3。 ​ 对比一下数据库在没有页目录时候的查找流程，假设要查找id=3的数据，在没有页目录的情况下，需要查找id=1、id=2、id=3，三次才能找到该数据，而如果有页目录之后，只需要先查看一下id=3存在于哪个目录项下，然后直接通过目录项进行数据的查找即可，如果在该目录项下没有找到这条数据，那么就可以直接确定这条数据不存在，这样就大大提升了数据库的查找效率。但是这种页目录的实现，首先就需要基于数据是在已经进行过排序的场景下，才可以发挥其作用，所以到这里，大家应该明白第二个问题了，为什么数据库在插入时会进行排序，这才是真正发挥排序的作用的地方。 页的扩展​ 在上文中，我们基本上说明白了数据库中页的概念，以及它是如何基于页来减少磁盘IO次数，以及排序是如何优化查询的效率的。 ​ 那么第三个问题：在开头说页的概念的时候，我们有说过，MySQL中每一页的大小只有16KB，不会随着数据的插入而自动扩容，所以这16KB不可能存下我们所有的数据，那么必定会有多个页来存储数据。那么在多页的情况下，MySQL中又是怎么组织这些页的呢？ ​ 针对这个问题，我们继续画出来我们现在多了解的多页的结构图： ​ 可以看到，在数据不断变多的情况下，MySQL会再去开辟新的页来存放新的数据，而每个页都有指向下一页的指针和指向上一页的指针，将多个页组织起来（这里修改了数据，将每一列的数据都放到了数据区中，其中第一个空格之前的代表id）,第一页中存放id为1-5的数据，第二页存放id为6-10的数据，第三页存放id为11-15的数据。需要注意的是，在开辟新页的时候，我们插入的数据不一定是在新开辟的页上，而是要进行所有页的数据比较，来决定这条插入的数据放在哪一页上，而完成数据插入后，最终的多页结构会像上图中画的那样。 多页模式​ 在多页模式下，MySQL终于完成多数据的存储，就是采用开辟新页的方式，将多条数据放在不同的页中，然后同样采用链表的数据结构，将每一页连接起来，那么可以思考第四个问题：多页情况下是否对查询效率有影响呢？ 多页模式对于查询效率的影响​ 答案是肯定的，多页会对查询效率产生一定的影响，影响主要就体现在，多页其本质也是一个链表结构，只要是链表结构，查询效率一定不会高。 ​ 假设数据又非常多，数据库就会开辟非常多的新页，而这些新页就会像链表一样连接在一起，当我们要在这么多页中查询某条数据时，它还是会从头节点遍历到存在我们需要的那条数据所存在的页上。我们好不容易通过页目录优化了页中数据的查询效率，现在又出现了以页为单位的链表。 优化多页模式​ 由于多页模式会影响查询的效率，那么肯定需要有一种方式来优化多页模式下的查询。既然我们可以用页目录来优化页内的数据区，那么我们也可以采取类似的方式来优化这种多页的情况。是的，页内数据区和多页模式本质上都是链表，的确可以采用相同的方式来对其进行优化，它就是目录页。 ​ 我们对比页内数据区，来分析如何优化多页结构。在单页时，我们采用了页目录的目录项来指向一行数据，这条数据就是存在于这个目录项中的最小数据，那么就可以通过页目录来查找所需数据。 ​ 所以对于多页结构也可以采用这种方式，使用一个目录项来指向某一页，而这个目录项存放的就是这一页中存放的最小数据的索引值。和页目录不同的地方在于，这种目录管理的级别是页，而页目录管理的级别是行。 ​ 分析到这里，我们多页模式的结构就会是下图所示的那样： ​ 存在一个目录页还管理目录，目录页中的数据存放就是指向的那一页中最小的数据。这里需要注意的一点是：其实目录页的本质也是页，普通页中存放的数据是项目数据，而目录页中存的数据是普通页的地址。 ​ 假设我们要查找id = 19的数据，按照以前的查找方式，我们需要从第一页开始查找，发现不存在那么再到第二页查找，一直找到第四页才能找到id = 19的数据，但是如果有了页目录，就可以使用id = 19与页目录中存放的数据进行比较，发现19大于任何一条数据，于是进入id = 16指向的页进行查找，然后再通过页内的页目录行级别的数据的查找，很快就可以找到id为19的数据了。随着数据越来越多，这种结构的效率相对于普通的多页模式，优势也就越来越明显。 ​ 相信对MySQL比较了解的同学已经发现，我们画的最终的这幅图，就是MySQL中的一种索引结构-B+树。 B+树的引入​ 接着往下说，我们将我们画的存在在目录页的多页模式图宏观化，可以形成下面的这张图： ​ 这就是我们兜兜转转由简到繁形成的一颗B+树。和常规B+树有些许不同，这是一棵MySQL意义上的B+树，MySQL上的一种索引结构，其中的每个节点就可以理解为是一个页，而叶子节点也就是数据页，除了叶子节点以外的节点就是目录页。 ​ 这一点在图中也可以看出来，非叶子节点只存放了索引，而只有叶子节点存放了真实的数据，这也是符合B+树的特点。 B+树的优势由于叶子节点上存放了所有的数据，并且有指针相连，每个叶子节点在逻辑上是相连的，所以对于查找范围比较友好。 B+树的所有数据都在叶子节点上，所以B+树的查询效率稳定，一般都是查询3次。 B+树有利于数据库的扫描。 B+树有利于磁盘的IO，因为它的层高基本不会因为数据扩大而增高（三层树结构大概可以存放两千万数据量）。 页的完整结构​ 说完了页的概念和页时如何一步一步地组合成为B+树的结构之后，相信大家对于页都有了一个比较清楚的认知。所以这里就要开始说说官方的概念了。基于我们上文所说的，给出一个完整的页结构，也算是对上文中理解的页结构的一种补充。 ​ 上图为Page数据结构，File Header字段用于记录Page的头信息，其中比较重要的是FIL_PAGE_PREV和FIL_PAGE_NEXT字段，通过这两个字段，我们可以找到该页的上一页和下一页，实际上所有页通过这两个字段可以形成一条双向链表。 ​ Page Header字段用于记录Page的状态信息。接下来的Infimum和Supremum是两个伪行记录，Infimum（下确界）记录比该页中任何主键值都要小的值，Supremum（上确界）记录比该页中任何主键值都要大的值，这个伪记录分别构成了页中记录的边界。 ​ User Records中存放的是实际的数据行记录。Free Space中存放的是空闲空间，被删除的行记录会被记录成空闲空间。Page Directory记录着与二叉查找相关的信息。File Trailer存储用于检测数据完整性的校验和等数据。 基于B+树聊赖MySQL的其他知识点​ 看到这里，我们已经了解了MySQL从单条数据开始，到通过页来减少磁盘IO次数，并且在页中实现了页目录来优化页中的查询效率，然后使用多页模式来存储大量的数据，最终使用目录页来实现多页模式的查询效率并形成我们口中的索引结构—B+树。接下来，我们说说MySQL的其他知识点。 聚簇索引和非聚簇索引​ 简单地说，所谓聚簇索引，就是将索引和数据放到一起，找到索引也就找到了数据，我们刚才看到的B+树索引就是一种聚簇索引。而非聚簇索引就是将数据和索引分开，查找时需要先查找到索引，然后通过索引回表找到相应的数据。InnoDB有且只有一个聚簇索引，而MyISAM中都是非聚簇索引。 联合索引的最左前缀匹配原则​ 在MySQL数据库中不仅可以对某一列建立索引，还可以对多列建立一个联合索引，而联合索引存在一个最左前缀匹配原则的概念，如果基于B+树来理解这个最左前缀匹配原则，相对来说就会容易很多了。 ​ 首先我们基于文首的这张表建立一个联合索引： 1create index idx_obj on user(age asc,height asc,weight asc) ​ 我们已经了解了索引的数据结构是一棵B+树，也了解了B+树优化查询效率的其中一个因素就是对数据进行了排序，那么我们在创建idx_obj这个索引的时候，也就相当于创建了一颗B+树索引，而这个索引就是依据联合索引的成员来进行排序，这里是age，height，weight。 ​ InnoDB中只要有主键被定义，那么主键列被作为一个聚簇索引，而其他索引都被作为非聚簇索引，所以自然而然的，这个索引就会是一个非聚簇索引。所以根据这些我们可以得出结论： idx_obj这个索引会根据age，height，weight进行排序 idx_obj这个索引是一个非聚簇索引，查询时需要回表 ​ 根据这两个结论，首先需要了解的就是，如何排序？单列排序很简单，就是比大小。但多列排序是基于什么原则呢？实际上在MySQL中，联合索引的排序有这么一个原则，从左到右依次比较大小。就拿刚才建立的索引，它会先去比较age的大小，如果age的大小相同，那么比较height的大小，如果height也无法比较大小，那么就比较weight的大小，最终对这个索引进行排序。 ​ 那么根据这个排序我们也可以画出一个B+树，这里就不像上文画的那么详细了，简化一下： ​ 数据： ​ B+树： ​ 注意，此时由于是非聚簇索引，所以叶子节点不在有数据，而是存了一个主键索引，最终会通过主键索引来回表查询数据。 ​ B+树的结构有了，就可以通过这个来理解最左前缀匹配原则了。我们先下一个查询语句： 1SELECT * FROM user WHERE age=1 and height = 2 and weight = 7 ​ 毫无疑问，这条语句一定会走idx_obj这个索引。那我们再看一个语句： 1SELECT * FROM user WHERE height=2 and weight = 7 ​ 这条SQL会走索引吗？答案是否定的。为什么这条语句不会走索引？上文中我们提到了一个多列的排序原则，是从左到右进行比较然后排序的，而我们的idx_obj这个索引从左到右依次是age，height，weight，所以当我们使用height和weight来作为查询条件时，由于age的缺失，那么就无法从age来进行比较了。 ​ 难道不能直接用height和weight来进行比较吗？显然是不可以的。举个例子，我们把缺失的这一列写作一个问号，那么这条语句的查询条件就变成了?27，那么我们从这棵B+树的根节点开始，根节点上有127和365，那么以height和weight来进行比较的是，走的一定是127这一边，但是如果缺失的数字是大于3的呢？比如427,527,627，那么如果走索引来查询数据，将会丢失数据，错误查询。所以这种情况下是不会走索引查询的。这就是最左前缀匹配原则的成因。 ​ 1、最左前缀匹配原则，MySQL会一直向右匹配直到遇到范围查询（&gt;、&lt;、between、like）就停止匹配。比如a = 3 and b = 4 and c &gt; 5 and d = 6，如果建立（a, b, c, d）顺序的索引，d是无法使用索引的，如果建立（a, b, d, c）的索引则都可以使用到。a、b、d的顺序可以任意调整。 ​ 2、=和in可以乱序。比如a = 1 and b = 2 and c = 3，建立(a, b, c)索引可以任意顺序，MySQL的查询优化器会帮你优化成索引可以识别的形式。 ​ 根据我们了解的可以得出结论：只要无法进行排序比较大小的，就无法走联合索引。 ​ 再看几个语句： 1SELECT * FROM user WHERE age=1 and height = 2 ​ 这条语句是可以走idx_obj索引的，因为它可以通过比较（12? &lt; 365）。 1SELECT * FROM user WHERE age=1 and weight=7 ​ 这条语句也是可以走idx_obj索引的，因为它也可以通过比较(1?7 &lt; 364)，走左子树，但是实际上weight并没有用到索引，因为根据最左匹配原则，如果有两页的age都等于1，那么会去比较height，但是height在这里并不作为查询条件，所以MySQL会将这两页全都加载到内存中进行最后的weight字段的比较，进行扫描查询。 1SELECT * FROM user where age&gt;1 ​ 这条语句不会走索引，但是可以走索引。这句话什么意思呢？这条SQL很特殊，由于其存在可以比较的索引，所以它走索引也可以查询出结果，但是由于这种情况是范围查询并且是全字段查询，如果走索引，还需要进行回表，MySQL查询优化器就会认为走索引的效率比全表扫描还要低，所以MySQL会去优化它，让它直接进行全表扫描。 1SELECT * FROM user WHERE age=1 and height&gt;2 and weight=7 ​ 这条语句可以走索引的，因为它可以通过age进行比较，但是weight不会用到索引，因为height是范围查找，与第二条语句类似，如果有两页的height都大于2，那么MySQL会将两页的数据都加载进内存，然后再来通过weight匹配正确的数据。 索引的范围列匹配假设创建索引 create index (shop_id,product_id,gmt_create)。如果你是范围查询，比如 &gt;=，&lt;=，between 操作，你只能是符合最左前缀的规则才可以范围，范围之后的列就不用索引了。 1SELECT * FROM product WHERE shop_id &gt;= 1 AND product_id = 1 这里就只有 shop_id 走索引查询了，而 product_id 没有走索引。 索引的包含函数如果你对某个列用了函数，比如 substring 之类的，那么那一列不用索引 1SELECT * FROM product WHERE shop_id = 1 AND 函数(product_id) = 2 上面就只有 shop_id 在联合索引中走了索引。 为什么InnoDB只有一个聚簇索引，而不将所有索引都是用聚簇索引​ 因为聚簇索引是将索引和数据都存放在叶子节点中，如果所有的索引都是用聚簇索引，则每一个索引都将保存一份数据，会造成数据的冗余，在数据量很大的情况下，这种数据冗余是很消耗资源的。 补充两个索引的点​ 1、什么情况下会发生明明创建了索引，但是执行的时候并没有通过索引呢？ ​ 查询优化器执行一条SQL语句的查询，可以有不同的执行方案，至于最终选择哪种方案，需要通过优化器进行选择，选择执行成本最低的方案。 ​ 在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案。这个成本最低的方案就是所谓的执行计划。优化过程大致如下： 根据搜索条件，找出所有可能使用的索引 计算全表扫描的代价 计算使用不同索引执行查询的代价 对比各种执行方案的代价，找出成本最低的那一个 ​ 2、在费聚簇索引情况下通常需要通过叶子节点的指针回表查询数据，什么情况下不需要回表？ ​ 覆盖索引。覆盖索引是指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。 ​ 当一条查询语句符合覆盖索引条件时，MySQL只需要通过索引就可以返回查询所需要的数据，这样避免了查到索引后再返回表操作，减少I/O提高效率。 ​ 例如，表covering_index_sample中有一个普通索引idx_key1_key2(key1, key2)。当我们通过SQL语句：select key2 from covering_index_sample where key1 = &#39;keytest&#39;;的时候，就可以通过覆盖索引查询，无需回表。 ​ 例如上面的SELECT age FROM user where age = 1。这句话就不需要进行回表查询。 索引的缺点以及使用注意索引是有缺点的，常见的就是会增加磁盘消耗，因为要占用磁盘文件，同时高并发的时候频繁插入和修改索引，会导致性能消耗。我们给的建议是就是，尽量创建少的索引。比如一个表建两三个索引。 某些字段只有两个值，例如 status、is_delete 等，就只有 0 和 1。这些建立索引就没有意义了，几乎跟全表扫描差不多。你有个 id 字段，每个 id 都不太一样，建立个索引，这个时候用索引效果就很好。比如定位到某个 id 的行，通过索引二分查找，可以大大减少要扫描的数据量，性能是非常好的。 另外，InnoDB 下不要用 UUID 生成的超长字符串作为主键。因为这么搞会导致所有的索引的 data 都是那个主键值，最终导致索引会变得过大，浪费很多磁盘空间。 还有，一般 InnoDB 表里，建议统一用 auto_increment 自增作为主键值，因为这样可以保持聚簇索引直接加记录就可以了。如果用那种不是单调递增的主键值，可能会导致 B+ 树分裂后重新组织，浪费时间。 结语​ 本文着重讲解关于MySQL的索引结果，从零开始慢慢构建了一个B+树索引，并且根据这个过程谈了B+树是如何一步一步去优化查询效率的。简单地归纳一下就是： ​ 排序：优化查询的根本，插入时进行排序实际上就是为了优化查询的效率。 ​ 页：用于减少IO次数，还可以利用程序局部性原理，来稍微提高查询的效率。 ​ 页目录：用于规避链表的软肋，避免在查询时进行链表的扫描。 ​ 多页：数据量增加的情况下开辟新页来保存数据。 ​ 目录页：特殊的页目录，其中保存的数据是页的地址。查询时可以通过目录页快速定位到页，避免多页的扫描。 参考资料​ 转载自索引很难么？带你从头到尾捋一遍MySQL索引结构，不信你学不会！ ​]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Netty底层架构原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F13%2F%E6%B5%85%E8%B0%88Netty%E5%BA%95%E5%B1%82%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 对于高性能的RPC框架，Netty作为异步通信框架，几乎成了必需品。例如Dubbo框架中通信组件，还有RocketMQ中生产者和消费者的通信，都是用了Netty。现在让我们开简单看一下Netty的基本架构和原理。 Netty的特点与NIO​ Netty是一个异步的、基于事件驱动的网络应用框架，它可以用来开发高性能服务端和客户端。以前编写网络调用程序的时候，我们都会在客户端创建一个Socket，通过这个Socket连接到服务端。服务端根据这个Socket创建一个Thread，用来发出请求。客户端在发起调用以后，需要等待服务端处理完成，才能继续后面的操作。这样线程会出现等待的状态。 ​ 如果客户端请求数越多，服务端创建的处理线程也会越多，JVM管理如此多的线程并不是容易的事。 ​ 为了解决上述问题，退出了NIO的概念，就是（Non-blocking I/O）。其中Selector机制就是NIO的核心。当每次客户端请求时，会创建一个Socket Channel，并将其注册到Selector上（多路复用器），然后Selector关注服务端IO读写事件，此时客户端并不用等待IO事件完成，可以继续做接下来的工作。一旦服务端完成了IO读写操作，Selector会接到通知，同时告诉客户端IO操作已经完成。接到通知的客户端，就可以通过SocketChannel获取需要的数据了。 ​ 上面描述的过程有异步的意思，不过，Selector实现的并不是真正意义上的异步操作。因为Selector需要通过线程阻塞的方式监听IO事件变更，只是这种方式没有让客户端等待，是Selector在等待IO返回，并且通知客户端去获取数据。 ​ 谈好了NIO再来谈谈Netty。Netty作为NIO的实现，它适用于服务器/客户端通讯的场景，以及针对于TCP协议下的高并发应用。对于开发者来说，它具有以下特点： 对NIO进行封装，开发者不需要关注NIO的底层原理，只需要调用Netty组件就能完成工作。 对网络调用透明，从Socket建立TCP连接到网络异常的处理都做了包装 对数据处理灵活，Netty支持多种序列化框架，通过ChannelHandler机制，可以自定义“编/解码器” 对性能调优友好，Netty提供了线程池模式以及Buffer的重用机制（对象池化），不需要构件复制的多线程模型和操作队列。 从一个简单的例子开始​ 现在通过一个例子来讲解。假设有一个客户端去调用一个服务端，假设服务端叫做EchoServer，客户端叫做EchoClient，用Netty架构实现代码如下。 服务端代码​ 构建服务器端，假设服务器接受客户端传来的信息，然后在控制台打印。首先，生成EchoServer，在构件函数中传入需要监听的端口号。然后再编写服务的启动方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package server;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import java.net.InetSocketAddress;public class EchoServer &#123; private final int port; public EchoServer(int port) &#123; this.port = port; &#125; public void start() throws Exception&#123; final EchoServerHandler serverHandler = new EchoServerHandler(); // 1、创建EventLoopGroup EventLoopGroup group = new NioEventLoopGroup(); try &#123; // 2、创建ServerBootstrap ServerBootstrap b = new ServerBootstrap(); b.group(group) // 3、指定所使用的 NIO 传输 Channel .channel(NioServerSocketChannel.class) // 4、使用指定的端口设置套接字地址 .localAddress(new InetSocketAddress(port)) // 5、添加一个 EchoServerHandler 到 Channel 的 ChannelPipeline .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(serverHandler); &#125; &#125;); // 6、异步绑定服务器：调用sync()方法阻塞等到直到绑定完成 ChannelFuture f = b.bind().sync(); System.out.println(EchoServer.class.getName() + "started and listening for connections on " + f.channel().localAddress()); // 7、获取Channel 的 CloseFuture，并且阻塞当前线程直到它完成 f.channel().closeFuture().sync(); &#125;finally &#123; // 8、关闭EventLoopGroup，释放所有的资源 group.shutdownGracefully().sync(); &#125; &#125;&#125; ​ Server的启动方法涉及到了一些组件的使用，例如EventLoopGroup、Channel。这些后面会讲解，这里有个大概的印象就好： 创建EventLoopGroup。 创建ServerBootstrap。 指定所使用的NIO传输Channel。 使用指定的端口设置套接字地址。 添加一个ServerHandler到Channel的ChannelPipeline。 异步地绑定服务器，调用sync()方法阻塞等待直到绑定完成。 获取Channel的CloseFuture，并且阻塞当前线程直到它完成。 关闭EventLoopGroup，释放所有的资源。 ​ NettyServer启动以后会监听某个端口的请求，当接收到了请求就需要处理了。在Netty中客户端请求服务端，被称为“入站”操作。可以通过ChannelInboundHandlerAdapter实现，具体内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940package server;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFutureListener;import io.netty.channel.ChannelHandler;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import io.netty.util.CharsetUtil;@ChannelHandler.Sharablepublic class EchoServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf in = (ByteBuf) msg; //将消息记录到控制台 System.out.println("Server received：" + in.toString(CharsetUtil.UTF_8)); //将接收到的消息写给发送者，而不冲刷出站消息 ctx.write(in); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx)throws Exception &#123; //将未决消息冲刷到远程节点，并且关闭该 Channel ctx.writeAndFlush(Unpooled.EMPTY_BUFFER) .addListener(ChannelFutureListener.CLOSE); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; //打印异常栈跟踪 cause.printStackTrace(); //关闭该Channel ctx.close(); &#125;&#125; ​ 从上面的代码可以看出，服务端处理的代码包含了三个方法。这三个方法是根据事件触发的。它们分别是： 当接收到消息时的操作：channelRead。 消息读取完成时的方法：channelReadComplete。 出现异常时的方法：exceptionCaught 客户端代码​ 客户端和服务端的代码基本相似，在初始化时需要输入服务端的IP和Port。整个客户端的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package client;import io.netty.bootstrap.Bootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import java.net.InetSocketAddress;public class EchoClient &#123; private final String host; private final int port; public EchoClient(String host, int port) &#123; this.host = host; this.port = port; &#125; public void start() throws Exception&#123; EventLoopGroup group = new NioEventLoopGroup(); try &#123; // 创建 Bootstrap Bootstrap b = new Bootstrap(); // 指定 EventLoopGroup以处理客户端事件：需要适用于NIO的实现 b.group(group) // 适用于NIO传输的Channel 类型 .channel(NioSocketChannel.class) // 设置服务器的InetSocketAddress .remoteAddress(new InetSocketAddress(host, port)) // 在创建C喊你了时，向ChannelPipeline中添加一个 EchoClientHandler实例 .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new EchoClientHandler()); &#125; &#125;); // 连接到远程节点，阻塞等待直到连接完成 ChannelFuture f = b.connect().sync(); //阻塞，直到Channel 关闭 f.channel().closeFuture().sync(); &#125;finally &#123; // 关闭线程池并且释放所有的资源 group.shutdownGracefully().sync(); &#125; &#125;&#125; ​ 客户端的启动程序的顺序： 创建Bootstrap。 指定EventLoopGroup用来监听事件。 定义Channel的传输模式为NIO。 设置服务器的InetSocketAddress。 在创建Channel时，向ChannelPipeline中添加一个EchoClientHandler实例。 连接到远程节点，阻塞等待直到连接完成。 阻塞，直到Channel关闭。 关闭线程池并且释放所有的资源。 ​ 客户端在完成以上操作以后，会与服务端建立连接从而传输数据。同样在接受到Channel中触发的事件时，客户端会触发对应事件的操作。 1234567891011121314151617181920212223242526272829package client;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;import io.netty.util.CharsetUtil;public class EchoClientHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt; &#123; @Override public void channelActive(ChannelHandlerContext ctx) &#123; // 当被通知 Channel是活跃的时候，发送一条信息 ctx.writeAndFlush(Unpooled.copiedBuffer("Netty rocks!", CharsetUtil.UTF_8)); &#125; @Override public void channelRead0(ChannelHandlerContext ctx, ByteBuf in) throws Exception &#123; //记录已接收信息的转储 System.out.println("Client received：" + in.toString(CharsetUtil.UTF_8)); &#125; // 在发生异常时，记录错误并关闭Channel @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; ​ 例如Channel激活，客户端接受到服务端的消息，或者发生异常的捕获。 Netty核心组件​ 通过上面的例子，发现有些Netty组件在服务初始化以及通讯时被用到，下面就来介绍这些组件的用途和关系。 Channel​ 上面的例子可以看出，当客户端和服务端连接的时候会建立一个Channel。这个Channel可以理解为Socket连接，它负责基本的IO操作，例如：bind()、connect()、read()和write()等等。简单理解就是，Channel就是代表连接，实体之间的连接，程序之间的连接，文件之间的连接，设备之间的连接。同时它也是数据入站和出站的载体。 EventLoop和EventLoopGroup​ 既然有了Channel连接服务，让信息之间可以流动。如果服务发出的消息称作“出站”消息，服务接受的消息称作“入站”消息，那么消息的“出站”/“入站”就会产生事件（Event）。例如：连接已激活；数据读取；用户事件；异常事件；打开链接；关闭链接等待。 ​ 顺着这个思路往下想，有了数据，数据的流动产生事件，那么就有一个机制去监控和协调事件。这个机制（组件）就是EventLoop。在Netty中每个Channel都会被分配到一个EventLoop，而一个EventLoop可以服务多个Channel。而每个EventLoop会占用一个Thread，同时这个Thread会处理EventLoop上面发生的所有IO操作和事件（Netty 4.0）。 ​ 理解了EventLoop，理解EventLoopGroup就容量了。EventLoopGroup是用来生成EventLoop的。上面的例子代码中第一行就new了EventLoopGroup对象。一个EventLoopGroup包含了多个EventLoop对象，而EventLoopGroup要做的就是创建一个新的Channel，并且给他分配一个EventLoop。 ​ 在异步传输的情况下，一个EventLoop是可以处理多个Channel中产生的事件的，它主要的工作就是事件的发现以及通知。相对于以前一个Channel就占用一个Thread的情况，Netty的方式要合理多了。 ​ 客户端发送消息到服务端，EventLoop发现以后会告诉服务端：“你去获取消息”，同时客户端进行其他的工作；当EventLoop检测到服务端返回的消息，也会通知客户端：“消息返回了，你去取吧”。客户端再去获取消息。整个过程EventLoop就是监视器 + 传声筒。 ChannelHandler，ChannelPipeline和ChannelHandlerContext​ 如果说EventLoop是事件的通知者，那么ChannelHandler就是事件的处理者。在ChannelHandler中可以添加一些业务代码，例如数据转换，逻辑运算等等。正如上面的例子中展示的，Server和Client分别都有一个ChannelHandler来处理，读取信息，网络可用，网络异常之类的信息。并且，针对出站和入站的事件，有不同的ChannelHandler，分别是： ChannelInBoundHandler（入站事件处理器） ChannelOutBoundHandler（出站事件处理器） ​ 假设每次请求都会触发事件，而由ChannelHandler来处理这些事件，这个事件的处理顺序是由ChannelPileLine来决定的。 ​ ChannelPipeline为ChannelHandler链提供了容器，到Channel被创建的时候，会被Netty框架自动分配到ChannelPipeline上。ChannelPipeline保证了ChannelHandler按照一定顺序处理事件，当事件触发以后，会将数据通过ChannelPipeline按照一定的顺序通过ChannelHandler。级，ChannelPipeline是复制“排队”的。这里的“排队”是处理事件的顺序。同时，ChannelPipeline也可以添加或者删除ChannelHandler，管理这个队列。 ​ 如上图，ChannelPipeline使ChannelHandler按照先后顺序排列，信息按照箭头所示方向流动并且被ChannelHandler处理。 ​ 说完了ChannelPipeline和ChannelHandler，前者管理后者的排列顺序。那么它们之间的关联就有ChannelHandlerContext来表示了。每当有ChannelHandler添加到ChannelPipeline时，同时会创建ChannelHandlerContext。ChannelHandlerContext的主要功能就是管理ChannelHandler和ChannelPipeline的交互。 ​ 上面的例子中，几乎ChannelHandler中每个处理事件函数，传入的参数就ChannelHandlerContext。ChannelHandlerContext参数贯穿ChannelPipeline，将信息传递给每个ChannelHandler，是个合格的“通讯员”。 ​ 把上面提到的几个核心组件归纳一下，用下图表示方便记忆它们之间的关系： Netty的数据容器​ 前面介绍了Netty的几个核心组件，服务器在数据传输的时候，产生事件，并且对事件进行监控和处理。接下来看数据是如何存放以及读写的。Netty将ByteBuf作为数据容器，来存放数据。 ByteBuf工作原理​ 从结构上来说，ByteBuf由一串字节数组构成。数组中每个字节用来存放信息。ByteBuf提供了两个索引，一个用于读取数据，一个用于写入数据，这两个索引通过在字节数组中移动，来定位需要或者读写信息的位置。当从ByteBuf读取时，它的readerIndex（读索引）将会根据读取的字节数递增。同样，当写ByteBuf时，它的writeIndex也会根据写入的字节数进行递增。 ​ 需要注意的是极限的情况是readerIndex刚好读到了writeIndex写入的地方。如果readerIndex超过了writeIndex的时候，Netty会抛出IndexOutOfBoundsException异常。 ByteBuf使用模式​ 说了ByteBuf的工作原理后，再来看它的使用模式。根据存放缓冲区的不同分为三类： 堆缓冲区：ByteBuf将数据存储在JVM的堆中，通过数组实现，可以做到快速分配。由于在堆上被JVM管理，在不被使用时可以快速释放。可以通过ByteBuf.array()来获取byte[]数据。 直接缓冲区：在JVM的堆之外直接分配内存，用来存储数据。其不占用堆空间，使用时需要考虑内存容量。它在使用Socket传递时性能较好，因为间接从缓冲区发送数据，在发送之前JVM会先将数据复制到直接缓冲区再进行发送。由于直接缓冲区的数据分配在堆之外，通过JVM进行垃圾回收，并且分配时也需要做复制的操作，因此使用成本较高。 复合缓冲区：顾名思义就是将上述两类缓冲区聚合在一起。Netty提供了一个CompsiteByteBuf，可以将堆缓冲区和直接缓冲区的数据放在一起，让使用更加方便。 ByteBuf的分配​ 接下来看看ByteBuf如何分配缓冲区的数据。Netty提供了两种ByteBufAllocator的实现，他们分别是： PooledByteBufAllocator：实现了ByteBuf的对象的池化，提高性能减少内存碎片。 UnpooledByteBufAllocator：没有实现对象的池化，每次会生成新的对象实例。 ​ 对象池化的技术和线程池比较相似，主要目的是提高内存的使用率。池化的简单实现思路，是在JVM堆内存上构建一层内存池，通过allocate方法获取内存池中的空间，通过release方法将空间归还给内存池。 ​ 对象的生成和销毁，会大量地调用allocate和release方法，因此内存池面临碎片空间回收的问题，在频繁申请和释放空间后，内存池需要保证连续的内存空间，用于对象的分配。基于这个需求，有两种算法用于优化这一块的内存分配：伙伴系统和slab系统。 ​ 伙伴系统，用完全二叉树管理内存区域，左右节点互为伙伴，每个节点代表一个内存块。内存分配将大块内存不断二分，直到找到满足所需的最小内存分片。内存释放会判断释放内存分片的伙伴（左右节点）是否空闲，如果空闲则将左右节点合成更大快内存。 ​ slab系统，主要解决内存碎片问题，将大块内存按照一定内存大小进行等分，形成相等大小的内存片构成的内存集。按照内存申请空间的大小，申请尽量小块内存或者其整数倍的内存。释放内存时，也是将内存分片归还给内存集。 ​ Netty内存池管理以Allocate对象的形式出现。一个Allocate对象由多个Arena组成，每个Arena能执行内存块的分配和回收。Arena内有三类内存管理单元： TinySubPage SmallSubPage ChunkList ​ Tiny和Small符合Slab系统的管理策略，ChunkList符合伙伴系统的管理策略。当用户申请内存介于tingSize和smallSize之间时，从tinySubPage中获取内存块；申请内存介于smallSize和pageSize之间时，从smallSubPage中获取内存块；介于pageSize和chunkSize之间时，从ChunkList中获取内存；大于ChunkSize（不知道分配内存的大小）的内存块不通过池化分配。 Netty的Bootstrap​ 说完了Netty的核心组件以及数据存储。回到最开始的例子程序，在程序最开始的时候会new一个Bootstrap对象，后面所有的配置都是基于这个对象展开的。Boosttrap的作用就是将Netty核心组件配置到程序中，并且让他们运行起来。 ​ 从Bootstrap的继承结构来看，分为两类，分别是Bootstrap和ServerBootstrap，一个对应客户端的引导，一个对应服务端的引导。 ​ 客户端引导Bootstrap，主要有两个方法：bind()和connetct()。Bootstrap通过bind()方法创建一个Channel。在bind()之后，通过调用connect()方法来创建Channel连接。 ​ 服务端引导ServerBootstrap，与客户端不同的是在bind()方法之后会创建一个ServerChannel，它不仅会创建新的Channel，还会管理已经存在的Channel。 ​ 通过上面的描述，服务端和客户端的引导存在两个区别： ServerBootstrap（服务端引导）绑定一个端口，用来监听客户端的连接请求。而Bootstrap（客户端引导）只要知道服务端IP和Port建立连接就可以了。 Bootstrap（客户端引导）需要一个EventLoopGroup，但是ServerBootstrap（服务端引导）则需要两个EventLoopGroup。因为服务器需要两组不同的Channel。第一组ServerChannel自身监听本地端口的套接字，第二组用于监听客户端请求的套接字。 总结​ 我们从NIO入手，谈到了Selector的核心机制。然后通过介绍Netty客户端和服务端的代码运行流程。让大家对Netty编写代码有基本的认识。 ​ 在Netty的核心组件中，Channel提供Socket的连接通道，EventLoop会对应Channel监听其产生的事件，并且通知执行者。EventLoopGroup负责生成和管理EventLoop。 ​ ChannelPipeline作为ChannelHandler的容器会绑定到Channel上，然后由ChannelHandler提供具体事件处理。另外，ChannelHandlerContext为ChannelHandler和ChannelPipeline提供信息共享。 ​ ByteBuf作为Netty的数据容器，通过字节数组的方式存储数据，并且通过读索引和写索引来引导读写操作。 ​ 上述的核心组件都是通过Bootstrap来配置并且引导启动的，Bootstrap启动方式虽然一致，但是针对客户端和服务端有些许的区别。 参考资料Netty底层架构原理]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ详解]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F10%2FRocketMQ%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MQ 集群化部署以支撑高并发访问假设 RocketMQ 部署在一台机器上，即使这个机器的配置很高，但一般来说一台机器也就是支撑 10万+ 的并发访问。如果这个时候，有大量的系统都要往 RocketMQ 里高并发的写入消息，可能达到每秒几十万请求，这个时候就要将 RocketMQ 进行集群化部署，部署在多台机器上。假设每台机器能抗 10 万并发，只要让几十万请求分散到多台机器上接可以了。 MQ 存储海量消息一般情况下，MQ 收到的大量消息并不是立马会被所有的消费方获取过去消费，所以 MQ 一般都得把消息在自己本地磁盘存储起来，然后等到消费方去处理。这样，MQ 就得存储大量的消息，可能是几百万条，甚至几亿条，这么多的消息在一台机器上是没法存储的，那 RocketMQ 是如何处理的？ 其实发送消息到 MQ 的系统会把消息分散发送给多台不同的机器，假设有一万条消息，分散发送给 10 台机器，可能每台机器就是接收到 1000 条消息。 其次，每台机器上部署的 RocketMQ 进程一般称之为 Broker，每个 Broker 都会接收到不同的消息，然后就会把这批消息存储在自己本地的磁盘文件里。 高可用保障如果某一台 Broker 宕机了，导致 RocketMQ 里一部分的消息没了，这就会导致 MQ 的不可靠和不可用。而RocketMQ的解决思路就是 Broker 主从架构以及多副本策略。 简单来说，Broker 有 Master 和 Slave 两种角色： Master Broker 收到消息之后会同步给Slave Broker，这样 Slave Broker 上就能有一模一样的一份副本数据。这个时候如果任何一个 Master Broker 出现故障，还有一个Slave Broker上有一份数据副本，可以保证数据不丢失，还能继续对外提供服务，保证了 MQ 的可靠性和高可用性。 数据路由：消息中间件路由中心对于系统来说，要发送消息到 MQ 去，还要从 MQ 里消费信息，因此需要解决一个问题：大家怎么知道有哪些 Broker？怎么知道要连接哪一台 Broker 上去发送和接收消息？RocketMQ 为了解决这个问题，有一个 NameServer 的概念。它也是独立部署在几台机器上，然后所有的 Broker 都会把自己注册到 NameServer 上去，NameServer 就知道集群里有哪些Broker了。 对于我们系统而言，如果它要发送消息到 Broker，会找 NameServer 去获取路由信息，就是集群里有哪些 Broker 等信息；如果系统要从 Broker 获取消息，也会找 NameServer 获取路由信息，去找到对应的 Broker 获取消息。 NameServer 的集群化部署NameServer 集群化部署的一个主要原因，就是高可用性。NameServer 是集群里非常关键的一个角色，它要管理 Broker 信息，别人都要通过它才知道跟哪个 Broker 通信，如果 NameServer 就部署一台机器的话，一旦 NameServer 宕机了，就会导致 RocketMQ 集群出现故障。所以通常来说，NameServer 一定会多机器部署，实现一个集群，起到高可用的效果。 Broker挂了，NameServer 如何感知一个 Broker 启动之后向 NameServer 注册了，每个 NameServer 都知道集群里有这么一台 Broker 的存在了，然后各个系统从 NameServer 也拉取到了一台信息，知道集群里有这么一台 Broker，但如果这台 Broker 挂了之后，NameServer 要如何感知？ 这个问题的解决靠的就是 Broker 跟 NameServer 之间的心跳机制，Broker 会每隔 30s 给所有的 NameServer 发送心跳，告诉每个 NameServer 自己还活着，每次 NameServer 收到一个 Broker 的心跳，就可以更新一下它的最近一次心跳的时间，然后每隔 10s 运行一个任务，去检查各个 Broker 最近的一次心跳时间，如果某个 Broker 超过 120s 都没发送心跳了，那么就认为这个 Broker 已经挂掉了。 Broker 的主从架构Master Broker 如何将消息同步给 Slave Broker一般情况下，为了保证 MQ 的数据不丢失且具备一定的高可用性，所以一般都是将 Broker 部署成 Master-Slave 模式的，也就是一个 Master Broker 对应一个 Slave Broker。然后 Master 需要在接收的到消息之后，将数据同步给 Slave，这样一旦 Master Broker 挂了，还有 Slave 上有一份数据。需要注意的是，Slave Broker 也会向所有的 NameServer 进行注册，也会向所有的 NameServer 每 30s 发送心跳。 那么，Master Broker 是如何将消息同步给 Slave Broker 的？答案是 RocketMQ 自身的 Master-Slave 模式采取的是 Slave Broker 不停地发送请求到 Master Broker 去拉取消息。即我们要明白一点，就是 RocketMQ 自身的 Master-Slave 模式采取的是 Pull 模式拉取消息。如图： RocketMQ 有实现读写分离吗既然 Master Broker 主要是接收系统的消息写入，然后会同步给 Slave Broker，那么 Slave Broker 也应该有一份一样的数据。所以，作为消费者的系统在获取消息的时候，是从 Master Broker 获取的？还是从 Slave Broker 获取的？ 其实都不是，答案是：有可能是从 Master Broker 获取消息，也有可能从 Slave Broker 获取消息。作为消费者的系统在获取消息的时候会先发送请求到 Master Broker 上去，请求获取一批消息，此时 Master Broker 是会返回一批消息给消费者系统的。 然后 Master Broker 在返回消息给消费者系统的时候，会根据当时 Master Broker 的负载情况和 Slave Broker 的同步情况，向消费者建议下一次拉取消息的时候是从 Master Broker 拉取还是从 Slave Broker 拉取。 例如，要是这个时候 Master Broker 负载很重，本身要抗 10 万写并发了，你还要从它这里拉取信息，增加负担，那肯定是不合适的。此时 Master Broker 就会建议你从 Slave Broker 去拉取消息。又或者，本身这个时候 Master Broker 上都已经写入了 100 万条数据了，但是Slave Broker 不知道啥原因，才同步了 96 万条数据，落后了整整 4 万条消息的同步，这个时候你作为消费者系统可能都已经获取到 96 万条数据了，那么下次还是只能从 Master Broker 去拉取消息。因为 Slave Broker 同步太慢了，导致你没法从它那里获取更新的消息了。 所以这一切都会有 Master Broker 根据情况来决定，如图： 总结一下就是：在写入消息的时候，通常来说肯定是选择 Master Broker 去写入的，但是在拉取消息的时候，有可能从 Master Broker 获取，也可能从 Slave Broker 去获取，一切都根据当时的情况来定。 Slave Broker 挂掉了会有什么影响如果 Slave Broker 挂掉了，那么会对这个系统有一点影响，但是影响并不大。因为消息写入全部是发送到 Master Broker 的，然后消息获取也可以走 Master Broker，只不过有一些消息获取可能是从 Slave Broker 去走的。 所以如果 Slave Broker 挂了，那么此时无论消息写入还是拉取，还是可以继续从 Master Broker 去走，对整体运行不影响。只不过少了 Slave Broker，会导致所有读写压力都集中在 Master Broker 上。 Master Broker 挂掉了会有什么影响如果 Master Broker 挂掉了，这个时候对消息的写入和获取都有一定的影响。但是，Slave Broker 也是跟 Master Broker 一样有一份数据在的，只不过 Slave Broker 上的数据可能有部分没来得及从 Master Broker 同步。但是此时RocketMQ 可以实现直接自动将 Slave Broker 切换为 Master Broker 吗？ 在 RocketMQ 4.5 版本之前，是不能的。所以在这种情况下，如果 Master Broker 宕机了，这是就得手动做一些运维操作，把 Slave Broker 重新修改一些配置，重启机器给调整为 Master Broker，这有点麻烦，而且会导致中间一段时间不可用。所以这种 Master-Slave 模式不是彻底的高可用模式，它没法实现自动把 Slave 切换为 Master。 基于 Dledger 实现 RocketMQ 高可用自动切换在 RocketMQ 4.5 之后，这种情况得到看改变，因为 RocketMQ 支持了一种新的机制，叫做 Dledger。简单来说，把 Dledger 融入 RocketMQ 之后，就可以让一个 Master Broker 对应多个 Slaver Broker，也就是一份数据可以有多份副本，比如一个 Master Broker 对应两个 Slave Broker。然后依然会在 Master 和 Slave 之间进行数据同步。 此时一旦 Master Broker 宕机了，就可以在多个 Slave 中，通过 Dledger 技术和 Raft 协议算法进行 leader 选举，直接将一个 Slave Broker 选举为新的 Master Broker，然后这个新的 Master Broker 就可以对外提供服务了。 这个过程也许只要 10 秒或者几十秒的时间就可以完成，这样的话，就可以实现 Master Broker 挂掉之后，自动从多个 Slave Broker 中选举出来一个新的 Master Broker，继续对外服务，一切都是自动的。 所以，我们在设计 RocketMQ 生成部署架构的时候，可以采用基于 Dledger 的部署方式，这样可以让 RocketMQ 做到自动切换故障了。 Broker 如何跟 NameServer 进行通信上面说过，Broker 会每隔 30 秒发送心跳到所有的 NameServer 上去，然后每个 NameServer 都会每隔 10s 检查一次有没有哪个 Broker 超过 120s 没发送心跳。如果有，就认为那个 Broker 已经宕机了，从路由信息里要摘除这个 Broker。 那么 Broker 和 NameServer 是如何进行通信的呢？在 RocketMQ 的实现中，Broker 和 NameServer 之间的通信是采用 TCP 长连接进行通信的。也就是说，Broker 会跟每个 NameServer 都建立一个 TCP 长连接，然后定时通过 TCP 长连接发送心跳请求过去。 所以各个 NameServer 就是通过跟 Broker 建立好的长连接不断收到心跳包，然后定时检查 Broker 有没有 120s 都没发送心跳包，来判定集群里各个 Broker 到底挂掉了没有。 MQ 的核心数据模型：Topic生产者和消费者都会往 MQ 里写入消息和获取消息，但是，MQ 中的数据模型是什么？你投递出去的消息在逻辑上到底是放到哪去的？ 这就涉及到一个概念，这个就是 MQ 中的核心数据模型：Topic。这个 Topic，表达的意思就是一个数据集合的意思。举个例子，现在你的订单系统都是进入这个 “topic_order_info” 里面去的，如果你的仓储系统要获取订单消息，那么它可以指定从 “topic_order_info” 这里面去获取消息，获取出来得都是它想要的订单消息。 总结起来就是，Topic 其实就是一个数据集合的意思，不同类型的数据你得放到不同的 Topic 里去。要是你有一些商品数据要发送到 MQ 里，你就应该创建一个 Topic 叫做 “topic_product_info”，代表里面都是商品数据，那些想要从 MQ 里获取商品数据的系统就可以从 “topic_product_info” 里获取了。 所以，你的系统如果要往 MQ 里写入信息或者获取信息，首先就得创建一些 Topic，作为数据集合存放不同类型的消息。 Topic 怎么在 Broker 集群里存储那我们创建的那些 Topic 是怎么存储在 Broker 集群里的？这就体现出一个分布式存储的概念了。 如果我们有一个订单 Topic，可能订单系统每天都会往里面投递几百万条数据，然后这些数据在 MQ 的集群上还得保留几天，那么最终可能会有几千万的数据量，这还只是一个 Topic。如果有多个 Topic，并且里面都有大量的数据，最终加起来的总和也许就是一个惊人的数字，而这么大的数据本身是不太可能存放在一台机器上的。这个时候，就需要分布式存储了。 我们可以在创建 Topic 的时候指定让它里面的数据分散存储在多台 Broker 机器上，比如一个 Topic 里有 1000 万条数据，此时有 2 台Broker，那么可以让每台 Broker 都放 500 万条数据。这样就可以把一个 Topic 代表的数据集合分布式存储在多台机器上了。 另外很重要的一件事是，每个 Broker 在进行定时的心跳汇报给 NameServer 的时候，都会告诉 NameServer 自己当前的数据情况，比如有哪些 Topic 的哪些数据在自己这里，这些信息都是属于路由信息的一部分。 生产者系统如何将消息发送给 Broker接下来，生产者系统是如何将消息发送到 Broker 上的？ 我们在上面说过，在发送消息之前，得有一个 Topic，然后在发送消息的时候你得指定你要发送到哪个 Topic 里面去。既然你知道你要发送的 Topic，那么就可以跟 NameServer 建立一个 TCP 长连接，然后定时从它那里拉取到最新的路由信息，包括集群里有哪些 Broker，集群里有哪些 Topic，每个 Topic 都存储在哪些 Broker上。 然后生产者系统就可以通过路有信息找到自己要投递的 Topic 分布在哪几台 Broker 上。此时可以根据负载均衡算法，从里面选择一台 Broker机器出来。比如 round robine 轮询算法，或者 hash 算法等等。然后选择一台 Broker 之后，就可以跟那个 Broker 也建立一个 TCP 长连接，然后通过长连接向 Broker 发送消息即可。 这里要注意的一点是，生产者一定是投递消息到 Master Broker 的，然后 Master Broker 会同步数据给它的 Slave Brokers，实现一份数据多份副本，保证 Master 故障的时候数据不丢失，而且可以自动把 Slave 切换为 Master 提供服务。 消费者如何从 Broker 上拉取消息消费者系统跟生产者原理是类似的。它们也会跟 NameServer 建立长连接，然后拉取路由消息，接着找到自己要获取的 Topic 在哪几台 Broker 上，就可以跟 Broker 建立长连接，从里面拉取消息了。 这里要注意的一点是，消费者系统可能会从 Master Broker 拉取消息，也可能从 Slave Broker 拉取消息。一切都看具体情况。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM工具使用-使用jmap和jhat弄清楚线上系统的对象分布]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F09%2FJVM%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8-%E4%BD%BF%E7%94%A8jmap%E5%92%8Cjhat%E5%BC%84%E6%B8%85%E6%A5%9A%E7%BA%BF%E4%B8%8A%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AF%B9%E8%B1%A1%E5%88%86%E5%B8%83%2F</url>
    <content type="text"><![CDATA[​ JVM中有两个非常实用的工具：jmap和jhat。这两个工具可以帮助我们观察线上JVM中的对象分布，了解到你的系统运行过程中，哪些对象占据了主角位置，占据了多少内存空间，让你对你的系统有更加细致的了解。 使用jmap了解系统运行时的内存区域​ 如果只是要了解JVM的运行状况，然后去进行JVM GC优化，一般情况下jstat就够用了。但是有时候我们会发现JVM新增对象的速度很快，想要了看看，到底什么对象占据了那么多的内存。如果发现有的对象在代码中可以优化一下创建的时机，避免多种对象对内存占用过大，也许甚至可以去反过来优化一下代码。当然，如果不是出现OOM那种极端情况，也没有那么大的必要着急优化代码。 ​ 先看一个命令：jmap -heap PID，这个命令可以打印出来一系列的信息，大致来说，这个信息会打印出来堆内存相关的一些参数设置，然后就是当前堆内存里的一些基本各个区域的情况。比如Eden区总容量，已经使用的容量、剩余空间容量、两个Survivor区的总容量、已经使用的容量和剩余的空间容量、老年代的总容量、已经使用和剩余的容量等等。 ​ 但是其实这些信息jstat就已经有了，所以一般不会用jmap去看这些信息，毕竟它的信息还没jstat全，例如缺少gc相关的统计。 使用jmap了解系统运行时的对象分布​ jmap命令比较有用的使用方式，是jmap -histo PID。这个命令会打印出类似下面的信息： ​ 这个命令打印出来的东西，会按照各种对象占用内存空间的大小降序排列，把占用内存最多的对象放在最上面。所以如果你只是想要简单了解一下当前JVM中的对象对内存占用的情况，直接使用jmap -histo命令即可。这样就可以快速了解到当前内存里到底是哪个对象占用了大量的内存空间。 使用jmap生成堆内存转储快照​ 如果上面的信息还不够深入，想要更仔细点的。那就可以使用jmap命令生成一个堆内存快照放到一个文件里，用如下的命令：jmap -dump:live,format=b,file=dump.hprof PID。这个命令会在当前目录下生成一个dump.hrpof文件，你不能直接打开看得，它把这一时刻JVM堆内存里所有对象的快照放到文件里去，以方便后续去分析。 使用jhat在浏览器中分许堆转储快照​ 接着就可以使用jhat去分析堆快照了。jhat内置了web服务器，它会支持你通过浏览器以图形化的方式分析堆转储快照。使用jhat dump.hprof命令即可启动jhat服务器，还可以指定自己想要的http端口号，默认是7000端口号。接着你就在浏览器上访问当前这台机器的7000端口号，就可以通过图形化的方式去分析堆内存里的对象分布情况了。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM工具使用-使用jstat了解线上系统的JVM运行状况]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F02%2FJVM%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8-%E4%BD%BF%E7%94%A8jstat%E4%BA%86%E8%A7%A3%E7%BA%BF%E4%B8%8A%E7%B3%BB%E7%BB%9F%E7%9A%84JVM%E8%BF%90%E8%A1%8C%E7%8A%B6%E5%86%B5%2F</url>
    <content type="text"><![CDATA[​ 平时我们对运行中的系统，如果要检查他的JVM的整体运行情况，比较实用的工具是jstat。它可以让你看到当前运行中的系统，它的JVM内的Eden、Survivor、老年代的内存使用情况，还有Young GC和Full GC的执行次数以及耗时。通过这些指标，我们可以分析出当前系统的运行情况，判断当前系统的内存使用压力以及GC压力，还有就是内存分配是否合理。 jstat的使用jstat -gc PID​ 首先要在生产机器linux上，找出Java进程的PID。接着就针对我们的Java进程执行jstat -gc PID。这样就可以看到这个Java进程（其实本质就是一个JVM）的内存和GC情况了。 ​ 运行这个命令之后会看到如下列： 123456789101112131415S0C：这是From Survivor区的大小S1C：这是To Survivor区的大小S0U：这个From Survivor区当前使用的内存大小S1U：这是To Survivor区当前使用的内存大小EC：这是Eden区的大小EU：这是Eden区当前使用后的内存大小OC：这是老年代的大小OU：这是老年代当前使用的内存大小MC：这是方法区（永久代、元数据区）的大小MU：这是方法区（永久代、元数据区）的当前使用的内存大小YGC：这是系统运行迄今为止的Young GC次数YGCT：这是Young GC的耗时FGC：这是系统运行迄今为止的Full GC次数FGCT：这是Full GC的耗时GCT：这是所有GC的总耗时 其他的jstat命令​ 除了上面的jstat -gc命令是最常用的以外，它还有一些命令可以看到更多详细的信息： 123456jstat -gccapacity PID：堆内存分析jstat -gcnew PID：年轻代GC分析，这里的TT和MTT可以看到对象在年轻代存活的年龄和存活的最大年龄jstat -gcnewcapacity PID：年轻代内存分析jstat -gcold PID：老年代GC分析jstat -gcoldcapacity PID：老年代内存分析jstat -gcmetacapacity PID：元数据区内存分析 如何使用jstat工具​ 一般我们分析线上JVM线程，最想知道的信息有哪些？包括如下：新生代对象增长的速率、Young GC的触发频率，Young GC的耗时，每次Young GC后有多少对象是存活下来的，每次Young GC过后有多少对象进入了老年代、老年代对象增长的速率，Full GC的触发频率，Full GC的耗时。 新生代对象增长的速率​ 这其实是对JVM第一个要了解的事情，就是随着系统运行，每秒种会在年轻代的Eden区分配多少对象。要分析这个，你只要在线上linux机器上运行如下命令：jstat -gc PID 1000 10。它的意思是每隔一秒钟更新出最新的一行jstat统计信息，一共执行10次jstat统计。 ​ 通过这个命令，可以非常灵活的对线上机器通过固定频率输出统计信息，观察每隔一段时间的jvm中的Eden区对象占用变化。例如，执行这个命令后，第一秒先显示出Eden区使用了200MB内存，第二秒显示出的统计信息里，Eden区使用了205MB，第三秒显示出Eden区使用了209MB内存，以此类推。此时你就可以推断出这个系统每秒种会新增5MB左右的对象。 ​ 这里大家可以根据自己系统的情况灵活多变地使用，比如系统负载很低，不一定每秒都有请求，那么可以把上面的1秒钟调整为1分钟，甚至10分钟，去看你们系统每隔一定时间大概增长多少对象。还有就是一般系统都有高峰和日常两种状态，比如系统高峰期用的人很多，此时就应该用上述命令看看高峰期的对象增长率，然后还得在非高峰的日常时间段内看看对象的增长速率。 Young GC的触发频率和每次耗时​ 多久触发一次Young GC很容易推测出来，因为系统高峰和日常的对象增长速率都知道了，那么非常简单就可以推测出高峰期多久发生一次Young GC，日常期多久发生一次Young GC。 ​ 比如你Eden区有800MB内存，发现高峰期每秒新增5MB对象，大概高峰期就是3分钟会触发一次Young GC。日常期每秒新增0.5MB，那么日常期大概需要半个小时才会触发一次Young GC。 ​ 至于如何计算Young GC的平均耗时，jstat会告诉你迄今为止系统已经发生了多少次Young GC以及这些Young GC的总耗时。例如系统运行24小时后发生了260次Young GC，总耗时为20s，那么平均下来每次Young GC大概就耗时几十毫秒的时间，你就知道每次Young GC的时候会导致系统停顿几十毫秒。 每次Young GC后有多少对象是存活和进入老年代​ 接着我们想知道每次Young GC后有多少对象会存活下来，以及有多少对象会进入老年代。这个没办法直接看出来，但有办法可以大概推算出来。 ​ 之前我们推算出高峰期的时候多久发生一次Young GC，比如3分钟会有一次Young GC，那么此时我们可以执行下述jstat命令：jstat -gc 180000 10。这就是让他每隔三分钟执行一次统计，连续执行十次。此时可以观察一下，每隔三分钟之后发生了一次Young GC，此时Eden、Survivor和老年代的对象变化。 ​ 正常来说，Eden区肯定会几乎放满之后重新变得里面对象很少，比如800MB的空间就使用了几十MB，Survivor区肯定会放入一些存活对象，老年代可能会增长一些对象占用，所以这里的关键，就是观察老年代的对象增长速率。 ​ 一般情况下，老年代的对象不太可能不停地快速增长的，因为普通的系统没那么多长期存活的对象，如果你发现每次Young GC过后，老年代对象都要增长几十MB，那很有可能就是你一次Young GC过后存活的对象太多了。存活的对象太多，可能导致放入到Survivor区域之后触发了动态年龄判定规则进入老年代，也可能是Survivor区域放不下了，所以大部分存活对象进入老年代。 ​ 最常见的情况是这种：如果你的老年代每次在Young GC过后就新增几百KB，或者几MB的对象，这个还算情有可原，但是如果老年嗲对象快速增长，那一定是不正常的。所以通过上述观察策略，你就可以知道每次Young GC过后多少对象是存活的，实际上Survivor区域里和进入老年代的对象，都是存活的。你也可以知道老年代对象的增长速率，比如每隔3分钟一次Young GC，每次会有50MB对象进入老年代，这就是老年代对象的增长速率，每隔3分钟增长50MB。 Full GC的触发时机和耗时​ 只要知道了老年代对象的增长速率，那么Full GC的触发时机就很清晰了。比如老年代总共有800MB的内存，每隔3分钟新增50MB对象，那么大概每小时就会触发一次Full GC。然后可以看到jstat打印出来的系统运行迄今为止的Full GC次数以及总耗时，比如一共执行了10次Full GC，总耗时30s，每次Full GC大概就是需要耗费3s左右。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之看懂垃圾回收的日志]]></title>
    <url>%2FCKING.github.io%2F2019%2F11%2F29%2FJVM%E4%B9%8B%E7%9C%8B%E6%87%82%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%9A%84%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[打印JVM的GC日志​ 如果想打印GC日志，需要在系统的JVM参数中加入GC日志的打印选型，如下： 123-XX:+PrintGCDetail #打印详细的gc日志-XX:+PrintGCTimeStamps #打印出每次GC发生的时间-Xloggc:log #设置将gc日志写入一个磁盘文件 示例示例程序代码12345678910111213public class Demo1 &#123; public static void main(String[] args) &#123; byte[] array1 = new byte[1024 * 1024]; array1 = new byte[1024 * 1024]; array1 = new byte[1024 * 1024]; array1 = null; byte[] array2 = new byte[2 * 1024 * 1024]; &#125;&#125; ​ 给上述程序配置一下JVM参数： 1-XX:NewSize=5242880 -XX:MaxNewSize=5242880 -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:SurvivorRatio=8 -XX:PretenureSizeThreshold=10485760 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log ​ 这些JVM参数的意思是给堆内存分配10MB内存空间，其中新生代是5MB内存空间，其中Eden区占4MB，每个Survivor区占0.5MB，大对象必须超过10MB才会直接进入老年低，年轻代使用ParNew垃圾回收器，老年代使用CMS垃圾回收器，如图所示： 对象如何分配在Eden区内的​ 上面的代码比较简单。先通过“new byte[1024 * 1024]”这样的代码连续分配了3个数组，每个数组都是1MB。然后通过array1这个局部变量依次引用这三个对象，最后还把array1这个局部变量指向了null。那么在JVM中上述代码如何运行？ ​ 首先第一行代码：byte[] array1 = new byte[1024 * 1024]。这个代码一运行，会在JVM的Eden区内放一个1MB的对象，同时在main线程的虚拟机栈中会压入一个main()方法的桢栈，在main()方法桢栈内部，会有一个“array1”变量，这个变量是指向堆内存Eden区的那个1MB的数组，如下图： ​ 接着第二行代码：array1 = new byte[1024 * 1024]。此时会在堆内存的Eden区中创建第二个数组，并且让局部变量指向第二个数组，然后第一个数组就没人引用了，此时第一个数据就变了没人引用的“垃圾对象”，如图所示： ​ 然后第三行代码：byte[] array1 = new byte[1024 * 1024]。这行代码在堆内存的Eden区内创建了第三个数组，同时让array1变量指向了第三个数组，此时前面两个数组都没有引用了，变成了垃圾对象。 ​ 第四行代码：array1 = null。这行代码一执行，就让array1这个变量什么都不指向，此时会导致之前创建的3个数组全部变成垃圾对象，如图： ​ 最后第五行代码：byte[] array2 = new byte[2 * 1024 * 1024]。此时会分配一个2MB大小的数组，尝试放入Eden区中。但这是不行的，因为Eden区总共就4MB大小，而且里面已经放入了3个1MB的数组，所以剩余空间只有1MB，此时放一个2MB的的数组是放不下的。这个时候就会触发年轻代的Young GC。 讲解GC日志​ 当我们以指定的JVM参数运行，会在根目录生成一个文件gc.log。打开gc.log文件，会看到如下内容： 1234567891011121314151617181920212223Java HotSpot(TM) 64-Bit Server VM (25.151-b12) for windows-amd64 JRE (1.8.0_151-b12), built on Sep 5 2017 19:33:46 by "java_re" with MS VC++ 10.0 (VS2010)Memory: 4k page, physical 33450456k(25709200k free), swap 38431192k(29814656k free)CommandLine flags: -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:MaxNewSize=5242880 -XX:NewSize=5242880 -XX:OldPLABSize=16 -XX:PretenureSizeThreshold=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:-UseLargePagesIndividualAllocation -XX:+UseParNewGC0.268: [GC (Allocation Failure) 0.269: [ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs] 4030K-&gt;574K(9728K), 0.0017518 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]Heappar new generation total 4608K, used 2601K [0x00000000ff600000, 0x00000000ffb00000, 0x00000000ffb00000) eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000)concurrent mark-sweep generation total 5120K, used 62K [0x00000000ffb00000, 0x0000000100000000, 0x0000000100000000)Metaspace used 2782K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K ​ 现在让我们来讲解一下这个日志。 ​ 首先在GC日志中，可以看到以下内容： CommandLine flags: -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:MaxNewSize=5242880 ......... ​ 这是说明这次运行程序采取的JVM参数是什么，基本是我们设置的，同时还有一些参数默认就给设置了，不过一般关系不大。 ​ 接着看GC日志中的如下一行： 0.268: [GC (Allocation Failure) 0.269: [ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs] 4030K-&gt;574K(9728K), 0.0017518 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] ​ 这个就是概要说明了本次GC的执行情况。GC (Allocation Failure)是发生GC的原因，我们要分配一个2MB的数组，结果Eden区内存不够，所以就出现了“Allocation Failure”，即对象分配失败。所以此时就要触发一次Young GC。 ​ 那这次GC什么时候发生呢？通过上面的一个数字0.268，这个意思是说你的系统运行以后过了多少秒发生了本次的GC，比如这里就是大概系统运行之后大概200多毫秒，发生了本次GC。 ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs ​ 这个ParNew。我们触发的是年轻代的Young GC，所以用我们指定的ParNew垃圾回收器执行GC的。而4030K -&gt; 512K(4608K)，这个代表的意思是年轻代可用的空间是4608KB，也就是4.5MB。因为上面的例子中，Eden区是4MB，两个Survivor中只有一个是可以放存活对象的，另外一个必须一致保持空闲，所以它考虑年轻代的可用空间，就是Eden + 1个Survivor的大小，也就是4.5MB。 ​ 然后4030K -&gt; 512K。意思是对年轻代执行了一次GC，GC之前都使用了4030KB，但是GC之后只有512KB的对象存活了下来。而0.0015734 secs这个是本次GC耗费的时间。这里大概是1.5ms，仅仅是回收3MB的对象而已。 ​ 4030K-&gt;574K(9728K), 0.0017518 secs，这段话指的是整个Java堆内存的情况。意思是整个Java堆内存是总可用空间9728KB（9.5MB），其实就是4.5MB + 老年代5MB，然后GC前整个Java堆内存里使用了4030KB，GC之后Java堆内存使用了574KB。 [Times: user=0.00 sys=0.00, real=0.00 secs] ​ 这个意思就是本次GC消耗的时间。这里最小单位是小数点之后两位，但是这里全部是0.00 secs，也就是说本次gc就耗费了几毫秒。所以从秒为单位来看，几乎是0。 图解GC执行过程​ 第一个问题，ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs。在GC之前，明明在Eden区域里放了3个1MB的数组，一共是3MB，也就是3072KB的对象，那么GC之前年轻代应该是使用了3072KB的内存，为什么是4030KB的内存？其实要明白两点： 虽然你创建的数组本身是1MB，但是为了存储这个数组，JVM内置还会附带一些其他信息，所以每个数组实际占用的内存是大于1MB的； 除了你自己创建的对象以外，可能还有一些你看不见的对象在Eden区里。 ​ 如图所以，GC之前，三个数组和其他一些未知对象加起来，就是占据了4030KB的内存： ​ 接着你要在Eden分配一个2MB的数组，此时肯定触发了“Allocation Failure”，对象分配失败，就触发了Young GC，然后ParNew执行垃圾回收，回收掉之前我们创建的三个数组，此时因为它们都没人引用了，一定是垃圾对象，如图： ​ 继续看gc日志：ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs。gc回收之后，从4030KB内存使用降低到了512KB的内存使用，也就是说这次gc日志有512KB的对象存活了下来，从Eden区转移到了Survivor1区。或者我们改一下称呼，叫做Survivor From区，另外一个叫做Survivor To区。 ​ 结合GC日志日志就能看出，这就是本次GC的全过程。 GC过后的堆内存使用情况​ 接着我们看下面的GC日志： 123456789101112131415Heappar new generation total 4608K, used 2601K [0x00000000ff600000, 0x00000000ffb00000, 0x00000000ffb00000) eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000)concurrent mark-sweep generation total 5120K, used 62K [0x00000000ffb00000, 0x0000000100000000, 0x0000000100000000)Metaspace used 2782K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K ​ 这段日志是在JVM退出的时候打印出来的当前堆内存的使用情况，其实也很简单。先看这段： 1234567par new generation total 4608K, used 2601K [0x00000000ff600000, 0x00000000ffb00000, 0x00000000ffb00000) eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000) ​ par new generation total 4608K,used 2601K，就是说“ParNew”垃圾回收器复制的年轻代共有4608KB（4.5MB）可用内存，目前是使用了2601KB（2.5MB）。为什么JVM退出之前，年轻代占用了2.5MB的内存？因为在gc之后，我们有通过了代码byte[] array2 = new byte[2 * 1024 * 1024]分配了一个2MB的数组，所以此时Eden区中会有一个2MB的数组，也就是2048KB，然后上次gc之后在From Survivor区中存活了一个512KB的对象。但2048 + 512 = 2560KB，为什么年轻代使用了2601KB？因为之前说过每个数组会额外占据一些内存来存放一些自己这个对象的元数据，所以你可以认为多出来的41KB可以是数组对象额外使用的空间。如图： ​ 继续看日志 12345eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000) ​ 通过GC日志可以验证我们的推测是正确的，这里说的很清楚，Eden区此时4MB的内存被使用了51%，就是因为有一个2MB的数组在里面，然后From Survivor区，512KB是100%的使用率，此时被之前gc后的512KB的未知对象占据了。 ​ 后面的日志 12345concurrent mark-sweep generation total 5120K, used 62K [0x00000000ffb00000, 0x0000000100000000, 0x0000000100000000)Metaspace used 2782K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K ​ concurrent mark-sweep generation total 5120K, used 62K这就是CMS垃圾回收器，管理的老年代内存空间一共是5MB。此时使用了62KB的空间。而下面两段日志也很简单，就是Metaspace元数据空间和Class空间，存放一些类信息、常量池之类的东西，此时他们的总容量和使用内存等等。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾回收器之G1回收器]]></title>
    <url>%2FCKING.github.io%2F2019%2F11%2F05%2FJVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%E4%B9%8BG1%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[ParNew + CMS组合的痛点​ 传统的JVM垃圾回收器ParNew + CMS组合有一个很大的痛点，就是Stop the World。无论是新生代垃圾回收，还是老年代垃圾回收，都会或多或少产生“Stop the World”现象，对系统的运行有一定的影响。所以后面对垃圾回收器的优化，都是朝着减少“Stop the World”的目标去做的。在这个基础上，G1垃圾回收器就应运而生，它提供了比ParNew + CMS组合更好的垃圾回收的性能。 G1垃圾回收器​ G1垃圾回收器是可以同时回收新生代和老年代的对象的，不需要两个垃圾回收器配合起来运作，它一个人就可以搞定所有的垃圾回收。 ​ 它最大的一个特点，就是把Java堆内存拆分为多个大小相等的Region，如图： ​ 然后G1也会有新生代和老年代的概念，但是只不过是逻辑上的概念，即，新生代可能包含了某些Region，老年代也可能包含了某些Region，如图： ​ 而且G1最大的一个特点，就是可以让我们设置一个垃圾回收的预期停顿时间。也就是说比如我们可以指定：希望G1在垃圾回收的时候，可以保证，在一小时内由G1垃圾回收导致的“Stop the World”时间，不能超过一分钟。 ​ 这个就很厉害了，我们之前的一系列JVM优化思路，包括内存合理分配等待，都是为了尽可能减少Minor GC和Full GC带来的系统停顿，避免影响系统处理请求。但是我们现在可以直接给G1指定，在一个时间内，垃圾回收导致的系统停顿时间不能超过多久，G1全权给你负责，保证达到目标，这相当于我们就可以直接控制垃圾回收对系统性能的影响了。 G1对垃圾回收导致的系统停顿可控的原理​ G1要做到这一点，就必须要追踪每个Region里的回收价值。也就是说，它必须搞清楚每个Region里的对象有多少是垃圾，如果对这个Region进行垃圾回收，需要耗费多长时间，可以回收掉多少垃圾。 ​ 如下图，G1通过追踪发现，1个Region的垃圾对象有10MB，回收它们需要耗费1秒钟，另外一个Region中对垃圾对象有20MB，回收它们需要耗费200毫秒。 ​ 然后在垃圾回收的时候，G1会发现在最近一个时间段内，比如一小时内，垃圾回收已经导致了几百毫秒的停顿了，现在又要执行一次垃圾回收，那么必须是回收上图中那个只需要200ms就能回收掉20MB垃圾的Region，于是G1触发一次垃圾回收，虽然导致了系统停顿了200ms，但是一下子回收了更多的垃圾。 ​ 所以简单来说，G1可以做到让你来设定垃圾回收对系统的影响，它自己通过把内存拆分为大量小Region，以及追踪每个Region中可回收对象大小和预估时间，最后在垃圾回收的时候，尽量把垃圾回收对系统造成的影响控制在你指定的时间范围内，同时在有限的时间内尽量回收尽可能多的垃圾对象。这就是G1的核心设计思路。 Region可能属于新生代也可能是老年代​ 在G1中，每一个Region可能属于新生代，也可能属于老年代。刚开始Region可能谁都不属于，然后接着就分配给了新生代，放了很多属于新生代的对象，接着就触发了垃圾回收这个Region。然后下一次同一个Region可能又分配了老年代，用来存放老年代的长生存周期的对象。 ​ 所以其实在G1对应的内存模型中，Region随时会属于新生代也会属于老年代，所以没有所谓新生代给多少内存，老年代给多少内存这一说了，实际上新生代和老年代各自的内存区域是不停变动的，由G1自动控制。 设定G1对应的内存大小​ 上面说到G1对应的是一大堆的Region内存区域，每个Region的大小是一致的。那到底有多少个Region呢？每个Region的大小是多大呢？其实这个默认情况下是自动计算和设置的，我们可以给整个堆内存设置一个大小，比如用-Xms和-Xmx来设置堆内存的大小，然后JVM启动的时候发现你使用的是G1垃圾回收器，可以使用-XX:+UseG1GC来指定使用G1垃圾回收器，此时会自动用堆大小除以2048，因为JVM最多可以有2048个Region，然后Region的大小必须是2的倍数，比如说1MB、2MB和4MB之类的。 ​ 比如说堆大小是4G，就是4096MB，此时除以2048个Region，每个Region的大小就是2MB，大概就是这个样子来决定Region的数量和大小的，一般保持默认的计算方式就可以。如果通过手动的方式来指定，则可以使用-XX:G1HeapRegionSize。 ​ 刚开始的时候，默认新生代对堆内存的占比是5%，也就是占据200MB左右，对应大概是100个Region。这个可以通过-XX:G1NewSizePercent来设置新生代初始占比，其实维持这个默认值即可，因为在系统运行中，JVM会不停地给新生代增加更多的Region，但是最多新生代的占比不会超过60%，可以通过-XX:G1MaxNewSizePercent来设置。而且一旦Region进行了垃圾回收，此时新生代的Region数量还会减少，这些其实都是动态的。 新生代还有Eden和Survivor的概念​ 虽然G1把内存划分了很多的Region，但是其实还是有新生代和老年代的区分，而且新生代里还是有Eden和Survivor的划分的。之前说过的一个新生代的参数：-XX:SurvivorRatio=8，比如说新生代刚开始的时候，有100个Region，那么可能80个Region就是Eden，两个Survivor各自占10个Region。所以大家要明白这里其实还是有Eden和Survivor的概念的，它们会各自占据不同的Region，只不过随着对象不停地在新生代里分配，属于新生代的Region会不断增加，Eden和Survivor对应的Region也会不断增加。 G1的新生代垃圾回收​ 既然G1的新生代也有Eden和Survivor的区分，那么触发垃圾回收的机制都是类似的。 ​ 随着不停地在新生代的Eden对应的Region中放对象，JVM会不停地给新生代加入更多的Region，直到新生代占据堆大小的最大比例60%。一旦新生代达到了设定的占据堆内存的最大大小60%，比如都有1200个Region了，里面的Eden可能占据了1000个Region，每个Survivor是100个Region，而且Eden区还占满了对象，如图： ​ 这个时候还是会触发新生代的GC，G1就会用之前说过的复制算法来进行垃圾回收，进入了一个“Stop the World”状态，然后把Eden对应的Region中的存活对象放入到S1对应的Region中，接着回收掉Eden对应的Region中的垃圾对象。 ​ 但是这个过程还有跟之前有区别的，因为G1是可以设定目标GC停顿时间的，也就是G1执行GC的时候最多可以让系统停顿多长时间，可以通过-XX:MaxGCPauseMills参数来设定，默认值是200ms。那么G1就会通过之前说的，对每个Region追踪回收它需要多少时间，可以回收多少对象来选择回收一部分的Region，保证GC停顿时间控制在指定范围内，尽可能多地回收掉一些对象。 对象什么时候进入老年代​ 在G1的内存模型下，新生代和老年代各自都会占据一定的Region，老年代也会有自己的Region，按照默认，新生代最多只能占据堆内存60%的Region来推算，老年代最多可以占据40%的Region。那么对象什么时候可以从新生代进入老年代呢？ 对象在新生代躲过了很多次的垃圾回收，达到了一定的年龄了，-XX:MaxTenuringThreshold参数可以设置这个年龄，他就会进入老年代。 动态年龄判定规则，如果一旦发现某次新生代GC过后，存活对象超过了Survivor的50%。此时就会判断一下，比如年龄为1岁、2岁、3对和4岁的对象的大小综合超过了Survivor的50%，此时4岁以上的对象全部会进入老年代。这就是动态年龄判定规则。 ​ 经过一段时间的新生代使用和垃圾回收之后，总有一些对象会进入老年代中。 大对象Region​ 在以前，大对象是可以直接进入老年代的，那G1这套内存模型下呢？实际上这里会有所不同，G1提供了专门的Region来存放大对象，而不是让大对象进入老年代的Region中。 ​ 在G1中，大对象的判定规则就是一个大对象超过了一个Region大小的50%，例如按照上面的算的，每个Region是2MB，只要一个对象超过了1MB，就被被放入专门的Region中。而且一个大对象如果太大，可能会横跨多个Region来存放。如图： ​ 那堆内存哪些Region用来存放大对象呢？之前不是说60%给新生代，40%给老年代吗，那还有哪些Region给大对象？很简单，之前说过了，在G1里，新生代和老年代的Region是不停变化的。比如新生代占据了1200个Region，但是一次垃圾回收之后，就让里面1000个Region都空了，此时那1000个Region就可以不属于新生代了，里面很多Region可以用来存放大对象。 ​ 在垃圾回收方面，新生代、老年代在回收的时候，会顺带着对大对象Region一起回收，所以这就是G1内存模型下对大对象的分配和回收的策略。 新生代 + 老年代的混合垃圾回收​ G1有一个参数，是-XX:InitiatingHeapOccupancyPercent，它的默认值是45%。意思是说，如果老年代占据了堆内存的45%的Region的时候，此时就会尝试触发一个新生代 + 老年代一起回收的混合回收阶段。 G1垃圾回收的过程​ 首先会触发一个“初始标记”的操作，这个过程需要进入“Stop the World”，但仅仅只是标记一下GC Roots直接能引用的对象，这个过程是很快的。它会先停止系统的运行，然后对各个线程栈内存中的局部变量代表的GC Roots、以及方法区中的静态变量代表的GC Roots，进行扫描，标记出它们直接引用的那些对象。 ​ 接着会进入“并发标记”的阶段，这个阶段允许系统程序的运行，同时进行GC Roots，从GC Roots开始追踪所有的存活对象。 ​ 这里对GC Roots追踪做更加详细的说明，比如下面的代码 12345678public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125;public class ReplicaManager &#123; public ReplicaFetcher replicaFetcher = new ReplicaFetcher();&#125; ​ 上面代码中，Kafka类有一个静态变量是“replicaManager”，它就是一个GC Roots对象，初始标记阶段，仅仅就是标记这个“replicaManager”作为GC Roots直接关联的对象，就是“ReplicaManager”对象，它肯定是要存活的。 ​ 然后在并发标记阶段，就会进行GC Roots追踪，会从“replicaManager”这个GC Roots对象直接关联的“ReplicaManager”对象开始往下追踪，可以看到“ReplicaManager”对象里有一个实例变量“replicaFetcher”，此时追踪这个“replicaFetcher”变量可以看到它引用了“ReplicaFetcher”对象，那么此时这个“ReplicaFetcher”对象也要被标记为存活对象。 ​ 这个并发标记阶段还是很耗时的，因为要追踪全部的存活对象，但是这个阶段可以跟系统程序并发运行，所以对系统程序的影响不太大，而且JVM会对并发标记阶段对对象做出的一些修改记录起来，比如说哪个对象被新建了，哪个对象失去了引用。 ​ 接着下一个阶段，最终标记阶段，这个阶段会进入“Stop the World”，系统程序是禁止运行的，但是会根据并发标记阶段记录的那些对象修改，最终标记有哪些存活对象，有哪些是垃圾对象。 ​ 最后一个极端就是“混合回收”阶段。这个阶段会计算老年代中每个Region中的存活对象数量，存活对象的占比，还有执行垃圾回收的预期性和效率。接着系统会停止系统程序，然后全力以赴尽快进行垃圾回收，此时会选择部分Region进行回收，因为必须让垃圾回收的停顿时间控制在我们指定的范围内。 ​ 这里需要注意的是，老年代对堆内存占比达到45%的时候，触发的是混合回收。即，此时垃圾回收不仅仅是回收老年代，还会回收新生代和大对象。那到底是回收这些区域的哪些Region呢？这个就要看情况了，因为我们设定了对GC停顿时间的目标，所以它会从新生代、老年代和大对象各自挑选一些Region，保证用指定的时间回收尽可能多的垃圾，这就是所谓的混合回收。 G1垃圾回收器的一些参数​ 上面说过老年代的Region占据了堆内存的Region的45%之后，会触发一个混合回收的过程，并且分了四个阶段。在最后一个阶段，就是执行混合回收，从新生代和老年代都回收一些Region。但是最后一个阶段混合回收的时候，其实会停止所有程序运行，所以说G1是允许执行多次混合回收的。 ​ 例如先停止工作，执行一次混合回收回收掉一些Region，接着恢复系统运行，然后再次停止系统运行，再执行一次混合回收回收掉一些Region。 ​ 有一些参数可以控制这个，比如-XX:G1MixedGCCountTarget参数，就是在一次混合回收的过程中，最后一个阶段执行几次混合回收，默认是8次。意味着最后一个阶段，先停止系统运行，混合回收一些Region，再恢复系统运行，接着再次禁止系统运行，混合回收一些Region，反复8次。 ​ 例如一次混合回收预期要回收一共有160个Region，那么此时第一次混合回收，会回收掉一些Region，比如就是20个Region，接着恢复系统一会儿，然后再执行一次“混合回收”，再次回收掉20个Region。如此反复执行8次回收阶段之后，就可以把预期的160个Region都回收掉了，而且还把系统停顿时间控制在指定范围内。 ​ 为什么要反复回收多次？因为你停止系统一会儿，回收掉一些Region，再让系统运行一会儿，然后再次停止系统一会儿，再次回收掉一些Region，这样可以尽可能让系统不要停顿时间过长，可以在多次回收的间隙，也运行一下。 ​ 还有一个参数：-XX:G1HeapWasterPercent，默认值是5%。它的意思是说，在混合回收的时候，对Region回收都是基于复制算法进行的，都是把要回收的Region里的存活对象放入其他Region，然后这个Region中的垃圾对象全部清理掉。 ​ 这样的话回收过程就会不断空出来新的Region，一旦空闲出来的Region数量达到了堆内存的5%，此时就会立即停止混合回收，意味着本次混合回收就结束了。而且G1整体是基于复制算法对Region进行垃圾回收的，不会出现内存碎片的问题，不需要像CMS那样标记-清理之后，再进行内存碎片的整理。 ​ 还有一个参数：-XX:G1MixedGCLiveThresholdPercent，它的默认值是85%，意思就是确定要回收的Region的时候，必须是存活对象低于85%的Region才可以进行回收。 回收失败的Full GC​ 如果在进行Mixed回收的时候，无论是年轻代还是老年代都基于复制算法进行回收的，都要把各个Region的存活对象拷贝到别的Region里去，此时万一出现拷贝的过程中发现没有空闲的Region可以承载自己的存活对象那，就会处罚一次失败。 ​ 一旦失败，立马就会切换为停止系统程序，然后采用单线程进行标记、清理和压缩整理，空闲出来一批Region，这个过程是极慢极慢的。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Stream入门]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F29%2FSpring-Cloud-Stream%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Spring Cloud Stream​ 官方定义Spring Cloud Stream是一个构建消息驱动微服务的框架。应用程序通过inputs或者outputs来与Spring Cloud Stream中binder交互，通过我们来配置binding，而Spring Cloud Stream的binder负责与消息中间件交互。所以，我们只需要搞清楚如何与Spring Cloud Stream交互就可以方便使用消息驱动的方式。它通过使用Spring Integration来连接消息中间件以实现消息事件驱动。Spring Cloud Stream为一些供应商的消息中间件产品提供了个性化的自动化配置实现，引用了发布-订阅、消费组、分区的三个概念。目前支持市场上主流的多个消息中间件。 发布/订阅​ 简单的讲就是一种生产者、消费者模式。发布者是生产，将输出发布到数据中心，订阅者是消费者，订阅自己感兴趣的数据。当有数据到达数据中心，就把数据发送给对应的订阅者。 消费组​ 直观的理解就是一群消费者一起处理消息。需要注意的是：每个发动到消费组的数据，仅有消费组中的一个消费者处理。 分区​ 类比于消费组，分区是将数据分区。例如，某个应用有多个实例，都绑定到同一个数据中心，也就是不同实例都将数据发布到同一个数据中心。分区就是将数据中心的数据再细分成不同的区。为什么需要分区？因为即使是同一个应用，不同实例发布的数据类型可能不同，也希望这些数据由不同的消费者处理。这就需要，消费者可以仅订阅一个数据中心的部分数据，这就需要分区这个东西了。 Stream解决了什么问题​ Stream解决了开发人员无感知地使用消息中间件的问题，因为Stream对消息中间件的进一步封装，可以做到代码层面对中间件的无感知，甚至于动态的切换中间件（rabbitMQ切换为Kafka），使得微服务开发的高度解耦，服务可以关注更多自己的业务流程。结构图如下： 组成 说明 Middleware 中间件，支持市场上多种主流的MQ中间件 Binder Binder是应用与消息中间件之间的封装。通过Binder可以很方便地连接中间件，可以动态地改变消息类型（对应于Kafka的topic，RabbitMQ的exchange），这些都可以通过配置文件来实现 @Input 注解标识输入通道，通过该输入通道接收到的信息进入应用程序 @Output 注解标识输出通道，发布的消息将通过该通道离开应用程序 @StreamListener 监听队列，用于消费者队列的消息接收 @EnableBinding 指信道channel和exchange绑定在一起 消息驱动入门案例​ 现在通过一个入门案例来演示通过stream整合RabbitMQ来实现消息的异步通信的效果。首先是先安装部署RabbitMQ，具体方法自行百度。我这边是用docker安装的RabbitMQ，参考的是这篇文章：Docker 安装部署RabbitMQ。 ​ RabbitMQ安装好之后，就开始我们的代码了。首先先创建SpringCloud的一个父工程，然后在父工程下面新建两个服务： cloud-stream-producer-rabbitmq：作为一个发布者，将消息推动到RabbitMQ cloud-stream-consumer-rabbitmq：消费者消费信息 ​ 首先是添加依赖，其中最主要的是spring cloud stream的RabbitMQ依赖，还有就是为了使用spring cloud stream，我们还要引入spring cloud依赖，整个pom文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;cloud-stream-producer-rabbitmq&lt;/module&gt; &lt;module&gt;cloud-stream-consumer-rabbitmq&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.springcloudstream&lt;/groupId&gt; &lt;artifactId&gt;rabbitmqdemo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmqdemo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-test-support&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 创建生产者​ 如前所述，将消息从发布者传递到队列的整个过程是通过通道Channel完成的，因此，我们创建一个HelloBinding接口，其中包含我们自定义的消息信道greetingChannel。 12345public interface HelloBinding &#123; @Output("greetingChannel") MessageChannel greeting();&#125; ​ 因为这个是要发布消息的，所以我们使用@Output注解，方法名可以是我们想要的任何名称，当然，我们可以在一个接口中有多个Channel（通道）。 ​ 现在，我们创建一个Controller，它将消息推动到这个Channel（通道） 12345678910111213141516@RestControllerpublic class ProducerController &#123; private MessageChannel greet; public ProducerController(HelloBinding binding) &#123; greet = binding.greeting(); &#125; @GetMapping("/greet/&#123;name&#125;") public void publish(@PathVariable String name) &#123; String greeting = "hello " + name + "!"; Message&lt;String&gt; msg = MessageBuilder.withPayload(greeting).build(); this.greet.send(msg); &#125;&#125; ​ 上面我们创建了一个ProducerController类，它有一个MessageChannel类型的属性，这是我们通过我们前面声明的方法在构造函数中初始化的。然后，我们有一个简单的Restful接口， 它接收PathVariable的name，并使用MessageBuilder创建一个String类型的消息。最后，我们使用MessageChannel上的.send()方法来发布消息。 ​ 现在,我们将在的主类中添加@EnableBinding注解，传入HelloBinding告诉Spring加载。 12345678@EnableBinding(HelloBinding.class)@SpringBootApplicationpublic class ProducerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProducerApplication.class, args); &#125;&#125; ​ 最后，我们必须告诉Spring如何连接到RabbitMQ，并将greetingChannel连接到一可用的消费这。而这些都是在application.properties配置文件中定义的。 123456789spring.rabbitmq.addresses=47.105.176.129spring.rabbitmq.username=rootspring.rabbitmq.password=xxxspring.rabbitmq.port=5672spring.rabbitmq.virtual-host=my_vhostspring.rabbitmq.publisher-confirms=truespring.cloud.stream.bindings.greetingChannel.destination=greetingsserver.port=8080 ​ 其中，spring.cloud.stream.bindings.greetingChannel.destination的意思是greetingChannel这个通道的目的地，类似于Kafka的Topic和RabbitMQ的队列的概念 。后面的消费者也是通过这个去配置消费者去相同的Channel中取数据。另外一个配置spring.rabbitmq.virtual-host，是配置当前用户的权限，这个我们可以通过RabbitMQ的管理界面去确定这个配置的内容： 创建消费者​ 现在，我们需要监听之前创建的通道greetingChannel。让我们创建一个绑定，为了区分，消费者的Channel我们命名为helloChannel。 1234567public interface HelloBinding &#123; String GERRTING = "helloChannel"; @Input(GERRTING) SubscribableChannel greeting();&#125; ​ 与生产者绑定的两个非常明显的区别。因为我们是要消费信息，所以我们使用SubscribableChannel和@Input标识它为消费者。消息推送将被推送到这里。 ​ 现在，我们创建处理数据的方法： 12345678@EnableBinding(HelloBinding.class)public class HelloListener &#123; @StreamListener(target = HelloBinding.GERRTING) public void processHelloChannelGreeting(String msg) &#123; System.out.println(msg); &#125;&#125; ​ 在这里，我们创建一个HelloListener类，在processHelloChannelGreeting方法上添加@StreamListener注解，这个方法需要一个字符串作为参数。我们还在类添加@EnableBinding启用了HelloBinding。 ​ 注意，我们在这里使用@EnableBinding，而不是主类，我们的主类，其实是没有任何修改的： 123456@SpringBootApplicationpublic class ConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class, args); &#125;&#125; ​ 最后，我们修改消费者的配置文件： 123456789spring.rabbitmq.addresses=47.105.176.129spring.rabbitmq.username=rootspring.rabbitmq.password=xxxspring.rabbitmq.port=5672spring.rabbitmq.virtual-host=my_vhostspring.rabbitmq.publisher-confirms=truespring.cloud.stream.bindings.helloChannel.destination=greetingsserver.port=9090 ​ 其中，spring.cloud.stream.bindings.helloChannel.destination的意思是helloChannel这个通道的目的地是greetings，这个跟生产者是一样的，从而让消费者指向了跟生产者一样的目的地。 测试​ 我们同时启动生产者和消费者，通过浏览器或postman访问http://localhost:8080/greet/ckin来生产消息，可以在打印台中看到看到消息内容： ​ 现在我们启动另一个消费者服务。端口号为9091，当我们点击生产者的REST端点生产消息时，我们看到两个消费者都收到了消息： ​ 如果我们只想让一个消费者消费一条消息的话，我们可以在application.properties中创建一个消费者组。消费者的文件如下： 1spring.cloud.stream.bindings.greetingChannel.group = greetings-group ​ 相关代码已上传到github，需要的可以去下载。 参考资料Spring Cloud Stream入门介绍 消息驱动式微服务：Spring Cloud Stream &amp; RabbitMQ]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之垃圾回收器]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F23%2FJVM%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[​ 在新生代和老年代进行垃圾回收的时候，都是要用垃圾回收器进行回收的，不同的区域用不同的垃圾回收器。常用的垃圾回收机有一下几种： Serial和Serial Old垃圾回收器：分别用来回收新生代和老年代的垃圾对象。工作原理就是单线程运行，垃圾回收的时候会停止我们自己写的系统的其他工作线程，让我们系统直接卡死不动，然后让他们垃圾回收，这个现在一般写后台Java系统几乎不用。 ParNew和CMS垃圾回收器：ParNew现在一般都是用在新生代的垃圾回收器，CMS是用在老年代的垃圾回收器，他们都是多线程并发的机制，性能更好，现在一般是线上生产系统的标配组合。 G1垃圾回收器：统一收集新生代和老年代，采用了更加优秀的算法和设计机制。下面会详细介绍这个G1垃圾回收器。 GC的大概流程​ 看下图，新生代的内存一般都是分为一个Eden和两个Survivor ​ 此时系统不停的运行，然后把Eden给塞满了，此时就会触发Minor GC。进行垃圾回收时有专门的垃圾回收线程的，而且对不同的内存区域会有不同的垃圾回收器。相当于垃圾回收线程和垃圾回收器配合起来，使用自己的垃圾回收算法，对指定的内存区域进行垃圾回收。 ​ 由上图可知，垃圾回收会通过一个后台运行的垃圾回收线程来执行它具体的一个逻辑。比如针对新声代我们会用ParNew垃圾回收器进行回收，然后ParNew垃圾回收器针对新生代采用的就是复制算法来垃圾回收。 GC的时候还能继续创建新的对象吗​ 我们写好的Java系统在运行期间能不能继续在新生代里创建新的对象？假设一个场景，如下图： ​ 如果所示，如果一边垃圾回收器在想办法把Eden和Survivor2里的存活对象标记出来转移到Survivor2去，然后还在想办法把Eden和Survivor2的垃圾对象清理掉，结果这个时候系统程序还在不停的在Eden里创建新的对象。而这些新的对象很快就成了垃圾对象，有的还有人引用是存活对象。这样子就会全部乱套了，对于程序新创建的这些对象，你怎么让垃圾回收器去持续追踪这些新对象的新状态？所以，在垃圾回收过程中，同时还允许我们写的Java系统不停的运行在Eden里持续创建新的对象，目前来看是不合适的。 Stop the World​ 由上述可知，平时使用的JVM最大的痛点，就是在垃圾回收的这个过程。因为在垃圾回收的时候，尽可能让垃圾回收器专心致志的干活，不能随便让我们写的Java系统继续创建对象了，所以此时JVM会在后台直接进入“stop the World”状态。即，它会直接停止我们写的Java系统的所有工作线程，让我们写的代码不再运行，然后让垃圾回收线程可以专心致志地进行垃圾回收的工作。 ![stop the world](JVM之垃圾回收器/stop the world.png) ​ 这样的话，就可以让我们的系统暂停运行，然后不再创建新的对象，同时让垃圾回收线程尽快完成垃圾回收的工作，就是标记和转移Eden和Survivor2的存活对象到Survivor1中去，然后尽快一次性地回收掉Eden和Survivor2中的垃圾对象。一旦垃圾回收完毕，既可以继续恢复我们写的Java系统的工作线程了，然后我们的那些代码就可以继续运行，继续在Eden中创建新的对象。 Stop the World造成的系统停顿​ 现在大家清楚了“Stop the World”对系统造成的影响了，假设我们的Minor GC要运行100ms，那么可能会导致我们系统直接停顿100ms不能处理任何请求。如果因为内存分配不合理，导致对象频繁进入老年代，平均七八分钟一次Full GC，而Full GC是最慢的，有的时候弄不好一次回收要运行几秒钟，甚至是几分钟都是有可能的。 ​ 因此，无论是新生代GC还是老年代GC，都尽量不要让频率过高，也避免持续时间过长，避免影响系统正常运行，这也是使用JVM过程中一个最需要优化的地方，也是最大的一个痛点。 新生代垃圾回收器：ParNew​ 一般来说，假设没有最新的G1垃圾回收器的话，大家线上系统都是ParNew垃圾回收器作为新生代的垃圾回收器。 ​ 新生代的ParNew垃圾回收器主打的是多线程垃圾回收机制。另外一种Serial垃圾回收器主打的是单线程垃圾回收，他们两都是回收新生代的，唯一的区别就是单线程和多线程的区别，但是垃圾回收算法都是一致的。 ​ 如下图，ParNew垃圾回收器如果一旦在合适的时期执行Minor GC的时候，就会把系统程序的工作线程全部停掉，禁止程序继续运行创建新的对象，然后自己就用多个垃圾回收线程去进行垃圾回收，回收的机制和算法跟之前是一样的。 为线上系统指定使用ParNew垃圾回收器​ 线上系统，如果部署到Tomcat时可以在Tomcat的catalina.sh中设置Tomcat的JVM参数，使用Spring Boot也可以在启动时指定JVM参数。 ​ 在启动系统的时候，使用-XX:+UseParNewGC选项，就可以对系统指定使用ParNew垃圾回收器。那么Minor GC的时机，检查机制，包括垃圾回收的具体过程，以及对象升入老年代的机制，都是我们之前说的那套原理了，只不过，ParNew会使用多个线程来进行垃圾回收。 ParNew垃圾回收器默认情况下的线程数量​ 因为现在一般我们不熟系统的服务器都是多核CPU，所以为了在垃圾回收的时候充分利用多核CPU的资源，一旦我们指定了使用ParNew垃圾回收器之后，他默认给自己设置的垃圾回收线程的数量就是跟CPU的核数是一样的。 ​ 比如我们线上机器假设用的是4核CPU或者8核CPU，那么此时ParNew的垃圾回收线程数就会分别是4个线程、8个线程。 ​ 这个东西一般不用我们手动去调节，因为跟CPU核数一致的线程数量，是可以充分进行并行处理的。如果要调节ParNew的垃圾回收线程数量，可以使用-XX:ParallelGCThreads参数即可。但是一般不建议随意动这个参数。 老年代垃圾回收器：CMS​ 一般老年代我们选择的垃圾回收器是CMS，他采用的是标记整理算法，其实非常简单，就是先用之前讲过的标记方法区标记出哪些对象是垃圾对象，然后把这些垃圾对象清理掉。 先Stop the World，再垃圾回收？​ 如果先Stop the World，然后再采用“标记-整理”算法去回收垃圾。会造成系统卡死时间过长，很多相应无法处理。所以CMS垃圾回收器采取的是垃圾回收线程和系统工作线程尽量同时执行的模式来处理的。 CMS的垃圾回收过程​ CMS在执行一次垃圾回收的过程一共分为4个阶段： 初始标记 并发标记 重新标记 并发清理 初始标记​ 首先，CMS要进行垃圾回收，会先执行初始标记阶段，这个阶段会让系统的工作线程全部停止，进入“Stop the World”状态。而所谓的“初始标记”，就是标记出来所有GC Roots直接引用的对象。例如下面的代码： 12345678public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125;public class ReplicaManager &#123; private ReplicaFetcher replicaFetcher = new ReplicaFetcher();&#125; ​ 在初始标记阶段，仅仅过通过“replicaManager”这个类的静态变量代表的GC Roots，去标记出他直接引用的ReplicaManager对象，这就是初始标记的过程。它不会去管ReplicaFetcher这种对象，因为ReplicaFetcher对象是被ReplicaManager类的“replicaFetcher”实例变量引用的。之前说过，方法的局部变量和类的静态变量是GC Roots。但类的实例变量不是GC Roots。 ​ 所以第一个阶段，初始标记，虽然要造成“Stop the World”暂停一切工作线程，但是其实影响并不大，因为他的速度很快，仅仅标记GC Roots直接引用的那些对象而已。 并发标记​ 第二个阶段是并发标记，这个阶段会让系统线程可以随意创建各种对象，继续运行。在运行期间可能会创建新的存活对象，有可能让部分存活对象失去引用，变成垃圾对象。在这个过程中，会尽可能地对已有的对象进行GC Roots追踪。 ​ 所谓进行GC Roots追踪，意思就是对类似“ReplicaFetcher”之类的全部老年代里的对象，看它被谁引用了。比如这里是被“ReplicaManager”对象的实例变量引用了，接着会看，“ReplicaManager”对象被谁引用了，会发现被“Kafka”类的静态变量引用了。那么此时可以认定“ReplicaFetcher”对象是被GC Roots间接引用的，因此此时就不需要回收它。但是在这个过程，在进行并发标记的时候，系统程序会不停的工作，它可能会创建出新的对象，部分对象可能变成为垃圾，如下图： ​ 第二个阶段，就是标记出 GC roots 关联到的对象的引用对象有哪些。比如说 A -&gt; B (A 引用 B，假设 A 是 GC Roots 关联到的对象)，那么这个阶段就是标记出 B 对象， A 对象会在初始标记中标记出来。 这个阶段其实是最耗时的，但是这个最耗时的阶段，是跟系统并发运行的，所以这个阶段不会对系统运行造成影响。 重新标记​ 在第二阶段并发标记中，因为一边标记存活对象和垃圾对象，一边系统不停运行创建对象，让老对象变成垃圾。所以第二阶段结束之后，会有很多存活对象和垃圾对象，是之前第二阶段没标记出来的。所以此时进入第三阶段，要继续让系统程序停下来，再次进入“Stop the World”状态。然后重新标记下在第二阶段里创建的一些对象，还有一些已有对象可能失去引用变成垃圾的情况。 ​ 重新标记的阶段，速度是很快的。因为它其实就是对在第二阶段中被系统程序运行变动过的少数对象进行标记，所以运行速度很快。 并发清理​ 这个阶段就是让系统程序随意运行，然后它来清理之前标记为垃圾的对象即可。这个阶段其实也很耗时，因为需要进行对象的清理，但是它也是跟随系统程序并发运行的，所以也不影响系统的执行。 CMS的垃圾回收机制性能分析​ 从上述我们知道CMS的垃圾回收机制已经尽可能地进行了性能优化。其中最耗时的，就是对老年代全部对相关进行GC Roots追踪，标记出来哪些可以回收，然后就是对各种垃圾对象从内存里清理掉。 ​ 但是他的第二和第四阶段，即并发标记和并发清理，都是和系统程序并发执行的，所以基本对性能影响不大。只有第一和第三阶段是需要“Stop the World”的，但是这两个阶段都是简单的标记而已，速度非常快，所以基本上对系统运行影响也不大。 CMS的一些细节并发回收垃圾导致CPU资源紧张​ CMS垃圾回收器有一个问题，虽然能在垃圾回收的同事让系统同事工作，但在并发标记和并发清理两个最耗时的阶段，垃圾回收线程和系统工作线程同时工作，会导致有限的CPU资源被垃圾回收线程占用了一部分。CMS默认启动的垃圾会回收线程的数量是（CPU核数 + 3）/ 4。假设是2核CPU，那么CMS会有（2 + 3）/ 4 = 1个垃圾回收线程，去占用一个CPU。所以CMS这个并发垃圾回收机制，第一个问题就是会消耗CPU资源。 Concurrent Mode Failure问题​ 在并发清理阶段，CMS只不过是回收之前标记好的垃圾对象。但是这个阶段系统一直在运行，可能会随着系统运行让一些对象进入老年代，同时还变成垃圾对象，这种垃圾对象被称为为“浮动垃圾”。 ​ 虽然它成为了垃圾，但是CMS只能回收之前标记出来的垃圾对象，不会回收它们，需要等待到下一次GC的时候才会回收它们。所以为了保证CMS垃圾回收期间，还有一定的内存空间让一些对象可以进入老年代，一般会预留一些空间。CMS垃圾回收的触发时机，其中有一个就是当老年代内存占用达到一定比例了，就会自动执行GC。 ​ -XX:CMSInitiatingOccupancyFaction参数可以用来设置老年代占用多少比例的时候触发CMS垃圾回收，JDK1.6默认的值是92%。即老年代占用了92%的空间了，就自动进行CMS垃圾回收，预留8%的空间给并发回收期间，系统程序把一些新对象放入老年代中。 ​ 如果CMS垃圾回收期间，系统程序要放入老年代的对象大于可用内存空间，这个时候，会发生Concurrent Mode Failure，就是说并发垃圾回收失败了，我一边回收，你一边把对象放入老年代，内存都不够了。 ​ 此时就会自动用“Serial Old”垃圾回收器替代CMS，就是直接把系统程序“Stop the World”，重新进行长时间的GC Roots追踪，标记出全部垃圾对象，不允许新的对象产生，然后一次性把垃圾对象都回收掉，完事了再恢复系统线程。 ​ 所以在生产实践中，这个自动触发CMS垃圾回收的比例需要合理优化一下，避免“Concurrent Mode Failure”问题。 内存碎片问题​ 老年代的CMS采用“标记-清理”算法，每次都是标记出来垃圾对象，然后一次性回收掉。这样会导致大量的内存碎片产生。如果内存碎片太多，会导致后续对象进入老年代找不到可用的连续内存空间，然后就触发Full GC。所以CMS不是完全仅仅用“标记-清理”算法的，因为太多的内存碎片实际上会导致更加频繁的Full GC。 ​ CMS有一个参数是-XX:+UseCMSCompactAtFullCollection，默认是打开的，意思是在Full GC之后要再次进入“Stop the World”，停止工作线程，然后进行碎片整理，就是把存活对象挪到一起，空出来大片连续内存空间，避免内存碎片。还有一个参数时-XX:CMSFullGCsBeforeCompaction,这个意思是执行多少次Full GC之后再执行一次内存碎片整理的工作，默认是0，意思是每次Full GC之后都会进行一次内存整理。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之垃圾回收]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F18%2FJVM%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 在Java中，平时我们系统运行创建的对象都是优先分配在新生代里的。如果新生代里的对象越来越多，都快满了，此时就会触发垃圾回收，把新生代没有引用的对象给回收掉，从而释放内存空间。现在我们来看看，JVM是按照什么规则来回收垃圾对象的。 哪些引用对象不能被回收​ JVM中使用了可达性分析算法来判定哪些对象是可以被回收的。这个算法的意思是，对每个对象，都分析一下有谁在引用他，然后一层一层往上去判断，看是否有一个GC Roots。其中方法的局部变量、类的静态变量都可以看做是一种GC Roots。 案例​ 如下一段代码，就是在一个方法中创建了一个对象，然后有一个局部变量引用了这个对象。 12345678910public class Kafka &#123; public static void main(String[] args) &#123; loadReplicaFromDisk(); &#125; public static void loadReplicaFromDisk() &#123; ReplicaManager replicaManager = new ReplicaManager(); &#125;&#125; ​ 分析代码可知，“main()”方法的桢栈入栈，然后调用“loadReplicaFromDisk()”方法，桢栈入栈，接着让局部变量“replicaManager”引用堆内存里的“ReplicaManager”实例对象，如下图： ​ 现在上图中“ReplicaManager”对象被局部变量给引用了，此时一旦新生代满了，发生垃圾回收，就会分析这个“ReplicaManager”对象的可达性。此时会发现它是不能被回收的，因为它被人引用了，而且是局部变量“replicaManager”引用的。 ​ 只要一个对象被局部变量引用了，那么说明它有一个GC Roots，此时就不能被回收了。 ​ 另外一种情况，如下面代码： 1234public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125; ​ 跟上面的那个一样，一分析，发现“ReplicaManager”对象被Kafka类的一个静态变量”replicaManager”给引用了，此时就不会去回收它。 ​ 总结：只要你的对象被方法的局部变量、类的静态变量给引用了，就不会回收它们。 Java中对象不同的引用类型​ 关于引用和垃圾回收的关系，我们要有一个概念，就是Java里有不同的引用类型。分别是强引用、软引用、弱引用和虚引用。 强引用​ 强引用，就是类似下面的代码： 1234public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125; ​ 这个就是最普通的代码，一个变量引用一个对象。只要是强引用的类型，那么垃圾回收的时候就绝对不会去回收这个对象的。 软引用​ 软引用，类似下面的代码： 12345public class Kafka &#123; public static SoftReference&lt;ReplicaManager&gt; replicaManager = new SoftReference&lt;ReplicaManager&gt;(new ReplicaManager());&#125; ​ 就是把“ReplicaManager”实例对象用一个“SoftReference”软引用类型的对象给包裹起来，此时这个“replicaManager”变量对“ReplicaManager”对象的引用就是软引用了。 ​ 正常情况下垃圾回收时不会回收软引用对象的，但是如果进行垃圾回收之后，发现内存空间还不不够存放新的对象，此时就会把这些软引用对象给回收了。即便它被变量引用了，但是因为它是软引用，所以还是可以回收的。 弱引用​ 弱引用，类似下面代码： 12345public class Kafka &#123; public static WeakReference&lt;ReplicaManager&gt; replicaManager = new WeakReference&lt;ReplicaManager&gt;(new ReplicaManager());&#125; ​ 弱引用就跟没有引用是类似的，如果发生垃圾回收，就会把这个对象回收掉。 虚引用​ 虚引用，正如其名，对一个对象而言，这个引用形同虚设，有和没有一样。此外，虚引用必须和引用队列一起使用。 finalize()方法的作用​ 从上面可知，有GC Roots引用的对象不能回收，没有GC Roots引用的对象可以别回收。如果有GC Roots引用，但是引用时软引用或者弱引用，也有可能被回收。 ​ 但是没有GC Roots引用的对象，一定会被立马回收吗？其实并不是，这里有一个finalize()方法可以抢救一下。如下代码： 123456789public class ReplicaManager &#123; public static ReplicaManager instance; @Override protected void finalize() throws Throwable &#123; ReplicaManager.instance = this; &#125;&#125; ​ 如果有一个ReplicaManager对象要被垃圾回收了，那么假如这个对象重写了Object类中的finalize()方法。此时会先尝试调用它的finalize方法，看是否把这个实例对象给了某个GC Roots变量，比如上面代码就给了ReplicaManager类的静态变量。这样就重新让某个GC Roots变量引用了自己，那么就不用被垃圾回收了。 垃圾回收算法标记-清除算法​ 改算法会从每个GC Roots出发，依次标记没有引用关系的对象，最后将没有被标记的对象清除。但是这种算法会带来大量的空间碎片，导致需要分配一个较大连续空间时容易触发full GC. 标记-整理算法​ 为了解决“标记-清除”算法导致的大量内存碎片问题，又提出了“标记-整理算法”。改算法类似计算机的磁盘整理，首先会从GC Roots出发标记存活的对象，然后将存活的对象整理到内存空间的一端，形成连续的已使用空间，最后把已使用空间之外的部分全部清除掉，这样就不会产生空间碎片的问题。 复制算法​ 为了能够并行地标记和整理，将空间分为两块，每次只激活其中一块，垃圾回收时只需把存活的对象复制到另一块未激活的空间上，将未激活空间标记为已激活，将已激活空间标记为未激活，然后清除原空间中的原对象。两块空间就这么重复循环使用。复制算法现作为主流的YGC算法进行新生代的垃圾回收。 JVM中对复制算法的优化​ 在实际真正的复制算法中，把新生代内存区域划分为三块：1个Eden区，2个Survivor区。其中Eden区占80%内存空间，每一块Survivor区各占10%内存空间。平时可以使用的，就是Eden区和其中一块Survivor区。但是刚开始对象都是分配在Eden区的，如果Eden区满了吗，此时就会触发YGC。 ​ 此时就会把Eden区中的存活对象都一次性转移到空着的Survivor区，接着Eden区就会被清空，然后再次分配新对象到Eden区。这就就会变成Eden区和Survivor区里都是有对象的，其中Survivor区里放的是上一个YGC存活后的对象。 ​ 这么设计会始终保持一个Survivor区的空着的，就这样一直循环只用这三块内存区域。这么最最大的好处是，只有10%的空间时被闲置的，90%的内存都被用上了。 老年代和新生代怎样变成老年代​ 对象一般都先分配在新生代，但什么情况下新生代会变成老年代呢？ 躲过15次GC之后进入老年代​ 一般情况下，我们系统刚启动的时候，创建的各种各样的对象，都是分配在新生代里的。然后系统跑着跑着，新生代就满了，此时就会触发Minor GC，可能就是1%的少量存活对象转移到空着的Survivor区中。然后系统继续运行，继续在Eden区了分配各种对象。大概就是这个流程。 ​ 但那些每次在新生代里躲过一次GC被转移到一块Survivor区域中，它的年龄就会增长一岁。默认情况下，当对象的年龄达到15岁时，也就是躲过15次GC的时候，它就会转移到老年代里去。具体是多少岁进入老年代，可以通过参数-XX:MaxTenuringThreshold来设置，默认是15岁。 动态对象年龄判断​ 这里跟这个对象年龄有另外一个规则可以让对象进入老年代，不用等待15次GC过后才可以。大致的规则是：假如当前放对象的Survivor区域里，一批对象的总大小大于了这块区域的内存大小的50%，那么此时大于等于这批对象年龄的对象，就可以直接进入老年代了。 ​ 假设图里的Survivor2区有两个对象，这两对象的年龄一样，都是2岁。然后这两对象加起来超过了50MB，超过了Survivor2区的100MB内存的一半了，这个时候，Survivor2区里的大于等于2岁的对象，就要全部进入老年代里去。 ​ 这就是所谓的动态年龄判断的规则。实际上这个规则运行的时候是如下的逻辑：年龄1 + 年龄2 + 年龄n的多个年龄对象总和超过了Survivor区域的50%，此时就会把年龄n以上的对象都放入老年代。 大对象直接进入老年代​ 有一个JVM参数，就是-XX:PretenureSizeThreshold，可以把他的值设置为字节数，比如“1048576”，就是1MB。它的意思是，如果你要创建一个大于等于这个大小的对象，比如一个超大的数组，此时就直接把这个大对象放到老年代去，不会经过新生代。 ​ 这么做的原因，就是要避免新生代里出现那种大对象，然后屡次躲过GC，还得把它在两个Survivor区域里来回复制多次之后才能进入老年代，那么大的对象在内存里来回复制，浪费时间。 Minor GC后的对象太多无法放入Survivor区怎么办​ 如果Minor GC后的对象太多无法放入Survivor，那么这个时候就必须把这些对象直接转移到老年代中去。 老年代空间分配担保规则 在执行任何一次Minor GC之前，JVM会先检查一下老年代可用的内存空间，是否大于新生代所有对象的总大小。为什么检查这个，因为极端情况下，可能新生代Minor GC过后，所有对象都存活下来。 如果老年代的内存大小是大于新生代所有对象的，此时就可以放心大胆的对新生代发起一次Minor GC。因此即使Minor GC之后所有对象存活，Survivor区放不下，也可以转移到老年代去。 如果老年代的可用内存已经小于新生代的全部对象了，就去看-XX:-HandlePromotionFailure参数是否设置。 如果设置了，就看老年代的内存大小，是否大于之前每一次Minor GC后进入老年代的对象的平均大小。例如，之前每次Minor GC后，平均都有10MB左右的对象会进入老年代，那么此时老年代可用内存大于10MB。很可能这次Minor GC过后也是差不多10MB左右的对象会进入老年代，此时老年代空间是够的。 如果判断失败，或者是-XX:-HandlePromotionFailure参数没设置，此时就会触发一次“Full GC”，就是对老年代进行垃圾回收，尽量腾出一些内存空间，然后再执行Minor GC。 如果上面两个步骤都判断成功了，那就可以冒风险尝试一下Minor GC。此时进行Minor GC有几种可能。 第一种可能，Minor GC过后，剩余存活的对象的大小小于Survivor区的大小，那么此时存活对象进入Survivor区域即可。 第二种可能，Minor GC过后，剩余的存活对象的大小，大于Survivor区域的大小，但是小于老年代可用内存大小，此时直接进入老年代。 第三种可能，Minor GC过后，剩余的存活对象的大小，大于Survivor区域的大小，也大于老年代可用内存的大小。此时老年代都放不下这些存活对象了，就会发生“Handle Promotion Failure”的情况，这个时候就会触发一次“Full GC”。Full GC就是对老年代进行垃圾回收，同时一般也会对新生代进行垃圾回收。 如果Full GC之后，老年代还是没有足够的空间存放Minor GC过后的剩余存活对象，那么此时就会导致所谓的“OOM”内存溢出。 老年代垃圾回收算法​ 通过上面的内容，可以总结一句话：对老年代触发垃圾回收时机，一般就是两个： 在Minor GC之前，检查发现很可能Minor GC之后要进入老年代的对象太多了，老年代放不下，此时需要提前触发Full GC然后再带着进行Minor GC。 在Minor GC之后，发现剩余对象太多，老年代内存不够。 ​ 那么对老年代进行垃圾回收采用的是什么算法呢？简单地说，就是上面提到过的标记-整理算法。但是，这个老年代的垃圾回收算法的速度比新生代的垃圾回收算法的速度慢10倍。如果系统频繁出现老年代的Full GC，会导致系统性能被严重影响，出现频繁卡顿的情况。 ​ 其实， 所谓JVM优化，就是尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列之RocketMQ]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F10%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B9%8BRocketMQ%2F</url>
    <content type="text"><![CDATA[​ RocketMQ是阿里开源并贡献给Apache基金会的一款分布式消息平台，具有低延迟。高性能和可靠性、万亿级容量和灵活的可伸缩性的特点。单机也可以支持亿级的消息堆积能力、单机写入TPS单实例越7万条/秒，单机部署3个Broker，最高可以跑到12万条/秒。 RocketMQ的基本构成​ 整个RocketMQ消息系统主要由4个部分组成。 ​ 从中间件服务角度来看整个RocketMQ消息系统（服务端）主要分为：NameSrv和Broker两个部分。 NameSrv​ 在RocketMQ分布式消息系统中，NameSrv主要提供两个功能： 提供服务发现和注册。这里主要是管理Broker，NameSrv接受来自Broker的注册，并通过心跳机制来检测Broker服务的健康性。 提供路由功能。集群（这里是指以集群方式部署的NameSrv）中的每个NameSrv都保存了Broker集群（这是是指以集群方式部署的Broker）中整个的路由信息和队列信息。这里需要注意，在NameSrv集群中，每个NameSrv都是相互独立的，所以每个Broker需要连接所有的NameSrv，每创建一个新的topic都要同步到所有的NameSrv上。 Broker​ 主要是负责消息的存储、传递、查询以及高可用（HA）保证等。其由如下几个子模块构成： remoting：是Broker的服务入口，负责客户端的接入（Producer和Consumer）和请求处理。 client：管理客户端和维护消费者对于Topic的订阅。 store：提供针对存储和消息查询的简单的API（数据存储在物理磁盘）。 HA：提供数据在主从节点间同步的功能特性。 Index：通过特定的key构建消息索引，并提供快速的索引查询服务。 ​ 而从客户端的角度看主要有：Producer、Consumer两个部分。 Producer​ 消息的生产者，由用户进行分布式部署，消息有Producer通过多种负载均衡模式发送到Broker集群，发送低延时，支持快速失败。 Consumer​ 消息的消费者，也有用户部署，支持PUSH和PULL两种消费模式，支持集群消费和广播消费，提供实时的消息订阅机制，满足大多数消费场景。 RocketMQ的其他概念Producer Group​ 相同角色的生产者被组织到一起。在事务提交后，生产组中不同实例都可以连接broker执行提交或回滚事务，以防原生产者在提交后就挂掉。 Consumer Group​ 具有完全相同角色的消费者被组合在一起并命名为消费者组，消费群体是一个很好的概念，它在消费信息方面实现负载平衡和容错目标是非常容易的。另外，消费者组的消费者实例必须具有完全相同的主题订阅。 Topic​ 主题是生产者提供消息和消费者提取消息的类别。主题与生产者和消费者的关系非常松散，具体而言，一个主题可能有零个，一个或多个向其发送消息的生产者；相反，生产者可以发送不同主题的信息。从消费者的角度来看，一个主题可能有零个，一个或多个消费者群体订阅。同样，一个消费群体可以订阅一个或多个主题，只要这个群体的实例保持其订阅的一致性即可。 Message​ 消息是要传递的信息。一条信息必须要有一个主题，可以将其解释为要发送给您的信件的地址。一条消息也可能有一个可选标签和额外的键值对。例如，你可以为消息设置业务密钥，并在Broker上查找消息以在开发期间诊断问题。 Message Queue​ 主题被划分为一个或多个子主题，这就是消息队列。 Tag​ 标签可以理解为更细一级的主题，为使用者提供更灵活的查找。使用标签，来自同一业务模块的具有不同目的消息可能就有相同的主题和不同的标签。标签将有助于保持代码的清洁和一致性，并且标签还可以方便RocketMQ提供的查询系统。 Message Order​ 当使用DefaultMQPushConsumer时，你可能需要决定消费是顺序的还是并发的。 Orderly（顺序）：有序的消息意味着消息的使用顺序与生产者为每个消息队列发送的顺序相同。如果你的使用场景要求是必须顺序的，你要确保只用一个队列存放消息。如果消费顺序被指定，最大的消费并发数就是这个消费者组的消息队列的订阅数。 Concurrently（并发）：并发使用消息时，消费消息的最大并发性仅受限于为每个消费者客户端指定的线程池。 安装RocketMQ1、下载Apache最新rocketmq二进制压缩文件​ 可以到官网下载后上传到服务器上，也可以用wget命令。 1wget https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.5.2/rocketmq-all-4.5.2-bin-release.zip/ 2、解压安装​ 使用unzip命令进行解压。 1unzip -d /usr/local rocketmq-all-4.5.2-bin-release.zip 3、环境变量​ 配置环境变量 vi /etc/profile。添加如下代码： 1export NAMESRV_ADDR=127.0.0.1:9876 4、启动RocketMQ​ 进入rocketmq的bin目录，修改runserver.sh，如下代码： 1JAVA_OPT="$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m" ​ 主要根据自己机器内存酌情修改-Xms -Xmx -Xmn这几个参数的内存。 ​ 同理修改bin目录下的runbroker.sh的JVM参数。 ​ 进入conf目录，修改broker.conf，新增一行： 1brokerIP1=xx.xx.xx.xx # 你的公网IP ​ 然后开始启动mqnamesrv，进入到rocket目录，执行nohup sh bin/mqnamesrv &amp;启动namesrv，然后再执行nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf &amp;启动broker。 ​ 执行jps，看namesrv和broker是否启动成功，如果没成功。可以通过执行tail -f ~/logs/rocketmqlogs/namesrv.log和tail -f ~/logs/rocketmqlogs/broker.log查看相应日志。 RocketMQ集群模式​ RocketMQ集群部署有多种方式，对于NameSrv来说可以同时部署多个节点，并且这些节点间也不需要有任何的信息同步，因为这里每个NameSrv节点都会存储全量路由信息。在NameSrv集群模式下，每个Broker都需要同时向集群中的每个NameSrv节点发送注册信息，所以这里对于NameSrv的集群部署来说并不需要做什么额外的设置。 ​ 而对于Broker集群来说就有多种模式了，主要有如下几个模式： 单个Master模式​ 一个Broker作为主服务，不设置任何Slave，这种方式风险比较大，存在单节点故障会导致整个基于消息的服务挂掉，所以生产环境不可能采用这种模式。 多Master模式​ 这种模式的Broker集群，全是Master，没有Slave。 优点​ 配置会比较简单一些，如果单个Master挂掉或重启维护的话对应用是没有什么影响的。如果磁盘配置为RAID10（服务器的磁盘阵列模式）的话，即使在机器宕机不可恢复的情况下，由于RAID10磁盘本身的可靠性，消息也不会丢失（异步刷盘丢失少量消息，同步刷盘一条不丢），这个Broker的集群模式性能相对来说是最高的。 缺点​ 在单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前是不可以进行消息订阅的，这对消息的实时性有一些影响。 多Master多Slave模式（异步复制）​ 这种模式下的Broker集群存在多个Master节点，并且每个Master节点都会对应一个Slave节点，有多对Master-Slave，HA（高可用）之间采用异步复制的方式进行信息同步，在这种方式下主从之间会有短暂的毫秒级的消息延迟。 优点​ 这种模式下即使磁盘损坏了，消息丢失的情况也非常少，因为主从之间有消息备份。并且，这种模式下的实时性也不会受影响，因为Master宕机后Slave可以自动切换为Master模式，这样Consumer仍然可以通过Slave进行消息消费，而这个过程对应用来说是完全透明的，并不需要人工干预。另外，这种模式的性能与多Master模式几乎差不多。 缺点​ 如果Master宕机，并且在磁盘损坏的情况下，会丢失少量的消息。 多Master多Slave模式（同步复制）​ 这种模式与上面那个差不多，只是HA采用的是同步双写的方式，即主备都写成功后，才会向应用返回成功。 优点​ 这种模式下数据与服务不存在单点的情况，在Master宕机的情况下，消息也没有延迟，服务的可用性以及数据的可用性都非常高。 缺点​ 性能相比于异步复制略低一些（大约10%）。 SpringBoot整合RocketMQ​ 这里主要讲解一下生产者和消费者的代码，完整的项目代码已上传到github上。 消息生产者RocketMQProvider​ 以顺序发消息为例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.example.rocketmqDemo.rocketmq;import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.client.producer.MessageQueueSelector;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.common.message.Message;import org.apache.rocketmq.common.message.MessageQueue;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Service;import org.springframework.util.StopWatch;import java.util.List;@Servicepublic class RocketMQProvider &#123; @Value("$&#123;apache.rocketmq.producer.producerGroup&#125;") private String producerGroup; @Value("$&#123;apache.rocketmq.namesrvAddr&#125;") private String namesrvAddr; public void defaultMQProducer() &#123; //生产组的名称 DefaultMQProducer producer = new DefaultMQProducer(producerGroup); //指定NameServer地址，多个地址以;隔开 producer.setNamesrvAddr(namesrvAddr); try &#123; //Producer对象在使用之前必须要调用start初始化，初始化一次即可 //注意：切记不可以在每次发送消息时，都调用start方法 producer.start(); //创建一个消息实例，包含topic、tag和消息体 //如下：topic为"TopicTest"，tag为"push" Message message = new Message("TopicTest", "push", "发送消息----".getBytes()); StopWatch stop = new StopWatch(); stop.start(); for(int i = 0; i &lt; 10; i++) &#123; SendResult result = producer.send(message, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, 1); System.out.println("发送相应：MsgId: " + result.getMsgId() + ".发送状态: " + result.getSendStatus()); &#125; stop.stop(); System.out.println("-----------------------发送十条消息耗时：" + stop.getTotalTimeMillis()); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; producer.shutdown(); &#125; &#125;&#125; ​ 一般消息时通过轮询所有队列来发送的（负载均衡策略），顺序消息可以根据业务发送到同一个队列。比如将订单号相同的消息发送到同一个队列。下面的代码中指定了1,1处这个值相同的获取到的队列是同一个队列。 12345678SendResult result = producer.send(message, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125;&#125;, 1); 消息消费者RocketMQConsumer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.example.rocketmqDemo.rocketmq;import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.common.consumer.ConsumeFromWhere;import org.apache.rocketmq.common.message.MessageExt;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.CommandLineRunner;import org.springframework.stereotype.Service;@Servicepublic class RocketMQConsumer implements CommandLineRunner &#123; //消费者的组名 @Value("$&#123;apache.rocketmq.consumer.PushConsumer&#125;") private String consumerGroup; @Value("$&#123;apache.rocketmq.namesrvAddr&#125;") private String namesrvAddr; public void defaultMQPushConsumer() &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(consumerGroup); consumer.setNamesrvAddr(namesrvAddr); try &#123; //订阅PushTopic下Tag为push的消息 consumer.subscribe("TopicTest", "push"); //设置Consumer第一次启动是从头部开始消费还是队列尾部开始消费 //如果非第一次启动，那么按照上次消费的位置继续消费 consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.registerMessageListener((MessageListenerConcurrently)(list, context)-&gt; &#123; try &#123; for(MessageExt messageExt : list) &#123; //输出消息内容 System.out.println("messageExt: " + messageExt); String messageBody = new String(messageExt.getBody()); //输出消息内容 System.out.println("消费响应：msgId : " + messageExt.getMsgId() + ", msgBody : " + messageBody); &#125; &#125;catch (Exception e) &#123; e.printStackTrace(); //稍后重试 return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; //消费成功 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;); consumer.start(); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run(String... args) throws Exception &#123; this.defaultMQPushConsumer(); &#125;&#125; ​ 消费者中我们实现了CommandLineRunner接口。它的作用是让消费者在springboot启动时执行。具体可以参考CommandLineRunnable详解。 ​ 项目成功启动后，测试的结果应该是： 123456789101112131415161718192021222324252627282930313233342019-10-11 17:13:50.785 INFO 12872 --- [nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'2019-10-11 17:13:50.785 INFO 12872 --- [nio-8080-exec-2] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'2019-10-11 17:13:50.793 INFO 12872 --- [nio-8080-exec-2] o.s.web.servlet.DispatcherServlet : Completed initialization in 8 ms发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OK发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=51, sysFlag=0, bornTimestamp=1570785233301, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231900, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEAFFF, commitLogOffset=28225535, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=52, CONSUME_START_TIME=1570785233370, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]messageExt: MessageExt [queueId=1, storeSize=178, queueOffset=50, sysFlag=0, bornTimestamp=1570785233233, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231856, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEAF4D, commitLogOffset=28225357, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=52, CONSUME_START_TIME=1570785233370, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=52, sysFlag=0, bornTimestamp=1570785233346, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231943, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB0B1, commitLogOffset=28225713, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=53, CONSUME_START_TIME=1570785233411, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=53, sysFlag=0, bornTimestamp=1570785233387, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231986, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB163, commitLogOffset=28225891, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=54, CONSUME_START_TIME=1570785233453, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=54, sysFlag=0, bornTimestamp=1570785233430, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232028, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB215, commitLogOffset=28226069, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=55, CONSUME_START_TIME=1570785233495, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=55, sysFlag=0, bornTimestamp=1570785233472, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232071, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB2C7, commitLogOffset=28226247, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=56, CONSUME_START_TIME=1570785233538, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=56, sysFlag=0, bornTimestamp=1570785233516, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232114, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB379, commitLogOffset=28226425, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=57, CONSUME_START_TIME=1570785233580, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=57, sysFlag=0, bornTimestamp=1570785233557, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232156, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB42B, commitLogOffset=28226603, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=58, CONSUME_START_TIME=1570785233622, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=58, sysFlag=0, bornTimestamp=1570785233600, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232199, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB4DD, commitLogOffset=28226781, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=59, CONSUME_START_TIME=1570785233665, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OK-----------------------发送十条消息耗时：1479messageExt: MessageExt [queueId=1, storeSize=178, queueOffset=59, sysFlag=0, bornTimestamp=1570785233642, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232241, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB58F, commitLogOffset=28226959, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=60, CONSUME_START_TIME=1570785233707, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息---- 参考资料Centos7下安装Rocket RocketMQ连接异常 基于RocketMQ搭建生产级消息集群]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[外观模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F08%2F%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ 在软件开发中，有时候为了完成一项较为复杂的功能，一个类需要和多个其他业务类交互，而这些需要交互的业务类经常会作为一个完整的整体出现，由于涉及的类比较多，导致使用时代码较为复杂，此时，需要一个类似服务员一样的角色，由它来负责和多个业务类进行交互，而使用这些业务类的类只需和该类交互即可。外观模式通过引入一个新的外观类来实现该功能，外观类充当了软件系统中的“服务员”，它为多个业务类的调用提供了一个统一的入口，简化了类与类之间的交互。 外观模式定义​ 外观模式要求一个子系统的外部与其内部的通信通过一个统一的外观角色进行，外观角色将客户端与子系统的内部复杂性分隔开，使得客户端只需要与外观角色打交道，而不需要与子系统内部的很多对象打交道，其定义如下： ​ 外部与一个子系统的通信通过一个统一的外观角色进行，为子系统中的一组接口提供一个一致的入口，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。外观模式又称为门面模式，它是一种对象结构型模式。 外观模式结构图 ​ 在外观模式结构图中包含以下两种角色： Facade（外观角色）：在客户端可以调用这个角色的方法，在外观角色中可以知道相关的（一个或者多个）子系统的功能和责任，在正常情况下，它将所有从客户端发来的请求委派到相应的子系统中去，传递给相应的子系统对象处理。 SubSystem（子系统角色）：在软件系统中可以有一个或者多个子系统角色，每一个子系统可以不是一个单独的类，而是一个类的集合，它实现子系统的功能，每一个子系统都可以被客户端直接调用，或者被外观角色调用，它处理由外观类传过来的请求；子系统并不知道外观的存在，对于子系统而言，外观角色仅仅是另外一个客户端而已。 案例​ 某软件公司欲开发一个可应用与多个软件的文件加密模块，改模块可以对文件中的数据进行加密并将加密之后的数据存储在一个新文件中，具体流程包括三个部分，分别是读取源文件、加密、保存加密之后的文件。其中，读取文件和保存文件使用流来实现，加密操作通过求模运算来实现。这三个操作相互独立，为了实现代码的独立重用，让设计更符合单一职责原则，这3个操作的业务代码封装在3个不同的类中。 ​ 相关代码已上传至github上。 抽象外观类的引入​ 在标准的外观模式中，如果需要增加、删除或更换与外观类交互的子系统类，必须修改外观类或客户端的源代码，这将违背开闭原则，因此可以通过引入抽象外观类来对系统进行改进，在一定程度上解决该问题。在引入抽象外观类之后，客户端可以针对抽象外观类进行编程，对于新的业务需求，不需要修改原有外观类，而对应增加一个新的具体外观类，由新的具体外观类来关联新的子系统对象，同时通过修改配置文件来达到不修改任何源代码并更换外观类的目的。 ​ 如在上面的案例中，如果要更换原有的加密方式，换成新的加密方式。那么相应的解决思路如下图： 外观模式主要优缺点主要优点 对客户端屏蔽了子系统组件，减少了客户端所需处理的对象数目并使得子系统使用起来更加容易。通过引入外观模式，客户端代码变得很简单，与之关联的对象也很少。 实现了子系统与客户端之间的松耦合关系，这使得子系统的变化不会影响到调用它的客户端，只需要调整外观类即可。 一个子系统的修改对其他子系统没有任何影响，而且子系统内部变化也不会影响到外观对象。 只是提供了一个访问子系统的统一入口，并不影响客户端直接使用子系统类。 主要缺点 不能很好地限制客户端直接使用子系统类，如果对客户端访问子系统类做太多的限制则减少了可变性和灵活性。 如果设计不当，当增加新的子系统可能需要修改外观类的源代码，这违背了开闭原则。 外观模式适用场景 当要为访问一系列复杂的子系统提供一个简单入口时可以使用外观模式。 客户端程序与多个子系统之间存在很大的依赖。引入外挂类可以将子系统与客户端解耦，从而提供子系统的独立性和可移植性。 在层次化结构中，可以使用外观模式定义系统中每一层的入口，层与层之间不直接产生联系，而通过外观类建立联系，降低层之间的耦合度。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列之RabbitMQ]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F07%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B9%8BRabbitMQ%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ RabbitMQ是一个消息代理，一个消息系统的媒介。它可以为你的应用提供一个通用的消息发送和接收平台，并且保证消息在传输过程中的安全。 基础概念​ RabbitMQ中除了正常的生产者消费者之外，还有一些其他的概念来支撑这样一个复杂的消息队列。 Broker​ Broker是消息服务中间件的一个服务节点，大部分情况下可以把一个Broker看成一个RabbitMQ的服务器。 ​ 上图可以看出Broker相当于一个消息服务的中央节点，而我们的消息队列核心功能也就在Broker上。 队列​ 消息都存储在队列中，下图是一个简单的模型。实际上，一个简单的消息队列服务只要有生成者、消费者和存储单元组成队列即可。 Exchange​ 交换机（Exchange）在RabbitMQ中承担了一些队列的逻辑处理功能。一般来说，对于生产者，我们只知道把产生的内容丢到MQ当中，但是发到哪个队列中，这一点对于生产者来说是无感知的，也不知道目前对列的状况如何。而Exchange就承担了发到哪个队列中的职责，用几种路由策略来决定如何分发给不同的队列。 Connection和Channel​ 每一个Connection是一条TCP连接，理论上而言每一个消费者和生产者都需要一条Connection，但是TCP连接的开销很大，所以我们会使用Channel来进行TCP复用，减少性能的开销。 Exchange类型fanout​ 我们比较常用的一种Exchange类型，它会把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。 direct​ 把消息路由到binding 可以和routing key完全匹配的队列中。 ​ binding key和routing key基本上可以理解为对一个Queue的称呼。 ​ 图中Queue1叫warning，Queue2可以叫info，warning或者debug，那样Exchange叫了声warning的时候会有两个Queue过来拿数据，而info只有Queue2会回应。 topic​ direct类型太过严格，大部分我们都用不上这么严格的规则，因此有了topic。topic可以看做是一种正则表达式规则，满足正则表达式的规则就会进入队列。 headers​ 这种类型根据发送信息中的header来匹配，性能差，基本没用。 死信队列​ DLX（Dead-Letter-Exchanage）。利用DLX，当消息在一个对列中变成死信之后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。消息变成死信一般有以下几种情况： 消息被拒绝（basic.reject/basic.nack）并且不再重新投递 require = false 消息过期（rabbitmq Time-To-Live -&gt; messageProperties.setExpiration()） 队列达到最长长度 ​ 当一个消息变成死信导致队列无法处理的时候，开启死信队列，使得消息不会堆积在队列中，而换到死信队列被消费。在RabbitMQ中开启死信队列非常简单，只要配置为DLX即可。 公用Connection而不是Channel​ 公用Connection的理由在上面已经提过，那为什么不建议公用Channel呢？ ​ 计算机网络传输信息的时候，本质上都是二进制传输，而传输的数据经过一定的处理，最终变成我们可读可处理的数据，Channel已经是复用了TCP连接的，此时如果我们再进行并行的数据传输，很有可能会导致某一帧数据的异常。 RabbitMQ的高可用性​ RabbitMQ是基于主从做高可用性的。一般来说，RabbitMQ有三种模式：单机模式、普通集群模式和镜像集群模式。 单机模式​ 单机模式，就是Demo级别的，一般就是你本地启动了做做demo，基本没人生产用单机模式。 普通集群模式（无高可用性）​ 普通集群模式，意思就是在多台机器上启动多个RabbitMQ实例，每个机器启动一个。你创建的queue，只会放在一个RabbitMQ实例上，但是每个实例都同步queue的元数据（元数据可以认为是queue的一些配置信息，通过元数据，可以找到queue所在实例）。你消费的时候，实际上如果连接到了另一个实例，那么那个实例会从queue所在实例上拉取数据过来。 ​ 这种方式不仅麻烦，而且也没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。 ​ 而且如果那个放queue的实例宕机了，会导致接下来其他实例无法从那个实例拉取数据。如果你开启了消息持久化，让RabbitMQ落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。 ​ 因此这个方案主要是用来提供吞吐量的，就是让集群中多个节点来服务某个queue的读写操作，没有所谓的高可用性。 镜像集群模式（高可用性）​ 这种模式，才是所谓的RabbitMQ的高可用模式。跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，就是说，每个RabbitMQ节点都有这个queue的一个完成镜像，包含queue的全部数据的意思。然后你每次写消息到queue的时候，都会自动把消息同步到多个实例的queue上。 ​ 如何开启镜像集群模式？RabbitMQ有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求同步指定数据的节点，再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。 ​ 这样处理，好处在于任何一个机器宕机了，其他机器还包含了这个queue的完整数据，别的consumer都可以到其他节点上去消费数据。坏处在于：第一，性能开销太大，消息需要同步到所有机器上，导致网络带宽压力和消耗都重；第二，这样处理并不是分布式的，没有扩展性可言，如果某个queue负载很重，你加机器，新的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue。 RabbitMQ的可靠性传输​ 数据的丢失问题，可能出现在生产者、MQ、消费者中，如下图： 生产者弄丢了数据​ 生产者将数据发送到RabbitMQ的时候，因为网络问题或其他情况，导致数据在半路就搞丢了。 事务机制​ 此时可以选择用RabbitMQ提供的事务功能，就是生产者发送数据之前开启RabbitMQ事务channel.txSelect，然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息，如果收到了消息，那么可以提交事务channel.txCommit。 123456789101112// 开启事务channel.txSelecttry &#123; // 这里发送消息&#125; catch (Exception e) &#123; channel.txRollback // 这里再次重发这条消息&#125;// 提交事务channel.txCommit ​ 但是问题是，这样会导致吞吐量下来，因为太耗性能。 confirm机制​ 因此一般情况下，要确保RabbitMQ的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ中，RabbitMQ会给你回传一个ack消息，告诉你这个消息OK了，如果RabbitMQ没能处理这个消息，会回调你的一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。 两个机制的区别​ 事务机制和confirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息RabbitMQ接收了之后会异步回调你的一个接口通知你这个消息接收到了。所以一般在生产者这块避免数据丢失，都是用confirm机制。 RabbitMQ弄丢了数据​ 即使RabbitMQ自己弄丢了数据，这个你必须开启RabbitMQ的持久化，就是消息写入之后会持久化到磁盘，哪怕是RabbitMQ自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非RabbitMQ还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率比较小。 ​ 设置持久化有两个步骤： 创建queue的时候将其设置为持久化，这样就可以保证RabbitMQ持久化queue的元数据，但是它不会持久化queue里的数据。 第二是是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上去。 ​ 必须要同时设置这两个持久化才行，这样RabbitMQ哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。 ​ 但是哪怕是你给RabbitMQ开启了持久化机制，也有一种可能，就是这个消息写到了RabbitMQ中，但是还没来得及持久化到磁盘上，结果RabbitMQ挂了，就会导师内存里的一点点数据丢失。所以，持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产这ack了。这样即便是持久化到磁盘之前，RabbitMQ挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。 消费端弄丢了数据​ 如果消费端刚消费到消息，但还没处理，结果进程挂了，这样就尴尬了。RabbitMQ认为你都消费了，这数据也就丢了。 ​ 这个时候可以用RabbitMQ提供的ack机制，即，你必须关闭RabbitMQ的自动ack,可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里ack一把。这样的话，如果你还没处理完，就没有ack,RabbitMQ就认为你还没处理完，这个时候RabbitMQ会把这个消费分配给别的consumer去处理，消息是不会丢的。 RabbitMQ的消息顺序性​ 举个例子，一个mysql binlog同步的系统，日同步数据要达到上亿，就是说数据从一个mysql库原封不动同步到另一个mysql库里面去（mysql -&gt; mysql）。然后你在mysql里增删改一条数据，对应出来增删改3条binlog日志，接着这三条binlog发送到MQ里面，再消费出来依次执行，要保证是按顺序执行的。否则本来是：增加、修改、删除，最后换了顺序给执行成删除、修改、增加。这就错了。 ​ 先看看RabbitMQ消息会错乱的场景：在RabbitMQ中，一个queue，多个consumer、比如生产者向RabbitMQ里发送了三条数据，顺序依次是data1/data2/data3，压入的是RabbitMQ的一个内存队列。有三个消费者分别从MQ中消费这三条数据中的一条，结果消费者2先执行完操作，把data2存入数据库，然后是data1/data3，这样就乱了。 解决方案​ 拆分多个queue，每个queue一个consumer，就是多一些queue而已；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然胡分发给不同的worker来处理。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis在实践中的一些常见问题与优化思路]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F06%2FRedis%E5%9C%A8%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E4%B8%8E%E4%BC%98%E5%8C%96%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[fork耗时操作导致高并发请求延时​ Redis在开启RDB和AOF持久化机制的时候，会有生成RDB快照，AOF rewrite等耗费磁盘IO的操作，此时主进程会fork子进程去执行。fork的时候，子进程需要拷贝父进程的空间内存页表的，这个也会耗费一定的时间。一般来说，如果父进程内存有1个G的数据，那么fork可能会耗费20ms左右，如果是10G30G，那么就会耗费200600ms，也就是几百毫秒的时间。可以在redis中执行info stats，其中的latest_fork_usec，可以看到最近一次form的时长。 ​ 如果redis单机QPS是几万，fork可能一下子就会拖慢几万条操作的请求时长。 优化思路​ fork耗时跟redis主进程的内存有关系，一般控制redis的内存在10GB以内。 AOF的阻塞问题​ redis将数据写入AOF缓冲区，然后会每秒做一次fsync。但是redis主线程会检查两次fsync的时间，如果距离上次fsync时间超过了2秒，那么写请求就会阻塞。这样可以保证redis最多丢失2秒的数据，但一旦fsync超过2秒的延时，整个redis就会被拖慢。 优化思路​ 优化硬盘写入速度，建议采用SSD，不要用普通的机械硬盘。 主从复制延迟问题​ 主从复制可能会超时严重，这个时候需要良好的监控和报警机制，在redis中执行info replication，可以见到master和slave复制的offset，做一个差值就可以看到对应的延迟量，如果延迟过多，那么久进行报警。 主从复制风暴问题​ 如果一下子让多个slave从master去执行全量复制，一份大的RDB同时发送到多个slave，会导致网络带宽被严重占用。如果一个master需要挂载很多个slave，那么尽量用树状结构，不要用星型结构。 Linux系统内核的优化​ 不同版本的Linux系统设置可能不一样，以下的内容只是提供一个思路，具体命令请根据不同的版本号自行百度。 vm.overcommit_memory​ 执行cat /proc/sys/vm/overcommit_memory，默认情况会返回0。这些数字代表的意义如下： 0：检查有没有足够内存，没有的话申请内存失败 1：允许使用内存直到用完为止 2：内存地址空间不能超过swap + 50% ​ 如果是0的话，可能导致类似fork等操作执行失败，申请不到足够的内存空间。可以将该参数设置为1。可以先后执行echo &quot;vm.overcommit_memory=1&quot; &gt;&gt; /etc/sysctl.conf和sysctl vm.overcommit_memory=1。 swapiness​ 执行cat /proc/version，查看系统内核版本。 ​ 如果Linux内核版本&lt;3.5，那么swapiness设置为0，这样系统宁愿swap也不会oom killer（杀掉进程） ​ 如果Linux内核版本&gt;=3.5，那么swapiness设置为1，这样系统宁愿swap也不会oom killer。 ​ 这样可以保证redis不会被杀掉。 12echo 0 &gt; /proc/sys/vm/swappinessecho vm.swapiness=0 &gt;&gt; /etc/sysctl.conf 最大打开文件句柄​ ulimit -n 10032 10032 tcp backlog​ 开始之前我们先回忆一下TCP建立连接的三次握手： Client发出一个数据包并将SYN置1，表示希望建立连接。这个包中的序列号假设是x。并将状态修改为SYN_SENT。 Server抽到Client发过来的数据包后，通过SYN得知这是一个建立连接的请求。于是发送一个响应包并将SYN和ACK都置1。假设这个包中的序列号是y，而确认序列号必须是x+1，表示收到了A发过来的SYN。并将自己的状态修改为SYN_RCVD，并把该请求放到syns queue队里中。 Client收到Server的响应包后进行确认，确认包中将ACK置1，并将确认序列号设置为y+1，表示收到了B的SYN。此时将状态修改为ESTABLISHED Server收到ACK后，将状态修改为ESTABLISHED，并把该请求从syns queue中放到accept queue。 ​ 在Linux系统内核中维护了两个队列：sync queue和accept queue。 sync queue：用于保存半连接状态的请求，其大小通过/proc/sys/net/ipv4/tcp_max_syn_backlog指定，一般默认值是512，不过这个设置有效的前提是系统的syncookies功能被禁用。互联网常见的TCP SYN FLOOD恶意DOS攻击方式就是建立大量的半连接状态的请求，然后丢弃，导致syns queue不能保存其它正常的请求。 accept queue：用于保存全连接状态的请求，其大小通过/proc/sys/net/core/somaxconn指定，在使用listen函数时，内核会根据传入的backlog参数与系统参数somaxconn，取二者的较小值。 如果accpet queue队列满了，server将发送一个ECONNREFUSED错误信息Connection refused到client。 ​ 这个方案就是调大accept queue的大小，其默认值是128，我们可以将其设置为511. 12cat /proc/sys/net/core/somaxconnecho 511 &gt; /proc/sys/net/core/somaxconn]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零开始搭建Redis集群]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F06%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BARedis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[​ Redis Cluster集群，要求至少3个master去组成一个高可用，健壮的分布式的集群，每个master都建议至少给一个slave，因此，最少要求3个master，3个slave。在正式环境中，建议在6台机器上搭建。也可是3台，但要保证每个master都跟自己的slave不在同一台机器上。 搭建Redis​ 搭建Redis Cluster之前，我们需要先搭建redis。先去官网中下载一个redis，目前稳定版本是redis-5.0.5。下载完后将其上传到Linux系统上，我一般放在/usr/local目录中。 上传完成后，执行tar -zxvf redis-5.0.5.tar.gz解压 执行cd redis-5.0.5/进入redis目录 执行make &amp;&amp; make test &amp;&amp; make install 编译过程中会报一个错误You need tcl 8.5 or newer in order to run the Redis test，说明我们需要安装tcl才能安装redis。执行yum install tcl进行安装 安装好之后再次执行make &amp;&amp; make test &amp;&amp; make install进行编译，需要等待一定的时间。等他编译好之后，有可能会报一个warning，这个可以不用管它。 这样我们就把redis装好了。执行ls查看redis文件夹下的文件 生产环境的redis启动方案​ 在生产环境中，要把redis作为一个系统的daemon进程去执行，每次系统启动，redis进程也一起启动。 在redis_util目录中，有个redis_init_scipt脚本。将这个脚本拷贝到Linux的/etc/init.d目录中，将redis_init_script重命名为redis_6379,6379使我们希望这个redis实例监听的端口号。cp redis_init_script /etc/init.d/redis_6379 修改redis_6379脚本的REDISPORT，设置为6379（默认就是6379）。 创建两个目录：/etc/redis（存放redis的配置文件），/var/redis/6379（存放redis的持久化文件）。 修改redis配置文件，默认在根目录下，拷贝到/etc/redis目录中，修改名称为6379.conf。 修改redis.conf的部分配置： daemonize yes pidfile /var/run/redis_6379.pid # 设置redis的pid文件位置 port 6379 #设置redis的监听端口号 dir /var/redis/6379 #设置持久化文件的存储位置 启动redis 分别执行以下语句 cd /etc/init.d、chmod 777 redis_6379、./redis_6379 start 执行ps -ef | grep redis确认redis进程是否启动。 在redis跟随系统启动自动启动。在redis_6379脚本中的上面，加入两行注释，然后执行chkconfig redis_6379 on。 123# chkconfig: 2345 90 10# description: Redis is a persistent key-value database 搭建Redis Cluster​ 现在开始搭建redis集群。这个案例模拟的是在三台服务器上搭建redis cluster。在搭建redis集群的时候先关闭所有的redis实例。在搭建之前，先了解几个redis cluster的重要配置： cluster-enabled &lt;yes/no&gt; cluster-config-file 这是指定一个文件，供cluster模式下的redis实例将集群状态保存在那里，包括集群中其他机器的信息，比如节点的上线和下线，故障转移。这个不是我们去维护，只是给它指定一个文件，让redis自己去维护。 cluster-node-time 节点存活超时时长，超过一定时长，认为节点宕机，master宕机的话就会触发主备切换，salve宕机就不会提供服务。 开始搭建redis cluster 先在三台服务器上安装redis。我们需要在三个服务器上搭建六个redis实例，端口号分别为7001、7002、7003、7004、7005和7006 先在三个服务器上建两个文件件mkdir -p /etc/redis-cluster 、mkdir -p /var/log/redis，然后在服务器1建立mkdir -p /var/redis/7001和mkdir -p /var/redis/7002文件夹，再在服务器2和服务器3分别建立7003、7004和7005、7006文件夹。 修改redis的配置文件。举一个例子，将上面的6379.conf配置文件复制一份并修改为7001.conf。重点修改一下几个配置： 12345678910port 7001cluster-enabled yescluster-config-file /etc/redis-cluster/node-7001.confcluster-node-timeout 15000daemonize yes pidfile /var/run/redis_7001.pid dir /var/redis/7001 logfile /var/log/redis/7001.logbind 192.168.31.187 appendonly yes 然后再接着生成并修改7002 7003 7004 7005 7006.conf配置文件，并放在相应的服务器中。 准备生产环境的启动脚本。在服务器1中，在/etc/init.d目录下，将redis_6379启动启动脚本复制一份并命名为redis_7001，并修改里面的端口号。同样的生成7002 7003 7004 7005 7006的启动脚本，并放在相应服务器的/etc/init.d目录下。 分别在3台服务器上，启动6个redis实例。 创建集群​ 6个redis实例启动后，就开始创建集群。 随便选中一台服务器，开始安装ruby。执行yum install -y ruby yum install -y rubygems gem install redis。 安装完成后，将redis-5.0.5目录中的src目录下的redis-trib.rb拷贝到/usr/local/bin中。cp /usr/local/redis-3.2.8/src/redis-trib.rb /usr/local/bin 执行redis-trib.rb create --replicas 1 192.168.0.112:7001 192.168.0.112:7002 192.168.0.113:7003 192.168.0.113:7004 192.168.0.114:7005 192.168.0.114:7006。其中上面的IP地址就是你的机器地址。 执行后会报下面的错误，这是因为yum安装的ruby的版本太低的缘故，可以执行ruby -v查看相应的版本。 1234567redis-trib.rb:6: odd number list for Hash white: 29, ^ redis-trib.rb:6: syntax error, unexpected &apos;:&apos;, expecting &apos;&#125;&apos; white: 29, ^ redis-trib.rb:7: syntax error, unexpected &apos;,&apos;, expecting kEND 执行yum remove -y ruby和yum remove -y rubygems 从官网下载最新的ruby压缩包，上传到服务器上 解压tar -zxvf ruby-2.6.5.tar.gz，解压后进入到相应目录中，开始编译。执行./configure 、make 、 make install，并等待一段时间。 执行ruby -v查看是否安装成功。 再次执行 redis-trib.rb create --replicas 1 192.168.0.112:7001 192.168.0.112:7002 192.168.0.113:7003 192.168.0.113:7004 192.168.0.114:7005 192.168.0.114:7006。此时会抱一个WARNING。 12345678910111213141516WARNING: redis-trib.rb is not longer available! You should use redis-cli instead. All commands and features belonging to redis-trib.rb have been moved to redis-cli. In order to use them you should call redis-cli with the --cluster option followed by the subcommand name, arguments and options. Use the following syntax: redis-cli --cluster SUBCOMMAND [ARGUMENTS] [OPTIONS] Example: redis-cli --cluster create 127.0.0.1:30001 127.0.0.1:30002 127.0.0.1:30003 127.0.0.1:30004 127.0.0.1:30005 127.0.0.1:30006 --cluster-replicas 1 To get help about all subcommands, type: redis-cli --cluster help 按照example执行以下命令redis-cli --cluster create 192.168.0.112:7001 192.168.0.112:7002 192.168.0.113:7003 192.168.0.113:7004 192.168.0.114:7005 192.168.0.114:7006 --cluster-replicas 1 这样就创建好集群了，它会帮你指定好谁当master谁当slave。你查看后觉得没问题就输入yes即可。 节点的增加与删除增加master节点 先按照上述操作，新建一个端口号为7007的redis实例，并启动。 在7001服务器上执行redis-cli --cluster add-node 192.168.0.114:7007 192.168.0.112:7001，将新增的7007redis实例增加到redis cluster中。 执行redis-cli --cluster check 192.168.0.114:7007查看redis cluster的情况，可以看到7007实例已经作为master新增到redis cluster中。但这个master只有0个hash slots，所以我们还要给他分配hash slots. 因为16364 / 4 = 4096，因此需要从其他三个master中迁移总共4096个节点到7007上。在任意一台服务器上执行redis-cli --cluster reshard 192.168.0.112 7001。执行后会出现How many slots do you want to move (from 1 to 16384)?，这是询问你要迁移多少slots，我们输入4096。执行后会出现What is the receiving node ID?这是询问你要迁移到哪里去，根据上图可知7007的ID是eb9267b3f16da7317e0f13f7f42fd2f2cf0857a1，输入进行执行。然后会出现Please enter all the source node IDs. Type &#39;all&#39; to use all the nodes as source nodes for the hash slots. Type &#39;done&#39; once you entered all the source nodes IDs.。这是让我们输入数据源的redis的ID，我们输入另外3个master的ID后输入done，之后再输入yes即可。 再次执行redis-cli --cluster check 192.168.0.114:7007查看redis cluster的情况。可以看到此时7007已经有4096个slots了。 增加slave节点 先按照上述操作，新建一个端口号为7008的redis实例，并启动。 执行redis-cli --cluster add-node 192.168.0.114:7008 192.168.0.112:7001 --cluster-slave --cluster-master-id f7b8e55612bce7574deecd57827e3b8203c1c9a6。其中的master-id是7004redis的ID。意思是将7008挂载为7004的slave。 执行redis-cli --cluster 192.168.0.113:7004查看7004的情况，可以看到7008已经是7004的slave了，但之前7001本来是7004的slave，却挂载到本来没有slave的7007master上，称为7007的slave。 删除节点 删除master之前。先用reshard将数据迁移到其他节点，确保node为空后，才能执行remove操作 假设我们要删除7007节点，先执行redis-cli --cluster reshard 192.168.0.112:7001，然后输入1365，将1365个slot迁移到其中一个master中。然后再依次迁移1365和1366个slot到另外两个master中。此时7007零个slots。 执行redis-cli --cluster del-node 192.168.0.112:7001 eb9267b3f16da7317e0f13f7f42fd2f2cf0857a1,，其中那串ID是7007的ID。当你清空了一个master的hashslot时，redis cluster就会自动将其slave挂载到其他master上去，这个时候就只要删除掉master就可以了。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[命令模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F29%2F%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ 在软件开发中有很多类似这样的一个场景：一个按钮，它可能是一个“关闭窗口”请求的发送者，而按钮点击事件处理类则是该请求的接收者。为了降低系统的耦合度，将请求的发送者和接收者解耦，可以使用一种被称之为命令模式的设计模式来设计系统。在命令模式中，发送者与接收者之间引入了新的命令对象，将发送者的请求封装在命令模式中，再通过命令对象来调用接收者的方法。 ​ 在软件开发中，经常需要向某些对象发送请求（调用其中的某个或某些方法），但是并不知道请求的接收者是谁，也不知道被请求的操作是哪个，此时，希望能以一种松耦合的方式来设计软件，使得请求发送者与请求接收者能够消除彼此之间的耦合，让对象之间的调用关系更加灵活。 ​ 命令模式可以将请求发送者和接收者完全解耦，发送者与接收者之间没有直接引用关系，发送请求的对象只需要知道如何发送请求，而不必知道如何完成请求。 命令模式定义​ 将一个请求封装为一个对象，从而可用不同的请求对客户进行参数化；对请求排队或者记录日志，以及支持可撤销的操作。命令模式是一种对象行为型模式，又称为动作模式或事物模式。 命令模式结构图​ 命令模式的核心在于引入了命令类，通过命令类来降低发送者和接收者的耦合度，请求发送者只需要指定一个命令对象，再通过命令对象来调动请求接收者的处理方法，其结果如下： ​ 由上图可知命令模式包含以下四个角色： Command（抽象命令类）：抽象命令类一般是一个抽象类或接口，在其中声明了用于执行请求execute()等方法，通过这些方法可以调用请求接收者的相关操作。 ConcreteCommand（具体命令类）：具体命令类是抽象命令类的子类，实现了在抽象命令类中声明的方法，它对应具体的接收者对象，将接收者对象的动作绑定在其中。在实现execute()方法时，将调用接收者对象的相关操作（Action）. Invoker（调用者）：调用者即请求发送者，它通过命令对象来执行请求。一个调用者并不需要在设计时确定其接收者，因此它只与抽象命令类之间存在关联关系。在程序运行时可以将一个具体命令对象注入其中，再调用具体命令对象的execute()方法，从而实现间接调用请求接收者的相关操作。 Receiver（接收者）：接收者执行与请求相关的操作，它具体实现对请求的业务处理。 具体案例​ 某公司开发人员为公司内部OA系统开发了一个桌面版应用程序，该应用程序为客户提供了一系列自定义功能键，用户可以通过这些功能键来实现一些快捷操作。产品人员通过分析，发现不同的用户可能有不同的使用习惯，在设置功能键的时候每个人都有自己的喜好，例如有人喜欢将第一个功能键设置为“打开帮助文档”，有的人则喜欢将该功能键设置为“最小化至托盘”。为了让用户能够灵活地进行功能键的设置,开发人员提供了一个“功能键设置”窗口,如图所示： ​ 通过这个窗口界面，用户可以将功能键和相应功能绑定在一起，还可以根据需要来修改功能键的设置，而且系统未来还可能增加一些新的功能或功能键。 ​ 该软件使用命令模式设计，结构图如下所示： ​ 相关代码已上传到github上。 命令队列的实现​ 有时候需要将多个请求排队，当一个请求发送者发送一个请求时，不止一个请求接收者产生响应，这些请求接收者将逐个执行业务方法，完成对请求的处理。此时，可以通过命令队列来实现。 ​ 命令队列的实现方法有多种形式，其中最常用、灵活性最好的一种方式是增加一个CommandQueue类，由该类来负责存储多个命令对象，而不同的命令对象可以对应不同的请求接收者。CommandQueue类的典型代码如下： 123456789101112131415161718192021222324package com.command;import java.util.ArrayList;public class CommandQueue &#123; //定义一个ArrayList来存储命令队列 private ArrayList&lt;Command&gt; commands = new ArrayList&lt;Command&gt;(); public void addCommand(Command command) &#123; commands.add(command); &#125; public void removeCommand(Command command) &#123; commands.remove(command); &#125; //循环调用每一个命令对象的execute()方法 public void execute() &#123; commands.stream().forEach(command -&gt; &#123; command.execute(); &#125;); &#125;&#125; ​ 在增加了命令队列类CommandQueue以后，请求发送者类Invoker将针对CommandQueue编程，代码如下： 123456789101112131415161718192021package com.command;public class Invoker &#123; //维持一个CommandQueue对象的引用 private CommandQueue commandQueue; public Invoker(CommandQueue commandQueue) &#123; this.commandQueue = commandQueue; &#125; //设值注入 public void setCommandQueue(CommandQueue commandQueue) &#123; this.commandQueue = commandQueue; &#125; //调用CommandQueue类的execute()方法 public void call() &#123; commandQueue.execute(); &#125;&#125; ​ 命令队列与批处理有点类似。批处理，意思就是可以对一组对象（命令）进行批量处理，当一个发送者发送请求后，将有一系列接收者对请求作出相应，命令对象可以用于设计批处理应用程序，如果请求接收者的接受次序没有严格的先后次序，还可以使用多线程技术来并发调用命令对象的execute()方法，从而提高程序的执行效率。 撤掉操作的实现​ 在命令模式中，可以通过调用一个命令对象的execute()方法来实现对请求的处理，如果需要撤销请求，可以通过在命令类中增加一个逆向操作来实现。此外，还可以通过保存对象的历史状态来实现撤销。 案例​ 某公司欲开发一个简易计算器，该计算器可以实现简单的数学运算，还可以对运算实施撤销操作和恢复操作。 ​ 本例完整代码已上传到github上 请求日志​ 请求日志就是将请求的历史记录保存下来，通常以日志文件的形式永久存储在计算机系统中。在实现请求日志时，可以将命令对象通过序列化写到日志文件中，此时命令类必须实现java.io.Serializable接口。 案例​ 某公司开发了一个网站配置文件管理工具，可以通过一个可视化界面对网站配置文件进行增删改等操作，该工具使用命令模式进行设计，结构如下所示。现在改公司开发人员希望对配置文件的操作请求记录在日志文件中，如果网站重新部署，主需要执行保存在日志文件中的命令对象即可修改配置文件。 ​ 该案例的相关代码已上传到github上。 命令模式主要优缺点主要优点 降低系统的耦合度。由于请求者与接收者之间不存在直接引用，因此请求者与接收者之间实现完全解耦，相同的请求者可以对应不同的接收者，同样，相同的接收者也可以供不同的请求者使用，两者之间具有良好的独立性。 新的命令可以很容易地加入到系统中。由于增加新的具体命令类不会影响到其他类，因此增加新的具体命令类很容易，无须修改原有系统源代码甚至客户类代码，满足开闭原则。 可以比较容易地设计一个命令队列或宏命令。 为请求的撤销和恢复操作提供了一种设计和实现方案。 主要缺点​ 主要缺点是：使用命令模式可能会导致某些系统有过多的具体命令类。因为针对每一个请求接收者的调用操作都需要设计一个具体命令类，因此在某些系统中可能需要提供大量的具体命令类，这将影响命令模式的使用。 命令模式使用场景 系统需要将请求调用者和请求接收者解耦，使得调用者和接收者不直接交互。请求调用者无须知道接收者的存在，也无须知道接收者是谁，接收者也无须关心何时被调用。 系统需要在不同的时间指定请求、将请求排队和执行请求。一个命令对象和请求的初始调用者可以有不同的生命期。即，最初的请求发出者可能已经不在了，而命令对象本身仍然是活动的，可以通过该命令对象去调用请求接收者，而无须关系请求调用者的存在性，可以通过请求日志文件等机制来具体实现。 系统需要支持命令的撤销操作和恢复操作。 系统需要将一组操作组合在一起形成宏命令。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F25%2F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ 在软件开发中，常常会遇到这种情况：实现某个功能有多条途径，每一条途径对应一种算法，此时可以使用一种设计模式来实现灵活地选择解决途径，也能够方便地增加新的解决途径。那就是策略模式。 ​ 在策略模式中，可以定义一些独立的类来封装不同的算法，每一个类封装一种具体的算法。在这里，每一个封装算法的类都可以称之为一种策略，为了保证这些策略在使用时具有一致性，一般会提供一个抽象的策略来做规则的定义，而每种算法则对应一个具体策略类。 ​ 策略模式的主要目的是将算法的定义与使用分开，也就是将算法的行为和环境分开，将算法的定义放在专门的策略类中，每一个策略类封装了一种实现算法，使用算法的环境类针对抽象策略类进行编程，符合依赖倒转原则。在出现新的算法时，只需要增加一个新的实现了抽象策略类的具体策略类即可。 策略模式定义​ 定义了一系列算法类，将每一个算法封装起来，并让他们可以互相替换。策略模式让算法独立于使用它的客户而变化，也称为政策模式。策略模式是一种对象行为型模式。 策略模式结构图 ​ 由结构图可以看到包含以下3个角色： Context（环境类）：环境类是使用算法的角色，它在解决某个问题（即实现某个方法）时可以采用多种策略。在环境类中维持一个对抽象策略类的引用实例，用于定义所采用的策略。 Strategy（抽象类）：它为所支持的算法声明了抽象方法，是所有策略类的父类，它可以是抽象类或具体类，也可以是接口。环境类通过抽象策略中声明的方法在运行时调用具体策略类中实现的算法。 ConcreteStrategy（具体策略类）：它实现了在抽象策略类中声明的算法，在运行时，具体策略类将覆盖在环境类中定义的抽象策略类对象，使用一种具体的算法实现某个业务处理。 策略模式主要优缺点主要优点 策略模式提供了对开闭原则的完美支持，用户可以在不修改原有系统的基础上选择算法或行为，也可以灵活地增加新的算法或行为。 策略模式提供了管理相关的算法族的办法，策略类的等级结构定义了一个算法或行为族，恰当使用继承可以把公共的代码移到抽象策略类中，从而避免重复的代码。 策略模式提供了一种可以替换继承关系的办法。如果不使用策略模式，那么使用算法的环境类就可能会有一些子类，每个子类提供一种不同的算法。但是，这样一来算法的使用就和算法本身混在一起，不符合单一职责原则，决定使用哪一种算法的逻辑和该算法本身混合在一起，从而不可能再独立演化；而且使用继承无法实现算法或行为在程序运行时的动态切换。 使用策略模式可以避免多重条件选择语句。多重条件选择语句不易维护，它把采取哪一种算法或行为的逻辑与算法或行为本身的实现逻辑混合在一起，将他们全部硬编码在一个庞大的多重条件选择语句中，比直接集成环境类的办法还要原始和落后。 策略模式提供了一种算法的复用机制，由于将算法单独提取出来封装在策略类中，因此不同的环境类可以方便地复用这些策略类。 主要缺点 客户端必须知道所有的策略类，并且自行决定使用哪一个策略类。这就意味着客户端必要理解这些算法的区别，以便实时选择恰当的算法。换言之，策略模式只适用于客户端知道所有的算法或行为的情况。 策略模式将造成系统产生很多具体策略类，任何细小的变化都将导致系统要增加一个新的具体策略类。 无法同时在客户端使用多个策略类，也就是说，在使用策略模式时，客户端每次只能使用一个策略类，不支持使用一个策略类完成部分功能后再使用另一个策略类来完成剩余功能的情况。 策略模式适用场景​ 在以下情况下可以考虑使用策略模式： 一个系统需要动态地在几种算法中选择一种，那么可以将这些算法封装到一个个的具体算法类中，而这些算法类都是一个抽象算法类的子类。换言之，这些具体算法类均有统一的接口，根据里氏代换原则和面向对象的多态性，客户端可以选择使用任何一个具体算法类，并且只要维持一个数据类型是抽象算法类的对象。 一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重条件选择语句来实现。此时，使用策略模式，把这些行为转移到相应的具体策略类里面，就可以避免使用难以维护的多重条件选择语句。 不希望客户端知道复制的、与算法相关的数据结构，在具体策略类中封装算法与相关的数据结构，可以提高算法的保密性与安全性。 具体事例案例1​ Sunny软件公司为某电影院开发了一套影院售票系统，在改系统中需要为不同类型的用户提供不同的电影票打折方式，具体打折方案如下： 学生凭学生证可以享受8折优惠。 年龄在10周岁及以下的儿童可享受每张票减免10元的优惠（原始票价需大于等于20元） 影院VIP用户除享受票价半价优惠外还可以积累积分，积分累计到一定额度可以兑换电影院赠送的奖品。 ​ 改系统在将来可能还需要个根据需要引入新的打折方式。 传统的实现方案大概会如下： 123456789101112131415161718192021222324public double calculate() &#123; //学生票折后票价计算 if(this.type.equalsIgnoreCase("student")) &#123; System.out.println("学生票： "); return this.price * 0.8; &#125; //儿童票折后票价计算 else if(this.type.equalsIgnoreCase("children") &amp;&amp; this.price &gt;= 20) &#123; System.out.println("儿童票："); return this.price - 10; &#125; //VIP票折价后票价计算 else if(this.type.equalsIgnoreCase("vip")) &#123; System.out.println("VIP票："); System.out.println("增加积分！"); return this.price * 0.5; &#125; else &#123; return this.price; &#125; &#125; ​ 使用策略模式实现的代码已上传至github上。 案例2​ 使用策略模式和自定义注解去掉大量的if-else https://mp.weixin.qq.com/s/sa_MMAzYg6jpy9s_rtvcCQ]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产环境中redis的数据备份和灾难恢复策略]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F22%2F%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%ADredis%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E5%92%8C%E7%81%BE%E9%9A%BE%E6%81%A2%E5%A4%8D%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[本节思维导图 ![生产环境中的数据 备份和灾难恢复](生产环境中redis的数据备份和灾难恢复策略/生产环境中的数据 备份和灾难恢复.png) ​ 我们生产环境中redis的数据备份和灾难恢复策略简单地说就是：开启AOF机制，并用RDB做冷备。 数据备份方案​ 具体的数据备份方案如下： 写crontab定时调度脚本去做数据备份。 每小时都备份一份rdb，可以copy到一个目录中去，并且只保留最近48小时的备份。 每天都保留一份当日的rdb备份到一个目录中去，仅仅保留最近一个月的备份。 每次copy备份的时候，把最旧的备份删掉。 每天晚上将当前服务器上所有的数据备份，发送一份到远程的云服务上去。 ​ 首先先创建一个目录，/usr/local/redis，然后在redis的目录中创建copy文件夹，用来存储复制快照文件的脚本。然后在redis目录中创建snapshotting文件夹，用来存储备份的rdb快照。 ​ 执行vi redis_rdb_copy_hourly.sh，编写每小时复制一份rdb的shell脚本。 123456789#!/bin/sh cur_date=`date +%Y%m%d%k`rm -rf /usr/local/redis/snapshotting/$cur_datemkdir /usr/local/redis/snapshotting/$cur_datecp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_datedel_date=`date -d -48hour +%Y%m%d%k`rm -rf /usr/local/redis/snapshotting/$del_date ​ 执行vi redis_rdb_copy_daily.sh，编写每天复制一份rdb的shell脚本。 123456789#!/bin/sh cur_date=`date +%Y%m%d`rm -rf /usr/local/redis/snapshotting/$cur_datemkdir /usr/local/redis/snapshotting/$cur_datecp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_datedel_date=`date -d -1month +%Y%m%d`rm -rf /usr/local/redis/snapshotting/$del_date ​ 上面cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date中的/var/redis/6379/dump.rdb是redis生成的快照文件的存储地址，可以根据具体情况进行修改。 ​ 最后再执行crontab -e新建调度任务，命令如下： 120 * * * * sh /usr/local/redis/copy/redis_rdb_copy_hourly.sh0 0 * * * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh ​ 然后再每天一次将所有的数据上传一次到远程的云服务器上去，这样一个数据备份方案就算完成了。 数据恢复方案 如果是redis进程挂掉了，那么重启redis进程即可，直接基于AOF日志文件恢复数据。 如果是redis进程所在机器宕机了，那么重启机器后，尝试重启redis进程，尝试直接基于AOF日志文件进行数据恢复。如果AOF没有破损，那么久直接基于AOF恢复，如果AOF文件损坏，那么用redis-check-aof fix修复日志文件。 如果redis当前最新的AOF文件和RDB文件出现了丢失，那么可以尝试基于该机器上当前的某个最新的RDB数据副本进行数据恢复。具体操作步骤为：停掉redis，关闭AOF，拷贝AOF备份，重启redis，确认数据恢复，直接在命令行热修改redis配置，即在redis-cli中执行config set appendonly yes打开AOF。这个时候redis就会将内存中的数据对应的日志，写入AOF文件中，此时AOF和RDB两份数据文件的数据就同步了。用redis config set热修改配置参数，可能配置文件中的实际参数没有被持久化的修改，需要再停止redis，手动修改配置文件，打开AOF，然后再重启redis。 如果当前机器上的所有RDB文件全部损坏，那么从远程的云服务上拉取最新的RDB快照来恢复数据。 如果是发现有重大的数据错误，比如某个小时上线的程序一下子将数据全部污染了，数据全错了，那么可以选择某个更早的时间点，对数据进行恢复 举个例子，12点上线了代码，发现代码有bug，导致代码生成的所有的缓存数据，写入redis，全部错了 找到一份11点的rdb的冷备，然后按照上面的步骤，去恢复到11点的数据，就可以了。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM中的一些参数介绍]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F16%2FJVM%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[JVM配置常用参数堆参数 参数 描述 -Xms 设置JVM启动时堆内存的初始化大小 -Xmx 设置堆内存最大值 -Xmn 设置年轻代的空间大小，剩下的为老年代的空间大小 -XX:PermGen 设置永久代内存的初始化大小（JDK1.8开始废弃了永久代） -XX:MaxPermGen 设置永久代的最大值 -XX:SurvivorRatio 设置Eden区和Survivor区的空间比例：Eden/S0 = Eden/S1 默认为8 -XX:NewRatio 设置老年代与年轻代的比例大小，默认值为2 回收器参数 参数 描述 -XX:+UseSerialGC 串行，Young区和Old区都使用串行，使用复制算法回收，逻辑简单高效，无线程切换开销 -XX:+UseParallelGC 并行，Young区：使用Parallel scavenge回收算法，会产生多个线程并行回收。通过-XX:ParallelGCThreads=n参数指定有线程数，默认是CPU核数；Old区：单线程 -XX:+UseParallelOldGC 并行，和UseParallelGCC一样，Young区和Old区的垃圾回收时都使用多线程手机 -XX:+UseConcMarkSweepGC 并发，短暂停顿的并发收集。Young区：可以使用普通的或者parallel垃圾回收算法，由参数 -XX:+UseParNewGC来控制；Old区：只能使用Concurrent Mark Sweep -XX:+UseG1GC 并行的、并发的和增量式压缩短暂停顿的垃圾收集器。不区分Young区和Old区空间。它把堆空间划分为多个大小相等的区域。当进行垃圾收集时，它会优先收集存活对象较少的区域，因此叫“Garbage First” ​ 如上表所示，目前主要有串行、并行和并发三种。对于大内存的应用而言，串行的性能太低，因此使用到的主要是并行和并发两种。并行和并发GC的策略通过UseParallelGCC和UseCon从MarkSweepGC来指定，还有一些细节的配置参数用来配置策略的执行。例如：XX:ParallelGCThreads、XX:CMSInitiatingOccupancyFraction等。通常：Young区对象回收只可选择并行（耗时间），Old区选择并发（耗CPU）。 项目中常用配置 参数设置 描述 -Xms4800m 初始化堆空间大小 -Xmx4800m 最大堆空间大小 -Xmn1800m 年轻代的空间大小 -Xss512k 设置线程栈空间大小 -XX:PermSize=256m 永久区空间大小（jdk1.8开始废弃了永久代） -XX:MaxPermSize=256m 最大永久区空间大小 -XX:+UseStringCache 默认开启，启用缓存常用的字符串 -XX:+UseConcMarkSewwpGC 老年代使用CMS收集器 -XX:UseParNewGC 新生代使用并行收集器 -XX:ParallelGCThreads=4 并行线程数量4 -XX:+CMSClassUnloadingEnabled 允许对类的元数据进行清理 XX:+DisableExplicitGC 禁止显示的GC -XX:+UseCMSInitiatingOccupancyOnly 表示只有达到阈值之后才进行CMS回收 -XX:CMSInitiatingOccupancyFraction=68 设置CMS在老年代回收的阈值为68% -verbose:gc 输出虚拟机GC详情 -XX:+PrintGCDetails 打印GC详情日志 -XX:+PrintGCDataStamps 打印GC的耗时 -XX:+PrintTenuringDistribution 打印Tenuring年龄信息 -XX:+HeapDumpOnOutOfMemoryError 当抛出OOM时进行HeapDump -XX:HeapDumpPath=/home/admin/logs 指定HeapDump的文件路径或目录 常用组合 Young Old JVM Options Serial Serial -XX:+UseSerialGC Parallel scavenge Parallel Old/Serial -XX:+UseParallelGC-XX:+UseParallelOldGC Serial/Parallel scavenge CMS -XX:+UseParNewGC-XX:+UseConcMarkSweepGC G1 -XX:+UseG1GC 常用GC调优策略GC调优原则​ 在调优之前，我们需要记住下面的原则： 多数的Java应用不需要在服务器上进行GC优化。 多数导致GC问题的Java应用，都不是因为我们参数设置错误，而是代码问题。 在应用上线之前，先考虑将机器的JVM参数设置到最优（最适合）。 减少创建对象的数量。 减少使用全局变量和大对象。 GC优化是到最后不得已才 采用的手段。 在实际使用中，分析GC情况优化代码比优化GC参数要多得多。 GC调优目的 将转移到老年代的对象数量降低到最小。 减少GC的执行时间 GC调优策略 策略1：将新对象预留在新生代，由于Full GC的成本远高于Minor GC，因此尽可能将对象分配在新生代是明智的做法，实际项目中根据GC日志分析新生代空间大小分配是否合理，适当通过“-Xmn”命令调节新生代大小，最低限度降低新对象直接进入老年代的情况。 策略2：大对象进入老年代，虽然在大部分情况下，将对象分配在新生代是合理的。但是对于大对象这种做法却值得商榷，大对象如果首次在新生代分配可能会出现空间不足导致很多年龄不够的小对象被分配到老年代，破坏新生代的对象结构，可能会出现频繁的full gc。因此，对于大对象，可以设置直接进入老年代（当然短命的大对象对于垃圾回收来说就是噩梦）。-XX:PretenureSizeThreshold可以设置直接进入老年代的对象大小。 策略3：合理设置进入老年代对象的年龄，-XX:MaxTenuingThreshold设置对象进入老年代的年龄大小，减少老年代的内存占用，降低full GC发送的频率。 策略4：设置稳定的堆大小，堆打下设置有两个参数：-Xms初始化堆大小，-Xms最大堆大小。 策略5：如果满足下面的指标，则一般不需要进行GC优化： MinorGC执行时间不到50ms MinorGC执行不频繁，约10秒一次 Full GC执行时间不到1s Full GC执行频率不算频繁，不低于10分钟1次。 参考资料Java应用如何调优]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单讲一下分库分表]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F10%2F%E7%AE%80%E5%8D%95%E8%AE%B2%E4%B8%80%E4%B8%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[分库分表​ 分库分表是两回事，可能是光分库不分表，也可能是光分表不分库，都有可能。 分表​ 如果你单表都几千万数据了，单表数据量太大，会极大影响你的Sql执行的性能，到了后面sql可能就跑的很慢了。一般来说，单表到了几百万的时候，性能就会相对差一些，你就得分表了。 ​ 分表，就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户ID来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就可以了。这样可以控制每个表的数据量在可控的方范围内，比如每个表就固定在200万以内。 分库​ 分库，就是一般而言我们一个库，最多支撑到2000并发，就一定要扩容了，而且一个健康的单库并发值最好保持在每秒1000左右，不要太大。可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。 分库分表前 分库分表后 并发支撑情况 MySQL单机部署，扛不住高并发 MySQL从单机到多机，能承受的并发增加了多倍 磁盘使用情况 MySQL单机磁盘容量几乎撑满 拆分为多个库，数据库服务器磁盘使用率大大降低 SQL执行性能 单表数据量太大，SQL越跑越慢 单表数据库量减少，SQL执行效率明显提升 分库分表的中间件​ 比较常见的分库分表的中间件包括： Cobar TDDL Atlas Sharding-jdbc Mycat ​ 目前市场上比较主流的就是sharding-jdbc和Mycat，这两个都可以考虑去使用。Sharding-jdbc这种属于Client层方案，优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合Sharding-jdbc的依赖。Mycat属于proxy层方案，缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间间那里处理即可。 ​ 通常来说，这两个方案其实都可以选用，但是大佬建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。 如何对数据库进行水平拆分和垂直拆分水平拆分​ 水平拆分，就是把一个表的数据弄个多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的表里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。 垂直拆分​ 垂直拆分，就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。 ​ 还有表层面的拆分，就是分表，将一个表变成N个表，就是让每个表的数据量控制在一定范围内，保证SQL的性能。否则单表的数据量越大，SQL性能就越差。 ​ 无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，中间件可以根据你指定的某个字段值，比如说 userid，自动路由到对应的库上去，然后再自动路由到对应的表里去。 ​ 你就得考虑一下，你的项目里该如何分库分表？一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。 ​ 有两种分库分表的方式： 按照range来分，就是每个库一段连续的数据，这个一般是按照，例如时间范围来的。但是这种一般较少使用，因为很容易产生热点问题，大量的流量都打在最新的数据上了 按照某个子段hash一下均匀分散，这个较为常用。 ​ range来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。 ​ hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。]]></content>
      <categories>
        <category>分布式</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[保证缓存与数据库双写的一致性]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F08%2F%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%2F</url>
    <content type="text"><![CDATA[本节思维导图 Cache Aside Pattern​ 最经典的缓存+ 数据库读写的模式，就是这个Cache Aside Pattern 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回请求。 更新的时候，先更新数据库，然后再删除缓存。 ​ 至于为什么是删除缓存，而不是更新缓存。原因在于在复杂的缓存场景，缓存不单单是数据库中直接拉取出来的值。比如更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据进行运算，才能计算出缓存最新的值的。 ​ 而且更新缓存的代价有时候是很高的。对于复杂的缓存数据计算场景，如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新，但这个数据有可能只需要被访问一次呢？例如一个缓存涉及的表的字段，在一分钟内就修改了一百次，而缓存也更新了一百次，但是这个缓存在一分钟内只被读取一次，有大量的冷数据。如果只是删除缓存的话，那么在1分钟内，这个缓存也就重新计算一次，大幅度降低开销。用到缓存才去算缓存。 最初级的缓存不一致问题及解决方案​ 如果先更新数据库，在删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。 解决思路​ 先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存是空的，那么数据不会不一致。因为读的时候缓存没有了，所以读了数据库中的旧数据，然后更新到缓存中。 高并发场景下数据不一致问题分析​ 数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改，一个请求过来，先去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。这样就会发生数据库与缓存的数据不一致了。 什么场景下会发生上述情况​ 只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。如果并发量很低的话，特别是读并发很低，每天访问量就一万，那么很少的情况才会出现上述情况。如果每天是上亿的流量，每秒并发读是几万，每秒只要有数据更新的情况，就可坑出现上述的数据库和缓存不一致的情况。 解决方案​ 更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据 + 更新缓存的操作，根据唯一标识路由之后，也发到同一个jvm内部队列中。 ​ 一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没有完成更新。此时如果一个读请求过来，没有读到缓存，可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。 ​ 这里有一个可以优化的地方。一个队列中，多个更新缓存请求串在一起是没意义的。可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新缓存的请求操作进去，直接等前面的更新操作请求完成即可。 ​ 等那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库读取最新的值，然后写入缓存中。 ​ 如果请求还在等待时间范围内，不断轮询，发现可以取到值了，那么久直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。 存在的问题 读请求长时阻塞 由于读请求进行了非常轻度的异步化，所以要注意读超时的问题，每个读请求必须在超时时间范围内返回。 ​ 解决方案，或者最大的风险点在于可能数据更新很频繁。导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库。因此务必通过一些模拟真实的测试，看看数据更新的频率是怎样的。 ​ 另外，因为一个队列中，可能会积压对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务。每个服务分摊一些数据的更新操作。如果一个内存队列路积压100个商品的库存修改操作，每个库存修改操作需要耗费10ms去完成，那么最后一个商品的读请求，可能等待10 * 100ms = 1s，才能得到数据，这个时候就导致读请求的长时阻塞。 读请求并发量过大 ​ 这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时hang在服务上，看服务能不能抗的住，需要多少机器才能抗住最大的极限情况的峰值。 ​ 但是因为不是所有的数据都在同一时间更新，缓存也不会再同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。 多服务实例部署的请求路由 ​ 可能这个服务部署了多个实例，那么必须保证，执行数据更新操作，以及执行缓存更新操作的请求，都通过Nginx服务器路由到相同的服务实例上。 ​ 例如对同一个商品的读写请求，全部路由到同一台服务器上。可以自己去做服务间的按照某个请求参数的hash路由，也可以用Nginx的hash路由功能等。 热点商品的路由问题，导致请求的倾斜 ​ 如果某个商品的读写请求特别高，全部打到相同机器相同的队列里，可能会造成某台机器的压力过大。就是说，因为只有在商品更新的时候才会清空缓存，然后才会导致读写并发。所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响不是特别大，但是的确可能某些机器的负载会高一些。 总结​ 一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说系统不是严格要求“缓存 + 数据库”必须保持一致性的话，最好不要做“读请求和写请求串行化”，串到一个内存队列里去。 ​ 串行化可以保证一定不会出现不一致的情况，但是它会导致系统的吞吐量大幅度降低。]]></content>
      <categories>
        <category>分布式</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis集群]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F04%2FRedis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[本节思维导图 ![Redis Cluster](Redis集群/Redis Cluster.png) ​ Redis cluster，主要是针对海量数据 + 高并发 + 高可用的场景。Redis cluster支撑N个redis master node，每个master node都可以挂载多个slave node。这样整个redis就可以横向扩容了。如果要支撑更大数据量的缓存，那就横向扩容更多的master节点。 Redis cluster介绍 自动将数据进行分片，每个master上放一部分数据 提供内置的高可用支持，部分master不可用时，还是可以继续工作的 ​ 在redis cluster架构下，每个redis要开放两个端口号，比如一个是6379，另一个就是加1W的端口号，比如16379. ​ 16379端口号是用来进行节点间通信的，也就是cluster bus的东西。cluster bus的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus使用一种二进制的协议，gossip协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。 节点间的内部通信机制基本通信原理​ 集群元数据的维护有两种方式：集中式。Gossip协议。redis cluster节点间采用gossip协议进行通信。 ​ 集中式是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于ZooKeeper（分布式协调的中间件）对所有元数据进行存储维护。 ​ redis维护集群元数据采用另一个方式，gossip协议，所有节点都持有一份元数据，不同节点如果出现了元数据的变更，就不断将元数据发送给其他的节点，让其他节点也进行元数据的并更。 ​ 集中式的好处在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其他节点读取的时候就可以感知到；不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。 ​ gossip好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆续打到所有节点上去更新，降低了压力；缺点是元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。 1000端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+ 10000。每个节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几个节点接收到ping之后返回pong。 交换的信息：信息包括故障信息，节点的增加和删除，hash slot信息等等。 gossip协议​ gossip协议包含多种消息，包含ping、pong、meet、fail等等。 meet：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信。 1redis-trib.rb add-node 其实内部就是发送了一个gossip meet消息给新加入的节点，通知那个节点去加入我们的集群。 ping：每个节点都会频繁给其它节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据。 pong：返回ping和meet，包含自己的状态和其它信息，也用于消息广播和更新。 fail：某个节点判断另一个节点fail之后，就发送fail给其它节点，通知其它节点某个节点宕机了。 ping消息深入​ ping时要携带一些元数据，如果很频繁，可能会加重网络负担。 ​ 每个节点每秒会执行10次ping，每次会选择5个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了cluster_node_timeout / 2，那么立即发送ping，避免数据交换延时过长，落后的时间过长。例如，两个节点之间都10分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以cluster_node_timeout可以调节，如果调的比较大，那么会降低ping的频率。 ​ 每次ping，都会带上自己节点的信息，还有就是带上1/10其它节点的信息，发送出去，进行交换。至少包含3个其它节点的信息，最多包含总结点减2个其它节点的信息。 分布式寻址算法 hash算法 一致性hash算法（自动缓存迁移） + 虚拟节点（自动负载均衡） redis cluster的hash slot算法 hash算法​ 来了一个key，首先计算hash值，然后对节点数取模。然后打在不同的master节点上，一旦某一个master节点宕机，所有请求过来，都会基于最新的master节点数去取模，尝试去取数据。这会导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库。 一致性hash算法​ 一致性hash算法将整个hash值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织。下一步将各个master节点（使用服务器的ip或主机名）进行hash。这样就能确定每个节点在其哈希环上的位置。 ​ 来了一个key，首先计算hash值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，遇到的第一个master节点就是可以所在位置。 ​ 在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其他不收影响，增加一个节点也同理。 ​ 但是如果一致性哈希算法在节点太少是，容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性hash算法引入了虚拟节点机制，即对每一个节点计算多个hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。 redis cluster的hash slot算法​ redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot。 ​ redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot。hash slot让node的增加和移除都很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去。移动hash slot的成本是非常低的。客户端的API，可以对指定的数据，让他们走同一个hash slot，同时hash tag来实现。 ​ 任何一台机器宕机，redis的寻址都不受影响。因为key找的是hash slot，不是机器。 ![hash slot](Redis集群/hash slot.png) Redis Cluster的高可用与主备切换原理​ redis cluster的高可用的原理，几乎跟哨兵是类似的。 判断节点宕机​ 如果一个节点认为另一个节点宕机，那么就是pfail，主观宕机。如果多个节点都认为一个节点宕机了，那么就是fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown。 ​ 在cluster-node-timeout内，某个节点一直没有返回pong，那么就会认为fail。 ​ 如果一个节点认为某个节点fail，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，那么就会变成fail. 从节点过滤​ 对宕机的master node，从其所有的slave node中，选择一个切换成master node。 ​ 检查每个slave node与master node断开连接的时间，如果超过了cluster-node-timeout * cluster-salve-validity-factor，那么就没有资格切换成master。 从节点选举​ 每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。 ​ 所有的master node开始slave选举投票，给要进行选举的slave进行投票，如果大部分master node (N / 2 + 1)都投票给某个从节点，那么选举通过，那个从节点 可以切换成master。 ​ 从节点执行主备切换，从节点切换为主节点。 与哨兵比较​ 整个流程跟哨兵相比，非常类似。所以redis cluster相当于直接集成了replication和sentinel的功能。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F01%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ Redis持久化的意义在于数据备份和灾难恢复。Redis如果仅仅只是将数据缓存在内存里面，如果Redis宕机了再重启，内存里的数据就全部弄丢了。所以得用Redis的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行持久化。如果Redis宕机重启，自动从磁盘上加载之前持久化的一些数据即可，也许会丢失少许数据，但是至少不会将所有数据都弄丢。 Redis持久化的两种方式 RDB：RDB持久化机制，是对Redis中的数据进行周期性的持久化。 AOF：AOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在Redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集。 ​ 通过RDB或AOF，都可以将Redis内存中的数据持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如阿里云等云服务等。 ​ 如果同时使用RDB和AOF两种持久化机制，那么redis重启的时候，会使用AOF来重构新数据，因为AOF中的数据更加完整。 RDB优缺点 RDB会生成多个数据文件，每个数据文件都代表某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完备的数据文件发送到一些远程的安全存储上去，比如国内的阿里云的ODPS分布式存储上，以预定好的备份策略来定期备份redis中的数据。 RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可。 相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速。 如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，一般都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据。 RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。 AOF优缺点 AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。 AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使尾部破损，也很容易修复。 AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewritelog的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后日志文件ready的时候，再交换新老日志文件即可。 AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急操作。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据。 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大。 AOF开启后，支持的QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然每秒一次fsync性能也还是很高的。但如果实时写入，那么QPS会大降，redis性能会大大降低。 以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据。因此，类似AOF这种较为复杂的基于命令/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照的方式，更加脆弱一些，容易有bug。不过AOF就是为了避免 rewrite 过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge，而是基于当时内存中的数据进行指令的重新构建，这样健壮性好很多。 补充：rewrite类似于普通数据库管理系统日志恢复点，当AOF文件随着写命令的运行膨胀时，当文件大小触碰到临界时，rewrite会被运行。 rewrite会像replication一样，fork出一个子进程，创建一个临时文件，遍历数据库，将每个key、value对输出到临时文件。输出格式就是Redis的命令，但是为了减小文件大小，会将多个key、value对集合起来用一条命令表达。在rewrite期间的写操作会保存在内存的rewrite buffer中，rewrite成功后这些操作也会复制到临时文件中，在最后临时文件会代替AOF文件。 RDB和AOF到底该如何选择 不要仅仅使用RDB，因为那样会导致你丢失很多数据。 也不要仅仅使用AOF，因为那样有两个问题：第一，通过AOF做冷备，没有RDB做冷备来得恢复速度更快；第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug； redis支持同时开启两种持久化方式，我们可以综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择，用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复。 如何配置RDB持久化的配置​ 打开redis的配置文件，搜索save，如图所示： ​ save 60 10000表示，每隔60秒，如果有超过10000个key发生了变化，那么就生成一个新的dump.rdb文件，就是当前redis内存中完整的数据快照，这个操作也被称为snapshotting。save可以设置多个，就是多个snapshotting检查点，每到一个检查点，就会去check一下，是否有指定的key数量发生了变更，如果有，就生成一个新的dump。 ​ 也可以手动调用save或者bgsave命令，同步或异步执行rdb快照生成。 ​ 如果你通过redis-cli SHUTDOWN的方式去停掉redis，这其实是一种安全退出的模式，redis在退出的时候会将内存中的数据立即生成一份完整的快照。如果用kill -9粗暴杀死redis进程，则相当于redis故障异常退出，不会生成dump快照文件。 AOF持久化的配置​ AOF持久化默认是关闭的，默认是打开RDB持久化。要开启AOF持久化配置，在redis配置文件中搜索appendonly，如下所示，将no改为yes即可。打开AOF持久化机制之后，redis每收到一条写指令，就会写入日志文件中。会先写入os cache，然后每隔一定时间再fsync一下。 ​ AOF的fsync总共有三种策略： appendfsync always：每次写入一条数据，立即将这个数据对应的写日志fsync到磁盘上去，性能很差，吞吐量很低，但确保了redis里的数据一条不丢。 appendfsync everysec：每秒执行一次fsync。这个最常用，生产环境一般这么配置，性能很高，QPS可以上万。 appendfsync no：不主动执行fsync，由操作系统自行判断。不可控。 AOF rewrite的配置​ 这里主要讲两个rewrite的配置 12auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 举个例子，比如上一次AOF rewrite之后，日志大小是128MB。此时就会接着128MB继续写AOF日志，如果发现增长的比例已经超过了之前的100%，256MB，就可能会去触发一次rewrite。但是此时还要去跟min-size， 64mb去比较，256 &gt; 64时，才会触发rewrite。 AOF破损文件的修复如果redis在append数据到AOF文件时，机器宕机了，可能会导致AOF文件破损 用redis-check-aof –fix命令来修复破损的AOF文件]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计核心接口的防重幂等性]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A0%B8%E5%BF%83%E6%8E%A5%E5%8F%A3%E7%9A%84%E9%98%B2%E9%87%8D%E5%B9%82%E7%AD%89%E6%80%A7%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 在分布式系统中，一般都会有重试机制。但重复机制又有一定几率出现重复的数据。例如订单系统消费了消息，但是由于网络等问题消息系统未收到反馈是否已成功处理，此时消息系统会根据配置的规则隔断时间就retry一次。但如果此时网络恢复正常，我第一次收到的消息成功处理了，这是又收到一条消息，如果没有防护措施，就有可能出现重复数据。 接口幂等性​ 幂等性指任意多次执行所产生的影响均与一次执行的影响相同。多次调用对系统的产生的影响是一样的，即对资源的作用是一样的，但是返回值允许不同。在我们编程中主要操作就是CURD，其中读取（Retrieve）操作和删除（Delete）操作是天然幂等的，受影响的就是创建（Create）、更新（Update）。 对于业务中需要考虑幂等性的地方一般都是接口的重复请求，重复请求是指同一个请求因为某些原因被多次提交。导致这个情况会有几种场景： 前端重复提交：提交订单，用户快速重复点击多次，造成后端生成多个内容重复的订单。 接口超时重试：对于给第三方调用的接口，为了防止网络抖动或其他原因造成请求丢失，这样的接口一般都会设计成超时重试多次。 消息重复消费：MQ消息中间件，消息重复消费。 幂等性实现方式Token机制 服务端提供了发送token的接口，我们在分析业务的时候，哪些是存在幂等问题的，就必须在执行业务前，前去获取token，服务器会把token保存到redis中； 然后调用业务接口请求时，把token携带过去，一般反正请求头部； 服务器判断token是否存在redis中，存在表示第一次请求，可以继续执行业务，业务完成后，需要把redis中的token删掉； 如果判断token不存在redis中，就表示是重复操作，直接返回重复标记给client，这样就保证了业务代码，不被重复执行。 这就是token+redis的幂等方案。适用于绝大部分场景。主要针对前端重复连续多次点击的情况，网上也有另一个版本的Token方案，不同的地方是：网上方案检验token存在后，就立刻删除token，再进行业务处理。而上面的方式是检验token存在后，先进行业务处理，再删除token。 网上方案的缺点是先删除token，这是出现系统问题导致业务处理出现异常，业务处理没有成功，接口调用方也没有获取到明确的结果，然后进行重试，但token已经删除掉了，服务端判断token不存在，认为是重复请求，就直接返回了，无法进行业务处理了。 而上面的方案后删除token也是会存在问题的，如果进行业务处理成功后，删除redis中的token失败了，这样就导致了有可能会发生重复请求，因为token没有被删除。 token机制缺点业务请求每次请求，都会有额外的请求（一次获取token请求、判断token是否存在的业务）。其实真实的生产环境中，1万请求也许只会存在10个左右的请求会发生重试，为了这10个请求，我们让9990个请求都发生了额外的请求。（当然redis性能很好，耗时不会太明显） 去重表机制往去重表里插入数据的时候，利用数据库的唯一索引特性，保证唯一的逻辑。唯一序列号可以是一个字段，也可以是多字段的唯一性组合。 这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。 另外，使用数据库防重表的方式它有个严重的缺点，那就是系统容错性不高，如果幂等表所在的数据库连接异常或所在的服务器异常，则会导致整个系统幂等性校验出问题。 乐观锁机制乐观锁解决了计算赋值型的修改场景。例如： 123456update user set point = point + 20, version = version + 1 whereuserid=1 and version=1 加上了版本号后，就让此计算赋值型业务，具备了幂等性。 乐观锁缺点在操作业务前，需要先查询出当前的version版本。 唯一主键机制这个机制是利用了数据库的主键唯一约束的特性，解决了在insert场景时幂等问题。但主键的要求不是自增的主键，这样就需要业务生成全局唯一的主键，之前老顾的文章也介绍过分布式唯一主键ID的生成，可自行查阅。如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。因为对主键有一定的要求，这个方案就跟业务有点耦合了，无法用自增主键了。 Redis实现Redis实现的方式就是将唯一序列号作为Key，唯一序列号可以拿几个字段MD5加密生产的密文，value可以是你想填的任何信息。唯一序列号也可以是一个字段，例如订单的订单号，也可以是多字段的唯一性组合。当然这里需要设置一个 key 的过期时间，否则 Redis 中会存在过多的 key。 状态机对于很多业务有一个业务流转状态的，每个状态都有前置状态和后置状态，以及最后的结束状态。例如流程的待审批，审批中，驳回，重新发起，审批通过，审批拒绝。订单的待提交，待支付，已支付，取消。 以订单为例，已支付的状态的前置状态只能是待支付，而取消状态的前置状态只能是待支付，通过这种状态机的流转我们就可以控制请求的幂等。 123456789101112131415161718192021222324252627public enum OrderStatusEnum &#123; UN_SUBMIT(0, 0, "待提交"), UN_PADING(0, 1, "待支付"), PAYED(1, 2, "已支付待发货"), DELIVERING(2, 3, "已发货"), COMPLETE(3, 4, "已完成"), CANCEL(0, 5, "已取消"), ; //前置状态 private int preStatus; //状态值 private int status; //状态描述 private String desc; OrderStatusEnum(int preStatus, int status, String desc) &#123; this.preStatus = preStatus; this.status = status; this.desc = desc; &#125; //...&#125; 假设当前状态是已支付，如果支付接口又收到了支付请求，则会抛出异常会拒绝此处处理。 参考资料https://juejin.im/post/5ceb4c4f51882572a206d174 https://juejin.im/post/5d1e01aaf265da1bbc6ff400]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud生产环境配置服务的配置超时和重试参数]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F26%2FSpringCloud%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%85%8D%E7%BD%AE%E8%B6%85%E6%97%B6%E5%92%8C%E9%87%8D%E8%AF%95%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[启动Ribbon的饥饿加载​ 在生产环境中，系统第一次启动时，调用其他服务经常会出现timeout，经过查阅资料得知：每个服务第一次被请求的时候，他会去初始化一个Ribbon的组件，初始化这些组件需要耗费一定的时间，所以很容易会导致timeout问题。解决方案是让每个服务启动的时候直接初始化Ribbon相关的组件，避免第一次请求的时候初始化。 123ribbon: eager-load: enabled: true ​ 上面只是解决了内部服务之间的调用，但还有一个问题就是：网关到内部服务的访问。由于Spring Cloud Zuul的路由转发也是通过Ribbon实现负载均衡的，所以也会存在第一次调用时比较慢的情况。 ​ 此时可以通过以下配置 12345zuul: ignored-services: '*' ribbon: eager-load: enabled: true ​ Spring Cloud Zuul的饥饿加载中没有设计专门的参数来配置，而是直接采用了读取路由配置来进行饥饿加载的做法。所以，如果我们使用默认路由，而没有通过配置的方式制定具体路由规则，那么zuul.ribbon.eager-load.enabled=true的配置就没有作用了。 ​ 因此，在真正使用的时候，可以通过zuul.ignored-services=*来忽略所有的默认路由，让所有的路由配置均维护在配置文件中，以达到网关启动时就默认初始化好各个路由转发的负载均衡对象。 Ribbon配置超时和重试参数​ 以下配置是用来配置Ribbon的超时时间和重试次数的： 12345678910111213ribbon: ConnectTimeout: 250 # 连接超时时间(ms) ReadTimeout: 2000 # 通信超时时间(ms) OkToRetryOnAllOperations: true # 是否对所有操作重试 MaxAutoRetriesNextServer: 1 # 同一服务不同实例的重试次数 MaxAutoRetries: 1 # 同一实例的重试次数hystrix: command: default: execution: isolation: thread: timeoutInMillisecond: 10000 # 熔断超时时长：10000ms ​ 假设在网关Zuul配置了以上参数，MaxAutoRetriesNextServer和MaxAutoRetries的意思是如果Zuul认为某个服务超时了，此时会先重试一下该服务对应的这台机器，如果还是不行就会重试一下该服务的其他机器。 ​ 重试机制除了上面的参数配置的方式之外，还可以使用Spring-Retry实现。相比配置参数配置的方式，灵活性和扩展性更强。详情可以看大佬的这一篇Spring Retry重试机制]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里分布式事务框架seata的使用和介绍]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F24%2F%E9%98%BF%E9%87%8C%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%A1%86%E6%9E%B6seata%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[​ 在分布式系统中，分布式事务是一个必须要解决的问题，目前使用较多的是最终一致性方案。自年初阿里开源了Fescar（四月初更名为Seata）后，该项目受到了极大的关注，目前已接近 8000 Star。Seata以高性能和零侵入的特性为目标解决微服务领域的分布式事务难题，目前正处于快速迭代中。 seata的几个概念​ 在讲解seata的原理之前，我们先了解几个Seata的相关概念。 XID：全局事务的唯一标识，由 ip:port:sequence 组成； Transaction Coordinator (TC)：事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚； Transaction Manager (TM )：控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议； Resource Manager (RM)：控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚； seata的简单使用​ 本文主要基于springcloud + Eureka + mysql + seata的结构搭建一个分布式系统的demo。具体步骤如下： 下载Eureka的demo https://github.com/seata/seata-samples/tree/master/springcloud-eureka-seata 下载seata-server 0.8.0 https://github.com/seata/seata/releases 创建数据库fescar，并用Navicat执行一个SQL文件创建相应测试用的表格和数据，内容如下：（这一步其实可以省略，demo中配置文件的数据库地址其实是有效的） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/* Navicat Premium Data Transfer Source Server : seata Source Server Type : MySQL Source Server Version : 50616 Source Host : 47.95.78.215:3306 Source Schema : fescar Target Server Type : MySQL Target Server Version : 50616 File Encoding : 65001 Date: 23/08/2019 11:22:20*/SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for account_tbl-- ----------------------------DROP TABLE IF EXISTS `account_tbl`;CREATE TABLE `account_tbl` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `money` int(11) NULL DEFAULT 0, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 214 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Records of account_tbl-- ----------------------------INSERT INTO `account_tbl` VALUES (213, &apos;U100000&apos;, 10000);-- ------------------------------ Table structure for order_tbl-- ----------------------------DROP TABLE IF EXISTS `order_tbl`;CREATE TABLE `order_tbl` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `commodity_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `count` int(11) NULL DEFAULT 0, `money` int(11) NULL DEFAULT 0, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 247 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Table structure for storage_tbl-- ----------------------------DROP TABLE IF EXISTS `storage_tbl`;CREATE TABLE `storage_tbl` ( `id` int(11) NOT NULL AUTO_INCREMENT, `commodity_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `count` int(11) NULL DEFAULT 0, PRIMARY KEY (`id`) USING BTREE, UNIQUE INDEX `commodity_code`(`commodity_code`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 1135 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Records of storage_tbl-- ----------------------------INSERT INTO `storage_tbl` VALUES (1134, &apos;C100000&apos;, 200);-- ------------------------------ Table structure for undo_log-- ----------------------------DROP TABLE IF EXISTS `undo_log`;CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `context` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime(0) NOT NULL, `log_modified` datetime(0) NOT NULL, `ext` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE, UNIQUE INDEX `ux_undo_log`(`xid`, `branch_id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 619 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;SET FOREIGN_KEY_CHECKS = 1; 修改demo中配置文件中数据库的账号和密码（这一步其实也可以省略，理由同上） 修改seata-server中的配置文件registry.conf，将registry的方式type改为“euraka”。如果有需要，你可以在下面修改eureka的配置，指定相应的serviceUrl和application。 修改demo中所有服务resources文件夹下的registry.conf，将注册方式type改为“file”。 先运行demo中的eureka服务，然后在seata-server的bin文件下运行命令seata-server.bat -h 127.0.0.1 -p 8091 -m file启动seata-server，然后再运行demo中的其他服务。若无明显错误信息，则启动成功。 测试demo的分布式事务功能，主要的事务发起者是business-service，测试地址如下： 提交：http://localhost:8084/purchase/commit 回滚：http://localhost:8084/purchase/rollback 修改后的源码下载地址：https://github.com/GD-CKING/demo demo解析引入依赖​ 通过分析demo，如果要使用分布式事务架构Seata，在需要引入seata的服务中引入以下依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-seata&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt;&lt;/dependency&gt; ​ demo中除了eureka之外其他服务都引入了这些依赖。 配置文件​ seata的配置文件主要有两个：registry.conf和file.conf。其中registry.conf是seata的配置入口文件。在registry中可以指定具体配置的形式，默认使用file类型，在file.conf配置文件中有一下配置内容： transport​ transport部分的配置对用NettyServerConfig类，用于定义Netty相关的参数。TM、RM和seata-server之间使用Netty进行通信。 service​ service中主要要注意service.vgroup_mapping这个配置，service.vgroup_mapping后面跟的内容要跟在配置文件中的spring.cloud.alibaba.seata.tx-service-group设置的属性一致，否则会提示no available server to connect.这个属性主要是为了定义一个tx-server-group名称 ，这个名称就是file.conf中的service.vgroup_mapping.${spring.cloud.alibaba.seata.tx-service-group}。 ​ 而file.conf中vgroup_mapping.my_test_tx_group = &quot;default&quot;指定seata-server的地址是下面default.grouplist设定的地址： 12345678910service &#123; #vgroup-&gt;rgroup #配置Client连接TC的地址 vgroup_mapping.my_test_tx_group = "default" default.grouplist = "127.0.0.1:8091" #degrade current not support enableDegrade = false #disable 是否启用seata的分布式事务 disableGlobalTransaction = false &#125; client1234567client &#123; #RM接收TC的commit通知后缓冲上限 async.commit.buffer.limit = 10000 lock &#123; retry.internal = 10 retry.times = 30 &#125; &#125; 表undo-log​ 要使用seata必须创建一个undo-log表。undo_log 是需要在业务库上创建的一个表，seata 依赖该表记录每笔分支事务的状态及二阶段 rollback 的回放数据。不用担心该表的数据量过大形成单点问题，在全局事务 commit 的场景下事务对应的 undo_log 会异步删除。 123456789101112CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, `ext` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 使用@GlobalTransactional开启事务​ 是开启分布式事务非常简单，只需要在要开启事务的业务方式上加上@GlobalTransactional注解开启事务即可。Seata 会将事务的 xid 通过拦截器添加到调用其他服务的请求中，实现分布式事务 TM处理流程​ 在本例中，TM 的角色是 business-service, BusinessService 的 purchase 方法标注了 @GlobalTransactional 注解。 ​ 方法调用后将会创建一个全局事务，首先关注 @GlobalTransactional 注解的作用，在GlobalTransactionalInterceptor中被拦截处理。 ​ 全局事务创建后，就开始执行 business.execute()，即业务代码storageFeignClient.deduct(commodityCode, orderCount)进入 RM 处理流程，此处的业务逻辑为调用 storage-service 的扣减库存接口。 RM处理流程 获取business-service传来的XID 绑定XID到当前上下文中 执行业务逻辑sql 向TC创建本次RM的Netty连接 向TC发送分支事务的相关信息 获得TC返回的branchId 记录Undo Log数据 向TC发送本次事务PhaseOne阶段的处理结果 从当前上下文中解绑XID 事务提交​ 各分支事务执行完成后，TC 对各 RM 的汇报结果进行汇总，给各 RM 发送 commit 或 rollback 的指令。 ​ 对于commit动作的处理，RM只需删除xid、branchId对应的undo_log即可。 事务回滚​ 对于rollback场景的触发有两种情况 分支事务处理异常，即ConnectionProxy中report(false)的情况。 TM捕获到下游系统上抛的异常，即发起全局事务标有@GlobalTransactional注解的方法捕获到的异常。在前面TransactionalTemplate类的execute模版方法中，对business.execute()的调用进行了catch，catch后会调用rollback，由TM通知TC对应XID需要回滚事务。 参考资料https://zhuanlan.zhihu.com/p/63381854]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的主从复制架构]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F22%2FRedis%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[本节思维导图 Redis主从架构​ 单机的Redis，能够承载的QPS大概在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构设计成主从（master-slave）架构，一主多从，主负责写，并且将数据复制到其他的slave节点，从节点复制读。所有的读请求全部走从节点。这样也可以轻松实现水平扩容，支撑读高并发。 ​ redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发 redis replication的核心机制 redis采用异步方式复制数据到slave节点，不过redis2.8开始，slave node会周期性地确认自己每次复制的数据量 一个master node是可以配置多个slave node的 slave node也可以连接其他的slave node slave node做复制的时候，不会block master node的正常工作 slave node做复制的时候，也不会block对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候会暂停对外服务了 slave node主要用来进行横向扩容，做读写分离，扩容的slave node可以提高读的吞吐量 ​ 如果采用了主从架构，那么建议必须开启master nod的持久化，不建议用slave node作为master node的数据热备，因为那样的话，你关掉了master的持久化，可能在master宕机重启的时候数据是空的，然后可能一经过复制，slave node的数据也丢了。 ​ 另外，master的各种备份方案 也需要做。如果本地的所有文件丢弃，从备份中挑选一份rdb去恢复master，这样才能确保启动的时候，是有数据的。即使采用了高可用机制，slave node可以自动接管master node，但也可能哨兵（sentinel）还没检测到masterfailure，master node自动重启了，还是可能导致上面的slave node数据被清空。 redis主从复制的核心原理​ 当启动一个slave node的时候，它会发送一个PSYNC命令给master node。 ​ 如果是slave node初次连接到master node，那么会触发一次full resynchronization全量复制。此时master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端新收到的所有命令缓存在内存中。RDB文件生产完毕后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着master会将内存中缓存的命令发送给slave，slave也会同步这些数据。slave node如果跟master node有网络故障，断开了连接，会自动重连，连接之后master node仅会复制给slave部分缺失的数据。 主从复制的断点续传​ 从redis2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么就可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。 ​ master node会在内存中维护一个backlog，master和slave都会保存一个replica offset，还有一个master run id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制，如果没有找到对应的offset，就会执行一次resynchronization。 ​ 使用master run id，是为了定位到上次传输数据的master。如果是根据host + ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分。 无磁盘化复制​ master在内存中直接创建RDB，然后发送给slave，不会在本地落地磁盘。要想开启这个功能，只需要在配置文件中国开启repl-diskless-syc yes即可。 1234repl-diskless-sync yes# 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来repl-diskless-sync-delay 5 过期key处理​ slave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。 复制的完整流程​ slave node启动时，会在自己本地保存master node的信息，包括master node的host和ip，但是复制流程没开始。 ​ slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接。然后master node发送ping命令给master node。如果master设置了requirepass，那么slave node必须发送masterauth的口令过去进行认证。master node第一次执行全量复制，将所有数据发送给slave node，而在后续，master node持续将写命令，异步复制给slave node。 数据同步相关的核心机制​ 数据同步相关的核心机制指的就是第一次slave连接master的时候，执行的全量复制，这个过程里面的一些细节的机制。 master和slave都会维护一个offset​ master会在自身不断累加offset，slave也会在自身不断累加offset。slave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset。 ​ 这个不是特定就用在全量复制的，主要是master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况。 backlog​ master node有一个backlog，默认是1MB大小。master node在给slave node复制数据时，也会将数据在backlog中同步写一份。backlog主要是用来做全量复制中断开后的增量复制的。 master run id​ info server可以看到master run id。 ​ 上面说过，根据host+ip定位master node是不靠谱的，如果master node重启或者数据发生了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制。如果需要不更改run id重启redis，可以使用redis-cli debug reload命令。 psync​ 从节点使用psync从master node进行复制，psync runid offset ​ master node会根据自身的情况返回相应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制。 全量复制 master执行bgsave，在本地生成一份RDB快照文件 master node将RDB快照文件发送给slave node，如果RDB复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调大这个参数。 master node在生成RDB时，会将所有新的写命令缓存在内存中，在slave node保存了RDB之后，再将新的写命令复制给slave node 如果在复制期间，内存缓冲区持续消耗超过64MB，会在一次性超过256MB，那么停止复制，复制失败。 1client-output-buffer-limit slave 256MB 64MB 60 slave node接收到RDB之后，清空自己的旧数据，然后重新加载RDB到自己内存中，同时基于旧的数据版本对外提供服务。 如果slave node开启了AOF，那么会立即执行BGREWAITEAOF，重写AOF 增量复制 如果全量复制过程中，master-slave网络连接断掉了，那么slave重新连接master时，会触发增量复制 master会直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB master就是根据slave发送的psync中的offset来从backlog中获取数据的。 heartbeat​ 主从节点互相都会发送heartbeat信息 ​ master默认每隔10秒发送一次heartbeat，slave node每隔1秒发送一个heartbeat。 异步复制​ master每次接收到写命令之后，现在内部写入数据，然后异步发送给slave node redis如何才能做到高可用​ 一个slave故障了，并不会影响可用性，还有其他的slave在提供服务。但master node死掉了，会导致无法写数据。没有master可以写数据，slave也就没用了，系统就不可用了。 ​ redis的高可用架构，叫做failover故障转移，也可以叫做主备切换。 ​ master node在故障时，自动检测，并且将某个slave node自动切换为master node的过程，叫做主备切换。这个过程就实现了redis的主从架构下的高可用。 主从复制的配置​ 讲了那么多，我们来看看如何配置，从而实现主从架构。 ​ 首先先配置从节点: 打开从节点的配置文件，搜索replicaof （低版本的有些是slaveof），去配置从节点要连接的主节点。如replicaof 192.168.1.1 6379，其中192.168.1.1是我们主节点的IP地址。 在配置文件中搜索replica-read-only（低版本的有些是slave-read-only），将该属性配置为也是：replica-read-only yes，这样就开启了只读redis从节点，它会拒绝所有的写操作，这样可以强制搭建读写分离的架构，从而实现读写分离。 在配置文件中搜索masterauth，来配置主节点redis的连接口令。如masterauth redis-pass，其中redis-pass就是主节点的认证口令。 在配置文件中搜索bind，将bind 127.0.0.1改成bind 自己的IP地址。bind 127.0.0.1是本地的开发调式的模式，就只有127.0.0.1本地才能访问到6379的端口。 强制开启6379端口iptables -A INPUT -ptcp --dport 6379 -j ACCEPT。（这一步有时可以省略） ​ 配置主节点： 打开主节点的配置文件，搜索requirepass，配置主节点的认证口令，使其与从节点配置的masterauth保持一致。 在配置文件中搜索bind，将bind 127.0.0.1改成bind 自己的IP地址。 强制开启6379端口iptables -A INPUT -ptcp --dport 6379 -j ACCEPT。（这一步有时可以省略） ​ 这样主从架构就配置好了，我们测试一下，先启动主节点，再启动从节点。进入主节点的redis中，执行info replication查看相关信息 ​ 同样的，进入从节点的redis，执行info replication查看相关信息]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的线程模型及和mencached的区别]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F20%2FRedis%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%92%8Cmencached%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[本节思维导图 Redis和Memcached的区别Redis支持复杂的数据结构​ redis相比于memcached来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作，redis相对来说比较好。 Redis原生支持集群模式​ redis 3.X便能支持cluster模式，而memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。 性能对比​ 由于redis只使用单核，而memcached可以使用多核，所以平均每一个核上redis存储小数据时比memcached性能更高。而在100K以上的数据中，memcached性能要高于redis。 Redis的线程模型​ redis内部使用文件事件处理器file event handler，这个文件事件处理器是单线程的，所以redis才叫做单线程的模型。它采用IO多路复用机制同时监听多个socket，将产生事件的socket压入内存队列中，事件分派器根据socket上的事件类型来选择对应的事件处理器进行处理。 ​ 文件事件处理器的结构包含4个部分： 多个socket IO多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 客户端与redis的一次通信过程如下： 首先，redis服务端进程初始化的时候，会将server socket的AE_READABLE事件与连接应答处理器关联。 ​ 客户端socket01向redis进程的server socket请求建立连接，此时server socket会产生一个AE_READABLE事件，IO多路复用程序监听到server socket产生的事件后，将该socket压入队列中。文件事件分派器从队列中获取socket，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的socket01，并将该socket01的AE_READABLE事件与命令请求处理器关联。 ​ 假设客户端发送了一个set key value请求，此时redis中的socket01会产生AE_READABLE事件，IO多路复用程序将socket01压入队列，此时事件分派器从队列中获取到socket01产生的AE_READABLE事件，由于前面的socket01的AE_READABLE事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取socket01的key value并在自己内存中完成key value的设置，操作完成后，它会将socket01的AE_WRITABLE事件与命令回复处理器关联。 ​ 如果此时客户端准备好接受返回结果了，那么redis中的socket01会产生一个AE_WRITABLE事件，同样压入队列，事件分派器找到相关联的命令回复处理器，由命令回复处理器对socket01输入本次操作的一个结果，之后解除socket01的AE_WRITABLE事件与命令回复处理器的关联。 Redis单线程效率高的原因 纯内存操作 核心是基于非阻塞的IO多路复用机制 C语言实现，一般来说，C语言实现的程序更接近操作系统，执行速度相对会快 单线程反而避免了多线程的频繁上下文切换，预防了多线程可能产生的竞争问题]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zuul-实现灰度发布]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F20%2FZuul-%E5%AE%9E%E7%8E%B0%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[​ 一般情况下，我们要发布新版本了，在不确定正确性的情况下，我们会选择先部分节点升级，然后再让一些特定的流量进入到这些新节点，完成测试后再全量发布。这就是灰度发布。 ​ 在Eureka中注册多个服务后，如果一个服务有多个实例，那么默认会走ribbon的软负载均衡来进行分发请求。而要完成灰度发布，要做的就是修改ribbon的负载策略。在SpringCloud体系中，完成这件事，一般都是根据Eureka的metadata进行自定义元数据，然后修改Ribbon的规则。 ​ 我们可以用数据库来动态开启灰度发布和指定灰度发布的请求，当然你也可以用Apollo配置中心、Redis、ZooKeeper，其实都可以。先创建一个灰度发布启用表： 1234567CREATE TABLE `gray_release_config` ( `id` int(11) NOT NULL AUTO_INCREMENT, `service_id` varchar(255) DEFAULT NULL, `path` varchar(255) DEFAULT NULL, `enable_gray_release` int(11) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ​ 其中“enable_gray_release”表示是否启用灰度发布，默认数字0是不启动，1启动。然后插入一条数据，方便我们测试： 1INSERT INTO gray_release_config VALUES(1, 'order-service', '/order', 0) ​ 首先，我们需要在Zuul项目里添加依赖： 12345&lt;dependency&gt; &lt;groupId&gt;io.jmnarloch&lt;/groupId&gt; &lt;artifactId&gt;ribbon-discovery-filter-spring-cloud-starter&lt;/artifactId&gt; version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; ​ 接着在网关中新建给表的实体类： 1234567891011121314151617181920212223242526272829303132333435package com.zhss.demo.zuul.gateway;public class GrayReleaseConfig &#123; private int id; private String serviceId; private String path; private int enableGrayRelease; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getServiceId() &#123; return serviceId; &#125; public void setServiceId(String serviceId) &#123; this.serviceId = serviceId; &#125; public String getPath() &#123; return path; &#125; public void setPath(String path) &#123; this.path = path; &#125; public int getEnableGrayRelease() &#123; return enableGrayRelease; &#125; public void setEnableGrayRelease(int enableGrayRelease) &#123; this.enableGrayRelease = enableGrayRelease; &#125; &#125; ​ 然后我们可以编写一个定时器，定时获取灰度表的信息，看哪些服务需要灰度发布，新建类GrayReleaseConfigManager： 1234567891011121314151617181920212223242526272829303132333435363738394041package com.zhss.demo.zuul.gateway;import java.util.List;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.core.BeanPropertyRowMapper;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.scheduling.annotation.EnableScheduling;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component;@Component@Configuration @EnableScheduling public class GrayReleaseConfigManager &#123; private Map&lt;String, GrayReleaseConfig&gt; grayReleaseConfigs = new ConcurrentHashMap&lt;String, GrayReleaseConfig&gt;(); @Autowired private JdbcTemplate jdbcTemplate; @Scheduled(fixedRate = 1000) private void refreshRoute() &#123; List&lt;GrayReleaseConfig&gt; results = jdbcTemplate.query( "select * from gray_release_config", new BeanPropertyRowMapper&lt;&gt;(GrayReleaseConfig.class)); for(GrayReleaseConfig grayReleaseConfig : results) &#123; grayReleaseConfigs.put(grayReleaseConfig.getPath(), grayReleaseConfig); &#125; &#125; public Map&lt;String, GrayReleaseConfig&gt; getGrayReleaseConfigs() &#123; return grayReleaseConfigs; &#125;&#125; ​ 然后再编写一个Zuul的过滤器，实现灰度发布的逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100package com.zhss.demo.zuul.gateway;import org.springframework.context.annotation.Configuration;import com.netflix.zuul.ZuulFilter;import com.netflix.zuul.context.RequestContext;import io.jmnarloch.spring.cloud.ribbon.support.RibbonFilterContextHolder;import static org.springframework.cloud.netflix.zuul.filters.support.FilterConstants.*;import java.util.Map;import java.util.Random;import javax.annotation.Resource;import javax.servlet.http.HttpServletRequest;@SuppressWarnings("unused")@Configurationpublic class GrayReleaseFilter extends ZuulFilter &#123; @Resource private GrayReleaseConfigManager grayReleaseConfigManager; /** * 过滤的优先级，数字越大，级别越低 * @return */ @Override public int filterOrder() &#123; return PRE_DECORATION_FILTER_ORDER - 1; &#125; @Override public String filterType() &#123; return PRE_TYPE; &#125; /** * 是否执行该过滤器 * @return */ @Override public boolean shouldFilter() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); String requestURI = request.getRequestURI(); // http://localhost:9000/order/order?xxxx Map&lt;String, GrayReleaseConfig&gt; grayReleaseConfigs = grayReleaseConfigManager.getGrayReleaseConfigs(); for(String path : grayReleaseConfigs.keySet()) &#123; if(requestURI.contains(path)) &#123; GrayReleaseConfig grayReleaseConfig = grayReleaseConfigs.get(path); if(grayReleaseConfig.getEnableGrayRelease() == 1) &#123; System.out.println("启用灰度发布功能"); return true; &#125; &#125; &#125; System.out.println("不启用灰度发布功能"); return false; &#125; /** * 过滤器的具体逻辑 * @return */ @Override public Object run() &#123;// RequestContext ctx = RequestContext.getCurrentContext();// HttpServletRequest request = ctx.getRequest();// String gray = request.getParameter("gray");//// if("true".equals(gray)) &#123;// RibbonFilterContextHolder.getCurrentContext().add("version", "new");// &#125; else &#123;// RibbonFilterContextHolder.getCurrentContext().add("version", "current");// &#125; Random random = new Random(); int seed = random.nextInt(100); if (seed == 50) &#123; // put the serviceId in `RequestContext` RibbonFilterContextHolder.getCurrentContext() .add("version", "new"); &#125; else &#123; RibbonFilterContextHolder.getCurrentContext() .add("version", "old"); &#125; return null; &#125;&#125; ​ 上面的代码主要还是看run()方法的实现。注释掉的代码是通过判断请求连接中是否包含“gray”参数，如果包含gray参数并且它的值为“true”，则将流量引到新的节点。而没有注释的代码则是根据随机数seed的值来引流。当你希望有10%的流量引到新节点时，可以将if(seed == 50)改成 seed &gt;= 90或者其他。 ​ 最后，就是在要升级的服务配置上增加metadata的自定义数据即可，根据上述的代码，我们应该在要升级的服务的配置文件中增加：eureka: instance: metadata-map: version: new。在没升级的服务的配置文件中增加：eureka: instance: metadata-map: version: old ​ 这样，基于Zuul的灰度发布功能就实现了。当然，基于灰度发布这块，国内有了更强大的开源框架Nepxion Discovery。Nepxion Discovery是一款对Spring Cloud Discovery服务注册发现、Ribbon负载均衡、Feign和RestTemplate调用的增强中间件，感兴趣的朋友可以去官方的github上查看：https://github.com/Nepxion/Discovery]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis分布式锁的实现原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F20%2FRedis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 目前基于Redis实现的分布式锁常用的框架是Redisson,它的使用比较简单，在项目中引入Redisson的依赖，然后基于Redis实现分布式锁的加锁与释放锁，如下所示： ​ 接下来我们就说一下Redisson这个框架对于Redis分布式锁的实现原理。 Redis分布式锁的底层原理​ Redisson这个框架对Redis分布式锁的实现原理图如下： 加锁机制​ 某个客户端要加锁。如果该客户端面对的是一个Redis Cluster集群，它首先会根据hash节点选择一台机器，这里注意，仅仅只是选择一台机器。紧接着就会发送一段lua脚本到redis上，lua脚本如下所示： ​ 使用lua脚本，可以把一大堆业务逻辑通过封装在lua脚本发送给redis，保证这段赋值业务逻辑执行的原子性。在这段脚本中，这里KEYS[1]代表的是你加锁的那个key，比如说：RLock lock = redisson.getLock(“myLock”);这里你自己设置了加锁的那个锁key就是“myLock”。 ​ ARGV[1]代表的就是锁key的默认生存时间，默认30秒。ARGV[2]代表的是加锁的客户端的ID，类似于下面这样：8743c9c0-0795-4907-87fd-6c719a6b4586:1。 ​ 脚本的意思大概是：第一段if判断语句，就是用“exists myLock”命令判断一下，如果你要加锁的那个key不存在，就可以进行加锁。加锁就是用“hset myLock 8743c9c0-0795-4907-87fd-6c719a6b4586:1 1”命令。通过这个命令设置一个hash数据结构，这个命令执行后，会出现一个类似下面的数据结构： ​ 上述就代表“8743c9c0-0795-4907-87fd-6c719a6b4586:1”这个客户端对“myLock”这个锁key完成了加锁。接着会执行“pexpire myLock 30000”命令，设置myLock这个锁key的生存时间是30秒。好了，到此为止，ok，加锁完成了。 锁互斥机制​ 如果这个时候客户端B来尝试加锁，执行了同样的一段lua脚本。第一个if判断会执行“exists myLock”，发现myLock这个锁key已经存在。接着第二个if判断，判断myLock锁key的hash数据结构中，是否包含客户端B的ID，但明显没有，那么客户端B会获取到pttl myLock返回的一个数字，代表myLock这个锁key的剩余生存时间。此时客户端B会进入一个while循环，不听的尝试加锁。 watch dog自动延期机制​ 客户端A加锁的锁key默认生存时间只有30秒，如果超过了30秒，客户端A还想一直持有这把锁，怎么办？其实只要客户端A一旦加锁成功，就会启动一个watch dog看门狗，它是一个后台线程，会每隔10秒检查一下，如果客户端A还持有锁key，那么就会不断的延长锁key的生存时间。 可重入加锁机制​ 客户端A已经持有锁了，然后可重入加锁，如下代码所示： ​ 这个时候lua脚本是这样执行的：第一个if判断不成立，“exists myLock”会显示锁key已经存在了。第二个if判断会成立，因为myLock的hash数据结构中包含的那个ID，就是客户端A的ID，此时就会执行可重入加锁的逻辑，它会用“incrby myLock 8743c9c0-0795-4907-87fd-6c71a6b4586:1 1 ”这个命令对客户端A的加锁次数，累加1，此时myLock的数据结构变成下面这样： ​ 即myLock的hash数据结构中的那个客户端ID，就对应着加锁的次数。 释放锁机制​ 执行lock.unlock()，就可以释放分布式锁。释放逻辑是：每次对myLock数据结构中的那个加锁次数减1，如果加锁次数为0了，说明客户端已经不再持有锁了，此时就会用“del MyLock”命令，从redis里删除了这个key。然后另外的客户端B就可以尝试完成加锁了。 上述Redis分布式锁的缺点​ 上面方案的最大问题，就是如果你对某个redis master实例，写入了myLock这种锁key的value，此时会异步复制给对应的master slave实例，但是这个过程中如果发送redis master宕机，主备切换，redis slave变为了redis master。 ​ 这就会导致客户端B来尝试加锁的时候，在新的redis master上完成了加锁，而客户端A也以为自己成功加了锁，此时就会导致多个客户端对一个分布式锁完成了加锁。这时就会导致各种脏数据的产生。 ​ 所以这个就是redis cluster，或者是redis master-slave架构的主从异步复制导致的redis分布式锁的最大缺陷：在redis master实例宕机的时候，可能导致多个客户端同时完成加锁。]]></content>
      <categories>
        <category>分布式</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper分布式锁的实现原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F19%2FZooKeeper%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[ZooKeeper分布式锁机制​ 本文将基于常用的ZooKeeper分布锁实现框架–Curator，说一下这个框架对ZooKeeper分布式锁的实现。 ​ 首先模拟一下两个客户端一起争抢ZK上的一把分布式锁的场景： ​ ZK里有一把锁，这个锁就是ZK上的一个节点。然后两个客户端都要来获取这个锁。假设客户端A抢先一步，对ZK发起了加分布式锁的请求，这个加锁请求是用到了ZK的“临时顺序节点”。简答来说就是直接在“my_lock”这个锁节点下，创建一个顺序节点，这个节点有ZK内部自行维护的一个节点序号。 ​ 例如第一个客户端来搞一个顺序节点，ZK内部会起个名字叫xxx-00001。然后第二个客户端搞一个顺序节点，ZK可能会起个名字叫xxx-00002。规律就是最后一个数字都是依次递增的，从1开始递增，ZK会维护这个顺序。 ​ 所以这个时候，假如客户端A先发起请求，就会搞出一个顺序节点，如图所示： ​ 客户端A发起一个加锁请求，先会在你要加锁的node下搞一个临时顺序节点，节点名字由Curator框架自己生成出来，但最后一个数字是“1”，因为客户端是第一个发起请求的。 ​ 客户端A常见完一个节点后，它会查一下“my_lock”这个锁节点下的所有子节点，并且这些子节点都是按照序号排序的，这个时候他大概会拿到一个集合： ​ 接着客户端A会走一个关键性的判断：我创建的那个顺序节点，是不是排在第一个？如果是的话，那我就可以加锁了。因为我是第一个创建顺序节点的人，所以我是第一个尝试加分布式锁的人。 ​ 客户端A加完锁了，客户端B过来想要加锁，这时它会先在“my_lock”这个锁节点下创建一个临时顺序节点，此时名字大概会是“xxx-00002” ​ 客户端B因为是第二个来创建顺序节点的，所以ZK内部会维护序号为“2”。接着客户端B会走加锁判断逻辑，查询“my_lock”锁节点下的所有子节点，按照顺序排列，类似于： ​ 同时检查自己创建的顺序节点，是不是集合中的第一个？如果不是，那就加锁失败。失败之后，客户端B就会通过ZK的API对他的顺序节点的上一个顺序节点加一个监听器 ​ 接着，客户端A加锁之后，逻辑处理完后就会释放锁，释放锁实际就是把ZK里创建的顺序节点“xxx-00001”给删除掉。删除了节点之后，ZK会负责通知监听这个节点的监听器，也就是客户端B的监听器说锁释放了。 ​ 此时客户端B的监听器感知到了上一个顺序节点被删除，也就是排在他之前的某个客户单释放了锁，此时客户端B重新尝试去获取锁，也就是获取“my_lock”节点下的子节点集合： ​ 然后客户端B判断自己是否是集合中的第一个顺序节点，如果是，直接完成加锁，运行完业务代码后，再次释放锁。 总结​ 总结一下多个客户端争抢一个ZK分布式锁的原理： 客户端上来直接创建一个锁节点下的一个接一个的临时顺序节点 如果自己不是第一个节点，就对自己上一个节点加监听器 只要上一个节点释放锁，自己就排到前面去，相当于一个排队机制。 ​ 而且用临时加节点的另一个好处就是，如果某个客户端创建临时顺序节点之后，自己宕机了也没关系，ZK感知到那个客户端宕机，会自动删除对应的临时顺序节点，相当于自动释放锁。 ​ 最后看一下用Curator框架进行加锁和释放锁的一个过程：]]></content>
      <categories>
        <category>分布式</category>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单了解ZooKeeper]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F19%2F%E7%AE%80%E5%8D%95%E4%BA%86%E8%A7%A3ZooKeeper%2F</url>
    <content type="text"><![CDATA[本节思维导图 ZooKeeper的数据结构​ ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗树，每个节点叫做ZNode，每一个节点可以通过路径来标识： ​ ZooKeeper的节点我们称之为ZNode，ZNode分为两种类型： 短暂/临时：当客户端和服务端断开连接后，所创建的ZNode（节点）会自动删除 持久：当客户端和服务端断开连接后，所创建的ZNode不会删除 ​ 这些节点由可以分成另外两种类型： 普通节点 带顺序号节点 监听器​ ZooKeeper之所以能实现那么多功能，最主要还是配合了监听器。 ​ 常见的监听器有以下两个功能： 监听ZNode节点的数据变化 监听子节点的增减变化 ​ 通过监听+ZNode节点，Zookeeper就可以实现比较多的功能了 ZooKeeper的作用统一配置管理​ 比如现在有三个系统A、B、C，他们有三份配置ASystem.yml、BSystem.yml、CSystem.yml，然后，这三份配置又非常类似，很多配置项几乎一样。此时如果我们要改变其中一份配置项的信息，很可能另外两份都要改，并且改了配置项的系统很能就要重启系统。 ​ 于是我们希望把ASystem.yml、BSystem.yml、CSystem.yml相同的配置项抽取出来成一份公用的配置common.yml，并且即使common.yml改了，也不需要系统A、B、C重启。 ​ 解决方案是我们可以把common.yml这份配置放在ZooKeeper的ZNode节点中，系统A B C监听这个节点有无变更，变更了就及时响应。 ​ 具体实现可以大佬写的 基于zookeeper实现统一配置管理 统一命名服务​ 统一命名服务的理解其实跟域名一样，是我们为这某一部分的资源给它取另一个名字，别人通过这个名字就可以拿到对应的资源。 ​ 例如我们有一个域名叫www.test.com。但这个域名下有多台机器： 192.168.1.1 192.168.1.2 192.168.1.3 192.168.1.4 别人访问www.test.com即可访问到我的机器，而不是通过IP去访问。 分布式锁​ 详情请参考这篇 ZooKeeper的分布式锁的实现原理 集群管理​ 还是以三个系统A B C为例，在ZooKeeper中创建临时节点即可， ​ 只要系统A挂了，那么/groupMember/A这个节点就会删除，通过监听groupMember下的子节点，系统B和C就能感知到系统A挂了，新增也是同理。 ​ 除了能感知节点的上下线变化，Zookeeper还可以实现动态选举Master的功能（如果集群是主从结构模式下）。原理也很简单，如果想要实现这个功能，只要ZNode节点的类型是带顺序号的临时节点就好了。ZooKeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的ZNode节点就会删除，然后让新的最小编号作为Master，这样就可以实现动态选举的功能。]]></content>
      <categories>
        <category>分布式</category>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务方案]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F16%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[本节思维导图 目前分布式事务的实现方案主要有以下5种： XA方案 TCC方案 本地消息表 可靠消息最终一致性方案 最大努力通知方案 两阶段提交方案/XA方案​ 所谓的XA方案，就是两阶段提交。有一个事务管理器的概念，负责协调多个数据库（资源管理器）的事务，事务管理器先询问各个数据库是否准备好了，如果数据库都准备好了，就正式提交事务，在各个数据库上执行。如果任何其中一个数据库回答不OK，那么就回滚事务。 ​ 这种分布式方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复制的事务，效率很低。绝对不适合高并发的场景。如果要实现，可以基于Spring+JTA就可以实现。 ​ 这个方案，一般很少用。一般来说某个系统内部如果出现跨多个库的操作，是不合规的。即便是现在的微服务，一个大的系统分成十几个甚至几百个服务。一般来说，都是要求每个服务只能操作自己对应的一个数据库。如果要操作别的服务对应的库，不允许直接连接，违反微服务架构的规范，你随便交叉胡乱访问，几百个服务的话，全体乱套，这样的一套服务是没法管理的，没法治理的，可能会出现数据被别人改错，自己的库被别人写挂等情况。 如果你要操作别人的服务的库，你必须是通过调用别的服务的接口来实现，绝对不允许交叉访问别人的数据库。 TCC方案​ tcc全称是：try、confirm、cancel Try阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预定。 Confirm：这个阶段说的是在各个服务中执行实际的操作。 Cancel：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）。 ​ 这种方案也用的比较少，但是也有使用的场景。因为这个事务回滚实际上是严重依赖于自己写的代码来回滚和补偿的，会造成补偿代码巨大。一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，会使用TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性。而且最好是你的各个业务执行的时间都比较短。但是一般情况下尽量不要使用TCC方案，自己手写回滚逻辑或者是补偿代码，都是很恶心的，业务代码很难维护。 本地消息表​ 本地消息表的大概意思如下： A系统在自己本地一个事务里操作同时，插入一条数据到消息表； 接着A系统将这个消息发送到MQ中去； B系统接收到消息之后，在一个事务里，往自己本地消息表插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过，那么此时这个事务会回滚，这样保证不会重复处理消息； B系统执行成功之后，就会更新自己本地信息表的状态以及A系统信息表的状态； 如果B系统处理失败，那么久不会更新信息表状态，那么此时A系统会定时扫描自己的消息表，如果有未处理的消息，则会发送到MQ中去，让B再次处理； 这个方案保证了最终一致性，哪怕B事务失败了，但是A会不断重发信息一致到B那边成功为止。 这个方案最大的问题是就是严重依赖于数据库的消息表来管理事务，如果是高并发场景，很难扩展，所以一般比较少用。 可靠消息最终一致性方案​ 这个的意思，就是干脆不用本地消息表了，直接基于MQ来实现事务，比如阿里的RocketMQ就支持消息事务，大概的思路如下： A系统先发送一个prepared消息到mq，如果这个prepared消息发送失败那么就直接取消操作别执行了； 如果这个消息发送成功了，那么接着执行本地事务，如果成功就告诉MQ发送确认信息，如果失败就告诉mq回滚消息； 如果发送了确认消息，那么此时B系统会接收到确认信息，然后执行本地事务； MQ会自动定时轮询所有prepared消息回调你的接口，问你这个消息是不是本地事务处理失败了，所有没发送确认消息的信息，是继续重试还是回滚？一般来说这里你就可以查下数据库之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。 这个方案里，要是系统B的事务失败了，那就重试，自动不断地重试直到成功，如果实在不行，那就针对重要的资金业务进行回滚，比如B系统本地回滚后，想办法通知系统A也回滚，或者是发送警报由人工来手工回滚和补偿 ​ 这个方案还是比较合适的，目前国内的互联网公司大部分都是这样设计。你可以使用RocketMQ，也可以使用其他消息队列封装一套类似的逻辑出来。 最大努力通知方案​ 这个方案的大概思路就是： 系统A本地事务执行完之后，发送个消息到MQ； 这里会有个专门消费MQ的最大努力通知服务，这个服务会消费MQ然后写入数据中记录下来，或者是放入个内存队列里，接着调用系统B的接口； 要是系统B执行成功就OK了，要是系统B执行失败了，那么最大努力同时服务就定时尝试重新调用系统B，反复N次，最后还是不行就放弃。 总结​ 基本上，一些特别严格的场景，用的是TCC来保证强一致性，例如严格要求资金绝对不能错的场景；其他的一些场景基于阿里的RocketMQ来实现分布式事务，例如一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么敏感，可以用可靠消息最终一致性方案。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设计一个能抗住上万服务实例的注册中心]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F15%2F%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E8%83%BD%E6%8A%97%E4%BD%8F%E4%B8%8A%E4%B8%87%E6%9C%8D%E5%8A%A1%E5%AE%9E%E4%BE%8B%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[​ 之前说过ZooKeeper和Eureka由于自己的特性，都不太适合支撑大规模的服务实例。Eureka是peer-to-peer模式，每台机器都是高并发请求的话会有瓶颈。而ZooKeeper是每次服务上下线，就会全量通知其他服务，导致网络宽带被打满，这也是一个瓶颈。具体可以查看服务注册中心的选型调研这篇文章。那么怎样才能实现一个能抗住上万服务实例的注册中心呢？ ​ 目前大公司的服务注册中心为了能支撑大规模的服务实例，基本都是自研服务注册中心。基本的思路就是实现一个分布式服务注册中心。主要设计逻辑包括：分片存储服务注册表、支持横向扩容、每台机器均摊高并发请求、各个服务主动拉取注册表信息，避免方向通知网卡被打爆等等。 ​ 简单的原理图如下所示：]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zuul-实现动态路由]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F13%2FZuul-%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1%2F</url>
    <content type="text"><![CDATA[​ 一般情况下，Zuul需要在配置文件里写好路由信息，这样zuul才可以通过这些路由信息根据连接转发到相应的服务上去。但每增加一个服务，就需要停下网关去重新编写配置文件，这样就比较麻烦了。因此，就有人提出了动态路由的方法。 ​ 动态路由有很多方式实现，这里主要讲一下用数据库去实现动态路由。 ​ 首先，先创建一个表，用于存储路由信息： 1234567891011CREATE TABLE `gateway_api_route` ( `id` varchar(50) NOT NULL, `path` varchar(255) NOT NULL, `service_id` varchar(50) DEFAULT NULL, `url` varchar(255) DEFAULT NULL, `retryable` tinyint(1) DEFAULT NULL, `enabled` tinyint(1) NOT NULL, `strip_prefix` int(11) DEFAULT NULL, `api_name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ​ 该表结构主要是按照Zuul的ZuulProperties.ZuulRoute类设计的： ​ 插入一条数据，方便测试： 1INSERT INTO gateway_api_route (id, path, service_id, retryable, strip_prefix, url, enabled) VALUES ('order-service', '/order/**', 'order-service',0,1, NULL, 1); ​ 然后编写表gateway_api_route相应的实体类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class GatewayApiRoute &#123; private String id; private String path; private String serviceId; private String url; private boolean stripPrefix = true; private Boolean retryable; private Boolean enabled; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getPath() &#123; return path; &#125; public void setPath(String path) &#123; this.path = path; &#125; public String getServiceId() &#123; return serviceId; &#125; public void setServiceId(String serviceId) &#123; this.serviceId = serviceId; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public boolean isStripPrefix() &#123; return stripPrefix; &#125; public void setStripPrefix(boolean stripPrefix) &#123; this.stripPrefix = stripPrefix; &#125; public Boolean getRetryable() &#123; return retryable; &#125; public void setRetryable(Boolean retryable) &#123; this.retryable = retryable; &#125; public Boolean getEnabled() &#123; return enabled; &#125; public void setEnabled(Boolean enabled) &#123; this.enabled = enabled; &#125; &#125; ​ 接下来就开始编写动态路由的实现逻辑，其实基本逻辑就是从数据库里取出路由数据，然后封装成ZuulProperties.ZuulRoute。主要代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.zhss.demo.zuul.gateway;import org.springframework.beans.BeanUtils;import org.springframework.cloud.netflix.zuul.filters.RefreshableRouteLocator;import org.springframework.cloud.netflix.zuul.filters.SimpleRouteLocator;import org.springframework.cloud.netflix.zuul.filters.ZuulProperties;import org.springframework.jdbc.core.BeanPropertyRowMapper;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.util.StringUtils; import java.util.LinkedHashMap;import java.util.List;import java.util.Map;public class DynamicRouteLocator extends SimpleRouteLocator implements RefreshableRouteLocator &#123; private JdbcTemplate jdbcTemplate; private ZuulProperties properties; public void setJdbcTemplate(JdbcTemplate jdbcTemplate) &#123; this.jdbcTemplate = jdbcTemplate; &#125; public DynamicRouteLocator(String servletPath, ZuulProperties properties) &#123; super(servletPath, properties); this.properties = properties; &#125; @Override public void refresh() &#123; doRefresh(); &#125; @Override protected Map&lt;String, ZuulProperties.ZuulRoute&gt; locateRoutes() &#123; LinkedHashMap&lt;String, ZuulProperties.ZuulRoute&gt; routesMap = new LinkedHashMap&lt;String, ZuulProperties.ZuulRoute&gt;(); // 加载application.yml中的路由表 routesMap.putAll(super.locateRoutes()); // 加载db中的路由表 routesMap.putAll(locateRoutesFromDB()); // 统一处理一下路由path的格式 LinkedHashMap&lt;String, ZuulProperties.ZuulRoute&gt; values = new LinkedHashMap&lt;&gt;(); for (Map.Entry&lt;String, ZuulProperties.ZuulRoute&gt; entry : routesMap.entrySet()) &#123; String path = entry.getKey(); if (!path.startsWith("/")) &#123; path = "/" + path; &#125; if (StringUtils.hasText(this.properties.getPrefix())) &#123; path = this.properties.getPrefix() + path; if (!path.startsWith("/")) &#123; path = "/" + path; &#125; &#125; values.put(path, entry.getValue()); &#125; System.out.println("路由表：" + values); return values; &#125; private Map&lt;String, ZuulProperties.ZuulRoute&gt; locateRoutesFromDB() &#123; Map&lt;String, ZuulProperties.ZuulRoute&gt; routes = new LinkedHashMap&lt;&gt;(); List&lt;GatewayApiRoute&gt; results = jdbcTemplate.query( "select * from gateway_api_route where enabled = true ", new BeanPropertyRowMapper&lt;&gt;(GatewayApiRoute.class)); for (GatewayApiRoute result : results) &#123; if (StringUtils.isEmpty(result.getPath()) ) &#123; continue; &#125; if (StringUtils.isEmpty(result.getServiceId()) &amp;&amp; StringUtils.isEmpty(result.getUrl())) &#123; continue; &#125; ZuulProperties.ZuulRoute zuulRoute = new ZuulProperties.ZuulRoute(); try &#123; BeanUtils.copyProperties(result, zuulRoute); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; routes.put(zuulRoute.getPath(), zuulRoute); &#125; return routes; &#125; &#125; 然后在新建一个配置类DynamicRouteConfiguration 12345678910111213141516171819202122232425262728package com.zhss.demo.zuul.gateway;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.web.ServerProperties;import org.springframework.cloud.netflix.zuul.filters.ZuulProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.core.JdbcTemplate; @Configurationpublic class DynamicRouteConfiguration &#123; @Autowired private ZuulProperties zuulProperties; @Autowired private ServerProperties server; @Autowired private JdbcTemplate jdbcTemplate; @Bean public DynamicRouteLocator routeLocator() &#123; DynamicRouteLocator routeLocator = new DynamicRouteLocator( this.server.getServletPrefix(), this.zuulProperties); routeLocator.setJdbcTemplate(jdbcTemplate); return routeLocator; &#125; &#125; 这样就差不多，最后再实现一个定时器，定时刷新路由信息： 1234567891011121314151617181920212223242526272829package com.zhss.demo.zuul.gateway;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.cloud.netflix.zuul.RoutesRefreshedEvent;import org.springframework.cloud.netflix.zuul.filters.RouteLocator;import org.springframework.context.ApplicationEventPublisher;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.EnableScheduling;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component;@Component@Configuration @EnableScheduling public class RefreshRouteTask &#123; @Autowired private ApplicationEventPublisher publisher; @Autowired private RouteLocator routeLocator; @Scheduled(fixedRate = 5000) private void refreshRoute() &#123; System.out.println("定时刷新路由表"); RoutesRefreshedEvent routesRefreshedEvent = new RoutesRefreshedEvent(routeLocator); publisher.publishEvent(routesRefreshedEvent); &#125; &#125; 这样一个基于zuul的动态路由功能就完成了，代码跑起来后，可以看到定时器在工作，定数刷新路由信息：]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eureka的一些参数配置优化]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F13%2FEureka%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ Eureka的默认配置是比较糟糕的，一般服务的上线和下线极端情况下需要一分多钟才能感知到，服务故障极端情况下需要两到三分钟才能感知到，这相对于ZooKeeper的秒级感知来说实在是太慢了。因此我们可以通过修改Eureka的一些配置参数来达到秒级通知的效果。 Eureka-Server端的配置eureka.server.responseCacheUpdateIntervalMs​ 这个参数表示的是Eureka中ReadWriteCacheMap的缓存数据多久会更新到ReadOnlyCacheMap中去，应为Eureka-Client是从ReadOnlyCacheMap拉取数据的。这个参数默认是30秒更新一次ReadOnlyCacheMap，我们可以改为3秒更新一次：eureka.server.response-cache-update-interval-ms = 3000 eureka.server.evictionIntervalTimerInMs​ 这个参数表示的是Eureka-Server中的缓存数据每隔多少秒主动失效。默认是60秒主动清空服务列表，我们可以改为6秒：eureka.server.eviction-interval-timer-in-ms = 6000 eureka.instance.leaseExpirationDurationInSeconds​ 服务过期时间配置，超过这个时间没有接收到心跳就会认为该服务实例已经挂了。并将该服务实例从注册表中剔除掉。默认情况下是90秒，我们可以设置为9秒：eureka.instance.lease-expiration-duration-in-seconds = 9 Eureka-Client端的配置eureka.client.registryFetchIntervalSeconds​ 这个参数表示的是Eureka-Client拉取数据，刷新本地缓存的时间，默认是每30秒拉取一次数据，我们可以将速度提高10倍，改为3秒：eureka.client.registry-fetch-interval-seconds = 3 eureka.instant.leaseRenewalIntervalInSeconds​ 这个参数表示的是Eureka-Client每隔多久发送一次心跳，默认是30秒发送一次心跳到Eureka-Server上。我们可以改成3秒：eureka.instant.lease-renewal-interval-in-seconds = 30]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务注册中心的选型调研]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F11%2F%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E7%9A%84%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 目前市场上使用最多的服务注册中心应该是Eureka和Zookeeper，当然Consul和Nacos，也在慢慢崛起。本文主要从集群模式、一致性保障、时效性和容量这几个角度来讨论Eureka和ZooKeeper的区别。 服务注册发现的集群模式Eureka​ Eureka的集群模式，简单地说就是peer-to-peer。部署一个集群，但是集群里每个机器的地位是对等的，各个服务可以向任何一个Eureka实例进行服务注册和发现，集群里的任何一个Eureka实例收到请求后，会自动同步给其他所有的Eureka实例。除了注册信息，服务发送的心跳信息也会同步到其他Eureka实例上。如图所示： ZooKeeper​ ZooKeeper的集群模式，简单就是Leader+Follower，其中只有Leader可以负责写，即服务注册，领完，它还负责把数据同步给Follow。服务发现的时候，Leader/Follow都可以读。 一致性保障：CP or AP​ CAP原则包含如下三个元素： C（Consistency）：一致性。在分布式系统中的所有数据备份，在同一时刻具有同样的值，所有节点在同一时刻读取的数据都是最新的数据副本。 A（Availability）：可用性。好的相应性能。完全的可用性指的是在任何故障模型下，服务都会在有限的时间内处理完成并进行相应。 P（Partition tolerance）：分区容错性。尽管网络上有部分消息丢失，但系统仍然可以继续工作。 CAP原理证明，任何分布式系统只可同时满足以上两点，无法三者兼顾。由于关系型数据库是单节点无复制的，因此不具有分区容忍性，但是具有一致性和可用性；而分布式的服务化系统都需要满足分区容忍性，那么我们必须在一致性和可用性之间进行权衡。 Eureka​ Eureka是AP模式的，即它牺牲了一致性，而实现可用性和分区容错性。因为Eureka是peer-to-peer模式，可能数据还没有同步互过去，自己就挂掉了，但服务实例依然可以从别的Eureka实例上拉去注册表，但是看到的数据就不是最新的收据了。但Eureka保证了最终一致性。例如服务A除了注册服务之外还会发送心跳信息，当服务A发现Eureka1实例挂掉之后，会向另一个活着的Eureka2实例发送心跳信息，Eureka2就能感知到服务A的存在并更新注册表的数据，从而实现最终一致性。 ZooKeeper​ ZooKeeper是CP模式的。ZooKeeper是有一个Leader节点会接收数据，然后同步其他节点，一旦Leader挂掉了，就要重新选举Leader，这个过程为了一致性，就会牺牲看可用性，会不可用一段时间，那么就可以继续写数据了，保证了一致性。即ZooKeeper是同步数据期间和Leader选举期间，都处于不可用阶段，等结束之后就可以继续使用，但这样却保证了强一致性。 服务注册发现的时效性​ ZooKeeper的时效性更好，注册或者是挂了，一般秒级就能感知到。 ​ Eureka，默认配置非常糟糕。服务发现感知要到几十秒，甚至分钟级别。上线一个新的服务，到其他服务可以发现它，极端情况下可能要一分钟的时间。（30秒ReadWriteCache更新ReadOnlyCacheMap数据，再30秒服务实例去拉取ReadOnlyCacheMap的数据）。 ​ 在默认情况下，服务故障，隔60秒才去检查心跳，发现这个服务上一次心跳是在30秒之前。在隔60秒去检查心跳，超过90秒没有心跳，才会认为这个服务已经挂了，这样子就已经过去两分钟了。 ​ 因此极端情况下，你的服务挂掉了，到其他服务感知到，可能需要两三分钟时间，比较漫长。 容量​ Eureka很难支撑大规模的服务实例，因为每个Eureka实例都要接受所有服务的注册请求信息和心跳信息，实例多了压力太大扛不住，很难做到几千服务实例。比如服务实例太多，达到上千个，每秒钟的有上千个心跳信息，那要同时同步到其余心跳信息。压力会比较大。 ​ ZooKeeper同样不适合大规模的服务实例，因为服务上线的时候，需要瞬间推送数据通知到所有的其他服务实例，所以一旦服务规模太大，到了几千个服务实例的时候，会导致网络带宽被大量占用。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>服务注册</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud常用组件原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F11%2FSpringCloud%E5%B8%B8%E7%94%A8%E7%BB%84%E4%BB%B6%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[​ Spring Cloud是一个全家桶式的技术栈，包含了很多组件。本文主要简单介绍下最核心的几个组件的底层原理。包括Eureka、Ribbon、Feign、Hystrix和Zuul这几个组件。 业务场景介绍​ 文章先假定一个业务场景：现在开发一个电商系统，要实现支付订单的功能，流程如下： 创建一个订单之后，如果用户立刻支付了这个订单，我们需要将订单状态更新为“已支付” 扣减相应的商品库存 通知仓储中心，进行发货 给用户的这次购物增加相应的积分 针对上述流程，我们需要有订单服务、库存服务、仓储服务、积分服务。整个流程的大体思路如下： 用户针对一个订单完成支付之后，就会去找订单服务，更新订单状态 订单服务调用库存服务，完成相应功能 订单服务调用仓储服务，完成相应功能 订单服务调用积分服务，完成相应功能 如图所示： SpringCloud核心组件：Eureka​ Eureka是微服务架构中的注册中心，主要功能是服务注册与发现和心跳检测与故障。在上述场景中，订单服务不知道其他其他服务在哪台机器上，此时就需要一个注册中心，来管理各个服务的地址，如图所示： ​ 如上图所示，所有服务都有一个Eureka Client组件，这个组件专门负责将这个服务的信息注册到Eureka Server中，也就相当于告诉了Eureka Server自己在哪台服务器上，监听这哪个端口。而Eureka中维护了一个注册表，保存着各个服务的机器和端口号。 ​ 新增服务、下线服务都是直接操作Eureka-Server的注册表的，而注册表变更时为了并发安全是会加锁操作的（使用ReentrantReadWriteLock）然后注册表一变更，立刻清楚掉ReadWrite缓存的数据，并重新写入新数据。服务从ReadOnlyCache上拉取服务 ，并缓存到本地。而Eureka-Server采用两个缓存，是为了避免并发冲突。 ​ 假设没有ReadOnlyCacheMap，万一刚好注册表发生变更的时候，ReadWriteCacheMap会被失效掉，所以客户端的请求也就直接来读注册表了，会涉及到锁的操作，弄了个ReadOnlyCacheMap可以大大减少锁操作发生的概率。 ​ 假设没有ReadWriteCacheMap，那么ReadOnlyCacheMap每隔30秒刷新的时候就只能跟注册表比较了，如果此时注册表也发生了变更，也会涉及到锁的操作，因为ReadWriteCacheMap的存在（因为ReadWriteCacheMap是每隔180秒才会主动失效一次）也可以大大减少这个锁操作发生的概率。 ​ 除了服务注册与发现之外，Eureka还有检测心跳的功能，以此来判断那台机器出现故障。Eureka-Client默认每30秒想Eureka发送一次心跳，而Eureka-Server会有专门的线程来检测心跳。 ​ 总结一下：Eureka拥有服务注册与发现、心跳检测与故障等功能。其中： Eureka-Client：负责将这个服务的信息注册到Eureka Server中 Eureka-Server：注册中心，里面有注册表和两个缓存，保存了各个服务所在的机器和端口。 SpringCloud核心组件：Feign​ 通过Eureka我们知道了各个服务在哪里，但如何向其他服务发起请求呢，这个就是Feign的作用。如下所示： 1234567@Component@FeignClient("tensquare-user")public interface UserClient &#123; @RequestMapping(value = "/user/incfollow/&#123;userid&#125;/&#123;x&#125;", method = RequestMethod.POST) public void incFollowcount(@PathVariable("userid")String userid, @PathVariable("x") int x);&#125; ​ 通过使用Feign，直接就是用注解定义一个FeignClient接口，然后调用那个接口就可以了，FeignClient会在底层根据你的注解，跟你指定的服务建立连接、构造请求、发起请求、获取响应、解析响应等等。 ​ 而Feign之所以能实现这些功能，关键的机制是使用了动态代理。我们根据下图来分析： 首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理 接着你要是调用按个接口，本质上就是调用Feign创建的动态代理，这是核心中的核心 Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的地址。 最后针对这个地址，发起请求，解析响应 SpringCloud核心组件：Ribbon​ 如果库存系统部署子在了五台机器上，Feign怎么知道该请求哪台机器呢。这时SpringCloud Ribbon就派上永用处了。它的作用是负载均衡，会帮你在每次请求时选择一台机器，均匀的把请求分发到各个机器上。 ​ Ribbon的负载均衡默认使用的是Round Robin轮询算法。就是说如果订单服务对库存系统发起10次请求，那就先让你请求第1台机器。然后是第2台、第3台，第4、第5，然后再来一个循环，第1、第2。。。以此类推。 ​ 此外，Ribbon和Feign以及Eureka紧密协作而完成工作的，具体如下： 首先Ribbon会从Eureka-Client获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口。 然后Ribbon就可以使用默认的Round Robin算法，从中选择一台。 Feign就会针对这台机器，构造并发起请求。 SpringCloud核心组件：Hystrix​ 在微服务架构里，一个系统会有很多的服务，以本文的业务场景为例：订单服务在一个业务流程里需要调用三个服务。现在假设订单服务有100个线程可以处理请求，然后积分服务不幸挂了，每次订单服务调用积分服务的时候，都会卡住几秒，然后抛出一个超时异常。这样会导致几个问题： 1、如果系统处于高并发的场景下，大量请求涌过来的时候，订单服务的100个线程都会卡在请求积分这块，导致订单服务没有一个线程可以处理请求。 2、然后就会导致别人请求订单服务的时候，发现订单服务也挂了，不响应任何请求了。 这就是微服务架构中的服务雪崩问题。这么多服务互相调用，要是不做任何保护的话，某一个服务挂了，就会引起连锁反应，导致别的服务也挂了。 ​ 但就算积分系统挂了，订单服务也可以不用挂啊。结合业务来看，支付订单的时候，只要把库存减了，然后通知仓库发货就可以了；如果积分系统挂了，大不了恢复之后，再手工恢复数据，不应该因为一个积分服务挂了，就直接导致订单服务也挂了。 ​ 这个时候就要使用Hystrix了。Hystrix是隔离、熔断以及降级的一个框架。就是Hystrix会搞很多个小小的线程池，例如订单服务请求库存服务是一个线程池，请求仓储服务是一个线程池，请求积分服务是一个线程池，每个线程池里的线程就仅仅用于请求哪个服务。 ​ 比如积分系统挂了，会导致订单服务里的那个调用积分服务的线程都卡死不能工作了，但是由于订单服务调用库存系统、仓储系统的这两个线程池都是正常工作的，所以这两个服务不会受到任何影响。 ​ 这个时候如果别人请求订单服务，订单服务还是可以正常调用库存服务扣减库存，调用仓储服务通知发货。只不过调用积分服务的时候，每次都会报错。但是如果积分服务都挂了，每次调用都要去卡住几秒钟干啥呢？有意义吗？当然没有！所以我们直接对积分服务熔断不就得了，比如在5分钟内请求积分服务直接就返回了，不要去走网络请求卡住几秒钟，这个过程，就是所谓的熔断！ ​ 而且积分系统挂了，我们还可以来个降级：每次调用积分服务，你就在数据库里记录一条消息，说给某某用户增加了多少积分，因为积分服务挂了，导致没增加成功！这样等积分服务恢复了，你可以根据这些记录手工加一下积分。这个过程，就是所谓的降级。 SpringCloud的核心组件：Zuul​ 说完了Hystrix，接着给大家说说最后一个组件：Zuul，也就是微服务网关。这个组件是负责网络路由的。不懂网络路由？行，那我给你说说，如果没有Zuul的日常工作会怎样？ ​ 假设你后台部署了几百个服务，现在有个前端兄弟，人家请求是直接从浏览器那儿发过来的。打个比方：人家要请求一下库存服务，你难道还让人家记着这服务的名字叫做inventory-service？部署在5台机器上？就算人家肯记住这一个，你后台可有几百个服务的名称和地址呢？难不成人家请求一个，就得记住一个？你要这样玩儿，那真是友谊的小船，说翻就翻！ ​ 上面这种情况，压根儿是不现实的。所以一般微服务架构中都必然会设计一个网关在里面，像android、ios、pc前端、微信小程序、H5等等，不用去关心后端有几百个服务，就知道有一个网关，所有请求都往网关走，网关会根据请求中的一些特征，将请求转发给后端的各个服务。 ​ 而且有一个网关之后，还有很多好处，比如可以做统一的降级、限流、认证授权、安全，等等。 总结最后再来总结一下，上述几个Spring Cloud核心组件，在微服务架构中，分别扮演的角色： Eureka：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里 Ribbon：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台 Feign：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求 Hystrix：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题 Zuul：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存区域]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F09%2FJVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[JVM内存布局 存放类的方法区​ 这个方法区是在JDK1.8以前的版本里，代表JVM中的一块区域。主要是放从“.class”文件里加载进来的类，还会有一些类似常量池的东西放在这个区域。JDK1.8以后，这个区域改了名字，叫“Metaspace”，也叫“元空间”。 ​ 还是拿之前的代码举例，如下： 123456public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); &#125;&#125; ​ 这两个类加载后，就会放在这个方法区中， 执行代码指令用的程序计数器​ 假设我们的代码是这样： 1234567public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125; ​ 实际上这段代码先存在于“.java”后缀的文件里，但为了能让计算机看懂这段代码，需要将这个文件经过编译器编译，把“.java”后缀的源文件编译为“.class”后缀的字节码文件。这个“.class”后缀的字节码文件里，存放的就是编译好的字节码了，字节码才是计算机可以理解的一种语言。字节码大概如下： ​ 所以首先明白一点：我们写好的Java代码会被翻译成字节码，对应各种字节码指令 ​ 现在Java代码通过JVM跑起来的第一件事情就确定了，首先Java代码被编译成字节码指令，然后字节码指令一定会被一条一条地执行，这样才能实现我们写好的代码执行的效果。当JVM加载类信息到内存之后，实际就会使用自己的字节码执行引擎，去执行我们写的代码编译出来的代码指令，那么在执行字节码指令的时候，JVM就需要一个特殊的内存区域，“程序计数器”。它是用来记录当前的字节码指令位置的，也就是记录目前执行到了哪一条字节码指令。 ​ JVM是支持多个线程的，所以你写好的代码可能会开启多个线程并发执行不同的代码，所以就会有各个线程来并发的执行不同的代码指令，因此每个线程都会有自己的一个程序计数器，专门记录当前这个线程目前执行到了哪一条字节码指令。 Java虚拟机栈​ Java代码在执行的时候，一定是线程来执行某个方法中的代码，即使是下面的代码，也会有一个main线程来执行main()方法里的代码。在main线程执行main()方法的代码指令的时候，就会通过main线程对应的程序计数器记录自己执行的指令位置。 1234567public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125; ​ 但在方法里，一般会定义一些方法内的局部变量，例如上面的代码中就有一个“replicaManager”局部变量。因此JVM必须有一块保存每个方法内的局部变量等数据的，这个区域就是Java虚拟机栈。每个线程都有自己的Java虚拟机栈，比如这里的main线程就会有自己的一个Java虚拟机栈，用来存放自己执行的那些方法的局部变量。 ​ 如果线程执行了一个方法，就会对这个方法调用创建对应的一个栈帧。栈帧就有这个方法的局部变量表、操作数栈。动态链接、方法出口等信息。 ​ 比如main线程执行了main()方法，那么就会给main()方法创建一个栈帧，压入main线程的Java虚拟机栈，同时在main()方法的栈帧里，存放对应的“replicaManager”局部变量。 ​ 然后假设main()线程继续执行ReplicaManager对象里的方法，比如下面，就在“loadReplicasFromDisk”方法里定义了一个局部变量：“hasFinishedLoad”。 123456public class ReplicaManager &#123; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; &#125;&#125; ​ 那么main线程执行上面的“loadReplicasFromDish”方法时，就会为“loadReplicasFromDish”方法创建一个栈帧压入线程自己的Java虚拟机栈里面去。 ​ 接着如果“loadReplicasFromDish”方法调用了另外一个“isLocalDataCorrupt()”方法，这个方法里也有自己的局部变量，如下： 123456789101112131415public class ReplicaManager &#123; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; if(isLocalDataCorrupt()) &#123; &#125; &#125; public Boolean isLocalDataCorrupt() &#123; Boolean isCorrupt = false; return isCorrupt &#125;&#125; ​ 这个时候会给“isLocalDataCorrupt”方法又创建一个栈帧，压入线程的Java虚拟机里，而且“isLocalDataCorrupt”方法的栈帧的局部变量表里会有一个“isCorrupt”变量，这个“isLocalDataCorrupt”的局部变量，整个过程如下： ​ 接着如果“isLocalDataCorrupt”方法执行完毕，就会把“isLocalDataCorrupt”方法对应的栈帧从Java虚拟机栈里出栈；然后如果“loadReplicasFromDisk”方法也执行完毕，就会把“loadReplicasFromDisk”方法也从Java虚拟机栈里出栈、 ​ “JAVA虚拟机栈”这个组件的作用：调用执行任何方法时，都会给方法创建栈帧然后入栈，在栈帧里存放了这个方法对应的局部变量之类的数据，包括这个方法执行的其他相关信息，方法执行完毕之后出栈。 Java堆内存​ Java堆主要是存放我们在代码中创建的各种对象。 1234567public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125; ​ 上面的“new ReplicaManager()”这个代码就是创建了一个ReplicaManager类的对象实例，这个对象实例里面会包含一些数据，如下代码所示：这个“ReplicaManager”类里的“replicaCount”就是属于这个对象实例的一个数据。而类似ReplicaManager这样的对象实例就会存放在Java堆内存里。 12345678910111213141516public class ReplicaManager &#123; private long replicaCount; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; if(isLocalDataCorrupt()) &#123; &#125; &#125; public Boolean isLocalDataCorrupt() &#123; Boolean isCorrupt = false; return isCorrupt &#125;&#125; ​ Java堆内存区域里会放入类似ReplicaManager的对象，然后我们因为在main方法里创建了ReplicaManager对象，那么在线程执行main方法代码的时候，就会在main方法对应的栈帧的局部变量表里，让一个引用类型的“replicaManager”局部变量来存放ReplicaManager对象的地址。 ​ 相当于你可以认为局部变量表的“replicaManager”指向了Java堆内存里的ReplicaManager对象。 核心内存区域的全流程串讲​ 123456789101112131415161718192021222324public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125;public class ReplicaManager &#123; private long replicaCount; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; if(isLocalDataCorrupt()) &#123; &#125; &#125; public Boolean isLocalDataCorrupt() &#123; Boolean isCorrupt = false; return isCorrupt &#125;&#125; ​ 首先，你的JVM进程会启动，就会先加载Test类到内存里，然后有一个main线程，开始执行你的Test中的main()方法。main线程是关联了一个程序计数器的，他执行到哪一行指令，就会记录在这里。 ​ 其次，就是main线程执行main()方法的时候，会在main线程相关的Java虚拟机栈里，压入一个main()方法的栈帧，接着会发现需要创建一个ReplicaManager类的实例对象，此时会加载ReplicaManager类到内存里来。 ​ 然后会创建一个ReplicaManager的对象实例分配在堆内存里，并且在main()方法的栈帧里的局部变量表引入一个“replicaManager”变量，让他引用ReplicaManager对象在Java堆内存中的地址。 ​ 接着，main线程开始执行ReplicaManager对象中的方法，会依次把自己执行到的方法对应的栈帧压入自己的Java虚拟机栈。 ​ 执行完方法之后再把方法对应的栈帧从Java虚拟机栈里出栈。 其他内存区域​ 在JDK很多底层API里，比如IO相关、网络Socket相关的，很多地方都不是JAVA代码了，而是走的native方法去调用本地操作系统里面的一些方法，可能调用的都是C语言写的方法，或者一些底层类库。在调用这种native方法时，就会有线程对应的本地方法栈，这个跟Java虚拟机栈类似的，也是存放各种native方法的局部变量表之类的信息。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM类加载机制]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F07%2FJVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 JVM什么情况下会加载一个类​ 首先，我们应该清楚一个类从加载到使用，一般会经过加载–&gt;链接–&gt;初始化–&gt;使用–&gt;卸载这几个过程，其实链接阶段又可以细分为三个：验证–&gt;准备–&gt;解析。所以首先要明白的一个问题就是，JVM在执行我们代码的时候，什么时候去加载一个类呢？即什么时间会从“.class”字节码文件中加载这个类到JVM内存中？ ​ 答案就是你的代码中用到这个类的时候。 ​ 比如下面有一个类，里面有一个“main()”方法作为入口，那么一旦你的JVM进程启动之后，它一定会先把这个类加载到内存里，然后从main()方法入口的代码开始执行。 12345public class Test &#123; public static void main(String[] args) &#123; &#125;&#125; 接着上面的代码中，出现了这么一行代码： 123456public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); &#125;&#125; 这个时候，你的代码中明显需要使用“ReplicaManager”这个对象，因此会从“ReplicaManager.class”字节码中加载对应的类到内存中使用。 简单概括就是：首先你的代码中包含“main()”方法的主类一定会在JVM启动后加载到内存中，开始执行你的“main()”方法中的代码，接着遇到你使用了别的类，此时就会从对应的“.class”字节码文件中加载对应的类到内存里来。 从使用角度出发，来看验证、准备和初始化的过程1、验证阶段​ 简单来说，这一步即使根据JAVA虚拟机规范，来检验你加载进来的“.class”文件中的内容，是否符合指定的规范。 2、准备阶段​ 一般情况下，我们写好的类，都有一些类变量，如下： 1234public class ReplicaManager &#123; public static int flushInterval;&#125; ​ 假设有这么一个类“ReplicaManager”，它的“ReplicaManager.class”，刚被加载到内存之后，会被进行验证，确认这个验证码是符合规范的。接着就会进行准备工作。这个准备工作，就是给这个“ReplicaManager”类分配一定的内存空间，然后给他里面的类变量（也就是static修饰的变量）分配内存空间，来一个默认的初始值。比如上面的“flushInterval”这个类变量分配的内存空间，会给一个“0”初始值。 3、解析阶段​ 这个阶段，实际上就是把符合引用替换为直接引用的过程 4、三个阶段的小结​ 这三个阶段中，最核心的就是“准备阶段”，这个阶段是给加载进来的类分配好了内存空间，类变量也分配好了内存空间，并且给了默认的初始值。 核心阶段：初始化​ 上面说过，在准备阶段，会把我们的“ReplicaManager”类给分配好内存空间。另外的一个类变量“flushInterval”也会给一个默认的初始值“0”。那么接下来，在初始化阶段，就会正式执行我们的类初始化的代码了。 ​ 那什么是类初始化代码呢？看看以下代码 12345public class ReplicaManager &#123; public static int flushInterval = Configuration.getInt("replica.flush.interval");&#125; 通过以上代码我们可以知道，这个类变量，我们是通过Configuration.getInt(“replica.flush.interval”)这段代码来获取一个值，并且赋值给他的。但是这个赋值逻辑并不在准备阶段执行，在准备阶段，仅仅是给这个类变量开辟一个内存空间，然后给个初始值“0”而已。 ​ 而这段赋值的代码，则是在“初始化”阶段来执行。在该阶段，代码Configuration.getInt(“replica.flush.interval”)会在这里执行，完成一个配置项的读取，然后赋值给这个类变量“flushInterval”。 另外比如下面的static静态代码块，也会在这个阶段执行。 123456789101112131415public class ReplicaManager &#123; public static int flushInterval = Configuration.getInt("replica.flush.interval"); private static Map&lt;String, Object&gt; replicas; static &#123; loadReplicaFromDish(); &#125; public static void loadReplicaFromDish() &#123; this.replicas = new HashMap&lt;String, Object&gt;(); &#125;&#125; 什么时候会初始化一个类​ 一般来说有一下时机：比如“new ReplicaManager()”来实例化类的对象，此时就会触发类的加载到初始化全过程，把这个类准备好，然后再实例化一个对象出来； ​ 或者是包含“main”方法的主类，必须是立马初始化的。 ​ 这里还有一个非常重要的规则，就是如果初始化一个类的时候，发现它的父类还没初始化，那么先必须初始化它的父类。 类加载器和双亲委派机制​ 上述的过程中，都必须依赖类加载器来实现，Java里主要有几种类加载器 1、启动类加载器（Bootstrap ClassLoader）​ 它主要负责加载我们机器上安装的java目录下的核心类，比如Object、System、String等。 2、扩展类加载器（Extension ClassLoader）​ 用于加载一些扩展的系统类，比如XML、加密、压缩相关的功能类等。JDK9之后变成了平台类加载器，即Platform ClassLoader。 3、应用类加载器（Application ClassLoader）​ 主要是加载用户定义的CLASSPATH路径下的类。 4、自定义类加载器​ 除了上面几种之外，还可以自定义类加载器，去根据你自己的需求加载你的类。 双亲委派机制​ 低层次的当前类加载器，不能覆盖更高层次类加载器已经加载的类。如果低层次的类加载器想加载一个未知类，要礼貌地向上级询问：“请问这个类已经加载了吗”？被询问的高层次类加载器会自问两个问题：第一，我是否已加载过此类？第二，如果没有，是否可以加载此类？只有当所有高层次类加载器在两个问题上的答案均为“否”时，才可以让当前类加载器加载这个未知类。 ​ 简单地讲，所谓的双亲委派模型：先找父亲去加载，不行的话再由儿子来加载。 最后总结]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo的负载均衡策略、集群容错策略和动态代理策略]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F07%2Fdubbo%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5%E5%92%8C%E9%9B%86%E7%BE%A4%E5%AE%B9%E9%94%99%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[本节思维导图 dubbo的负载均衡策略random loadbalance​ 随机调用实现负载均衡。这是dubbo默认的负载均衡策略。可以对provider设置不同的权重，会按照权重来负载均衡，权重大分配流量越高。一般使用这个策略即可。 roundrobin loadbalance​ 均匀地将流量打到各个机器上，但如果各个机器性能不一样，容易导致性能差的机器负载过高，所以此时需要调整权重，让性能差的机器承载比较小的流量。 leastactive loadbalance​ 这个就是自动感知一下，某个机器的性能越差，接收的流量就越小，就越不活跃，此时就会给不活跃性能差的机器更小的请求。 consistentHash loadbalance​ 一致性哈希算法，相同参数的请求一定分发到一个provider上去，provider挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。如果你需要的不是随机负载均衡，是要一类请求都到一个节点，那就使用这个一致性哈希算法。 dubbo集群容错策略failover cluster模式失败自动切换，自动重试其他机器，默认使用这个，常见于读操作。（失败重试其他机器） 可以通过以下几种方式配置重试次数： 1&lt;dubbo:service retries="2" /&gt; 或者 1&lt;dubbo:reference retries="2" /&gt; 或者 123&lt;dubbo:reference&gt; &lt;dubbo:method name="findFoo" retries="2" /&gt;&lt;/dubbo:reference&gt; failfast cluster模式一次调用失败就立即失败，常用与非幂等性的写操作，比如新增一条记录（调用失败就立即失败） failsafe cluster模式出现异常时忽略掉，常用与不重要的接口调用，比如日志记录。 配置示例如下： 1&lt;dubbo:service cluster="failsafe" /&gt; failsafe cluster模式 或者 1&lt;dubbo:reference cluster="failsafe" /&gt; failback cluster模式失败了后台自动记录请求，然后定时重发，比较适合于写消息队列。 forking cluster模式并行调用多个provider，只要一个成功立即返回，常用于实时性要求比较高的读操作，但是会浪费更多的服务资源，可以通过forks=”2”来设置最大并行数。 broadcast cluster模式逐个调用所有的provider，任何一个provider出错则报错。通用用于通知所有provider更新缓存或日志等本地资源信息。 dubbo动态代理策略默认使用javassist动态字节码生成，创建代理类。但是可以通过spi扩展机制配置自己的动态代理策略。]]></content>
      <categories>
        <category>分布式</category>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo支持的通信协议、序列化协议以及hession的数据结构]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F06%2Fdubbo%E6%94%AF%E6%8C%81%E7%9A%84%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E3%80%81%E5%BA%8F%E5%88%97%E5%8C%96%E5%8D%8F%E8%AE%AE%E4%BB%A5%E5%8F%8Ahession%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[本节思维导图 dubbo支持的通信协议dubbo协议​ 默认就是走dubbo协议，单一长连接，进行的是NIO异步通信，基于hession作为序列化协议。使用的场景是：传输数据量小（每次请求在100kb以内），但是并发量高。 ​ 为了支持高并发场景，一般是服务提供者就几台机器，但是服务消费者有上百台，可能每天调用量达到上亿次，此时用长连接是最合适的，就是跟每个服务消费者维持一个长连接即可，可能总共就100个连接，然后后面直接基于长连接NIO异步通信，可以支撑高并发请求。 ​ 长连接，通俗讲就是建立连接后可以持续发送请求，无须再建立连接。 ​ 而短连接，每次要发送请求之前，需要先重新建立一次连接。 rmi协议​ 走JAVA二进制序列化，多个短连接，适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。 hession协议​ 走hession序列化协议，多个短连接，适用于提供者数量比消费者数量还多的情况，适用于文件传输，一般较少用。 http协议​ 走JSON序列化 webService​ 走SOAP文本序列化 dubbo支持的序列化协议​ dubbo默认的序列化协议是hession序列化协议，除此之外还支持java二进制协议、json和SOAP文本序列化等多种序列化协议。 hession数据结构​ hession的数据结构可以分为三类型：8种基本原始类型、3种递归类型和1中特殊类型 8种基本原始类型 原始二进制数据 64-bit date（64位毫秒值日期） 64-bit double 64–bit long 32-bit int boolean null UTF-8 编码的string 3种递归类型 list for lists and arrays map for maps and dictionaries object for objects 1种特殊类型 ref：用于表示对共享对象的引用 为什么PB的效率是最高的​ protocol buffer是Google出品的一种轻量并且高效的结构化数据存储格式，性能要比JSON和XML高得多。它性能高主要有两个原因：一是，它使用protocol编译器，自动进行序列化和反序列化，速度非常快，差不多比XML和JSON快上了20~100倍；第二，它的数据压缩效果好，它序列化后的数据量体积小，因为体积小，传输起来带宽和速度上会有优化。]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的缓存穿透、缓存击穿、缓存雪崩、热点数据失效问题及解决方案]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F05%2FRedis%E7%9A%84%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 在我们的平常的项目中多多少少都会使用到缓存，因为一些数据我们没有必要每次查询的时候都去查询到数据库。特别是高 QPS 的系统，每次都去查询数据库，对于你的数据库来说将是灾难。但缓存使用不当，也会引起灾难。 缓存穿透什么是缓存穿透​ 正常情况下，我们去查询的数据都是存在。但如果请求去查询一条数据库根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。这种查询不存在数据的现象称为缓存穿透。 缓存穿透带来的问题​ 如果有黑客对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库中，可能会导致你的数据库由于压力太大而宕机。 解决方案1、缓存空值​ 之所以会穿透，是因为缓存中没有存储这些空数据的key，从而导致每次查询都到数据库去了。因此我们可以为这些key对应的值设置null丢到缓存里面去，后面再出现查询这个key的请求的时候，就直接返回null。不过要设置过期时间。 2、布隆过滤器​ 这种方式在大数据场景应用比较多，比如Hbase中使用它去判断数据是否在磁盘上，还有在爬虫场景判断URL是否已经被爬取。 ​ 这种方案可以加在第一种方案中，在缓存之前再加一层布隆过滤器，在查询的时候先去布隆过滤器查询key是否存在，如果不存在就直接返回，存在再走查缓存和数据库。 3、用户鉴权​ 这种情况有可能是黑客进行恶意攻击，因此我们可以在系统中增加用户鉴权校验或者在接口层增加校验，直接拦截不正常的请求。 方案选择​ 对于一些恶意攻击，攻击带过来的大量的key是不存在的，那么我们采用第一种方案就会缓存大量不存在key的数据，此时第一种方案就不合适了，我们可以先使用第二种方案过滤掉这些key。即针对这种key异常多、请求重复率比较低的数据，我们没有必要进行缓存，使用第二种方案直接过滤掉。 缓存击穿什么是缓存击穿​ 在平常高并发的系统中，大量的请求同时查询一个key时，此时这个key刚好失效了，就会导致大量的请求打到数据库上面去，这种现象我们成为缓存击穿。 缓存击穿带来的问题​ 会造成某一时刻数据库请求里过大，压力剧增。 解决方案1、设置热点数据永不过期2、加互斥锁​ 多个线程同时去查询数据库的这条数据时，我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它，其他线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来了，就可以直接走缓存了。 缓存雪崩什么是缓存雪崩​ 缓存雪崩的情况是，在某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上。结果就是DB撑不住宕机了。 解决方案1、事前，使用集群缓存，保证缓存服务的高可用​ 这种方案是在发生雪崩前对缓存集群实现高可用，如果是使用Redis，可以使用 主从+哨兵或者Redis Cluster来避免Redis全盘崩溃的情况。 2、事中：ehcache本地缓存 + Hystrix限流&amp;降级，避免数据库被打死​ 使用ehcache本地缓存的目的也是考虑在Redis Cluster完全不可用的时候，ehcache本地缓存可以支撑一阵。 ​ 使用Hystrix进行限流&amp;降级，例如一秒来了3000个请求，我们可以设置只能有一秒1000个请求能通过这个组件，那么其他剩余的2000请求就会走限流逻辑。然后去调用我们自己开发的降级组件，比如设置一些默认值之类的，以此来保护数据库不会被大量的请求给打死。 3、事后：开启Redis持久化机制，尽快恢复缓存集群​ 一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。 解决热点数据集中失效问题什么是热点数据集中失效​ 我们在设置缓存的时候，一般会给缓存设置一个失效时间，过了这个时间，缓存就失效。对于一些热点的数据来说，当缓存失效以后会存在大量的请求过来，然后打到数据库中去，从而可能导致数据库崩溃的情况。 解决方案1、设置不同的过期时间​ 为了避免这些热点数据集中失效，那么我们在设置缓存过期时间的时候，尽量让他们失效的时间错开。例如在一个基础的时间上加上或减去一个范围内的随机值。 2、互斥锁​ 结合上面击穿的情况，在第一个请求去查询数据库的时候加一个互斥锁，其余的查询都会被阻塞住，知道锁释放，从而保护数据库。 ​ 但是因为它会阻塞其他线程，此时系统吞吐量会下降，需要结合实际的业务去考虑是否要这么做。 参考资料https://juejin.im/post/5c9a67ac6fb9a070cb24bf34]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的IO模型]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F02%2FJava%E7%9A%84IO%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[本节思维导图 同步和异步的概念：针对接口调用，API调用，服务调用等。同步调用者必须等待这个接口的磁盘读写或网络通信的操作执行完毕，调用者才可以返回，如图所示： 异步调用者调用接口后，直接就返回，不用等待磁盘读写或网络通信操作完成，而是可以去做其他事情。而这个接口如果干完了某件事，会反过来通知调用者，之前的调用成功了。这个可以通过内部机制来通知，或者通过回调函数来通知。 阻塞和非阻塞：针对的是底层底层IO操作阻塞比如我们的程序现在想要通过网络读取数据，如果是阻塞IO模式，一旦发起请求到操作系统内核去从网络中读取数据，就会阻塞在那里，必须等待网络中的数据到达之后，才能从网络中读取数据到内核，再从内核返回给程序。 非阻塞程序发送请求给内核要从网络读取数据，但是此时网络中的数据还没到，此时不会阻塞住，内核会返回一个异常信息给程序，程序可以干别的，然后不断去轮询去访问内核，看请求的数据是否读取到了。如图所示： BIO，NIO，多路复用IO，信号驱动式IO和AIOBIO​ 主要是同步阻塞IO模型，在JAVA里叫做BIO，在JDK1.4之前，在JAVA代码里调用IO相关接口，发起IO操作之后，JAVA程序就会同步等待，这个同步指的是JAVA程序调用IO API接口的层面而言。 ​ 而IO API在底层的IO操作是基于阻塞IO来的，向操作系统内核发起IO请求，系统内核会等待数据就位之后，才会执行IO操作，执行完毕了才会返回。 NIO​ 在JDK1.4之后提供了NIO，他的概念是同步非阻塞，也就是说如果你调用NIO接口去执行IO操作，其实还是同步等待，但是在底层的IO操作上，会对系统内核发起非阻塞IO请求，以非阻塞的形式来执行IO。 ​ 也就是说，如果底层数据没到位，那么内核会返回异常信息，不会阻塞住，但是NIO接口内部会采用非阻塞方式过一会儿再次调用内核发起IO请求，知道成功为止。 ​ 之所以说是同步非阻塞的，这里的“同步”指的就是因为在你的JAVA代码调用NIO接口层面是同步的，你还是要同步等待底层IO操作真正完成了才可以返回，只不过在执行底层IO的时候采用了非阻塞的方式来执行罢了。 IO多路复用模型​ 实际上，如果基于NIO进行网络通信，采取的就是多路复用的IO模型，这个多路复用IO模型针对的是网络通信中的IO场景来说的。就是在基于Socket进行网络通信的时候，如果有多个客户端跟你的服务端建立了Socket连接，你就需要维护多个Socket连接。而所谓的多路复用IO模型，就是说你的JAVA代码直接通过一个select函数（一般都是系统内核级别的函数，除此还有poll,epoll）调用，直接进入一个同步等待的状态。 ​ 这也是为什么说NIO一定是“同步”的，因为你必须在这里同步等待某个Socket连接有请求到来。接着你就要同步等着select函数去对底层的多个Socket连接进行轮询，不断地查看各个Socket连接谁有请求到达，就可以让select函数返回，交给我们的java程序处理。 ​ select函数在底层会通过非阻塞的方式轮询各个Socket，任何一个Socket如果没有数据到达，那么非阻塞的特性会立即返回一个信息。然后select函数可以轮询下一个Socket，不会阻塞在某个Socket上，所以底层是基于这种非阻塞的模式来“监视”各个Socket谁有数据到达的。 ​ 这就是所谓的“同步非阻塞”，但是因为操作系统把上述工作都封装在一个select函数调用里，可以对多路Socket连接同时进行监控，所以就把这种模型称为“IO多路复用”模型。 ​ 通过这个模型，就可以用一个线程，调用一个select函数，然后监视大量的客户端连接，如下图： 信号驱动式IO​ 首先我们允许Socket进行信号驱动IO，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，会收到一个SIGIO信号，可以在信号处理函数中调用IO操作函数处理数据，如下图所示： ​ 相比于非阻塞式IO的轮询方式，信号驱动IO的CPU利用率更高。 AIO​ 在JDK1.7之后，又支持了AIO，也就做NIO2.0，他就支持异步IO模型。 ​ 异步IO模型，就是你的Java程序可以基于AIO API发起一个请求，比如接收网络数据，AIO API底层会基于异步IO模型来调用操作系统内核。此时不惜要去管这个IO是否成功，AIO接口会直接返回，你的Java程序也会直接返回。然后，你的Java程序就可以去干别的事情了。 ​ BIO，NIO都是同步的，你发起IO请求，都必须同步等待IO操作完成，但是这里你发起一个请求，直接AIO接口就返回了，你可以干别的事情了，纯异步方法，不过需要你提供一个回调函数给AIO接口，一旦底层系统内核完成了具体的IO请求，比如网络读写之类的，就会回调你提供的回调函数。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo工作原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F31%2Fdubbo%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[本节思维导图 dubbo工作原理 第一层：service层，接口层：有服务提供者和服务消费者实现 第二层：config层，配置层：主要对dubbo进行各种配置 第三层：proxy层，服务代理层，为provider、consumer生成代理，代理之间进行网络通信 第四层：registry层，服务注册层，负责服务的注册与发现 第五层：cluster层，集群层，封装多个服务提供者的路由和负载均衡，将多个实例组合成一个服务 第六层：monitor层，监控层，对rpc接口的调用时间和调用次数进行监控 第七层：protocal层，远程调用层，封装rpc调用 第八层：exchange层，信息交换层，封装请求相应模式，同步转异步 第九层：transport层，网络传输层，抽象mina和Netty为统一接口 第十层：serialize层，数据序列化层 工作流程 第一步：provider向注册中心注册 第二步：consumer从注册中心订阅服务，注册中心通知consumer注册好的服务 第三步：consumer调用provider 第四步：consumer和provider都异步通知监控中心 dubbo架构图 注册中心挂了可以继续通信吗可以，因为刚开始初始化的时候，消费者会将提供服务的地址信息拉取到本地缓存，所以注册中心挂了可以继续通信]]></content>
      <categories>
        <category>分布式</category>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F30%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ “红灯停，绿灯行”。在这个过程中，信号灯是汽车的观察目标，汽车是观察者。随着信号灯的变化，汽车的行为也随着变化。在软件系统中，一个对象的状态或行为的变化将导致其他对象的行为或状态也发生改变，它们之间将产生联动。为了更好地描述对象之间存在的这种一对多（包括一对一）的联动，观察者模式应运而生。 ​ 观察者模式是使用频率最高的设计模式之一，用于建立一种对象与对象之间的依赖关系，一个对象发生改变时将自动通知其他对象，其他对象将相应作出反应。在观察者模式中，发生改变的对象成为观察目标，而被通知的对象成为观察者。这些观察者之间可以没有任何相互联系，可以根据需要增加和删除观察者，使得系统更易于扩展。 观察者模式定义：观察者模式：定义对象之间的一种一对多依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象皆得到通知并被自动更新。观察者模式的别名包括发布-订阅（Publish/Subscribe）模式、模型-视图（Model/View）模式、源-监听器（Source/Listener）模式或从属者（Dependents）模式。观察者模式是一种对象行为型模式。 观察者模式结构图： 在结构图中包含以下四个角色： （1）Subject（目标）：目标又称为主题，它是指被观察的对象。在目标中定义了一个观察者集合，一个观察目标可以接受任意数量的观察者来观察，它提供一系列方法来增加和删除观察者对象，同时定义了通知方法notify()。目标类可以是接口，也可以是抽象类或具体类。 （2）ConcreteSubject（具体目标）：具体目标是目标类的子类，通常包含有经常发生改变的数据，当他的状态改变时，向其各个观察者发出通知；同时它还实现了在目标类中定义的抽象业务逻辑方法（如果有的话）。如果无须扩展目标类，则目标具体类可以省略。 （3）Observer（观察者）：观察者将对观察目标的改变做出反应，观察者一般定义为接口，改接口声明了更新数据的方法update()，因此又称为抽象观察者。 （4）ConcreteObserver（具体观察者）：在具体观察者中维护一个指向具体目标对象的引用，它存储具体观察者的有关状态，这些状态需要和具体目标的状态保持一致。它实现了在抽象观察者Observer中声明的update()方法。通常在实现时，可以调用具体的目标类的attach()方法将自己添加到目标类的集合或通过detach()方法将自己从目标类的集合中删除。 观察者模式主要优缺点：1、主要优点（1）观察者模式可以实现表示层和数据逻辑层的分离，定义了稳定的消息更新传递机制，并抽象了更新接口，使得可以有各种各样不同的表示层充当具体观察者角色。 （2）观察者模式在观察目标和观察者之间建立一个抽象的耦合。观察目标只需要维持一个抽象观察者的集合，无须了解其具体观察者。由于观察目标和观察者没有紧密地耦合在一起，因此它们可以不同的抽象化层次。 （3）观察者支持广播通信，观察目标会向所有已注册的观察者对象发送通知，简化了一对多系统设计的难度。 （4）观察者模式满足开闭原则的要求，增加新的具体观察者无须修改原有系统代码，在具体观察者与观察目标之间不存在关联关系的情况下，增加新的观察目标也很方便。 2、主要缺点（1）如果一个观察目标对象有很多直接或间接观察者，将所有的观察者都通知到会花费很多时间 （2）如果在观察者和观察目标之间存在循环依赖，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 （3）观察者模式没有相应的机制让观察者知道所观察的目标是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 观察者模式使用场景：（1）一个抽象模型有两个方面，其中一个方面依赖于另一个方面，将这两个方面封装在独立的对象中使它们可以各自独立地改变和复用。 （2）一个对象的改变将导致一个或多个其他对象也发生改变，而并不知道具体有多少对象将发生改变，也不知道这些对象是谁。 （3）需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 观察者模式与MVC的关系：​ MVC是一种架构模式，它包含3个角色：模型（Model）、视图（View）和控制器（Controller）。其中，模型可应对于观察者模式中的观察目标，而视图对应于观察者，控制器可充当两者之间的中介者，当模型层的数据发生改变时，视图层将自动显示内容。 案例​ Sunny软件公司欲开发一款多人联机对战游戏（类似魔兽世界），在该游戏中，多个玩家可以加入同一战队组成联盟，当战队中某一成员受到敌人攻击时将给所有其他盟友通知，盟友收到通知后将做出响应。 ​ Sunny公司通过对系统功能需求进行分析，发现在改系统中战队成员之间的联动过程可以简单描述如下：联盟成员受到攻击–&gt;发送通知给盟友–&gt;盟友做出响应。如果按照此思路来设计系统，因为成员在受到攻击时需要通知他的每位盟友，所以每个成员都需要持有其他所有盟友的信息，这将导致系统开销较大。因此开发人员决定引入一个新的角色–“战队控制中心”来负责维护和管理每个战队所有成员的信息。当一个成员受到攻击时，向相应的战队控制中心发送求助信息，战队控制中心再逐一通知每个盟友，盟友再做出相应。如图所示： 为了实现对象之间的联动，Sunny公司决定使用观察者模式来进行多人联机对战游戏的设计，其基本结构图如图所示： 相关代码实现已上传]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis哨兵集群实现高可用]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F29%2FRedis%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[哨兵的介绍​ sentinel，也叫哨兵。哨兵是Redis集群机构中非常重要的一个组件，有以下功能： 集群监控：负责监控redis master和slave进程是否正常工作。 消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障转移：如果master node挂掉了，会自动转移到slave node上。 配置中心：如果故障转移发生了，通知client客户端新的master地址。 ​ 哨兵用于实现Redis集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。 故障转移时，判断一个master node是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。 即使部分哨兵节点挂掉了，哨兵集群还是能正常工作。 哨兵的核心知识sdown和odown转换机制 sdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，那么就是主观宕机。 odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机。 sdown达成的条件比较简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机了；如果一个哨兵在指定的时间内，收到了quorum数量的其他哨兵也认为那个master是sdown，那么就认为是odown。 quorum（法定人数）和majority​ 每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到majority哨兵的授权，才能正式执行切换。 ​ 如果quorum &lt; majority，比如5个哨兵，majority就是3， quorum设置为2，那么就需要3个哨兵授权就可以执行切换。 ​ 如果quorum &gt;= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换。 核心知识 哨兵至少需要3个实例，来保证自己的健壮性。 哨兵 + Redis主从的部署架构，是不保证数据零丢失的，只能保证redis集群的高可用性。 对于哨兵 + redis主从这种复制的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。 哨兵集群必须部署2个以上节点，如果哨兵集群仅仅部署了2个哨兵实例，quorum = 1。 ​ 配置quorum = 1，如果master宕机，两个哨兵只要有1个哨兵认为master宕机了，就可以进行切换，同时会选举出一个哨兵来执行故障转移，但是同时这个时候，需要majority个哨兵，也就是大多数哨兵是运行的。 123452 个哨兵，majority=23 个哨兵，majority=24 个哨兵，majority=25 个哨兵，majority=3... ​ 如果此时只是Master宕机，哨兵1正常运行，那么故障转移时OK的，如果是Master和哨兵1运行的机器宕机了，那么哨兵只有一个，此时就没有majority数量个哨兵来执行故障转移，虽然另外一台机器上还有一个哨兵，但是故障转移不会执行。 ​ 经典的3节点哨兵集群是这样的： ​ 配置quorum = 2，如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机了，然后选举一个来执行故障转移，同时3个哨兵的majority是2，所以还剩下2个哨兵运行着，就可以允许执行故障转移。 Redis哨兵主备切换的数据丢失问题异步复制导致的数据丢失​ 因为master -&gt; slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这部分数据就丢失了。 脑裂导致的数据丢失​ 脑裂，即某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着，此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master。这个时候，集群里就会有两个master，这就是所谓的脑裂。 ​ 此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续向旧的master写数据。因此旧master再次恢复的时候，会被作为一个master挂到新的master上去，自己的数据会清空，重新从新的master复制数据，而新的master并没有后来client写入的数据，因此这部分数据也就丢失了。 数据丢失问题的解决方案可行进行如下配置： 12min-slaves-to-write 1min-slaves-max-lag 10 表示，要求至少有1个slave，数据复制和同步的延迟不能超过10秒。 减少异步复制数据的丢失 ​ 有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低到可控范围内。 减少脑裂的数据丢失 ​ 如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定的slave发送数据，而且slave超过了10秒没有给自己（master）ack消息，那么就直接拒绝客户端的写请求，因此在脑裂的情况下，最多就丢失10秒的数据。 哨兵集群的自动发现机制​ 哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往_sentine__:hello这个channel里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知其他哨兵的存在。 ​ 每隔两秒钟，每个哨兵都会往自己监控的某个maser + slave对应的_sentinel__:hellochannel里发送一个消息，内容是自己的Host、ip和runid还有对这个master的监控配置。 ​ 每个哨兵也会去监听自己监控的每个 master+slaves 对应的 __sentinel__:hello channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。 ​ 每个哨兵还会跟其他哨兵交换对 master 的监控配置，互相进行监控配置的同步。 slave配置的自动纠正​ 哨兵会负责自动纠正slave的一些配置，比如slave如果要成为潜在的master候选人，哨兵会确保复制现有的master数据；如果slave连接到了一个错误的master上。比如故障转移后，那么哨兵会确保它们连接到正确的master上。 slave -&gt; master选举算法​ 如果一个master被认为odown，而且majority数量的哨兵都允许主备切换，那么某个哨兵就会执行住别切换操作，此时需要选举一个slave来当master，会考虑slave的一些信息： 跟master断开连接的时长 slave优先级 复制offset run id ​ 如果一个slave跟master断开连接的时间已经超过了down-after-milliseconds的10倍，外加master的宕机的时长，那么slave就被认为不适合选举为master 1(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state ​ 接下来会对slave进行排序： 按照slave优先级进行排序，slave priority越低，优先级越高。 如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高。 如果上面两个条件都相同，那么选一个run id比较小的那个。 configuration epoch​ 哨兵会对一套redis master + slaves进行监控，有相应的监控配置。 ​ 执行切换的那个哨兵，会从要切换到新的master（slave -&gt; master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一。 ​ 如果第一个选举出的哨兵切换失败，那么其他哨兵，就会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号。 configuration传播​ 哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前说的pub/sub消息机制。 ​ 这里之前的version号就很重要了，以为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的。其他的哨兵都是根据版本号的大小来跟新自己的master配置的。]]></content>
      <categories>
        <category>分布式</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UML之类之间的关系]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F27%2FUML%E4%B9%8B%E7%B1%BB%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[​ 在软件系统中国，类并不是孤立存在的，类与类之间存在各种关系，对于不同类型的关系，UML提供了不同的表示方式。 关联关系​ 关联关系是类与类之间最常用的一种关系，它是一种结构化关系，用于表示一类对象与另一类对象之间有联系，如汽车和轮胎，师傅和徒弟，班级和学生等。在UML类图中，用实现连接有关联关系的对象所对应的类。 ​ 例如现在一个登陆界面类LoginForm中包含一个JButton类型的注册按钮loginButton，它们之间可以表示为关联关系，代码实现时可以在LoginForm中定义一个名为loginButton的属性对象，其类型为JButton，如图所示： 对应的JAVA代码片段如下： 1234567891011public class LoginForm &#123; //定义成员变量 private JButton loginButton; ...&#125;public class JButton &#123; ...&#125; ​ 在UML中，关联关系又包含如下几种形式。 双向关联​ 默认情况下，关联是双向的。例如顾客购买商品并拥有商品，反之，卖出的商品总有某个顾客与之关联。因此，Customer类和Product类之间具有双向关联关系，如图所示： ​ 对应的代码片段如下： 123456789101112public class Customer &#123; private Product[] products; ...&#125;public class Product &#123; private Customer customer; ...&#125; 单向关联​ 类的关联关系也可以是单向的，在UML中单向关联关系用带箭头的实线表示。例如，顾客拥有地址，则Customer类与Address类具有单向关联关系，如图所示： ​ 对应的代码如下： 1234567891011public class Customer &#123; private Address address; ...&#125;public class Address &#123; ...&#125; 自关联​ 在系统中可能会存在一些类的属性对象类型为该类本身，这种特殊的关联关系成为自关联。例如，一个节点类（Node）的成员又是节点Node类型的对象，如图所示： ​ 对应的代码如下： 123456public class Node &#123; private Node subNode; ...&#125; 多重性关联​ 多重性关联关系又称为重数性（Multiplicity）关联关系，表示两个关联对象在数量上的对应关系。在UML中，对象之间的多重性可以直接在关联直线上用一个数字或一个数字范围表示。 ​ 对象之间可以存在多种多重关联惯性，常见的多重性表示方法如下表： 表示方式 多重性说明 1.. 1 表示另一个类的一个对象只与改类的一个对象有关系 0.. * 表示另一个类的一个对象与该类的零个或多个对象有关系 1.. * 表示另一个类的一个对象与该类的一个或多个对象有关系 0.. 1 表示另一个类的一个对象没有或只与改类的一个对象有关系 m.. n 表示另一个类的一个对象与该类最少m，最多n个对象有关系（m &lt;= n） ​ 例如，一个界面可以拥有零个或多个按钮，但是一个按钮只能属于一个界面。因此，一个Form类的对象可以与零个或多个Button类的对象相关联，但一个Button类的对象只能与一个Form类的对象关联，如图所示： ​ 对应的代码如下： 123456789101112public class Form &#123; //定义一个集合对象 private Button[] buttons; ...&#125;public class Button &#123; ...&#125; 聚合关系​ 聚合关系表示整体与部分的关系。在聚合关系中，成员对象是整体对象的一部分，但是成员对象可以脱离整体对象独立存在。在UML中，聚合关系用带空心菱形的直线表示。例如，汽车发送机是汽车的组成部分，但是汽车发送机可以独立存在，因此，汽车和发送机是聚合关系，如图所示： ​ 在代码实现聚合关系时，成员对象通常作为构造方法、Setter方法或业务方法的参数注入到整体对象中，如下所示： 123456789101112131415161718192021public class Car &#123; private Engine engine; //构造注入 public Car(Engine engine) &#123; this.engine = engine; &#125; //设值注入 public void setEngine(Engine engine) &#123; this.engine = engine; &#125; ...&#125;public class Engine &#123; ...&#125; 组合关系​ 组合关系也表示类之间整体和部分的关系，但是在组合关系中整体对象可以控制成员对象的生命周期，一旦整体对象不存在，成员对象也将不存在，成员对象与整体对象之间具有同生共死的关系。在UML中，组合关系用带实心菱形的直线表示。例如，人的头（Head）与嘴巴（Mouth），嘴巴是头的组成部分之一，而且如果头没了，嘴巴也就没了，因此头和嘴巴是组合关系，如图所示： ​ 在代码实现组合关系时，通常在整体类的构造方法中直接实例化成员类，如下所示： 123456789101112131415public class Head &#123; private Mouth mouth; public Head() &#123; mouth = new Mouth(); &#125; ...&#125;public class Mouth &#123; ...&#125; 依赖关系​ 依赖关系是一种使用关系，特定事物的改变有可能会影响到使用该事物的其他的事物，在需要表示一个事物使用另一个事物时使用依赖关系。大多数情况下，依赖关系体现在某个类的方法使用另一个类的对象作为参数。在UML中，依赖关系用带箭头的虚线表示，由依赖的一方指向被依赖的一方。例如，驾驶员开车，在Driver类的drive()方法中将Car类型的对象作为一个参数传递，以便在drive()方法中能调用Car类的move()方法，且驾驶员的drive()方法依赖车的move()方法，因此类Drive依赖类Car，如图所示： ​ 在系统实施阶段，依赖关系通常通过3种方式来实现。第1种也是最常用的一种方式是上面讲的将一个类的对象作为另一个类中方法的参数；第2种方式是在一个类的方法中将另一个类的对象作为其局部变量；第3种方式是在一个类的方法中调用另一个类的静态方法。 ​ 相应的代码如下： 12345678910111213141516public class Driver &#123; public void drive(Car car) &#123; car.move(); &#125; ...&#125;public class Car &#123; public void move() &#123; ... &#125; ...&#125; 泛化关系​ 泛化关系也就是继承关系,用于描述父类与子类之间的关系，父类又称作基类或超类，子类又称作派生类。在UML中,泛化关系用带空心三角形的直线来表示。在代码实现时,使用面向对象的继承机制来实现泛化关系，如在Java语言中使用extends关键字、在C++/C#中使用冒号“:”来实现。 ​ 相应的代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637//父类public class Person &#123; protected String name; protected int age; public void move() &#123; ... &#125; public void say() &#123; ... &#125;&#125;//子类public class Student extends Person &#123; private String stuedentNo; public void study() &#123; ... &#125;&#125;//子类public class Teacher extends Person&#123; private String teacherNo; public void teach() &#123; ... &#125;&#125; 接口与实现关系​ 在很多面向对象语言中都引人了接口的概念，如Java、C#等。在接口中,通常没有属性，而且所有的操作都是抽象的，只有操作的声明，没有操作的实现。UML中用与类的表示法类似的方式表示接口，接口之间也可以有与类之间关系类似的继承关系和依赖关系，但是接口和类之间还存在一种实现(Realization)关系。在这种关系中，类实现了接口，类中的操作实现了接口中所声明的操作。在UML中,类与接口之间的实现关系用带空心三角形的虚线来表示。 ​ 相应的代码如下所示： 1234567891011121314151617public interface Vehicle &#123; public void move();&#125;public class Ship implements Vehicle &#123; public void move() &#123; ... &#125;&#125;public class Car implements Vehicle &#123; public void move() &#123; ... &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP的基础概念]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F25%2FHTTP%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[本节思维导图 URIURI(Uniform Resource Identifier)统一资源标识符，其中包括两个部分：URL(Uniform Resource Locator)统一资源定位符和URN(Uniform Resource Name)统一资源名称。 HTTP方法客户端发送的请求报文的第一行为请求行，包含了方法字段。 GET 获取资源 HEAD 获取报文首部 和GET方法类似，但不返回报文实体主体部分。主要用于确认URL的有效性和资源更新的日期时间等。 POST 传输实体主体 POST主要用来传输数据，GET只要用来获取资源 PUT 上传文件 由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法 PATCH 对资源进行部分修改 PUT也可以用于修改资源，但是只能完全替代原始资源，PATCH允许部分修改。 DELETE 删除文件 与PUT功能相反，并且同样不带验证机制 OPTIONS 查询支持的方法 查询指定的URL能够支持的方法。会返回Allow:GET, POST, HEAD, OPTIONS 这样的内容 CONNECT TRACE]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列优缺点]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F24%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%BC%98%E7%BC%BA%E7%82%B9%2F</url>
    <content type="text"><![CDATA[本节思维导图 消息队列的优点消息队列主要有三个优点：解耦、异步和削峰 削峰假设一个业务场景如图所示，A系统分别发送信息给B C D系统，此时系统的耦合性比较高，当需求改变要求不给D系统发送消息，或者增加一个E系统也需要A系统发送数据，那么我们就不得不去修改A系统的代码。除此之外如果其他系统挂了，同样也会影响到A系统，如果引入MQ，那么A系统就只需要把数据放进MQ中，由需要这个数据的系统去订阅这个MQ，这样就可以实现系统解耦。这样A系统不仅不需关系哪个系统需要这个消息，也不需要关心消息发送失败或者超时等情况。 总结：通过MQ，Pub/Sub发布订阅消息模型，A系统就跟其他系统解耦了。 异步业务场景如图所示，用户向A系统发起请求，需要在本地写数据库，还需要在B C D系统写数据库，假设本地写耗时10ms，如下图需要10+20+30+40共100ms。那么这样相对来说比较慢。 但如果引入MQ，假设将消息放入MQ耗时5ms，那么总共需要15ms，极大提高了响应速度。 削峰假设每天0:00-12:00系统每秒并发请求数量只有十几个，但过了12点之后，请求数量猛增到几千个，而且数据库系统是mysql，每秒最多也就执行一千多条SQL语句，这样导致mysql崩溃，但过了高峰期之后并发请求又恢复到了相对比较低的水平，对整个系统又没啥压力了。 引入MQ之后，A系统每秒中只能处理一千个SQL，那就从MQ中取出一千个SQL去处理，这样即使在高峰的时候，A系统也不会崩溃，而在高峰期间MQ可能会有几百万的请求积压在MQ中，但这个短暂的高峰的积压是允许，等高峰期一过，MQ积压的数据就能够迅速被处理。 消息队列的缺点缺点有以下几个： 系统可用性降低引入的外部依赖越多，风险就越高。本来只是调用几个系统的接口就可以了，现在引入MQ之后，如果MQ挂了，整个系统就崩溃了。 系统复杂性提高引入MQ之后，需要考虑很多问题。例如如何保证消息传递的顺序，保证消息没有重复消费和怎么处理消息丢失的情况。 数据一致性问题A系统将数据放到MQ将返回成功了，但如果B系统数据丢失了，那就会造出数据不一致了。 ActiveMQ、RabbitMQ、RocketMQ和kafka有什么优缺点 特性 ActiveMQ RabbitMQ RocketMQ kafka 单机吞吐量 万级，比RocketMQ、kafka低一级 同ActiveMQ 10万级，支撑高吞吐 10万级，高吞吐，一般配合大数据类的系统机型实时数据计算，日志采集等场景 topic数量对吞吐量的影响 topic可以达到几百/几千的级别，这是RocketMQ的优势，在同等机器下，可以支撑大量的topic topic从几十到几百个左右的时候，吞吐量会大幅度下降，kafka尽量保证topic数量不要过多，如果要支撑大规模的topic，需要增加更多的机器资源 时效性 ms级 微秒级，这是RabbitMQ的一大特点，延迟最低 ms级 延迟在ms级以内 可用性 高，基于主从架构实现高可用 同ActiveMQ 非常高，分布式架构 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 基本不丢 经过参数优化配置，可以做到0丢失 同RocketMQ 功能支持 MQ领域的功能极其完备 基于erlang开发，并发能力很强，性能极好，延时很低 MQ功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用 综上，各种对比之后，有如下建议： 一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了； 后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高； 不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hello</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的过期策略和内存淘汰机制]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F21%2FRedis%E7%9A%84%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E5%92%8C%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ redis主要是基于内存来进行高性能、高并发的读写操作的。但既然内存是有限的，例如redis就只能使用10G，你写入了20G。这个时候就需要清理掉10G数据，保留10G数据。那应该保留哪些数据，清除哪些数据，为什么有些数据明明过期了，怎么还占用着内存？这都是由redis的过期策略来决定的。 redis过期策略​ redis的过期策略就是：定期删除 + 惰性删除。 ​ 定期删除，指的是redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查是否过期，如果过期就删除。 ​ 假设redis里放了10W个key，都设置了过期时间，你每隔几百毫秒就检查全部的key，那redis很有可能就挂了，CPU负载会很高，都消耗在检查过期的key上。注意，这里不是每隔100ms就遍历所有设置过期时间的key，那样就是一场性能灾难。实际上redis是每隔100ms就随机抽取一些key来检查和删除的。 ​ 定期删除可能会导致很多过期的key到了时间并没有被删除掉。这个时候就可以用到惰性删除了。惰性删除是指在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间并且已经过期了，此时就会删除，不会给你返回任何东西。 ​ 但即使是这样，依旧有问题。如果定期删除漏掉了很多过期的key，然后你也没及时去查，也就没走惰性删除。此时依旧有可能大量过期的key堆积在内存里，导致内存耗尽。 ​ 这个时候就需要内存淘汰机制了。 内存淘汰机制​ redis内存淘汰机制有以下几个： noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。这个一般很少用。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key，这个是最常用的。 allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。 LRU算法​ 上面的内存淘汰机制中，用到的是LRU算法。什么是LRU算法？LRU算法其实就是上面说的最近最少使用策略。实现LRU算法，大概的思路如下： ​ 维护一个有序单链表，越靠近链表尾部的节点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表： 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的节点，并将其从原来的位置删除，然后再插入到链表的头部。 如果此数据没有在缓存链表中，又可以分为两种情况： 如果此时缓存未满，则将此节点直接插入到链表的头部； 如果此时缓存已满，则链表尾节点删除，将新的数据节点插入链表的头部。 ​ 这就就实现了LRU算法。 ​ 当然我们也可以基于Java现有的数据结构LinkedHashMap手撸一个。LinkHashMap本质上是一个Map与双向链表的结合，比起上述的单链表，效率更高。代码如下： 1234567891011121314151617181920class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int CACHE_SIZE; /** * 传递进来最多能缓存多少数据 * * @param cacheSize 缓存大小 */ public LRUCache(int cacheSize) &#123; // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。 super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true); CACHE_SIZE = cacheSize; &#125; @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。 return size() &gt; CACHE_SIZE; &#125;&#125;]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的数据结构及其应用场景]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F21%2FRedis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[本节思维导图 redis主要有以下几种数据类型： string hash list set sorted set string这是最简单的类型，就是普通的set和get，做简单的KV缓存 1set college gpnu hash这个是类似map的一种结构，一般是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他对象）给缓存在redis里，然后每次读写缓存的时候，就可以操作hash里的某个字段。 1234hset person name bingohset person age 20hset person id 1hget person name 12345person = &#123; "name": "bingo", "age": 20, "id": 1&#125; listlist是有序列表。可以通过list存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的。 还可以通过lrange命令，读取某个闭区间内的元素，可以基于list实现分页查询，基于redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走 12# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。lrange mylist 0 -1 123456lpush mylist 1lpush mylist 2lpush mylist 3 4 5# 1rpop mylist setset是无序集合，自动去重。 直接基于set将系统里需要去重的数据扔进去，自动就去去重了。如果你需要对一些数据进行快速的全局去重，如果是单机系统就可以基于Java的HashSet进行去重，如果你的某个系统部署在多台机器上，就可以基于redis进行全局的set去重。 可以基于set玩交集、并集、差集的操作。比如交集，可以把两个人的粉丝列表整一个交集，看看两人的共同好友是谁。或者把两个大V的粉丝放在两个set中，对两个set做交集。 1234567891011121314151617181920212223242526272829303132#-------操作一个set-------# 添加元素sadd mySet 1# 查看全部元素smembers mySet# 判断是否包含某个值sismember mySet 3# 删除某个/些元素srem mySet 1srem mySet 2 4# 查看元素个数scard mySet# 随机删除一个元素spop mySet#-------操作多个set-------# 将一个set的元素移动到另外一个setsmove yourSet mySet 2# 求两set的交集sinter yourSet mySet# 求两set的并集sunion yourSet mySet# 求在yourSet中而不在mySet中的元素sdiff yourSet mySet sorted setsorted set是排序的set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序 12345678910zadd board 85 zhangsanzadd board 72 lisizadd board 96 wangwuzadd board 63 zhaoliu# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）zrevrange board 0 3# 获取某用户的排名zrank board zhaoliu]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
</search>
