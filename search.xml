<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[初步了解 InnoDB 存储引擎的架构设计]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F26%2F%E5%88%9D%E6%AD%A5%E4%BA%86%E8%A7%A3-InnoDB-%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[我们知道，MySQL 最常用的就是 InnoDB 存储引擎，那么我们今天借助一条更新语句的执行，来初步地了解一下 InnoDB 存储引擎的架构设计。 首先假设我们一条 SQL 语句： 1UPDATE users SET name = &apos;xxx&apos; WHERE id = 10 首先我们的系统通过一个数据库连接发送到 MySQL 上，然后经过 SQL 接口、解析器、优化器、执行器几个环节，解析 SQL 语句，生成执行计划，接着由执行器去负责这个计划的执行，调用 InnoDB 存储引擎的接口去执行。所以如下图，大致会走下图的这个流程： 接下来我们看一下这个存储引擎里的架构设计，以及如何基于存储引擎完成一条更新语句的执行。 InnoDB 的重要内存结构：缓冲池InnoDB 存储引擎中有一个非常重要的放在内存里的组件，就是缓冲池（Buffer Pool），这里面会缓冲很多的数据，以便于以后在查询的时候，如果内存缓冲池里有数据，就可以不用去查磁盘了。 引擎执行更新语句的时候，比如对 “id = 10” 这一行数据，它其实会将 “id = 10” 这一行数据看看是否在缓冲池里，如果不在的话，那么会直接从磁盘里加载到缓冲池里来，而且接着会对这行记录加独占锁。因为在我们更新 “id = 10” 的这一行数据的时候，肯定是不允许别人同时更新的，所以必须要对这行记录加独占锁。 undo 日志文件：让你更新的数据可以回滚接着，假设 “id = 10” 这行数据的 name 原来是 “zhangsan”，现在我们要更新为 “xxx”，那么此时我们得先把要更新的原来的值 “zhangsan” 和 “id = 10” 这些信息，写入到 undo 日志文件中去。 如果之前有接触过数据库的话，我们应该知道，如果我们要执行一个更新语句，要是他是在一个事务里的话，那么事务提交之前我们都是可以对数据进行回滚的，也就是把你更新为 “xxx” 的值回滚到之前的 “zhangsan” 去。所以为了考虑到未来可能要回滚数据的需要，这里会把你更新前的值写入 undo 日志文件，如图： 更新 buffer pool 中的缓存数据当我们把要更新的那行记录从磁盘文件加载到缓冲池，同时对它加锁之后，而且还要把更新前的旧值写入 undo 日志文件之后，就可以正式更新这行数据了。更新的时候，先更新缓冲池中的记录，此时这个数据就是脏数据了。这里所谓的更新内存缓冲池里的数据，意思就是把内存里的 “id = 10” 这行数据的 name 字段修改为 “xxx”。 那为什么说此时这行数据是脏数据呢？因为这个时候磁盘上 “id = 10” 这行数据的 name 字段还是 “zhangsan” ，但是内存里这行数据已经被修改了，所以就会叫它是脏数据。如图： Redo Log Buffer：万一系统宕机，如何避免数据丢失接下来，按照上图的说明，现在已经把内存里的数据进行修改，但是磁盘上的数据还没修改。那么此时万一 MySQL 所在的机器宕机了，必然会导致内存里修改过的数据丢失，这怎么解决？这个时候，就必须把对内存所做的修改写入到一个 Redo Log Buffer 里去，这也是内存里的一个缓冲区，是用来存放 redo 日志的。 所谓的 redo 日志，就是记录下来你对数据做了什么修改，比如对 “id = 10” 这行数据修改了 name 字段的值为 “xxx”，这就是一个日志。 ![redo log buffer](初步了解-InnoDB-存储引擎的架构设计/redo log buffer.png) 这个 redo 日志是用来在 MySQL 突然宕机的时候，用来恢复你更新过的数据的。 如果还没提交事务，MySQL 宕机了怎么办一般情况下，在数据库中，哪怕执行一条 SQL 语句，其实也可以是一个独立的事务，只有当你提交事务之后，SQL 语句才算执行结束。所以到目前为止，其实还没有提交事务，那么此时如果 MySQL 崩溃，必然导致内存里 Buffer Pool 中的修改过的数据丢失，同时你写入 Redo Log Buffer 中的 redo 日志也会丢失。 那么此时数据丢失要紧吗？其实不要紧，因为你一条更新语句，没提交事务，就代表它没执行成功，此时 MySQL 宕机虽然导致内存里的数据都丢失了，但是磁盘上的数据依然还停留在原样子。也就是说，”id = 1” 的那行数据的 name 字段的值还是老的值 “zhangsan”，所以此时你的这个事务就是执行失败了，没能成功完成更新，你会收到一个数据库的异常。然后当 mysql 重启之后，你会发现你的数据没有任何变化。 所以此时如果 MySQL 宕机，不会有任何问题。 提交事务的时候将 redo 日志写入磁盘中接着我们要提交一个事务了，此时就会根据一定的策略把 redo 日志从 redo log buffer 里刷入到磁盘文件里去。此时这个策略是通过 innodb_flush_log_at_trx_commit 来配置的，它又几个选项： 当这个参数的值为0时，你提交事务的时候，不会把 redo log buffer 里的数据刷入磁盘文件，此时可能你都提交事务了，结果 MySQL 宕机了，然后此时内存里的数据全部丢失。相当于你提交事务成功了，但是由于 MySQL 突然宕机了，导致内存中的数据和 redo 日志都丢失了。 当这个参数的值为1时，你提交事务的时候，就必须把 redo log 从内存刷入到磁盘文件里去，只要事务提交成功，那么 redo log 就必然在磁盘里了。 ![redo 日志](初步了解-InnoDB-存储引擎的架构设计/redo 日志.png) 那么只要提交事务成功之后，redo 日志一定在磁盘文件里，此时你肯定会有一条 redo 日志说“我此时对哪个数据做了哪些修改，比如 name 字段 修改为了 xxx 了”。 然后哪怕此时 buffer pool 中更新过的数据还没刷新到磁盘里去，此时内存里的数据是已经更新过的 “name = xxx”，然后磁盘上的数据是还没更新的 “name = zhangsan”。然后此时 MySQL 系统突然崩溃了，此时会丢失数据吗？答案是不会，因为虽然内存里的修改成 name = xxx 的数据会丢失，但是 redo 日志里已经说了，对某某数据做了修改 name=xxx，所以此时 MySQL 重启之后，它可以根据 redo 日志去恢复之前做过的修改。 最后来看看，如果 innodb_flush_log_at_trx_commit 的值是 2，那么提交事务的时候，把redo 日志写入磁盘文件对应的 os cache 缓存里去，而不是直接进入磁盘文件，可能 1 秒后才会把 os cache 里的数据写入到磁盘文件里去。 这种模式下，你提交事务之后，redo log 可能仅仅停留在 os cache 内存缓存里，没实际进入磁盘文件，万一此时你要是机器宕机了，那么 os cache 里的 redo log 就会丢失，同样会让你感觉提交事务了，结果数据丢失了。 ![os cache](初步了解-InnoDB-存储引擎的架构设计/os cache.png)]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 的架构设计]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F22%2FMySQL-%E7%9A%84%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[一般情况下，我们的系统采用数据库连接池的方法去并发访问数据库，然后数据库自己也会维护一个连接池，其中管理了各种系统跟这台数据库服务器建立的所有连接。 ![MySQL 连接](MySQL-的架构设计/MySQL 连接.png) 当我们的系统只要能从连接池获取到一个数据库连接之后，我们就可以执行增删改查的SQL语句了。但大部分人都停留在把 MySQL 当成一个黑盒的阶段，只知道执行相应的 SQL 语句就可以得到相应的结果，如果语句性能差了，就在表里建几个索引，完全当它是个黑盒子，来建表以及执行 SQL 语句。 接下来我们就要深入底层，去探索数据库的工作原理以及生产问题的优化手段。 网络连接必须让线程来处理假设我们的数据库服务器的连接池中的某个连接接收到了网络请求，假设就是一条 SQL 语句，那么由谁负责从这个连接中去监听网络请求？谁负责从网络连接里把请求数据读取出来？大家应该或多或少都知道一点，那就是网络连接必须得分配给一个线程去处理，由一个线程来监听请求以及读取请求数据，比如从网络连接中读取和解析出来一条我们的系统发送过去的 SQL 语句。如图： SQL 接口：负责处理接收到的 SQL 语句当 MySQL 内部的工作线程从一个网络连接中读取出来一个 SQL 语句之后，此时会如何执行这个 SQL 语句呢？为了执行这些 SQL 语句，去完成底层数据的增删改查，MySQL 内部提供了一个组件，就是 SQL 接口（SQL Interface），它是一套执行 SQL 语句的接口，专门用于执行我们发送给 MySQL 的那些增删改查的 SQL 语句。 因此 MySQL 的工作线程接收到 SQL 语句之后，就会转交给 SQL 接口去执行，如图： ![SQL 接口](MySQL-的架构设计/SQL 接口.png) 查询解析器：让 MySQL 能看懂 SQL 语句当工作线程将 SQL 语句交给 SQL 接口去执行，那么 SQL 接口怎么执行 SQL 语句呢？直接把 SQL 语句交给 MySQL，它能看懂和理解这些 SQL 语句吗？ 例如有这么一个 SQL 语句： 1SELECT id, name, age FROM users WHERE id = 1 这个 SQL 语句，我们用人脑是直接就可以处理一下，只要懂 SQL 语法的人，一看就知道是什么意思。但是 MySQL 自己本身也是一个系统，是一个数据库管理系统，它没直接理解这些 SQL 语句。所以这就需要一个关键的组件：查询解析器 这个查询解析器就是负责对 SQL 语句进行解析的，比如上面的那个 SQL 语句进行一些拆解，拆解成以下几个部分： 我们现在要从 “users” 表里查询数据 查询 “id” 字段的值等于 1 的那行数据 对查出来的那行数据要提取里面的 “id, name, age” 三个字段 所谓的 SQL 解析，就是按照既定的 SQL 语法，对我们按照 SQL 语句规则编写的 SQL 语句进行解析，然后理解这个 SQL 语句要干什么事情，如图所示： 查询优化器：选择最优的查询路径当我们通过解析器理解了 SQL 语句要干什么时候，接着会找查询优化器来选择一个最优的查询路径。 什么叫做最优的查询路径？举个简单的例子，就拿上面的那个 SQL 语句，现在 SQL 要干这么一件事情：我们要从 “users” 表里查询数据，查询 “id” 字段的值等于 1 的那行数据，对查出来的那行数据要提取里面的 “id, name, age” 三个字段。那到底应该怎么来实现呢？ 假设要完成这件事有以下几个查询路径（只是用于大家理解的例子，不代表真实的 MySQL 原理，但是通过这个例子，能让大家理解最优查询路径的意思）： 直接定位到 “users” 表中的 “id” 字段等于 1 的一行数据，然后查出来那行数据的 “id, name, age” 三个字段的值就可以了 先把 “user” 表中的每一行数据的 “id, name, age” 三个字段的值都查出来，然后从这批数据里过滤出来 “id” 字段等于 1 的那行数据的 “id, name, age” 三个字段 上面就是那个 SQL 语句的两种实现路径，我们会发现，要完成这个 SQL 的目标，两个路径都可以做到，但很显然感觉上是第一种查询路径更好。 所以查询优化器大概就是干这个的，它会针对你编写的几十行、几百行复制 SQL 语句生成查询路径树，然后从里面选择一条最优的查询路径处理。相当于会告诉你，你应该按照一个什么样的步骤和顺序，去执行哪些操作，然后一步一步地把 SQL 语句给完成了。 调用存储引擎接口，真正执行 SQL 语句接下来，就是把查询优化器选择的最优查询路径，也就是你到底应该按照一个什么样的顺序和步骤去执行这个 SQL 语句的计划，把这个计划交给底层的存储引擎去真正的执行。这个存储引擎是 MySQL 的架构设计中很有特色的一个环节。 真正在执行 SQL 语句的时候，要不然是更新数据，要不是查询数据，那数据会放在哪里？说到底数据库也不是什么神秘莫测的东西，可以把它理解成一个类似你平时写的图书管理系统，电信计费系统之类的系统。 数据库自己本身就是一个编程语言写出来的系统而已，然后启动之后也是一个进程，执行它里面的各种代码。所以对数据库而言，我们的数据要不是放在内存里，要不就是放在磁盘文件里，没什么特殊的地方。假设我们的数据有的放在内存里，有的放在磁盘文件里，如图： 那么问题来了，我们已经知道一个 SQL 语句要如何执行了，但是我们现在要怎么知道哪些数据在内存里，哪些数据在磁盘里，我们执行的时候是更新内存的数据，还是更新磁盘的数据，我们如果更新磁盘的数据，是先查询哪个磁盘文件，再更新哪个磁盘文件？ 是不是感觉很懵逼。这个时候就需要存储引擎了。存储引擎其实就是执行 SQL 语句的，它会按照一定的步骤去查询内存缓存数据，更新磁盘数据，查询磁盘数据等等诸如一系列的操作。如图： MySQL 的架构设计中，SQL 接口、SQL 解析器、查询优化器其实都是通用的，它就是一套组件而已。但是存储引擎的话，它是支持各种各样的存储引擎的，比如我们常见的 InnoDB、MyISAM、Memory 等等，我们是可以选择使用哪种存储引擎来负责具体的 SQL 语句执行的。当然现在 MySQL 一般都是使用 InnoDB 存储引擎的。 执行器：根据执行计划调用存储引擎的接口看完存储引擎之后，我们回过头来思考一个问题，存储引擎可以帮助我们去访问内存以及磁盘上的数据，那么是谁来调用存储引擎的接口呢？ 其实我们还漏了一个执行器的概念，这个执行器会根据优化器选择的执行方案，去调用存储引擎的接口按照一定的顺序和步骤，把 SQL 语句的逻辑给执行了。 例如，执行器可能会先调用存储引擎的一个接口，去获取 “users” 表中的第一行数据，然后判断一下这个数据的 “id” 字段的值是否等于我们期望的一个值，如果不是的话，那就继续调用存储引擎的接口，去获取 “users” 表的下一行数据。 就是基于上述的思路，执行器就会根据我们的优化器生成的一套执行计划，然后不停地调用存储引擎的各种接口去完成 SQL 语句的执行计划，大致就是不停地更新或提取一些数据出来。]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 的事务实现原理和传播机制]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F22%2FSpring-%E7%9A%84%E4%BA%8B%E5%8A%A1%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%E5%92%8C%E4%BC%A0%E6%92%AD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 事务管理是应用系统开发中必不可少的一部分。Spring 为事务管理提供了丰富的功能支持。Spring 事务管理分为编程式和声明式两种。编程式事务指的是通过编码方式实现事务；声明式事务基于 AOP，将具体的逻辑与事务处理解耦。生命式事务管理使业务代码逻辑不受污染，因此实际使用中声明式事务用的比较多。 声明式事务有两种方式，一种是在配置文件（XML）中做相关的事务规则声明，另一种是基于 @Transactional 注解的方式。本文着重介绍基于 @Transactional 注解的事务管理。 需要明确几点： 默认配置下 Spring 只会回滚运行时、未检查异常（继承自 RuntimeException 的异常）或者 Error。 @Transactional 注解只能应用到 public 方法才有效。 事务的实现原理事务的实现原理。如果说你加了一个 @Transactional 注解，此时 Spring 会使用 AOP 思想，对你的这个方法在执行之前，先去开启一个事务。执行完毕之后，根据你的方法是否报错，来决定回滚还是提交事务。 @Transactional 注解的属性介绍下面分别介绍一下 @Transactional 的几个属性 value 和 transactionManager 属性它们两个是一样的意思。当配置了多个事务管理器时，可以使用该属性指定选择哪个事务管理器。 isolation 属性事务的隔离级别，默认值为 Isolation.DEFAULT。可选的值有 Isolation.DEFAULT：使用底层数据库默认的隔离级别 Isolation.READ_UNCOMMITTED：读取未提交数据（会出现脏读，不可重复读）基本不使用 Isolation.READ_COMMITTED：读取已提交数据（会出现不可重复读和幻读） Isolation.REPEATABLE_READ：可重复读（会出现幻读） Isolation.SERIALIZABLE：串行化 tip： MySQL 默认为 REPEATABLE_READ 级别 SQL_SERVER 默认为 READ_COMMITED 级别 脏读：一个事务读取到另一个事务未提交的更新数据 不可重复读：同一事务中，多次读取同一数据返回的结果有所不同，即，后续读取可以读到另一事务已提交的更新数据 可重复读：在同一事务中多次读取数据时，能够保证所读数据一样，也就是后续读取不能读到另一事务已提交的更新数据 幻读：一个事务读到另一个事务已提交的 insert 数据。 timeout 属性事务的超时时间，默认值为 -1。如果超过该时间限制但事务还没有完成，则自动回滚事务。 readOnly 属性指定事务是否为只读事务，默认值为 false；为了忽略那些不需要事务的方法，比如读取数据，可以设置 read-only 为 true rollbackFor 属性用于指定能够触发事务回滚的异常类型，可以指定多个异常类型 noRollbackFor 属性抛出指定的异常类型，不会滚事务，也可以指定多个异常类型 propagation 属性事务的传播行为，默认值为 Propagation.REQUIRED。可选的值有： PROPAGATION.REQUIRED：如果当前没有事务，则创建一个新事务。如果当前存在事务，就加入该事务。该设置是最常用的设置。 PROPAGATION.SUPPORTS：支持当前事务，如果当前存在事务，就加入该事务。如果当前不存在事务，就以非事务执行。 PROPAGATION.MANDATORY：支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。 PROPAGATION.REQUIRE_NEW：创建新事务，无论当前存不存在事务，都创建新事务。 PROPAGATION.NOT_SUPPORTED：以非事务方式执行操作，如果当前事务存在，就把当前事务挂起。 PROPAGATION.NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。 PROPAGATION.NESTED：如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则按 REQUIRED 属性执行。 @Transactional 的 propagation 属性代码示例比如如下代码，save 方法首先调用 method1 方法，然后抛出了异常，就会导致事务回滚，如下两条数据都不会插入数据库。 1234567891011121314151617@Transactional(propagation = Propagation.REQUIRED)public void save() &#123; method1(); User user = new User("服部半藏"); userMapper.insertSelective(user); if(true) &#123; throw new RuntimeException("save 抛异常了"); &#125;&#125;public void method1() &#123; User user = new User("宫本武藏"); userMapper.insertSelective(user);&#125; 现在有需求如下，就算 save 方法的后面抛异常了，也不能影响 method1 方法的数据插入。一般方法时给 method1 加入一个新的事务，这样 method1 就会在这个新的事务中执行，原来的事务不会影响到新的事务。例如给 method1 加 propagation 属性为 Propagation.REQUIRES_NEW 的事务。 123456789101112131415161718@Transactional(propagation = Propagation.REQUIRED)public void save() &#123; method1(); User user = new User("服部半藏"); userMapper.insertSelective(user); if(true) &#123; throw new RuntimeException("save 抛异常了"); &#125;&#125;@Transactional(propagation = Propagation.REQUIRES_NEW)public void method1() &#123; User user = new User("宫本武藏"); userMapper.insertSelective(user);&#125; 运行之后，发现并没有起作用，数据也是没有插入数据库。通过查看日志发现，两个方法都是处于同一个事务中，method1 方法并没有创建一个新的事务。 通过 Spring 官方文档可以知道：在默认的代理模式下，只有目标方法由外部调用，才能被 Spring 的事务拦截器拦截。在同一个类中的两个方法直接调用，是不会被 Spring 的事务拦截器拦截，就像上面的 save 方法直接调用了同一个类中 method1 方法，method1 方法不会被 Spring 的事务拦截器拦截。可以使用 AspectJ 取代 Spring AOP 代理来解决这个问题。但是这里不展开。 为了解决这个问题，我们可以新建一个类： 123456789101112@Servicepublic class OtherServiceImpl implements OtherService &#123; @Autowired private UserMapper userMapper; @Transactional(propagation = Propagation.REQUIRES_NEW) public void method1() &#123; User user = new User("风魔小太郎"); userMapper.insertSelective(user); &#125;&#125; 然后再 save 方法中调用 otherService.method1 方法 12345678910111213141516@Autowiredprivate OtherService otherService;@Transactional(propagation = Propagation.REQUIRED)@Overridepublic void save() &#123; otherService.method1(); User user = new User("服部半藏"); userMapper.insertSelective(user); if (true) &#123; throw new RuntimeException("save 抛异常了"); &#125;&#125; 这下，otherService.method1 方法的数据插入成功，save 方法的数据未插入，事务回滚。继续查看日志： 从日志可以看出，首先创建了 save 方法的事务，由于 otherService.method1 方法的 @Transactional 的 propagation 属性为 Propagation.REQUIRES_NEW，所以接着暂停了 save 方法的事务，重新创建了 otherService.method1 方法的事务，接着 otherService.method1 方法的事务提交，接着 save 方法的事务回滚，这就印证了只有目标方法由外部调用，才能被 Spring 的事务拦截器拦截。 Spring 事务传播机制总结Spring 事务传播机制总共有 7 种，其中使用最多的应该是 PROPAGATION_REQUIRES、PROPAGATION_REQUIRES_NEW 和 PROPAGATION_NESTED。其中所谓的嵌套事务，是指外层的事务如果回滚，会导致内层的事务也回滚；但是内层的事务如果回滚，仅仅是滚回自己的代码。 比如现在有一段业务代码，方法 A 调用方法 B，我希望的是如果方法 A 出错了，此时仅仅回滚方法 A，不能回滚方法 B，这个时候可以给方法 B 使用 REQUIRES_NEW 传播机制，让他们两的事务是不同的。 如果方法 A 调用方法 B，如果出错，方法 B 只能回滚它自己，方法 A 可以带着方法 B 一起回滚。那这种情况可以给方法 B 加上 NESTED 嵌套事务。 参考资料Spring Boot 中使用 @Transactional 注解配置事务管理]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK 动态代理和 CGLIB 动态代理]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F10%2FJDK-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%E5%92%8C-CGLIB-%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[什么是动态代理动态代理即动态的代理模式，所谓动态，是指抽象类（即抽象角色）在编译期是未确定的，在运行期生成。相对的，静态代理中抽象类的行为是在编译期确定的。动态代理是 AOP（面向切面编程）常见的实现方式。 Spring 里使用 AOP，比如说你对一批和它们的方法做了一个切面，定义好了要在这些类的方法里的增强代码，那 Spring 要对那些类生成动态代理，在动态代理中去执行你定义的那些增强代码。 JDK 动态代理动态代理使用示例JDK 动态代理使用起来比较简单，只要我们掌握 Proxy.newProxyInstance 方法即可。Proxy。newProxyInstance 方法在 JDK 中定义如下： 1234567891011121314151617181920212223242526/** * 返回一个受调用处理器 (InvocationHandler) 管理，实现了指定接口的代理类的实例 * * @param loader 声明这个代理类的 ClassLoader * @param interfaces 代理类实现的接口列表 * @param h 处理代理类的调用的调用处理器 * @return 一个受调用处理器 (InvocationHandler) 管理，实现了指定接口的代理类的实例 * @throws IllegalArgumentException 违反了 getProxyClass 函数的参数限制条件 * @throws SecurityException 如果安全管理器存在并且下面的任意条件满足： * (1) 传入的 loader 是 null 且调用者的类加载器非空， * 使用 RuntimePermission("getClassLoader")权限 * 调用 SecurityManager#checkPermission禁止访问 * * (2) 对于每一个代理接口，调用者的类加载器与接口类加载器不同或不是其父类, * 并且调用 SecurityManager#checkPackageAccess 无权访问接口 * * (3) 所有传入的代理接口都是非公共的，且调用者类与非公共接口不在同一个包下， * 使用 ReflectPermission("newProxyInPackage.&#123;package name&#125;") 调用 * SecurityManager#checkPermission 无访问权限 * @throws NullPointerException interfaces 数组参数或其中的元素为 null，以及调用处理器 h 为 null */@CallerSensitivepublic static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException; 从 Javadoc 中我们可以获知，主需要传入相应的类加载器，接口，调用处理器即可产生一个代理实例，那么我们不熟悉的就是 InvocationHandler 类，我们看一下 InvocationHandler 类的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package java.lang.reflect;/*** InvocationHandler是代理实例的调用处理器实现的接口。* 每个代理实例都有一个关联的调用处理器。* 在调用代理实例的方法时，方法调用将被编码并分派给其调用处理程序的 invoke 方法。** @author Peter Jones* @see Proxy* @since 1.3*/public interface InvocationHandler &#123; /** * 在代理实例上处理方法调用并返回结果。当在与其关联的代理实例上调用 * 方法时，将调用处理期上的此方法。 * * @param proxy 该方法被调用的代理实例 * * @param method Method 对象将是代理接口声明的方法，它可能是代理 * 类继承方法的代理接口的超级接口。 * @param args 包含在代理实例的方法调用中传递的参数值的对象数组， * 如果interface方法不带参数，则为null。基本类型的参 * 数被封装在适当的基本封装类的实例中，比如 * java.lang.Integer 或者 java.lang.Boolean。 * @return 调用代理实例上的方法获得的返回值。如果接口方法的声明返 * 回类型是基本类型，则此方法返回的值必须是相应基本包装类 * 的实例;否则，它必须是转换为声明的返回类型的类型。如果 * 此方法返回的值为null，并且接口方法的返回类型为原始类型， * 则代理实例上的方法调用将引发NullPointerException。如果 * 此方法返回的值与上面所述的接口方法的声明返回类型不兼容， * 则将通过代理实例上的方法调用抛出ClassCastException。 * * @throws 抛出调用代理实例的方法时抛出的异常。异常的类型必须可以 * 转化为接口方法的 throws 子句中声明的异常类型，也可以分 * 配给不强制检查的异常类型 java.lang.RuntimeException 或 * java.lang.Error。如果这个方法抛出一个强制检查的异常， * 这个异常不能转化为接口方法的 throws 子句中声明的异常类 * 型，那么将会抛出包含这个异常的 * UndeclaredThrowableException 异常。 * * @see UndeclaredThrowableException */ public Object invoke(Object proxy, Method method, Object[] args) throws Throwable;&#125; 从 Javadoc 中我们知道，通过调用 Proxy.newProxyInstance 方法创建的代理实例中的方法时，会执行传入的 InvocationHandler#invoke 方法，代理实例中方法返回值为 InvocationHandler#invoke 方法返回值。 我们做一个测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 代理接口 */public interface ITest &#123; String test(String val);&#125;/** * 代理实现类 */public class Test implements ITest &#123; @Override public String test(String val) &#123; return val + "我是Test"; &#125;&#125;/** * 调用处理器 */public class TestInvocationHandler implements InvocationHandler &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(method); return args[0] + "我是TestProxy"; &#125;&#125;public class Main &#123; /** * 分别对正常实现的 ITest 实现类和动态代理实现类进行调用 * @param args */ public static void main(String[] args) &#123; ITest test = new Test(); ITest testProxy = (ITest) Proxy.newProxyInstance(test.getClass().getClassLoader(), new Class[] &#123;ITest.class&#125;, new TestInvocationHandler()); System.out.println(test.test("Hello，")); System.out.println("------------"); System.out.println(testProxy.test("Hello，")); &#125;&#125; 输出结果为： 1234Hello，我是Test----------public abstract java.lang.String com.example.demo.Main$ITest.test(java.lang.String)Hello，我是TestProxy 从测试例子中，我们可以看出两个特点： 实现了 ITest 接口的实现类并不需要我们手动写，是自动生成并实例化的。 调用自动生成的 ITest 代理类实例，将调用 InvocationHandler#invoke 方法。 不知各位使用 MyBatis 的时候有没有疑问，为什么可以直接调用接口？答案就在这里，事实上，MyBatis 使用类似的技术，帮我们实现了一个代理类，我们拿到的都是接口的代理类实例。 JDK动态代理实现原理为了突出重点，以下代码仅展示与主题相关的代码，防御性编程，异常处理等无关内容已被省略，完整实现请自寻 JDK 源码 那么 Java 的动态代理是怎样实现的呢？我们去 JDK 源码，查看 Proxy.newProxyInstance 的实现： 12345678910111213141516public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; final Class&lt;?&gt; intfs = interfaces.clone(); // 通过类加载器和接口使用 getProxyClass0 方法创建实现类 Class&lt;?&gt; c1 = getProxyClass0(loader, intfs); // 获得指定构造器 final Constructor&lt;?&gt; cons = c1.getConstructor(constructorParams); // 创建实例 return cons.newInstance(new Object[](h));&#125; 其中两句创建实例的过程都是常见的反射操作，这里不赘述。但是 getProxyClass0 方法是如何通过接口创建类的？我们继续跟进 getProxyClass0 方法的实现： 1234private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; return proxyClassCache.get(loader, interfaces);&#125; 我们跟进至 proxyClassCache.get 的实现，这应该是一个负责缓存管理的类： 123456public V get(K key, P parameter) &#123; // Cache 置换，检查等实现均已省略，已下是 Cache 未命中时，创建新实现类的代码 Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); V value = supplier.get(); return value;&#125; 我们跟进至 ProxyClassFactory#apply 的实现： 1234567891011public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt; interfaces) &#123; for(Class&lt;?&gt; intf : interfaces) &#123; interfaceClass = Class.forName(intf.getName(), false, loader); // 对 interfaceClass 进行了系列权限检查，实现略 &#125; // 根据 interfaces.accessFlags 产生名为 proxyName 的代理类字节码 byte[] proxyClassFile = ProxyGenerator.generateProxyClass(proxyName, interface, accessFlags); // 加载字节码，产生类对象 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length);&#125; 从代码中，可以看到： ProxyGenerator.generateProxyClass 用于产生代理类的字节码 defineClass0 用于加载字节码产生类对象 这里的 defineClass0 是一个 native 方法，我们不深究。ProxyGenerator.generateProxyClass 是对字节码进行操作。我们做一个小实验： 123456789101112131415161718public class Main2 &#123; /** * 代理接口 */ interface ITest &#123; String test(String val); &#125; public static void main(String[] args) throws IOException &#123; // 通过 ProxyGenerator.generateProxyClass 产生字节码 byte[] testProxyBytes = ProxyGenerator.generateProxyClass("TestProxy", new Class[]&#123;ITest.class&#125;); // 将字节码输出到文件，然后我们再反编译它，看看它的内容是什么 FileOutputStream fileOutputStream = new FileOutputStream("TestProxy.class"); fileOutputStream.write(testProxyBytes); fileOutputStream.flush(); fileOutputStream.close(); &#125;&#125; TestProxy.class 反编译后的源码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public final class TestProxy extends Proxy implements ITest &#123; private static Method m1; private static Method m2; private static Method m3; private static Method m0; public TestProxy(InvocationHandler var1) throws &#123; super(var1); &#125; public final boolean equals(Object var1) throws &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final String toString() throws &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; public final String test(String var1) throws &#123; try &#123; return (String)super.h.invoke(this, m3, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; public final int hashCode() throws &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; static &#123; try &#123; m1 = Class.forName("java.lang.Object").getMethod("equals", Class.forName("java.lang.Object")); m2 = Class.forName("java.lang.Object").getMethod("toString"); m3 = Class.forName("com.example.demo.Main2$ITest").getMethod("test", Class.forName("java.lang.String")); m0 = Class.forName("java.lang.Object").getMethod("hashCode"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125; 通过 ProxyGenerator.generatorProxyClass 生成的类字节码有以下特点： 该类继承了 Proxy 实现了传入接口类（ITest） 该类在 static 代码块中定义了所有该类包含的方法的 Method 实例。 该类有一个构造器 TestProxy(InvocationHandler var1) 传入调用处理器。 该类所有方法都执行 super.h.invoke 并返回结果。 那么这里的 super.h 是什么呢，我们看其父类 Proxy 的代码： 12345protected InvocationHandler h;protected Proxy(InvocationHandler h) &#123; Objects.requireNonNull(h); this.h = h;&#125; 恍然大悟！这里的 super.h 就是 TestProxy(InvocationHandler var1) 构造器中传入的h。 总结 用户通过 Proxy.newProxyInstance 方法传入类加载器、接口对象、调用处理器来创建代理类实例。 JDK 中通过 ProxyGenerator.generateProxyClass 方法根据传入接口类对象生成代理类的字节码，并加载字节码产生代理类对象。 生成的代理类继承了 Proxy 实现了传入接口类。 该类的每一个方法都会执行调用处理器的 invoke 方法，传入相应参数，返回 invoke 方法的返回值 CGLIB 动态代理CGLIB 是什么CGLIB（Code Generation Library）是一个开源项目，是一个强大的，高性能，高质量的 Code 生成类库，它可以在运行期扩展 Java 类与实现 Java 接口。CGLIB 是一个强大的高性能的代码生成包。它广泛地被许多 AOP 框架使用，例如 Spring AOP 和 dynaop。 CGLIB 实现动态代理先来个 service，注意没有接口 1234567891011121314151617181920public class CglibService &#123; public CglibService() &#123; System.out.println("CglibDao 构造方法"); &#125; /** * 该方法不能被子类覆盖，Cglib是无法代理final修饰的方法的 * @param name * @return */ final public String sayOthers(String name) &#123; System.out.println("CglibDao final sayOthers：" + name); return null; &#125; public void sayHello() &#123; System.out.println("CglibDao:syaHello"); &#125;&#125; 新建一个 Interceptor 实现 org.springframework.cglib.proxy.MethodInterceptor 123456789101112131415161718public class MyMethodInterceptor implements MethodInterceptor &#123; /** * * @param o 代理对象 * @param method 被代理的对象方法 * @param objects 方法入参 * @param methodProxy 代理方法 * @return * @throws Throwable */ @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println("===========插入前通知==========="); Object object = methodProxy.invokeSuper(o, objects); System.out.println("===========插入后通知==========="); return object; &#125;&#125; 新建测试类 1234567891011121314151617public class cglibAgentTest &#123; public static void main(String[] args) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(CglibService.class); // 设置 enhancer 的回调对象 enhancer.setCallback(new MyMethodInterceptor()); // 创建代理对象 CglibService proxy = (CglibService) enhancer.create(); // 通过代理对象调用目标方法 proxy.sayHello(); proxy.sayOthers("小明"); &#125;&#125; 打印的值 12345CglibDao 构造方法======插入前置通知======CglibDao:sayHello======插入后置通知======CglibDao final sayOthers:小明 可以看出，会先执行它的构造方法，当调用 sayHello 时会先调用它们的代理方法，如果当方法为 final 修饰时，无法实现代理。 原理CGLIB 可以在运行时，动态生成一个代理类继承我们的目标类，并重写了目标方法，如下： 动态生成的代理类，在方法中调用了父类（目标类）的目标方法，并在调用前后做了一些处理。 总结如果你的类是实现了某个接口的，Spring AOP 会使用 JDK 动态代理，生成一个跟你实现同样接口的一个代理类，构造一个实例对象出来，JDK 动态代理，其实就是在你的类有接口的时候，就会来使用。 如果你的类是没有实现接口的，Spring AOP 会改用 cglib 来动态生成代理，它是生成你的类的一个子类，可以动态生成字节码，覆盖你的一些方法，在方法里加入增强的代理。 参考资料小豹子带你看源码：JDK 动态代理 CGLIB 动态代理]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IOC 和 Spring AOP]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F09%2FSpring-IOC-%E5%92%8C-Spring-AOP%2F</url>
    <content type="text"><![CDATA[Spring IOC在没有 Spring 之前，我们开发 Web 系统基本是使用 Servlet + Tomcat。就是 Tomcat 启动之后，它可以监听一个端口号的 http 请求，然后可以把情趣转交给你的 servlet，jsp 配合起来使用，由 servlet 处理请求。大概像下面的代码： 123456789101112131415public class MyServlet &#123; private MyService myService = new MyServiceImpl(); public void doPost(HttpServletRequest request) &#123; // 对请求一通处理 // 调用自己的业务逻辑组件 myService.doService(request); &#125;&#125;public interface MyService &#123;&#125;public class MyServiceImpl implements MyService &#123;&#125;public class NewServiceManagerImpl implements MyService &#123;&#125; 例如我们的一个 Tomcat + servlet 的这样的一个系统里，有几十个地方，都是直接用 MyService myService = new MyServiceImpl() 直接创建，引用和依赖了一个 MyServiceImpl 这样的一个类的对象。那么在这个系统里，就有几十个地方都跟 MyServiceImpl 类直接耦合在一起了。 如果现在不想用 MyServiceImpl 了，希望使用 NewServiceManagerImpl，同样也是 implements MyService 这个借口的。那么所有的实现逻辑都不同了，我们需要在这个系统的几十个地方，都去修改对应的 MyServiceImpl 这个类，切换为 NewServiceManagerImpl 这个类。这样就很麻烦。而且代码的改动成本很大，改动以后的测试成本很大，改动的过程可能会有点复杂，出现一些 bug。归根到底，代码里各种类之间完全耦合在一起，出现任何一丁点的变动，都需要改动大量的代码，重新测试，可能还有 bug。 这个时候，Spring IOC 框架就出场了。IOC（Inversion Of Control），中文翻译为“控制反转”，我们也叫依赖注入。之前是通过 XML 文件进行一个配置，现在可以基于注解来进行自动依赖注入。 1234567891011121314151617@Controllerpublic class MyController &#123; @Resource private MyService myService; public void doRequest(HttpServletRequest request) &#123; // 对请求一通处理 // 调用自己的业务逻辑组件，去执行一些业务逻辑 myService.doService(request); &#125;&#125;public class MyServiceImpl implements MyService &#123;&#125;@Servicepublic class NewServiceManagerImpl implements MyService &#123;&#125; 我们只要在这个工程里通过 maven 引入一些 spring 框架的依赖，就可以实现 IOC 的功能。 Tomcat 在启动的时候，会直接启动 spring 容器。而 spring 容器，会根据 XML 的配置，或者是你的注解，去实例化一些 bean 对象，然后根据 XML 配置或者注解，去对 bean 对象之间的引用关系，进行依赖注入，某个 bean 依赖了另一个 bean。而这底层的核心技术，就是反射。它会通过反射的技术，直接根据你的类去构建对应的对象出来。 Spring IOC，最大的好处就是让系统的类与类之间彻底的解耦合。 ![spring ioc](Spring-IOC-和-Spring-AOP/spring ioc.png) Spring AOPSpring AOP，又叫面向切面编程，可以应用于事务和日志等场景。拿事务举个例子，在数据库里，例如 MySQL，都提供一个事务机制，如果我们开启一个事务，在这个事务里执行多条增删改的 SQL 语句。在这个过程中，如果任何一个 SQL 语句失败了，会导致这个事务的回滚，把其他 SQL 做的数据更改都恢复回去。 在一个事务里的所有 SQL，要么一起成功，要么一起失败，事务功能可以保证我们的数据的一致性。我们可以在业务逻辑组件里加入这个事务。 123456789101112131415161718192021222324252627282930313233343536373839@Controllerpublic class MyController &#123; @Resource private MyService myServiceA; public void doRequest() &#123; myServiceA.doServiceA(); &#125;&#125;@Servicepublic class MyServiceAImpl implements MyServiceA &#123; public void doServiceA() &#123; // 开启事务 //insert语句 //update语句 //delete语句 //根据是否抛出异常，回滚事务 or 提交事务 &#125;&#125;@Servicepublic class MyServiceBImpl implements MyServiceB &#123; public void doServiceB() &#123; // 开启事务 // update语句 // update语句 // insert语句 //根据是否抛出异常，回滚事务 or 提交事务 &#125;&#125; 由上面的代码可以看出，所有的业务逻辑都有几段跟事务相关的代码。假设我们有几十个 Service 组件，类似一样的代码，重复的代码，必须在几十个地方都去写一样的东西，这就很难受了。这时候就轮到 Spring AOP 机制出马了。 AOP 作为一种编程范式，已经衍生出了属于它的一些先关术语。为了更好地理解如何在 Spring 中使用 AOP，我们必须对这些术语有一定的认知。 通知（Advice）Spring AOP 支持五种类型的通知，它们分别定义了切面在什么时候使用，以及定义了切面需要做些什么。 @Before 前置通知，目标方法被调用之前执行 @After 后置通知，目标方法完成之后执行 @AfterReturning 返回通知，目标方法执行成功（未抛出异常）之后执行 @AfterThrowing 异常通知，目标方法执行失败（抛出异常）之后执行 @Around 环绕通知，目标方法执行前后都会调用 连接点（JoinPoint）程序执行的某个特定位置：如类开始初始化前、类初始化后、类满足某个方法调用前、调用后、方法抛出异常后。一个类或一段程序代码拥有一些具有边界性质的特定点，这些点中的特定点就称为“连接点”。Spring 仅支持方法的连接点，即仅能在方法调用前、方法调用后、方法抛出异常时以及方法调用前后这些程序执行点织入增强。连接点由两个信息确定：第一是用方法表示的程序执行点，第二是用相对点表示的方位。 切点（Poincut）每个程序类都拥有多个连接点，如一个拥有两个方法的类，这两个方法都是连接点，即连接点是程序中客观存在的事物。AOP 通过“切点”定位特定的连接点。连接点相当于数据库中的记录，而切点相当于查询条件。切点和连接点不是一对一的关系，一个切点可以匹配多个连接点。在 Spring 中，切点通过 org.springframework.aop.Pointcut 接口进行描述，它使用类和方法作为连接点的查询条件，Spring AOP 的规则解析引擎负责切点所设定的查询条件，找打对应的连接点。其实确切地说，不能称之为查询连接点，因为连接点是方法执行前、执行后等包括方位信息的具体程序执行点，而切点只定位到某个方法上，所以如果希望定位到具体连接点上，还需要提供方位信息。 切面（Aspect）切面由切点和增强（引介）组成，它既包括了横切逻辑的定义，也包括了连接点的定义，Spring AOP 就是负责实施切面的框架，它将切面所定义的横切逻辑织入到切面所指定的连接点中。 引入（Introduction）引入使我们具备了为类添加一些属性和方法的能力。这样，即使一个业务类原本没有实现某个接口，通过 AOP 的引介功能，我们可以动态地为该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。 织入（weaving）织入是将增强添加对目标类具体连接点上的过程。AOP 像一台织布机，将目标类、增强或引介通过 AOP 这台织布机天衣无缝地编织到一起。根据不同的实现技术，AOP 有三种织入的方式：1. 编译期织入，这要求使用特殊的Java编译器。2. 类装载期织入，这要求使用特殊的类装载器。3. 动态代理织入，在运行期为目标类添加增强生成子类的方式。Spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装载期织入。 代理（Proxy） 一个类被 AOP 织入增强后，就产出了一个结果类，它是融合了原类和增强逻辑的代理类。根据不同的代理方式，代理类既可能是和原类具有相同接口的类，也可能就是原类的子类，所以我们可以采用调用原类相同的方式调用代理类。 一个切面，如何定义呢？例如 MyServiceImplXXXX 的这种类，在这些类的所有方法中，都去织入一些代码，在所有这些方法刚开始运行的时候，都先去开启一个事务，在所有这些方法执行完毕之后，去根据是否抛出异常来判断一下，如果抛出异常，就回滚事务，如果没有异常，就提交事务。 Spring 在运行的时候，会使用动态代理技术，这也是 AOP 的核心技术，来给你的那些类生成动态代理。 1234567891011public class ProxyMyServiceA implements MyServiceA &#123; private MyServiceA myServiceA; public void doServiceA() &#123; // 开启事务 // 直接去调用我依赖的MyServiceA对象的方法 myServiceA.doServiceA(); // 根据是否抛出异常，回滚事务 or 提交事务 &#125;&#125; 那么上面的代码就可以变成这样： 123456789101112131415161718192021@Controllerpublic class MyController &#123; @Resource private MyService myServiceA; // 注入的是动态代理的对象实例，ProxyMyServiceA public void doRequest() &#123; myServiceA.doServiceA(); // 直接调用到动态代理的对象实例的方法中去 &#125;&#125;@Servicepublic class MyServiceAImpl implements MyServiceA &#123; public void doServiceA() &#123; //insert语句 //update语句 //delete语句 &#125;&#125; 下面给个简单的AOP代码的例子： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@Aspect@Componentpublic class ApiIdempotentAop &#123; @Autowired private JedisUtil jedisUtil; @Pointcut("@annotation(com.example.midx.annotation.ApiIdempotent)") public void apiIdempotentPointCut() &#123; &#125; @Around("apiIdempotentPointCut()") public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; System.err.println("进来AOP了"); Object[] args = joinPoint.getArgs(); //获取request和response ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); HttpServletRequest request = attributes.getRequest(); HttpServletResponse response = attributes.getResponse(); String requestURI = request.getRequestURI(); MethodSignature signature = (MethodSignature) joinPoint.getSignature(); ApiIdempotent annotation = signature.getMethod().getAnnotation(ApiIdempotent.class); Object result; if(annotation != null) &#123; String token = request.getHeader("token"); if (StringUtils.isBlank(token)) &#123;// header中不存在token token = request.getParameter("token"); if (StringUtils.isBlank(token)) &#123;// parameter中也不存在token throw new ServiceException("参数不合法"); &#125; &#125; if (!jedisUtil.exists(token)) &#123; System.err.println("请勿重复操作"); throw new ServiceException("请勿重复操作"); &#125; result = joinPoint.proceed(); Long del = jedisUtil.del(token); if (del &lt;= 0) &#123; throw new ServiceException("请勿重复操作"); &#125; return result; &#125; return null; &#125; @Before("execution(* com.cdc.bdom.portal..*.mapper.*Mapper.select*(..)) || execution(* com.cdc.bdom.portal..*.mapper.*Mapper.get*(..)) || execution(* com.cdc.bdom.portal..*.mapper.*Mapper.find*(..))") public void setReadDataSourceType() &#123; logger.info("调用读数据库"); DataSourceContextHolder.read(); &#125;&#125;]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx详解]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F07%2FNginx%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Nginx 简介​ Nginx是一个免费、开源、高性能、轻量级的HTTP和反向代理服务器，也是一个电子邮件（IMAP/POP3）代理服务器，其特点是占有内存少，并发能力强。 ​ Nginx由内核和一系列模块组成，内核提供Web服务的基本功能，如启用网络协议，创建运行环境，接收和分配客户端请求，处理模块之间的交互。 ​ Nginx的各种功能和操作都由模块来实现。Nginx的模块从结构上分为： 核心模块：HTTP模块、EVENT模块和MAIL模块。 基础模块：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块和HTTP Rewrite模块。 第三方模块：HTTP Upstream Request Hash模块、Notice模块和HTTP Access Key模块及用户自己开发的模块。 ​ 这样的设计使Nginx方便开发和扩展，也因此才使得Nginx功能如此强大。Nginx的模块默认编译进Nginx中，如果需要增加或删除模块，需要重新编译Nginx，这一点不如Apache的动态加载模块方便。如果有需要动态加载模块，可以使用由淘宝网发起的Web服务器Tengine，在Nginx的基础上增加了很多高特定，完全兼容Nginx，已被国内很多网站采用。Nginx有很多扩展版本： 开源版nginx.org 商业版NGINX Plus 淘宝网发起的Web服务器Tengine 基于Nginx和Lua的Web平台OpenResty Nginx 作为 Web 服务器​ Web服务器也称为WWW（World Wide Web）服务器，主要功能是提供网上信息浏览服务，常常以B/S（Browser/Server）方式提供服务： 应用层使用HTTP协议 HTML文档格式 浏览器统一资源定位器（URL） ​ Nginx可以作为静态页面的Web服务器，同时还支持CGI协议的动态语言，比如Perl、PHP等，但是不支持Java。Java程序一般都是通过与Tomcat配合完成，让我们看看Nginx和Tomcat的区别。 ​ Nginx、Apache和Tomcat： Nginx：由俄罗斯程序员lgor Sysoev所开发的轻量级，高并发HTTP服务器。 Apache HTTP Server Project：一个Apache基金会下的HTTP服务项目，和Nginx功能类似。 Apache Tomcat：是Apache基金会下的另外一个项目，是一个Application Server。更准确地说是一个Servlet应用容器，与Apache HTTP Server和Nginx相比，Tomcat能够动态生成资源并且返回到客户端。 ​ Apache HTTP Server和Nginx本身不支持生成动态页面，但它们可以通过其他模块来支持（例如通过Shell、PHP、Python脚本程序来动态生成内容）。 ​ 一个HTTP Server关心的是HTTP协议层面的传输和访问控制，所以在Apache/Nginx上你可以看到代理、负载均衡等功能。客户端通过HTTP Server访问服务器上存储的资源（HTML文件、图片文件等待）。通过CGI技术，也可以将处理过的内容通过HTTP Server分发，但是一个HTTP Server始终只是把服务器上的文件如实地通过HTTP协议传输给客户端。 ​ 而应用服务器，则是一个应用执行的容器。它首先需要支持开发语言的运行（对于Tomcat来说，就是Java），保证应用能够在应用服务器上正常运行。其次，需要支持应用相关的规范，例如类库、安全方面的特性。对于Tomcat来说，就是需要提供JSP/Servlet运行需要的标准库。Interface等。 ​ 为了方便，应用服务器往往也会集成HTTP Server的功能，但是不如专业的HTTP Server那么强大。所以应用服务器往往是运行在HTTP Server的背后，执行应用，将动态的内容转化为静态的内容之后，通过HTTP Server分发到客户端。 正向代理正向代理：如果把局域网外的Internet想象成一个巨大的资源库，则局域网中的客户端要访问Internet，则需要通过代理服务器来访问，这种代理服务就称为正向代理。 正向代理“代理”的是客户端。例如你想去YouTube看个动作片，可国内不允许啊，就需要找翻墙代理，这个就是所谓的“正向代理”。 反向代理与负载均衡反向代理与正向代理相反，反向代理是指以代理服务器来接收Internet上的连接请求，然后将请求转发到内部网络上的服务器，并将服务器上得到的结果返回给客户端。此时代理服务器对外表现就是一个服务器，客户端对代理是无感知的。反向代理“代理”的是服务端。 再比如，你想在“优酷”上看个综艺，youku.com 会把你的请求分发到存放视频的那台机器上，这就是所谓的“反向代理”。 为什么使用反向代理，原因如下： 保护和隐藏原始资源服务器 加密和SSL加速 通过缓存静态资源，加速Web请求 实现负载均衡 地址重定向：Nginx的Rewrite主要的功能就是实现URL重写，比如输入360.com跳转到360.cn。 动静分离为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度，降低原来单个服务器额的压力。 这里指的就是让动态程序（Java、PHP）去访问应用服务器，让缓存、图片、JS、CSS等去访问Nginx。 Nginx 安装​ 1、下载nginx 1wget http://nginx.org/download/nginx-1.16.1.tar.gz 2、安装需要编译的插件 用于编译C、C++代码的GCC 用C语言编写的正则表达式函数库Pcre（使用Rewrite模块） 用于数据压缩的函数库Zlib 安全套接字层密码库OpenSSL（启用SSL支持） 1234yum install gcc c++ yum install -y pcre pcre-devel yum install -y zlib zlib-devel yum install -y openssl openssl-devel 3、解压、配置（nginx支持各种配置选项）。编译、安装Nginx 1234tar -zxvf nginx-1.15.tar.gz cd nginx-1.16.1cd nginx-1.16.1./configuremake &amp;&amp; sudo make install 4、启动、重启、关闭 123456789cd /usr/local/nginx/ cd sbin./nginx#关闭命令 ./nginx -s stop#重启，热部署./nginx -s reload#修改配置文件后也别嘚瑟，反正我会动不动就写错，检查修改的nginx.conf配置是否正确./nginx -t 5、验证（浏览器输入IP） 配置文件nginx.conf配置文件主要分为三部分： 全局块 Events 块 HTTPS 块 ​ Nginx配置语法： 配置文件由指令和指令块构成 每条指令以分号（;）结尾，指令和参数间以空格符分隔 指令块以大括号{}将多条指令组织在一起 include 语句允许组合多个配置文件以提高可维护性 使用#添加注释 使用$定义变量 部分指令的参数支持正则表达式 全局块全局配置部分用来配置对整个Server都有效的参数。主要会设置一些影响 Nginx 的服务器整体运行的配置指令，包括配置运行Nginx服务器的用户（组）、允许生成的 Work Process 数，进程 PID 存放路径、日志存放路径和类型以及配置文件的引入等。示例如下： 123user nobody;worker_processes 4;error_log /data/nginx/logs/error.log notice; Events 块Events块涉及的指令主要影响Nginx服务器与用户的网络连接，常用的设置包括是否开启对多 Work Process 下的网络连接进行序列化，是否允许同时接收多个网络连接，选取哪种事件驱动模型来处理连接请求，每个 Work Process 可以同时支持的最大连接数等。 1234events &#123; #每个 work process 支持的最大连接数为 1024 work_connections 1024;&#125; HTTP 块这算是Nginx服务器配置中最频繁的部分。代理、缓存和日志定义等绝大多数功能和第三方模块的配置都在这里。需要注意的是：HTTP 块也可以包括 HTTP 全局快、Server 块。 HTTP 全局块HTTP 全局块配置的指令包括文件引入、MIME-TYPE 定义、日志自定义、连接超时时间、单链接请求上限等。 123456http &#123; include mime.types; default_type application/octet-stream sendfile on; keepalive_timeout 65;&#125; Server 块这块和虚拟主机有密切关系，虚拟主机从用户角度看，和一台独立的硬件主机是完全一样的，该技术的产生是为了节省互联网服务器硬件成本。 每个 HTTP 块可以包括多个 Server 块，而每个 Server 块就相当于一个虚拟主机。而每个 Server 块也分为全局 Server 块，以及可以同时包含多个 Location 块。 全局 Server 块：也被叫做“ 虚拟服务器 ”部分，它描述的是一组根据不同 server_name 指令逻辑分割的资源，这些虚拟服务器响应 HTTP 请求，因此都包含在 HTTP 部分。最常见的配置是本虚拟机主机的监听配置和本虚拟主机的名称或 IP 配置。 12345server &#123; listen 80; #server_name 也支持通配符，*.example.com、www.example.*、.example.com server_name localhost;&#125; Location 块：一个 Server 块可以配置多个 Location 块。 这块的主要作用是基于 Nginx 服务器接收到的请求字符串（例如 server_name/uri-string），对虚拟主机名称（也可以是IP别名）之外的字符串（例如前面的 /uri-string）进行匹配，对特定的请求进行处理。地址定向、数据缓存和应答控制等功能，还有许多第三方模块的配置也在这里进行。 Location 指令说明：该指令用于匹配 URL。语法如下：location [ = | ~ | * | ^ ] uri {} =：该修饰符使用精确匹配并且终止搜索。 ~：该修饰符使用区分大小写的正则表达式匹配。 ~*：该修饰符使用不区分大小写的正则表达式匹配。 ^~：用于不含正则表达式的 URI 前，要求 Nginx 服务器找到表示 URI 和请求字符串匹配度最高的 Location 后，立即使用此 Location 处理请求，而不再使用 Location 块中的正则 URI 和请求字符串做匹配。 注意，如果 URI 包含正则表达式，则必须要有 ~ 或者 ~* 标识。 当一个请求进入时，URI 将会被检测匹配一个最佳的 Location： 没有正则表达式的 Location 被作为最佳的匹配，独立于含有正则表达式的 Location 顺序。 在配置文件中按照查找顺序进行正则表达式匹配。在查找到第一个正则表达式匹配之后结束查找。由这个最佳的 Location 提供请求处理。 1234location / &#123; root html; index index.html index.htm;&#125; nginx.conf 详细配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293#定义Nginx运行的用户和用户组uesr www www;#nginx进程数，通常设置成和cpu的数量相等work_processes 4;#全局错误日志定义类型，[debug | info | notice | warn | error | crit]#error_log /data/nginx/logs/error.log;#error_log /data/nginx/logs/error.log notice;#日志文件存放路径 access_log path [format [buffer=size | off]]access_log /data/nginx/logs/lazyegg.com/web/access/log combinedio;#进程pid文件#pid logs/nginx.pid;#指定进程可以打开的最大描述符：数目#工作模式与连接上限#这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit - n）#与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit - n的值保持一致。这是因#为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可#能超过10240了，这时会返回502错误worker_rlimit_nofile 65535;################################# events ###############################events &#123; #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll]; epoll模型 use epoll #单个进程最大连接数（最大连接数 = 连接数 + 进程数） worker_connections 1024; #keepalive 超时时间 keepalive_timeout 60; #客户端请求头部的缓冲区大小 client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致， #inactive是指经过多少时间文件没被请求后删除缓存 open_file_cache max=65535 inactive=60s; #这个指多长时间检查一次缓存的有效信息 open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述 #符一直是在缓存中打开的。如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除 open_file_cache_min_uses 1; #语法：open_file_chche_errors on | off 默认值：open_file_cache_errors off 使用 #字段：http，server，location 这个指令指定是否在搜索一个文件是否记录cache错误 open_file_cache_errors on;&#125;############################## http ###################################设定http服务器，利用它的反向代理功能提供负载均衡支持http &#123; #文件扩展名与文件类型映射表 include mime.types; #默认文件类型 default_type application/octet-stream; #默认编码 charset utf-8; #服务器名字的hash表大小 server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小 client_header_buffer_size 32k; #客户请求头缓冲大小 large_client_header_buffers 4 64k; #允许客户端请求的最大单个文件字节数 client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用 #应该设置为on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理 #速度，降低系统的负载。注意：如果图片显示不正常把这个改成off sendfile on; #开启目录列表访问，适合下载服务器，默认关闭 autoindex on; #此选项允许或禁止使用socket的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒 keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解 fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置 gzip on; #开启gzip压缩输出 gzip_min_length 1k; #最小压缩文件大小 gzip_buffers 4 16k; #压缩缓冲区 gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0） gzip_comp_level 2; #压缩类型，默认就已经包含了textml，所以下面就不用再写了，写了也不会有问题，但是会有一个warn gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; #开启限制IP连接数的时候需要使用 #limit_zone crawler $binary_remote_addr 10m; #负载均衡配置 upstream lazyegg.net &#123; #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weight参数表示权值，权 #值越高被分配的几率越大 server 192.168.80.121:80 weigth=3; server 192.168.80.122:80 weigth=2; server 192.168.80.123:80 weigth=3; #nginx的upstream目前支持4种方式的分配 #1、轮询（默认） #每个请求按照时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 #2、weight #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况 #例如： #upstream bakend &#123; # server 192.168.0.14 weight=10; # server 192.168.0.15 weight=10; #&#125; #3、ip_hash #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session问题 #例如： #upstream bakend &#123; # ip_hash; # server 192.168.0.14:88; # server 192.168.0.15:80; #&#125; #4、fair（第三方） #按后端服务器的相应时间来分配请求，相应时间短的优先分配 #upstream backend &#123; # server server1; # server server2; # fair; #&#125; #5、uil_hash（第三方） #按访问URL的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效 #例：在upstream中加入hash语句，server语句中不能写入weight等其他参数，hash_method #是使用的hash算法 #upstream backend &#123; # server squid1:3128; # server squid2:3128; # hash $request_uri; # hash_method crc32; #&#125; #tips: #upstream bakend&#123;#定义负载均衡设备的Ip及设备状态&#125;&#123; # ip_hash; # server 127.0.0.1:9090 down; # server 127.0.0.1:8080 weight=2; # server 127.0.0.1:6060; # server 127.0.0.1:7070 backup; #&#125; #在需要使用负载均衡的server中增加 proxy_pass http://bakend/; #每个设备的状态设置为： #1、down表示单前的server暂时不参与负载 #2、weight为weight越大，负载的权重就越大 #3、max_fails：允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream模块定义的错误 #4、fail_timeout：max_fails次失败后，暂停的时间。 #5、backup：其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力最轻 #nginx支持同时设置多组的负载均衡，用来给不同的server使用 #client_body_in_file_only 设置为 on，可以将client post过来的数据记录到文件中用来做debug #client_body_temp_path 设置记录文件的目录，可以设置最多3层目录 #location对URL进行匹配，可以进行重定向或者进行新的代理，负载均衡 &#125; #虚拟主机的配置 server &#123; #监听端口 listen 80; #域名可以有多个，用空格隔开 server_name lazyegg.net; #默认入口文件名称 index index.html index.htm index.php; root /data/www/lazyegg; #对******进行复制均衡 location ~ .*.(php|php5)?$ &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125; #图片缓存时间设置 location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ &#123; expires 10d; &#125; #JS和CSS缓存时间设置 location ~ .*.(js|css)?$ &#123; expires 1h; &#125; #日志格式设定 #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址 #$remote_user：用来记录客户端用户名称 #$time_local：用来记录访问时间与时区 #$request：用来记录请求的url与http协议 #$status：用来记录请求状态，成功是200 #$body_bytes_sent：记录发送给客户端文件主体内容大小 #$http_referer：用来记录从哪个页面链接访问过来的 #$http_user_agent：记录客户浏览器的相关信息 #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_addr拿 #到的IP地址是反向代理服务器的ip地址。范子昂代理服务器在转发请求的http头信息中，可以增加 #x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址 log_format access '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" $http_x_forwarded_for'; #定义本虚拟主机的访问日志 access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 "/connect-controller"启用反向代理 location /connect_controller &#123; proxy_pass http://127.0.0.1:88 #此处端口号不能与虚拟主机监听的端口号一样 proxy_redirect off; proxy_set_header X_Real_IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP proxy_set_header X-Forwarded-For $proxy_add_x_forwarded-for; #以下是一些反向代理的配置，可选 proxy_set_header Host $host; #允许客户端请求的最大单文件字节数 client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数 #如果把它设置为比较大的数值，例如256k，那么，无论使用Firefox还是IE浏览器，来提交 #任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size #设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了 #无论使用Firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误 client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答 proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候相应超时时间 #nginx跟后端服务器连接超时时间（代理连接超时） proxy_connect_timeout 90; #后端服务器数据回传时间（代理发送超时） #后端服务器数据回传时间，就是在规定时间之内后端服务器必须传完所有的数据 proxy_send_timeout 90; #连接成功后，后端服务器响应时间（代理接收超时） #连接成功后，等待后端服务器相应时间，其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间） proxy_read_timeout 90; #proxy_buffer缓冲区，网页平均在32k一下的设置 #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也认为页大小，根据操作系统的不同可能是4K或者是8K proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2） proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件是阻塞太长 #设定缓存文件夹大小，大于这个值，将从upstream服务器传 proxy_temp_file_write_size 64k; &#125; #本地动静分离反向代理配置 #所有jsp页面均交由Tomcat或resin处理 location ~ .(jsp|jspx|do)?$ &#123; proxy_set_header Host $host; proxy_set_header X_Real_IP $remote_addr; proxy_set_header X-Forwarded_For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; &#125; &#125; &#125; Nginx 配置实例反向代理 Demo 1实现效果：使用 nginx 反向代理，访问 www.12345.com 直接跳转到自己的机器 127.0.0.1:8080。 1、创建一个SpringBoot项目，写一个简单的Controller。 12345678@RestControllerpublic class TestController &#123; @RequestMapping(method = &#123;RequestMethod.POST, RequestMethod.GET&#125;) public String helloWorld() &#123; return "Hello World"; &#125;&#125; 启动项目后，在浏览器访问 127.0.0.1:8080，出现如下界面： 2、通过修改本地Host文件（ C:\Windows\System32\drivers\etc ），添加 127.0.0.1 www.12345.com 将 www.12345.com 映射到自己的机器IP上。 3、配置完成之后，我们便可以通过 www.12345.com:8080 访问到第一步出现的界面。 那么如何主需要输入 www.12345.com 便可以跳转到初始界面呢？这是就可以用到 nginx 的反向代理 4、修改 nginx.conf 配置文件，增加如下配置 proxy_pass: 12345678server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; proxy_pass http://127.0.0.1:8080; &#125; 5、如上配置，我们监听 80 端口，访问域名为 www.12345.com，不加端口号时默认为 80 端口，故访问该域名时会跳转到 127.0.0.1:8080 路径上。 在浏览器输入 www.12345.com 结果如下： 反向代理 Demo 2实现效果：使用 Nginx 反向代理，根据访问的路径跳转到不同端口的服务中： 访问 http://127.0.0.1/java/ 直接跳转到 127.0.0.1:8080 访问 http://127.0.0.1/egg/ 直接跳转到 127.0.0.1:8081 先启动两个 springboot 项目，其中 8080 端口的项目返回 “Hello java”，8081 的端口返回 “Hello egg”。 修改 nginx.conf，在 HTTP 块中添加 server{} : 123456789101112server &#123; listen 80; server_name localhost; location ~ /java/ &#123; proxy_pass http://127.0.0.1:8080; &#125; location ~ /egg/ &#123; proxy_pass http://127.0.0.1:8081; &#125;&#125; 重启 nginx，验证结果： Nginx 配置：负载均衡随着互联网信息的爆炸性增长，负载均衡已经不再是一个陌生的话题。顾名思义，负载均衡是将负载分摊到不同的服务单元，既保证服务的可用性，又保证相应足够块，给用户很好的体验。Nginx 的负载均衡是 Proxy 模块和 Upstream 模块搭配实现的。Upstream 模块将会启用一个新的配置区段，在改区段定义了一组上游服务器。 实现效果：配置负载均衡还是使用上次两个 springboot 的项目，其中 8080 端口 返回 “Hello java”，而 8081 端口返回 “Hello egg”。 接着，修改 nginx.conf： 123456789101112http &#123; upstream myserver &#123; server localhost:8080; server localhost:8081; &#125; server &#123; listen 80; location / &#123; proxy_pass http://myserver; &#125; &#125;&#125; 重启 Nginx，验证结果（默认轮询的方式，每次打开新窗口，8080 和 8081 会交替出现，同一个窗口的话需要关闭浏览器缓存）。 Nginx 分配策略： 轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 Down 掉，能自动剔除。 Weight ：代表权重，默认为 1，权重越高被分配的客户端越多，指定轮询几率，Weight 和访问比率成正比，用于后端服务器性能不均的情况。例如： 1234upstream server_pool &#123; server 192.168.0.1 weight=10; server 192.168.0.2 weigth=10;&#125; ip_hash：每个请求按访问 IP 的 Hash 结构分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。例如： 12345upstream server_pool &#123; ip_hash; server 192.168.0.1:80; server 192.168.0.2:80;&#125; fair（第三方）：按后端服务器的相应时间来分配请求，相应时间短的优先分配。 12345upstream server_pool &#123; server 192.068.0.1:80; server 192.168.0.2:80; fair;&#125; Nginx 配置：动静分离Nginx 动静分离简单说就是把动态和静态请求分开，不能理解成只是单纯地把动态页面和静态页面物理分离。严格意义上说应该是动态跟静态请求分开，可以理解成使用 Nginx 处理静态页面，Tomcat 处理动态页面。 动静分离从目前实现角度来说大致分为两种： 纯粹把静态文件独立成单独的域名，放在独立的服务器上，也是目前主流推崇的方案； 动态跟静态文件混合在一起发布，通过 Nginx 来分开。 通过 Location 指定不同的后缀名实现不同的请求转发。通过 Expires 参数设置，可以使浏览器缓存过期时间，减少与服务器之间的请求和流量。 具体 Expires 定义：是给一个资源设定一个过期时间，也就是说无须去服务端验证，直接通过浏览器自身确认是否过期，所以不会产生额外的流量。此种方法非常适合不经常变动的资源（如经常更新的文件，不建议使用 Expires 来缓存） 我这里设置 3d，表示在这 3 天之内访问这个 URL，发送一个请求，比对服务器该文件最后更新时间没有变化，则不会从服务器抓取，返回状态码 304，如果有修改，则直接从服务器重启下载，返回状态码 200。 服务器找个目录存放自己的静态文件： 配置 Nginx： 1234567891011121314151617181920212223242526272829303132333435363738server &#123; listen 80;#端口号 server_name localhost;#本机 charset utf-8; #access_log logs/host.access.log main; location ~ .*\.(gif|jpg|jpeg|png)$ &#123; expires 24h; root /usr/data/image/;#指定图片存放路径 access_log /usr/local/websrv/nginx-1.9.4/logs/images.log;#日志存放路径 proxy_store on; proxy_store_access user:rw group:rw all:rw; proxy_temp_path /usr/data/image/;#图片访问路径 proxy_redirect off; proxy_set_header Host 127.0.0.1; client_max_body_size 10m; client_body_buffer_size 1280k; proxy_connect_timeout 900; proxy_send_timeout 900; proxy_read_timeout 900; proxy_buffer_size 40k; proxy_buffers 40 320k; proxy_busy_buffers_size 640k; proxy_temp_file_write_size 640k; if ( !-e $request_filename) &#123; proxy_pass http://127.0.0.1;#默认80端口 &#125; &#125; location / &#123; root /home/html; #html访问路径 index index.html index2.htm; #html文件名称 &#125;&#125; 重启 Nginx，验证结果： Nginx 的 RewriteRewrite 是 Nginx 服务器提供的一个重要的功能，它可以实现 URL 重写和重定向功能。 场景如下： URL 访问跳转，支持开发设计。页面跳转、兼容性支持（新旧版本更迭）、展示效果（网址精简）等 SEO 优化（Nginx 伪静态的支持） 后台维护、流量转发 安全（动态界面进行伪装） 该指令是通过正则表达式的使用来改变 URI。可以同时存在一个或多个指令。需要按照顺序依次对 URI 进行匹配和处理。 采用反向代理 Demo2 中的例子，修改 nginx.conf（只多加一行 rewrite） 12345678910111213server &#123; listen 80; server_name localhost; location /java/ &#123; proxy_pass http://127.0.0.1:8080; rewrite ^/java /egg/ redirect; &#125; location /egg/ &#123; proxy_pass http://127.0.0.1:8081; &#125;&#125; 重启 nginx，验证结果（输入 ip/java/ 被重定向到 egg）： Rewrite 指令可以在 Server 块或 Location 块中配置，其基本语法结构如下： 1rewrite regex replacement [flag]; rewrite 的含义：该指令是实现 URL 重写的指令。 regex 的含义：用于匹配 URI 的正则表达式。 replacement：将 regex 正则匹配到的内容替换成 replacement。 flag：flag 标记 flag 有如下值： last：本条规则匹配完成后，继续向下匹配新的 Location URI 规则（不常用）。 break：本条规则匹配完成即终止，不再匹配后面的任何规则（不常用）。 redirect：返回 302 临时重定向，浏览器地址会显示新的 URL地址。 permanent：返回 301 永久重定向。浏览器会显示跳转新的 URL 地址。 1rewrite ^/(.*) http://www.360.cn/$1 permanent; Nginx 高可用如果将 Web 服务器集群当做一个城池，那么负载均衡服务器就相当于城门。如果“城门”关闭了，与外界的通道就断了。如果只有一台 Nginx 复制均衡器，当故障宕机的时候，就会导致整个网站无法访问。所以我们需要两台以上的 Nginx 来实现故障转移和高可用。那么如何实现？ 双机热备方案这种方案是国内企业中最为普遍的一种高可用方案，双机热备其实就是指一台服务器在提供服务，另一台为某服务的备用状态，当一台服务器不可用时另一台就会顶替上去。 Keepalived 是什么？Keepalived 软件起初是转为 LVS 负载均衡软件设计的，用来管理并监控 LVS 集群系统中各个服务节点的状态。后来又加入了可以实现高可用的 VRRP（Virtual Router Redundancy Protocol，虚拟路由器冗余协议）功能。因此，Keepalived 高可用服务之间的故障切换转移，是通过 VRRP 来实现的。 故障转移机制Keepalived 高可用服务之间的故障切换转移，是通过 VRRP 来实现的。 在 Keepalived 服务正常工作时，主 Master 节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉 Backup 节点自己还活着。 当主 Master 节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master 节点的心跳了，于是调用自身的接管程序，接管主 Master 节点的 IP 资源及服务。 而当主 Master 节点恢复时，背 Backup 节点又会释放主节点故障时自身接管的 IP 资源及服务，恢复到原来的备用角色。 实现方法如下： 准备两台安装 Nginx 和 Keepaliver（yum install keepalived -y）的服务器 修改两台服务器上的 /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526#主机#检测脚本vrrp_script chk_http_port &#123; script "/usr/local/src/check_nginx.sh" #心跳执行的脚本，检测nginx是否启动 interval 2 #（检测脚本执行的间隔，单位是秒） weight 2 #权重&#125;#vrrp 实例定义部分vrrp_instance VI_1 &#123; state MASTER # 指定keepalived的角色，MASTER为主，BACKUP为备 interface ens33 # 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡 virtual_router_id 66 # 虚拟路由编号，主从要一直 priority 100 # 优先级，数值越大，获取处理请求的优先级越高 advert_int 1 # 检查间隔，默认为1s(vrrp组播周期秒数) #授权访问 authentication &#123; auth_type PASS #设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信 auth_pass 1111 &#125; track_script &#123; chk_http_port #（调用检测脚本） &#125; virtual_ipaddress &#123; 192.168.16.150 # 定义虚拟ip(VIP)，可多设，每行一个 &#125;&#125; 1234567891011121314151617181920212223242526# 备机#检测脚本vrrp_script chk_http_port &#123; script "/usr/local/src/check_nginx.sh" #心跳执行的脚本，检测nginx是否启动 interval 2 #（检测脚本执行的间隔） weight 2 #权重&#125;#vrrp 实例定义部分vrrp_instance VI_1 &#123; state BACKUP # 指定keepalived的角色，MASTER为主，BACKUP为备 interface ens33 # 当前进行vrrp通讯的网络接口卡(当前centos的网卡) 用ifconfig查看你具体的网卡 virtual_router_id 66 # 虚拟路由编号，主从要一直 priority 99 # 优先级，数值越大，获取处理请求的优先级越高 advert_int 1 # 检查间隔，默认为1s(vrrp组播周期秒数) #授权访问 authentication &#123; auth_type PASS #设置验证类型和密码，MASTER和BACKUP必须使用相同的密码才能正常通信 auth_pass 1111 &#125; track_script &#123; chk_http_port #（调用检测脚本） &#125; virtual_ipaddress &#123; 192.168.16.150 # 定义虚拟ip(VIP)，可多设，每行一个 &#125;&#125; 新建检测脚本（chmod 775 check_nginx.sh）： 123456789#!/bin/bash#检测nginx是否启动了A=`ps -C nginx --no-header |wc -l` if [ $A -eq 0 ];then #如果nginx没有启动就启动nginx systemctl start nginx #重启nginx if [ `ps -C nginx --no-header |wc -l` -eq 0 ];then #nginx重启失败，则停掉keepalived服务，进行VIP转移 killall keepalived fifi 启动 Nginx 和 Keepalived（systemctl start keepalived.service） 模拟 Nginx 故障（关闭主服务器 Nginx），验证，仍可以通过配置的虚拟 IP 访问，OK Nginx 原理与优化参数配置Nginx 默认采用多进程工作方式，Nginx 启动后，会运行一个 Master 进程和多个 Worker 进程。 其中 Master 充当整个进程组与用户的交互接口，同时对进程进行监护，管理 Worker 进程来实现重复服务、平滑升级、更护日志文件、配置文件实时生效等功能。 Worker 用来处理基本的网络事件，Worker 之间是平等的，他们共同竞争来处理来自客户端的请求。 master-worker 的机制的好处： 可以使用 nginx -s reload 热部署 每个 Worker是独立的进程，不需要加锁，省掉了锁带来的开销。采用独立的进程，可以让互相之间不会影响。一个进程退出后，其他进程还在工作，服务不会中断，Master 进程则很快启动新的 Worker 进程。 需要设置多少个 Worker？Nginx 同 Redis 类似都采用了 IO 多路复用机制，每个 Worker 都是独立的进程，但每个进程里只有一个主线程，通过异常非阻塞的方式来处理请求，即使是成千上万个请求也不在话下。 每个 Worker 的线程可以把一个 CPU 的性能发挥到极致。所以 Worker 数和服务器的 CPU 数相等是最为适宜的。设少了浪费 CPU，设多了会造成 CPU 频繁切换上下文带来的损耗。 123456#设置 worker 数量。 worker_processes 4 #work 绑定 cpu(4 work 绑定 4cpu)。 worker_cpu_affinity 0001 0010 0100 1000 #work 绑定 cpu (4 work 绑定 8cpu 中的 4 个) 。 worker_cpu_affinity 0000001 00000010 00000100 00001000 连接数 worker_connection：这个值是表示每个 Worker 进程所能建立连接的最大值。所以，一个 Nginx 能建立的最大连接数，应该是 worker_connections * worker_processes。 当然这里说的是最大连接数，对于 HTTP 请求本地资源来说，能够支持的最大并发数量是 worker_connections * worker_process，如果是支持 http1.1 的浏览器，每次访问要占两个连接，所以普通的静态访问最大并发数是：worker_connections * worker_processes / 2。 而如果是 HTTP 作为反向代理来说，最大并发数量应该是 worker_connections * worker_processes / 4，因为作为反向代理服务器，每个并发会建立与客户端的连接和与后端服务的连接，会占用两个连接。 Nginx 总结Nginx 在项目中的作用反向代理服务器 实现负载均衡 做静态资源服务器 作为 HTTP Server Nginx 常用的命令1234567启动nginx ./sbin/nginx停止nginx ./sbin/nginx -s stop ./sbin/nginx -s quit重载配置 ./sbin/nginx -s reload(平滑重启) service nginx reload重载指定配置文件 ./sbin/nginx -c /usr/local/nginx/conf/nginx.conf查看nginx版本 ./sbin/nginx -v检查配置文件是否正确 ./sbin/nginx -t显示帮助信息 ./sbin/nginx -h Nginx 如何实现高并发Nginx 采用的是多进程（单线程）&amp; 多路 IO 复用模型，异步，非阻塞。 一个主进程 Master，多个工作进程 Worker，每个工作进程可以处理多个请求，Master 进程主要负责收集、分发请求。每当一个请求过来时，Master 就会拉起一个 Worker 进程负责处理这个请求。同时Master进程也复制监控Work的状态，保证高可用性。 在 Nginx 中的 Work 进程中，为了应对高并发场景，采取了 Reactor 模型（也就是 I/O 多路复用，NIO）。 I/O 多路复用模型：在 I/O 多路复用模型中，最重要的就是系统调用 Select 函数。该方法能够同时监控多个文件描述符的可读可写情况（每一个网络连接其实都对应一个文件描述符），当其中的某些文件描述符可读可写时，Select 方法就会返回可读以及可写的文件描述符个数。 Nginx Work 进程使用 I/O 多路复用模块同时监听多个 FD（文件描述符）。当 Accept、Read、Write 和 Close 事件产生时，操作系统就会回调 FD 绑定的事件处理器。这时候 Work 进程再去处理相应事件，而不是阻塞在某个请求连接上等待。这样就可以实现一个进程同时处理多个连接。每一个 Worker 进程通过 I/O 多路复用处理多个连接请求。 为了减少进程切换（需要系统调用）的性能损耗，一般设置 Worker 进程数量和 CPU 数量一致。 Nginx 和 Apache 的区别轻量级，同样是 Web 服务，比 Apache 占用更少的内存及资源抗并发，Nginx 处理请求是异步非阻塞的，而 Apache 则是阻塞型的。 在高并发下 Nginx 能保持低资源低消耗高性能高度模块化的设计，编写相对简单，最核心的区别在于 Apache 是同步多线程模型，一个连接对应一个进程；Nginx 是异步的，多个连接（万级别）可以对应一个进程。 Nginx 的 upstream 支持的负载均衡模式 轮询 weight：指定权重 ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访问固定访问一个后台服务器 第三方：fair、url_hash Nginx 常见的优化配置 调整 worker_processes：指 Nginx 要生成的 Worker 数量。最佳实践是每个 CPU 运行 1 个工作进程。 最大化 worker_connections。 启用 Gzip：压缩文件大小，减少客户端 HTTP 的传输带宽，因此提高了页面加载速度。 为静态文件启用缓存。 禁用 access_logs：访问日志记录，它记录每个 Nginx 请求，因此消耗了大量 CPU 资源，从而降低了 Nginx 性能。 参考资料Nginx 的这些妙用，你都 get 到了吗]]></content>
      <categories>
        <category>NGINX</category>
      </categories>
      <tags>
        <tag>NGINX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单例模式]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F06%2F%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式的动机对于一个系统的某些类而言，无须创建多个实例。举个例子– Windows 任务管理器、在正常情况下，无论启动任务管理器多少次，Windows 系统始终只能弹出一个任务管理器窗口。也就是说，在一个Windows 系统中，任务管理器存在唯一性。这样设计有两个原因：第一，如果能弹出多个窗口，且这些窗口的内容完全一致，全部是重复对象，这势必会浪费系统资源（任务管理器需要获取系统运行时的诸多信息，这些信息的获取需要消耗一定的系统资源，包括 CPU 资源及内存资源等），而且根本没有必要显示多个内容完全相同的接口；第二，如果弹出的多个窗口不一致，问题就更加严重了，这意味着在某一瞬间系统资源使用情况和进程。服务等信息存在多个状态，例如任务管理器窗口 A 显示“CPU 使用率”为 10%，窗口B显示“CPU 使用率”为 15%，到底哪个才是正确的？这会给用户带来误解，更不可取。由此可见，确保 Windows 任务管理器在系统中有且仅有一个非常重要。 在实际开发中也经常遇到类似的情况，为了节约系统资源，有时需要确保系统中某个类只有唯一一个实例，当这个唯一实例创建成功之后，无法再创建一个同类型的其他对象，所有的操作都只能基于这个唯一实例。为了确保对象的唯一性，可以通过单例模式来实现，这就是单例模式的动机所在。 单例模式概述下面来模拟实现 Windows 任务管理器。假设任务管理器的类名为 TaskManager，在 TaskManager 类中包含了大量的成员方法，例如构造函数 TaskManager()，显示进程的方法 displayProcesses()，显示服务的方法 displayServices()等，该类的示意代码如下： 123456789101112131415161718class TaskManager&#123; // 初始化窗口 public TaskManager() &#123; ... &#125; // 显示进程 public void displayProcesses() &#123; ... &#125; // 显示服务 public void displayServices() &#123; ... &#125; ...&#125; 为了实现 Windows 任务管理器的唯一性，通过以下3步对TaskManager类进行重构： （1）由于每次使用 new 关键字来实例化 TaskManager 类时都将产生一个新对象，为了确保 TaskManager 实例的唯一性，需要禁止类的外部直接引用使用 new 来创建对象，因此需要将 TaskManager 的构造函数的可见性改为 private，如下 1private TaskManager() &#123; ... &#125; （2）将构造函数的可见性改为 private 后，虽然类的外部不能在使用 new 来创建对象，但是在 TaskManager 的内部还是可以创建对象的，可见性只对类外有效。因此，可以在 TaskManager 中创建并保存这个唯一实例。为了让外界可以访问这个唯一实例，需要在 TaskManager 中定义一个静态的 TaskManager 类型的私有变量，代码如下： 1private static TaskManager tm = null; （3）为了保证成员变量的封装性，将 TaskManager 类型的 tm 对象的可见性设置为 private，但外界该如何使用该成员变量并何时实例化该成员变量呢？答案是增加一个工友的静态方法，如下： 123456public static TaskManager getInstance() &#123; if (tm == null) &#123; tm = new TaskManager(); // 自行实例化 &#125; return tm;&#125; 在 getInstance() 方法中首选判断 tm 对象是否存在，如果不存在，则使用 new 关键字创建一个新的 TaskManager 类型的 tm 对象，再返回新创建的 tm 对象；否则直接返回已有的 tm 对象。需要注意的是 getInstance() 方法的修饰符。 首先它应该是一个 public 方法，以便外界其他对象使用；其次它使用了 static 关键字，即它是一个静态方法，在类外可以直接通过类名来访问，而无须创建 TaskManager 对象。事实上，在类外也无法创建 TaskManager 对象，因为构造函数是私有的。最终整合的代码如下： 12345678910111213class TaskManager &#123; private static TaskManager tm = null; private TaskManager() &#123; ... &#125; // 初始化窗口 public void displayProcesses() &#123; ... &#125; // 显示进程 public void displayServices() &#123; ... &#125; // 显示服务 public static TaskManager getInstance() &#123; if(tm === null) &#123; tm = new TaskManager(); &#125; return tm; &#125;&#125; 上述代码是单例模式的一种最典型实现方式，有了以上基础，理解单例模式的定义和结构就非常容易了。单例模式定义如下： 单例模式：确保某一个类只有一个实例，而且自行实例化并向这个系统提供这个实例，这个类称为单例类，它提供全局访问的方法。单例模式是一种对象性创建模式。 单例模式有 3 个要点：（1）某个类只有有一个实例；（2）它必须自行创建这个实例；（3）它必须自行向整个系统提供这个实例。单例模式的结构图如图所示： 负载均衡器的设计Sunny 软件公司承接了一个服务器负载均衡（Load Balance）软件的开发工作，该软件运行在一台负载均衡服务器上，可以将并发访问和数据流量分发到服务器集群中的多台设备上进行并发处理，提高系统的整体处理能力。由于集群汇总的服务器需要动态删减，且客户端请求需要统一分发，因此需要确保负载均衡器的唯一性，即只能有一个负载均衡器来负责服务器的管理和请求的分发，否则会带来服务器状态的不一致以及请求分配冲突等问题。 Sunny 公司开发人员通过分析和权衡，决定使用单例模式来设计该负载均衡器。将负载均衡器 LoadBalancer 设计为单例类，其中包含一个存储服务器信息的集合 serverList，每次在 serverList 中随机选择一台服务器来相应客户端的请求，实现代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 负载均衡器 LoadBalancer:单例类，真实环境该类非常复杂，包括大量初始化的工作和 * 业务方法，考虑到代码的可读性和易理解性，只列出部分与模式相关的核心代码 */public class LoadBalancer &#123; // 私有静态成员变量，存储唯一实例 private static LoadBalancer instance = null; // 服务器集合 private List serverList = null; private LoadBalancer() &#123; serverList = new ArrayList(); &#125; public static LoadBalancer getLoadBalancer() &#123; if (instance == null) &#123; instance = new LoadBalancer(); &#125; return instance; &#125; /** * 增加服务器 * @param server */ public void addServer(String server) &#123; serverList.add(server); &#125; /** * 删除服务器 * @param server */ public void removeServer(String server) &#123; serverList.remove(server); &#125; /** * 使用 Random 类随机获取服务器 * @return */ public String getServer() &#123; Random random = new Random(); int i = random.nextInt(serverList.size()); return (String) serverList.get(i); &#125;&#125; 1234567891011121314151617181920212223242526272829public class Client &#123; public static void main(String[] args) &#123; // 创建 4 个 LoadBalancer 对象 LoadBalancer balancer1, balancer2, balancer3, balancer4; balancer1 = LoadBalancer.getLoadBalancer(); balancer2 = LoadBalancer.getLoadBalancer(); balancer3 = LoadBalancer.getLoadBalancer(); balancer4 = LoadBalancer.getLoadBalancer(); // 判断服务器复制均衡器是否相同 if (balancer1 == balancer2 &amp;&amp; balancer2 == balancer3 &amp;&amp; balancer3 == balancer4) &#123; System.out.println("服务器负载均衡器具有唯一性"); &#125; // 增加服务器 balancer1.addServer("Server 1"); balancer1.addServer("Server 2"); balancer1.addServer("Server 3"); balancer1.addServer("Server 4"); // 模拟客户端请求的分发 for(int i = 0; i &lt; 10; i++) &#123; String server = balancer1.getServer(); System.out.println("分发请求至服务器： " + server); &#125; &#125;&#125; 编译并运行程序，输出结果如下： 虽然创建了 4 个 LoadBalancer 对象，但是它们实际上是同一个对象，因此，通过使用单例模式可以确保 LoadBalancer 对象的唯一性。 饿汉式单例与懒汉式单例的讨论Sunny 公司开发人员使用了单例模式实现了负载均衡器的设计，但是在实际使用中出现了一个非常严重的问题，当负载均衡器在启动过程中用户再次启动负载均衡器时，系统无任何异常，但当客户端提交请求时出现请求分发失败，通过仔细分析发现原来系统中还是存在多个负载均衡器对象导致分发时目标服务器不一致，从而产生冲突。为什么会这样？ 现在对负载均衡器的实现代码进行再次分析，当第一次调用 getLoadBalancer() 方法创建并启动负载均衡器时， instance 对象为 null 值，因此系统将执行代码 instance = new LoadBalancer()，在此过程中，由于要对 LoadBalancer 进行大量初始化工作，需要一段时间来创建 LoadBalancer 对象。而在此时，如果再一次调用 getLoadBalancer() 方法（通常发生在多线程环境中），由于 instance 尚未创建成功，仍为 null 值，判断条件 instance == null 为真值，因此代码 instance = new LoadBalancer() 将再次执行，导致最终创建了多个 instance 对象，这违背了单例模式的初衷，也导致系统发生运行错误。 如何解决该问题？至少有两种解决方案，在此之前，先介绍一下单例类的两种不同实现方式—饿汉式单例类和懒汉式单例类 饿汉式单例类饿汉式单例类是实现起来最容易的单例类，其代码如下： 12345678class EagerSingleton &#123; private static final EagerSingleton instance = new EagerSingleton(); private EagerSingleton() &#123;&#125; public static EagerSingleton getInstance() &#123; return instance; &#125;&#125; 当类被加载时，静态变量 instance 会被初始化，此时类的私有构造函数会被调用，单例类的唯一实例将被创建。如果使用饿汉式单例类实现负责均衡器 LoadBalancer 类的设计，则不会创建出多个单例对象的情况，可确保单例对象的唯一性。 懒汉式单例类与线程锁定除了饿汉式单例，还有一种经典的懒汉式单例，就是前面的负载均衡器 LoadBalancer 类的实现方式。由之前的代码可以看出，懒汉式单例在第一次调用 getInstance() 方法时实例化，在类加载时并不自行实例化，这种技术又称为延迟加载技术，即需要的时候再加载实例，为了避免多个线程同时调用 getInstance() 方法，可以使用关键字 synchronized，代码如下： 123456789101112class LazySingleton &#123; private static LazySingleton instance = null; private LazySingleton() &#123;&#125; synchronized public static LazySingleton getInstance() &#123; if (instance == null) &#123; instance = new LazySingleton(); &#125; return instance; &#125;&#125; 该懒汉式单例类在 getInstance() 方法面前增加了关键字 synchronized 进行线程锁定，以处理多个线程同时访问的问题。上述代码虽然解决了线程安全问题，但是每次调用 getInstance() 时都需要进行线程锁定判断，在多线程高并发访问环境中，将会导致系统性能大大降低。继续对懒汉式单例进行改进，事实上，无须对整个 getInstance() 方法进行锁定，只需锁定代码 instance = new LazySingleton() 即可。如下： 12345678public static LazySingleton getInstance() &#123; if (instance == null) &#123; synchronized (LazySingleton.class) &#123; instance = new LazySingleton(); &#125; &#125; return instance;&#125; 其实这样子也没有解决问题。原因如下：如果某一瞬间线程 A 和线程 B 都在调用 getInstance() 方法，此时 instance 对象为 null 值，均能通过 instance == null 的判断，由于实现了 synchronized 加锁机制，线程 A进入synchronized 锁定的代码中执行实例创建代码。但当 A 执行完毕时，线程 B并不知道实例已经创建，将继续创建新的实例，导致产生多个单例对象，因此需要进一步改进，在synchronized 锁定代码中再进行一次 instance == null 判断，这种方式称为双重检查锁定。完整代码如下： 12345678910111213141516171819class LazySingleton &#123; private volatile static LazySinleton instance = null; private LazySingleton() &#123;&#125; public static LazySingleton getInstance() &#123; // 第一重判断 if (instance == null) &#123; // 锁定代码块 synchronized(LazySingleton.class) &#123; // 第二重判断 if (instance == null) &#123; instance = new LazySingleton(); &#125; &#125; &#125; return instance; &#125;&#125; 需要注意的是，如果使用双重检查锁定来实现懒汉式单例类，需要在静态成员变量 instance 之前增加修饰符 volatile，被 volatile 修饰的成员变量可以确保多个线程都能够正确处理，且该代码只能在 JDK 1.5 及以上版本才能正确执行。由于 volatile 关键字会屏蔽 Java 虚拟机所做的一些代码优化，可能会导致系统运行效率降低，因此使用双重检查来实现单例模式也不是一种完美的实现方式。 饿汉式单例类与懒汉式单例类比较饿汉式单例类在类被加载时就将自己实例化，它的优点在于无须考虑多线程访问问题，可以确保实例的唯一性；从调用速度和反应时间来说，由于单例对象一开始就得以创建，因此要优于懒汉式单例。但是无论系统在运行时是否需要使用该单例对象，由于在类加载时该对象就需要创建，因此从资源利用效率角度来讲，饿汉式单例不及懒汉式单例，而且在系统加载时由于需要创建饿汉式单例对象，加载时间可能会比较长。 懒汉式单例类在第一次使用时创建，无须一直占用系统资源，实现了延迟加载，但是必须处理好多个线程同时访问的问题，特别是当单例类作为资源控制器，在实例化时必然涉及资源初始化，而资源初始化很有可能耗费大量时间，这意味着出现多线程同时首次引用此类的几率变得比较大，需要通过双重检查锁定机制进行控制，这将导致系统性能受到一定影响。 一种更好的单例实现方法饿汉式单例类不能实现延迟加载，不管将来用不用，它始终占据内存；懒汉式单例类线程安全控制烦琐，而且性能受影响。无论是饿汉式单例还是懒汉式单例都存在问题，接下来就介绍一种更好的方法，称之为 Initialization on Demand Holder（IoDH）。 实现 IoDH 时，需在单例类中增加一个静态内部类，在该内部类中创建单例对象，再将该单例对象通过 getInstance() 方法返回给外部使用，代码如下： 123456789101112131415161718192021class Singleton &#123; private Singleton() &#123; &#125; private static class HolderClass&#123; private static final Singleton instance = new Singleton(); &#125; public static Singleton getInstance() &#123; return HolderClass.instance; &#125; public static void main(String args[]) &#123; Singleton s1, s2; s1 = Singleton.getInstance(); s2 = Singleton.getInstance(); System.out.println(s1 == s2); &#125;&#125; 编译并运行上述代码，运行结果为 true，即创建的单例对象 s1 和 s2 为同一对象。由于静态单例对象没有作为 Singleton 的成员变量直接实例化，因此类加载时不会实例化 Singleton，第一次调用 getInstance() 时将加载内部类 HolderClass，在该内部类中定义了一个 static 类型的变量 instance，此时会首先初始化这个成员变量，由 Java 虚拟机来保证其线程安全性，确保该成员变量只能初始化一次。由于 getInstance() 方法没有任何线程锁定，因此其性能不会造成任何影响。 通过使用 IoDH，既可以实现延迟加载，又可以保证线程安全，不影响系统性能，因此，IoDH不失为一种比较好的 Java 语言单例模式实现方式；其缺点是与编程语言本身的特性相关，很多面向对象语言不支持 IoDH。 单例模式总结单例模式作为一种目标明确，结构简单，理解容易的设计模式，在软件开发中使用频率相当高，在很多应用软件和框架中得以广泛应用。 主要优点 单例模式提供了对唯一实例的受控访问。因为单例类封装了它的唯一实例，所以它可以严格控制客户怎样以及何时访问它。 由于在系统内存中只存在一个对象，因此可以节约系统资源，对于一些需要频繁创建和销毁的对象，单例模式无疑可以提高系统的性能。 允许可变数目的实例。基于单例模式，开发人员可以进行扩展，使用与控制单例对象相似的方法来获得指定个数的实例对象，既节省资源系统，又解决了由于单例对象共享过多有损性能的问题。 主要缺点 由于单例模式中没有抽象层，因此单例类的扩展有很大的困难。 单例类的职责过重，在一定程度上违背了单一原则。因为单例类既提供了业务方法，又提供了创建对象的方法（工厂方法），将对象的创建和对象本身的功能耦合在一起。 很多面向对象语言的运行环境都提供了自动垃圾回收技术，因此，如果实例化的共享对象长时间不被利用，系统会认为它是垃圾，会自动销毁并回收资源，下次利用时又将重新实例化，这将导致共享的单例对象状态的丢失。 使用场景 系统只需要一个实例对象。例如，系统要求提供一个唯一的序列号生成器或资源管理器，或者需要考虑资源消耗太大而只允许创建一个对象。 客户调用类的单个实例只允许使用一个公共访问点，除了该公共访问点，不能通过其他途径访问该实例。 参考资料《设计模式的艺术——软件开发人员内功修炼之道》 – 刘伟]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之jstat案例分析-Young GC]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F02%2FJVM%E4%B9%8Bjstat%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-Young-GC%2F</url>
    <content type="text"><![CDATA[百万级商机的BI系统​ 有这么一个场景，有一个服务于百万级商机的BI系统。所谓BI系统，简单来说，就是一个平台有数十万深圳上百万的商家在你的平台上做生意，会使用你的这个平台系统，此时会产生大量的数据。然后基于这些数据我们需要为商家提供一些数据报表，比如：每个商家每天有多少访客？有多少交易？付费转化率是多少？当然实际情况会比这个更复杂，这里只是说个概念。 ​ 此时就需要一套BI系统，所谓BI，全称是Business Intelligence，就是“商业智能”。就是把一些商家平时日常经营的数据收集起来进行分析，然后把各种数据报表展示给商家的一套系统。而所谓的商业智能，指的就是给你看一些数据报表，然后让你平时更好地了解自己的经营情况，然后让老板“智能”地去调整经营策略，提升业绩。 ​ 所以类似这样的一个BI系统，大致的运行逻辑如下所示： 首先，从我们提供给商家日常使用的一个平台上会采集出来很多商家日常经营的数据； 接着可以对这些经营数据依托各种大数据计算平台，比如Hadoop、Spark、Flink等技术进行海量数据的计算，计算出各种各样的数据报表； 然后我们需要将计算好的各种数据分析报表都放入一些存储中，比如MySQL、Elasticsearch、HBase都可以存放类似的数据； 最后，就是基于MySQL、HBase、Elasticsearch中存储的数据报表，基于Java开发出来一个BI系统，通过这个系统把各种存储好的数据暴露给前端，允许前端基于各种条件对存储的数据进行复杂的筛选和分析。 ​ 这个流程如图所示： 刚开始上线时的架构部署​ 我们这里重点作为案例分析的就是上述场景中的“BI系统”，其他环节都跟大数据相关的技术有关联的，暂时先不care。 ​ 刚开始的时候BI系统使用的商家是不多的，因为即使在一个庞大的互联网大厂里，虽然大厂本身积累了大量商家，但是要针对他们上线一个付费产品，刚开始未必所有人都买账，所以一开始系统上线就少数商家在使用，比如就几千个商家。 ​ 刚开始系统部署非常简单，就是用几台机器来部署上述的BI系统，机器都是普通的4核8G配置。在这个配置下，一般来说给堆内存中的新生代分配的内存都在1.5G左右，Eden区大概也就1G左右的空间，如图： 技术痛点：实时自动刷新报表 + 大数据量报表​ 刚开始，在少数商家的量级下，这个系统是没多大问题，运行的非常良好。但是问题恰恰就出在突然使用系统的商家数量开始暴涨的时候，突然使用系统的商家开始越来越多，例如，当商家的数量级达到几万的时候。此时要给大家说明一个此类BI系统的特点，就是在BI系统中有一种数据报表，它是支持前端页面有一个JS脚本，自动每隔几秒钟就发送请求到后台刷新一下数据的，这种报表称之为“实时数据报表” ​ 那么大家设想一下，假设仅仅就几万商家作为你的系统用户，很可能同一时间打开那个实时报表的商家就有几千个，然胡每个商家打开实时报表后，前端页面都会每隔几秒钟发送请求到后台加载最新数据，基本上会出现BI系统部署的每台机器每秒的请求会达到几百个，这里我们假设就是每秒500个请求吧。然后每个请求都会加载出来一张报表需要的大量数据，因为BI系统可能还需要针对那些数据进行内存中的现场计算加工一下，才能返回给前端页面展示，根据我们之前的测算，每个请求大概需要加载出来100KB的数据进行计算，因此每秒500个请求，就需要记载出来50MB的数据到内存中进行计算，如图： 没什么大影响的频繁Young GC​ 在上述系统运行模型下，基本上每秒会加载50MB的数据到Eden区中，只要区区20s，就会迅速填满Eden区，然后触发一次Young GC对新生代进行垃圾回收。当然1G左右的Eden进行Young GC速度相对是比较快的，可能也就几十ms的时间就可以搞定了。所以其实对系统性能影响并不大，而且上述BI系统场景下，基本上每次Young GC后存活对象可能就几十MB，甚至是几MB。 ​ 所以如果仅仅只是这样的话，那么大家可能会看到如下场景，BI系统运行20s过后，就会突然卡顿个10ms，但是对终端用户和系统性能几乎是没有影响的。 模拟频繁Young GC场景​ 接着我们会用一段程序来模拟上述BI系统那种频繁Young GC的一个场景，此时JVM参数如下所示： 1-XX:NewSize=104857600 -XX:MaxNewSize=104857600 -XX:InitialHeapSize=209715200 -XX:MaxHeapSize=209715200 -XX:SurvivorRatio=8 -XX:MaxTenuringThreshold=15 -XX:PretenureSizeThreshold=3145728 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log ​ 大家只要注意一下上述我们把堆内存设置为了200MB，把年轻代设置为了100MB，然后Eden区是80MB，每块Survivor区是10MB，老年代也是100MB。我们把案例中的内存大小适当缩小了一些，这样方便在本地电脑进行试验。 示例程序123456789101112131415161718public class Demo1 &#123; public static void main(String[] args) throws Exception &#123; Thread.sleep(30000); while (true) &#123; loadData(); &#125; &#125; private static void loadData() throws Exception &#123; byte[] data = null; for(int i = 0; i &lt; 50; i++) &#123; data = new byte[100 * 1024]; &#125; data = null; Thread.sleep(1000); &#125;&#125; ​ 针对这段示例程序给大家做一点说明。首先看第一行代码：Thread.sleep(30000);。这里刚开始休眠30s，是为了启动程序后，让我们找到这个程序的PID，也就是进行ID，然后再执行jstat命令来观察运行时的JVM的状态。 ​ 接着看loadData()方法内的代码，它会循环50次，模拟每秒50个请求，然后互每次请求都会分配一个100KB的数组，模拟每次请求会从存储中加载100KB的数据，接着会休眠1秒钟，模拟这一切都是发生在1秒内的。其实这些对象都是短生存周期的对象，所以方法运行结束直接对象都是垃圾，随时可以回收的。然后在main()方法里有一个while(true)循环，模拟系统按照每秒钟50个请求，每个请求加载100KB数据的方式不停地运行，除非我们手动终止程序，否则永不停歇。 通过jstat观察程序的运行状态​ 接着我们使用预定的JVM参数启动程序，此时程序会先进入一个30秒的休眠状态，此时尽快执行JPS命令，查看一下我们启动程序的进程ID，如下图： ​ 此时会发现我们运行的Demo1这个程序的JVM进程ID是51464，然后尽快执行下述jstat命令：jstat -gc 51464 1000 1000。它的意思是针对51464这个进程统计JVM运行状态，同时每隔1秒钟打印一次统计信息，连续打印1000次。然后我们就让jstat开始统计运行，每隔一秒它都会打印一行新的统计信息，过了几十秒后可以看到如下图所示的统计信息： ​ 接着我们一点点来分析这个图。首先我们先看如下图所示的一段信息： ​ 这个EU，就是之前我们所说的Eden区被使用的容量，可以发现它刚开始是3MB左右的内存使用量。接着从我们程序开始运行，会发现每秒钟都会有对象增长，从3MB左右到7MB左右，接着是12MB，17MB，22MB，每秒都会新增5MB左右的对象。这个跟我们写的代码是完全吻合的，我们就是每秒钟会增加5MB左右的对象。然后当Eden区使用量达到70多MB的时候，再要分配5MB的对象就失败了，此时就会触发一次Young GC，然后大家继续看下图： ![Young GC](JVM之jstat案例分析-Young-GC/Young GC.png) ​ 注意看上面红圈里的内容，大家会发现，Eden区的使用量从70多MB降低为1MB多，这就是因为一次Young GC直接回收掉了大部分对象。所以我们现在就知道了，针对这个代码示例，可以清晰地从jstat中看出来，对象增速大致为5MB每秒，大致在十几秒左右会触发一次Young GC。这就是Young GC的触发频率，以及每次Young GC的耗时。接着看下图： ​ 上图清晰告诉你，一次Young GC回收70多MB对象，大概就1毫秒，所以Young GC其实是很快的，即使回收800MB的对象，也就10毫秒那样。所以如果是线上系统，Eden区800MB的话，每秒新增对象50MB，十多秒一次Young GC，也就10毫秒左右，系统卡顿10毫秒，几乎没什么大影响。所以我们继续推论，在这个示例中，80MB的Eden区，每秒新增对象5MB，大概十多秒触发一次Young GC，每次Young GC耗时在1毫秒左右。 ​ 那么每次Young GC过后存活的对象呢？简单看上图，S1U就是Survivor中被使用的内存，之前一直都是0，在一次Young GC过后变成了675KB，所以一次Young GC后也就存活675KB的对象而已，轻松放入10MB的Survivor中。 ​ 而且大家注意上上图中的OU，那是老年代被使用的内存量，在Young GC前后都是0。说明这个系统运行良好，Young GC都不会导致对象进入老年代，这就几乎不需要什么优化了，因为几乎可以默认老年代对象增速为0，Full GC发生频率趋向于0，对系统无影响。 ​ 所以回顾一下，通过这个示例程序的运行，是不是可以通过jstat分析出来以下信息： 新生代对象增长的速率 Young GC的触发频率 Young GC的耗时 每次Young GC后有多少对象是存活下来的 每次Young GC过后有多少对象进入了老年代 老年代对象的增长速率 Full GC的触发频率 Full GC的耗时]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程杂记Ⅱ]]></title>
    <url>%2FCKING.github.io%2F2020%2F01%2F02%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%9D%82%E8%AE%B0%E2%85%A1%2F</url>
    <content type="text"><![CDATA[Java内存模型​ Java线程之间的通信采用的是共享内存模型，这里提到的共享内存模型指的就是Java内存模型（Java Memory Model，简称JMM），JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和内存之间的抽象关系：线程之间的共享变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写共享变量额的副本。本地内存是JMM的一个抽象概念，并不真实存在。它涵盖了缓存，写缓存区，寄存器以及其他的硬件和编译器优化。 ​ Java内存模型主要有read、load、use、assign、store、write这几个动作。举一个例子，下面这么一段代码： 12345678910111213141516171819202122232425262728293031323334public class HelloWorld &#123; private int data = 0; public void increment() &#123; data++; &#125; public int getData() &#123; return data; &#125; public static void main(String[] args) &#123; final HelloWorld helloWorld = new HelloWorld(); Thread thread1 = new Thread() &#123; @Override public void run() &#123; helloWorld.increment(); System.out.println("=====线程1：" + helloWorld.getData() + " ====="); &#125; &#125;; Thread thread2 = new Thread() &#123; @Override public void run() &#123; helloWorld.increment(); System.out.println("=====线程2：" + helloWorld.getData() + " ====="); &#125; &#125;; thread1.start(); thread2.start(); &#125;&#125; ​ 通过上面的代码，我们来梳理一下线程与共享变量之间的关系： Java并发之原子性、有序性和可见性原子性​ 原子性指的是一个或者多个操作在CPU执行的过程中不被中断的特性。 ​ 线程切换带来的原子性问题 ​ Java并发程序都是基于多线程的，操作系统为了充分利用CPU的资源，将CPU分成若干个时间片，在多线程环境下，线程会被操作系统调度进行任务切换。 ​ 为了直观了解什么是原子性，我们看下面哪些操作是原子性操作 123int count = 0;count++;int a = count; ​ 上面展示语句中，除了语句1是原子操作，其它两个语句都不是原子性操作，下面来分析一下语句2。其实语句2在执行的时候，包含三个指令操作： 指令1：首先。先把变量count从内存加载到CPU的寄存器 指令2：之后，在寄存器中执行 +1 操作 指令3：最后，将结果写入内存 ​ 对于上面的三条指令来说，如果线程A在指令1执行后做线程切换，线程A和线程B按照下图的序列执行，那么我们会发现两个线程都执行了count += 1的操作，但是得到的结果不是我们期待的2，而是1。 ​ 操作系统做任务切换，可以发生在任何一条CPU指令执行完 有序性​ 有序性指的是程序按照代码的先后顺序执行 ​ 编译优化带来的有序性问题 ​ 为了性能优化，编译器和处理器会进行指令重排序，有时候会改变程序中语句的先后顺序，比如程序： 12345678910flag = false;// 线程1prepare(); // 准备资源falg = true;// 线程2while(!flag) &#123; Thread.sleep(1000);&#125;execute(); // 基于准备好的资源执行操作 ​ 重排序之后，让flag = true先执行了，会导致线程2直接跳过while等待，执行某段代码，结果prepare()方法还没执行，资源还没准备好，此时就会导致代码逻辑出现异常。 ​ synchronized（具有有序性、原子性、可见性）表示锁在同一时刻中一个线程进行获取，当锁被占用后，其他线程只能等待。在单例模式的实现上有一种双重检验锁定的方式 1234567891011121314151617181920public class Singleton &#123; private Singleton() &#123; &#125; private volatile static Singleton instance = null; public static Singleton getInstance() &#123; if(instance == null) &#123; synchronized (Singleton.class) &#123; if(instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; ​ 我们先看instance = new Singleton()的未被编译器优化的操作： 指令1：分配一块内存M； 指令2：在内存M初始化Singleton对象； 指令3：然后M的地址赋值给instance变量； 编译器优化后的操作指令： 指令1：分配一块内存M； 指令2：将M的地址赋值给instance变量； 指令3：然后内存M上初始化Singleton对象。 ​ 现有A，B两个线程，我们假设线程A先执行了getInstance()方法，当执行编译器优化后的操作指令2时（此时未完成对象的初始化），这时发生了线程切换，那么线程B进入，刚好执行到第一次判断instance == null会发现instance不等于null了，所以直接返回instance，而此时的instance，是没有初始化过的。 可见性​ 可见性指的是当一个线程修改了共享变量后，其它线程能够立刻得知这个修改。 缓存导致的可见性问题 ​ 让我们回顾一下上面讲的java内存模型： 我们定义的所有变量都存储在主内存中。 每个线程都有自己独立的功能内存，里面保存该线程使用到的变量的副本（主内存中该变量的一份拷贝） 线程对共享变量所有的操作都必须在自己的工作内存中进行，不能直接从主内存中读写（不能越级） 不同线程之间也无法直接访问其他线程的工作内存中的变量，线程间变量值的传递需要通过主内存来进行。（同级之间不能相互访问） ​ 线程1对共享变量的修改要被线程2及时看到的话，要经过如下步骤： 把工作内存1中更新的变量刷新到主内存中； 把主内存中的变量的值更新到工作内存2中 我们可以使用synchronized、volatile、final来保证可见性 volatile​ volatile关键字是用来保证可见性和有序性，在有些罕见的条件下，可以有限的保证原子性，但它不是用来保证原子性的。基本原理是当一个线程对一个volatile修饰的共享变量进行修改后，会强制线程将这个修改后的副本刷入主内存，同时，让其他线程对这个共享变量的副本进行失效，让他们重新去主内存中读取数据，从而保证可见性。 ​ 那volatile是如何保证有序性的呢？它是如何避免指令重排的呢？这就涉及了Java中的一个原则，叫做happens-before原则。在编译器对代码进行代码重排序之前，要遵守happens-before原则。如果符合happens-before原则，那么就不能胡乱重排，如果不符合这些规则，那就可以自己排序。happens-before规则包括以下几个： 程序次序规则：一个线程内，按照代码顺序，书写前面的操作先行发生于书写后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。 锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。比如说在代码里对一个锁的lock.lock()、lock.unlock()、lock.lock()操作，第二个unlock操作要先行发生于第三个的lock操作，而不能重排序成lock.lock()、lock.lock()、lock.unlock()。 volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个volatile变量的读操作。volatile变量写，再读，必须保证是先写，再读。 传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。例如thread.start()要先行发生于thread.interrupt()，而不能将thread.interrupt()重排序到thread.start()前面。 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。 线程终结原则：线程中所有的操作都先行发生于线程的终止检测。我们可以通过thread.join()方法结束、thread.isAlive()的返回值手段检测到线程已经终止执行。 对象终结规则：一个对象的初始化完成先行发生于它的finalize()方法的开始。 ​ 这8条规则是避免出现乱七八糟扰乱秩序的指令重排，要求是这几个重要的场景下，要按照顺序来执行。这8条规则之外，可以重排指令。这happens-before规则也说明了为什么volatile为什么能保证它的有序性。因为volatile要求的是，volatile前面的代码一定不能指令重排到volatile变量操作后面，volatile后面的代码也不能指令重排到volatile前面。 ​ volatile在底层是如何保证可见性和有序性的呢？ （1）lock指令：volatile保证可见性 ​ 对volatile修饰的变量，执行写操作的话，JVM会发送一条lock前缀指令给CPU，CPU在计算完之后会立即将这个值写会主内存，因为同时有MESI缓存一致性协议，所以各个CPU都会对总线进行嗅探，自己本地缓存中的数据是否被别人修改。 ​ 如果发现别人修改了某个缓存的数据，那么CPU就会将自己本地缓存的数据过期掉，然后这个CPU上执行的线程在读取这个变量的时候，就会从主内存重新加载最新的数据了。 ​ lock前缀指令+ MESI缓存一致性协议 （2）内存屏障：volatile禁止指令重排序 ​ 先简单了解两个指令： Store：将处理器缓存的数据刷新到内存中 Load：将内存存储的数据拷贝到处理器的缓存中 屏障类型 指令示例 说明 LoadLoad Load1;LoadLoad;Load2 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的操作 StoreStore Store1;StoreStore;Store2 该屏障确保Store立刻刷新数据到内存（使其对其它处理器可见）的操作先于Store2及其后所有存储指令的操作 LoadStore Load1;LoadStore;Store2 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作 StoreLoad Store1;StoreLoad;Load2 该屏障确保Store1立刻刷新到内存的操作先于Load2及其后所有装载指令的操作。它会使屏障之前的所有内存访问指令（存储指令和访问指令）完成之后，才执行改屏障之后的内存访问指令 1234Load1:int localVar = this.variableLoadLoad屏障int localVar = this.variable2 12345Store1:this.variable = 1StoreStore屏障Store2:this.variable = 2 ​ 那么volatile的作用是什么呢？ 123volatile variable = 1this.variable = 2 // store操作int localVariable = this.variable // load操作 ​ 每个volatile写操作前面，加StoreStore屏障，禁止上面的普通写和他重排；每个volatile写操作后面，加StoreLoad屏障，禁止跟下面的volatile读/写重排。 ​ 每个volatile读操作后面，加LoadLoad屏障，禁止下面的普通读和volatile读重排；每个volatile读操作后面，加LoadStore屏障，禁止下面的普通写和volatile读重排。 ​ volatile经常用于以下场景：状态标记变量、Double Check、一个线程写多个线程读。 参考资料 Java并发之原子性、有序性、可见性]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池杂记]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F27%2FJava%E7%BA%BF%E7%A8%8B%E6%B1%A0%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[简单说一下Java线程池的底层工作原理​ 一般情况下，系统是不会说无限制地创建大量的线程，会构建一个线程池，保持一定数量的线程，让他们执行各种各样的任务，线程执行完任务后，不要销毁自己，继续去等待执行下一个任务。这样可以避免频繁地创建线程和销毁线程。 12345678ExecutorService threadPool = Executors.newFixedThreadPool(3);threadPool.submit(new Callable&lt;Object&gt;() &#123; @Override public Object call() throws Exception &#123; return null; &#125;&#125;); ​ 大概流程是这样的：提交任务，先看一下线程池里的线程数量是否小于corePoolSize，也就是上面代码的3。如果小于，直接创建一个线程出来执行你的任务；执行完任务之后，这个线程是不会死掉的，它会尝试从一个无界的LinkedBlockingQueue里获取新的任务，如果没有新的任务，此时就会阻塞住，等待新的任务到来。 ​ 应用持续提交任务，上述流程反复执行，只要线程池的线程数量小于corePoolSize，都会直接创建新线程来执行这个任务，执行完了就尝试从无界队列里获取任务，知道线程里有corePoolSize个线程；接着再次提交任务，会发现线程数量已经跟corePoolSize一样大了，此时就会直接把任务放入队列中就可以了，线程会争取获取任务执行。如果所有人的线程此时都在执行任务，那么无界队列里的任务就可能会越来越多。 线程池的核心配置参数​ 上面的那段代码：Executors.newFixedThreadPool(3);，进去里面查看源码，是这样子的： 12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()); &#125; ​ 创建一个线程池就是这样子的。除了那个0L，参数依次是corePoolSize、maximumPoolSize，keepAliveTime，queue。如果你不用fixed之类的线程池，可以自己通过这个构造函数创建自己的线程池。 1234corePoolSize: 3maximumPoolSize: 200keepAliveTime: 60snew ArrayBlockingQueue&lt;Runnable&gt;(200) ​ 如果你把queue做成有界队列，比如上面的new ArrayBlockingQueue(200)，假设corePoolSize个线程都在繁忙地工作，大量的任务进入有界队列，队列满了，如果你的maximumPoolSize是比corePoolSize大的，此时会继续创建额外的线程放入线程池里，来处理这些任务，然后超过corePoolSize数量的线程如果处理完了一个任务也会尝试从队列里去获取任务来执行。 ​ 如果额外线程都创建完了去处理任务了，队列还是满了，此时还有新的任务，那该怎么办？只能reject掉。目前有几种reject策略，可以传入RejectExecutionHandler AbortPolicy DiscardPolicy DiscardOldestPolicy CallerRunsPolicy 自定义 ​ 如果后续队列里，慢慢没有任务了，线程空闲了，超过corePoolSize的线程会自动释放掉，在keepAliveTime之后就会释放。在具体场景中，我们可以根据上述原理定制自己的线程池，来考虑corePoolSize的数量、队列类型、最大线程数量、拒绝策略和线程释放时间等等。一般常用的是fixed线程。 线程池的队列满了之后会发生什么事情​ 这个要分情况考虑，如果maximumPoolSize是Integer.MAX_VALUE，那么线程池会创建无限多的线程，最终有可能导致内存溢出或者CPU负载过高而服务器挂掉。如果maximumPoolSize不是Integer.MAX_VALUE，而线程池的队列是无界队列，那么有可能系统会创建大量任务塞进队列中，最终导致内存溢出；如果队列是有界的，并且maximumPoolSize不是Integer.MAX_VALUE，那么有可能部分任务没被执行到而被reject掉。可以自定义一个reject策略，如果线程池无法执行更多的任务，此时建议可以把这个任务信息持久化写入到磁盘里去，后台专门启动一个线程，后续等待线程池的工作负载降低了，可以慢慢地从磁盘读取之前持久化的任务，重新提交到线程池里去执行。 线上机器突然宕机，如果处理线程池阻塞队列中的请求​ 服务器突然宕机，会导致线程池里积压的任务丢失。可以这么处理，如果你要提交一个任务到线程池里去，在提交之前，先在数据库里插入这个任务的信息，更新它的状态：未提交。已提交、已完成。提交成功之后，更新它的状态是已提交状态。 ​ 系统重启，后台线程去扫描数据库里的未提交和已提交状态的任务，可以把任务的信息读取出来，重新提交到线程池里去，继续执行。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程杂记]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F23%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E6%9D%82%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[synchronized关键字的底层原理​ synchronized底层的原理，是跟jvm指令和monitor有关系的。你如果用到了synchronized关键字，在底层编译后的jvm指令中，会有monitorenter和monitorexit两个指令。 123monitorenter // 代码对应的指令monitorexit ​ 那么monitorenter指令执行的时候会干什么呢？每个对象都有一个关联的monitor。比如一个实例对象就有一个monitor，一个类的Class对象也有一个monitor，如果要对这个对象加锁，那么必须先获取这个对象关联的monitor的lock锁。 ​ 它的原理和思路大概是这样的：monitor里面有一个计数器，从0开始。如果一个线程要获取monitor的锁，就看看它的计数器是不是0，如果是0的话，那么说明没人获取锁，它就可以获取锁了，然后对计数器加1。 ​ 这个monitor的锁是支持重入加锁的，什么意思呢？好比下面的代码片段： 12345678synchronized(myObject) &#123; // 一大堆代码 synchronized(myObject) &#123; // 一堆代码 &#125;&#125; ​ 加锁，一般来说都是必须对同一个对象进行加锁。如果一个线程第一次synchronized那里，获取到了myObject对象的monitor的锁，计数器加1，然后第二次synchronized那里，会再次获取myObject对象的monitor的锁，这个就是重入加锁了，然后计数器会再次加1，变成2。 ​ 这个时候，其他的线程在第一次synchronized那里，会发现myObject对象的monitor锁的计数器是大于0的，意味着被别人加锁了，然后此时线程就会进入block阻塞状态，什么都干不了，就是等着获取锁。 ​ 接着如果出了synchronized修饰的代码片段的范围，就会有一个monitorexit指令在底层。此时获取锁的线程就会对那个对象的monitor的计数器减1，如果有多次重入加锁就会对应多次减1，直到最后计数器是0。然后后面block住阻塞的线程，会再次尝试获取锁，但是只有一个线程可以获取到锁。 CAS的理解及其底层实现原理​ 首先我们先看这一段代码： 12345678910111213141516public class MyObject &#123; int i = 0; // 在一个对象实例的方法上加上synchronized // 同一时间只有一个线程可以进入这个方法 public synchronized void increment() &#123; i++ &#125; public static void main(String[] args) &#123; // 第一个线程同时都基于myObject这一个对象，来执行increment()方法 MyObject myObject = new MyObject(); myObject.increment(); &#125;&#125; ​ 上面的代码中，synchronized的意思就是针对当前执行这个方法的myObject对象进行加锁，此时只有一个线程可以成功地对myObject加锁，可以对它关联的monitor的计数器加1.一旦多个线程并发的去执行synchronized加锁，这就会变成串行化，导致很多线程都要去排队去执行，效率并不是太高。 ​ 再来看下面的这段代码： 1234567891011public class MyObject &#123; // 底层就是基于CAS来进行实现的 AtomicInteger i = new AtomicInteger(0); // 多个线程此时执行这段代码 // 不需要synchronized加锁，也是线程安全的 public void increment() &#123; i.incrementAndGet(); &#125;&#125; ​ CAS（compare and set）。就是设值的时候先进行比较，如果当前的值等于之前获取到的旧值，就说明之前没有其他线程对这个值进行过修改，就可以将我们的新值设置给它。如果当前的值不等于我们之前获取的旧值，说明之前有线程对它进行过修改，那么就设置新值失败。 ​ CAS在底层的硬件级别给你保证一定是原子性的，同一时间只有一个线程可以执行CAS。先比较再设置，其他的线程的CAS同时间去执行就会失败。 ​ ConcurrentHashMap实现线程安全的底层原理​ 多个线程访问同一个数据，为了保证线程安全，可以synchronized加锁，或者CAS进行安全的累加，从而实现多线程场景下安全更新一个数据的效果。在比较多的情况下，可能就是多个线程同时读写一个HashMap。 ​ 为了保证线程安全，可以对HashMap进行synchronized，但没这个必要。HashMap的底层就是一个大的数组，假设多个线程过来，线程1要put的位置是数组[5]，线程2要put的位置是数组[21]，如果使用synchronized加锁，那么线程1跟线程2就要排队执行，但这明显不好，锁的粒度太粗，效率太低。除非是对同一个元素执行put操作，此时多线程才需要进行同步。 ​ 因此，JDK并发包里推出了一个ConcurrentHashMap，它默认实现了线程安全。在JDK1.7以及之前的版本，ConcurrentHashMap底层采取的是分段加锁来实现线程安全。ConcurrentHashMap本身是一个大数组，把它拆成多个数组：[数组1]，[数组2]，[数组3]…，每个数组都对应一个锁，这就是分段加锁。 ​ [数组1]，[数组2]，[数组3] -&gt; 每个数组都对应一个锁，分段加锁 ​ 当多个线程过来，线程1要put的位置是数组1的第五个位置[5]，线程2要put的位置是数组2的第21个位置[21]，那这样子两个线程就互不干扰，可以同时对ConcurrentHashMap赋值。 ​ JDK1.8以及之后，对ConcurrentHashMap做了一些优化和改进，就是细化锁的粒度。在JDK1.8及其之后，ConcurrentHashMap底层还是一个大的数组，但对数组每个元素进行put操作，都是有一个不同的锁。刚开始进行put的时候，如果两个线程都是在数组[5]这个位置进行put。这个时候，就是对数组[5]这个位置进行put的时候，采取的是CAS的策略。 ​ 同一时间，只有一个线程能成功执行这个CAS。就是说，它刚开始先获取一下数组[5]这个位置的值，为null，然后执行CAS，然后线程1比较当前还是null，就可以put进去我的这条数据。同时间，其他线程执行CAS，都会失败。 ​ 这其实也可以算是分段加锁，通过对数组每个元素执行CAS的策略。如果是很多线程对数组里不同的元素执行put，大家互不干扰，没有关系。如果其他线程失败了，发现数组[5]这个位置，已经别人放进去值了，就需要在这个位置基于链表+红黑树进行处理。就是synchronized(数组[5])进行加锁，然后基于链表或者红黑树在这个位置插进去自己的数据。所以说，如果你是对数组里同一个位置的元素进行操作，才会加锁进行串行化处理；如果是对数组不同位置的元素操作，那么此时大家可以并发执行。 ​ 总的来说，在JDK1.8之前，多个数组，分段加锁，一个数组一个锁。在JDK1.8之后，优化细粒度，一个数组，每个元素进行CAS，如果失败说明有人了，此时synchronized对数组元素进行加锁，基于链表+红黑树处理，对数组每个元素加锁。 简单说一下AQS​ AQS，全称Abstract Queue Synchronizer，中文名叫抽象队列同步器。java并发包中的Semahore和部分Lock底层的实现原理都是利用AQS，例如可重入锁ReentrantLock。现在简单说一下AQS的原理。 ​ AQS内部主要包含state变量，一个存储当前加锁线程的变量和一个等待队列。当多个线程访问时，先通过CAS尝试更新state的变量，如果成功了，将加锁线程的变量更改为自己，并进行后续操作。如果失败了，进入队列等待，等待拥有锁的线程释放锁后唤醒。大概如下图： ​ 接下来会涉及到公平锁和非公平锁。像ReentractLock，默认就是非公平锁。只有ReentrantLock lock = new ReentrantLock(true)时，才是公平锁。那什么是公平锁，什么是非公平锁。例如上面那个图，非公平锁就是，此时线程1释放了资源，唤醒线程2，但此时刚好线程3来进行CAS加锁等操作，并且成功了，那是此时就是线程3获取这个锁，而线程2继续回到等待队列。这就是非公平锁。 ​ 公平锁就是新的线程来获取锁时，会先看等待队列是否有其它线程，有的话就进入等待队列。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[捋一遍MySQL索引结构]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F18%2F%E6%8D%8B%E4%B8%80%E9%81%8DMySQL%E7%B4%A2%E5%BC%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[从一个简单的表开始​ 首先我们先建一个表，语句如下： 1234567create table user( id int primary key, age int, height int, weight int, name varchar(32))engine = innoDb; ​ 然后往这个表中插入一些数据： 12345INSERT INTO user(id,age,height,weight,name)VALUES(2,1,2,7,'小吉');INSERT INTO user(id,age,height,weight,name)VALUES(5,2,1,8,'小尼');INSERT INTO user(id,age,height,weight,name)VALUES(1,4,3,1,'小泰');INSERT INTO user(id,age,height,weight,name)VALUES(4,1,5,2,'小美');INSERT INTO user(id,age,height,weight,name)VALUES(3,5,6,7,'小蔡'); ​ 最后，我们查一下这些数据是否已经放入表中 1select * from user; ​ 结果如下： ​ 可以看到，数据已经完整地放到我们创建的user表中。但是有一个地方需要注意：我们插入的数据都是乱序的，但MySQL好像按照id给我们的数据排了序。为什么会出现MySQL在我们没有显式排序的情况下，默默帮我们排序了？它是在什么时候进行排序的？ 页的引入​ 在操作系统的概念中，当我们往磁盘中取数据，假设要取出的数据的大小是1KB，但是操作系统并不会只取出这1KB的数据，而是会取出4KB的数据，因为操作系统的一个页表项的大小是4KB。那为什么我们主需要1KB的数据，但是操作系统要取出4KB的数据呢？ ​ 这就涉及到一个程序局部性的概念，大概就是“一个程序在访问了一条数据之后，在之后会有极大可能再次访问这条数据和访问这条数据的相邻数据”。所以索性直接加载4KB的数据到内存，下次要访问这一页的数据时，直接从内存中找，可以减少磁盘IO次数。因此磁盘IO是影响程序性能主要的因素，因为磁盘IO和内存IO的速度是不可同日而语的。 ​ 我们回到数据库层面中，重新理解页的概念。假设还是我们刚才插入的那些数据，我们现在要找id=5的数据，依照最原始的方式，我们一定会想到的就是遍历。这也是我们刚开始学计算机的时候最常用的寻找数据的方式。我们来看看，以遍历的方式，我们找到id=5的数据，需要经历几次磁盘IO。 ​ 首先，我们得先从id=1的数据开始读起，然后判断是否是我们需要的数据，如果不是，就再取id=2的数据，再进行判断，循环往复。在MySQL帮我们排好序之后，我们需要经历五次磁盘IO，才能将5号数据找到并读出来。 ​ 如果引入页的概念后，我们是如何读取数据的。 ​ 在引入页的概念后，MySQL会将多条数据存入一个叫“页”的数据结构中，当MySQL读取id=1的数据时，会将id=1数据所在的页整页读到内存中，然后在内存中进行遍历判断，由于内存的IO速度比磁盘高很多，所以相对于磁盘IO，几乎可以忽略不计。 ​ 假设一页可以存4条数据，那么我们第一次读取id=1的数据，并且将id=1到id=4的数据全部读到内存中，这是第一次磁盘IO。第二次将读取id=5的数据到内存中，这是第二次磁盘IO。我们只需要经历2次磁盘IO就可以找到id=5的这条数据。 ​ 但其实，在MySQL的InnoDB引擎中，页的大小是16KB，是操作系统的4倍，而int类型的数据是4个字节，其他类型的数据的字节数通常也在4000字节以内，所以一页是可以存放很多条数据的。而MySQL的数据正是以页为基本单位组合而成的。 ​ 上图是我们目前为止所理解的页的结构，它包含我们的多条数据。另外，MySQL的数据以页组成，那么它有指向下一页的指针和指向上一页的指针。 ​ 到这里，可以回答第一个问题。MySQL实际上就是在我们插入数据的时候，就帮我们在页中排好了序。至于为什么排序，接着往下看。 排序对性能的影响​ 上面我们提了一个问题，为什么数据库再插入数据时要对其进行排序呢？这就涉及到一个数据库查询流程的问题了。无论如何，我们是绝对不会平白无故地在插入数据时增加一个操作让流程复杂化的，所以插入数据时排序一定有其目的，就是优化查询的效率。而我们不难看出，页内部存放数据的模块，实质上就是一个链表结构，链表的特点就是增删快，查询慢。所以优化查询的效率是必须的。 基于单页模式存储的查询流程​ 还是基于上面的那张页图来说，我们插入了五条数据，id分别是从1-5，那么假设我要找一个表中不存在的id，假设id = -1，那么查询的流程就是： ​ 将id=1的这一整页数据取出，进行逐个比对，那么当我们找到id=1的这条数据时，发现这个id大于我们所需要找的那个id。由于数据库再插入数据时，已经进行过排序了，那么在id=1的数据后面，都是id &gt; 1的数据，所以我们就不需要再继续往下找了。 ​ 如果在插入时没有进行排序，那我们需要在继续往下寻找，逐条查找直到结尾也没有找到这条数据，才能返回不存在这条数据。当然，这只是排序优化的冰山一角。 上述页模式可能带来的问题​ 说完了排序，我们就分析一下上面的那张页图，对于大数据量下有什么弊端，或者说，我们可以怎么对这个模式进行优化。 ​ 不难看出，现阶段我们了解的页模式中，只有一个功能，就是在查询某条数据的时候直接将一整页的数据加载到内存中，以较少磁盘IO次数，从而提高性能。但是，我们也可以看到，现在的页模式内部，实际上是采用了链表的结构，前一条数据指向后一条数据，本质上还是通过数据的逐条比较来取出特定的数据。 ​ 如果这一页中有一百万条数据，我们要查的数据正好在最后一个，那么我们是不是一定要从前往后找到这一条数据呢r？如果是这样，我们需要查找的次数就达到了一百万次，即使是在内存中查找，这个效率也是不高的。那么有什么办法来优化这种情况下的查找效率呢？ 页目录的引入​ 打个比方，我们在看书的时候，如果要找到某一节，而这一节我们并不知道在哪一页，我们不需要从前往后，一节一节寻找我们需要的内容。以为在书的前面，存在目录，它会告诉你这一节在哪一页。在数据库的页中，实际上也使用了这种目录的结构，这就是页目录。 ​ 在引入页目录之后，我们所理解的页结构，就变成了这样： ​ 分析下这张图，实际上页目录就像是我们在看书的时候书本的目录一样，目录项1就相当于第一节，目录项2就相当于第二节，而每一条数据就相当于书本的每一页，这张图就可以解释成：第一节从第一页开始，第二节从第三页开始。而实际上，每个目录项会存放自己这个目录项当中最小的id，也就是说，目录项1中会存放1，而目录项2会存放3。 ​ 对比一下数据库在没有页目录时候的查找流程，假设要查找id=3的数据，在没有页目录的情况下，需要查找id=1、id=2、id=3，三次才能找到该数据，而如果有页目录之后，只需要先查看一下id=3存在于哪个目录项下，然后直接通过目录项进行数据的查找即可，如果在该目录项下没有找到这条数据，那么就可以直接确定这条数据不存在，这样就大大提升了数据库的查找效率。但是这种页目录的实现，首先就需要基于数据是在已经进行过排序的场景下，才可以发挥其作用，所以到这里，大家应该明白第二个问题了，为什么数据库在插入时会进行排序，这才是真正发挥排序的作用的地方。 页的扩展​ 在上文中，我们基本上说明白了数据库中页的概念，以及它是如何基于页来减少磁盘IO次数，以及排序是如何优化查询的效率的。 ​ 那么第三个问题：在开头说页的概念的时候，我们有说过，MySQL中每一页的大小只有16KB，不会随着数据的插入而自动扩容，所以这16KB不可能存下我们所有的数据，那么必定会有多个页来存储数据。那么在多页的情况下，MySQL中又是怎么组织这些页的呢？ ​ 针对这个问题，我们继续画出来我们现在多了解的多页的结构图： ​ 可以看到，在数据不断变多的情况下，MySQL会再去开辟新的页来存放新的数据，而每个页都有指向下一页的指针和指向上一页的指针，将多有页组织起来（这里修改了数据，将每一列的数据都放到了数据区中，其中第一个空格之前的代表id）,第一页中存放id为1-5的数据，第二页存放id为6-10的数据，第三页存放id为11-15的数据。需要注意的是，在开辟新页的时候，我们插入的数据不一定是在新开辟的页上，而是要进行所有页的数据比较，来决定这条插入的数据放在哪一页上，而完成数据插入后，最终的多页结构会像上图中画的那样。 多页模式​ 在多页模式下，MySQL终于完成多数据的存储，就是采用开辟新页的方式，将多条数据放在不同的页中，然后同样采用链表的数据结构，将每一页连接起来，那么可以思考第四个问题：多页情况下是否对查询效率有影响呢？ 多页模式对于查询效率的影响​ 答案是肯定的，多页会对查询效率产生一定的影响，影响主要就体现在，多页其本质也是一个链表结构，只要是链表结构，查询效率一定不会高。 ​ 假设数据又非常多，数据库就会开辟非常多的新页，而这些新页就会像链表一样连接在一起，当我们要在这么多页中查询某条数据时，它还是会从头节点遍历到存在我们需要的那条数据所存在的页上。我们好不容易通过页目录优化了页中数据的查询效率，现在又出现了以页为单位的链表。 优化多页模式​ 由于多页模式会影响查询的效率，那么肯定需要有一种方式来优化多页模式下的查询。既然我们可以用页目录的优化页内的数据区，那么我们也可以采取类似的方式来优化这种多页的情况。是的，页内数据区和多页模式本质上都是链表，的确可以采用相同的方式来对其进行优化，它就是目录页。 ​ 我们对比页内数据区，来分析如何优化多页结构。在单页时，我们采用了页目录的目录项来指向一行数据，这条数据就是存在于这个目录项中的最小数据，那么就可以通过页目录来查找所需数据。 ​ 所以对于多页结构也可以采用这种方式，使用一个目录项来指向某一页，而这个目录项存放的就是这一页中存放的最小数据的索引值。和页目录不同的地方在于，这种目录管理的级别是页，而页目录管理的级别是行。 ​ 分析到这里，我们多页模式的结构就会是下图所示的那样： ​ 存在一个目录页还管理目录，目录页中的数据存放就是指向的那一页中最小的数据。这里需要注意的一点是：其实目录页的本质也是页，普通页中存放的数据是项目数据，而目录页中存的数据是普通页的地址。 ​ 假设我们要查找id = 19的数据，按照以前的查找方式，我们需要从第一页开始查找，发现不存在那么再到第二页查找，一直找到第四页才能找到id = 19的数据，但是如果有了页目录，就可以使用id = 19与页目录中存放的数据进行比较，发现19大于任何一条数据，于是进入id = 16指向的页进行查找，然后再通过页内的页目录行级别的数据的查找，很快就可以找到id为19的数据了。随着数据越来越多，这种结构的效率相对于普通的多页模式，优势也就越来越明显。 ​ 相信对MySQL比较了解的同学已经发现，我们画的最终的这幅图，就是MySQL中的一种索引结构-B+树。 B+树的引入​ 接着往下说，我们将我们画的存在在目录页的多页模式图宏观化，可以形成下面的这张图： ​ 这就是我们兜兜转转由简到繁形成的一颗B+树。和常规B+树有些许不同，这是一棵MySQL意义上的B+树，MySQL上的一种索引结构，其中的每个节点就可以理解为是一个页，而叶子节点也就是数据页，除了叶子节点以外的节点就是目录页。 ​ 这一点在图中也可以看出来，非叶子节点只存放了索引，而只有叶子节点存放了真是的数据，这也是符合B+树的特点。 B+树的优势由于叶子节点上存放了所有的数据，并且有指针相连，每个叶子节点在逻辑上是相连的，所以对于查找范围比较友好。 B+树的所有数据都在叶子节点上，所以B+树的查询效率稳定，一般都是查询3次。 B+树有利于数据库的扫描。 B+树有利于磁盘的IO，因为它的层高基本不会因为数据扩大而增高（三层树结构大概可以存放两千万数据量）。 页的完整结构​ 说完了页的概念和页时如何一步一步地组合成为B+树的结构之后，相信大家对于页都有了一个比较清楚的认知。所以这里就要开始说说官方的概念了。基于我们上文所说的，给出一个完整的页结构，也算是对上文中理解的页结构的一种补充。 ​ 上图为Page数据结构，File Header字段用于记录Page的头信息，其中比较重要的是FIL_PAGE_PREV和FIL_PAGE_NEXT字段，通过这两个字段，我们可以找到该页的上一页和下一页，实际上所有页通过这两个字段可以形成一条双向链表。 ​ Page Header字段用于记录Page的状态信息。接下来的Infimum和Supremum是两个伪行记录，Infimum（下确界）记录比该页中任何主键值都要小的值，Supremum（上确界）记录比该页中任何主键值都要大的值，这个伪记录分别构成了页中记录的边界。 ​ User Records中存放的是实际的数据行记录。Free Space中存放的是空闲空间，被删除的行记录会被记录成空闲空间。Page Directory记录着与二叉查找相关的信息。File Trailer存储用于检测数据完整性的校验和等数据。 基于B+树聊赖MySQL的其他知识点​ 看到这里，我们已经了解了MySQL从单条数据开始，到通过页来减少磁盘IO次数，并且在页中实现了页目录来优化页中的查询效率，然后使用多页模式来存储大量的数据，最终使用目录页来实现多页模式的查询效率并形成我们口中的索引结构—B+树。接下来，我们说说MySQL的其他知识点。 聚簇索引和非聚簇索引​ 简单地说，所谓聚簇索引，就是将索引和数据放到一起，找到索引也就找到了数据，我们刚才看到的B+树索引就是一种聚簇索引。而非聚簇索引就是将数据和索引分开，查找时需要先查找到索引，然后通过索引回表找到相应的数据。InnoDB有且只有一个聚簇索引，而MyISAM中都是非聚簇索引。 联合索引的最左前缀匹配原则​ 在MySQL数据库中不仅可以对某一列建立索引，还可以对多列建立一个联合索引，而联合索引存在一个最左前缀匹配原则的概念，如果基于B+树来理解这个最左前缀匹配原则，相对来说就会容易很多了。 ​ 首先我们基于文首的这张表建立一个联合索引： 1create index idx_obj on user(age asc,height asc,weight asc) ​ 我们已经了解了索引的数据结构是一棵B+树，也了解了B+树优化查询效率的其中一个因素就是对数据进行了排序，那么我们在创建idx_obj这个索引的时候，也就相当于创建了一颗B+树索引，而这个索引就是依据联合索引的成员来进行排序，这里是age，height，weight。 ​ InnoDB中只要有主键被定义，那么主键列被作为一个聚簇索引，而其他索引都被作为非聚簇索引，所以自然而然的，这个索引就会是一个非聚簇索引。所以根据这些我们可以得出结论： idx_obj这个索引会根据age，height，weight进行排序 idx_obj这个索引是一个非聚簇索引，查询时需要回表 ​ 根据这两个结论，首先需要了解的就是，如何排序？单列排序很简单，就是比大小。但多列排序是基于什么原则呢？实际上在MySQL中，联合索引的排序有这么一个原则，从左到右依次比较大小。就拿刚才建立的索引，它会先去比较age的大小，如果age的大小相同，那么比较height的大小，如果height也无法比较大小，那么就比较weight的大小，最终对这个索引进行排序。 ​ 那么根据这个排序我们也可以画出一个B+树，这里就不像上文画的那么详细了，简化一下： ​ 数据： ​ B+树： ​ 注意，此时由于是非聚簇索引，所以叶子节点不在有数据，而是存了一个主键索引，最终会通过主键索引来回表查询数据。 ​ B+树的结构有了，就可以通过这个来理解最左前缀匹配原则了。我们先下一个查询语句： 1SELECT * FROM user WHERE age=1 and height = 2 and weight = 7 ​ 毫无疑问，这条语句一定会走idx_obj这个索引。那我们再看一个语句： 1SELECT * FROM user WHERE height=2 and weight = 7 ​ 这条SQL会走索引吗？答案是否定的。为什么这条语句不会走索引？上文中我们提到了一个多列的排序原则，是从左到右进行比较然后排序的，而我们的idx_obj这个索引从左到右依次是age，height，weight，所以当我们使用height和weight来作为查询条件时，由于age的缺失，那么就无法从age来进行比较了。 ​ 难道不能直接用height和weight来进行比较吗？显然是不可以的。举个例子，我们把缺失的这一列写作一个问号，那么这条语句的查询条件就变成了?27，那么我们从这棵B+树的根节点开始，根节点上有127和365，那么以height和weight来进行比较的是，走的一定是127这一边，但是如果缺失的数字是大于3的呢？比如427,527,627，那么如果走索引来查询数据，将会丢失数据，错误查询。所以这种情况下是不会走索引查询的。这就是最左前缀匹配原则的成因。 ​ 1、最左前缀匹配原则，MySQL会一直向右匹配直到遇到范围查询（&gt;、&lt;、between、like）就停止匹配。比如a = 3 and b = 4 and c &gt; 5 and d = 6，如果建立（a, b, c, d）顺序的索引，d是无法使用索引的，如果建立（a, b, d, c）的索引则都可以使用到。a、b、d的顺序可以任意调整。 ​ 2、=和in可以乱序。比如a = 1 and b = 2 and c = 3，建立(a, b, c)索引可以任意顺序，MySQL的查询优化器会帮你优化成索引可以识别的形式。 ​ 根据我们了解的可以得出结论：只要无法进行排序比较大小的，就无法走联合索引。 ​ 再看几个语句： 1SELECT * FROM user WHERE age=1 and height = 2 ​ 这条语句是可以走idx_obj索引的，因为它可以通过比较（12? &lt; 365）。 1SELECT * FROM user WHERE age=1 and weight=7 ​ 这条语句也是可以走idx_obj索引的，因为它也可以通过比较(1?7 &lt; 364)，走左子树，但是实际上weight并没有用到索引，因为根据最左匹配原则，如果有两页的age都等于1，那么会去比较height，但是height在这里并不作为查询条件，所以MySQL会将这两页全都加载到内存中进行最后的weight字段的比较，进行扫描查询。 1SELECT * FROM user where age&gt;1 ​ 这条语句不会走索引，但是可以走索引。这句话什么意思呢？这条SQL很特殊，由于其存在可以比较的索引，所以它走索引也可以查询出结果，但是由于这种情况是范围查询并且是全字段查询，如果走索引，还需要进行回表，MySQL查询优化器就会认为走索引的效率比全表扫描还要低，所以MySQL会去优化它，让它直接进行全表扫描。 1SELECT * FROM user WHERE age=1 and height&gt;2 and weight=7 ​ 这条语句可以走索引的，因为它可以通过age进行比较，但是weight不会用到索引，因为height是范围查找，与第二条语句类似，如果有两页的height都大于2，那么MySQL会将两页的数据都加载进内存，然后再来通过weight匹配正确的数据。 为什么InnoDB只有一个聚簇索引，而不将所有索引都是用聚簇索引​ 因为聚簇索引是将索引和数据都存放在叶子节点中，如果所有的索引都是用聚簇索引，则每一个索引都将保存一份数据，会造成数据的冗余，在数据量很大的情况下，这种数据冗余是很消耗资源的。 补充两个索引的点​ 1、什么情况下会发生明明创建了索引，但是执行的时候并没有通过索引呢？ ​ 查询优化器执行一条SQL语句的查询，可以有不同的执行方案，至于最终选择哪种方案，需要通过优化器进行选择，选择执行成本最低的方案。 ​ 在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案。这个成本最低的方案就是所谓的执行计划。优化过程大致如下： 根据搜索条件，找出所有可能使用的索引 计算全表扫描的代价 计算使用不同索引执行查询的代价 对比各种执行方案的代价，找出成本最低的那一个 ​ 2、在费聚簇索引情况下通常需要通过叶子节点的指针回表查询数据，什么情况下不需要回表？ ​ 覆盖索引。覆盖索引是指一个查询语句的执行只用从索引中就能够取得，不必从数据表中读取。也可以称之为实现了索引覆盖。 ​ 当一条查询语句符合覆盖索引条件时，MySQL只需要通过索引就可以返回查询所需要的数据，这样避免了查到索引后再返回表操作，减少I/O提高效率。 ​ 例如，表covering_index_sample中有一个普通索引idx_key1_key2(key1, key2)。当我们通过SQL语句：select key2 from covering_index_sample where key1 = &#39;keytest&#39;;的时候，就可以通过覆盖索引查询，无需回表。 ​ 例如上面的SELECT age FROM user where age = 1。这句话就不需要进行回表查询。 结语​ 本文着重讲解关于MySQL的索引结果，从零开始慢慢构建了一个B+树索引，并且根据这个过程谈了B+树是如何一步一步去优化查询效率的。简单地归纳一下就是： ​ 排序：优化查询的根本，插入时进行排序实际上就是为了优化查询的效率。 ​ 页：用于减少IO次数，还可以利用程序局部性原理，来稍微提高查询的效率。 ​ 页目录：用于规避链表的软肋，避免在查询时进行链表的扫描。 ​ 多页：数据量增加的情况下开辟新页来保存数据。 ​ 目录页：特殊的页目录，其中保存的数据是页的地址。查询时可以通过目录页快速定位到页，避免多页的扫描。 参考资料​ 转载自索引很难么？带你从头到尾捋一遍MySQL索引结构，不信你学不会！ ​]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Netty底层架构原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F13%2F%E6%B5%85%E8%B0%88Netty%E5%BA%95%E5%B1%82%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 对于高性能的RPC框架，Netty作为异步通信框架，几乎成了必需品。例如Dubbo框架中通信组件，还有RocketMQ中生产者和消费者的通信，都是用了Netty。现在让我们开简单看一下Netty的基本架构和原理。 Netty的特点与NIO​ Netty是一个异步的、基于事件驱动的网络应用框架，它可以用来开发高性能服务端和客户端。以前编写网络调用程序的时候，我们都会在客户端创建一个Socket，通过这个Socket连接到服务端。服务端根据这个Socket创建一个Thread，用来发出请求。客户端在发起调用以后，需要等待服务端处理完成，才能继续后面的操作。这样线程会出现等待的状态。 ​ 如果客户端请求数越多，服务端创建的处理线程也会越多，JVM管理如此多的线程并不是容易的事。 ​ 为了解决上述问题，退出了NIO的概念，就是（Non-blocking I/O）。其中Selector机制就是NIO的核心。当每次客户端请求时，会创建一个Socket Channel，并将其注册到Selector上（多路复用器），然后Selector关注服务端IO读写事件，此时客户端并不用等待IO事件完成，可以继续做接下来的工作。一旦服务端完成了IO读写操作，Selector会接到通知，同时告诉客户端IO操作已经完成。接到通知的客户端，就可以通过SocketChannel获取需要的数据了。 ​ 上面描述的过程有异步的意思，不过，Selector实现的并不是真正意义上的异步操作。因为Selector需要通过线程阻塞的方式监听IO事件变更，只是这种方式没有让客户端等待，是Selector在等待IO返回，并且通知客户端去获取数据。 ​ 谈好了NIO再来谈谈Netty。Netty作为NIO的实现，它适用于服务器/客户端通讯的场景，以及针对于TCP协议下的高并发应用。对于开发者来说，它具有以下特点： 对NIO进行封装，开发者不需要关注NIO的底层原理，只需要调用Netty组件就能完成工作。 对网络调用透明，从Socket建立TCP连接到网络异常的处理都做了包装 对数据处理灵活，Netty支持多种序列化框架，通过ChannelHandler机制，可以自定义“编/解码器” 对性能调优友好，Netty提供了线程池模式以及Buffer的重用机制（对象池化），不需要构件复制的多线程模型和操作队列。 从一个简单的例子开始​ 现在通过一个例子来讲解。假设有一个客户端去调用一个服务端，假设服务端叫做EchoServer，客户端叫做EchoClient，用Netty架构实现代码如下。 服务端代码​ 构建服务器端，假设服务器接受客户端传来的信息，然后在控制台打印。首先，生成EchoServer，在构件函数中传入需要监听的端口号。然后再编写服务的启动方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package server;import io.netty.bootstrap.ServerBootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import java.net.InetSocketAddress;public class EchoServer &#123; private final int port; public EchoServer(int port) &#123; this.port = port; &#125; public void start() throws Exception&#123; final EchoServerHandler serverHandler = new EchoServerHandler(); // 1、创建EventLoopGroup EventLoopGroup group = new NioEventLoopGroup(); try &#123; // 2、创建ServerBootstrap ServerBootstrap b = new ServerBootstrap(); b.group(group) // 3、指定所使用的 NIO 传输 Channel .channel(NioServerSocketChannel.class) // 4、使用指定的端口设置套接字地址 .localAddress(new InetSocketAddress(port)) // 5、添加一个 EchoServerHandler 到 Channel 的 ChannelPipeline .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(serverHandler); &#125; &#125;); // 6、异步绑定服务器：调用sync()方法阻塞等到直到绑定完成 ChannelFuture f = b.bind().sync(); System.out.println(EchoServer.class.getName() + "started and listening for connections on " + f.channel().localAddress()); // 7、获取Channel 的 CloseFuture，并且阻塞当前线程直到它完成 f.channel().closeFuture().sync(); &#125;finally &#123; // 8、关闭EventLoopGroup，释放所有的资源 group.shutdownGracefully().sync(); &#125; &#125;&#125; ​ Server的启动方法涉及到了一些组件的使用，例如EventLoopGroup、Channel。这些后面会讲解，这里有个大概的印象就好： 创建EventLoopGroup。 创建ServerBootstrap。 指定所使用的NIO传输Channel。 使用指定的端口设置套接字地址。 添加一个ServerHandler到Channel的ChannelPipeline。 异步地绑定服务器，调用sync()方法阻塞等待直到绑定完成。 获取Channel的CloseFuture，并且阻塞当前线程直到它完成。 关闭EventLoopGroup，释放所有的资源。 ​ NettyServer启动以后会监听某个端口的请求，当接收到了请求就需要处理了。在Netty中客户端请求服务端，被称为“入站”操作。可以通过ChannelInboundHandlerAdapter实现，具体内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940package server;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelFutureListener;import io.netty.channel.ChannelHandler;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.ChannelInboundHandlerAdapter;import io.netty.util.CharsetUtil;@ChannelHandler.Sharablepublic class EchoServerHandler extends ChannelInboundHandlerAdapter &#123; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) &#123; ByteBuf in = (ByteBuf) msg; //将消息记录到控制台 System.out.println("Server received：" + in.toString(CharsetUtil.UTF_8)); //将接收到的消息写给发送者，而不冲刷出站消息 ctx.write(in); &#125; @Override public void channelReadComplete(ChannelHandlerContext ctx)throws Exception &#123; //将未决消息冲刷到远程节点，并且关闭该 Channel ctx.writeAndFlush(Unpooled.EMPTY_BUFFER) .addListener(ChannelFutureListener.CLOSE); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; //打印异常栈跟踪 cause.printStackTrace(); //关闭该Channel ctx.close(); &#125;&#125; ​ 从上面的代码可以看出，服务端处理的代码包含了三个方法。这三个方法是根据事件触发的。它们分别是： 当接收到消息时的操作：channelRead。 消息读取完成时的方法：channelReadComplete。 出现异常时的方法：exceptionCaught 客户端代码​ 客户端和服务端的代码基本相似，在初始化时需要输入服务端的IP和Port。整个客户端的代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package client;import io.netty.bootstrap.Bootstrap;import io.netty.channel.ChannelFuture;import io.netty.channel.ChannelInitializer;import io.netty.channel.EventLoopGroup;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import java.net.InetSocketAddress;public class EchoClient &#123; private final String host; private final int port; public EchoClient(String host, int port) &#123; this.host = host; this.port = port; &#125; public void start() throws Exception&#123; EventLoopGroup group = new NioEventLoopGroup(); try &#123; // 创建 Bootstrap Bootstrap b = new Bootstrap(); // 指定 EventLoopGroup以处理客户端事件：需要适用于NIO的实现 b.group(group) // 适用于NIO传输的Channel 类型 .channel(NioSocketChannel.class) // 设置服务器的InetSocketAddress .remoteAddress(new InetSocketAddress(host, port)) // 在创建C喊你了时，向ChannelPipeline中添加一个 EchoClientHandler实例 .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override public void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new EchoClientHandler()); &#125; &#125;); // 连接到远程节点，阻塞等待直到连接完成 ChannelFuture f = b.connect().sync(); //阻塞，直到Channel 关闭 f.channel().closeFuture().sync(); &#125;finally &#123; // 关闭线程池并且释放所有的资源 group.shutdownGracefully().sync(); &#125; &#125;&#125; ​ 客户端的启动程序的顺序： 创建Bootstrap。 指定EventLoopGroup用来监听事件。 定义Channel的传输模式为NIO。 设置服务器的InetSocketAddress。 在创建Channel时，向ChannelPipeline中添加一个EchoClientHandler实例。 连接到远程节点，阻塞等待直到连接完成。 阻塞，直到Channel关闭。 关闭线程池并且释放所有的资源。 ​ 客户端在完成以上操作以后，会与服务端建立连接从而传输数据。同样在接受到Channel中触发的事件时，客户端会触发对应事件的操作。 1234567891011121314151617181920212223242526272829package client;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.ChannelHandlerContext;import io.netty.channel.SimpleChannelInboundHandler;import io.netty.util.CharsetUtil;public class EchoClientHandler extends SimpleChannelInboundHandler&lt;ByteBuf&gt; &#123; @Override public void channelActive(ChannelHandlerContext ctx) &#123; // 当被通知 Channel是活跃的时候，发送一条信息 ctx.writeAndFlush(Unpooled.copiedBuffer("Netty rocks!", CharsetUtil.UTF_8)); &#125; @Override public void channelRead0(ChannelHandlerContext ctx, ByteBuf in) throws Exception &#123; //记录已接收信息的转储 System.out.println("Client received：" + in.toString(CharsetUtil.UTF_8)); &#125; // 在发生异常时，记录错误并关闭Channel @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; cause.printStackTrace(); ctx.close(); &#125;&#125; ​ 例如Channel激活，客户端接受到服务端的消息，或者发生异常的捕获。 Netty核心组件​ 通过上面的例子，发现有些Netty组件在服务初始化以及通讯时被用到，下面就来介绍这些组件的用途和关系。 Channel​ 上面的例子可以看出，当客户端和服务端连接的时候会建立一个Channel。这个Channel可以理解为Socket连接，它负责基本的IO操作，例如：bind()、connect()、read()和write()等等。简单理解就是，Channel就是代表连接，实体之间的连接，程序之间的连接，文件之间的连接，设备之间的连接。同时它也是数据入站和出站的载体。 EventLoop和EventLoopGroup​ 既然有了Channel连接服务，让信息之间可以流动。如果服务发出的消息称作“出站”消息，服务接受的消息称作“入站”消息，那么消息的“出站”/“入站”就会产生事件（Event）。例如：连接已激活；数据读取；用户事件；异常事件；打开链接；关闭链接等待。 ​ 顺着这个思路往下想，有了数据，数据的流动产生事件，那么就有一个机制去监控和协调事件。这个机制（组件）就是EventLoop。在Netty中每个Channel都会被分配到一个EventLoop，而一个EventLoop可以服务多个Channel。而每个EventLoop会占用一个Thread，同时这个Thread会处理EventLoop上面发生的所有IO操作和事件（Netty 4.0）。 ​ 理解了EventLoop，理解EventLoopGroup就容量了。EventLoopGroup是用来生成EventLoop的。上面的例子代码中第一行就new了EventLoopGroup对象。一个EventLoopGroup包含了多个EventLoop对象，而EventLoopGroup要做的就是创建一个新的Channel，并且给他分配一个EventLoop。 ​ 在异步传输的情况下，一个EventLoop是可以处理多个Channel中产生的事件的，它主要的工作就是事件的发现以及通知。相对于以前一个Channel就占用一个Thread的情况，Netty的方式要合理多了。 ​ 客户端发送消息到服务端，EventLoop发现以后会告诉服务端：“你去获取消息”，同时客户端进行其他的工作；当EventLoop检测到服务端返回的消息，也会通知客户端：“消息返回了，你去取吧”。客户端再去获取消息。整个过程EventLoop就是监视器 + 传声筒。 ChannelHandler，ChannelPipeline和ChannelHandlerContext​ 如果说EventLoop是事件的通知者，那么ChannelHandler就是事件的处理者。在ChannelHandler中可以添加一些业务代码，例如数据转换，逻辑运算等等。正如上面的例子中展示的，Server和Client分别都有一个ChannelHandler来处理，读取信息，网络可用，网络异常之类的信息。并且，针对出站和入站的事件，有不同的ChannelHandler，分别是： ChannelInBoundHandler（入站事件处理器） ChannelOutBoundHandler（出站事件处理器） ​ 假设每次请求都会触发事件，而由ChannelHandler来处理这些事件，这个事件的处理顺序是由ChannelPileLine来决定的。 ​ ChannelPipeline为ChannelHandler链提供了容器，到Channel被创建的时候，会被Netty框架自动分配到ChannelPipeline上。ChannelPipeline保证了ChannelHandler按照一定顺序处理事件，当事件触发以后，会将数据通过ChannelPipeline按照一定的顺序通过ChannelHandler。级，ChannelPipeline是复制“排队”的。这里的“排队”是处理事件的顺序。同时，ChannelPipeline也可以添加或者删除ChannelHandler，管理这个队列。 ​ 如上图，ChannelPipeline使ChannelHandler按照先后顺序排列，信息按照箭头所示方向流动并且被ChannelHandler处理。 ​ 说完了ChannelPipeline和ChannelHandler，前者管理后者的排列顺序。那么它们之间的关联就有ChannelHandlerContext来表示了。每当有ChannelHandler添加到ChannelPipeline时，同时会创建ChannelHandlerContext。ChannelHandlerContext的主要功能就是管理ChannelHandler和ChannelPipeline的交互。 ​ 上面的例子中，几乎ChannelHandler中每个处理事件函数，传入的参数就ChannelHandlerContext。ChannelHandlerContext参数贯穿ChannelPipeline，将信息传递给每个ChannelHandler，是个合格的“通讯员”。 ​ 把上面提到的几个核心组件归纳一下，用下图表示方便记忆它们之间的关系： Netty的数据容器​ 前面介绍了Netty的几个核心组件，服务器在数据传输的时候，产生事件，并且对事件进行监控和处理。接下来看数据是如何存放以及读写的。Netty将ByteBuf作为数据容器，来存放数据。 ByteBuf工作原理​ 从结构上来说，ByteBuf由一串字节数组构成。数组中每个字节用来存放信息。ByteBuf提供了两个索引，一个用于读取数据，一个用于写入数据，这两个索引通过在字节数组中移动，来定位需要或者读写信息的位置。当从ByteBuf读取时，它的readerIndex（读索引）将会根据读取的字节数递增。同样，当写ByteBuf时，它的writeIndex也会根据写入的字节数进行递增。 ​ 需要注意的是极限的情况是readerIndex刚好读到了writeIndex写入的地方。如果readerIndex超过了writeIndex的时候，Netty会抛出IndexOutOfBoundsException异常。 ByteBuf使用模式​ 说了ByteBuf的工作原理后，再来看它的使用模式。根据存放缓冲区的不同分为三类： 堆缓冲区：ByteBuf将数据存储在JVM的堆中，通过数组实现，可以做到快速分配。由于在堆上被JVM管理，在不被使用时可以快速释放。可以通过ByteBuf.array()来获取byte[]数据。 直接缓冲区：在JVM的堆之外直接分配内存，用来存储数据。其不占用堆空间，使用时需要考虑内存容量。它在使用Socket传递时性能较好，因为间接从缓冲区发送数据，在发送之前JVM会先将数据复制到直接缓冲区再进行发送。由于直接缓冲区的数据分配在堆之外，通过JVM进行垃圾回收，并且分配时也需要做复制的操作，因此使用成本较高。 复合缓冲区：顾名思义就是将上述两类缓冲区聚合在一起。Netty提供了一个CompsiteByteBuf，可以将堆缓冲区和直接缓冲区的数据放在一起，让使用更加方便。 ByteBuf的分配​ 接下来看看ByteBuf如何分配缓冲区的数据。Netty提供了两种ByteBufAllocator的实现，他们分别是： PooledByteBufAllocator：实现了ByteBuf的对象的池化，提高性能减少内存碎片。 UnpooledByteBufAllocator：没有实现对象的池化，每次会生成新的对象实例。 ​ 对象池化的技术和线程池比较相似，主要目的是提高内存的使用率。池化的简单实现思路，是在JVM堆内存上构建一层内存池，通过allocate方法获取内存池中的空间，通过release方法将空间归还给内存池。 ​ 对象的生成和销毁，会大量地调用allocate和release方法，因此内存池面临碎片空间回收的问题，在频繁申请和释放空间后，内存池需要保证连续的内存空间，用于对象的分配。基于这个需求，有两种算法用于优化这一块的内存分配：伙伴系统和slab系统。 ​ 伙伴系统，用完全二叉树管理内存区域，左右节点互为伙伴，每个节点代表一个内存块。内存分配将大块内存不断二分，直到找到满足所需的最小内存分片。内存释放会判断释放内存分片的伙伴（左右节点）是否空闲，如果空闲则将左右节点合成更大快内存。 ​ slab系统，主要解决内存碎片问题，将大块内存按照一定内存大小进行等分，形成相等大小的内存片构成的内存集。按照内存申请空间的大小，申请尽量小块内存或者其整数倍的内存。释放内存时，也是将内存分片归还给内存集。 ​ Netty内存池管理以Allocate对象的形式出现。一个Allocate对象由多个Arena组成，每个Arena能执行内存块的分配和回收。Arena内有三类内存管理单元： TinySubPage SmallSubPage ChunkList ​ Tiny和Small符合Slab系统的管理策略，ChunkList符合伙伴系统的管理策略。当用户申请内存介于tingSize和smallSize之间时，从tinySubPage中获取内存块；申请内存介于smallSize和pageSize之间时，从smallSubPage中获取内存块；介于pageSize和chunkSize之间时，从ChunkList中获取内存；大于ChunkSize（不知道分配内存的大小）的内存块不通过池化分配。 Netty的Bootstrap​ 说完了Netty的核心组件以及数据存储。回到最开始的例子程序，在程序最开始的时候会new一个Bootstrap对象，后面所有的配置都是基于这个对象展开的。Boosttrap的作用就是将Netty核心组件配置到程序中，并且让他们运行起来。 ​ 从Bootstrap的继承结构来看，分为两类，分别是Bootstrap和ServerBootstrap，一个对应客户端的引导，一个对应服务端的引导。 ​ 客户端引导Bootstrap，主要有两个方法：bind()和connetct()。Bootstrap通过bind()方法创建一个Channel。在bind()之后，通过调用connect()方法来创建Channel连接。 ​ 服务端引导ServerBootstrap，与客户端不同的是在bind()方法之后会创建一个ServerChannel，它不仅会创建新的Channel，还会管理已经存在的Channel。 ​ 通过上面的描述，服务端和客户端的引导存在两个区别： ServerBootstrap（服务端引导）绑定一个端口，用来监听客户端的连接请求。而Bootstrap（客户端引导）只要知道服务端IP和Port建立连接就可以了。 Bootstrap（客户端引导）需要一个EventLoopGroup，但是ServerBootstrap（服务端引导）则需要两个EventLoopGroup。因为服务器需要两组不同的Channel。第一组ServerChannel自身监听本地端口的套接字，第二组用于监听客户端请求的套接字。 总结​ 我们从NIO入手，谈到了Selector的核心机制。然后通过介绍Netty客户端和服务端的代码运行流程。让大家对Netty编写代码有基本的认识。 ​ 在Netty的核心组件中，Channel提供Socket的连接通道，EventLoop会对应Channel监听其产生的事件，并且通知执行者。EventLoopGroup负责生成和管理EventLoop。 ​ ChannelPipeline作为ChannelHandler的容器会绑定到Channel上，然后由ChannelHandler提供具体事件处理。另外，ChannelHandlerContext为ChannelHandler和ChannelPipeline提供信息共享。 ​ ByteBuf作为Netty的数据容器，通过字节数组的方式存储数据，并且通过读索引和写索引来引导读写操作。 ​ 上述的核心组件都是通过Bootstrap来配置并且引导启动的，Bootstrap启动方式虽然一致，但是针对客户端和服务端有些许的区别。 参考资料Netty底层架构原理]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RocketMQ详解]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F10%2FRocketMQ%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[MQ集群化部署以支撑高并发访问​ 假设RocketMQ部署在一台机器上，即使这个机器的配置很高，但一般来说一台机器也就是支撑10万+的并发访问。如果这个时候，有大量的系统都要往RocketMQ里高并发的写入消息，可能达到每秒几十万请求，这个时候就要将RocketMQ进行集群化部署，部署在多台机器上。假设每台机器能抗10万并发，只要让几十万请求分散到多台机器上接可以了。 MQ存储海量消息​ 一般情况下，MQ收到的大量消息并不是立马会被所有的消费方获取过去消费，所以MQ一般都得把消息在自己本地磁盘存储起来，然后等到消费方去处理。这样，MQ就得存储大量的消息，可能是几百万条，甚至几亿条，这么多的消息在一台机器上是没法存储的，那RocketMQ是如何处理的？ ​ 其实发送消息到MQ 的系统会把消息分散发送给多台不同的机器，假设有一万条消息，分散发送给10台机器，可能每台机器就是接收到1000条消息。 ​ 其次，每台机器上部署的RocketMQ进程一般称之为Broker，每个Broker都会接收到不同的消息，然后就会把这批消息存储在自己本地的磁盘文件里。 高可用保障​ 如果某一台Broker宕机了，导致RocketMQ里一部分的消息没了，这就会导致MQ的不可靠和不可用。而RocketMQ的解决思路就是Broker主从架构以及多副本策略。 ​ 简单来说，Broker有Master和Slave两种角色： ​ Master Broker收到消息之后会同步给Slave Broker，这样Slave Broker上就能有一模一样的一份副本数据。这个时候如果任何一个Master Broker出现故障，还有一个Slave Broker上有一份数据副本，可以保证数据不丢失，还能继续对外提供服务，保证了MQ 的可靠性和高可用性。 数据路由：消息中间件路由中心​ 对于系统来说，要发送消息到MQ去，还要从MQ里消费信息，因此需要解决一个问题：大家怎么知道有哪些Broker？怎么知道要连接哪一台Broker上去发送和接收消息？RocketMQ为了解决这个问题，有一个NameServer的概念。它也是独立部署在几台机器上，然后所有的Broker都会把自己注册到NameServer上去，NameServer就知道集群里有哪些Broker了。 ​ 对于我们系统而言，如果它要发送消息到Broker，会找NameServer去获取路由信息，就是集群里有哪些Broker等信息；如果系统要从Broker获取消息，也会找NameServer获取路由信息，去找到对应的Broker获取消息。 NameServer的集群化部署​ NameServer集群化部署的一个主要原因，就是高可用性。NameServer是集群里非常关键的一个角色，它要管理Broker信息，别人都要通过它才知道跟哪个Broker通信，如果NameServer就部署一台机器的话，一旦NameServer宕机了，就会导致RocketMQ集群出现故障。所以通常来说，NameServer一定会多机器部署，实现一个集群，起到高可用的效果。 Broker挂了，NameServer如何感知​ 一个Broker启动之后向NameServer注册了，每个NameServer都知道集群里有这么一台Broker的存在了，然后各个系统从NameServer也拉取到了一台信息，知道集群里有这么一台Broker，但如果这台Broker挂了之后，NameServer要如何感知？ ​ 这个问题的解决靠的就是Broker跟NameServer之间的心跳机制，Broker会每隔30s给所有的NameServer发送心跳，告诉每隔NameServer自己还活着，每次NameServer收到一个Broker的心跳，就可以更新一下它的最近一次心跳的时间，然后每隔10s运行一个任务，去检查各个Broker最近的一次心跳时间，如果某个Broker超过120s都没发送心跳了，那么就认为这个Broker已经挂掉了。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM工具使用-使用jmap和jhat弄清楚线上系统的对象分布]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F09%2FJVM%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8-%E4%BD%BF%E7%94%A8jmap%E5%92%8Cjhat%E5%BC%84%E6%B8%85%E6%A5%9A%E7%BA%BF%E4%B8%8A%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AF%B9%E8%B1%A1%E5%88%86%E5%B8%83%2F</url>
    <content type="text"><![CDATA[​ JVM中有两个非常实用的工具：jmap和jhat。这两个工具可以帮助我们观察线上JVM中的对象分布，了解到你的系统运行过程中，哪些对象占据了主角位置，占据了多少内存空间，让你对你的系统有更加细致的了解。 使用jmap了解系统运行时的内存区域​ 如果只是要了解JVM的运行状况，然后去进行JVM GC优化，一般情况下jstat就够用了。但是有时候我们会发现JVM新增对象的速度很快，想要了看看，到底什么对象占据了那么多的内存。如果发现有的对象在代码中可以优化一下创建的时机，避免多种对象对内存占用过大，也许甚至可以去反过来优化一下代码。当然，如果不是出现OOM那种极端情况，也没有那么大的必要着急优化代码。 ​ 先看一个命令：jmap -heap PID，这个命令可以打印出来一系列的信息，大致来说，这个信息会打印出来堆内存相关的一些参数设置，然后就是当前堆内存里的一些基本各个区域的情况。比如Eden区总容量，已经使用的容量、剩余空间容量、两个Survivor区的总容量、已经使用的容量和剩余的空间容量、老年代的总容量、已经使用和剩余的容量等等。 ​ 但是其实这些信息jstat就已经有了，所以一般不会用jmap去看这些信息，毕竟它的信息还没jstat全，例如缺少gc相关的统计。 使用jmap了解系统运行时的对象分布​ jmap命令比较有用的使用方式，是jmap -histo PID。这个命令会打印出类似下面的信息： ​ 这个命令打印出来的东西，会按照各种对象占用内存空间的大小降序排列，把占用内存最多的对象放在最上面。所以如果你只是想要简单了解一下当前JVM中的对象对内存占用的情况，直接使用jmap -histo命令即可。这样就可以快速了解到当前内存里到底是哪个对象占用了大量的内存空间。 使用jmap生成堆内存转储快照​ 如果上面的信息还不够深入，想要更仔细点的。那就可以使用jmap命令生成一个堆内存快照放到一个文件里，用如下的命令：jmap -dump:live,format=b,file=dump.hprof PID。这个命令会在当前目录下生成一个dump.hrpof文件，你不能直接打开看得，它把这一时刻JVM堆内存里所有对象的快照放到文件里去，以方便后续去分析。 使用jhat在浏览器中分许堆转储快照​ 接着就可以使用jhat去分析堆快照了。jhat内置了web服务器，它会支持你通过浏览器以图形化的方式分析堆转储快照。使用jhat dump.hprof命令即可启动jhat服务器，还可以指定自己想要的http端口号，默认是7000端口号。接着你就在浏览器上访问当前这台机器的7000端口号，就可以通过图形化的方式去分析堆内存里的对象分布情况了。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM工具使用-使用jstat了解线上系统的JVM运行状况]]></title>
    <url>%2FCKING.github.io%2F2019%2F12%2F02%2FJVM%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8-%E4%BD%BF%E7%94%A8jstat%E4%BA%86%E8%A7%A3%E7%BA%BF%E4%B8%8A%E7%B3%BB%E7%BB%9F%E7%9A%84JVM%E8%BF%90%E8%A1%8C%E7%8A%B6%E5%86%B5%2F</url>
    <content type="text"><![CDATA[​ 平时我们对运行中的系统，如果要检查他的JVM的整体运行情况，比较实用的工具是jstat。它可以让你看到当前运行中的系统，它的JVM内的Eden、Survivor、老年代的内存使用情况，还有Young GC和Full GC的执行次数以及耗时。通过这些指标，我们可以分析出当前系统的运行情况，判断当前系统的内存使用压力以及GC压力，还有就是内存分配是否合理。 jstat的使用jstat -gc PID​ 首先要在生产机器linux上，找出Java进程的PID。接着就针对我们的Java进程执行jstat -gc PID。这样就可以看到这个Java进程（其实本质就是一个JVM）的内存和GC情况了。 ​ 运行这个命令之后会看到如下列： 123456789101112131415S0C：这是From Survivor区的大小S1C：这是To Survivor区的大小S0U：这个From Survivor区当前使用的内存大小S1U：这是To Survivor区当前使用的内存大小EC：这是Eden区的大小EU：这是Eden区当前使用后的内存大小OC：这是老年代的大小OU：这是老年代当前使用的内存大小MC：这是方法区（永久代、元数据区）的大小MU：这是方法区（永久代、元数据区）的当前使用的内存大小YGC：这是系统运行迄今为止的Young GC次数YGCT：这是Young GC的耗时FGC：这是系统运行迄今为止的Full GC次数FGCT：这是Full GC的耗时GCT：这是所有GC的总耗时 其他的jstat命令​ 除了上面的jstat -gc命令是最常用的以外，它还有一些命令可以看到更多详细的信息： 123456jstat -gccapacity PID：堆内存分析jstat -gcnew PID：年轻代GC分析，这里的TT和MTT可以看到对象在年轻代存活的年龄和存活的最大年龄jstat -gcnewcapacity PID：年轻代内存分析jstat -gcold PID：老年代GC分析jstat -gcoldcapacity PID：老年代内存分析jstat -gcmetacapacity PID：元数据区内存分析 如何使用jstat工具​ 一般我们分析线上JVM线程，最想知道的信息有哪些？包括如下：新生代对象增长的速率、Young GC的触发频率，Young GC的耗时，每次Young GC后有多少对象是存活下来的，每次Young GC过后有多少对象进入了老年代、老年代对象增长的速率，Full GC的触发频率，Full GC的耗时。 新生代对象增长的速率​ 这其实是对JVM第一个要了解的事情，就是随着系统运行，每秒种会在年轻代的Eden区分配多少对象。要分析这个，你只要在线上linux机器上运行如下命令：jstat -gc PID 1000 10。它的意思是每隔一秒钟更新出最新的一行jstat统计信息，一共执行10次jstat统计。 ​ 通过这个命令，可以非常灵活的对线上机器通过固定频率输出统计信息，观察每隔一段时间的jvm中的Eden区对象占用变化。例如，执行这个命令后，第一秒先显示出Eden区使用了200MB内存，第二秒显示出的统计信息里，Eden区使用了205MB，第三秒显示出Eden区使用了209MB内存，以此类推。此时你就可以推断出这个系统每秒种会新增5MB左右的对象。 ​ 这里大家可以根据自己系统的情况灵活多变地使用，比如系统负载很低，不一定每秒都有请求，那么可以把上面的1秒钟调整为1分钟，甚至10分钟，去看你们系统每隔一定时间大概增长多少对象。还有就是一般系统都有高峰和日常两种状态，比如系统高峰期用的人很多，此时就应该用上述命令看看高峰期的对象增长率，然后还得在非高峰的日常时间段内看看对象的增长速率。 Young GC的触发频率和每次耗时​ 多久触发一次Young GC很容易推测出来，因为系统高峰和日常的对象增长速率都知道了，那么非常简单就可以推测出高峰期多久发生一次Young GC，日常期多久发生一次Young GC。 ​ 比如你Eden区有800MB内存，发现高峰期每秒新增5MB对象，大概高峰期就是3分钟会触发一次Young GC。日常期每秒新增0.5MB，那么日常期大概需要半个小时才会触发一次Young GC。 ​ 至于如何计算Young GC的平均耗时，jstat会告诉你迄今为止系统已经发生了多少次Young GC以及这些Young GC的总耗时。例如系统运行24小时后发生了260次Young GC，总耗时为20s，那么平均下来每次Young GC大概就耗时几十毫秒的时间，你就知道每次Young GC的时候会导致系统停顿几十毫秒。 每次Young GC后有多少对象是存活和进入老年代​ 接着我们想知道每次Young GC后有多少对象会存活下来，以及有多少对象会进入老年代。这个没办法直接看出来，但有办法可以大概推算出来。 ​ 之前我们推算出高峰期的时候多久发生一次Young GC，比如3分钟会有一次Young GC，那么此时我们可以执行下述jstat命令：jstat -gc 180000 10。这就是让他每隔三分钟执行一次统计，连续执行十次。此时可以观察一下，每隔三分钟之后发生了一次Young GC，此时Eden、Survivor和老年代的对象变化。 ​ 正常来说，Eden区肯定会几乎放满之后重新变得里面对象很少，比如800MB的空间就使用了几十MB，Survivor区肯定会放入一些存活对象，老年代可能会增长一些对象占用，所以这里的关键，就是观察老年代的对象增长速率。 ​ 一般情况下，老年代的对象不太可能不停地快速增长的，因为普通的系统没那么多长期存活的对象，如果你发现每次Young GC过后，老年代对象都要增长几十MB，那很有可能就是你一次Young GC过后存活的对象太多了。存活的对象太多，可能导致放入到Survivor区域之后触发了动态年龄判定规则进入老年代，也可能是Survivor区域放不下了，所以大部分存活对象进入老年代。 ​ 最常见的情况是这种：如果你的老年代每次在Young GC过后就新增几百KB，或者几MB的对象，这个还算情有可原，但是如果老年嗲对象快速增长，那一定是不正常的。所以通过上述观察策略，你就可以知道每次Young GC过后多少对象是存活的，实际上Survivor区域里和进入老年代的对象，都是存活的。你也可以知道老年代对象的增长速率，比如每隔3分钟一次Young GC，每次会有50MB对象进入老年代，这就是老年代对象的增长速率，每隔3分钟增长50MB。 Full GC的触发时机和耗时​ 只要知道了老年代对象的增长速率，那么Full GC的触发时机就很清晰了。比如老年代总共有800MB的内存，每隔3分钟新增50MB对象，那么大概每小时就会触发一次Full GC。然后可以看到jstat打印出来的系统运行迄今为止的Full GC次数以及总耗时，比如一共执行了10次Full GC，总耗时30s，每次Full GC大概就是需要耗费3s左右。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之看懂垃圾回收的日志]]></title>
    <url>%2FCKING.github.io%2F2019%2F11%2F29%2FJVM%E4%B9%8B%E7%9C%8B%E6%87%82%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E7%9A%84%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[打印JVM的GC日志​ 如果想打印GC日志，需要在系统的JVM参数中加入GC日志的打印选型，如下： 123-XX:+PrintGCDetail #打印详细的gc日志-XX:+PrintGCTimeStamps #打印出每次GC发生的时间-Xloggc:log #设置将gc日志写入一个磁盘文件 示例示例程序代码12345678910111213public class Demo1 &#123; public static void main(String[] args) &#123; byte[] array1 = new byte[1024 * 1024]; array1 = new byte[1024 * 1024]; array1 = new byte[1024 * 1024]; array1 = null; byte[] array2 = new byte[2 * 1024 * 1024]; &#125;&#125; ​ 给上述程序配置一下JVM参数： 1-XX:NewSize=5242880 -XX:MaxNewSize=5242880 -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:SurvivorRatio=8 -XX:PretenureSizeThreshold=10485760 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:gc.log ​ 这些JVM参数的意思是给堆内存分配10MB内存空间，其中新生代是5MB内存空间，其中Eden区占4MB，每个Survivor区占0.5MB，大对象必须超过10MB才会直接进入老年低，年轻代使用ParNew垃圾回收器，老年代使用CMS垃圾回收器，如图所示： 对象如何分配在Eden区内的​ 上面的代码比较简单。先通过“new byte[1024 * 1024]”这样的代码连续分配了3个数组，每个数组都是1MB。然后通过array1这个局部变量依次引用这三个对象，最后还把array1这个局部变量指向了null。那么在JVM中上述代码如何运行？ ​ 首先第一行代码：byte[] array1 = new byte[1024 * 1024]。这个代码一运行，会在JVM的Eden区内放一个1MB的对象，同时在main线程的虚拟机栈中会压入一个main()方法的桢栈，在main()方法桢栈内部，会有一个“array1”变量，这个变量是指向堆内存Eden区的那个1MB的数组，如下图： ​ 接着第二行代码：array1 = new byte[1024 * 1024]。此时会在堆内存的Eden区中创建第二个数组，并且让局部变量指向第二个数组，然后第一个数组就没人引用了，此时第一个数据就变了没人引用的“垃圾对象”，如图所示： ​ 然后第三行代码：byte[] array1 = new byte[1024 * 1024]。这行代码在堆内存的Eden区内创建了第三个数组，同时让array1变量指向了第三个数组，此时前面两个数组都没有引用了，变成了垃圾对象。 ​ 第四行代码：array1 = null。这行代码一执行，就让array1这个变量什么都不指向，此时会导致之前创建的3个数组全部变成垃圾对象，如图： ​ 最后第五行代码：byte[] array2 = new byte[2 * 1024 * 1024]。此时会分配一个2MB大小的数组，尝试放入Eden区中。但这是不行的，因为Eden区总共就4MB大小，而且里面已经放入了3个1MB的数组，所以剩余空间只有1MB，此时放一个2MB的的数组是放不下的。这个时候就会触发年轻代的Young GC。 讲解GC日志​ 当我们以指定的JVM参数运行，会在根目录生成一个文件gc.log。打开gc.log文件，会看到如下内容： 1234567891011121314151617181920212223Java HotSpot(TM) 64-Bit Server VM (25.151-b12) for windows-amd64 JRE (1.8.0_151-b12), built on Sep 5 2017 19:33:46 by "java_re" with MS VC++ 10.0 (VS2010)Memory: 4k page, physical 33450456k(25709200k free), swap 38431192k(29814656k free)CommandLine flags: -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:MaxNewSize=5242880 -XX:NewSize=5242880 -XX:OldPLABSize=16 -XX:PretenureSizeThreshold=10485760 -XX:+PrintGC -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:SurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:-UseLargePagesIndividualAllocation -XX:+UseParNewGC0.268: [GC (Allocation Failure) 0.269: [ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs] 4030K-&gt;574K(9728K), 0.0017518 secs] [Times: user=0.00 sys=0.00, real=0.00 secs]Heappar new generation total 4608K, used 2601K [0x00000000ff600000, 0x00000000ffb00000, 0x00000000ffb00000) eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000)concurrent mark-sweep generation total 5120K, used 62K [0x00000000ffb00000, 0x0000000100000000, 0x0000000100000000)Metaspace used 2782K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K ​ 现在让我们来讲解一下这个日志。 ​ 首先在GC日志中，可以看到以下内容： CommandLine flags: -XX:InitialHeapSize=10485760 -XX:MaxHeapSize=10485760 -XX:MaxNewSize=5242880 ......... ​ 这是说明这次运行程序采取的JVM参数是什么，基本是我们设置的，同时还有一些参数默认就给设置了，不过一般关系不大。 ​ 接着看GC日志中的如下一行： 0.268: [GC (Allocation Failure) 0.269: [ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs] 4030K-&gt;574K(9728K), 0.0017518 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] ​ 这个就是概要说明了本次GC的执行情况。GC (Allocation Failure)是发生GC的原因，我们要分配一个2MB的数组，结果Eden区内存不够，所以就出现了“Allocation Failure”，即对象分配失败。所以此时就要触发一次Young GC。 ​ 那这次GC什么时候发生呢？通过上面的一个数字0.268，这个意思是说你的系统运行以后过了多少秒发生了本次的GC，比如这里就是大概系统运行之后大概200多毫秒，发生了本次GC。 ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs ​ 这个ParNew。我们触发的是年轻代的Young GC，所以用我们指定的ParNew垃圾回收器执行GC的。而4030K -&gt; 512K(4608K)，这个代表的意思是年轻代可用的空间是4608KB，也就是4.5MB。因为上面的例子中，Eden区是4MB，两个Survivor中只有一个是可以放存活对象的，另外一个必须一致保持空闲，所以它考虑年轻代的可用空间，就是Eden + 1个Survivor的大小，也就是4.5MB。 ​ 然后4030K -&gt; 512K。意思是对年轻代执行了一次GC，GC之前都使用了4030KB，但是GC之后只有512KB的对象存活了下来。而0.0015734 secs这个是本次GC耗费的时间。这里大概是1.5ms，仅仅是回收3MB的对象而已。 ​ 4030K-&gt;574K(9728K), 0.0017518 secs，这段话指的是整个Java堆内存的情况。意思是整个Java堆内存是总可用空间9728KB（9.5MB），其实就是4.5MB + 老年代5MB，然后GC前整个Java堆内存里使用了4030KB，GC之后Java堆内存使用了574KB。 [Times: user=0.00 sys=0.00, real=0.00 secs] ​ 这个意思就是本次GC消耗的时间。这里最小单位是小数点之后两位，但是这里全部是0.00 secs，也就是说本次gc就耗费了几毫秒。所以从秒为单位来看，几乎是0。 图解GC执行过程​ 第一个问题，ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs。在GC之前，明明在Eden区域里放了3个1MB的数组，一共是3MB，也就是3072KB的对象，那么GC之前年轻代应该是使用了3072KB的内存，为什么是4030KB的内存？其实要明白两点： 虽然你创建的数组本身是1MB，但是为了存储这个数组，JVM内置还会附带一些其他信息，所以每个数组实际占用的内存是大于1MB的； 除了你自己创建的对象以外，可能还有一些你看不见的对象在Eden区里。 ​ 如图所以，GC之前，三个数组和其他一些未知对象加起来，就是占据了4030KB的内存： ​ 接着你要在Eden分配一个2MB的数组，此时肯定触发了“Allocation Failure”，对象分配失败，就触发了Young GC，然后ParNew执行垃圾回收，回收掉之前我们创建的三个数组，此时因为它们都没人引用了，一定是垃圾对象，如图： ​ 继续看gc日志：ParNew: 4030K-&gt;512K(4608K), 0.0015734 secs。gc回收之后，从4030KB内存使用降低到了512KB的内存使用，也就是说这次gc日志有512KB的对象存活了下来，从Eden区转移到了Survivor1区。或者我们改一下称呼，叫做Survivor From区，另外一个叫做Survivor To区。 ​ 结合GC日志日志就能看出，这就是本次GC的全过程。 GC过后的堆内存使用情况​ 接着我们看下面的GC日志： 123456789101112131415Heappar new generation total 4608K, used 2601K [0x00000000ff600000, 0x00000000ffb00000, 0x00000000ffb00000) eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000)concurrent mark-sweep generation total 5120K, used 62K [0x00000000ffb00000, 0x0000000100000000, 0x0000000100000000)Metaspace used 2782K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K ​ 这段日志是在JVM退出的时候打印出来的当前堆内存的使用情况，其实也很简单。先看这段： 1234567par new generation total 4608K, used 2601K [0x00000000ff600000, 0x00000000ffb00000, 0x00000000ffb00000) eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000) ​ par new generation total 4608K,used 2601K，就是说“ParNew”垃圾回收器复制的年轻代共有4608KB（4.5MB）可用内存，目前是使用了2601KB（2.5MB）。为什么JVM退出之前，年轻代占用了2.5MB的内存？因为在gc之后，我们有通过了代码byte[] array2 = new byte[2 * 1024 * 1024]分配了一个2MB的数组，所以此时Eden区中会有一个2MB的数组，也就是2048KB，然后上次gc之后在From Survivor区中存活了一个512KB的对象。但2048 + 512 = 2560KB，为什么年轻代使用了2601KB？因为之前说过每个数组会额外占据一些内存来存放一些自己这个对象的元数据，所以你可以认为多出来的41KB可以是数组对象额外使用的空间。如图： ​ 继续看日志 12345eden space 4096K, 51% used [0x00000000ff600000, 0x00000000ff80a558, 0x00000000ffa00000) from space 512K, 100% used [0x00000000ffa80000, 0x00000000ffb00000, 0x00000000ffb00000) to space 512K, 0% used [0x00000000ffa00000, 0x00000000ffa00000, 0x00000000ffa80000) ​ 通过GC日志可以验证我们的推测是正确的，这里说的很清楚，Eden区此时4MB的内存被使用了51%，就是因为有一个2MB的数组在里面，然后From Survivor区，512KB是100%的使用率，此时被之前gc后的512KB的未知对象占据了。 ​ 后面的日志 12345concurrent mark-sweep generation total 5120K, used 62K [0x00000000ffb00000, 0x0000000100000000, 0x0000000100000000)Metaspace used 2782K, capacity 4486K, committed 4864K, reserved 1056768K class space used 300K, capacity 386K, committed 512K, reserved 1048576K ​ concurrent mark-sweep generation total 5120K, used 62K这就是CMS垃圾回收器，管理的老年代内存空间一共是5MB。此时使用了62KB的空间。而下面两段日志也很简单，就是Metaspace元数据空间和Class空间，存放一些类信息、常量池之类的东西，此时他们的总容量和使用内存等等。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM垃圾回收器之G1回收器]]></title>
    <url>%2FCKING.github.io%2F2019%2F11%2F05%2FJVM%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%E4%B9%8BG1%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[ParNew + CMS组合的痛点​ 传统的JVM垃圾回收器ParNew + CMS组合有一个很大的痛点，就是Stop the World。无论是新生代垃圾回收，还是老年代垃圾回收，都会或多或少产生“Stop the World”现象，对系统的运行有一定的影响。所以后面对垃圾回收器的优化，都是朝着减少“Stop the World”的目标去做的。在这个基础上，G1垃圾回收器就应运而生，它提供了比ParNew + CMS组合更好的垃圾回收的性能。 G1垃圾回收器​ G1垃圾回收器是可以同时回收新生代和老年代的对象的，不需要两个垃圾回收器配合起来运作，它一个人就可以搞定所有的垃圾回收。 ​ 它最大的一个特点，就是把Java堆内存拆分为多个大小相等的Region，如图： ​ 然后G1也会有新生代和老年代的概念，但是只不过是逻辑上的概念，即，新生代可能包含了某些Region，老年代也可能包含了某些Region，如图： ​ 而且G1最大的一个特点，就是可以让我们设置一个垃圾回收的预期停顿时间。也就是说比如我们可以指定：希望G1在垃圾回收的时候，可以保证，在一小时内由G1垃圾回收导致的“Stop the World”时间，不能超过一分钟。 ​ 这个就很厉害了，我们之前的一系列JVM优化思路，包括内存合理分配等待，都是为了尽可能减少Minor GC和Full GC带来的系统停顿，避免影响系统处理请求。但是我们现在可以直接给G1指定，在一个时间内，垃圾回收导致的系统停顿时间不能超过多久，G1全权给你负责，保证达到目标，这相当于我们就可以直接控制垃圾回收对系统性能的影响了。 G1对垃圾回收导致的系统停顿可控的原理​ G1要做到这一点，就必须要追踪每个Region里的回收价值。也就是说，它必须搞清楚每个Region里的对象有多少是垃圾，如果对这个Region进行垃圾回收，需要耗费多长时间，可以回收掉多少垃圾。 ​ 如下图，G1通过追踪发现，1个Region的垃圾对象有10MB，回收它们需要耗费1秒钟，另外一个Region中对垃圾对象有20MB，回收它们需要耗费200毫秒。 ​ 然后在垃圾回收的时候，G1会发现在最近一个时间段内，比如一小时内，垃圾回收已经导致了几百毫秒的停顿了，现在又要执行一次垃圾回收，那么必须是回收上图中那个只需要200ms就能回收掉20MB垃圾的Region，于是G1触发一次垃圾回收，虽然导致了系统停顿了200ms，但是一下子回收了更多的垃圾。 ​ 所以简单来说，G1可以做到让你来设定垃圾回收对系统的影响，它自己通过把内存拆分为大量小Region，以及追踪每个Region中可回收对象大小和预估时间，最后在垃圾回收的时候，尽量把垃圾回收对系统造成的影响控制在你指定的时间范围内，同时在有限的时间内尽量回收尽可能多的垃圾对象。这就是G1的核心设计思路。 Region可能属于新生代也可能是老年代​ 在G1中，每一个Region可能属于新生代，也可能属于老年代。刚开始Region可能谁都不属于，然后接着就分配给了新生代，放了很多属于新生代的对象，接着就触发了垃圾回收这个Region。然后下一次同一个Region可能又分配了老年代，用来存放老年代的长生存周期的对象。 ​ 所以其实在G1对应的内存模型中，Region随时会属于新生代也会属于老年代，所以没有所谓新生代给多少内存，老年代给多少内存这一说了，实际上新生代和老年代各自的内存区域是不停变动的，由G1自动控制。 设定G1对应的内存大小​ 上面说到G1对应的是一大堆的Region内存区域，每个Region的大小是一致的。那到底有多少个Region呢？每个Region的大小是多大呢？其实这个默认情况下是自动计算和设置的，我们可以给整个堆内存设置一个大小，比如用-Xms和-Xmx来设置堆内存的大小，然后JVM启动的时候发现你使用的是G1垃圾回收器，可以使用-XX:+UseG1GC来指定使用G1垃圾回收器，此时会自动用堆大小除以2048，因为JVM最多可以有2048个Region，然后Region的大小必须是2的倍数，比如说1MB、2MB和4MB之类的。 ​ 比如说堆大小是4G，就是4096MB，此时除以2048个Region，每个Region的大小就是2MB，大概就是这个样子来决定Region的数量和大小的，一般保持默认的计算方式就可以。如果通过手动的方式来指定，则可以使用-XX:G1HeapRegionSize。 ​ 刚开始的时候，默认新生代对堆内存的占比是5%，也就是占据200MB左右，对应大概是100个Region。这个可以通过-XX:G1NewSizePercent来设置新生代初始占比，其实维持这个默认值即可，因为在系统运行中，JVM会不停地给新生代增加更多的Region，但是最多新生代的占比不会超过60%，可以通过-XX:G1MaxNewSizePercent来设置。而且一旦Region进行了垃圾回收，此时新生代的Region数量还会减少，这些其实都是动态的。 新生代还有Eden和Survivor的概念​ 虽然G1把内存划分了很多的Region，但是其实还是有新生代和老年代的区分，而且新生代里还是有Eden和Survivor的划分的。之前说过的一个新生代的参数：-XX:SurvivorRatio=8，比如说新生代刚开始的时候，有100个Region，那么可能80个Region就是Eden，两个Survivor各自占10个Region。所以大家要明白这里其实还是有Eden和Survivor的概念的，它们会各自占据不同的Region，只不过随着对象不停地在新生代里分配，属于新生代的Region会不断增加，Eden和Survivor对应的Region也会不断增加。 G1的新生代垃圾回收​ 既然G1的新生代也有Eden和Survivor的区分，那么触发垃圾回收的机制都是类似的。 ​ 随着不停地在新生代的Eden对应的Region中放对象，JVM会不停地给新生代加入更多的Region，直到新生代占据堆大小的最大比例60%。一旦新生代达到了设定的占据堆内存的最大大小60%，比如都有1200个Region了，里面的Eden可能占据了1000个Region，每个Survivor是100个Region，而且Eden区还占满了对象，如图： ​ 这个时候还是会触发新生代的GC，G1就会用之前说过的复制算法来进行垃圾回收，进入了一个“Stop the World”状态，然后把Eden对应的Region中的存活对象放入到S1对应的Region中，接着回收掉Eden对应的Region中的垃圾对象。 ​ 但是这个过程还有跟之前有区别的，因为G1是可以设定目标GC停顿时间的，也就是G1执行GC的时候最多可以让系统停顿多长时间，可以通过-XX:MaxGCPauseMills参数来设定，默认值是200ms。那么G1就会通过之前说的，对每个Region追踪回收它需要多少时间，可以回收多少对象来选择回收一部分的Region，保证GC停顿时间控制在指定范围内，尽可能多地回收掉一些对象。 对象什么时候进入老年代​ 在G1的内存模型下，新生代和老年代各自都会占据一定的Region，老年代也会有自己的Region，按照默认，新生代最多只能占据堆内存60%的Region来推算，老年代最多可以占据40%的Region。那么对象什么时候可以从新生代进入老年代呢？ 对象在新生代躲过了很多次的垃圾回收，达到了一定的年龄了，-XX:MaxTenuringThreshold参数可以设置这个年龄，他就会进入老年代。 动态年龄判定规则，如果一旦发现某次新生代GC过后，存活对象超过了Survivor的50%。此时就会判断一下，比如年龄为1岁、2岁、3对和4岁的对象的大小综合超过了Survivor的50%，此时4岁以上的对象全部会进入老年代。这就是动态年龄判定规则。 ​ 经过一段时间的新生代使用和垃圾回收之后，总有一些对象会进入老年代中。 大对象Region​ 在以前，大对象是可以直接进入老年代的，那G1这套内存模型下呢？实际上这里会有所不同，G1提供了专门的Region来存放大对象，而不是让大对象进入老年代的Region中。 ​ 在G1中，大对象的判定规则就是一个大对象超过了一个Region大小的50%，例如按照上面的算的，每个Region是2MB，只要一个对象超过了1MB，就被被放入专门的Region中。而且一个大对象如果太大，可能会横跨多个Region来存放。如图： ​ 那堆内存哪些Region用来存放大对象呢？之前不是说60%给新生代，40%给老年代吗，那还有哪些Region给大对象？很简单，之前说过了，在G1里，新生代和老年代的Region是不停变化的。比如新生代占据了1200个Region，但是一次垃圾回收之后，就让里面1000个Region都空了，此时那1000个Region就可以不属于新生代了，里面很多Region可以用来存放大对象。 ​ 在垃圾回收方面，新生代、老年代在回收的时候，会顺带着对大对象Region一起回收，所以这就是G1内存模型下对大对象的分配和回收的策略。 新生代 + 老年代的混合垃圾回收​ G1有一个参数，是-XX:InitiatingHeapOccupancyPercent，它的默认值是45%。意思是说，如果老年代占据了堆内存的45%的Region的时候，此时就会尝试触发一个新生代 + 老年代一起回收的混合回收阶段。 G1垃圾回收的过程​ 首先会触发一个“初始标记”的操作，这个过程需要进入“Stop the World”，但仅仅只是标记一下GC Roots直接能引用的对象，这个过程是很快的。它会先停止系统的运行，然后对各个线程栈内存中的局部变量代表的GC Roots、以及方法区中的静态变量代表的GC Roots，进行扫描，标记出它们直接引用的那些对象。 ​ 接着会进入“并发标记”的阶段，这个阶段允许系统程序的运行，同时进行GC Roots，从GC Roots开始追踪所有的存活对象。 ​ 这里对GC Roots追踪做更加详细的说明，比如下面的代码 12345678public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125;public class ReplicaManager &#123; public ReplicaFetcher replicaFetcher = new ReplicaFetcher();&#125; ​ 上面代码中，Kafka类有一个静态变量是“replicaManager”，它就是一个GC Roots对象，初始标记阶段，仅仅就是标记这个“replicaManager”作为GC Roots直接关联的对象，就是“ReplicaManager”对象，它肯定是要存活的。 ​ 然后在并发标记阶段，就会进行GC Roots追踪，会从“replicaManager”这个GC Roots对象直接关联的“ReplicaManager”对象开始往下追踪，可以看到“ReplicaManager”对象里有一个实例变量“replicaFetcher”，此时追踪这个“replicaFetcher”变量可以看到它引用了“ReplicaFetcher”对象，那么此时这个“ReplicaFetcher”对象也要被标记为存活对象。 ​ 这个并发标记阶段还是很耗时的，因为要追踪全部的存活对象，但是这个阶段可以跟系统程序并发运行，所以对系统程序的影响不太大，而且JVM会对并发标记阶段对对象做出的一些修改记录起来，比如说哪个对象被新建了，哪个对象失去了引用。 ​ 接着下一个阶段，最终标记阶段，这个阶段会进入“Stop the World”，系统程序是禁止运行的，但是会根据并发标记阶段记录的那些对象修改，最终标记有哪些存活对象，有哪些是垃圾对象。 ​ 最后一个极端就是“混合回收”阶段。这个阶段会计算老年代中每个Region中的存活对象数量，存活对象的占比，还有执行垃圾回收的预期性和效率。接着系统会停止系统程序，然后全力以赴尽快进行垃圾回收，此时会选择部分Region进行回收，因为必须让垃圾回收的停顿时间控制在我们指定的范围内。 ​ 这里需要注意的是，老年代对堆内存占比达到45%的时候，触发的是混合回收。即，此时垃圾回收不仅仅是回收老年代，还会回收新生代和大对象。那到底是回收这些区域的哪些Region呢？这个就要看情况了，因为我们设定了对GC停顿时间的目标，所以它会从新生代、老年代和大对象各自挑选一些Region，保证用指定的时间回收尽可能多的垃圾，这就是所谓的混合回收。 G1垃圾回收器的一些参数​ 上面说过老年代的Region占据了堆内存的Region的45%之后，会触发一个混合回收的过程，并且分了四个阶段。在最后一个阶段，就是执行混合回收，从新生代和老年代都回收一些Region。但是最后一个阶段混合回收的时候，其实会停止所有程序运行，所以说G1是允许执行多次混合回收的。 ​ 例如先停止工作，执行一次混合回收回收掉一些Region，接着恢复系统运行，然后再次停止系统运行，再执行一次混合回收回收掉一些Region。 ​ 有一些参数可以控制这个，比如-XX:G1MixedGCCountTarget参数，就是在一次混合回收的过程中，最后一个阶段执行几次混合回收，默认是8次。意味着最后一个阶段，先停止系统运行，混合回收一些Region，再恢复系统运行，接着再次禁止系统运行，混合回收一些Region，反复8次。 ​ 例如一次混合回收预期要回收一共有160个Region，那么此时第一次混合回收，会回收掉一些Region，比如就是20个Region，接着恢复系统一会儿，然后再执行一次“混合回收”，再次回收掉20个Region。如此反复执行8次回收阶段之后，就可以把预期的160个Region都回收掉了，而且还把系统停顿时间控制在指定范围内。 ​ 为什么要反复回收多次？因为你停止系统一会儿，回收掉一些Region，再让系统运行一会儿，然后再次停止系统一会儿，再次回收掉一些Region，这样可以尽可能让系统不要停顿时间过长，可以在多次回收的间隙，也运行一下。 ​ 还有一个参数：-XX:G1HeapWasterPercent，默认值是5%。它的意思是说，在混合回收的时候，对Region回收都是基于复制算法进行的，都是把要回收的Region里的存活对象放入其他Region，然后这个Region中的垃圾对象全部清理掉。 ​ 这样的话回收过程就会不断空出来新的Region，一旦空闲出来的Region数量达到了堆内存的5%，此时就会立即停止混合回收，意味着本次混合回收就结束了。而且G1整体是基于复制算法对Region进行垃圾回收的，不会出现内存碎片的问题，不需要像CMS那样标记-清理之后，再进行内存碎片的整理。 ​ 还有一个参数：-XX:G1MixedGCLiveThresholdPercent，它的默认值是85%，意思就是确定要回收的Region的时候，必须是存活对象低于85%的Region才可以进行回收。 回收失败的Full GC​ 如果在进行Mixed回收的时候，无论是年轻代还是老年代都基于复制算法进行回收的，都要把各个Region的存活对象拷贝到别的Region里去，此时万一出现拷贝的过程中发现没有空闲的Region可以承载自己的存活对象那，就会处罚一次失败。 ​ 一旦失败，立马就会切换为停止系统程序，然后采用单线程进行标记、清理和压缩整理，空闲出来一批Region，这个过程是极慢极慢的。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud Stream入门]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F29%2FSpring-Cloud-Stream%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Spring Cloud Stream​ 官方定义Spring Cloud Stream是一个构建消息驱动微服务的框架。应用程序通过inputs或者outputs来与Spring Cloud Stream中binder交互，通过我们来配置binding，而Spring Cloud Stream的binder负责与消息中间件交互。所以，我们只需要搞清楚如何与Spring Cloud Stream交互就可以方便使用消息驱动的方式。它通过使用Spring Integration来连接消息中间件以实现消息事件驱动。Spring Cloud Stream为一些供应商的消息中间件产品提供了个性化的自动化配置实现，引用了发布-订阅、消费组、分区的三个概念。目前支持市场上主流的多个消息中间件。 发布/订阅​ 简单的讲就是一种生产者、消费者模式。发布者是生产，将输出发布到数据中心，订阅者是消费者，订阅自己感兴趣的数据。当有数据到达数据中心，就把数据发送给对应的订阅者。 消费组​ 直观的理解就是一群消费者一起处理消息。需要注意的是：每个发动到消费组的数据，仅有消费组中的一个消费者处理。 分区​ 类比于消费组，分区是将数据分区。例如，某个应用有多个实例，都绑定到同一个数据中心，也就是不同实例都将数据发布到同一个数据中心。分区就是将数据中心的数据再细分成不同的区。为什么需要分区？因为即使是同一个应用，不同实例发布的数据类型可能不同，也希望这些数据由不同的消费者处理。这就需要，消费者可以仅订阅一个数据中心的部分数据，这就需要分区这个东西了。 Stream解决了什么问题​ Stream解决了开发人员无感知地使用消息中间件的问题，因为Stream对消息中间件的进一步封装，可以做到代码层面对中间件的无感知，甚至于动态的切换中间件（rabbitMQ切换为Kafka），使得微服务开发的高度解耦，服务可以关注更多自己的业务流程。结构图如下： 组成 说明 Middleware 中间件，支持市场上多种主流的MQ中间件 Binder Binder是应用与消息中间件之间的封装。通过Binder可以很方便地连接中间件，可以动态地改变消息类型（对应于Kafka的topic，RabbitMQ的exchange），这些都可以通过配置文件来实现 @Input 注解标识输入通道，通过该输入通道接收到的信息进入应用程序 @Output 注解标识输出通道，发布的消息将通过该通道离开应用程序 @StreamListener 监听队列，用于消费者队列的消息接收 @EnableBinding 指信道channel和exchange绑定在一起 消息驱动入门案例​ 现在通过一个入门案例来演示通过stream整合RabbitMQ来实现消息的异步通信的效果。首先是先安装部署RabbitMQ，具体方法自行百度。我这边是用docker安装的RabbitMQ，参考的是这篇文章：Docker 安装部署RabbitMQ。 ​ RabbitMQ安装好之后，就开始我们的代码了。首先先创建SpringCloud的一个父工程，然后在父工程下面新建两个服务： cloud-stream-producer-rabbitmq：作为一个发布者，将消息推动到RabbitMQ cloud-stream-consumer-rabbitmq：消费者消费信息 ​ 首先是添加依赖，其中最主要的是spring cloud stream的RabbitMQ依赖，还有就是为了使用spring cloud stream，我们还要引入spring cloud依赖，整个pom文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;modules&gt; &lt;module&gt;cloud-stream-producer-rabbitmq&lt;/module&gt; &lt;module&gt;cloud-stream-consumer-rabbitmq&lt;/module&gt; &lt;/modules&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.5.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.springcloudstream&lt;/groupId&gt; &lt;artifactId&gt;rabbitmqdemo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;rabbitmqdemo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;spring-cloud.version&gt;Greenwich.SR1&lt;/spring-cloud.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rabbit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-test-support&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-cloud.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 创建生产者​ 如前所述，将消息从发布者传递到队列的整个过程是通过通道Channel完成的，因此，我们创建一个HelloBinding接口，其中包含我们自定义的消息信道greetingChannel。 12345public interface HelloBinding &#123; @Output("greetingChannel") MessageChannel greeting();&#125; ​ 因为这个是要发布消息的，所以我们使用@Output注解，方法名可以是我们想要的任何名称，当然，我们可以在一个接口中有多个Channel（通道）。 ​ 现在，我们创建一个Controller，它将消息推动到这个Channel（通道） 12345678910111213141516@RestControllerpublic class ProducerController &#123; private MessageChannel greet; public ProducerController(HelloBinding binding) &#123; greet = binding.greeting(); &#125; @GetMapping("/greet/&#123;name&#125;") public void publish(@PathVariable String name) &#123; String greeting = "hello " + name + "!"; Message&lt;String&gt; msg = MessageBuilder.withPayload(greeting).build(); this.greet.send(msg); &#125;&#125; ​ 上面我们创建了一个ProducerController类，它有一个MessageChannel类型的属性，这是我们通过我们前面声明的方法在构造函数中初始化的。然后，我们有一个简单的Restful接口， 它接收PathVariable的name，并使用MessageBuilder创建一个String类型的消息。最后，我们使用MessageChannel上的.send()方法来发布消息。 ​ 现在,我们将在的主类中添加@EnableBinding注解，传入HelloBinding告诉Spring加载。 12345678@EnableBinding(HelloBinding.class)@SpringBootApplicationpublic class ProducerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProducerApplication.class, args); &#125;&#125; ​ 最后，我们必须告诉Spring如何连接到RabbitMQ，并将greetingChannel连接到一可用的消费这。而这些都是在application.properties配置文件中定义的。 123456789spring.rabbitmq.addresses=47.105.176.129spring.rabbitmq.username=rootspring.rabbitmq.password=xxxspring.rabbitmq.port=5672spring.rabbitmq.virtual-host=my_vhostspring.rabbitmq.publisher-confirms=truespring.cloud.stream.bindings.greetingChannel.destination=greetingsserver.port=8080 ​ 其中，spring.cloud.stream.bindings.greetingChannel.destination的意思是greetingChannel这个通道的目的地，类似于Kafka的Topic和RabbitMQ的队列的概念 。后面的消费者也是通过这个去配置消费者去相同的Channel中取数据。另外一个配置spring.rabbitmq.virtual-host，是配置当前用户的权限，这个我们可以通过RabbitMQ的管理界面去确定这个配置的内容： 创建消费者​ 现在，我们需要监听之前创建的通道greetingChannel。让我们创建一个绑定，为了区分，消费者的Channel我们命名为helloChannel。 1234567public interface HelloBinding &#123; String GERRTING = "helloChannel"; @Input(GERRTING) SubscribableChannel greeting();&#125; ​ 与生产者绑定的两个非常明显的区别。因为我们是要消费信息，所以我们使用SubscribableChannel和@Input标识它为消费者。消息推送将被推送到这里。 ​ 现在，我们创建处理数据的方法： 12345678@EnableBinding(HelloBinding.class)public class HelloListener &#123; @StreamListener(target = HelloBinding.GERRTING) public void processHelloChannelGreeting(String msg) &#123; System.out.println(msg); &#125;&#125; ​ 在这里，我们创建一个HelloListener类，在processHelloChannelGreeting方法上添加@StreamListener注解，这个方法需要一个字符串作为参数。我们还在类添加@EnableBinding启用了HelloBinding。 ​ 注意，我们在这里使用@EnableBinding，而不是主类，我们的主类，其实是没有任何修改的： 123456@SpringBootApplicationpublic class ConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerApplication.class, args); &#125;&#125; ​ 最后，我们修改消费者的配置文件： 123456789spring.rabbitmq.addresses=47.105.176.129spring.rabbitmq.username=rootspring.rabbitmq.password=xxxspring.rabbitmq.port=5672spring.rabbitmq.virtual-host=my_vhostspring.rabbitmq.publisher-confirms=truespring.cloud.stream.bindings.helloChannel.destination=greetingsserver.port=9090 ​ 其中，spring.cloud.stream.bindings.helloChannel.destination的意思是helloChannel这个通道的目的地是greetings，这个跟生产者是一样的，从而让消费者指向了跟生产者一样的目的地。 测试​ 我们同时启动生产者和消费者，通过浏览器或postman访问http://localhost:8080/greet/ckin来生产消息，可以在打印台中看到看到消息内容： ​ 现在我们启动另一个消费者服务。端口号为9091，当我们点击生产者的REST端点生产消息时，我们看到两个消费者都收到了消息： ​ 如果我们只想让一个消费者消费一条消息的话，我们可以在application.properties中创建一个消费者组。消费者的文件如下： 1spring.cloud.stream.bindings.greetingChannel.group = greetings-group ​ 相关代码已上传到github，需要的可以去下载。 参考资料Spring Cloud Stream入门介绍 消息驱动式微服务：Spring Cloud Stream &amp; RabbitMQ]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之垃圾回收器]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F23%2FJVM%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[​ 在新生代和老年代进行垃圾回收的时候，都是要用垃圾回收器进行回收的，不同的区域用不同的垃圾回收器。常用的垃圾回收机有一下几种： Serial和Serial Old垃圾回收器：分别用来回收新生代和老年代的垃圾对象。工作原理就是单线程运行，垃圾回收的时候会停止我们自己写的系统的其他工作线程，让我们系统直接卡死不动，然后让他们垃圾回收，这个现在一般写后台Java系统几乎不用。 ParNew和CMS垃圾回收器：ParNew现在一般都是用在新生代的垃圾回收器，CMS是用在老年代的垃圾回收器，他们都是多线程并发的机制，性能更好，现在一般是线上生产系统的标配组合。 G1垃圾回收器：统一收集新生代和老年代，采用了更加优秀的算法和设计机制。下面会详细介绍这个G1垃圾回收器。 GC的大概流程​ 看下图，新生代的内存一般都是分为一个Eden和两个Survivor ​ 此时系统不停的运行，然后把Eden给塞满了，此时就会触发Minor GC。进行垃圾回收时有专门的垃圾回收线程的，而且对不同的内存区域会有不同的垃圾回收器。相当于垃圾回收线程和垃圾回收器配合起来，使用自己的垃圾回收算法，对指定的内存区域进行垃圾回收。 ​ 由上图可知，垃圾回收会通过一个后台运行的垃圾回收线程来执行它具体的一个逻辑。比如针对新声代我们会用ParNew垃圾回收器进行回收，然后ParNew垃圾回收器针对新生代采用的就是复制算法来垃圾回收。 GC的时候还能继续创建新的对象吗​ 我们写好的Java系统在运行期间能不能继续在新生代里创建新的对象？假设一个场景，如下图： ​ 如果所示，如果一边垃圾回收器在想办法把Eden和Survivor2里的存活对象标记出来转移到Survivor2去，然后还在想办法把Eden和Survivor2的垃圾对象清理掉，结果这个时候系统程序还在不停的在Eden里创建新的对象。而这些新的对象很快就成了垃圾对象，有的还有人引用是存活对象。这样子就会全部乱套了，对于程序新创建的这些对象，你怎么让垃圾回收器去持续追踪这些新对象的新状态？所以，在垃圾回收过程中，同时还允许我们写的Java系统不停的运行在Eden里持续创建新的对象，目前来看是不合适的。 Stop the World​ 由上述可知，平时使用的JVM最大的痛点，就是在垃圾回收的这个过程。因为在垃圾回收的时候，尽可能让垃圾回收器专心致志的干活，不能随便让我们写的Java系统继续创建对象了，所以此时JVM会在后台直接进入“stop the World”状态。即，它会直接停止我们写的Java系统的所有工作线程，让我们写的代码不再运行，然后让垃圾回收线程可以专心致志地进行垃圾回收的工作。 ![stop the world](JVM之垃圾回收器/stop the world.png) ​ 这样的话，就可以让我们的系统暂停运行，然后不再创建新的对象，同时让垃圾回收线程尽快完成垃圾回收的工作，就是标记和转移Eden和Survivor2的存活对象到Survivor1中去，然后尽快一次性地回收掉Eden和Survivor2中的垃圾对象。一旦垃圾回收完毕，既可以继续恢复我们写的Java系统的工作线程了，然后我们的那些代码就可以继续运行，继续在Eden中创建新的对象。 Stop the World造成的系统停顿​ 现在大家清楚了“Stop the World”对系统造成的影响了，假设我们的Minor GC要运行100ms，那么可能会导致我们系统直接停顿100ms不能处理任何请求。如果因为内存分配不合理，导致对象频繁进入老年代，平均七八分钟一次Full GC，而Full GC是最慢的，有的时候弄不好一次回收要运行几秒钟，甚至是几分钟都是有可能的。 ​ 因此，无论是新生代GC还是老年代GC，都尽量不要让频率过高，也避免持续时间过长，避免影响系统正常运行，这也是使用JVM过程中一个最需要优化的地方，也是最大的一个痛点。 新生代垃圾回收器：ParNew​ 一般来说，假设没有最新的G1垃圾回收器的话，大家线上系统都是ParNew垃圾回收器作为新生代的垃圾回收器。 ​ 新生代的ParNew垃圾回收器主打的是多线程垃圾回收机制。另外一种Serial垃圾回收器主打的是单线程垃圾回收，他们两都是回收新生代的，唯一的区别就是单线程和多线程的区别，但是垃圾回收算法都是一致的。 ​ 如下图，ParNew垃圾回收器如果一旦在合适的时期执行Minor GC的时候，就会把系统程序的工作线程全部停掉，禁止程序继续运行创建新的对象，然后自己就用多个垃圾回收线程去进行垃圾回收，回收的机制和算法跟之前是一样的。 为线上系统指定使用ParNew垃圾回收器​ 线上系统，如果部署到Tomcat时可以在Tomcat的catalina.sh中设置Tomcat的JVM参数，使用Spring Boot也可以在启动时指定JVM参数。 ​ 在启动系统的时候，使用-XX:+UseParNewGC选项，就可以对系统指定使用ParNew垃圾回收器。那么Minor GC的时机，检查机制，包括垃圾回收的具体过程，以及对象升入老年代的机制，都是我们之前说的那套原理了，只不过，ParNew会使用多个线程来进行垃圾回收。 ParNew垃圾回收器默认情况下的线程数量​ 因为现在一般我们不熟系统的服务器都是多核CPU，所以为了在垃圾回收的时候充分利用多核CPU的资源，一旦我们指定了使用ParNew垃圾回收器之后，他默认给自己设置的垃圾回收线程的数量就是跟CPU的核数是一样的。 ​ 比如我们线上机器假设用的是4核CPU或者8核CPU，那么此时ParNew的垃圾回收线程数就会分别是4个线程、8个线程。 ​ 这个东西一般不用我们手动去调节，因为跟CPU核数一致的线程数量，是可以充分进行并行处理的。如果要调节ParNew的垃圾回收线程数量，可以使用-XX:ParallelGCThreads参数即可。但是一般不建议随意动这个参数。 老年代垃圾回收器：CMS​ 一般老年代我们选择的垃圾回收器是CMS，他采用的是标记整理算法，其实非常简单，就是先用之前讲过的标记方法区标记出哪些对象是垃圾对象，然后把这些垃圾对象清理掉。 先Stop the World，再垃圾回收？​ 如果先Stop the World，然后再采用“标记-整理”算法去回收垃圾。会造成系统卡死时间过长，很多相应无法处理。所以CMS垃圾回收器采取的是垃圾回收线程和系统工作线程尽量同时执行的模式来处理的。 CMS的垃圾回收过程​ CMS在执行一次垃圾回收的过程一共分为4个阶段： 初始标记 并发标记 重新标记 并发清理 初始标记​ 首先，CMS要进行垃圾回收，会先执行初始标记阶段，这个阶段会让系统的工作线程全部停止，进入“Stop the World”状态。而所谓的“初始标记”，就是标记出来所有GC Roots直接引用的对象。例如下面的代码： 12345678public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125;public class ReplicaManager &#123; private ReplicaFetcher replicaFetcher = new ReplicaFetcher();&#125; ​ 在初始标记阶段，仅仅过通过“replicaManager”这个类的静态变量代表的GC Roots，去标记出他直接引用的ReplicaManager对象，这就是初始标记的过程。它不会去管ReplicaFetcher这种对象，因为ReplicaFetcher对象是被ReplicaManager类的“replicaFetcher”实例变量引用的。之前说过，方法的局部变量和类的静态变量是GC Roots。但类的实例变量不是GC Roots。 ​ 所以第一个阶段，初始标记，虽然要造成“Stop the World”暂停一切工作线程，但是其实影响并不大，因为他的速度很快，仅仅标记GC Roots直接引用的那些对象而已。 并发标记​ 第二个阶段是并发标记，这个阶段会让系统线程可以随意创建各种对象，继续运行。在运行期间可能会创建新的存活对象，有可能让部分存活对象失去引用，变成垃圾对象。在这个过程中，会尽可能地对已有的对象进行GC Roots追踪。 ​ 所谓进行GC Roots追踪，意思就是对类似“ReplicaFetcher”之类的全部老年代里的对象，看它被谁引用了。比如这里是被“ReplicaManager”对象的实例变量引用了，接着会看，“ReplicaManager”对象被谁引用了，会发现被“Kafka”类的静态变量引用了。那么此时可以认定“ReplicaFetcher”对象是被GC Roots间接引用的，因此此时就不需要回收它。但是在这个过程，在进行并发标记的时候，系统程序会不停的工作，它可能会创建出新的对象，部分对象可能变成为垃圾，如下图： ​ 第二个阶段，就是标记出 GC roots 关联到的对象的引用对象有哪些。比如说 A -&gt; B (A 引用 B，假设 A 是 GC Roots 关联到的对象)，那么这个阶段就是标记出 B 对象， A 对象会在初始标记中标记出来。 这个阶段其实是最耗时的，但是这个最耗时的阶段，是跟系统并发运行的，所以这个阶段不会对系统运行造成影响。 重新标记​ 在第二阶段并发标记中，因为一边标记存活对象和垃圾对象，一边系统不停运行创建对象，让老对象变成垃圾。所以第二阶段结束之后，会有很多存活对象和垃圾对象，是之前第二阶段没标记出来的。所以此时进入第三阶段，要继续让系统程序停下来，再次进入“Stop the World”状态。然后重新标记下在第二阶段里创建的一些对象，还有一些已有对象可能失去引用变成垃圾的情况。 ​ 重新标记的阶段，速度是很快的。因为它其实就是对在第二阶段中被系统程序运行变动过的少数对象进行标记，所以运行速度很快。 并发清理​ 这个阶段就是让系统程序随意运行，然后它来清理之前标记为垃圾的对象即可。这个阶段其实也很耗时，因为需要进行对象的清理，但是它也是跟随系统程序并发运行的，所以也不影响系统的执行。 CMS的垃圾回收机制性能分析​ 从上述我们知道CMS的垃圾回收机制已经尽可能地进行了性能优化。其中最耗时的，就是对老年代全部对相关进行GC Roots追踪，标记出来哪些可以回收，然后就是对各种垃圾对象从内存里清理掉。 ​ 但是他的第二和第四阶段，即并发标记和并发清理，都是和系统程序并发执行的，所以基本对性能影响不大。只有第一和第三阶段是需要“Stop the World”的，但是这两个阶段都是简单的标记而已，速度非常快，所以基本上对系统运行影响也不大。 CMS的一些细节并发回收垃圾导致CPU资源紧张​ CMS垃圾回收器有一个问题，虽然能在垃圾回收的同事让系统同事工作，但在并发标记和并发清理两个最耗时的阶段，垃圾回收线程和系统工作线程同时工作，会导致有限的CPU资源被垃圾回收线程占用了一部分。CMS默认启动的垃圾会回收线程的数量是（CPU核数 + 3）/ 4。假设是2核CPU，那么CMS会有（2 + 3）/ 4 = 1个垃圾回收线程，去占用一个CPU。所以CMS这个并发垃圾回收机制，第一个问题就是会消耗CPU资源。 Concurrent Mode Failure问题​ 在并发清理阶段，CMS只不过是回收之前标记好的垃圾对象。但是这个阶段系统一直在运行，可能会随着系统运行让一些对象进入老年代，同时还变成垃圾对象，这种垃圾对象被称为为“浮动垃圾”。 ​ 虽然它成为了垃圾，但是CMS只能回收之前标记出来的垃圾对象，不会回收它们，需要等待到下一次GC的时候才会回收它们。所以为了保证CMS垃圾回收期间，还有一定的内存空间让一些对象可以进入老年代，一般会预留一些空间。CMS垃圾回收的触发时机，其中有一个就是当老年代内存占用达到一定比例了，就会自动执行GC。 ​ -XX:CMSInitiatingOccupancyFaction参数可以用来设置老年代占用多少比例的时候触发CMS垃圾回收，JDK1.6默认的值是92%。即老年代占用了92%的空间了，就自动进行CMS垃圾回收，预留8%的空间给并发回收期间，系统程序把一些新对象放入老年代中。 ​ 如果CMS垃圾回收期间，系统程序要放入老年代的对象大于可用内存空间，这个时候，会发生Concurrent Mode Failure，就是说并发垃圾回收失败了，我一边回收，你一边把对象放入老年代，内存都不够了。 ​ 此时就会自动用“Serial Old”垃圾回收器替代CMS，就是直接把系统程序“Stop the World”，重新进行长时间的GC Roots追踪，标记出全部垃圾对象，不允许新的对象产生，然后一次性把垃圾对象都回收掉，完事了再恢复系统线程。 ​ 所以在生产实践中，这个自动触发CMS垃圾回收的比例需要合理优化一下，避免“Concurrent Mode Failure”问题。 内存碎片问题​ 老年代的CMS采用“标记-清理”算法，每次都是标记出来垃圾对象，然后一次性回收掉。这样会导致大量的内存碎片产生。如果内存碎片太多，会导致后续对象进入老年代找不到可用的连续内存空间，然后就触发Full GC。所以CMS不是完全仅仅用“标记-清理”算法的，因为太多的内存碎片实际上会导致更加频繁的Full GC。 ​ CMS有一个参数是-XX:+UseCMSCompactAtFullCollection，默认是打开的，意思是在Full GC之后要再次进入“Stop the World”，停止工作线程，然后进行碎片整理，就是把存活对象挪到一起，空出来大片连续内存空间，避免内存碎片。还有一个参数时-XX:CMSFullGCsBeforeCompaction,这个意思是执行多少次Full GC之后再执行一次内存碎片整理的工作，默认是0，意思是每次Full GC之后都会进行一次内存整理。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM之垃圾回收]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F18%2FJVM%E4%B9%8B%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 在Java中，平时我们系统运行创建的对象都是优先分配在新生代里的。如果新生代里的对象越来越多，都快满了，此时就会触发垃圾回收，把新生代没有引用的对象给回收掉，从而释放内存空间。现在我们来看看，JVM是按照什么规则来回收垃圾对象的。 哪些引用对象不能被回收​ JVM中使用了可达性分析算法来判定哪些对象是可以被回收的。这个算法的意思是，对每个对象，都分析一下有谁在引用他，然后一层一层往上去判断，看是否有一个GC Roots。其中方法的局部变量、类的静态变量都可以看做是一种GC Roots。 案例​ 如下一段代码，就是在一个方法中创建了一个对象，然后有一个局部变量引用了这个对象。 12345678910public class Kafka &#123; public static void main(String[] args) &#123; loadReplicaFromDisk(); &#125; public static void loadReplicaFromDisk() &#123; ReplicaManager replicaManager = new ReplicaManager(); &#125;&#125; ​ 分析代码可知，“main()”方法的桢栈入栈，然后调用“loadReplicaFromDisk()”方法，桢栈入栈，接着让局部变量“replicaManager”引用堆内存里的“ReplicaManager”实例对象，如下图： ​ 现在上图中“ReplicaManager”对象被局部变量给引用了，此时一旦新生代满了，发生垃圾回收，就会分析这个“ReplicaManager”对象的可达性。此时会发现它是不能被回收的，因为它被人引用了，而且是局部变量“replicaManager”引用的。 ​ 只要一个对象被局部变量引用了，那么说明它有一个GC Roots，此时就不能被回收了。 ​ 另外一种情况，如下面代码： 1234public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125; ​ 跟上面的那个一样，一分析，发现“ReplicaManager”对象被Kafka类的一个静态变量”replicaManager”给引用了，此时就不会去回收它。 ​ 总结：只要你的对象被方法的局部变量、类的静态变量给引用了，就不会回收它们。 Java中对象不同的引用类型​ 关于引用和垃圾回收的关系，我们要有一个概念，就是Java里有不同的引用类型。分别是强引用、软引用、弱引用和虚引用。 强引用​ 强引用，就是类似下面的代码： 1234public class Kafka &#123; public static ReplicaManager replicaManager = new ReplicaManager();&#125; ​ 这个就是最普通的代码，一个变量引用一个对象。只要是强引用的类型，那么垃圾回收的时候就绝对不会去回收这个对象的。 软引用​ 软引用，类似下面的代码： 12345public class Kafka &#123; public static SoftReference&lt;ReplicaManager&gt; replicaManager = new SoftReference&lt;ReplicaManager&gt;(new ReplicaManager());&#125; ​ 就是把“ReplicaManager”实例对象用一个“SoftReference”软引用类型的对象给包裹起来，此时这个“replicaManager”变量对“ReplicaManager”对象的引用就是软引用了。 ​ 正常情况下垃圾回收时不会回收软引用对象的，但是如果进行垃圾回收之后，发现内存空间还不不够存放新的对象，此时就会把这些软引用对象给回收了。即便它被变量引用了，但是因为它是软引用，所以还是可以回收的。 弱引用​ 弱引用，类似下面代码： 12345public class Kafka &#123; public static WeakReference&lt;ReplicaManager&gt; replicaManager = new WeakReference&lt;ReplicaManager&gt;(new ReplicaManager());&#125; ​ 弱引用就跟没有引用是类似的，如果发生垃圾回收，就会把这个对象回收掉。 虚引用​ 虚引用，正如其名，对一个对象而言，这个引用形同虚设，有和没有一样。此外，虚引用必须和引用队列一起使用。 finalize()方法的作用​ 从上面可知，有GC Roots引用的对象不能回收，没有GC Roots引用的对象可以别回收。如果有GC Roots引用，但是引用时软引用或者弱引用，也有可能被回收。 ​ 但是没有GC Roots引用的对象，一定会被立马回收吗？其实并不是，这里有一个finalize()方法可以抢救一下。如下代码： 123456789public class ReplicaManager &#123; public static ReplicaManager instance; @Override protected void finalize() throws Throwable &#123; ReplicaManager.instance = this; &#125;&#125; ​ 如果有一个ReplicaManager对象要被垃圾回收了，那么假如这个对象重写了Object类中的finalize()方法。此时会先尝试调用它的finalize方法，看是否把这个实例对象给了某个GC Roots变量，比如上面代码就给了ReplicaManager类的静态变量。这样就重新让某个GC Roots变量引用了自己，那么就不用被垃圾回收了。 垃圾回收算法标记-清除算法​ 改算法会从每个GC Roots出发，依次标记没有引用关系的对象，最后将没有被标记的对象清除。但是这种算法会带来大量的空间碎片，导致需要分配一个较大连续空间时容易触发full GC. 标记-整理算法​ 为了解决“标记-清除”算法导致的大量内存碎片问题，又提出了“标记-整理算法”。改算法类似计算机的磁盘整理，首先会从GC Roots出发标记存活的对象，然后将存活的对象整理到内存空间的一端，形成连续的已使用空间，最后把已使用空间之外的部分全部清除掉，这样就不会产生空间碎片的问题。 复制算法​ 为了能够并行地标记和整理，将空间分为两块，每次只激活其中一块，垃圾回收时只需把存活的对象复制到另一块未激活的空间上，将未激活空间标记为已激活，将已激活空间标记为未激活，然后清除原空间中的原对象。两块空间就这么重复循环使用。复制算法现作为主流的YGC算法进行新生代的垃圾回收。 JVM中对复制算法的优化​ 在实际真正的复制算法中，把新生代内存区域划分为三块：1个Eden区，2个Survivor区。其中Eden区占80%内存空间，每一块Survivor区各占10%内存空间。平时可以使用的，就是Eden区和其中一块Survivor区。但是刚开始对象都是分配在Eden区的，如果Eden区满了吗，此时就会触发YGC。 ​ 此时就会把Eden区中的存活对象都一次性转移到空着的Survivor区，接着Eden区就会被清空，然后再次分配新对象到Eden区。这就就会变成Eden区和Survivor区里都是有对象的，其中Survivor区里放的是上一个YGC存活后的对象。 ​ 这么设计会始终保持一个Survivor区的空着的，就这样一直循环只用这三块内存区域。这么最最大的好处是，只有10%的空间时被闲置的，90%的内存都被用上了。 老年代和新生代怎样变成老年代​ 对象一般都先分配在新生代，但什么情况下新生代会变成老年代呢？ 躲过15次GC之后进入老年代​ 一般情况下，我们系统刚启动的时候，创建的各种各样的对象，都是分配在新生代里的。然后系统跑着跑着，新生代就满了，此时就会触发Minor GC，可能就是1%的少量存活对象转移到空着的Survivor区中。然后系统继续运行，继续在Eden区了分配各种对象。大概就是这个流程。 ​ 但那些每次在新生代里躲过一次GC被转移到一块Survivor区域中，它的年龄就会增长一岁。默认情况下，当对象的年龄达到15岁时，也就是躲过15次GC的时候，它就会转移到老年代里去。具体是多少岁进入老年代，可以通过参数-XX:MaxTenuringThreshold来设置，默认是15岁。 动态对象年龄判断​ 这里跟这个对象年龄有另外一个规则可以让对象进入老年代，不用等待15次GC过后才可以。大致的规则是：假如当前放对象的Survivor区域里，一批对象的总大小大于了这块区域的内存大小的50%，那么此时大于等于这批对象年龄的对象，就可以直接进入老年代了。 ​ 假设图里的Survivor2区有两个对象，这两对象的年龄一样，都是2岁。然后这两对象加起来超过了50MB，超过了Survivor2区的100MB内存的一半了，这个时候，Survivor2区里的大于等于2岁的对象，就要全部进入老年代里去。 ​ 这就是所谓的动态年龄判断的规则。实际上这个规则运行的时候是如下的逻辑：年龄1 + 年龄2 + 年龄n的多个年龄对象总和超过了Survivor区域的50%，此时就会把年龄n以上的对象都放入老年代。 大对象直接进入老年代​ 有一个JVM参数，就是-XX:PretenureSizeThreshold，可以把他的值设置为字节数，比如“1048576”，就是1MB。它的意思是，如果你要创建一个大于等于这个大小的对象，比如一个超大的数组，此时就直接把这个大对象放到老年代去，不会经过新生代。 ​ 这么做的原因，就是要避免新生代里出现那种大对象，然后屡次躲过GC，还得把它在两个Survivor区域里来回复制多次之后才能进入老年代，那么大的对象在内存里来回复制，浪费时间。 Minor GC后的对象太多无法放入Survivor区怎么办​ 如果Minor GC后的对象太多无法放入Survivor，那么这个时候就必须把这些对象直接转移到老年代中去。 老年代空间分配担保规则 在执行任何一次Minor GC之前，JVM会先检查一下老年代可用的内存空间，是否大于新生代所有对象的总大小。为什么检查这个，因为极端情况下，可能新生代Minor GC过后，所有对象都存活下来。 如果老年代的内存大小是大于新生代所有对象的，此时就可以放心大胆的对新生代发起一次Minor GC。因此即使Minor GC之后所有对象存活，Survivor区放不下，也可以转移到老年代去。 如果老年代的可用内存已经小于新生代的全部对象了，就去看-XX:-HandlePromotionFailure参数是否设置。 如果设置了，就看老年代的内存大小，是否大于之前每一次Minor GC后进入老年代的对象的平均大小。例如，之前每次Minor GC后，平均都有10MB左右的对象会进入老年代，那么此时老年代可用内存大于10MB。很可能这次Minor GC过后也是差不多10MB左右的对象会进入老年代，此时老年代空间是够的。 如果判断失败，或者是-XX:-HandlePromotionFailure参数没设置，此时就会触发一次“Full GC”，就是对老年代进行垃圾回收，尽量腾出一些内存空间，然后再执行Minor GC。 如果上面两个步骤都判断成功了，那就可以冒风险尝试一下Minor GC。此时进行Minor GC有几种可能。 第一种可能，Minor GC过后，剩余存活的对象的大小小于Survivor区的大小，那么此时存活对象进入Survivor区域即可。 第二种可能，Minor GC过后，剩余的存活对象的大小，大于Survivor区域的大小，但是小于老年代可用内存大小，此时直接进入老年代。 第三种可能，Minor GC过后，剩余的存活对象的大小，大于Survivor区域的大小，也大于老年代可用内存的大小。此时老年代都放不下这些存活对象了，就会发生“Handle Promotion Failure”的情况，这个时候就会触发一次“Full GC”。Full GC就是对老年代进行垃圾回收，同时一般也会对新生代进行垃圾回收。 如果Full GC之后，老年代还是没有足够的空间存放Minor GC过后的剩余存活对象，那么此时就会导致所谓的“OOM”内存溢出。 老年代垃圾回收算法​ 通过上面的内容，可以总结一句话：对老年代触发垃圾回收时机，一般就是两个： 在Minor GC之前，检查发现很可能Minor GC之后要进入老年代的对象太多了，老年代放不下，此时需要提前触发Full GC然后再带着进行Minor GC。 在Minor GC之后，发现剩余对象太多，老年代内存不够。 ​ 那么对老年代进行垃圾回收采用的是什么算法呢？简单地说，就是上面提到过的标记-整理算法。但是，这个老年代的垃圾回收算法的速度比新生代的垃圾回收算法的速度慢10倍。如果系统频繁出现老年代的Full GC，会导致系统性能被严重影响，出现频繁卡顿的情况。 ​ 其实， 所谓JVM优化，就是尽可能让对象都在新生代里分配和回收，尽量别让太多对象频繁进入老年代，避免频繁对老年代进行垃圾回收，同时给系统充足的内存大小，避免新生代频繁的进行垃圾回收。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列之RocketMQ]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F10%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B9%8BRocketMQ%2F</url>
    <content type="text"><![CDATA[​ RocketMQ是阿里开源并贡献给Apache基金会的一款分布式消息平台，具有低延迟。高性能和可靠性、万亿级容量和灵活的可伸缩性的特点。单机也可以支持亿级的消息堆积能力、单机写入TPS单实例越7万条/秒，单机部署3个Broker，最高可以跑到12万条/秒。 RocketMQ的基本构成​ 整个RocketMQ消息系统主要由4个部分组成。 ​ 从中间件服务角度来看整个RocketMQ消息系统（服务端）主要分为：NameSrv和Broker两个部分。 NameSrv​ 在RocketMQ分布式消息系统中，NameSrv主要提供两个功能： 提供服务发现和注册。这里主要是管理Broker，NameSrv接受来自Broker的注册，并通过心跳机制来检测Broker服务的健康性。 提供路由功能。集群（这里是指以集群方式部署的NameSrv）中的每个NameSrv都保存了Broker集群（这是是指以集群方式部署的Broker）中整个的路由信息和队列信息。这里需要注意，在NameSrv集群中，每个NameSrv都是相互独立的，所以每个Broker需要连接所有的NameSrv，每创建一个新的topic都要同步到所有的NameSrv上。 Broker​ 主要是负责消息的存储、传递、查询以及高可用（HA）保证等。其由如下几个子模块构成： remoting：是Broker的服务入口，负责客户端的接入（Producer和Consumer）和请求处理。 client：管理客户端和维护消费者对于Topic的订阅。 store：提供针对存储和消息查询的简单的API（数据存储在物理磁盘）。 HA：提供数据在主从节点间同步的功能特性。 Index：通过特定的key构建消息索引，并提供快速的索引查询服务。 ​ 而从客户端的角度看主要有：Producer、Consumer两个部分。 Producer​ 消息的生产者，由用户进行分布式部署，消息有Producer通过多种负载均衡模式发送到Broker集群，发送低延时，支持快速失败。 Consumer​ 消息的消费者，也有用户部署，支持PUSH和PULL两种消费模式，支持集群消费和广播消费，提供实时的消息订阅机制，满足大多数消费场景。 RocketMQ的其他概念Producer Group​ 相同角色的生产者被组织到一起。在事务提交后，生产组中不同实例都可以连接broker执行提交或回滚事务，以防原生产者在提交后就挂掉。 Consumer Group​ 具有完全相同角色的消费者被组合在一起并命名为消费者组，消费群体是一个很好的概念，它在消费信息方面实现负载平衡和容错目标是非常容易的。另外，消费者组的消费者实例必须具有完全相同的主题订阅。 Topic​ 主题是生产者提供消息和消费者提取消息的类别。主题与生产者和消费者的关系非常松散，具体而言，一个主题可能有零个，一个或多个向其发送消息的生产者；相反，生产者可以发送不同主题的信息。从消费者的角度来看，一个主题可能有零个，一个或多个消费者群体订阅。同样，一个消费群体可以订阅一个或多个主题，只要这个群体的实例保持其订阅的一致性即可。 Message​ 消息是要传递的信息。一条信息必须要有一个主题，可以将其解释为要发送给您的信件的地址。一条消息也可能有一个可选标签和额外的键值对。例如，你可以为消息设置业务密钥，并在Broker上查找消息以在开发期间诊断问题。 Message Queue​ 主题被划分为一个或多个子主题，这就是消息队列。 Tag​ 标签可以理解为更细一级的主题，为使用者提供更灵活的查找。使用标签，来自同一业务模块的具有不同目的消息可能就有相同的主题和不同的标签。标签将有助于保持代码的清洁和一致性，并且标签还可以方便RocketMQ提供的查询系统。 Message Order​ 当使用DefaultMQPushConsumer时，你可能需要决定消费是顺序的还是并发的。 Orderly（顺序）：有序的消息意味着消息的使用顺序与生产者为每个消息队列发送的顺序相同。如果你的使用场景要求是必须顺序的，你要确保只用一个队列存放消息。如果消费顺序被指定，最大的消费并发数就是这个消费者组的消息队列的订阅数。 Concurrently（并发）：并发使用消息时，消费消息的最大并发性仅受限于为每个消费者客户端指定的线程池。 安装RocketMQ1、下载Apache最新rocketmq二进制压缩文件​ 可以到官网下载后上传到服务器上，也可以用wget命令。 1wget https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.5.2/rocketmq-all-4.5.2-bin-release.zip/ 2、解压安装​ 使用unzip命令进行解压。 1unzip -d /usr/local rocketmq-all-4.5.2-bin-release.zip 3、环境变量​ 配置环境变量 vi /etc/profile。添加如下代码： 1export NAMESRV_ADDR=127.0.0.1:9876 4、启动RocketMQ​ 进入rocketmq的bin目录，修改runserver.sh，如下代码： 1JAVA_OPT="$&#123;JAVA_OPT&#125; -server -Xms8g -Xmx8g -Xmn4g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m" ​ 主要根据自己机器内存酌情修改-Xms -Xmx -Xmn这几个参数的内存。 ​ 同理修改bin目录下的runbroker.sh的JVM参数。 ​ 进入conf目录，修改broker.conf，新增一行： 1brokerIP1=xx.xx.xx.xx # 你的公网IP ​ 然后开始启动mqnamesrv，进入到rocket目录，执行nohup sh bin/mqnamesrv &amp;启动namesrv，然后再执行nohup sh bin/mqbroker -n localhost:9876 -c conf/broker.conf &amp;启动broker。 ​ 执行jps，看namesrv和broker是否启动成功，如果没成功。可以通过执行tail -f ~/logs/rocketmqlogs/namesrv.log和tail -f ~/logs/rocketmqlogs/broker.log查看相应日志。 RocketMQ集群模式​ RocketMQ集群部署有多种方式，对于NameSrv来说可以同时部署多个节点，并且这些节点间也不需要有任何的信息同步，因为这里每个NameSrv节点都会存储全量路由信息。在NameSrv集群模式下，每个Broker都需要同时向集群中的每个NameSrv节点发送注册信息，所以这里对于NameSrv的集群部署来说并不需要做什么额外的设置。 ​ 而对于Broker集群来说就有多种模式了，主要有如下几个模式： 单个Master模式​ 一个Broker作为主服务，不设置任何Slave，这种方式风险比较大，存在单节点故障会导致整个基于消息的服务挂掉，所以生产环境不可能采用这种模式。 多Master模式​ 这种模式的Broker集群，全是Master，没有Slave。 优点​ 配置会比较简单一些，如果单个Master挂掉或重启维护的话对应用是没有什么影响的。如果磁盘配置为RAID10（服务器的磁盘阵列模式）的话，即使在机器宕机不可恢复的情况下，由于RAID10磁盘本身的可靠性，消息也不会丢失（异步刷盘丢失少量消息，同步刷盘一条不丢），这个Broker的集群模式性能相对来说是最高的。 缺点​ 在单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前是不可以进行消息订阅的，这对消息的实时性有一些影响。 多Master多Slave模式（异步复制）​ 这种模式下的Broker集群存在多个Master节点，并且每个Master节点都会对应一个Slave节点，有多对Master-Slave，HA（高可用）之间采用异步复制的方式进行信息同步，在这种方式下主从之间会有短暂的毫秒级的消息延迟。 优点​ 这种模式下即使磁盘损坏了，消息丢失的情况也非常少，因为主从之间有消息备份。并且，这种模式下的实时性也不会受影响，因为Master宕机后Slave可以自动切换为Master模式，这样Consumer仍然可以通过Slave进行消息消费，而这个过程对应用来说是完全透明的，并不需要人工干预。另外，这种模式的性能与多Master模式几乎差不多。 缺点​ 如果Master宕机，并且在磁盘损坏的情况下，会丢失少量的消息。 多Master多Slave模式（同步复制）​ 这种模式与上面那个差不多，只是HA采用的是同步双写的方式，即主备都写成功后，才会向应用返回成功。 优点​ 这种模式下数据与服务不存在单点的情况，在Master宕机的情况下，消息也没有延迟，服务的可用性以及数据的可用性都非常高。 缺点​ 性能相比于异步复制略低一些（大约10%）。 SpringBoot整合RocketMQ​ 这里主要讲解一下生产者和消费者的代码，完整的项目代码已上传到github上。 消息生产者RocketMQProvider​ 以顺序发消息为例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package com.example.rocketmqDemo.rocketmq;import org.apache.rocketmq.client.producer.DefaultMQProducer;import org.apache.rocketmq.client.producer.MessageQueueSelector;import org.apache.rocketmq.client.producer.SendResult;import org.apache.rocketmq.common.message.Message;import org.apache.rocketmq.common.message.MessageQueue;import org.springframework.beans.factory.annotation.Value;import org.springframework.stereotype.Service;import org.springframework.util.StopWatch;import java.util.List;@Servicepublic class RocketMQProvider &#123; @Value("$&#123;apache.rocketmq.producer.producerGroup&#125;") private String producerGroup; @Value("$&#123;apache.rocketmq.namesrvAddr&#125;") private String namesrvAddr; public void defaultMQProducer() &#123; //生产组的名称 DefaultMQProducer producer = new DefaultMQProducer(producerGroup); //指定NameServer地址，多个地址以;隔开 producer.setNamesrvAddr(namesrvAddr); try &#123; //Producer对象在使用之前必须要调用start初始化，初始化一次即可 //注意：切记不可以在每次发送消息时，都调用start方法 producer.start(); //创建一个消息实例，包含topic、tag和消息体 //如下：topic为"TopicTest"，tag为"push" Message message = new Message("TopicTest", "push", "发送消息----".getBytes()); StopWatch stop = new StopWatch(); stop.start(); for(int i = 0; i &lt; 10; i++) &#123; SendResult result = producer.send(message, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125; &#125;, 1); System.out.println("发送相应：MsgId: " + result.getMsgId() + ".发送状态: " + result.getSendStatus()); &#125; stop.stop(); System.out.println("-----------------------发送十条消息耗时：" + stop.getTotalTimeMillis()); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125;finally &#123; producer.shutdown(); &#125; &#125;&#125; ​ 一般消息时通过轮询所有队列来发送的（负载均衡策略），顺序消息可以根据业务发送到同一个队列。比如将订单号相同的消息发送到同一个队列。下面的代码中指定了1,1处这个值相同的获取到的队列是同一个队列。 12345678SendResult result = producer.send(message, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Integer id = (Integer) arg; int index = id % mqs.size(); return mqs.get(index); &#125;&#125;, 1); 消息消费者RocketMQConsumer123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.example.rocketmqDemo.rocketmq;import org.apache.rocketmq.client.consumer.DefaultMQPushConsumer;import org.apache.rocketmq.client.consumer.listener.ConsumeConcurrentlyStatus;import org.apache.rocketmq.client.consumer.listener.MessageListenerConcurrently;import org.apache.rocketmq.common.consumer.ConsumeFromWhere;import org.apache.rocketmq.common.message.MessageExt;import org.springframework.beans.factory.annotation.Value;import org.springframework.boot.CommandLineRunner;import org.springframework.stereotype.Service;@Servicepublic class RocketMQConsumer implements CommandLineRunner &#123; //消费者的组名 @Value("$&#123;apache.rocketmq.consumer.PushConsumer&#125;") private String consumerGroup; @Value("$&#123;apache.rocketmq.namesrvAddr&#125;") private String namesrvAddr; public void defaultMQPushConsumer() &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(consumerGroup); consumer.setNamesrvAddr(namesrvAddr); try &#123; //订阅PushTopic下Tag为push的消息 consumer.subscribe("TopicTest", "push"); //设置Consumer第一次启动是从头部开始消费还是队列尾部开始消费 //如果非第一次启动，那么按照上次消费的位置继续消费 consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.registerMessageListener((MessageListenerConcurrently)(list, context)-&gt; &#123; try &#123; for(MessageExt messageExt : list) &#123; //输出消息内容 System.out.println("messageExt: " + messageExt); String messageBody = new String(messageExt.getBody()); //输出消息内容 System.out.println("消费响应：msgId : " + messageExt.getMsgId() + ", msgBody : " + messageBody); &#125; &#125;catch (Exception e) &#123; e.printStackTrace(); //稍后重试 return ConsumeConcurrentlyStatus.RECONSUME_LATER; &#125; //消费成功 return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;); consumer.start(); &#125;catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; @Override public void run(String... args) throws Exception &#123; this.defaultMQPushConsumer(); &#125;&#125; ​ 消费者中我们实现了CommandLineRunner接口。它的作用是让消费者在springboot启动时执行。具体可以参考CommandLineRunnable详解。 ​ 项目成功启动后，测试的结果应该是： 123456789101112131415161718192021222324252627282930313233342019-10-11 17:13:50.785 INFO 12872 --- [nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet 'dispatcherServlet'2019-10-11 17:13:50.785 INFO 12872 --- [nio-8080-exec-2] o.s.web.servlet.DispatcherServlet : Initializing Servlet 'dispatcherServlet'2019-10-11 17:13:50.793 INFO 12872 --- [nio-8080-exec-2] o.s.web.servlet.DispatcherServlet : Completed initialization in 8 ms发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OK发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=51, sysFlag=0, bornTimestamp=1570785233301, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231900, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEAFFF, commitLogOffset=28225535, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=52, CONSUME_START_TIME=1570785233370, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]messageExt: MessageExt [queueId=1, storeSize=178, queueOffset=50, sysFlag=0, bornTimestamp=1570785233233, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231856, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEAF4D, commitLogOffset=28225357, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=52, CONSUME_START_TIME=1570785233370, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=52, sysFlag=0, bornTimestamp=1570785233346, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231943, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB0B1, commitLogOffset=28225713, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=53, CONSUME_START_TIME=1570785233411, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=53, sysFlag=0, bornTimestamp=1570785233387, bornHost=/61.144.97.110:2191, storeTimestamp=1570785231986, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB163, commitLogOffset=28225891, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=54, CONSUME_START_TIME=1570785233453, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=54, sysFlag=0, bornTimestamp=1570785233430, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232028, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB215, commitLogOffset=28226069, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=55, CONSUME_START_TIME=1570785233495, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=55, sysFlag=0, bornTimestamp=1570785233472, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232071, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB2C7, commitLogOffset=28226247, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=56, CONSUME_START_TIME=1570785233538, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=56, sysFlag=0, bornTimestamp=1570785233516, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232114, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB379, commitLogOffset=28226425, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=57, CONSUME_START_TIME=1570785233580, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=57, sysFlag=0, bornTimestamp=1570785233557, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232156, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB42B, commitLogOffset=28226603, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=58, CONSUME_START_TIME=1570785233622, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OKmessageExt: MessageExt [queueId=1, storeSize=178, queueOffset=58, sysFlag=0, bornTimestamp=1570785233600, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232199, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB4DD, commitLogOffset=28226781, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=59, CONSUME_START_TIME=1570785233665, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息----发送相应：MsgId: 847F127D324818B4AAC2373225500000.发送状态: SEND_OK-----------------------发送十条消息耗时：1479messageExt: MessageExt [queueId=1, storeSize=178, queueOffset=59, sysFlag=0, bornTimestamp=1570785233642, bornHost=/61.144.97.110:2191, storeTimestamp=1570785232241, storeHost=/47.105.176.129:10911, msgId=2F69B08100002A9F0000000001AEB58F, commitLogOffset=28226959, bodyCRC=800335203, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message [topic=TopicTest, flag=0, properties=&#123;MIN_OFFSET=0, MAX_OFFSET=60, CONSUME_START_TIME=1570785233707, UNIQ_KEY=847F127D324818B4AAC2373225500000, WAIT=true, TAGS=push&#125;, body=16]]消费响应：msgId : 847F127D324818B4AAC2373225500000, msgBody : 发送消息---- 参考资料Centos7下安装Rocket RocketMQ连接异常 基于RocketMQ搭建生产级消息集群]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[外观模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F08%2F%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ 在软件开发中，有时候为了完成一项较为复杂的功能，一个类需要和多个其他业务类交互，而这些需要交互的业务类经常会作为一个完整的整体出现，由于涉及的类比较多，导致使用时代码较为复杂，此时，需要一个类似服务员一样的角色，由它来负责和多个业务类进行交互，而使用这些业务类的类只需和该类交互即可。外观模式通过引入一个新的外观类来实现该功能，外观类充当了软件系统中的“服务员”，它为多个业务类的调用提供了一个统一的入口，简化了类与类之间的交互。 外观模式定义​ 外观模式要求一个子系统的外部与其内部的通信通过一个统一的外观角色进行，外观角色将客户端与子系统的内部复杂性分隔开，使得客户端只需要与外观角色打交道，而不需要与子系统内部的很多对象打交道，其定义如下： ​ 外部与一个子系统的通信通过一个统一的外观角色进行，为子系统中的一组接口提供一个一致的入口，外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。外观模式又称为门面模式，它是一种对象结构型模式。 外观模式结构图 ​ 在外观模式结构图中包含以下两种角色： Facade（外观角色）：在客户端可以调用这个角色的方法，在外观角色中可以知道相关的（一个或者多个）子系统的功能和责任，在正常情况下，它将所有从客户端发来的请求委派到相应的子系统中去，传递给相应的子系统对象处理。 SubSystem（子系统角色）：在软件系统中可以有一个或者多个子系统角色，每一个子系统可以不是一个单独的类，而是一个类的集合，它实现子系统的功能，每一个子系统都可以被客户端直接调用，或者被外观角色调用，它处理由外观类传过来的请求；子系统并不知道外观的存在，对于子系统而言，外观角色仅仅是另外一个客户端而已。 案例​ 某软件公司欲开发一个可应用与多个软件的文件加密模块，改模块可以对文件中的数据进行加密并将加密之后的数据存储在一个新文件中，具体流程包括三个部分，分别是读取源文件、加密、保存加密之后的文件。其中，读取文件和保存文件使用流来实现，加密操作通过求模运算来实现。这三个操作相互独立，为了实现代码的独立重用，让设计更符合单一职责原则，这3个操作的业务代码封装在3个不同的类中。 ​ 相关代码已上传至github上。 抽象外观类的引入​ 在标准的外观模式中，如果需要增加、删除或更换与外观类交互的子系统类，必须修改外观类或客户端的源代码，这将违背开闭原则，因此可以通过引入抽象外观类来对系统进行改进，在一定程度上解决该问题。在引入抽象外观类之后，客户端可以针对抽象外观类进行编程，对于新的业务需求，不需要修改原有外观类，而对应增加一个新的具体外观类，由新的具体外观类来关联新的子系统对象，同时通过修改配置文件来达到不修改任何源代码并更换外观类的目的。 ​ 如在上面的案例中，如果要更换原有的加密方式，换成新的加密方式。那么相应的解决思路如下图： 外观模式主要优缺点主要优点 对客户端屏蔽了子系统组件，减少了客户端所需处理的对象数目并使得子系统使用起来更加容易。通过引入外观模式，客户端代码变得很简单，与之关联的对象也很少。 实现了子系统与客户端之间的松耦合关系，这使得子系统的变化不会影响到调用它的客户端，只需要调整外观类即可。 一个子系统的修改对其他子系统没有任何影响，而且子系统内部变化也不会影响到外观对象。 只是提供了一个访问子系统的统一入口，并不影响客户端直接使用子系统类。 主要缺点 不能很好地限制客户端直接使用子系统类，如果对客户端访问子系统类做太多的限制则减少了可变性和灵活性。 如果设计不当，当增加新的子系统可能需要修改外观类的源代码，这违背了开闭原则。 外观模式适用场景 当要为访问一系列复杂的子系统提供一个简单入口时可以使用外观模式。 客户端程序与多个子系统之间存在很大的依赖。引入外挂类可以将子系统与客户端解耦，从而提供子系统的独立性和可移植性。 在层次化结构中，可以使用外观模式定义系统中每一层的入口，层与层之间不直接产生联系，而通过外观类建立联系，降低层之间的耦合度。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列之RabbitMQ]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F07%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%B9%8BRabbitMQ%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ RabbitMQ是一个消息代理，一个消息系统的媒介。它可以为你的应用提供一个通用的消息发送和接收平台，并且保证消息在传输过程中的安全。 基础概念​ RabbitMQ中除了正常的生产者消费者之外，还有一些其他的概念来支撑这样一个复杂的消息队列。 Broker​ Broker是消息服务中间件的一个服务节点，大部分情况下可以把一个Broker看成一个RabbitMQ的服务器。 ​ 上图可以看出Broker相当于一个消息服务的中央节点，而我们的消息队列核心功能也就在Broker上。 队列​ 消息都存储在队列中，下图是一个简单的模型。实际上，一个简单的消息队列服务只要有生成者、消费者和存储单元组成队列即可。 Exchange​ 交换机（Exchange）在RabbitMQ中承担了一些队列的逻辑处理功能。一般来说，对于生产者，我们只知道把产生的内容丢到MQ当中，但是发到哪个队列中，这一点对于生产者来说是无感知的，也不知道目前对列的状况如何。而Exchange就承担了发到哪个队列中的职责，用几种路由策略来决定如何分发给不同的队列。 Connection和Channel​ 每一个Connection是一条TCP连接，理论上而言每一个消费者和生产者都需要一条Connection，但是TCP连接的开销很大，所以我们会使用Channel来进行TCP复用，减少性能的开销。 Exchange类型fanout​ 我们比较常用的一种Exchange类型，它会把所有发送到该交换器的消息路由到所有与该交换器绑定的队列中。 direct​ 把消息路由到binding 可以和routing key完全匹配的队列中。 ​ binding key和routing key基本上可以理解为对一个Queue的称呼。 ​ 图中Queue1叫warning，Queue2可以叫info，warning或者debug，那样Exchange叫了声warning的时候会有两个Queue过来拿数据，而info只有Queue2会回应。 topic​ direct类型太过严格，大部分我们都用不上这么严格的规则，因此有了topic。topic可以看做是一种正则表达式规则，满足正则表达式的规则就会进入队列。 headers​ 这种类型根据发送信息中的header来匹配，性能差，基本没用。 死信队列​ DLX（Dead-Letter-Exchanage）。利用DLX，当消息在一个对列中变成死信之后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。消息变成死信一般有以下几种情况： 消息被拒绝（basic.reject/basic.nack）并且不再重新投递 require = false 消息过期（rabbitmq Time-To-Live -&gt; messageProperties.setExpiration()） 队列达到最长长度 ​ 当一个消息变成死信导致队列无法处理的时候，开启死信队列，使得消息不会堆积在队列中，而换到死信队列被消费。在RabbitMQ中开启死信队列非常简单，只要配置为DLX即可。 公用Connection而不是Channel​ 公用Connection的理由在上面已经提过，那为什么不建议公用Channel呢？ ​ 计算机网络传输信息的时候，本质上都是二进制传输，而传输的数据经过一定的处理，最终变成我们可读可处理的数据，Channel已经是复用了TCP连接的，此时如果我们再进行并行的数据传输，很有可能会导致某一帧数据的异常。 RabbitMQ的高可用性​ RabbitMQ是基于主从做高可用性的。一般来说，RabbitMQ有三种模式：单机模式、普通集群模式和镜像集群模式。 单机模式​ 单机模式，就是Demo级别的，一般就是你本地启动了做做demo，基本没人生产用单机模式。 普通集群模式（无高可用性）​ 普通集群模式，意思就是在多台机器上启动多个RabbitMQ实例，每个机器启动一个。你创建的queue，只会放在一个RabbitMQ实例上，但是每个实例都同步queue的元数据（元数据可以认为是queue的一些配置信息，通过元数据，可以找到queue所在实例）。你消费的时候，实际上如果连接到了另一个实例，那么那个实例会从queue所在实例上拉取数据过来。 ​ 这种方式不仅麻烦，而且也没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。 ​ 而且如果那个放queue的实例宕机了，会导致接下来其他实例无法从那个实例拉取数据。如果你开启了消息持久化，让RabbitMQ落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。 ​ 因此这个方案主要是用来提供吞吐量的，就是让集群中多个节点来服务某个queue的读写操作，没有所谓的高可用性。 镜像集群模式（高可用性）​ 这种模式，才是所谓的RabbitMQ的高可用模式。跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，就是说，每个RabbitMQ节点都有这个queue的一个完成镜像，包含queue的全部数据的意思。然后你每次写消息到queue的时候，都会自动把消息同步到多个实例的queue上。 ​ 如何开启镜像集群模式？RabbitMQ有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求同步指定数据的节点，再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。 ​ 这样处理，好处在于任何一个机器宕机了，其他机器还包含了这个queue的完整数据，别的consumer都可以到其他节点上去消费数据。坏处在于：第一，性能开销太大，消息需要同步到所有机器上，导致网络带宽压力和消耗都重；第二，这样处理并不是分布式的，没有扩展性可言，如果某个queue负载很重，你加机器，新的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue。 RabbitMQ的可靠性传输​ 数据的丢失问题，可能出现在生产者、MQ、消费者中，如下图： 生产者弄丢了数据​ 生产者将数据发送到RabbitMQ的时候，因为网络问题或其他情况，导致数据在半路就搞丢了。 事务机制​ 此时可以选择用RabbitMQ提供的事务功能，就是生产者发送数据之前开启RabbitMQ事务channel.txSelect，然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务channel.txRollback，然后重试发送消息，如果收到了消息，那么可以提交事务channel.txCommit。 123456789101112// 开启事务channel.txSelecttry &#123; // 这里发送消息&#125; catch (Exception e) &#123; channel.txRollback // 这里再次重发这条消息&#125;// 提交事务channel.txCommit ​ 但是问题是，这样会导致吞吐量下来，因为太耗性能。 confirm机制​ 因此一般情况下，要确保RabbitMQ的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ中，RabbitMQ会给你回传一个ack消息，告诉你这个消息OK了，如果RabbitMQ没能处理这个消息，会回调你的一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。 两个机制的区别​ 事务机制和confirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息RabbitMQ接收了之后会异步回调你的一个接口通知你这个消息接收到了。所以一般在生产者这块避免数据丢失，都是用confirm机制。 RabbitMQ弄丢了数据​ 即使RabbitMQ自己弄丢了数据，这个你必须开启RabbitMQ的持久化，就是消息写入之后会持久化到磁盘，哪怕是RabbitMQ自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非RabbitMQ还没持久化，自己就挂了，可能导致少量数据丢失，但是这个概率比较小。 ​ 设置持久化有两个步骤： 创建queue的时候将其设置为持久化，这样就可以保证RabbitMQ持久化queue的元数据，但是它不会持久化queue里的数据。 第二是是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上去。 ​ 必须要同时设置这两个持久化才行，这样RabbitMQ哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。 ​ 但是哪怕是你给RabbitMQ开启了持久化机制，也有一种可能，就是这个消息写到了RabbitMQ中，但是还没来得及持久化到磁盘上，结果RabbitMQ挂了，就会导师内存里的一点点数据丢失。所以，持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产这ack了。这样即便是持久化到磁盘之前，RabbitMQ挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。 消费端弄丢了数据​ 如果消费端刚消费到消息，但还没处理，结果进程挂了，这样就尴尬了。RabbitMQ认为你都消费了，这数据也就丢了。 ​ 这个时候可以用RabbitMQ提供的ack机制，即，你必须关闭RabbitMQ的自动ack,可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再在程序里ack一把。这样的话，如果你还没处理完，就没有ack,RabbitMQ就认为你还没处理完，这个时候RabbitMQ会把这个消费分配给别的consumer去处理，消息是不会丢的。 RabbitMQ的消息顺序性​ 举个例子，一个mysql binlog同步的系统，日同步数据要达到上亿，就是说数据从一个mysql库原封不动同步到另一个mysql库里面去（mysql -&gt; mysql）。然后你在mysql里增删改一条数据，对应出来增删改3条binlog日志，接着这三条binlog发送到MQ里面，再消费出来依次执行，要保证是按顺序执行的。否则本来是：增加、修改、删除，最后换了顺序给执行成删除、修改、增加。这就错了。 ​ 先看看RabbitMQ消息会错乱的场景：在RabbitMQ中，一个queue，多个consumer、比如生产者向RabbitMQ里发送了三条数据，顺序依次是data1/data2/data3，压入的是RabbitMQ的一个内存队列。有三个消费者分别从MQ中消费这三条数据中的一条，结果消费者2先执行完操作，把data2存入数据库，然后是data1/data3，这样就乱了。 解决方案​ 拆分多个queue，每个queue一个consumer，就是多一些queue而已；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然胡分发给不同的worker来处理。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis在实践中的一些常见问题与优化思路]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F06%2FRedis%E5%9C%A8%E5%AE%9E%E8%B7%B5%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E4%B8%8E%E4%BC%98%E5%8C%96%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[fork耗时操作导致高并发请求延时​ Redis在开启RDB和AOF持久化机制的时候，会有生成RDB快照，AOF rewrite等耗费磁盘IO的操作，此时主进程会fork子进程去执行。fork的时候，子进程需要拷贝父进程的空间内存页表的，这个也会耗费一定的时间。一般来说，如果父进程内存有1个G的数据，那么fork可能会耗费20ms左右，如果是10G30G，那么就会耗费200600ms，也就是几百毫秒的时间。可以在redis中执行info stats，其中的latest_fork_usec，可以看到最近一次form的时长。 ​ 如果redis单机QPS是几万，fork可能一下子就会拖慢几万条操作的请求时长。 优化思路​ fork耗时跟redis主进程的内存有关系，一般控制redis的内存在10GB以内。 AOF的阻塞问题​ redis将数据写入AOF缓冲区，然后会每秒做一次fsync。但是redis主线程会检查两次fsync的时间，如果距离上次fsync时间超过了2秒，那么写请求就会阻塞。这样可以保证redis最多丢失2秒的数据，但一旦fsync超过2秒的延时，整个redis就会被拖慢。 优化思路​ 优化硬盘写入速度，建议采用SSD，不要用普通的机械硬盘。 主从复制延迟问题​ 主从复制可能会超时严重，这个时候需要良好的监控和报警机制，在redis中执行info replication，可以见到master和slave复制的offset，做一个差值就可以看到对应的延迟量，如果延迟过多，那么久进行报警。 主从复制风暴问题​ 如果一下子让多个slave从master去执行全量复制，一份大的RDB同时发送到多个slave，会导致网络带宽被严重占用。如果一个master需要挂载很多个slave，那么尽量用树状结构，不要用星型结构。 Linux系统内核的优化​ 不同版本的Linux系统设置可能不一样，以下的内容只是提供一个思路，具体命令请根据不同的版本号自行百度。 vm.overcommit_memory​ 执行cat /proc/sys/vm/overcommit_memory，默认情况会返回0。这些数字代表的意义如下： 0：检查有没有足够内存，没有的话申请内存失败 1：允许使用内存直到用完为止 2：内存地址空间不能超过swap + 50% ​ 如果是0的话，可能导致类似fork等操作执行失败，申请不到足够的内存空间。可以将该参数设置为1。可以先后执行echo &quot;vm.overcommit_memory=1&quot; &gt;&gt; /etc/sysctl.conf和sysctl vm.overcommit_memory=1。 swapiness​ 执行cat /proc/version，查看系统内核版本。 ​ 如果Linux内核版本&lt;3.5，那么swapiness设置为0，这样系统宁愿swap也不会oom killer（杀掉进程） ​ 如果Linux内核版本&gt;=3.5，那么swapiness设置为1，这样系统宁愿swap也不会oom killer。 ​ 这样可以保证redis不会被杀掉。 12echo 0 &gt; /proc/sys/vm/swappinessecho vm.swapiness=0 &gt;&gt; /etc/sysctl.conf 最大打开文件句柄​ ulimit -n 10032 10032 tcp backlog​ 开始之前我们先回忆一下TCP建立连接的三次握手： Client发出一个数据包并将SYN置1，表示希望建立连接。这个包中的序列号假设是x。并将状态修改为SYN_SENT。 Server抽到Client发过来的数据包后，通过SYN得知这是一个建立连接的请求。于是发送一个响应包并将SYN和ACK都置1。假设这个包中的序列号是y，而确认序列号必须是x+1，表示收到了A发过来的SYN。并将自己的状态修改为SYN_RCVD，并把该请求放到syns queue队里中。 Client收到Server的响应包后进行确认，确认包中将ACK置1，并将确认序列号设置为y+1，表示收到了B的SYN。此时将状态修改为ESTABLISHED Server收到ACK后，将状态修改为ESTABLISHED，并把该请求从syns queue中放到accept queue。 ​ 在Linux系统内核中维护了两个队列：sync queue和accept queue。 sync queue：用于保存半连接状态的请求，其大小通过/proc/sys/net/ipv4/tcp_max_syn_backlog指定，一般默认值是512，不过这个设置有效的前提是系统的syncookies功能被禁用。互联网常见的TCP SYN FLOOD恶意DOS攻击方式就是建立大量的半连接状态的请求，然后丢弃，导致syns queue不能保存其它正常的请求。 accept queue：用于保存全连接状态的请求，其大小通过/proc/sys/net/core/somaxconn指定，在使用listen函数时，内核会根据传入的backlog参数与系统参数somaxconn，取二者的较小值。 如果accpet queue队列满了，server将发送一个ECONNREFUSED错误信息Connection refused到client。 ​ 这个方案就是调大accept queue的大小，其默认值是128，我们可以将其设置为511. 12cat /proc/sys/net/core/somaxconnecho 511 &gt; /proc/sys/net/core/somaxconn]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从零开始搭建Redis集群]]></title>
    <url>%2FCKING.github.io%2F2019%2F10%2F06%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BARedis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[​ Redis Cluster集群，要求至少3个master去组成一个高可用，健壮的分布式的集群，每个master都建议至少给一个slave，因此，最少要求3个master，3个slave。在正式环境中，建议在6台机器上搭建。也可是3台，但要保证每个master都跟自己的slave不在同一台机器上。 搭建Redis​ 搭建Redis Cluster之前，我们需要先搭建redis。先去官网中下载一个redis，目前稳定版本是redis-5.0.5。下载完后将其上传到Linux系统上，我一般放在/usr/local目录中。 上传完成后，执行tar -zxvf redis-5.0.5.tar.gz解压 执行cd redis-5.0.5/进入redis目录 执行make &amp;&amp; make test &amp;&amp; make install 编译过程中会报一个错误You need tcl 8.5 or newer in order to run the Redis test，说明我们需要安装tcl才能安装redis。执行yum install tcl进行安装 安装好之后再次执行make &amp;&amp; make test &amp;&amp; make install进行编译，需要等待一定的时间。等他编译好之后，有可能会报一个warning，这个可以不用管它。 这样我们就把redis装好了。执行ls查看redis文件夹下的文件 生产环境的redis启动方案​ 在生产环境中，要把redis作为一个系统的daemon进程去执行，每次系统启动，redis进程也一起启动。 在redis_util目录中，有个redis_init_scipt脚本。将这个脚本拷贝到Linux的/etc/init.d目录中，将redis_init_script重命名为redis_6379,6379使我们希望这个redis实例监听的端口号。cp redis_init_script /etc/init.d/redis_6379 修改redis_6379脚本的REDISPORT，设置为6379（默认就是6379）。 创建两个目录：/etc/redis（存放redis的配置文件），/var/redis/6379（存放redis的持久化文件）。 修改redis配置文件，默认在根目录下，拷贝到/etc/redis目录中，修改名称为6379.conf。 修改redis.conf的部分配置： daemonize yes pidfile /var/run/redis_6379.pid # 设置redis的pid文件位置 port 6379 #设置redis的监听端口号 dir /var/redis/6379 #设置持久化文件的存储位置 启动redis 分别执行以下语句 cd /etc/init.d、chmod 777 redis_6379、./redis_6379 start 执行ps -ef | grep redis确认redis进程是否启动。 在redis跟随系统启动自动启动。在redis_6379脚本中的上面，加入两行注释，然后执行chkconfig redis_6379 on。 123# chkconfig: 2345 90 10# description: Redis is a persistent key-value database 搭建Redis Cluster​ 现在开始搭建redis集群。这个案例模拟的是在三台服务器上搭建redis cluster。在搭建redis集群的时候先关闭所有的redis实例。在搭建之前，先了解几个redis cluster的重要配置： cluster-enabled &lt;yes/no&gt; cluster-config-file 这是指定一个文件，供cluster模式下的redis实例将集群状态保存在那里，包括集群中其他机器的信息，比如节点的上线和下线，故障转移。这个不是我们去维护，只是给它指定一个文件，让redis自己去维护。 cluster-node-time 节点存活超时时长，超过一定时长，认为节点宕机，master宕机的话就会触发主备切换，salve宕机就不会提供服务。 开始搭建redis cluster 先在三台服务器上安装redis。我们需要在三个服务器上搭建六个redis实例，端口号分别为7001、7002、7003、7004、7005和7006 先在三个服务器上建两个文件件mkdir -p /etc/redis-cluster 、mkdir -p /var/log/redis，然后在服务器1建立mkdir -p /var/redis/7001和mkdir -p /var/redis/7002文件夹，再在服务器2和服务器3分别建立7003、7004和7005、7006文件夹。 修改redis的配置文件。举一个例子，将上面的6379.conf配置文件复制一份并修改为7001.conf。重点修改一下几个配置： 12345678910port 7001cluster-enabled yescluster-config-file /etc/redis-cluster/node-7001.confcluster-node-timeout 15000daemonize yes pidfile /var/run/redis_7001.pid dir /var/redis/7001 logfile /var/log/redis/7001.logbind 192.168.31.187 appendonly yes 然后再接着生成并修改7002 7003 7004 7005 7006.conf配置文件，并放在相应的服务器中。 准备生产环境的启动脚本。在服务器1中，在/etc/init.d目录下，将redis_6379启动启动脚本复制一份并命名为redis_7001，并修改里面的端口号。同样的生成7002 7003 7004 7005 7006的启动脚本，并放在相应服务器的/etc/init.d目录下。 分别在3台服务器上，启动6个redis实例。 创建集群​ 6个redis实例启动后，就开始创建集群。 随便选中一台服务器，开始安装ruby。执行yum install -y ruby yum install -y rubygems gem install redis。 安装完成后，将redis-5.0.5目录中的src目录下的redis-trib.rb拷贝到/usr/local/bin中。cp /usr/local/redis-3.2.8/src/redis-trib.rb /usr/local/bin 执行redis-trib.rb create --replicas 1 192.168.0.112:7001 192.168.0.112:7002 192.168.0.113:7003 192.168.0.113:7004 192.168.0.114:7005 192.168.0.114:7006。其中上面的IP地址就是你的机器地址。 执行后会报下面的错误，这是因为yum安装的ruby的版本太低的缘故，可以执行ruby -v查看相应的版本。 1234567redis-trib.rb:6: odd number list for Hash white: 29, ^ redis-trib.rb:6: syntax error, unexpected &apos;:&apos;, expecting &apos;&#125;&apos; white: 29, ^ redis-trib.rb:7: syntax error, unexpected &apos;,&apos;, expecting kEND 执行yum remove -y ruby和yum remove -y rubygems 从官网下载最新的ruby压缩包，上传到服务器上 解压tar -zxvf ruby-2.6.5.tar.gz，解压后进入到相应目录中，开始编译。执行./configure 、make 、 make install，并等待一段时间。 执行ruby -v查看是否安装成功。 再次执行 redis-trib.rb create --replicas 1 192.168.0.112:7001 192.168.0.112:7002 192.168.0.113:7003 192.168.0.113:7004 192.168.0.114:7005 192.168.0.114:7006。此时会抱一个WARNING。 12345678910111213141516WARNING: redis-trib.rb is not longer available! You should use redis-cli instead. All commands and features belonging to redis-trib.rb have been moved to redis-cli. In order to use them you should call redis-cli with the --cluster option followed by the subcommand name, arguments and options. Use the following syntax: redis-cli --cluster SUBCOMMAND [ARGUMENTS] [OPTIONS] Example: redis-cli --cluster create 127.0.0.1:30001 127.0.0.1:30002 127.0.0.1:30003 127.0.0.1:30004 127.0.0.1:30005 127.0.0.1:30006 --cluster-replicas 1 To get help about all subcommands, type: redis-cli --cluster help 按照example执行以下命令redis-cli --cluster create 192.168.0.112:7001 192.168.0.112:7002 192.168.0.113:7003 192.168.0.113:7004 192.168.0.114:7005 192.168.0.114:7006 --cluster-replicas 1 这样就创建好集群了，它会帮你指定好谁当master谁当slave。你查看后觉得没问题就输入yes即可。 节点的增加与删除增加master节点 先按照上述操作，新建一个端口号为7007的redis实例，并启动。 在7001服务器上执行redis-cli --cluster add-node 192.168.0.114:7007 192.168.0.112:7001，将新增的7007redis实例增加到redis cluster中。 执行redis-cli --cluster check 192.168.0.114:7007查看redis cluster的情况，可以看到7007实例已经作为master新增到redis cluster中。但这个master只有0个hash slots，所以我们还要给他分配hash slots. 因为16364 / 4 = 4096，因此需要从其他三个master中迁移总共4096个节点到7007上。在任意一台服务器上执行redis-cli --cluster reshard 192.168.0.112 7001。执行后会出现How many slots do you want to move (from 1 to 16384)?，这是询问你要迁移多少slots，我们输入4096。执行后会出现What is the receiving node ID?这是询问你要迁移到哪里去，根据上图可知7007的ID是eb9267b3f16da7317e0f13f7f42fd2f2cf0857a1，输入进行执行。然后会出现Please enter all the source node IDs. Type &#39;all&#39; to use all the nodes as source nodes for the hash slots. Type &#39;done&#39; once you entered all the source nodes IDs.。这是让我们输入数据源的redis的ID，我们输入另外3个master的ID后输入done，之后再输入yes即可。 再次执行redis-cli --cluster check 192.168.0.114:7007查看redis cluster的情况。可以看到此时7007已经有4096个slots了。 增加slave节点 先按照上述操作，新建一个端口号为7008的redis实例，并启动。 执行redis-cli --cluster add-node 192.168.0.114:7008 192.168.0.112:7001 --cluster-slave --cluster-master-id f7b8e55612bce7574deecd57827e3b8203c1c9a6。其中的master-id是7004redis的ID。意思是将7008挂载为7004的slave。 执行redis-cli --cluster 192.168.0.113:7004查看7004的情况，可以看到7008已经是7004的slave了，但之前7001本来是7004的slave，却挂载到本来没有slave的7007master上，称为7007的slave。 删除节点 删除master之前。先用reshard将数据迁移到其他节点，确保node为空后，才能执行remove操作 假设我们要删除7007节点，先执行redis-cli --cluster reshard 192.168.0.112:7001，然后输入1365，将1365个slot迁移到其中一个master中。然后再依次迁移1365和1366个slot到另外两个master中。此时7007零个slots。 执行redis-cli --cluster del-node 192.168.0.112:7001 eb9267b3f16da7317e0f13f7f42fd2f2cf0857a1,，其中那串ID是7007的ID。当你清空了一个master的hashslot时，redis cluster就会自动将其slave挂载到其他master上去，这个时候就只要删除掉master就可以了。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[命令模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F29%2F%E5%91%BD%E4%BB%A4%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ 在软件开发中有很多类似这样的一个场景：一个按钮，它可能是一个“关闭窗口”请求的发送者，而按钮点击事件处理类则是该请求的接收者。为了降低系统的耦合度，将请求的发送者和接收者解耦，可以使用一种被称之为命令模式的设计模式来设计系统。在命令模式中，发送者与接收者之间引入了新的命令对象，将发送者的请求封装在命令模式中，再通过命令对象来调用接收者的方法。 ​ 在软件开发中，经常需要向某些对象发送请求（调用其中的某个或某些方法），但是并不知道请求的接收者是谁，也不知道被请求的操作是哪个，此时，希望能以一种松耦合的方式来设计软件，使得请求发送者与请求接收者能够消除彼此之间的耦合，让对象之间的调用关系更加灵活。 ​ 命令模式可以将请求发送者和接收者完全解耦，发送者与接收者之间没有直接引用关系，发送请求的对象只需要知道如何发送请求，而不必知道如何完成请求。 命令模式定义​ 将一个请求封装为一个对象，从而可用不同的请求对客户进行参数化；对请求排队或者记录日志，以及支持可撤销的操作。命令模式是一种对象行为型模式，又称为动作模式或事物模式。 命令模式结构图​ 命令模式的核心在于引入了命令类，通过命令类来降低发送者和接收者的耦合度，请求发送者只需要指定一个命令对象，再通过命令对象来调动请求接收者的处理方法，其结果如下： ​ 由上图可知命令模式包含以下四个角色： Command（抽象命令类）：抽象命令类一般是一个抽象类或接口，在其中声明了用于执行请求execute()等方法，通过这些方法可以调用请求接收者的相关操作。 ConcreteCommand（具体命令类）：具体命令类是抽象命令类的子类，实现了在抽象命令类中声明的方法，它对应具体的接收者对象，将接收者对象的动作绑定在其中。在实现execute()方法时，将调用接收者对象的相关操作（Action）. Invoker（调用者）：调用者即请求发送者，它通过命令对象来执行请求。一个调用者并不需要在设计时确定其接收者，因此它只与抽象命令类之间存在关联关系。在程序运行时可以将一个具体命令对象注入其中，再调用具体命令对象的execute()方法，从而实现间接调用请求接收者的相关操作。 Receiver（接收者）：接收者执行与请求相关的操作，它具体实现对请求的业务处理。 具体案例​ 某公司开发人员为公司内部OA系统开发了一个桌面版应用程序，该应用程序为客户提供了一系列自定义功能键，用户可以通过这些功能键来实现一些快捷操作。产品人员通过分析，发现不同的用户可能有不同的使用习惯，在设置功能键的时候每个人都有自己的喜好，例如有人喜欢将第一个功能键设置为“打开帮助文档”，有的人则喜欢将该功能键设置为“最小化至托盘”。为了让用户能够灵活地进行功能键的设置,开发人员提供了一个“功能键设置”窗口,如图所示： ​ 通过这个窗口界面，用户可以将功能键和相应功能绑定在一起，还可以根据需要来修改功能键的设置，而且系统未来还可能增加一些新的功能或功能键。 ​ 该软件使用命令模式设计，结构图如下所示： ​ 相关代码已上传到github上。 命令队列的实现​ 有时候需要将多个请求排队，当一个请求发送者发送一个请求时，不止一个请求接收者产生响应，这些请求接收者将逐个执行业务方法，完成对请求的处理。此时，可以通过命令队列来实现。 ​ 命令队列的实现方法有多种形式，其中最常用、灵活性最好的一种方式是增加一个CommandQueue类，由该类来负责存储多个命令对象，而不同的命令对象可以对应不同的请求接收者。CommandQueue类的典型代码如下： 123456789101112131415161718192021222324package com.command;import java.util.ArrayList;public class CommandQueue &#123; //定义一个ArrayList来存储命令队列 private ArrayList&lt;Command&gt; commands = new ArrayList&lt;Command&gt;(); public void addCommand(Command command) &#123; commands.add(command); &#125; public void removeCommand(Command command) &#123; commands.remove(command); &#125; //循环调用每一个命令对象的execute()方法 public void execute() &#123; commands.stream().forEach(command -&gt; &#123; command.execute(); &#125;); &#125;&#125; ​ 在增加了命令队列类CommandQueue以后，请求发送者类Invoker将针对CommandQueue编程，代码如下： 123456789101112131415161718192021package com.command;public class Invoker &#123; //维持一个CommandQueue对象的引用 private CommandQueue commandQueue; public Invoker(CommandQueue commandQueue) &#123; this.commandQueue = commandQueue; &#125; //设值注入 public void setCommandQueue(CommandQueue commandQueue) &#123; this.commandQueue = commandQueue; &#125; //调用CommandQueue类的execute()方法 public void call() &#123; commandQueue.execute(); &#125;&#125; ​ 命令队列与批处理有点类似。批处理，意思就是可以对一组对象（命令）进行批量处理，当一个发送者发送请求后，将有一系列接收者对请求作出相应，命令对象可以用于设计批处理应用程序，如果请求接收者的接受次序没有严格的先后次序，还可以使用多线程技术来并发调用命令对象的execute()方法，从而提高程序的执行效率。 撤掉操作的实现​ 在命令模式中，可以通过调用一个命令对象的execute()方法来实现对请求的处理，如果需要撤销请求，可以通过在命令类中增加一个逆向操作来实现。此外，还可以通过保存对象的历史状态来实现撤销。 案例​ 某公司欲开发一个简易计算器，该计算器可以实现简单的数学运算，还可以对运算实施撤销操作和恢复操作。 ​ 本例完整代码已上传到github上 请求日志​ 请求日志就是将请求的历史记录保存下来，通常以日志文件的形式永久存储在计算机系统中。在实现请求日志时，可以将命令对象通过序列化写到日志文件中，此时命令类必须实现java.io.Serializable接口。 案例​ 某公司开发了一个网站配置文件管理工具，可以通过一个可视化界面对网站配置文件进行增删改等操作，该工具使用命令模式进行设计，结构如下所示。现在改公司开发人员希望对配置文件的操作请求记录在日志文件中，如果网站重新部署，主需要执行保存在日志文件中的命令对象即可修改配置文件。 ​ 该案例的相关代码已上传到github上。 命令模式主要优缺点主要优点 降低系统的耦合度。由于请求者与接收者之间不存在直接引用，因此请求者与接收者之间实现完全解耦，相同的请求者可以对应不同的接收者，同样，相同的接收者也可以供不同的请求者使用，两者之间具有良好的独立性。 新的命令可以很容易地加入到系统中。由于增加新的具体命令类不会影响到其他类，因此增加新的具体命令类很容易，无须修改原有系统源代码甚至客户类代码，满足开闭原则。 可以比较容易地设计一个命令队列或宏命令。 为请求的撤销和恢复操作提供了一种设计和实现方案。 主要缺点​ 主要缺点是：使用命令模式可能会导致某些系统有过多的具体命令类。因为针对每一个请求接收者的调用操作都需要设计一个具体命令类，因此在某些系统中可能需要提供大量的具体命令类，这将影响命令模式的使用。 命令模式使用场景 系统需要将请求调用者和请求接收者解耦，使得调用者和接收者不直接交互。请求调用者无须知道接收者的存在，也无须知道接收者是谁，接收者也无须关心何时被调用。 系统需要在不同的时间指定请求、将请求排队和执行请求。一个命令对象和请求的初始调用者可以有不同的生命期。即，最初的请求发出者可能已经不在了，而命令对象本身仍然是活动的，可以通过该命令对象去调用请求接收者，而无须关系请求调用者的存在性，可以通过请求日志文件等机制来具体实现。 系统需要支持命令的撤销操作和恢复操作。 系统需要将一组操作组合在一起形成宏命令。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[策略模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F25%2F%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ 在软件开发中，常常会遇到这种情况：实现某个功能有多条途径，每一条途径对应一种算法，此时可以使用一种设计模式来实现灵活地选择解决途径，也能够方便地增加新的解决途径。那就是策略模式。 ​ 在策略模式中，可以定义一些独立的类来封装不同的算法，每一个类封装一种具体的算法。在这里，每一个封装算法的类都可以称之为一种策略，为了保证这些策略在使用时具有一致性，一般会提供一个抽象的策略来做规则的定义，而每种算法则对应一个具体策略类。 ​ 策略模式的主要目的是将算法的定义与使用分开，也就是将算法的行为和环境分开，将算法的定义放在专门的策略类中，每一个策略类封装了一种实现算法，使用算法的环境类针对抽象策略类进行编程，符合依赖倒转原则。在出现新的算法时，只需要增加一个新的实现了抽象策略类的具体策略类即可。 策略模式定义​ 定义了一系列算法类，将每一个算法封装起来，并让他们可以互相替换。策略模式让算法独立于使用它的客户而变化，也称为政策模式。策略模式是一种对象行为型模式。 策略模式结构图 ​ 由结构图可以看到包含以下3个角色： Context（环境类）：环境类是使用算法的角色，它在解决某个问题（即实现某个方法）时可以采用多种策略。在环境类中维持一个对抽象策略类的引用实例，用于定义所采用的策略。 Strategy（抽象类）：它为所支持的算法声明了抽象方法，是所有策略类的父类，它可以是抽象类或具体类，也可以是接口。环境类通过抽象策略中声明的方法在运行时调用具体策略类中实现的算法。 ConcreteStrategy（具体策略类）：它实现了在抽象策略类中声明的算法，在运行时，具体策略类将覆盖在环境类中定义的抽象策略类对象，使用一种具体的算法实现某个业务处理。 策略模式主要优缺点主要优点 策略模式提供了对开闭原则的完美支持，用户可以在不修改原有系统的基础上选择算法或行为，也可以灵活地增加新的算法或行为。 策略模式提供了管理相关的算法族的办法，策略类的等级结构定义了一个算法或行为族，恰当使用继承可以把公共的代码移到抽象策略类中，从而避免重复的代码。 策略模式提供了一种可以替换继承关系的办法。如果不使用策略模式，那么使用算法的环境类就可能会有一些子类，每个子类提供一种不同的算法。但是，这样一来算法的使用就和算法本身混在一起，不符合单一职责原则，决定使用哪一种算法的逻辑和该算法本身混合在一起，从而不可能再独立演化；而且使用继承无法实现算法或行为在程序运行时的动态切换。 使用策略模式可以避免多重条件选择语句。多重条件选择语句不易维护，它把采取哪一种算法或行为的逻辑与算法或行为本身的实现逻辑混合在一起，将他们全部硬编码在一个庞大的多重条件选择语句中，比直接集成环境类的办法还要原始和落后。 策略模式提供了一种算法的复用机制，由于将算法单独提取出来封装在策略类中，因此不同的环境类可以方便地复用这些策略类。 主要缺点 客户端必须知道所有的策略类，并且自行决定使用哪一个策略类。这就意味着客户端必要理解这些算法的区别，以便实时选择恰当的算法。换言之，策略模式只适用于客户端知道所有的算法或行为的情况。 策略模式将造成系统产生很多具体策略类，任何细小的变化都将导致系统要增加一个新的具体策略类。 无法同时在客户端使用多个策略类，也就是说，在使用策略模式时，客户端每次只能使用一个策略类，不支持使用一个策略类完成部分功能后再使用另一个策略类来完成剩余功能的情况。 策略模式适用场景​ 在以下情况下可以考虑使用策略模式： 一个系统需要动态地在几种算法中选择一种，那么可以将这些算法封装到一个个的具体算法类中，而这些算法类都是一个抽象算法类的子类。换言之，这些具体算法类均有统一的接口，根据里氏代换原则和面向对象的多态性，客户端可以选择使用任何一个具体算法类，并且只要维持一个数据类型是抽象算法类的对象。 一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重条件选择语句来实现。此时，使用策略模式，把这些行为转移到相应的具体策略类里面，就可以避免使用难以维护的多重条件选择语句。 不希望客户端知道复制的、与算法相关的数据结构，在具体策略类中封装算法与相关的数据结构，可以提高算法的保密性与安全性。 具体事例案例1​ Sunny软件公司为某电影院开发了一套影院售票系统，在改系统中需要为不同类型的用户提供不同的电影票打折方式，具体打折方案如下： 学生凭学生证可以享受8折优惠。 年龄在10周岁及以下的儿童可享受每张票减免10元的优惠（原始票价需大于等于20元） 影院VIP用户除享受票价半价优惠外还可以积累积分，积分累计到一定额度可以兑换电影院赠送的奖品。 ​ 改系统在将来可能还需要个根据需要引入新的打折方式。 传统的实现方案大概会如下： 123456789101112131415161718192021222324public double calculate() &#123; //学生票折后票价计算 if(this.type.equalsIgnoreCase("student")) &#123; System.out.println("学生票： "); return this.price * 0.8; &#125; //儿童票折后票价计算 else if(this.type.equalsIgnoreCase("children") &amp;&amp; this.price &gt;= 20) &#123; System.out.println("儿童票："); return this.price - 10; &#125; //VIP票折价后票价计算 else if(this.type.equalsIgnoreCase("vip")) &#123; System.out.println("VIP票："); System.out.println("增加积分！"); return this.price * 0.5; &#125; else &#123; return this.price; &#125; &#125; ​ 使用策略模式实现的代码已上传至github上。 案例2​ 使用策略模式和自定义注解去掉大量的if-else https://mp.weixin.qq.com/s/sa_MMAzYg6jpy9s_rtvcCQ]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产环境中redis的数据备份和灾难恢复策略]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F22%2F%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E4%B8%ADredis%E7%9A%84%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E5%92%8C%E7%81%BE%E9%9A%BE%E6%81%A2%E5%A4%8D%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[本节思维导图 ![生产环境中的数据 备份和灾难恢复](生产环境中redis的数据备份和灾难恢复策略/生产环境中的数据 备份和灾难恢复.png) ​ 我们生产环境中redis的数据备份和灾难恢复策略简单地说就是：开启AOF机制，并用RDB做冷备。 数据备份方案​ 具体的数据备份方案如下： 写crontab定时调度脚本去做数据备份。 每小时都备份一份rdb，可以copy到一个目录中去，并且只保留最近48小时的备份。 每天都保留一份当日的rdb备份到一个目录中去，仅仅保留最近一个月的备份。 每次copy备份的时候，把最旧的备份删掉。 每天晚上将当前服务器上所有的数据备份，发送一份到远程的云服务上去。 ​ 首先先创建一个目录，/usr/local/redis，然后在redis的目录中创建copy文件夹，用来存储复制快照文件的脚本。然后在redis目录中创建snapshotting文件夹，用来存储备份的rdb快照。 ​ 执行vi redis_rdb_copy_hourly.sh，编写每小时复制一份rdb的shell脚本。 123456789#!/bin/sh cur_date=`date +%Y%m%d%k`rm -rf /usr/local/redis/snapshotting/$cur_datemkdir /usr/local/redis/snapshotting/$cur_datecp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_datedel_date=`date -d -48hour +%Y%m%d%k`rm -rf /usr/local/redis/snapshotting/$del_date ​ 执行vi redis_rdb_copy_daily.sh，编写每天复制一份rdb的shell脚本。 123456789#!/bin/sh cur_date=`date +%Y%m%d`rm -rf /usr/local/redis/snapshotting/$cur_datemkdir /usr/local/redis/snapshotting/$cur_datecp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_datedel_date=`date -d -1month +%Y%m%d`rm -rf /usr/local/redis/snapshotting/$del_date ​ 上面cp /var/redis/6379/dump.rdb /usr/local/redis/snapshotting/$cur_date中的/var/redis/6379/dump.rdb是redis生成的快照文件的存储地址，可以根据具体情况进行修改。 ​ 最后再执行crontab -e新建调度任务，命令如下： 120 * * * * sh /usr/local/redis/copy/redis_rdb_copy_hourly.sh0 0 * * * sh /usr/local/redis/copy/redis_rdb_copy_daily.sh ​ 然后再每天一次将所有的数据上传一次到远程的云服务器上去，这样一个数据备份方案就算完成了。 数据恢复方案 如果是redis进程挂掉了，那么重启redis进程即可，直接基于AOF日志文件恢复数据。 如果是redis进程所在机器宕机了，那么重启机器后，尝试重启redis进程，尝试直接基于AOF日志文件进行数据恢复。如果AOF没有破损，那么久直接基于AOF恢复，如果AOF文件损坏，那么用redis-check-aof fix修复日志文件。 如果redis当前最新的AOF文件和RDB文件出现了丢失，那么可以尝试基于该机器上当前的某个最新的RDB数据副本进行数据恢复。具体操作步骤为：停掉redis，关闭AOF，拷贝AOF备份，重启redis，确认数据恢复，直接在命令行热修改redis配置，即在redis-cli中执行config set appendonly yes打开AOF。这个时候redis就会将内存中的数据对应的日志，写入AOF文件中，此时AOF和RDB两份数据文件的数据就同步了。用redis config set热修改配置参数，可能配置文件中的实际参数没有被持久化的修改，需要再停止redis，手动修改配置文件，打开AOF，然后再重启redis。 如果当前机器上的所有RDB文件全部损坏，那么从远程的云服务上拉取最新的RDB快照来恢复数据。 如果是发现有重大的数据错误，比如某个小时上线的程序一下子将数据全部污染了，数据全错了，那么可以选择某个更早的时间点，对数据进行恢复 举个例子，12点上线了代码，发现代码有bug，导致代码生成的所有的缓存数据，写入redis，全部错了 找到一份11点的rdb的冷备，然后按照上面的步骤，去恢复到11点的数据，就可以了。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM中的一些参数介绍]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F16%2FJVM%E4%B8%AD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%82%E6%95%B0%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[JVM配置常用参数堆参数 参数 描述 -Xms 设置JVM启动时堆内存的初始化大小 -Xmx 设置堆内存最大值 -Xmn 设置年轻代的空间大小，剩下的为老年代的空间大小 -XX:PermGen 设置永久代内存的初始化大小（JDK1.8开始废弃了永久代） -XX:MaxPermGen 设置永久代的最大值 -XX:SurvivorRatio 设置Eden区和Survivor区的空间比例：Eden/S0 = Eden/S1 默认为8 -XX:NewRatio 设置老年代与年轻代的比例大小，默认值为2 回收器参数 参数 描述 -XX:+UseSerialGC 串行，Young区和Old区都使用串行，使用复制算法回收，逻辑简单高效，无线程切换开销 -XX:+UseParallelGC 并行，Young区：使用Parallel scavenge回收算法，会产生多个线程并行回收。通过-XX:ParallelGCThreads=n参数指定有线程数，默认是CPU核数；Old区：单线程 -XX:+UseParallelOldGC 并行，和UseParallelGCC一样，Young区和Old区的垃圾回收时都使用多线程手机 -XX:+UseConcMarkSweepGC 并发，短暂停顿的并发收集。Young区：可以使用普通的或者parallel垃圾回收算法，由参数 -XX:+UseParNewGC来控制；Old区：只能使用Concurrent Mark Sweep -XX:+UseG1GC 并行的、并发的和增量式压缩短暂停顿的垃圾收集器。不区分Young区和Old区空间。它把堆空间划分为多个大小相等的区域。当进行垃圾收集时，它会优先收集存活对象较少的区域，因此叫“Garbage First” ​ 如上表所示，目前主要有串行、并行和并发三种。对于大内存的应用而言，串行的性能太低，因此使用到的主要是并行和并发两种。并行和并发GC的策略通过UseParallelGCC和UseCon从MarkSweepGC来指定，还有一些细节的配置参数用来配置策略的执行。例如：XX:ParallelGCThreads、XX:CMSInitiatingOccupancyFraction等。通常：Young区对象回收只可选择并行（耗时间），Old区选择并发（耗CPU）。 项目中常用配置 参数设置 描述 -Xms4800m 初始化堆空间大小 -Xmx4800m 最大堆空间大小 -Xmn1800m 年轻代的空间大小 -Xss512k 设置线程栈空间大小 -XX:PermSize=256m 永久区空间大小（jdk1.8开始废弃了永久代） -XX:MaxPermSize=256m 最大永久区空间大小 -XX:+UseStringCache 默认开启，启用缓存常用的字符串 -XX:+UseConcMarkSewwpGC 老年代使用CMS收集器 -XX:UseParNewGC 新生代使用并行收集器 -XX:ParallelGCThreads=4 并行线程数量4 -XX:+CMSClassUnloadingEnabled 允许对类的元数据进行清理 XX:+DisableExplicitGC 禁止显示的GC -XX:+UseCMSInitiatingOccupancyOnly 表示只有达到阈值之后才进行CMS回收 -XX:CMSInitiatingOccupancyFraction=68 设置CMS在老年代回收的阈值为68% -verbose:gc 输出虚拟机GC详情 -XX:+PrintGCDetails 打印GC详情日志 -XX:+PrintGCDataStamps 打印GC的耗时 -XX:+PrintTenuringDistribution 打印Tenuring年龄信息 -XX:+HeapDumpOnOutOfMemoryError 当抛出OOM时进行HeapDump -XX:HeapDumpPath=/home/admin/logs 指定HeapDump的文件路径或目录 常用组合 Young Old JVM Options Serial Serial -XX:+UseSerialGC Parallel scavenge Parallel Old/Serial -XX:+UseParallelGC-XX:+UseParallelOldGC Serial/Parallel scavenge CMS -XX:+UseParNewGC-XX:+UseConcMarkSweepGC G1 -XX:+UseG1GC 常用GC调优策略GC调优原则​ 在调优之前，我们需要记住下面的原则： 多数的Java应用不需要在服务器上进行GC优化。 多数导致GC问题的Java应用，都不是因为我们参数设置错误，而是代码问题。 在应用上线之前，先考虑将机器的JVM参数设置到最优（最适合）。 减少创建对象的数量。 减少使用全局变量和大对象。 GC优化是到最后不得已才 采用的手段。 在实际使用中，分析GC情况优化代码比优化GC参数要多得多。 GC调优目的 将转移到老年代的对象数量降低到最小。 减少GC的执行时间 GC调优策略 策略1：将新对象预留在新生代，由于Full GC的成本远高于Minor GC，因此尽可能将对象分配在新生代是明智的做法，实际项目中根据GC日志分析新生代空间大小分配是否合理，适当通过“-Xmn”命令调节新生代大小，最低限度降低新对象直接进入老年代的情况。 策略2：大对象进入老年代，虽然在大部分情况下，将对象分配在新生代是合理的。但是对于大对象这种做法却值得商榷，大对象如果首次在新生代分配可能会出现空间不足导致很多年龄不够的小对象被分配到老年代，破坏新生代的对象结构，可能会出现频繁的full gc。因此，对于大对象，可以设置直接进入老年代（当然短命的大对象对于垃圾回收来说就是噩梦）。-XX:PretenureSizeThreshold可以设置直接进入老年代的对象大小。 策略3：合理设置进入老年代对象的年龄，-XX:MaxTenuingThreshold设置对象进入老年代的年龄大小，减少老年代的内存占用，降低full GC发送的频率。 策略4：设置稳定的堆大小，堆打下设置有两个参数：-Xms初始化堆大小，-Xms最大堆大小。 策略5：如果满足下面的指标，则一般不需要进行GC优化： MinorGC执行时间不到50ms MinorGC执行不频繁，约10秒一次 Full GC执行时间不到1s Full GC执行频率不算频繁，不低于10分钟1次。 参考资料Java应用如何调优]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单讲一下分库分表]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F10%2F%E7%AE%80%E5%8D%95%E8%AE%B2%E4%B8%80%E4%B8%8B%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[分库分表​ 分库分表是两回事，可能是光分库不分表，也可能是光分表不分库，都有可能。 分表​ 如果你单表都几千万数据了，单表数据量太大，会极大影响你的Sql执行的性能，到了后面sql可能就跑的很慢了。一般来说，单表到了几百万的时候，性能就会相对差一些，你就得分表了。 ​ 分表，就是把一个表的数据放到多个表中，然后查询的时候你就查一个表。比如按照用户ID来分表，将一个用户的数据就放在一个表中。然后操作的时候你对一个用户就操作那个表就可以了。这样可以控制每个表的数据量在可控的方范围内，比如每个表就固定在200万以内。 分库​ 分库，就是一般而言我们一个库，最多支撑到2000并发，就一定要扩容了，而且一个健康的单库并发值最好保持在每秒1000左右，不要太大。可以将一个库的数据拆分到多个库中，访问的时候就访问一个库好了。 分库分表前 分库分表后 并发支撑情况 MySQL单机部署，扛不住高并发 MySQL从单机到多机，能承受的并发增加了多倍 磁盘使用情况 MySQL单机磁盘容量几乎撑满 拆分为多个库，数据库服务器磁盘使用率大大降低 SQL执行性能 单表数据量太大，SQL越跑越慢 单表数据库量减少，SQL执行效率明显提升 分库分表的中间件​ 比较常见的分库分表的中间件包括： Cobar TDDL Atlas Sharding-jdbc Mycat ​ 目前市场上比较主流的就是sharding-jdbc和Mycat，这两个都可以考虑去使用。Sharding-jdbc这种属于Client层方案，优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合Sharding-jdbc的依赖。Mycat属于proxy层方案，缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间间那里处理即可。 ​ 通常来说，这两个方案其实都可以选用，但是大佬建议中小型公司选用 Sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 Mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 Mycat，然后大量项目直接透明使用即可。 如何对数据库进行水平拆分和垂直拆分水平拆分​ 水平拆分，就是把一个表的数据弄个多个库的多个表里去，但是每个库的表结构都一样，只不过每个库表放的数据是不同的，所有库表的数据加起来就是全部数据。水平拆分的意义，就是将数据均匀放更多的表里，然后用多个库来抗更高的并发，还有就是用多个库的存储容量来进行扩容。 垂直拆分​ 垂直拆分，就是把一个有很多字段的表给拆分成多个表，或者是多个库上去。每个库表的结构都不一样，每个库表都包含部分字段。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另一个表里去。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越好。这个一般在表层面做的较多一些。 ​ 还有表层面的拆分，就是分表，将一个表变成N个表，就是让每个表的数据量控制在一定范围内，保证SQL的性能。否则单表的数据量越大，SQL性能就越差。 ​ 无论分库还是分表，上面说的那些数据库中间件都是可以支持的。就是基本上那些中间件可以做到你分库分表之后，中间件可以根据你指定的某个字段值，比如说 userid，自动路由到对应的库上去，然后再自动路由到对应的表里去。 ​ 你就得考虑一下，你的项目里该如何分库分表？一般来说，垂直拆分，你可以在表层面来做，对一些字段特别多的表做一下拆分；水平拆分，你可以说是并发承载不了，或者是数据量太大，容量承载不了，你给拆了，按什么字段来拆，你自己想好；分表，你考虑一下，你如果哪怕是拆到每个库里去，并发和容量都 ok 了，但是每个库的表还是太大了，那么你就分表，将这个表分开，保证每个表的数据量并不是很大。 ​ 有两种分库分表的方式： 按照range来分，就是每个库一段连续的数据，这个一般是按照，例如时间范围来的。但是这种一般较少使用，因为很容易产生热点问题，大量的流量都打在最新的数据上了 按照某个子段hash一下均匀分散，这个较为常用。 ​ range来分，好处在于说，扩容的时候很简单，因为你只要预备好，给每个月都准备一个库就可以了，到了一个新的月份的时候，自然而然，就会写新的库了；缺点，但是大部分的请求，都是访问最新的数据。实际生产用 range，要看场景。 ​ hash 分发，好处在于说，可以平均分配每个库的数据量和请求压力；坏处在于说扩容起来比较麻烦，会有一个数据迁移的过程，之前的数据需要重新计算 hash 值重新分配到不同的库或表。]]></content>
      <categories>
        <category>分布式</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[保证缓存与数据库双写的一致性]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F08%2F%E4%BF%9D%E8%AF%81%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%2F</url>
    <content type="text"><![CDATA[本节思维导图 Cache Aside Pattern​ 最经典的缓存+ 数据库读写的模式，就是这个Cache Aside Pattern 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回请求。 更新的时候，先更新数据库，然后再删除缓存。 ​ 至于为什么是删除缓存，而不是更新缓存。原因在于在复杂的缓存场景，缓存不单单是数据库中直接拉取出来的值。比如更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据进行运算，才能计算出缓存最新的值的。 ​ 而且更新缓存的代价有时候是很高的。对于复杂的缓存数据计算场景，如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新，但这个数据有可能只需要被访问一次呢？例如一个缓存涉及的表的字段，在一分钟内就修改了一百次，而缓存也更新了一百次，但是这个缓存在一分钟内只被读取一次，有大量的冷数据。如果只是删除缓存的话，那么在1分钟内，这个缓存也就重新计算一次，大幅度降低开销。用到缓存才去算缓存。 最初级的缓存不一致问题及解决方案​ 如果先更新数据库，在删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据就出现了不一致。 解决思路​ 先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存是空的，那么数据不会不一致。因为读的时候缓存没有了，所以读了数据库中的旧数据，然后更新到缓存中。 高并发场景下数据不一致问题分析​ 数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改，一个请求过来，先去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据库的修改。这样就会发生数据库与缓存的数据不一致了。 什么场景下会发生上述情况​ 只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。如果并发量很低的话，特别是读并发很低，每天访问量就一万，那么很少的情况才会出现上述情况。如果每天是上亿的流量，每秒并发读是几万，每秒只要有数据更新的情况，就可坑出现上述的数据库和缓存不一致的情况。 解决方案​ 更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个jvm内部队列中。读取数据的时候，如果发现数据不在缓存中，那么将重新读取数据 + 更新缓存的操作，根据唯一标识路由之后，也发到同一个jvm内部队列中。 ​ 一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样一个数据变更的操作，先删除缓存，然后再去更新数据库，但是还没有完成更新。此时如果一个读请求过来，没有读到缓存，可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存更新完成。 ​ 这里有一个可以优化的地方。一个队列中，多个更新缓存请求串在一起是没意义的。可以做过滤，如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新缓存的请求操作进去，直接等前面的更新操作请求完成即可。 ​ 等那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓存更新的操作，此时会从数据库读取最新的值，然后写入缓存中。 ​ 如果请求还在等待时间范围内，不断轮询，发现可以取到值了，那么久直接返回；如果请求等待的时间超过一定时长，那么这一次直接从数据库中读取当前的旧值。 存在的问题 读请求长时阻塞 由于读请求进行了非常轻度的异步化，所以要注意读超时的问题，每个读请求必须在超时时间范围内返回。 ​ 解决方案，或者最大的风险点在于可能数据更新很频繁。导致队列中积压了大量更新操作在里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库。因此务必通过一些模拟真实的测试，看看数据更新的频率是怎样的。 ​ 另外，因为一个队列中，可能会积压对多个数据项的更新操作，因此需要根据自己的业务情况进行测试，可能需要部署多个服务。每个服务分摊一些数据的更新操作。如果一个内存队列路积压100个商品的库存修改操作，每个库存修改操作需要耗费10ms去完成，那么最后一个商品的读请求，可能等待10 * 100ms = 1s，才能得到数据，这个时候就导致读请求的长时阻塞。 读请求并发量过大 ​ 这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在几十毫秒的延时hang在服务上，看服务能不能抗的住，需要多少机器才能抗住最大的极限情况的峰值。 ​ 但是因为不是所有的数据都在同一时间更新，缓存也不会再同一时间失效，所以每次可能也就是少数数据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。 多服务实例部署的请求路由 ​ 可能这个服务部署了多个实例，那么必须保证，执行数据更新操作，以及执行缓存更新操作的请求，都通过Nginx服务器路由到相同的服务实例上。 ​ 例如对同一个商品的读写请求，全部路由到同一台服务器上。可以自己去做服务间的按照某个请求参数的hash路由，也可以用Nginx的hash路由功能等。 热点商品的路由问题，导致请求的倾斜 ​ 如果某个商品的读写请求特别高，全部打到相同机器相同的队列里，可能会造成某台机器的压力过大。就是说，因为只有在商品更新的时候才会清空缓存，然后才会导致读写并发。所以其实要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响不是特别大，但是的确可能某些机器的负载会高一些。 总结​ 一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说系统不是严格要求“缓存 + 数据库”必须保持一致性的话，最好不要做“读请求和写请求串行化”，串到一个内存队列里去。 ​ 串行化可以保证一定不会出现不一致的情况，但是它会导致系统的吞吐量大幅度降低。]]></content>
      <categories>
        <category>分布式</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis集群]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F04%2FRedis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[本节思维导图 ![Redis Cluster](Redis集群/Redis Cluster.png) ​ Redis cluster，主要是针对海量数据 + 高并发 + 高可用的场景。Redis cluster支撑N个redis master node，每个master node都可以挂载多个slave node。这样整个redis就可以横向扩容了。如果要支撑更大数据量的缓存，那就横向扩容更多的master节点。 Redis cluster介绍 自动将数据进行分片，每个master上放一部分数据 提供内置的高可用支持，部分master不可用时，还是可以继续工作的 ​ 在redis cluster架构下，每个redis要开放两个端口号，比如一个是6379，另一个就是加1W的端口号，比如16379. ​ 16379端口号是用来进行节点间通信的，也就是cluster bus的东西。cluster bus的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus使用一种二进制的协议，gossip协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。 节点间的内部通信机制基本通信原理​ 集群元数据的维护有两种方式：集中式。Gossip协议。redis cluster节点间采用gossip协议进行通信。 ​ 集中式是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的storm。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于ZooKeeper（分布式协调的中间件）对所有元数据进行存储维护。 ​ redis维护集群元数据采用另一个方式，gossip协议，所有节点都持有一份元数据，不同节点如果出现了元数据的变更，就不断将元数据发送给其他的节点，让其他节点也进行元数据的并更。 ​ 集中式的好处在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其他节点读取的时候就可以感知到；不好在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。 ​ gossip好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆续打到所有节点上去更新，降低了压力；缺点是元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。 1000端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+ 10000。每个节点每隔一段时间都会往另外几个节点发送ping消息，同时其他几个节点接收到ping之后返回pong。 交换的信息：信息包括故障信息，节点的增加和删除，hash slot信息等等。 gossip协议​ gossip协议包含多种消息，包含ping、pong、meet、fail等等。 meet：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信。 1redis-trib.rb add-node 其实内部就是发送了一个gossip meet消息给新加入的节点，通知那个节点去加入我们的集群。 ping：每个节点都会频繁给其它节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据。 pong：返回ping和meet，包含自己的状态和其它信息，也用于消息广播和更新。 fail：某个节点判断另一个节点fail之后，就发送fail给其它节点，通知其它节点某个节点宕机了。 ping消息深入​ ping时要携带一些元数据，如果很频繁，可能会加重网络负担。 ​ 每个节点每秒会执行10次ping，每次会选择5个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了cluster_node_timeout / 2，那么立即发送ping，避免数据交换延时过长，落后的时间过长。例如，两个节点之间都10分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以cluster_node_timeout可以调节，如果调的比较大，那么会降低ping的频率。 ​ 每次ping，都会带上自己节点的信息，还有就是带上1/10其它节点的信息，发送出去，进行交换。至少包含3个其它节点的信息，最多包含总结点减2个其它节点的信息。 分布式寻址算法 hash算法 一致性hash算法（自动缓存迁移） + 虚拟节点（自动负载均衡） redis cluster的hash slot算法 hash算法​ 来了一个key，首先计算hash值，然后对节点数取模。然后打在不同的master节点上，一旦某一个master节点宕机，所有请求过来，都会基于最新的master节点数去取模，尝试去取数据。这会导致大部分的请求过来，全部无法拿到有效的缓存，导致大量的流量涌入数据库。 一致性hash算法​ 一致性hash算法将整个hash值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织。下一步将各个master节点（使用服务器的ip或主机名）进行hash。这样就能确定每个节点在其哈希环上的位置。 ​ 来了一个key，首先计算hash值，并确定此数据在环上的位置，从此位置沿环顺时针“行走”，遇到的第一个master节点就是可以所在位置。 ​ 在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其他不收影响，增加一个节点也同理。 ​ 但是如果一致性哈希算法在节点太少是，容易因为节点分布不均匀而造成缓存热点的问题。为了解决这种热点问题，一致性hash算法引入了虚拟节点机制，即对每一个节点计算多个hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。 redis cluster的hash slot算法​ redis cluster有固定的16384个hash slot，对每个key计算CRC16值，然后对16384取模，可以获取key对应的hash slot。 ​ redis cluster中每个master都会持有部分slot，比如有3个master，那么可能每个master持有5000多个hash slot。hash slot让node的增加和移除都很简单，增加一个master，就将其他master的hash slot移动部分过去，减少一个master，就将它的hash slot移动到其他master上去。移动hash slot的成本是非常低的。客户端的API，可以对指定的数据，让他们走同一个hash slot，同时hash tag来实现。 ​ 任何一台机器宕机，redis的寻址都不受影响。因为key找的是hash slot，不是机器。 ![hash slot](Redis集群/hash slot.png) Redis Cluster的高可用与主备切换原理​ redis cluster的高可用的原理，几乎跟哨兵是类似的。 判断节点宕机​ 如果一个节点认为另一个节点宕机，那么就是pfail，主观宕机。如果多个节点都认为一个节点宕机了，那么就是fail，客观宕机，跟哨兵的原理几乎一样，sdown，odown。 ​ 在cluster-node-timeout内，某个节点一直没有返回pong，那么就会认为fail。 ​ 如果一个节点认为某个节点fail，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，那么就会变成fail. 从节点过滤​ 对宕机的master node，从其所有的slave node中，选择一个切换成master node。 ​ 检查每个slave node与master node断开连接的时间，如果超过了cluster-node-timeout * cluster-salve-validity-factor，那么就没有资格切换成master。 从节点选举​ 每个从节点，都根据自己对master复制数据的offset，来设置一个选举时间，offset越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。 ​ 所有的master node开始slave选举投票，给要进行选举的slave进行投票，如果大部分master node (N / 2 + 1)都投票给某个从节点，那么选举通过，那个从节点 可以切换成master。 ​ 从节点执行主备切换，从节点切换为主节点。 与哨兵比较​ 整个流程跟哨兵相比，非常类似。所以redis cluster相当于直接集成了replication和sentinel的功能。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化]]></title>
    <url>%2FCKING.github.io%2F2019%2F09%2F01%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ Redis持久化的意义在于数据备份和灾难恢复。Redis如果仅仅只是将数据缓存在内存里面，如果Redis宕机了再重启，内存里的数据就全部弄丢了。所以得用Redis的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行持久化。如果Redis宕机重启，自动从磁盘上加载之前持久化的一些数据即可，也许会丢失少许数据，但是至少不会将所有数据都弄丢。 Redis持久化的两种方式 RDB：RDB持久化机制，是对Redis中的数据进行周期性的持久化。 AOF：AOF机制对每条写入命令作为日志，以append-only的模式写入一个日志文件中，在Redis重启的时候，可以通过回放AOF日志中的写入指令来重新构建整个数据集。 ​ 通过RDB或AOF，都可以将Redis内存中的数据持久化到磁盘上面来，然后可以将这些数据备份到别的地方去，比如阿里云等云服务等。 ​ 如果同时使用RDB和AOF两种持久化机制，那么redis重启的时候，会使用AOF来重构新数据，因为AOF中的数据更加完整。 RDB优缺点 RDB会生成多个数据文件，每个数据文件都代表某一个时刻中redis的数据，这种多个数据文件的方式，非常适合做冷备，可以将这种完备的数据文件发送到一些远程的安全存储上去，比如国内的阿里云的ODPS分布式存储上，以预定好的备份策略来定期备份redis中的数据。 RDB对redis对外提供的读写服务，影响非常小，可以让redis保持高性能，因为redis主进程只需要fork一个子进程，让子进程执行磁盘IO操作来进行RDB持久化即可。 相对于AOF持久化机制来说，直接基于RDB数据文件来重启和恢复redis进程，更加快速。 如果想要在redis故障时，尽可能少的丢失数据，那么RDB没有AOF好。一般来说，RDB数据快照文件，一般都是每隔5分钟，或者更长时间生成一次，这个时候就得接受一旦redis进程宕机，那么会丢失最近5分钟的数据。 RDB每次在fork子进程来执行RDB快照数据文件生成的时候，如果数据文件特别大，可能会导致对客户端提供的服务暂停数毫秒，或者甚至数秒。 AOF优缺点 AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。 AOF日志文件以append-only模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且文件不容易破损，即使尾部破损，也很容易修复。 AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在rewritelog的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志文件的时候，老的日志文件还是照常写入。当新的merge后日志文件ready的时候，再交换新老日志文件即可。 AOF日志文件的命令通过非常可读的方式进行记录，这个特定非常适合做灾难性的误删除的紧急操作。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据。 对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大。 AOF开启后，支持的QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然每秒一次fsync性能也还是很高的。但如果实时写入，那么QPS会大降，redis性能会大大降低。 以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据。因此，类似AOF这种较为复杂的基于命令/merge/回放的方式，比基于RDB每次持久化一份完整的数据快照的方式，更加脆弱一些，容易有bug。不过AOF就是为了rewrite过程导致的bug，因此每次rewrite并不是基于旧的指令日志进行merge，而是基于当时内存中的数据进行指令的重新构建，这样健壮性好很多。 补充：rewrite类似于普通数据库管理系统日志恢复点，当AOF文件随着写命令的运行膨胀时，当文件大小触碰到临界时，rewrite会被运行。 rewrite会像replication一样，fork出一个子进程，创建一个临时文件，遍历数据库，将每个key、value对输出到临时文件。输出格式就是Redis的命令，但是为了减小文件大小，会将多个key、value对集合起来用一条命令表达。在rewrite期间的写操作会保存在内存的rewrite buffer中，rewrite成功后这些操作也会复制到临时文件中，在最后临时文件会代替AOF文件。 RDB和AOF到底该如何选择 不要仅仅使用RDB，因为那样会导致你丢失很多数据。 也不要仅仅使用AOF，因为那样有两个问题：第一，通过AOF做冷备，没有RDB做冷备来得恢复速度更快；第二，RDB每次简单粗暴生成数据快照，更加健壮，可以避免AOF这种复杂的备份和恢复机制的bug； redis支持同时开启两种持久化方式，我们可以综合使用AOF和RDB两种持久化机制，用AOF来保证数据不丢失，作为数据恢复的第一选择，用RDB来做不同程度的冷备，在AOF文件都丢失或损坏不可用的时候，还可以使用RDB来进行快速的数据恢复。 如何配置RDB持久化的配置​ 打开redis的配置文件，搜索save，如图所示： ​ save 60 10000表示，每隔60秒，如果有超过10000个key发生了变化，那么就生成一个新的dump.rdb文件，就是当前redis内存中完整的数据快照，这个操作也被称为snapshotting。save可以设置多个，就是多个snapshotting检查点，每到一个检查点，就会去check一下，是否有指定的key数量发生了变更，如果有，就生成一个新的dump。 ​ 也可以手动调用save或者bgsave命令，同步或异步执行rdb快照生成。 ​ 如果你通过redis-cli SHUTDOWN的方式去停掉redis，这其实是一种安全退出的模式，redis在退出的时候会将内存中的数据立即生成一份完整的快照。如果用kill -9粗暴杀死redis进程，则相当于redis故障异常退出，不会生成dump快照文件。 AOF持久化的配置​ AOF持久化默认是关闭的，默认是打开RDB持久化。要开启AOF持久化配置，在redis配置文件中搜索appendonly，如下所示，将no改为yes即可。打开AOF持久化机制之后，redis每收到一条写指令，就会写入日志文件中。会先写入os cache，然后每隔一定时间再fsync一下。 ​ AOF的fsync总共有三种策略： appendfsync always：每次写入一条数据，立即将这个数据对应的写日志fsync到磁盘上去，性能很差，吞吐量很低，但确保了redis里的数据一条不丢。 appendfsync everysec：每秒执行一次fsync。这个最常用，生产环境一般这么配置，性能很高，QPS可以上万。 appendfsync no：不主动执行fsync，由操作系统自行判断。不可控。 AOF rewrite的配置​ 这里主要讲两个rewrite的配置 12auto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb 举个例子，比如上一次AOF rewrite之后，日志大小是128MB。此时就会接着128MB继续写AOF日志，如果发现增长的比例已经超过了之前的100%，256MB，就可能会去触发一次rewrite。但是此时还要去跟min-size， 64mb去比较，256 &gt; 64时，才会触发rewrite。 AOF破损文件的修复如果redis在append数据到AOF文件时，机器宕机了，可能会导致AOF文件破损 用redis-check-aof –fix命令来修复破损的AOF文件]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计核心接口的防重幂等性]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F26%2F%E8%AE%BE%E8%AE%A1%E6%A0%B8%E5%BF%83%E6%8E%A5%E5%8F%A3%E7%9A%84%E9%98%B2%E9%87%8D%E5%B9%82%E7%AD%89%E6%80%A7%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 在分布式系统中，一般都会有重试机制。但重复机制又有一定几率出现重复的数据。例如订单系统消费了消息，但是由于网络等问题消息系统未收到反馈是否已成功处理，此时消息系统会根据配置的规则隔断时间就retry一次。但如果此时网络恢复正常，我第一次收到的消息成功处理了，这是又收到一条消息，如果没有防护措施，就有可能出现重复数据。 接口幂等性​ 幂等性指任意多次执行所产生的影响均与一次执行的影响相同。多次调用对系统的产生的影响是一样的，即对资源的作用是一样的，但是返回值允许不同。在我们编程中主要操作就是CURD，其中读取（Retrieve）操作和删除（Delete）操作是天然幂等的，受影响的就是创建（Create）、更新（Update）。 对于业务中需要考虑幂等性的地方一般都是接口的重复请求，重复请求是指同一个请求因为某些原因被多次提交。导致这个情况会有几种场景： 前端重复提交：提交订单，用户快速重复点击多次，造成后端生成多个内容重复的订单。 接口超时重试：对于给第三方调用的接口，为了防止网络抖动或其他原因造成请求丢失，这样的接口一般都会设计成超时重试多次。 消息重复消费：MQ消息中间件，消息重复消费。 幂等性实现方式Token机制 服务端提供了发送token的接口，我们在分析业务的时候，哪些是存在幂等问题的，就必须在执行业务前，前去获取token，服务器会把token保存到redis中； 然后调用业务接口请求时，把token携带过去，一般反正请求头部； 服务器判断token是否存在redis中，存在表示第一次请求，可以继续执行业务，业务完成后，需要把redis中的token删掉； 如果判断token不存在redis中，就表示是重复操作，直接返回重复标记给client，这样就保证了业务代码，不被重复执行。 这就是token+redis的幂等方案。适用于绝大部分场景。主要针对前端重复连续多次点击的情况，网上也有另一个版本的Token方案，不同的地方是：网上方案检验token存在后，就立刻删除token，再进行业务处理。而上面的方式是检验token存在后，先进行业务处理，再删除token。 网上方案的缺点是先删除token，这是出现系统问题导致业务处理出现异常，业务处理没有成功，接口调用方也没有获取到明确的结果，然后进行重试，但token已经删除掉了，服务端判断token不存在，认为是重复请求，就直接返回了，无法进行业务处理了。 而上面的方案后删除token也是会存在问题的，如果进行业务处理成功后，删除redis中的token失败了，这样就导致了有可能会发生重复请求，因为token没有被删除。 token机制缺点业务请求每次请求，都会有额外的请求（一次获取token请求、判断token是否存在的业务）。其实真实的生产环境中，1万请求也许只会存在10个左右的请求会发生重试，为了这10个请求，我们让9990个请求都发生了额外的请求。（当然redis性能很好，耗时不会太明显） 去重表机制往去重表里插入数据的时候，利用数据库的唯一索引特性，保证唯一的逻辑。唯一序列号可以是一个字段，也可以是多字段的唯一性组合。 这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。 另外，使用数据库防重表的方式它有个严重的缺点，那就是系统容错性不高，如果幂等表所在的数据库连接异常或所在的服务器异常，则会导致整个系统幂等性校验出问题。 乐观锁机制乐观锁解决了计算赋值型的修改场景。例如： 123456update user set point = point + 20, version = version + 1 whereuserid=1 and version=1 加上了版本号后，就让此计算赋值型业务，具备了幂等性。 乐观锁缺点在操作业务前，需要先查询出当前的version版本。 唯一主键机制这个机制是利用了数据库的主键唯一约束的特性，解决了在insert场景时幂等问题。但主键的要求不是自增的主键，这样就需要业务生成全局唯一的主键，之前老顾的文章也介绍过分布式唯一主键ID的生成，可自行查阅。如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。因为对主键有一定的要求，这个方案就跟业务有点耦合了，无法用自增主键了。 Redis实现Redis实现的方式就是将唯一序列号作为Key，唯一序列号可以拿几个字段MD5加密生产的密文，value可以是你想填的任何信息。唯一序列号也可以是一个字段，例如订单的订单号，也可以是多字段的唯一性组合。当然这里需要设置一个 key 的过期时间，否则 Redis 中会存在过多的 key。 状态机对于很多业务有一个业务流转状态的，每个状态都有前置状态和后置状态，以及最后的结束状态。例如流程的待审批，审批中，驳回，重新发起，审批通过，审批拒绝。订单的待提交，待支付，已支付，取消。 以订单为例，已支付的状态的前置状态只能是待支付，而取消状态的前置状态只能是待支付，通过这种状态机的流转我们就可以控制请求的幂等。 123456789101112131415161718192021222324252627public enum OrderStatusEnum &#123; UN_SUBMIT(0, 0, "待提交"), UN_PADING(0, 1, "待支付"), PAYED(1, 2, "已支付待发货"), DELIVERING(2, 3, "已发货"), COMPLETE(3, 4, "已完成"), CANCEL(0, 5, "已取消"), ; //前置状态 private int preStatus; //状态值 private int status; //状态描述 private String desc; OrderStatusEnum(int preStatus, int status, String desc) &#123; this.preStatus = preStatus; this.status = status; this.desc = desc; &#125; //...&#125; 假设当前状态是已支付，如果支付接口又收到了支付请求，则会抛出异常会拒绝此处处理。 参考资料https://juejin.im/post/5ceb4c4f51882572a206d174 https://juejin.im/post/5d1e01aaf265da1bbc6ff400]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud生产环境配置服务的配置超时和重试参数]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F26%2FSpringCloud%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%9C%8D%E5%8A%A1%E7%9A%84%E9%85%8D%E7%BD%AE%E8%B6%85%E6%97%B6%E5%92%8C%E9%87%8D%E8%AF%95%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[启动Ribbon的饥饿加载​ 在生产环境中，系统第一次启动时，调用其他服务经常会出现timeout，经过查阅资料得知：每个服务第一次被请求的时候，他会去初始化一个Ribbon的组件，初始化这些组件需要耗费一定的时间，所以很容易会导致timeout问题。解决方案是让每个服务启动的时候直接初始化Ribbon相关的组件，避免第一次请求的时候初始化。 123ribbon: eager-load: enabled: true ​ 上面只是解决了内部服务之间的调用，但还有一个问题就是：网关到内部服务的访问。由于Spring Cloud Zuul的路由转发也是通过Ribbon实现负载均衡的，所以也会存在第一次调用时比较慢的情况。 ​ 此时可以通过以下配置 12345zuul: ignored-services: '*' ribbon: eager-load: enabled: true ​ Spring Cloud Zuul的饥饿加载中没有设计专门的参数来配置，而是直接采用了读取路由配置来进行饥饿加载的做法。所以，如果我们使用默认路由，而没有通过配置的方式制定具体路由规则，那么zuul.ribbon.eager-load.enabled=true的配置就没有作用了。 ​ 因此，在真正使用的时候，可以通过zuul.ignored-services=*来忽略所有的默认路由，让所有的路由配置均维护在配置文件中，以达到网关启动时就默认初始化好各个路由转发的负载均衡对象。 Ribbon配置超时和重试参数​ 以下配置是用来配置Ribbon的超时时间和重试次数的： 12345678910111213ribbon: ConnectTimeout: 250 # 连接超时时间(ms) ReadTimeout: 2000 # 通信超时时间(ms) OkToRetryOnAllOperations: true # 是否对所有操作重试 MaxAutoRetriesNextServer: 1 # 同一服务不同实例的重试次数 MaxAutoRetries: 1 # 同一实例的重试次数hystrix: command: default: execution: isolation: thread: timeoutInMillisecond: 10000 # 熔断超时时长：10000ms ​ 假设在网关Zuul配置了以上参数，MaxAutoRetriesNextServer和MaxAutoRetries的意思是如果Zuul认为某个服务超时了，此时会先重试一下该服务对应的这台机器，如果还是不行就会重试一下该服务的其他机器。 ​ 重试机制除了上面的参数配置的方式之外，还可以使用Spring-Retry实现。相比配置参数配置的方式，灵活性和扩展性更强。详情可以看大佬的这一篇Spring Retry重试机制]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里分布式事务框架seata的使用和介绍]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F24%2F%E9%98%BF%E9%87%8C%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%A1%86%E6%9E%B6seata%E7%9A%84%E4%BD%BF%E7%94%A8%E5%92%8C%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[​ 在分布式系统中，分布式事务是一个必须要解决的问题，目前使用较多的是最终一致性方案。自年初阿里开源了Fescar（四月初更名为Seata）后，该项目受到了极大的关注，目前已接近 8000 Star。Seata以高性能和零侵入的特性为目标解决微服务领域的分布式事务难题，目前正处于快速迭代中。 seata的几个概念​ 在讲解seata的原理之前，我们先了解几个Seata的相关概念。 XID：全局事务的唯一标识，由 ip:port:sequence 组成； Transaction Coordinator (TC)：事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚； Transaction Manager (TM )：控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议； Resource Manager (RM)：控制分支事务，负责分支注册、状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚； seata的简单使用​ 本文主要基于springcloud + Eureka + mysql + seata的结构搭建一个分布式系统的demo。具体步骤如下： 下载Eureka的demo https://github.com/seata/seata-samples/tree/master/springcloud-eureka-seata 下载seata-server 0.8.0 https://github.com/seata/seata/releases 创建数据库fescar，并用Navicat执行一个SQL文件创建相应测试用的表格和数据，内容如下：（这一步其实可以省略，demo中配置文件的数据库地址其实是有效的） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/* Navicat Premium Data Transfer Source Server : seata Source Server Type : MySQL Source Server Version : 50616 Source Host : 47.95.78.215:3306 Source Schema : fescar Target Server Type : MySQL Target Server Version : 50616 File Encoding : 65001 Date: 23/08/2019 11:22:20*/SET NAMES utf8mb4;SET FOREIGN_KEY_CHECKS = 0;-- ------------------------------ Table structure for account_tbl-- ----------------------------DROP TABLE IF EXISTS `account_tbl`;CREATE TABLE `account_tbl` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `money` int(11) NULL DEFAULT 0, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 214 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Records of account_tbl-- ----------------------------INSERT INTO `account_tbl` VALUES (213, &apos;U100000&apos;, 10000);-- ------------------------------ Table structure for order_tbl-- ----------------------------DROP TABLE IF EXISTS `order_tbl`;CREATE TABLE `order_tbl` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `commodity_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `count` int(11) NULL DEFAULT 0, `money` int(11) NULL DEFAULT 0, PRIMARY KEY (`id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 247 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Table structure for storage_tbl-- ----------------------------DROP TABLE IF EXISTS `storage_tbl`;CREATE TABLE `storage_tbl` ( `id` int(11) NOT NULL AUTO_INCREMENT, `commodity_code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, `count` int(11) NULL DEFAULT 0, PRIMARY KEY (`id`) USING BTREE, UNIQUE INDEX `commodity_code`(`commodity_code`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 1135 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;-- ------------------------------ Records of storage_tbl-- ----------------------------INSERT INTO `storage_tbl` VALUES (1134, &apos;C100000&apos;, 200);-- ------------------------------ Table structure for undo_log-- ----------------------------DROP TABLE IF EXISTS `undo_log`;CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `context` varchar(128) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime(0) NOT NULL, `log_modified` datetime(0) NOT NULL, `ext` varchar(100) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL, PRIMARY KEY (`id`) USING BTREE, UNIQUE INDEX `ux_undo_log`(`xid`, `branch_id`) USING BTREE) ENGINE = InnoDB AUTO_INCREMENT = 619 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Compact;SET FOREIGN_KEY_CHECKS = 1; 修改demo中配置文件中数据库的账号和密码（这一步其实也可以省略，理由同上） 修改seata-server中的配置文件registry.conf，将registry的方式type改为“euraka”。如果有需要，你可以在下面修改eureka的配置，指定相应的serviceUrl和application。 修改demo中所有服务resources文件夹下的registry.conf，将注册方式type改为“file”。 先运行demo中的eureka服务，然后在seata-server的bin文件下运行命令seata-server.bat -h 127.0.0.1 -p 8091 -m file启动seata-server，然后再运行demo中的其他服务。若无明显错误信息，则启动成功。 测试demo的分布式事务功能，主要的事务发起者是business-service，测试地址如下： 提交：http://localhost:8084/purchase/commit 回滚：http://localhost:8084/purchase/rollback 修改后的源码下载地址：https://github.com/GD-CKING/demo demo解析引入依赖​ 通过分析demo，如果要使用分布式事务架构Seata，在需要引入seata的服务中引入以下依赖： 12345678&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-seata&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-all&lt;/artifactId&gt;&lt;/dependency&gt; ​ demo中除了eureka之外其他服务都引入了这些依赖。 配置文件​ seata的配置文件主要有两个：registry.conf和file.conf。其中registry.conf是seata的配置入口文件。在registry中可以指定具体配置的形式，默认使用file类型，在file.conf配置文件中有一下配置内容： transport​ transport部分的配置对用NettyServerConfig类，用于定义Netty相关的参数。TM、RM和seata-server之间使用Netty进行通信。 service​ service中主要要注意service.vgroup_mapping这个配置，service.vgroup_mapping后面跟的内容要跟在配置文件中的spring.cloud.alibaba.seata.tx-service-group设置的属性一致，否则会提示no available server to connect.这个属性主要是为了定义一个tx-server-group名称 ，这个名称就是file.conf中的service.vgroup_mapping.${spring.cloud.alibaba.seata.tx-service-group}。 ​ 而file.conf中vgroup_mapping.my_test_tx_group = &quot;default&quot;指定seata-server的地址是下面default.grouplist设定的地址： 12345678910service &#123; #vgroup-&gt;rgroup #配置Client连接TC的地址 vgroup_mapping.my_test_tx_group = "default" default.grouplist = "127.0.0.1:8091" #degrade current not support enableDegrade = false #disable 是否启用seata的分布式事务 disableGlobalTransaction = false &#125; client1234567client &#123; #RM接收TC的commit通知后缓冲上限 async.commit.buffer.limit = 10000 lock &#123; retry.internal = 10 retry.times = 30 &#125; &#125; 表undo-log​ 要使用seata必须创建一个undo-log表。undo_log 是需要在业务库上创建的一个表，seata 依赖该表记录每笔分支事务的状态及二阶段 rollback 的回放数据。不用担心该表的数据量过大形成单点问题，在全局事务 commit 的场景下事务对应的 undo_log 会异步删除。 123456789101112CREATE TABLE `undo_log` ( `id` bigint(20) NOT NULL AUTO_INCREMENT, `branch_id` bigint(20) NOT NULL, `xid` varchar(100) NOT NULL, `rollback_info` longblob NOT NULL, `log_status` int(11) NOT NULL, `log_created` datetime NOT NULL, `log_modified` datetime NOT NULL, `ext` varchar(100) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8; 使用@GlobalTransactional开启事务​ 是开启分布式事务非常简单，只需要在要开启事务的业务方式上加上@GlobalTransactional注解开启事务即可。Seata 会将事务的 xid 通过拦截器添加到调用其他服务的请求中，实现分布式事务 TM处理流程​ 在本例中，TM 的角色是 business-service, BusinessService 的 purchase 方法标注了 @GlobalTransactional 注解。 ​ 方法调用后将会创建一个全局事务，首先关注 @GlobalTransactional 注解的作用，在GlobalTransactionalInterceptor中被拦截处理。 ​ 全局事务创建后，就开始执行 business.execute()，即业务代码storageFeignClient.deduct(commodityCode, orderCount)进入 RM 处理流程，此处的业务逻辑为调用 storage-service 的扣减库存接口。 RM处理流程 获取business-service传来的XID 绑定XID到当前上下文中 执行业务逻辑sql 向TC创建本次RM的Netty连接 向TC发送分支事务的相关信息 获得TC返回的branchId 记录Undo Log数据 向TC发送本次事务PhaseOne阶段的处理结果 从当前上下文中解绑XID 事务提交​ 各分支事务执行完成后，TC 对各 RM 的汇报结果进行汇总，给各 RM 发送 commit 或 rollback 的指令。 ​ 对于commit动作的处理，RM只需删除xid、branchId对应的undo_log即可。 事务回滚​ 对于rollback场景的触发有两种情况 分支事务处理异常，即ConnectionProxy中report(false)的情况。 TM捕获到下游系统上抛的异常，即发起全局事务标有@GlobalTransactional注解的方法捕获到的异常。在前面TransactionalTemplate类的execute模版方法中，对business.execute()的调用进行了catch，catch后会调用rollback，由TM通知TC对应XID需要回滚事务。 参考资料https://zhuanlan.zhihu.com/p/63381854]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的主从复制架构]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F22%2FRedis%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[本节思维导图 Redis主从架构​ 单机的Redis，能够承载的QPS大概在上万到几万不等。对于缓存来说，一般都是用来支撑读高并发的。因此架构设计成主从（master-slave）架构，一主多从，主负责写，并且将数据复制到其他的slave节点，从节点复制读。所有的读请求全部走从节点。这样也可以轻松实现水平扩容，支撑读高并发。 ​ redis replication -&gt; 主从架构 -&gt; 读写分离 -&gt; 水平扩容支撑读高并发 redis replication的核心机制 redis采用异步方式复制数据到slave节点，不过redis2.8开始，slave node会周期性地确认自己每次复制的数据量 一个master node是可以配置多个slave node的 slave node也可以连接其他的slave node slave node做复制的时候，不会block master node的正常工作 slave node做复制的时候，也不会block对自己的查询操作，它会用旧的数据集来提供服务；但是复制完成的时候，需要删除旧数据集，加载新数据集，这个时候会暂停对外服务了 slave node主要用来进行横向扩容，做读写分离，扩容的slave node可以提高读的吞吐量 ​ 如果采用了主从架构，那么建议必须开启master nod的持久化，不建议用slave node作为master node的数据热备，因为那样的话，你关掉了master的持久化，可能在master宕机重启的时候数据是空的，然后可能一经过复制，slave node的数据也丢了。 ​ 另外，master的各种备份方案 也需要做。如果本地的所有文件丢弃，从备份中挑选一份rdb去恢复master，这样才能确保启动的时候，是有数据的。即使采用了高可用机制，slave node可以自动接管master node，但也可能哨兵（sentinel）还没检测到masterfailure，master node自动重启了，还是可能导致上面的slave node数据被清空。 redis主从复制的核心原理​ 当启动一个slave node的时候，它会发送一个PSYNC命令给master node。 ​ 如果是slave node初次连接到master node，那么会触发一次full resynchronization全量复制。此时master会启动一个后台线程，开始生成一份RDB快照文件，同时还会将从客户端新收到的所有命令缓存在内存中。RDB文件生产完毕后，master会将这个RDB发送给slave，slave会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着master会将内存中缓存的命令发送给slave，slave也会同步这些数据。slave node如果跟master node有网络故障，断开了连接，会自动重连，连接之后master node仅会复制给slave部分缺失的数据。 主从复制的断点续传​ 从redis2.8开始，就支持主从复制的断点续传，如果主从复制过程中，网络连接断掉了，那么就可以接着上次复制的地方，继续复制下去，而不是从头开始复制一份。 ​ master node会在内存中维护一个backlog，master和slave都会保存一个replica offset，还有一个master run id，offset就是保存在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制，如果没有找到对应的offset，就会执行一次resynchronization。 ​ 使用master run id，是为了定位到上次传输数据的master。如果是根据host + ip定位master node，是不靠谱的，如果master node重启或者数据出现了变化，那么slave node应该根据不同的run id区分。 无磁盘化复制​ master在内存中直接创建RDB，然后发送给slave，不会在本地落地磁盘。要想开启这个功能，只需要在配置文件中国开启repl-diskless-syc yes即可。 1234repl-diskless-sync yes# 等待 5s 后再开始复制，因为要等更多 slave 重新连接过来repl-diskless-sync-delay 5 过期key处理​ slave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。 复制的完整流程​ slave node启动时，会在自己本地保存master node的信息，包括master node的host和ip，但是复制流程没开始。 ​ slave node内部有个定时任务，每秒检查是否有新的master node要连接和复制，如果发现，就跟master node建立socket网络连接。然后master node发送ping命令给master node。如果master设置了requirepass，那么slave node必须发送masterauth的口令过去进行认证。master node第一次执行全量复制，将所有数据发送给slave node，而在后续，master node持续将写命令，异步复制给slave node。 数据同步相关的核心机制​ 数据同步相关的核心机制指的就是第一次slave连接master的时候，执行的全量复制，这个过程里面的一些细节的机制。 master和slave都会维护一个offset​ master会在自身不断累加offset，slave也会在自身不断累加offset。slave每秒都会上报自己的offset给master，同时master也会保存每个slave的offset。 ​ 这个不是特定就用在全量复制的，主要是master和slave都要知道各自的数据的offset，才能知道互相之间的数据不一致的情况。 backlog​ master node有一个backlog，默认是1MB大小。master node在给slave node复制数据时，也会将数据在backlog中同步写一份。backlog主要是用来做全量复制中断开后的增量复制的。 master run id​ info server可以看到master run id。 ​ 上面说过，根据host+ip定位master node是不靠谱的，如果master node重启或者数据发生了变化，那么slave node应该根据不同的run id区分，run id不同就做全量复制。如果需要不更改run id重启redis，可以使用redis-cli debug reload命令。 ![run id](Redis的主从复制架构/run id.png) psync​ 从节点使用psync从master node进行复制，psync runid offset ​ master node会根据自身的情况返回相应信息，可能是FULLRESYNC runid offset触发全量复制，可能是CONTINUE触发增量复制。 全量复制 master执行bgsave，在本地生成一份RDB快照文件 master node将RDB快照文件发送给slave node，如果RDB复制时间超过60秒（repl-timeout），那么slave node就会认为复制失败，可以适当调大这个参数。 master node在生成RDB时，会将所有新的写命令缓存在内存中，在slave node保存了RDB之后，再将新的写命令复制给slave node 如果在复制期间，内存缓冲区持续消耗超过64MB，会在一次性超过256MB，那么停止复制，复制失败。 1client-output-buffer-limit slave 256MB 64MB 60 slave node接收到RDB之后，清空自己的旧数据，然后重新加载RDB到自己内存中，同时基于旧的数据版本对外提供服务。 如果slave node开启了AOF，那么会立即执行BGREWAITEAOF，重写AOF 增量复制 如果全量复制过程中，master-slave网络连接断掉了，那么slave重新连接master时，会触发增量复制 master会直接从自己的backlog中获取部分丢失的数据，发送给slave node，默认backlog就是1MB master就是根据slave发送的psync中的offset来从backlog中获取数据的。 heartbeat​ 主从节点互相都会发送heartbeat信息 ​ master默认每隔10秒发送一次heartbeat，slave node每隔1秒发送一个heartbeat。 异步复制​ master每次接收到写命令之后，现在内部写入数据，然后异步发送给slave node redis如何才能做到高可用​ 一个slave故障了，并不会影响可用性，还有其他的slave在提供服务。但master node死掉了，会导致无法写数据。没有master可以写数据，slave也就没用了，系统就不可用了。 ​ redis的高可用架构，叫做failover故障转移，也可以叫做主备切换。 ​ master node在故障时，自动检测，并且将某个slave node自动切换为master node的过程，叫做主备切换。这个过程就实现了redis的主从架构下的高可用。 主从复制的配置​ 讲了那么多，我们来看看如何配置，从而实现主从架构。 ​ 首先先配置从节点: 打开从节点的配置文件，搜索replicaof （低版本的有些是slaveof），去配置从节点要连接的主节点。如replicaof 192.168.1.1 6379，其中192.168.1.1是我们主节点的IP地址。 在配置文件中搜索replica-read-only（低版本的有些是slave-read-only），将该属性配置为也是：replica-read-only yes，这样就开启了只读redis从节点，它会拒绝所有的写操作，这样可以强制搭建读写分离的架构，从而实现读写分离。 在配置文件中搜索masterauth，来配置主节点redis的连接口令。如masterauth redis-pass，其中redis-pass就是主节点的认证口令。 在配置文件中搜索bind，将bind 127.0.0.1改成bind 自己的IP地址。bind 127.0.0.1是本地的开发调式的模式，就只有127.0.0.1本地才能访问到6379的端口。 强制开启6379端口iptables -A INPUT -ptcp --dport 6379 -j ACCEPT。（这一步有时可以省略） ​ 配置主节点： 打开主节点的配置文件，搜索requirepass，配置主节点的认证口令，使其与从节点配置的masterauth保持一致。 在配置文件中搜索bind，将bind 127.0.0.1改成bind 自己的IP地址。 强制开启6379端口iptables -A INPUT -ptcp --dport 6379 -j ACCEPT。（这一步有时可以省略） ​ 这样主从架构就配置好了，我们测试一下，先启动主节点，再启动从节点。进入主节点的redis中，执行info replication查看相关信息 ​ 同样的，进入从节点的redis，执行info replication查看相关信息]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的线程模型及和mencached的区别]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F20%2FRedis%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%92%8Cmencached%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[本节思维导图 Redis和Memcached的区别Redis支持复杂的数据结构​ redis相比于memcached来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支持更复杂的结构和操作，redis相对来说比较好。 Redis原生支持集群模式​ redis 3.X便能支持cluster模式，而memcached没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据。 性能对比​ 由于redis只使用单核，而memcached可以使用多核，所以平均每一个核上redis存储小数据时比memcached性能更高。而在100K以上的数据中，memcached性能要高于redis。 Redis的线程模型​ redis内部使用文件事件处理器file event handler，这个文件事件处理器是单线程的，所以redis才叫做单线程的模型。它采用IO多路复用机制同时监听多个socket，将产生事件的socket压入内存队列中，事件分派器根据socket上的事件类型来选择对应的事件处理器进行处理。 ​ 文件事件处理器的结构包含4个部分： 多个socket IO多路复用程序 文件事件分派器 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器） 客户端与redis的一次通信过程如下： 首先，redis服务端进程初始化的时候，会将server socket的AE_READABLE事件与连接应答处理器关联。 ​ 客户端socket01向redis进程的server socket请求建立连接，此时server socket会产生一个AE_READABLE事件，IO多路复用程序监听到server socket产生的事件后，将该socket压入队列中。文件事件分派器从队列中获取socket，交给连接应答处理器。连接应答处理器会创建一个能与客户端通信的socket01，并将该socket01的AE_READABLE事件与命令请求处理器关联。 ​ 假设客户端发送了一个set key value请求，此时redis中的socket01会产生AE_READABLE事件，IO多路复用程序将socket01压入队列，此时事件分派器从队列中获取到socket01产生的AE_READABLE事件，由于前面的socket01的AE_READABLE事件已经与命令请求处理器关联，因此事件分派器将事件交给命令请求处理器来处理。命令请求处理器读取socket01的key value并在自己内存中完成key value的设置，操作完成后，它会将socket01的AE_WRITABLE事件与命令回复处理器关联。 ​ 如果此时客户端准备好接受返回结果了，那么redis中的socket01会产生一个AE_WRITABLE事件，同样压入队列，事件分派器找到相关联的命令回复处理器，由命令回复处理器对socket01输入本次操作的一个结果，之后解除socket01的AE_WRITABLE事件与命令回复处理器的关联。 Redis单线程效率高的原因 纯内存操作 核心是基于非阻塞的IO多路复用机制 C语言实现，一般来说，C语言实现的程序更接近操作系统，执行速度相对会快 单线程反而避免了多线程的频繁上下文切换，预防了多线程可能产生的竞争问题]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zuul-实现灰度发布]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F20%2FZuul-%E5%AE%9E%E7%8E%B0%E7%81%B0%E5%BA%A6%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[​ 一般情况下，我们要发布新版本了，在不确定正确性的情况下，我们会选择先部分节点升级，然后再让一些特定的流量进入到这些新节点，完成测试后再全量发布。这就是灰度发布。 ​ 在Eureka中注册多个服务后，如果一个服务有多个实例，那么默认会走ribbon的软负载均衡来进行分发请求。而要完成灰度发布，要做的就是修改ribbon的负载策略。在SpringCloud体系中，完成这件事，一般都是根据Eureka的metadata进行自定义元数据，然后修改Ribbon的规则。 ​ 我们可以用数据库来动态开启灰度发布和指定灰度发布的请求，当然你也可以用Apollo配置中心、Redis、ZooKeeper，其实都可以。先创建一个灰度发布启用表： 1234567CREATE TABLE `gray_release_config` ( `id` int(11) NOT NULL AUTO_INCREMENT, `service_id` varchar(255) DEFAULT NULL, `path` varchar(255) DEFAULT NULL, `enable_gray_release` int(11) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ​ 其中“enable_gray_release”表示是否启用灰度发布，默认数字0是不启动，1启动。然后插入一条数据，方便我们测试： 1INSERT INTO gray_release_config VALUES(1, 'order-service', '/order', 0) ​ 首先，我们需要在Zuul项目里添加依赖： 12345&lt;dependency&gt; &lt;groupId&gt;io.jmnarloch&lt;/groupId&gt; &lt;artifactId&gt;ribbon-discovery-filter-spring-cloud-starter&lt;/artifactId&gt; version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; ​ 接着在网关中新建给表的实体类： 1234567891011121314151617181920212223242526272829303132333435package com.zhss.demo.zuul.gateway;public class GrayReleaseConfig &#123; private int id; private String serviceId; private String path; private int enableGrayRelease; public int getId() &#123; return id; &#125; public void setId(int id) &#123; this.id = id; &#125; public String getServiceId() &#123; return serviceId; &#125; public void setServiceId(String serviceId) &#123; this.serviceId = serviceId; &#125; public String getPath() &#123; return path; &#125; public void setPath(String path) &#123; this.path = path; &#125; public int getEnableGrayRelease() &#123; return enableGrayRelease; &#125; public void setEnableGrayRelease(int enableGrayRelease) &#123; this.enableGrayRelease = enableGrayRelease; &#125; &#125; ​ 然后我们可以编写一个定时器，定时获取灰度表的信息，看哪些服务需要灰度发布，新建类GrayReleaseConfigManager： 1234567891011121314151617181920212223242526272829303132333435363738394041package com.zhss.demo.zuul.gateway;import java.util.List;import java.util.Map;import java.util.concurrent.ConcurrentHashMap;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.core.BeanPropertyRowMapper;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.scheduling.annotation.EnableScheduling;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component;@Component@Configuration @EnableScheduling public class GrayReleaseConfigManager &#123; private Map&lt;String, GrayReleaseConfig&gt; grayReleaseConfigs = new ConcurrentHashMap&lt;String, GrayReleaseConfig&gt;(); @Autowired private JdbcTemplate jdbcTemplate; @Scheduled(fixedRate = 1000) private void refreshRoute() &#123; List&lt;GrayReleaseConfig&gt; results = jdbcTemplate.query( "select * from gray_release_config", new BeanPropertyRowMapper&lt;&gt;(GrayReleaseConfig.class)); for(GrayReleaseConfig grayReleaseConfig : results) &#123; grayReleaseConfigs.put(grayReleaseConfig.getPath(), grayReleaseConfig); &#125; &#125; public Map&lt;String, GrayReleaseConfig&gt; getGrayReleaseConfigs() &#123; return grayReleaseConfigs; &#125;&#125; ​ 然后再编写一个Zuul的过滤器，实现灰度发布的逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100package com.zhss.demo.zuul.gateway;import org.springframework.context.annotation.Configuration;import com.netflix.zuul.ZuulFilter;import com.netflix.zuul.context.RequestContext;import io.jmnarloch.spring.cloud.ribbon.support.RibbonFilterContextHolder;import static org.springframework.cloud.netflix.zuul.filters.support.FilterConstants.*;import java.util.Map;import java.util.Random;import javax.annotation.Resource;import javax.servlet.http.HttpServletRequest;@SuppressWarnings("unused")@Configurationpublic class GrayReleaseFilter extends ZuulFilter &#123; @Resource private GrayReleaseConfigManager grayReleaseConfigManager; /** * 过滤的优先级，数字越大，级别越低 * @return */ @Override public int filterOrder() &#123; return PRE_DECORATION_FILTER_ORDER - 1; &#125; @Override public String filterType() &#123; return PRE_TYPE; &#125; /** * 是否执行该过滤器 * @return */ @Override public boolean shouldFilter() &#123; RequestContext ctx = RequestContext.getCurrentContext(); HttpServletRequest request = ctx.getRequest(); String requestURI = request.getRequestURI(); // http://localhost:9000/order/order?xxxx Map&lt;String, GrayReleaseConfig&gt; grayReleaseConfigs = grayReleaseConfigManager.getGrayReleaseConfigs(); for(String path : grayReleaseConfigs.keySet()) &#123; if(requestURI.contains(path)) &#123; GrayReleaseConfig grayReleaseConfig = grayReleaseConfigs.get(path); if(grayReleaseConfig.getEnableGrayRelease() == 1) &#123; System.out.println("启用灰度发布功能"); return true; &#125; &#125; &#125; System.out.println("不启用灰度发布功能"); return false; &#125; /** * 过滤器的具体逻辑 * @return */ @Override public Object run() &#123;// RequestContext ctx = RequestContext.getCurrentContext();// HttpServletRequest request = ctx.getRequest();// String gray = request.getParameter("gray");//// if("true".equals(gray)) &#123;// RibbonFilterContextHolder.getCurrentContext().add("version", "new");// &#125; else &#123;// RibbonFilterContextHolder.getCurrentContext().add("version", "current");// &#125; Random random = new Random(); int seed = random.nextInt(100); if (seed == 50) &#123; // put the serviceId in `RequestContext` RibbonFilterContextHolder.getCurrentContext() .add("version", "new"); &#125; else &#123; RibbonFilterContextHolder.getCurrentContext() .add("version", "old"); &#125; return null; &#125;&#125; ​ 上面的代码主要还是看run()方法的实现。注释掉的代码是通过判断请求连接中是否包含“gray”参数，如果包含gray参数并且它的值为“true”，则将流量引到新的节点。而没有注释的代码则是根据随机数seed的值来引流。当你希望有10%的流量引到新节点时，可以将if(seed == 50)改成 seed &gt;= 90或者其他。 ​ 最后，就是在要升级的服务配置上增加metadata的自定义数据即可，根据上述的代码，我们应该在要升级的服务的配置文件中增加：eureka: instance: metadata-map: version: new。在没升级的服务的配置文件中增加：eureka: instance: metadata-map: version: old ​ 这样，基于Zuul的灰度发布功能就实现了。当然，基于灰度发布这块，国内有了更强大的开源框架Nepxion Discovery。Nepxion Discovery是一款对Spring Cloud Discovery服务注册发现、Ribbon负载均衡、Feign和RestTemplate调用的增强中间件，感兴趣的朋友可以去官方的github上查看：https://github.com/Nepxion/Discovery]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis分布式锁的实现原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F20%2FRedis%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 目前基于Redis实现的分布式锁常用的框架是Redisson,它的使用比较简单，在项目中引入Redisson的依赖，然后基于Redis实现分布式锁的加锁与释放锁，如下所示： ​ 接下来我们就说一下Redisson这个框架对于Redis分布式锁的实现原理。 Redis分布式锁的底层原理​ Redisson这个框架对Redis分布式锁的实现原理图如下： 加锁机制​ 某个客户端要加锁。如果该客户端面对的是一个Redis Cluster集群，它首先会根据hash节点选择一台机器，这里注意，仅仅只是选择一台机器。紧接着就会发送一段lua脚本到redis上，lua脚本如下所示： ​ 使用lua脚本，可以把一大堆业务逻辑通过封装在lua脚本发送给redis，保证这段赋值业务逻辑执行的原子性。在这段脚本中，这里KEYS[1]代表的是你加锁的那个key，比如说：RLock lock = redisson.getLock(“myLock”);这里你自己设置了加锁的那个锁key就是“myLock”。 ​ ARGV[1]代表的就是锁key的默认生存时间，默认30秒。ARGV[2]代表的是加锁的客户端的ID，类似于下面这样：8743c9c0-0795-4907-87fd-6c719a6b4586:1。 ​ 脚本的意思大概是：第一段if判断语句，就是用“exists myLock”命令判断一下，如果你要加锁的那个key不存在，就可以进行加锁。加锁就是用“hset myLock 8743c9c0-0795-4907-87fd-6c719a6b4586:1 1”命令。通过这个命令设置一个hash数据结构，这个命令执行后，会出现一个类似下面的数据结构： ​ 上述就代表“8743c9c0-0795-4907-87fd-6c719a6b4586:1”这个客户端对“myLock”这个锁key完成了加锁。接着会执行“pexpire myLock 30000”命令，设置myLock这个锁key的生存时间是30秒。好了，到此为止，ok，加锁完成了。 锁互斥机制​ 如果这个时候客户端B来尝试加锁，执行了同样的一段lua脚本。第一个if判断会执行“exists myLock”，发现myLock这个锁key已经存在。接着第二个if判断，判断myLock锁key的hash数据结构中，是否包含客户端B的ID，但明显没有，那么客户端B会获取到pttl myLock返回的一个数字，代表myLock这个锁key的剩余生存时间。此时客户端B会进入一个while循环，不听的尝试加锁。 watch dog自动延期机制​ 客户端A加锁的锁key默认生存时间只有30秒，如果超过了30秒，客户端A还想一直持有这把锁，怎么办？其实只要客户端A一旦加锁成功，就会启动一个watch dog看门狗，它是一个后台线程，会每隔10秒检查一下，如果客户端A还持有锁key，那么就会不断的延长锁key的生存时间。 可重入加锁机制​ 客户端A已经持有锁了，然后可重入加锁，如下代码所示： ​ 这个时候lua脚本是这样执行的：第一个if判断不成立，“exists myLock”会显示锁key已经存在了。第二个if判断会成立，因为myLock的hash数据结构中包含的那个ID，就是客户端A的ID，此时就会执行可重入加锁的逻辑，它会用“incrby myLock 8743c9c0-0795-4907-87fd-6c71a6b4586:1 1 ”这个命令对客户端A的加锁次数，累加1，此时myLock的数据结构变成下面这样： ​ 即myLock的hash数据结构中的那个客户端ID，就对应着加锁的次数。 释放锁机制​ 执行lock.unlock()，就可以释放分布式锁。释放逻辑是：每次对myLock数据结构中的那个加锁次数减1，如果加锁次数为0了，说明客户端已经不再持有锁了，此时就会用“del MyLock”命令，从redis里删除了这个key。然后另外的客户端B就可以尝试完成加锁了。 上述Redis分布式锁的缺点​ 上面方案的最大问题，就是如果你对某个redis master实例，写入了myLock这种锁key的value，此时会异步复制给对应的master slave实例，但是这个过程中如果发送redis master宕机，主备切换，redis slave变为了redis master。 ​ 这就会导致客户端B来尝试加锁的时候，在新的redis master上完成了加锁，而客户端A也以为自己成功加了锁，此时就会导致多个客户端对一个分布式锁完成了加锁。这时就会导致各种脏数据的产生。 ​ 所以这个就是redis cluster，或者是redis master-slave架构的主从异步复制导致的redis分布式锁的最大缺陷：在redis master实例宕机的时候，可能导致多个客户端同时完成加锁。]]></content>
      <categories>
        <category>分布式</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ZooKeeper分布式锁的实现原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F19%2FZooKeeper%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[ZooKeeper分布式锁机制​ 本文将基于常用的ZooKeeper分布锁实现框架–Curator，说一下这个框架对ZooKeeper分布式锁的实现。 ​ 首先模拟一下两个客户端一起争抢ZK上的一把分布式锁的场景： ​ ZK里有一把锁，这个锁就是ZK上的一个节点。然后两个客户端都要来获取这个锁。假设客户端A抢先一步，对ZK发起了加分布式锁的请求，这个加锁请求是用到了ZK的“临时顺序节点”。简答来说就是直接在“my_lock”这个锁节点下，创建一个顺序节点，这个节点有ZK内部自行维护的一个节点序号。 ​ 例如第一个客户端来搞一个顺序节点，ZK内部会起个名字叫xxx-00001。然后第二个客户端搞一个顺序节点，ZK可能会起个名字叫xxx-00002。规律就是最后一个数字都是依次递增的，从1开始递增，ZK会维护这个顺序。 ​ 所以这个时候，假如客户端A先发起请求，就会搞出一个顺序节点，如图所示： ​ 客户端A发起一个加锁请求，先会在你要加锁的node下搞一个临时顺序节点，节点名字由Curator框架自己生成出来，但最后一个数字是“1”，因为客户端是第一个发起请求的。 ​ 客户端A常见完一个节点后，它会查一下“my_lock”这个锁节点下的所有子节点，并且这些子节点都是按照序号排序的，这个时候他大概会拿到一个集合： ​ 接着客户端A会走一个关键性的判断：我创建的那个顺序节点，是不是排在第一个？如果是的话，那我就可以加锁了。因为我是第一个创建顺序节点的人，所以我是第一个尝试加分布式锁的人。 ​ 客户端A加完锁了，客户端B过来想要加锁，这时它会先在“my_lock”这个锁节点下创建一个临时顺序节点，此时名字大概会是“xxx-00002” ​ 客户端B因为是第二个来创建顺序节点的，所以ZK内部会维护序号为“2”。接着客户端B会走加锁判断逻辑，查询“my_lock”锁节点下的所有子节点，按照顺序排列，类似于： ​ 同时检查自己创建的顺序节点，是不是集合中的第一个？如果不是，那就加锁失败。失败之后，客户端B就会通过ZK的API对他的顺序节点的上一个顺序节点加一个监听器 ​ 接着，客户端A加锁之后，逻辑处理完后就会释放锁，释放锁实际就是把ZK里创建的顺序节点“xxx-00001”给删除掉。删除了节点之后，ZK会负责通知监听这个节点的监听器，也就是客户端B的监听器说锁释放了。 ​ 此时客户端B的监听器感知到了上一个顺序节点被删除，也就是排在他之前的某个客户单释放了锁，此时客户端B重新尝试去获取锁，也就是获取“my_lock”节点下的子节点集合： ​ 然后客户端B判断自己是否是集合中的第一个顺序节点，如果是，直接完成加锁，运行完业务代码后，再次释放锁。 总结​ 总结一下多个客户端争抢一个ZK分布式锁的原理： 客户端上来直接创建一个锁节点下的一个接一个的临时顺序节点 如果自己不是第一个节点，就对自己上一个节点加监听器 只要上一个节点释放锁，自己就排到前面去，相当于一个排队机制。 ​ 而且用临时加节点的另一个好处就是，如果某个客户端创建临时顺序节点之后，自己宕机了也没关系，ZK感知到那个客户端宕机，会自动删除对应的临时顺序节点，相当于自动释放锁。 ​ 最后看一下用Curator框架进行加锁和释放锁的一个过程：]]></content>
      <categories>
        <category>分布式</category>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单了解ZooKeeper]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F19%2F%E7%AE%80%E5%8D%95%E4%BA%86%E8%A7%A3ZooKeeper%2F</url>
    <content type="text"><![CDATA[本节思维导图 ZooKeeper的数据结构​ ZooKeeper的数据结构，跟Unix文件系统非常类似，可以看做是一颗树，每个节点叫做ZNode，每一个节点可以通过路径来标识： ​ ZooKeeper的节点我们称之为ZNode，ZNode分为两种类型： 短暂/临时：当客户端和服务端断开连接后，所创建的ZNode（节点）会自动删除 持久：当客户端和服务端断开连接后，所创建的ZNode不会删除 ​ 这些节点由可以分成另外两种类型： 普通节点 带顺序号节点 监听器​ ZooKeeper之所以能实现那么多功能，最主要还是配合了监听器。 ​ 常见的监听器有以下两个功能： 监听ZNode节点的数据变化 监听子节点的增减变化 ​ 通过监听+ZNode节点，Zookeeper就可以实现比较多的功能了 ZooKeeper的作用统一配置管理​ 比如现在有三个系统A、B、C，他们有三份配置ASystem.yml、BSystem.yml、CSystem.yml，然后，这三份配置又非常类似，很多配置项几乎一样。此时如果我们要改变其中一份配置项的信息，很可能另外两份都要改，并且改了配置项的系统很能就要重启系统。 ​ 于是我们希望把ASystem.yml、BSystem.yml、CSystem.yml相同的配置项抽取出来成一份公用的配置common.yml，并且即使common.yml改了，也不需要系统A、B、C重启。 ​ 解决方案是我们可以把common.yml这份配置放在ZooKeeper的ZNode节点中，系统A B C监听这个节点有无变更，变更了就及时响应。 ​ 具体实现可以大佬写的 基于zookeeper实现统一配置管理 统一命名服务​ 统一命名服务的理解其实跟域名一样，是我们为这某一部分的资源给它取另一个名字，别人通过这个名字就可以拿到对应的资源。 ​ 例如我们有一个域名叫www.test.com。但这个域名下有多台机器： 192.168.1.1 192.168.1.2 192.168.1.3 192.168.1.4 别人访问www.test.com即可访问到我的机器，而不是通过IP去访问。 分布式锁​ 详情请参考这篇 ZooKeeper的分布式锁的实现原理 集群管理​ 还是以三个系统A B C为例，在ZooKeeper中创建临时节点即可， ​ 只要系统A挂了，那么/groupMember/A这个节点就会删除，通过监听groupMember下的子节点，系统B和C就能感知到系统A挂了，新增也是同理。 ​ 除了能感知节点的上下线变化，Zookeeper还可以实现动态选举Master的功能（如果集群是主从结构模式下）。原理也很简单，如果想要实现这个功能，只要ZNode节点的类型是带顺序号的临时节点就好了。ZooKeeper会每次选举最小编号的作为Master，如果Master挂了，自然对应的ZNode节点就会删除，然后让新的最小编号作为Master，这样就可以实现动态选举的功能。]]></content>
      <categories>
        <category>分布式</category>
        <category>ZooKeeper</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>ZooKeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式事务方案]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F16%2F%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[本节思维导图 目前分布式事务的实现方案主要有以下5种： XA方案 TCC方案 本地消息表 可靠消息最终一致性方案 最大努力通知方案 两阶段提交方案/XA方案​ 所谓的XA方案，就是两阶段提交。有一个事务管理器的概念，负责协调多个数据库（资源管理器）的事务，事务管理器先询问各个数据库是否准备好了，如果数据库都准备好了，就正式提交事务，在各个数据库上执行。如果任何其中一个数据库回答不OK，那么就回滚事务。 ​ 这种分布式方案，比较适合单块应用里，跨多个库的分布式事务，而且因为严重依赖于数据库层面来搞定复制的事务，效率很低。绝对不适合高并发的场景。如果要实现，可以基于Spring+JTA就可以实现。 ​ 这个方案，一般很少用。一般来说某个系统内部如果出现跨多个库的操作，是不合规的。即便是现在的微服务，一个大的系统分成十几个甚至几百个服务。一般来说，都是要求每个服务只能操作自己对应的一个数据库。如果要操作别的服务对应的库，不允许直接连接，违反微服务架构的规范，你随便交叉胡乱访问，几百个服务的话，全体乱套，这样的一套服务是没法管理的，没法治理的，可能会出现数据被别人改错，自己的库被别人写挂等情况。 如果你要操作别人的服务的库，你必须是通过调用别的服务的接口来实现，绝对不允许交叉访问别人的数据库。 TCC方案​ tcc全称是：try、confirm、cancel Try阶段：这个阶段说的是对各个服务的资源做检测以及对资源进行锁定或者预定。 Confirm：这个阶段说的是在各个服务中执行实际的操作。 Cancel：如果任何一个服务的业务方法执行出错，那么这里就需要进行补偿，就是执行已经执行成功的业务逻辑的回滚操作。（把那些执行成功的回滚）。 ​ 这种方案也用的比较少，但是也有使用的场景。因为这个事务回滚实际上是严重依赖于自己写的代码来回滚和补偿的，会造成补偿代码巨大。一般来说跟钱相关的，跟钱打交道的，支付、交易相关的场景，会使用TCC，严格保证分布式事务要么全部成功，要么全部自动回滚，严格保证资金的正确性。而且最好是你的各个业务执行的时间都比较短。但是一般情况下尽量不要使用TCC方案，自己手写回滚逻辑或者是补偿代码，都是很恶心的，业务代码很难维护。 本地消息表​ 本地消息表的大概意思如下： A系统在自己本地一个事务里操作同时，插入一条数据到消息表； 接着A系统将这个消息发送到MQ中去； B系统接收到消息之后，在一个事务里，往自己本地消息表插入一条数据，同时执行其他的业务操作，如果这个消息已经被处理过，那么此时这个事务会回滚，这样保证不会重复处理消息； B系统执行成功之后，就会更新自己本地信息表的状态以及A系统信息表的状态； 如果B系统处理失败，那么久不会更新信息表状态，那么此时A系统会定时扫描自己的消息表，如果有未处理的消息，则会发送到MQ中去，让B再次处理； 这个方案保证了最终一致性，哪怕B事务失败了，但是A会不断重发信息一致到B那边成功为止。 这个方案最大的问题是就是严重依赖于数据库的消息表来管理事务，如果是高并发场景，很难扩展，所以一般比较少用。 可靠消息最终一致性方案​ 这个的意思，就是干脆不用本地消息表了，直接基于MQ来实现事务，比如阿里的RocketMQ就支持消息事务，大概的思路如下： A系统先发送一个prepared消息到mq，如果这个prepared消息发送失败那么就直接取消操作别执行了； 如果这个消息发送成功了，那么接着执行本地事务，如果成功就告诉MQ发送确认信息，如果失败就告诉mq回滚消息； 如果发送了确认消息，那么此时B系统会接收到确认信息，然后执行本地事务； MQ会自动定时轮询所有prepared消息回调你的接口，问你这个消息是不是本地事务处理失败了，所有没发送确认消息的信息，是继续重试还是回滚？一般来说这里你就可以查下数据库之前本地事务是否执行，如果回滚了，那么这里也回滚吧。这个就是避免可能本地事务执行成功了，而确认消息却发送失败了。 这个方案里，要是系统B的事务失败了，那就重试，自动不断地重试直到成功，如果实在不行，那就针对重要的资金业务进行回滚，比如B系统本地回滚后，想办法通知系统A也回滚，或者是发送警报由人工来手工回滚和补偿 ​ 这个方案还是比较合适的，目前国内的互联网公司大部分都是这样设计。你可以使用RocketMQ，也可以使用其他消息队列封装一套类似的逻辑出来。 最大努力通知方案​ 这个方案的大概思路就是： 系统A本地事务执行完之后，发送个消息到MQ； 这里会有个专门消费MQ的最大努力通知服务，这个服务会消费MQ然后写入数据中记录下来，或者是放入个内存队列里，接着调用系统B的接口； 要是系统B执行成功就OK了，要是系统B执行失败了，那么最大努力同时服务就定时尝试重新调用系统B，反复N次，最后还是不行就放弃。 总结​ 基本上，一些特别严格的场景，用的是TCC来保证强一致性，例如严格要求资金绝对不能错的场景；其他的一些场景基于阿里的RocketMQ来实现分布式事务，例如一般的分布式事务场景，订单插入之后要调用库存服务更新库存，库存数据没有资金那么敏感，可以用可靠消息最终一致性方案。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何设计一个能抗住上万服务实例的注册中心]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F15%2F%E5%A6%82%E4%BD%95%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E8%83%BD%E6%8A%97%E4%BD%8F%E4%B8%8A%E4%B8%87%E6%9C%8D%E5%8A%A1%E5%AE%9E%E4%BE%8B%E7%9A%84%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%2F</url>
    <content type="text"><![CDATA[​ 之前说过ZooKeeper和Eureka由于自己的特性，都不太适合支撑大规模的服务实例。Eureka是peer-to-peer模式，每台机器都是高并发请求的话会有瓶颈。而ZooKeeper是每次服务上下线，就会全量通知其他服务，导致网络宽带被打满，这也是一个瓶颈。具体可以查看服务注册中心的选型调研这篇文章。那么怎样才能实现一个能抗住上万服务实例的注册中心呢？ ​ 目前大公司的服务注册中心为了能支撑大规模的服务实例，基本都是自研服务注册中心。基本的思路就是实现一个分布式服务注册中心。主要设计逻辑包括：分片存储服务注册表、支持横向扩容、每台机器均摊高并发请求、各个服务主动拉取注册表信息，避免方向通知网卡被打爆等等。 ​ 简单的原理图如下所示：]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zuul-实现动态路由]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F13%2FZuul-%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E8%B7%AF%E7%94%B1%2F</url>
    <content type="text"><![CDATA[​ 一般情况下，Zuul需要在配置文件里写好路由信息，这样zuul才可以通过这些路由信息根据连接转发到相应的服务上去。但每增加一个服务，就需要停下网关去重新编写配置文件，这样就比较麻烦了。因此，就有人提出了动态路由的方法。 ​ 动态路由有很多方式实现，这里主要讲一下用数据库去实现动态路由。 ​ 首先，先创建一个表，用于存储路由信息： 1234567891011CREATE TABLE `gateway_api_route` ( `id` varchar(50) NOT NULL, `path` varchar(255) NOT NULL, `service_id` varchar(50) DEFAULT NULL, `url` varchar(255) DEFAULT NULL, `retryable` tinyint(1) DEFAULT NULL, `enabled` tinyint(1) NOT NULL, `strip_prefix` int(11) DEFAULT NULL, `api_name` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 ​ 该表结构主要是按照Zuul的ZuulProperties.ZuulRoute类设计的： ​ 插入一条数据，方便测试： 1INSERT INTO gateway_api_route (id, path, service_id, retryable, strip_prefix, url, enabled) VALUES ('order-service', '/order/**', 'order-service',0,1, NULL, 1); ​ 然后编写表gateway_api_route相应的实体类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class GatewayApiRoute &#123; private String id; private String path; private String serviceId; private String url; private boolean stripPrefix = true; private Boolean retryable; private Boolean enabled; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getPath() &#123; return path; &#125; public void setPath(String path) &#123; this.path = path; &#125; public String getServiceId() &#123; return serviceId; &#125; public void setServiceId(String serviceId) &#123; this.serviceId = serviceId; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; public boolean isStripPrefix() &#123; return stripPrefix; &#125; public void setStripPrefix(boolean stripPrefix) &#123; this.stripPrefix = stripPrefix; &#125; public Boolean getRetryable() &#123; return retryable; &#125; public void setRetryable(Boolean retryable) &#123; this.retryable = retryable; &#125; public Boolean getEnabled() &#123; return enabled; &#125; public void setEnabled(Boolean enabled) &#123; this.enabled = enabled; &#125; &#125; ​ 接下来就开始编写动态路由的实现逻辑，其实基本逻辑就是从数据库里取出路由数据，然后封装成ZuulProperties.ZuulRoute。主要代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889package com.zhss.demo.zuul.gateway;import org.springframework.beans.BeanUtils;import org.springframework.cloud.netflix.zuul.filters.RefreshableRouteLocator;import org.springframework.cloud.netflix.zuul.filters.SimpleRouteLocator;import org.springframework.cloud.netflix.zuul.filters.ZuulProperties;import org.springframework.jdbc.core.BeanPropertyRowMapper;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.util.StringUtils; import java.util.LinkedHashMap;import java.util.List;import java.util.Map;public class DynamicRouteLocator extends SimpleRouteLocator implements RefreshableRouteLocator &#123; private JdbcTemplate jdbcTemplate; private ZuulProperties properties; public void setJdbcTemplate(JdbcTemplate jdbcTemplate) &#123; this.jdbcTemplate = jdbcTemplate; &#125; public DynamicRouteLocator(String servletPath, ZuulProperties properties) &#123; super(servletPath, properties); this.properties = properties; &#125; @Override public void refresh() &#123; doRefresh(); &#125; @Override protected Map&lt;String, ZuulProperties.ZuulRoute&gt; locateRoutes() &#123; LinkedHashMap&lt;String, ZuulProperties.ZuulRoute&gt; routesMap = new LinkedHashMap&lt;String, ZuulProperties.ZuulRoute&gt;(); // 加载application.yml中的路由表 routesMap.putAll(super.locateRoutes()); // 加载db中的路由表 routesMap.putAll(locateRoutesFromDB()); // 统一处理一下路由path的格式 LinkedHashMap&lt;String, ZuulProperties.ZuulRoute&gt; values = new LinkedHashMap&lt;&gt;(); for (Map.Entry&lt;String, ZuulProperties.ZuulRoute&gt; entry : routesMap.entrySet()) &#123; String path = entry.getKey(); if (!path.startsWith("/")) &#123; path = "/" + path; &#125; if (StringUtils.hasText(this.properties.getPrefix())) &#123; path = this.properties.getPrefix() + path; if (!path.startsWith("/")) &#123; path = "/" + path; &#125; &#125; values.put(path, entry.getValue()); &#125; System.out.println("路由表：" + values); return values; &#125; private Map&lt;String, ZuulProperties.ZuulRoute&gt; locateRoutesFromDB() &#123; Map&lt;String, ZuulProperties.ZuulRoute&gt; routes = new LinkedHashMap&lt;&gt;(); List&lt;GatewayApiRoute&gt; results = jdbcTemplate.query( "select * from gateway_api_route where enabled = true ", new BeanPropertyRowMapper&lt;&gt;(GatewayApiRoute.class)); for (GatewayApiRoute result : results) &#123; if (StringUtils.isEmpty(result.getPath()) ) &#123; continue; &#125; if (StringUtils.isEmpty(result.getServiceId()) &amp;&amp; StringUtils.isEmpty(result.getUrl())) &#123; continue; &#125; ZuulProperties.ZuulRoute zuulRoute = new ZuulProperties.ZuulRoute(); try &#123; BeanUtils.copyProperties(result, zuulRoute); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; routes.put(zuulRoute.getPath(), zuulRoute); &#125; return routes; &#125; &#125; 然后在新建一个配置类DynamicRouteConfiguration 12345678910111213141516171819202122232425262728package com.zhss.demo.zuul.gateway;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.web.ServerProperties;import org.springframework.cloud.netflix.zuul.filters.ZuulProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.core.JdbcTemplate; @Configurationpublic class DynamicRouteConfiguration &#123; @Autowired private ZuulProperties zuulProperties; @Autowired private ServerProperties server; @Autowired private JdbcTemplate jdbcTemplate; @Bean public DynamicRouteLocator routeLocator() &#123; DynamicRouteLocator routeLocator = new DynamicRouteLocator( this.server.getServletPrefix(), this.zuulProperties); routeLocator.setJdbcTemplate(jdbcTemplate); return routeLocator; &#125; &#125; 这样就差不多，最后再实现一个定时器，定时刷新路由信息： 1234567891011121314151617181920212223242526272829package com.zhss.demo.zuul.gateway;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.cloud.netflix.zuul.RoutesRefreshedEvent;import org.springframework.cloud.netflix.zuul.filters.RouteLocator;import org.springframework.context.ApplicationEventPublisher;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.annotation.EnableScheduling;import org.springframework.scheduling.annotation.Scheduled;import org.springframework.stereotype.Component;@Component@Configuration @EnableScheduling public class RefreshRouteTask &#123; @Autowired private ApplicationEventPublisher publisher; @Autowired private RouteLocator routeLocator; @Scheduled(fixedRate = 5000) private void refreshRoute() &#123; System.out.println("定时刷新路由表"); RoutesRefreshedEvent routesRefreshedEvent = new RoutesRefreshedEvent(routeLocator); publisher.publishEvent(routesRefreshedEvent); &#125; &#125; 这样一个基于zuul的动态路由功能就完成了，代码跑起来后，可以看到定时器在工作，定数刷新路由信息：]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eureka的一些参数配置优化]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F13%2FEureka%E7%9A%84%E4%B8%80%E4%BA%9B%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ Eureka的默认配置是比较糟糕的，一般服务的上线和下线极端情况下需要一分多钟才能感知到，服务故障极端情况下需要两到三分钟才能感知到，这相对于ZooKeeper的秒级感知来说实在是太慢了。因此我们可以通过修改Eureka的一些配置参数来达到秒级通知的效果。 Eureka-Server端的配置eureka.server.responseCacheUpdateIntervalMs​ 这个参数表示的是Eureka中ReadWriteCacheMap的缓存数据多久会更新到ReadOnlyCacheMap中去，应为Eureka-Client是从ReadOnlyCacheMap拉取数据的。这个参数默认是30秒更新一次ReadOnlyCacheMap，我们可以改为3秒更新一次：eureka.server.response-cache-update-interval-ms = 3000 eureka.server.evictionIntervalTimerInMs​ 这个参数表示的是Eureka-Server中的缓存数据每隔多少秒主动失效。默认是60秒主动清空服务列表，我们可以改为6秒：eureka.server.eviction-interval-timer-in-ms = 6000 eureka.instance.leaseExpirationDurationInSeconds​ 服务过期时间配置，超过这个时间没有接收到心跳就会认为该服务实例已经挂了。并将该服务实例从注册表中剔除掉。默认情况下是90秒，我们可以设置为9秒：eureka.instance.lease-expiration-duration-in-seconds = 9 Eureka-Client端的配置eureka.client.registryFetchIntervalSeconds​ 这个参数表示的是Eureka-Client拉取数据，刷新本地缓存的时间，默认是每30秒拉取一次数据，我们可以将速度提高10倍，改为3秒：eureka.client.registry-fetch-interval-seconds = 3 eureka.instant.leaseRenewalIntervalInSeconds​ 这个参数表示的是Eureka-Client每隔多久发送一次心跳，默认是30秒发送一次心跳到Eureka-Server上。我们可以改成3秒：eureka.instant.lease-renewal-interval-in-seconds = 30]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务注册中心的选型调研]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F11%2F%E6%9C%8D%E5%8A%A1%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E7%9A%84%E9%80%89%E5%9E%8B%E8%B0%83%E7%A0%94%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 目前市场上使用最多的服务注册中心应该是Eureka和Zookeeper，当然Consul和Nacos，也在慢慢崛起。本文主要从集群模式、一致性保障、时效性和容量这几个角度来讨论Eureka和ZooKeeper的区别。 服务注册发现的集群模式Eureka​ Eureka的集群模式，简单地说就是peer-to-peer。部署一个集群，但是集群里每个机器的地位是对等的，各个服务可以向任何一个Eureka实例进行服务注册和发现，集群里的任何一个Eureka实例收到请求后，会自动同步给其他所有的Eureka实例。除了注册信息，服务发送的心跳信息也会同步到其他Eureka实例上。如图所示： ZooKeeper​ ZooKeeper的集群模式，简单就是Leader+Follower，其中只有Leader可以负责写，即服务注册，领完，它还负责把数据同步给Follow。服务发现的时候，Leader/Follow都可以读。 一致性保障：CP or AP​ CAP原则包含如下三个元素： C（Consistency）：一致性。在分布式系统中的所有数据备份，在同一时刻具有同样的值，所有节点在同一时刻读取的数据都是最新的数据副本。 A（Availability）：可用性。好的相应性能。完全的可用性指的是在任何故障模型下，服务都会在有限的时间内处理完成并进行相应。 P（Partition tolerance）：分区容错性。尽管网络上有部分消息丢失，但系统仍然可以继续工作。 CAP原理证明，任何分布式系统只可同时满足以上两点，无法三者兼顾。由于关系型数据库是单节点无复制的，因此不具有分区容忍性，但是具有一致性和可用性；而分布式的服务化系统都需要满足分区容忍性，那么我们必须在一致性和可用性之间进行权衡。 Eureka​ Eureka是AP模式的，即它牺牲了一致性，而实现可用性和分区容错性。因为Eureka是peer-to-peer模式，可能数据还没有同步互过去，自己就挂掉了，但服务实例依然可以从别的Eureka实例上拉去注册表，但是看到的数据就不是最新的收据了。但Eureka保证了最终一致性。例如服务A除了注册服务之外还会发送心跳信息，当服务A发现Eureka1实例挂掉之后，会向另一个活着的Eureka2实例发送心跳信息，Eureka2就能感知到服务A的存在并更新注册表的数据，从而实现最终一致性。 ZooKeeper​ ZooKeeper是CP模式的。ZooKeeper是有一个Leader节点会接收数据，然后同步其他节点，一旦Leader挂掉了，就要重新选举Leader，这个过程为了一致性，就会牺牲看可用性，会不可用一段时间，那么就可以继续写数据了，保证了一致性。即ZooKeeper是同步数据期间和Leader选举期间，都处于不可用阶段，等结束之后就可以继续使用，但这样却保证了强一致性。 服务注册发现的时效性​ ZooKeeper的时效性更好，注册或者是挂了，一般秒级就能感知到。 ​ Eureka，默认配置非常糟糕。服务发现感知要到几十秒，甚至分钟级别。上线一个新的服务，到其他服务可以发现它，极端情况下可能要一分钟的时间。（30秒ReadWriteCache更新ReadOnlyCacheMap数据，再30秒服务实例去拉取ReadOnlyCacheMap的数据）。 ​ 在默认情况下，服务故障，隔60秒才去检查心跳，发现这个服务上一次心跳是在30秒之前。在隔60秒去检查心跳，超过90秒没有心跳，才会认为这个服务已经挂了，这样子就已经过去两分钟了。 ​ 因此极端情况下，你的服务挂掉了，到其他服务感知到，可能需要两三分钟时间，比较漫长。 容量​ Eureka很难支撑大规模的服务实例，因为每个Eureka实例都要接受所有服务的注册请求信息和心跳信息，实例多了压力太大扛不住，很难做到几千服务实例。比如服务实例太多，达到上千个，每秒钟的有上千个心跳信息，那要同时同步到其余心跳信息。压力会比较大。 ​ ZooKeeper同样不适合大规模的服务实例，因为服务上线的时候，需要瞬间推送数据通知到所有的其他服务实例，所以一旦服务规模太大，到了几千个服务实例的时候，会导致网络带宽被大量占用。]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>服务注册</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringCloud常用组件原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F11%2FSpringCloud%E5%B8%B8%E7%94%A8%E7%BB%84%E4%BB%B6%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[​ Spring Cloud是一个全家桶式的技术栈，包含了很多组件。本文主要简单介绍下最核心的几个组件的底层原理。包括Eureka、Ribbon、Feign、Hystrix和Zuul这几个组件。 业务场景介绍​ 文章先假定一个业务场景：现在开发一个电商系统，要实现支付订单的功能，流程如下： 创建一个订单之后，如果用户立刻支付了这个订单，我们需要将订单状态更新为“已支付” 扣减相应的商品库存 通知仓储中心，进行发货 给用户的这次购物增加相应的积分 针对上述流程，我们需要有订单服务、库存服务、仓储服务、积分服务。整个流程的大体思路如下： 用户针对一个订单完成支付之后，就会去找订单服务，更新订单状态 订单服务调用库存服务，完成相应功能 订单服务调用仓储服务，完成相应功能 订单服务调用积分服务，完成相应功能 如图所示： SpringCloud核心组件：Eureka​ Eureka是微服务架构中的注册中心，主要功能是服务注册与发现和心跳检测与故障。在上述场景中，订单服务不知道其他其他服务在哪台机器上，此时就需要一个注册中心，来管理各个服务的地址，如图所示： ​ 如上图所示，所有服务都有一个Eureka Client组件，这个组件专门负责将这个服务的信息注册到Eureka Server中，也就相当于告诉了Eureka Server自己在哪台服务器上，监听这哪个端口。而Eureka中维护了一个注册表，保存着各个服务的机器和端口号。 ​ 新增服务、下线服务都是直接操作Eureka-Server的注册表的，而注册表变更时为了并发安全是会加锁操作的（使用ReentrantReadWriteLock）然后注册表一变更，立刻清楚掉ReadWrite缓存的数据，并重新写入新数据。服务从ReadOnlyCache上拉取服务 ，并缓存到本地。而Eureka-Server采用两个缓存，是为了避免并发冲突。 ​ 假设没有ReadOnlyCacheMap，万一刚好注册表发生变更的时候，ReadWriteCacheMap会被失效掉，所以客户端的请求也就直接来读注册表了，会涉及到锁的操作，弄了个ReadOnlyCacheMap可以大大减少锁操作发生的概率。 ​ 假设没有ReadWriteCacheMap，那么ReadOnlyCacheMap每隔30秒刷新的时候就只能跟注册表比较了，如果此时注册表也发生了变更，也会涉及到锁的操作，因为ReadWriteCacheMap的存在（因为ReadWriteCacheMap是每隔180秒才会主动失效一次）也可以大大减少这个锁操作发生的概率。 ​ 除了服务注册与发现之外，Eureka还有检测心跳的功能，以此来判断那台机器出现故障。Eureka-Client默认每30秒想Eureka发送一次心跳，而Eureka-Server会有专门的线程来检测心跳。 ​ 总结一下：Eureka拥有服务注册与发现、心跳检测与故障等功能。其中： Eureka-Client：负责将这个服务的信息注册到Eureka Server中 Eureka-Server：注册中心，里面有注册表和两个缓存，保存了各个服务所在的机器和端口。 SpringCloud核心组件：Feign​ 通过Eureka我们知道了各个服务在哪里，但如何向其他服务发起请求呢，这个就是Feign的作用。如下所示： 1234567@Component@FeignClient("tensquare-user")public interface UserClient &#123; @RequestMapping(value = "/user/incfollow/&#123;userid&#125;/&#123;x&#125;", method = RequestMethod.POST) public void incFollowcount(@PathVariable("userid")String userid, @PathVariable("x") int x);&#125; ​ 通过使用Feign，直接就是用注解定义一个FeignClient接口，然后调用那个接口就可以了，FeignClient会在底层根据你的注解，跟你指定的服务建立连接、构造请求、发起请求、获取响应、解析响应等等。 ​ 而Feign之所以能实现这些功能，关键的机制是使用了动态代理。我们根据下图来分析： 首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理 接着你要是调用按个接口，本质上就是调用Feign创建的动态代理，这是核心中的核心 Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的地址。 最后针对这个地址，发起请求，解析响应 SpringCloud核心组件：Ribbon​ 如果库存系统部署子在了五台机器上，Feign怎么知道该请求哪台机器呢。这时SpringCloud Ribbon就派上永昌路 。它的作用是负载均衡，会帮你在每次请求时选择一台机器，均匀的把请求分发到各个机器上。 ​ Ribbon的负载均衡默认使用的是Round Robin轮询算法。就是说如果订单服务对库存系统发起10次请求，那就先让你请求第1台机器。然后是第2台、第3台，第4、第5，然后再来一个循环，第1、第2。。。以此类推。 ​ 此外，Ribbon和Feign以及Eureka紧密协作而完成工作的，具体如下： 首先Ribbon会从Eureka-Client获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口。 然后Ribbon就可以使用默认的Round Robin算法，从中选择一台。 Feign就会针对这台机器，构造并发起请求。 SpringCloud核心组件：Hystrix​ 在微服务架构里，一个系统会有很多的服务，以本文的业务场景为例：订单服务在一个业务流程里需要调用三个服务。现在假设订单服务有100个线程可以处理请求，然后积分服务不幸挂了，每次订单服务调用积分服务的时候，都会卡住几秒，然后抛出一个超时异常。这样会导致几个问题： 1、如果系统处于高并发的场景下，大量请求涌过来的时候，订单服务的100个线程都会卡在请求积分这块，导致订单服务没有一个线程可以处理请求。 2、然后就会导致别人请求订单服务的时候，发现订单服务也挂了，不响应任何请求了。 这就是微服务架构中的服务雪崩问题。这么多服务互相调用，要是不做任何保护的话，某一个服务挂了，就会引起连锁反应，导致别的服务也挂了。 ​ 但就算积分系统挂了，订单服务也可以不用挂啊。结合业务来看，支付订单的时候，只要把库存减了，然后通知仓库发货就可以了；如果积分系统挂了，大不了恢复之后，再手工恢复数据，不应该因为一个积分服务挂了，就直接导致订单服务也挂了。 ​ 这个时候就要使用Hystrix了。Hystrix是隔离、熔断以及降级的一个框架。就是Hystrix会搞很多个小小的线程池，例如订单服务请求库存服务是一个线程池，请求仓储服务是一个线程池，请求积分服务是一个线程池，每个线程池里的线程就仅仅用于请求哪个服务。 ​ 比如积分系统挂了，会导致订单服务里的那个调用积分服务的线程都卡死不能工作了，但是由于订单服务调用库存系统、仓储系统的这两个线程池都是正常工作的，所以这两个服务不会受到任何影响。 ​ 这个时候如果别人请求订单服务，订单服务还是可以正常调用库存服务扣减库存，调用仓储服务通知发货。只不过调用积分服务的时候，每次都会报错。但是如果积分服务都挂了，每次调用都要去卡住几秒钟干啥呢？有意义吗？当然没有！所以我们直接对积分服务熔断不就得了，比如在5分钟内请求积分服务直接就返回了，不要去走网络请求卡住几秒钟，这个过程，就是所谓的熔断！ ​ 而且积分系统挂了，我们还可以来个降级：每次调用积分服务，你就在数据库里记录一条消息，说给某某用户增加了多少积分，因为积分服务挂了，导致没增加成功！这样等积分服务恢复了，你可以根据这些记录手工加一下积分。这个过程，就是所谓的降级。 SpringCloud的核心组件：Zuul​ 说完了Hystrix，接着给大家说说最后一个组件：Zuul，也就是微服务网关。这个组件是负责网络路由的。不懂网络路由？行，那我给你说说，如果没有Zuul的日常工作会怎样？ ​ 假设你后台部署了几百个服务，现在有个前端兄弟，人家请求是直接从浏览器那儿发过来的。打个比方：人家要请求一下库存服务，你难道还让人家记着这服务的名字叫做inventory-service？部署在5台机器上？就算人家肯记住这一个，你后台可有几百个服务的名称和地址呢？难不成人家请求一个，就得记住一个？你要这样玩儿，那真是友谊的小船，说翻就翻！ ​ 上面这种情况，压根儿是不现实的。所以一般微服务架构中都必然会设计一个网关在里面，像android、ios、pc前端、微信小程序、H5等等，不用去关心后端有几百个服务，就知道有一个网关，所有请求都往网关走，网关会根据请求中的一些特征，将请求转发给后端的各个服务。 ​ 而且有一个网关之后，还有很多好处，比如可以做统一的降级、限流、认证授权、安全，等等。 总结最后再来总结一下，上述几个Spring Cloud核心组件，在微服务架构中，分别扮演的角色： Eureka：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里 Ribbon：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台 Feign：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求 Hystrix：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题 Zuul：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务]]></content>
      <categories>
        <category>分布式</category>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM内存区域]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F09%2FJVM%E5%86%85%E5%AD%98%E5%8C%BA%E5%9F%9F%2F</url>
    <content type="text"><![CDATA[JVM内存布局 存放类的方法区​ 这个方法区是在JDK1.8以前的版本里，代表JVM中的一块区域。主要是放从“.class”文件里加载进来的类，还会有一些类似常量池的东西放在这个区域。JDK1.8以后，这个区域改了名字，叫“Metaspace”，也叫“元空间”。 ​ 还是拿之前的代码举例，如下： 123456public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); &#125;&#125; ​ 这两个类加载后，就会放在这个方法区中， 执行代码指令用的程序计数器​ 假设我们的代码是这样： 1234567public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125; ​ 实际上这段代码先存在于“.java”后缀的文件里，但为了能让计算机看懂这段代码，需要将这个文件经过编译器编译，把“.java”后缀的源文件编译为“.class”后缀的字节码文件。这个“.class”后缀的字节码文件里，存放的就是编译好的字节码了，字节码才是计算机可以理解的一种语言。字节码大概如下： ​ 所以首先明白一点：我们写好的Java代码会被翻译成字节码，对应各种字节码指令 ​ 现在Java代码通过JVM跑起来的第一件事情就确定了，首先Java代码被编译成字节码指令，然后字节码指令一定会被一条一条地执行，这样才能实现我们写好的代码执行的效果。当JVM加载类信息到内存之后，实际就会使用自己的字节码执行引擎，去执行我们写的代码编译出来的代码指令，那么在执行字节码指令的时候，JVM就需要一个特殊的内存区域，“程序计数器”。它是用来记录当前的字节码指令位置的，也就是记录目前执行到了哪一条字节码指令。 ​ JVM是支持多个线程的，所以你写好的代码可能会开启多个线程并发执行不同的代码，所以就会有各个线程来并发的执行不同的代码指令，因此每个线程都会有自己的一个程序计数器，专门记录当前这个线程目前执行到了哪一条字节码指令。 Java虚拟机栈​ Java代码在执行的时候，一定是线程来执行某个方法中的代码，即使是下面的代码，也会有一个main线程来执行main()方法里的代码。在main线程执行main()方法的代码指令的时候，就会通过main线程对应的程序计数器记录自己执行的指令位置。 1234567public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125; ​ 但在方法里，一般会定义一些方法内的局部变量，例如上面的代码中就有一个“replicaManager”局部变量。因此JVM必须有一块保存每个方法内的局部变量等数据的，这个区域就是Java虚拟机栈。每个线程都有自己的Java虚拟机栈，比如这里的main线程就会有自己的一个Java虚拟机栈，用来存放自己执行的那些方法的局部变量。 ​ 如果线程执行了一个方法，就会对这个方法调用创建对应的一个栈帧。栈帧就有这个方法的局部变量表、操作数栈。动态链接、方法出口等信息。 ​ 比如main线程执行了main()方法，那么就会给main()方法创建一个栈帧，压入main线程的Java虚拟机栈，同时在main()方法的栈帧里，存放对应的“replicaManager”局部变量。 ​ 然后假设main()线程继续执行ReplicaManager对象里的方法，比如下面，就在“loadReplicasFromDisk”方法里定义了一个局部变量：“hasFinishedLoad”。 123456public class ReplicaManager &#123; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; &#125;&#125; ​ 那么main线程执行上面的“loadReplicasFromDish”方法时，就会为“loadReplicasFromDish”方法创建一个栈帧压入线程自己的Java虚拟机栈里面去。 ​ 接着如果“loadReplicasFromDish”方法调用了另外一个“isLocalDataCorrupt()”方法，这个方法里也有自己的局部变量，如下： 123456789101112131415public class ReplicaManager &#123; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; if(isLocalDataCorrupt()) &#123; &#125; &#125; public Boolean isLocalDataCorrupt() &#123; Boolean isCorrupt = false; return isCorrupt &#125;&#125; ​ 这个时候会给“isLocalDataCorrupt”方法又创建一个栈帧，压入线程的Java虚拟机里，而且“isLocalDataCorrupt”方法的栈帧的局部变量表里会有一个“isCorrupt”变量，这个“isLocalDataCorrupt”的局部变量，整个过程如下： ​ 接着如果“isLocalDataCorrupt”方法执行完毕，就会把“isLocalDataCorrupt”方法对应的栈帧从Java虚拟机栈里出栈；然后如果“loadReplicasFromDisk”方法也执行完毕，就会把“loadReplicasFromDisk”方法也从Java虚拟机栈里出栈、 ​ “JAVA虚拟机栈”这个组件的作用：调用执行任何方法时，都会给方法创建栈帧然后入栈，在栈帧里存放了这个方法对应的局部变量之类的数据，包括这个方法执行的其他相关信息，方法执行完毕之后出栈。 Java堆内存​ Java堆主要是存放我们在代码中创建的各种对象。 1234567public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125; ​ 上面的“new ReplicaManager()”这个代码就是创建了一个ReplicaManager类的对象实例，这个对象实例里面会包含一些数据，如下代码所示：这个“ReplicaManager”类里的“replicaCount”就是属于这个对象实例的一个数据。而类似ReplicaManager这样的对象实例就会存放在Java堆内存里。 12345678910111213141516public class ReplicaManager &#123; private long replicaCount; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; if(isLocalDataCorrupt()) &#123; &#125; &#125; public Boolean isLocalDataCorrupt() &#123; Boolean isCorrupt = false; return isCorrupt &#125;&#125; ​ Java堆内存区域里会放入类似ReplicaManager的对象，然后我们因为在main方法里创建了ReplicaManager对象，那么在线程执行main方法代码的时候，就会在main方法对应的栈帧的局部变量表里，让一个引用类型的“replicaManager”局部变量来存放ReplicaManager对象的地址。 ​ 相当于你可以认为局部变量表的“replicaManager”指向了Java堆内存里的ReplicaManager对象。 核心内存区域的全流程串讲​ 123456789101112131415161718192021222324public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); replicaManager.loadReplicaFromDish(); &#125;&#125;public class ReplicaManager &#123; private long replicaCount; public void loadReplicasFromDish() &#123; Boolean hasFinishedLoad = false; if(isLocalDataCorrupt()) &#123; &#125; &#125; public Boolean isLocalDataCorrupt() &#123; Boolean isCorrupt = false; return isCorrupt &#125;&#125; ​ 首先，你的JVM进程会启动，就会先加载Test类到内存里，然后有一个main线程，开始执行你的Test中的main()方法。main线程是关联了一个程序计数器的，他执行到哪一行指令，就会记录在这里。 ​ 其次，就是main线程执行main()方法的时候，会在main线程相关的Java虚拟机栈里，压入一个main()方法的栈帧，接着会发现需要创建一个ReplicaManager类的实例对象，此时会加载ReplicaManager类到内存里来。 ​ 然后会创建一个ReplicaManager的对象实例分配在堆内存里，并且在main()方法的栈帧里的局部变量表引入一个“replicaManager”变量，让他引用ReplicaManager对象在Java堆内存中的地址。 ​ 接着，main线程开始执行ReplicaManager对象中的方法，会依次把自己执行到的方法对应的栈帧压入自己的Java虚拟机栈。 ​ 执行完方法之后再把方法对应的栈帧从Java虚拟机栈里出栈。 其他内存区域​ 在JDK很多底层API里，比如IO相关、网络Socket相关的，很多地方都不是JAVA代码了，而是走的native方法去调用本地操作系统里面的一些方法，可能调用的都是C语言写的方法，或者一些底层类库。在调用这种native方法时，就会有线程对应的本地方法栈，这个跟Java虚拟机栈类似的，也是存放各种native方法的局部变量表之类的信息。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM类加载机制]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F07%2FJVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 JVM什么情况下会加载一个类​ 首先，我们应该清楚一个类从加载到使用，一般会经过加载–&gt;链接–&gt;初始化–&gt;使用–&gt;卸载这几个过程，其实链接阶段又可以细分为三个：验证–&gt;准备–&gt;解析。所以首先要明白的一个问题就是，JVM在执行我们代码的时候，什么时候去加载一个类呢？即什么时间会从“.class”字节码文件中加载这个类到JVM内存中？ ​ 答案就是你的代码中用到这个类的时候。 ​ 比如下面有一个类，里面有一个“main()”方法作为入口，那么一旦你的JVM进程启动之后，它一定会先把这个类加载到内存里，然后从main()方法入口的代码开始执行。 12345public class Test &#123; public static void main(String[] args) &#123; &#125;&#125; 接着上面的代码中，出现了这么一行代码： 123456public class Test &#123; public static void main(String[] args) &#123; ReplicaManager replicaManager = new ReplicaManager(); &#125;&#125; 这个时候，你的代码中明显需要使用“ReplicaManager”这个对象，因此会从“ReplicaManager.class”字节码中加载对应的类到内存中使用。 简单概括就是：首先你的代码中包含“main()”方法的主类一定会在JVM启动后加载到内存中，开始执行你的“main()”方法中的代码，接着遇到你使用了别的类，此时就会从对应的“.class”字节码文件中加载对应的类到内存里来。 从使用角度出发，来看验证、准备和初始化的过程1、验证阶段​ 简单来说，这一步即使根据JAVA虚拟机规范，来检验你加载进来的“.class”文件中的内容，是否符合指定的规范。 2、准备阶段​ 一般情况下，我们写好的类，都有一些类变量，如下： 1234public class ReplicaManager &#123; public static int flushInterval;&#125; ​ 假设有这么一个类“ReplicaManager”，它的“ReplicaManager.class”，刚被加载到内存之后，会被进行验证，确认这个验证码是符合规范的。接着就会进行准备工作。这个准备工作，就是给这个“ReplicaManager”类分配一定的内存空间，然后给他里面的类变量（也就是static修饰的变量）分配内存空间，来一个默认的初始值。比如上面的“flushInterval”这个类变量分配的内存空间，会给一个“0”初始值。 3、解析阶段​ 这个阶段，实际上就是把符合引用替换为直接引用的过程 4、三个阶段的小结​ 这三个阶段中，最核心的就是“准备阶段”，这个阶段是给加载进来的类分配好了内存空间，类变量也分配好了内存空间，并且给了默认的初始值。 核心阶段：初始化​ 上面说过，在准备阶段，会把我们的“ReplicaManager”类给分配好内存空间。另外的一个类变量“flushInterval”也会给一个默认的初始值“0”。那么接下来，在初始化阶段，就会正式执行我们的类初始化的代码了。 ​ 那什么是类初始化代码呢？看看以下代码 12345public class ReplicaManager &#123; public static int flushInterval = Configuration.getInt("replica.flush.interval");&#125; 通过以上代码我们可以知道，这个类变量，我们是通过Configuration.getInt(“replica.flush.interval”)这段代码来获取一个值，并且赋值给他的。但是这个赋值逻辑并不在准备阶段执行，在准备阶段，仅仅是给这个类变量开辟一个内存空间，然后给个初始值“0”而已。 ​ 而这段赋值的代码，则是在“初始化”阶段来执行。在该阶段，代码Configuration.getInt(“replica.flush.interval”)会在这里执行，完成一个配置项的读取，然后赋值给这个类变量“flushInterval”。 另外比如下面的static静态代码块，也会在这个阶段执行。 123456789101112131415public class ReplicaManager &#123; public static int flushInterval = Configuration.getInt("replica.flush.interval"); private static Map&lt;String, Object&gt; replicas; static &#123; loadReplicaFromDish(); &#125; public static void loadReplicaFromDish() &#123; this.replicas = new HashMap&lt;String, Object&gt;(); &#125;&#125; 什么时候会初始化一个类​ 一般来说有一下时机：比如“new ReplicaManager()”来实例化类的对象，此时就会触发类的加载到初始化全过程，把这个类准备好，然后再实例化一个对象出来； ​ 或者是包含“main”方法的主类，必须是立马初始化的。 ​ 这里还有一个非常重要的规则，就是如果初始化一个类的时候，发现它的父类还没初始化，那么先必须初始化它的父类。 类加载器和双亲委派机制​ 上述的过程中，都必须依赖类加载器来实现，Java里主要有几种类加载器 1、启动类加载器（Bootstrap ClassLoader）​ 它主要负责加载我们机器上安装的java目录下的核心类，比如Object、System、String等。 2、扩展类加载器（Extension ClassLoader）​ 用于加载一些扩展的系统类，比如XML、加密、压缩相关的功能类等。JDK9之后变成了平台类加载器，即Platform ClassLoader。 3、应用类加载器（Application ClassLoader）​ 主要是加载用户定义的CLASSPATH路径下的类。 4、自定义类加载器​ 除了上面几种之外，还可以自定义类加载器，去根据你自己的需求加载你的类。 双亲委派机制​ 低层次的当前类加载器，不能覆盖更高层次类加载器已经加载的类。如果低层次的类加载器想加载一个未知类，要礼貌地向上级询问：“请问这个类已经加载了吗”？被询问的高层次类加载器会自问两个问题：第一，我是否已加载过此类？第二，如果没有，是否可以加载此类？只有当所有高层次类加载器在两个问题上的答案均为“否”时，才可以让当前类加载器加载这个未知类。 ​ 简单地讲，所谓的双亲委派模型：先找父亲去加载，不行的话再由儿子来加载。 最后总结]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo的负载均衡策略、集群容错策略和动态代理策略]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F07%2Fdubbo%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AD%96%E7%95%A5%E5%92%8C%E9%9B%86%E7%BE%A4%E5%AE%B9%E9%94%99%E7%AD%96%E7%95%A5%2F</url>
    <content type="text"><![CDATA[本节思维导图 dubbo的负载均衡策略random loadbalance​ 随机调用实现负载均衡。这是dubbo默认的负载均衡策略。可以对provider设置不同的权重，会按照权重来负载均衡，权重大分配流量越高。一般使用这个策略即可。 roundrobin loadbalance​ 均匀地将流量打到各个机器上，但如果各个机器性能不一样，容易导致性能差的机器负载过高，所以此时需要调整权重，让性能差的机器承载比较小的流量。 leastactive loadbalance​ 这个就是自动感知一下，某个机器的性能越差，接收的流量就越小，就越不活跃，此时就会给不活跃性能差的机器更小的请求。 consistentHash loadbalance​ 一致性哈希算法，相同参数的请求一定分发到一个provider上去，provider挂掉的时候，会基于虚拟节点均匀分配剩余的流量，抖动不会太大。如果你需要的不是随机负载均衡，是要一类请求都到一个节点，那就使用这个一致性哈希算法。 dubbo集群容错策略failover cluster模式失败自动切换，自动重试其他机器，默认使用这个，常见于读操作。（失败重试其他机器） 可以通过以下几种方式配置重试次数： 1&lt;dubbo:service retries="2" /&gt; 或者 1&lt;dubbo:reference retries="2" /&gt; 或者 123&lt;dubbo:reference&gt; &lt;dubbo:method name="findFoo" retries="2" /&gt;&lt;/dubbo:reference&gt; failfast cluster模式一次调用失败就立即失败，常用与非幂等性的写操作，比如新增一条记录（调用失败就立即失败） failsafe cluster模式出现异常时忽略掉，常用与不重要的接口调用，比如日志记录。 配置示例如下： 1&lt;dubbo:service cluster="failsafe" /&gt; failsafe cluster模式 或者 1&lt;dubbo:reference cluster="failsafe" /&gt; failback cluster模式失败了后台自动记录请求，然后定时重发，比较适合于写消息队列。 forking cluster模式并行调用多个provider，只要一个成功立即返回，常用于实时性要求比较高的读操作，但是会浪费更多的服务资源，可以通过forks=”2”来设置最大并行数。 broadcast cluster模式逐个调用所有的provider，任何一个provider出错则报错。通用用于通知所有provider更新缓存或日志等本地资源信息。 dubbo动态代理策略默认使用javassist动态字节码生成，创建代理类。但是可以通过spi扩展机制配置自己的动态代理策略。]]></content>
      <categories>
        <category>分布式</category>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo支持的通信协议、序列化协议以及hession的数据结构]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F06%2Fdubbo%E6%94%AF%E6%8C%81%E7%9A%84%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E3%80%81%E5%BA%8F%E5%88%97%E5%8C%96%E5%8D%8F%E8%AE%AE%E4%BB%A5%E5%8F%8Ahession%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[本节思维导图 dubbo支持的通信协议dubbo协议​ 默认就是走dubbo协议，单一长连接，进行的是NIO异步通信，基于hession作为序列化协议。使用的场景是：传输数据量小（每次请求在100kb以内），但是并发量高。 ​ 为了支持高并发场景，一般是服务提供者就几台机器，但是服务消费者有上百台，可能每天调用量达到上亿次，此时用长连接是最合适的，就是跟每个服务消费者维持一个长连接即可，可能总共就100个连接，然后后面直接基于长连接NIO异步通信，可以支撑高并发请求。 ​ 长连接，通俗讲就是建立连接后可以持续发送请求，无须再建立连接。 ​ 而短连接，每次要发送请求之前，需要先重新建立一次连接。 rmi协议​ 走JAVA二进制序列化，多个短连接，适合消费者和提供者数量差不多的情况，适用于文件的传输，一般较少用。 hession协议​ 走hession序列化协议，多个短连接，适用于提供者数量比消费者数量还多的情况，适用于文件传输，一般较少用。 http协议​ 走JSON序列化 webService​ 走SOAP文本序列化 dubbo支持的序列化协议​ dubbo默认的序列化协议是hession序列化协议，除此之外还支持java二进制协议、json和SOAP文本序列化等多种序列化协议。 hession数据结构​ hession的数据结构可以分为三类型：8种基本原始类型、3种递归类型和1中特殊类型 8种基本原始类型 原始二进制数据 64-bit date（64位毫秒值日期） 64-bit double 64–bit long 32-bit int boolean null UTF-8 编码的string 3种递归类型 list for lists and arrays map for maps and dictionaries object for objects 1种特殊类型 ref：用于表示对共享对象的引用 为什么PB的效率是最高的​ protocol buffer是Google出品的一种轻量并且高效的结构化数据存储格式，性能要比JSON和XML高得多。它性能高主要有两个原因：一是，它使用protocol编译器，自动进行序列化和反序列化，速度非常快，差不多比XML和JSON快上了20~100倍；第二，它的数据压缩效果好，它序列化后的数据量体积小，因为体积小，传输起来带宽和速度上会有优化。]]></content>
      <categories>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的缓存穿透、缓存击穿、缓存雪崩、热点数据失效问题及解决方案]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F05%2FRedis%E7%9A%84%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F%E3%80%81%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E3%80%81%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%83%AD%E7%82%B9%E6%95%B0%E6%8D%AE%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ 在我们的平常的项目中多多少少都会使用到缓存，因为一些数据我们没有必要每次查询的时候都去查询到数据库。特别是高 QPS 的系统，每次都去查询数据库，对于你的数据库来说将是灾难。但缓存使用不当，也会引起灾难。 缓存穿透什么是缓存穿透​ 正常情况下，我们去查询的数据都是存在。但如果请求去查询一条数据库根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。这种查询不存在数据的现象称为缓存穿透。 缓存穿透带来的问题​ 如果有黑客对你的系统进行攻击，拿一个不存在的id 去查询数据，会产生大量的请求到数据库中，可能会导致你的数据库由于压力太大而宕机。 解决方案1、缓存空值​ 之所以会穿透，是因为缓存中没有存储这些空数据的key，从而导致每次查询都到数据库去了。因此我们可以为这些key对应的值设置null丢到缓存里面去，后面再出现查询这个key的请求的时候，就直接返回null。不过要设置过期时间。 2、布隆过滤器​ 这种方式在大数据场景应用比较多，比如Hbase中使用它去判断数据是否在磁盘上，还有在爬虫场景判断URL是否已经被爬取。 ​ 这种方案可以加在第一种方案中，在缓存之前再加一层布隆过滤器，在查询的时候先去布隆过滤器查询key是否存在，如果不存在就直接返回，存在再走查缓存和数据库。 3、用户鉴权​ 这种情况有可能是黑客进行恶意攻击，因此我们可以在系统中增加用户鉴权校验或者在接口层增加校验，直接拦截不正常的请求。 方案选择​ 对于一些恶意攻击，攻击带过来的大量的key是不存在的，那么我们采用第一种方案就会缓存大量不存在key的数据，此时第一种方案就不合适了，我们可以先使用第二种方案过滤掉这些key。即针对这种key异常多、请求重复率比较低的数据，我们没有必要进行缓存，使用第二种方案直接过滤掉。 缓存击穿什么是缓存击穿​ 在平常高并发的系统中，大量的请求同时查询一个key时，此时这个key刚好失效了，就会导致大量的请求打到数据库上面去，这种现象我们成为缓存击穿。 缓存击穿带来的问题​ 会造成某一时刻数据库请求里过大，压力剧增。 解决方案1、设置热点数据永不过期2、加互斥锁​ 多个线程同时去查询数据库的这条数据时，我们可以在第一个查询数据的请求上使用一个互斥锁来锁住它，其他线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来了，就可以直接走缓存了。 缓存雪崩什么是缓存雪崩​ 缓存雪崩的情况是，在某一时刻发生大规模的缓存失效的情况，比如你的缓存服务宕机了，会有大量的请求进来直接打到DB上。结果就是DB撑不住宕机了。 解决方案1、事前，使用集群缓存，保证缓存服务的高可用​ 这种方案是在发生雪崩前对缓存集群实现高可用，如果是使用Redis，可以使用 主从+哨兵或者Redis Cluster来避免Redis全盘崩溃的情况。 2、事中：ehcache本地缓存 + Hystrix限流&amp;降级，避免数据库被打死​ 使用ehcache本地缓存的目的也是考虑在Redis Cluster完全不可用的时候，ehcache本地缓存可以支撑一阵。 ​ 使用Hystrix进行限流&amp;降级，例如一秒来了3000个请求，我们可以设置只能有一秒1000个请求能通过这个组件，那么其他剩余的2000请求就会走限流逻辑。然后去调用我们自己开发的降级组件，比如设置一些默认值之类的，以此来保护数据库不会被大量的请求给打死。 3、事后：开启Redis持久化机制，尽快恢复缓存集群​ 一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。 解决热点数据集中失效问题什么是热点数据集中失效​ 我们在设置缓存的时候，一般会给缓存设置一个失效时间，过了这个时间，缓存就失效。对于一些热点的数据来说，当缓存失效以后会存在大量的请求过来，然后打到数据库中去，从而可能导致数据库崩溃的情况。 解决方案1、设置不同的过期时间​ 为了避免这些热点数据集中失效，那么我们在设置缓存过期时间的时候，尽量让他们失效的时间错开。例如在一个基础的时间上加上或减去一个范围内的随机值。 2、互斥锁​ 结合上面击穿的情况，在第一个请求去查询数据库的时候加一个互斥锁，其余的查询都会被阻塞住，知道锁释放，从而保护数据库。 ​ 但是因为它会阻塞其他线程，此时系统吞吐量会下降，需要结合实际的业务去考虑是否要这么做。 参考资料https://juejin.im/post/5c9a67ac6fb9a070cb24bf34]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的IO模型]]></title>
    <url>%2FCKING.github.io%2F2019%2F08%2F02%2FJava%E7%9A%84IO%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[本节思维导图 同步和异步的概念：针对接口调用，API调用，服务调用等。同步调用者必须等待这个接口的磁盘读写或网络通信的操作执行完毕，调用者才可以返回，如图所示： 异步调用者调用接口后，直接就返回，不用等待磁盘读写或网络通信操作完成，而是可以去做其他事情。而这个接口如果干完了某件事，会反过来通知调用者，之前的调用成功了。这个可以通过内部机制来通知，或者通过回调函数来通知。 阻塞和非阻塞：针对的是底层底层IO操作阻塞比如我们的程序现在想要通过网络读取数据，如果是阻塞IO模式，一旦发起请求到操作系统内核去从网络中读取数据，就会阻塞在那里，必须等待网络中的数据到达之后，才能从网络中读取数据到内核，再从内核返回给程序。 非阻塞程序发送请求给内核要从网络读取数据，但是此时网络中的数据还没到，此时不会阻塞住，内核会返回一个异常信息给程序，程序可以干别的，然后不断去轮询去访问内核，看请求的数据是否读取到了。如图所示： BIO，NIO，多路复用IO，信号驱动式IO和AIOBIO​ 主要是同步阻塞IO模型，在JAVA里叫做BIO，在JDK1.4之前，在JAVA代码里调用IO相关接口，发起IO操作之后，JAVA程序就会同步等待，这个同步指的是JAVA程序调用IO API接口的层面而言。 ​ 而IO API在底层的IO操作是基于阻塞IO来的，向操作系统内核发起IO请求，系统内核会等待数据就位之后，才会执行IO操作，执行完毕了才会返回。 NIO​ 在JDK1.4之后提供了NIO，他的概念是同步非阻塞，也就是说如果你调用NIO接口去执行IO操作，其实还是同步等待，但是在底层的IO操作上，会对系统内核发起非阻塞IO请求，以非阻塞的形式来执行IO。 ​ 也就是说，如果底层数据没到位，那么内核会返回异常信息，不会阻塞住，但是NIO接口内部会采用非阻塞方式过一会儿再次调用内核发起IO请求，知道成功为止。 ​ 之所以说是同步非阻塞的，这里的“同步”指的就是因为在你的JAVA代码调用NIO接口层面是同步的，你还是要同步等待底层IO操作真正完成了才可以返回，只不过在执行底层IO的时候采用了非阻塞的方式来执行罢了。 IO多路复用模型​ 实际上，如果基于NIO进行网络通信，采取的就是多路复用的IO模型，这个多路复用IO模型针对的是网络通信中的IO场景来说的。就是在基于Socket进行网络通信的时候，如果有多个客户端跟你的服务端建立了Socket连接，你就需要维护多个Socket连接。而所谓的多路复用IO模型，就是说你的JAVA代码直接通过一个select函数（一般都是系统内核级别的函数，除此还有poll,epoll）调用，直接进入一个同步等待的状态。 ​ 这也是为什么说NIO一定是“同步”的，因为你必须在这里同步等待某个Socket连接有请求到来。接着你就要同步等着select函数去对底层的多个Socket连接进行轮询，不断地查看各个Socket连接谁有请求到达，就可以让select函数返回，交给我们的java程序处理。 ​ select函数在底层会通过非阻塞的方式轮询各个Socket，任何一个Socket如果没有数据到达，那么非阻塞的特性会立即返回一个信息。然后select函数可以轮询下一个Socket，不会阻塞在某个Socket上，所以底层是基于这种非阻塞的模式来“监视”各个Socket谁有数据到达的。 ​ 这就是所谓的“同步非阻塞”，但是因为操作系统把上述工作都封装在一个select函数调用里，可以对多路Socket连接同时进行监控，所以就把这种模型称为“IO多路复用”模型。 ​ 通过这个模型，就可以用一个线程，调用一个select函数，然后监视大量的客户端连接，如下图： 信号驱动式IO​ 首先我们允许Socket进行信号驱动IO，并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，会收到一个SIGIO信号，可以在信号处理函数中调用IO操作函数处理数据，如下图所示： ​ 相比于非阻塞式IO的轮询方式，信号驱动IO的CPU利用率更高。 AIO​ 在JDK1.7之后，又支持了AIO，也就做NIO2.0，他就支持异步IO模型。 ​ 异步IO模型，就是你的Java程序可以基于AIO API发起一个请求，比如接收网络数据，AIO API底层会基于异步IO模型来调用操作系统内核。此时不惜要去管这个IO是否成功，AIO接口会直接返回，你的Java程序也会直接返回。然后，你的Java程序就可以去干别的事情了。 ​ BIO，NIO都是同步的，你发起IO请求，都必须同步等待IO操作完成，但是这里你发起一个请求，直接AIO接口就返回了，你可以干别的事情了，纯异步方法，不过需要你提供一个回调函数给AIO接口，一旦底层系统内核完成了具体的IO请求，比如网络读写之类的，就会回调你提供的回调函数。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dubbo工作原理]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F31%2Fdubbo%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[本节思维导图 dubbo工作原理 第一层：service层，接口层：有服务提供者和服务消费者实现 第二层：config层，配置层：主要对dubbo进行各种配置 第三层：proxy层，服务代理层，为provider、consumer生成代理，代理之间进行网络通信 第四层：registry层，服务注册层，负责服务的注册与发现 第五层：cluster层，集群层，封装多个服务提供者的路由和负载均衡，将多个实例组合成一个服务 第六层：monitor层，监控层，对rpc接口的调用时间和调用次数进行监控 第七层：protocal层，远程调用层，封装rpc调用 第八层：exchange层，信息交换层，封装请求相应模式，同步转异步 第九层：transport层，网络传输层，抽象mina和Netty为统一接口 第十层：serialize层，数据序列化层 工作流程 第一步：provider向注册中心注册 第二步：consumer从注册中心订阅服务，注册中心通知consumer注册好的服务 第三步：consumer调用provider 第四步：consumer和provider都异步通知监控中心 dubbo架构图 注册中心挂了可以继续通信吗可以，因为刚开始初始化的时候，消费者会将提供服务的地址信息拉取到本地缓存，所以注册中心挂了可以继续通信]]></content>
      <categories>
        <category>分布式</category>
        <category>dubbo</category>
      </categories>
      <tags>
        <tag>dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[观察者模式]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F30%2F%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[​ “红灯停，绿灯行”。在这个过程中，信号灯是汽车的观察目标，汽车是观察者。随着信号灯的变化，汽车的行为也随着变化。在软件系统中，一个对象的状态或行为的变化将导致其他对象的行为或状态也发生改变，它们之间将产生联动。为了更好地描述对象之间存在的这种一对多（包括一对一）的联动，观察者模式应运而生。 ​ 观察者模式是使用频率最高的设计模式之一，用于建立一种对象与对象之间的依赖关系，一个对象发生改变时将自动通知其他对象，其他对象将相应作出反应。在观察者模式中，发生改变的对象成为观察目标，而被通知的对象成为观察者。这些观察者之间可以没有任何相互联系，可以根据需要增加和删除观察者，使得系统更易于扩展。 观察者模式定义：观察者模式：定义对象之间的一种一对多依赖关系，使得每当一个对象状态发生改变时，其相关依赖对象皆得到通知并被自动更新。观察者模式的别名包括发布-订阅（Publish/Subscribe）模式、模型-视图（Model/View）模式、源-监听器（Source/Listener）模式或从属者（Dependents）模式。观察者模式是一种对象行为型模式。 观察者模式结构图： 在结构图中包含以下四个角色： （1）Subject（目标）：目标又称为主题，它是指被观察的对象。在目标中定义了一个观察者集合，一个观察目标可以接受任意数量的观察者来观察，它提供一系列方法来增加和删除观察者对象，同时定义了通知方法notify()。目标类可以是接口，也可以是抽象类或具体类。 （2）ConcreteSubject（具体目标）：具体目标是目标类的子类，通常包含有经常发生改变的数据，当他的状态改变时，向其各个观察者发出通知；同时它还实现了在目标类中定义的抽象业务逻辑方法（如果有的话）。如果无须扩展目标类，则目标具体类可以省略。 （3）Observer（观察者）：观察者将对观察目标的改变做出反应，观察者一般定义为接口，改接口声明了更新数据的方法update()，因此又称为抽象观察者。 （4）ConcreteObserver（具体观察者）：在具体观察者中维护一个指向具体目标对象的引用，它存储具体观察者的有关状态，这些状态需要和具体目标的状态保持一致。它实现了在抽象观察者Observer中声明的update()方法。通常在实现时，可以调用具体的目标类的attach()方法将自己添加到目标类的集合或通过detach()方法将自己从目标类的集合中删除。 观察者模式主要优缺点：1、主要优点（1）观察者模式可以实现表示层和数据逻辑层的分离，定义了稳定的消息更新传递机制，并抽象了更新接口，使得可以有各种各样不同的表示层充当具体观察者角色。 （2）观察者模式在观察目标和观察者之间建立一个抽象的耦合。观察目标只需要维持一个抽象观察者的集合，无须了解其具体观察者。由于观察目标和观察者没有紧密地耦合在一起，因此它们可以不同的抽象化层次。 （3）观察者支持广播通信，观察目标会向所有已注册的观察者对象发送通知，简化了一对多系统设计的难度。 （4）观察者模式满足开闭原则的要求，增加新的具体观察者无须修改原有系统代码，在具体观察者与观察目标之间不存在关联关系的情况下，增加新的观察目标也很方便。 2、主要缺点（1）如果一个观察目标对象有很多直接或间接观察者，将所有的观察者都通知到会花费很多时间 （2）如果在观察者和观察目标之间存在循环依赖，观察目标会触发它们之间进行循环调用，可能导致系统崩溃。 （3）观察者模式没有相应的机制让观察者知道所观察的目标是怎么发生变化的，而仅仅只是知道观察目标发生了变化。 观察者模式使用场景：（1）一个抽象模型有两个方面，其中一个方面依赖于另一个方面，将这两个方面封装在独立的对象中使它们可以各自独立地改变和复用。 （2）一个对象的改变将导致一个或多个其他对象也发生改变，而并不知道具体有多少对象将发生改变，也不知道这些对象是谁。 （3）需要在系统中创建一个触发链，A对象的行为将影响B对象，B对象的行为将影响C对象……，可以使用观察者模式创建一种链式触发机制。 观察者模式与MVC的关系：​ MVC是一种架构模式，它包含3个角色：模型（Model）、视图（View）和控制器（Controller）。其中，模型可应对于观察者模式中的观察目标，而视图对应于观察者，控制器可充当两者之间的中介者，当模型层的数据发生改变时，视图层将自动显示内容。 案例​ Sunny软件公司欲开发一款多人联机对战游戏（类似魔兽世界），在该游戏中，多个玩家可以加入同一战队组成联盟，当战队中某一成员受到敌人攻击时将给所有其他盟友通知，盟友收到通知后将做出响应。 ​ Sunny公司通过对系统功能需求进行分析，发现在改系统中战队成员之间的联动过程可以简单描述如下：联盟成员受到攻击–&gt;发送通知给盟友–&gt;盟友做出响应。如果按照此思路来设计系统，因为成员在受到攻击时需要通知他的每位盟友，所以每个成员都需要持有其他所有盟友的信息，这将导致系统开销较大。因此开发人员决定引入一个新的角色–“战队控制中心”来负责维护和管理每个战队所有成员的信息。当一个成员受到攻击时，向相应的战队控制中心发送求助信息，战队控制中心再逐一通知每个盟友，盟友再做出相应。如图所示： 为了实现对象之间的联动，Sunny公司决定使用观察者模式来进行多人联机对战游戏的设计，其基本结构图如图所示： 相关代码实现已上传]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis哨兵集群实现高可用]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F29%2FRedis%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[哨兵的介绍​ sentinel，也叫哨兵。哨兵是Redis集群机构中非常重要的一个组件，有以下功能： 集群监控：负责监控redis master和slave进程是否正常工作。 消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员。 故障转移：如果master node挂掉了，会自动转移到slave node上。 配置中心：如果故障转移发生了，通知client客户端新的master地址。 ​ 哨兵用于实现Redis集群的高可用，本身也是分布式的，作为一个哨兵集群去运行，互相协同工作。 故障转移时，判断一个master node是否宕机了，需要大部分的哨兵都同意才行，涉及到了分布式选举的问题。 即使部分哨兵节点挂掉了，哨兵集群还是能正常工作。 哨兵的核心知识sdown和odown转换机制 sdown是主观宕机，就一个哨兵如果自己觉得一个master宕机了，那么就是主观宕机。 odown是客观宕机，如果quorum数量的哨兵都觉得一个master宕机了，那么就是客观宕机。 sdown达成的条件比较简单，如果一个哨兵ping一个master，超过了is-master-down-after-milliseconds指定的毫秒数之后，就主观认为master宕机了；如果一个哨兵在指定的时间内，收到了quorum数量的其他哨兵也认为那个master是sdown，那么就认为是odown。 quorum（法定人数）和majority​ 每次一个哨兵要做主备切换，首先需要quorum数量的哨兵认为odown，然后选举出一个哨兵来做切换，这个哨兵还需要得到majority哨兵的授权，才能正式执行切换。 ​ 如果quorum &lt; majority，比如5个哨兵，majority就是3， quorum设置为2，那么就需要3个哨兵授权就可以执行切换。 ​ 如果quorum &gt;= majority，那么必须quorum数量的哨兵都授权，比如5个哨兵，quorum是5，那么必须5个哨兵都同意授权，才能执行切换。 核心知识 哨兵至少需要3个实例，来保证自己的健壮性。 哨兵 + Redis主从的部署架构，是不保证数据零丢失的，只能保证redis集群的高可用性。 对于哨兵 + redis主从这种复制的部署架构，尽量在测试环境和生产环境，都进行充足的测试和演练。 哨兵集群必须部署2个以上节点，如果哨兵集群仅仅部署了2个哨兵实例，quorum = 1。 ​ 配置quorum = 1，如果master宕机，两个哨兵只要有1个哨兵认为master宕机了，就可以进行切换，同时会选举出一个哨兵来执行故障转移，但是同时这个时候，需要majority个哨兵，也就是大多数哨兵是运行的。 123452 个哨兵，majority=23 个哨兵，majority=24 个哨兵，majority=25 个哨兵，majority=3... ​ 如果此时只是Master宕机，哨兵1正常运行，那么故障转移时OK的，如果是Master和哨兵1运行的机器宕机了，那么哨兵只有一个，此时就没有majority数量个哨兵来执行故障转移，虽然另外一台机器上还有一个哨兵，但是故障转移不会执行。 ​ 经典的3节点哨兵集群是这样的： ​ 配置quorum = 2，如果M1所在机器宕机了，那么三个哨兵还剩下2个，S2和S3可以一致认为master宕机了，然后选举一个来执行故障转移，同时3个哨兵的majority是2，所以还剩下2个哨兵运行着，就可以允许执行故障转移。 Redis哨兵主备切换的数据丢失问题异步复制导致的数据丢失​ 因为master -&gt; slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了，此时这部分数据就丢失了。 脑裂导致的数据丢失​ 脑裂，即某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着，此时哨兵可能就会认为master宕机了，然后开启选举，将其他slave切换成了master。这个时候，集群里就会有两个master，这就是所谓的脑裂。 ​ 此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master，还继续向旧的master写数据。因此旧master再次恢复的时候，会被作为一个master挂到新的master上去，自己的数据会清空，重新从新的master复制数据，而新的master并没有后来client写入的数据，因此这部分数据也就丢失了。 数据丢失问题的解决方案可行进行如下配置： 12min-slaves-to-write 1min-slaves-max-lag 10 表示，要求至少有1个slave，数据复制和同步的延迟不能超过10秒。 减少异步复制数据的丢失 ​ 有了min-slaves-max-lag这个配置，就可以确保说，一旦slave复制数据和ack延时太长，就认为可能master宕机后损失的数据太多了，那么就拒绝写请求，这样可以把master宕机时由于部分数据未同步到slave导致的数据丢失降低到可控范围内。 减少脑裂的数据丢失 ​ 如果一个master出现了脑裂，跟其他slave丢了连接，那么上面两个配置可以确保说，如果不能继续给指定的slave发送数据，而且slave超过了10秒没有给自己（master）ack消息，那么就直接拒绝客户端的写请求，因此在脑裂的情况下，最多就丢失10秒的数据。 哨兵集群的自动发现机制​ 哨兵互相之间的发现，是通过redis的pub/sub系统实现的，每个哨兵都会往_sentine__:hello这个channel里发送一个消息，这时候所有其他哨兵都可以消费到这个消息，并感知其他哨兵的存在。 ​ 每隔两秒钟，每个哨兵都会往自己监控的某个maser + slave对应的_sentinel__:hellochannel里发送一个消息，内容是自己的Host、ip和runid还有对这个master的监控配置。 ​ 每个哨兵也会去监听自己监控的每个 master+slaves 对应的 __sentinel__:hello channel，然后去感知到同样在监听这个 master+slaves 的其他哨兵的存在。 ​ 每个哨兵还会跟其他哨兵交换对 master 的监控配置，互相进行监控配置的同步。 slave配置的自动纠正​ 哨兵会负责自动纠正slave的一些配置，比如slave如果要成为潜在的master候选人，哨兵会确保复制现有的master数据；如果slave连接到了一个错误的master上。比如故障转移后，那么哨兵会确保它们连接到正确的master上。 slave -&gt; master选举算法​ 如果一个master被认为odown，而且majority数量的哨兵都允许主备切换，那么某个哨兵就会执行住别切换操作，此时需要选举一个slave来当master，会考虑slave的一些信息： 跟master断开连接的时长 slave优先级 复制offset run id ​ 如果一个slave跟master断开连接的时间已经超过了down-after-milliseconds的10倍，外加master的宕机的时长，那么slave就被认为不适合选举为master 1(down-after-milliseconds * 10) + milliseconds_since_master_is_in_SDOWN_state ​ 接下来会对slave进行排序： 按照slave优先级进行排序，slave priority越低，优先级越高。 如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高。 如果上面两个条件都相同，那么选一个run id比较小的那个。 configuration epoch​ 哨兵会对一套redis master + slaves进行监控，有相应的监控配置。 ​ 执行切换的那个哨兵，会从要切换到新的master（slave -&gt; master）那里得到一个configuration epoch，这就是一个version号，每次切换的version号都必须是唯一。 ​ 如果第一个选举出的哨兵切换失败，那么其他哨兵，就会等待failover-timeout时间，然后接替继续执行切换，此时会重新获取一个新的configuration epoch，作为新的version号。 configuration传播​ 哨兵完成切换之后，会在自己本地更新生成最新的master配置，然后同步给其他的哨兵，就是通过之前说的pub/sub消息机制。 ​ 这里之前的version号就很重要了，以为各种消息都是通过一个channel去发布和监听的，所以一个哨兵完成一次新的切换之后，新的master配置是跟着新的version号的。其他的哨兵都是根据版本号的大小来跟新自己的master配置的。]]></content>
      <categories>
        <category>分布式</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>分布式</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UML之类之间的关系]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F27%2FUML%E4%B9%8B%E7%B1%BB%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[​ 在软件系统中国，类并不是孤立存在的，类与类之间存在各种关系，对于不同类型的关系，UML提供了不同的表示方式。 关联关系​ 关联关系是类与类之间最常用的一种关系，它是一种结构化关系，用于表示一类对象与另一类对象之间有联系，如汽车和轮胎，师傅和徒弟，班级和学生等。在UML类图中，用实现连接有关联关系的对象所对应的类。 ​ 例如现在一个登陆界面类LoginForm中包含一个JButton类型的注册按钮loginButton，它们之间可以表示为关联关系，代码实现时可以在LoginForm中定义一个名为loginButton的属性对象，其类型为JButton，如图所示： 对应的JAVA代码片段如下： 1234567891011public class LoginForm &#123; //定义成员变量 private JButton loginButton; ...&#125;public class JButton &#123; ...&#125; ​ 在UML中，关联关系又包含如下几种形式。 双向关联​ 默认情况下，关联是双向的。例如顾客购买商品并拥有商品，反之，卖出的商品总有某个顾客与之关联。因此，Customer类和Product类之间具有双向关联关系，如图所示： ​ 对应的代码片段如下： 123456789101112public class Customer &#123; private Product[] products; ...&#125;public class Product &#123; private Customer customer; ...&#125; 单向关联​ 类的关联关系也可以是单向的，在UML中单向关联关系用带箭头的实线表示。例如，顾客拥有地址，则Customer类与Address类具有单向关联关系，如图所示： ​ 对应的代码如下： 1234567891011public class Customer &#123; private Address address; ...&#125;public class Address &#123; ...&#125; 自关联​ 在系统中可能会存在一些类的属性对象类型为该类本身，这种特殊的关联关系成为自关联。例如，一个节点类（Node）的成员又是节点Node类型的对象，如图所示： ​ 对应的代码如下： 123456public class Node &#123; private Node subNode; ...&#125; 多重性关联​ 多重性关联关系又称为重数性（Multiplicity）关联关系，表示两个关联对象在数量上的对应关系。在UML中，对象之间的多重性可以直接在关联直线上用一个数字或一个数字范围表示。 ​ 对象之间可以存在多种多重关联惯性，常见的多重性表示方法如下表： 表示方式 多重性说明 1.. 1 表示另一个类的一个对象只与改类的一个对象有关系 0.. * 表示另一个类的一个对象与该类的零个或多个对象有关系 1.. * 表示另一个类的一个对象与该类的一个或多个对象有关系 0.. 1 表示另一个类的一个对象没有或只与改类的一个对象有关系 m.. n 表示另一个类的一个对象与该类最少m，最多n个对象有关系（m &lt;= n） ​ 例如，一个界面可以拥有零个或多个按钮，但是一个按钮只能属于一个界面。因此，一个Form类的对象可以与零个或多个Button类的对象相关联，但一个Button类的对象只能与一个Form类的对象关联，如图所示： ​ 对应的代码如下： 123456789101112public class Form &#123; //定义一个集合对象 private Button[] buttons; ...&#125;public class Button &#123; ...&#125; 聚合关系​ 聚合关系表示整体与部分的关系。在聚合关系中，成员对象是整体对象的一部分，但是成员对象可以脱离整体对象独立存在。在UML中，聚合关系用带空心菱形的直线表示。例如，汽车发送机是汽车的组成部分，但是汽车发送机可以独立存在，因此，汽车和发送机是聚合关系，如图所示： ​ 在代码实现聚合关系时，成员对象通常作为构造方法、Setter方法或业务方法的参数注入到整体对象中，如下所示： 123456789101112131415161718192021public class Car &#123; private Engine engine; //构造注入 public Car(Engine engine) &#123; this.engine = engine; &#125; //设值注入 public void setEngine(Engine engine) &#123; this.engine = engine; &#125; ...&#125;public class Engine &#123; ...&#125; 组合关系​ 组合关系也表示类之间整体和部分的关系，但是在组合关系中整体对象可以控制成员对象的生命周期，一旦整体对象不存在，成员对象也将不存在，成员对象与整体对象之间具有同生共死的关系。在UML中，组合关系用带实心菱形的直线表示。例如，人的头（Head）与嘴巴（Mouth），嘴巴是头的组成部分之一，而且如果头没了，嘴巴也就没了，因此头和嘴巴是组合关系，如图所示： ​ 在代码实现组合关系时，通常在整体类的构造方法中直接实例化成员类，如下所示： 123456789101112131415public class Head &#123; private Mouth mouth; public Head() &#123; mouth = new Mouth(); &#125; ...&#125;public class Mouth &#123; ...&#125; 依赖关系​ 依赖关系是一种使用关系，特定事物的改变有可能会影响到使用该事物的其他的事物，在需要表示一个事物使用另一个事物时使用依赖关系。大多数情况下，依赖关系体现在某个类的方法使用另一个类的对象作为参数。在UML中，依赖关系用带箭头的虚线表示，由依赖的一方指向被依赖的一方。例如，驾驶员开车，在Driver类的drive()方法中将Car类型的对象作为一个参数传递，以便在drive()方法中能调用Car类的move()方法，且驾驶员的drive()方法依赖车的move()方法，因此类Drive依赖类Car，如图所示： ​ 在系统实施阶段，依赖关系通常通过3种方式来实现。第1种也是最常用的一种方式是上面讲的将一个类的对象作为另一个类中方法的参数；第2种方式是在一个类的方法中将另一个类的对象作为其局部变量；第3种方式是在一个类的方法中调用另一个类的静态方法。 ​ 相应的代码如下： 12345678910111213141516public class Driver &#123; public void drive(Car car) &#123; car.move(); &#125; ...&#125;public class Car &#123; public void move() &#123; ... &#125; ...&#125; 泛化关系​ 泛化关系也就是继承关系,用于描述父类与子类之间的关系，父类又称作基类或超类，子类又称作派生类。在UML中,泛化关系用带空心三角形的直线来表示。在代码实现时,使用面向对象的继承机制来实现泛化关系，如在Java语言中使用extends关键字、在C++/C#中使用冒号“:”来实现。 ​ 相应的代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637//父类public class Person &#123; protected String name; protected int age; public void move() &#123; ... &#125; public void say() &#123; ... &#125;&#125;//子类public class Student extends Person &#123; private String stuedentNo; public void study() &#123; ... &#125;&#125;//子类public class Teacher extends Person&#123; private String teacherNo; public void teach() &#123; ... &#125;&#125; 接口与实现关系​ 在很多面向对象语言中都引人了接口的概念，如Java、C#等。在接口中,通常没有属性，而且所有的操作都是抽象的，只有操作的声明，没有操作的实现。UML中用与类的表示法类似的方式表示接口，接口之间也可以有与类之间关系类似的继承关系和依赖关系，但是接口和类之间还存在一种实现(Realization)关系。在这种关系中，类实现了接口，类中的操作实现了接口中所声明的操作。在UML中,类与接口之间的实现关系用带空心三角形的虚线来表示。 ​ 相应的代码如下所示： 1234567891011121314151617public interface Vehicle &#123; public void move();&#125;public class Ship implements Vehicle &#123; public void move() &#123; ... &#125;&#125;public class Car implements Vehicle &#123; public void move() &#123; ... &#125;&#125;]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP的基础概念]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F25%2FHTTP%E7%9A%84%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[本节思维导图 URIURI(Uniform Resource Identifier)统一资源标识符，其中包括两个部分：URL(Uniform Resource Locator)统一资源定位符和URN(Uniform Resource Name)统一资源名称。 HTTP方法客户端发送的请求报文的第一行为请求行，包含了方法字段。 GET 获取资源 HEAD 获取报文首部 和GET方法类似，但不返回报文实体主体部分。主要用于确认URL的有效性和资源更新的日期时间等。 POST 传输实体主体 POST主要用来传输数据，GET只要用来获取资源 PUT 上传文件 由于自身不带验证机制，任何人都可以上传文件，因此存在安全性问题，一般不使用该方法 PATCH 对资源进行部分修改 PUT也可以用于修改资源，但是只能完全替代原始资源，PATCH允许部分修改。 DELETE 删除文件 与PUT功能相反，并且同样不带验证机制 OPTIONS 查询支持的方法 查询指定的URL能够支持的方法。会返回Allow:GET, POST, HEAD, OPTIONS 这样的内容 CONNECT TRACE]]></content>
      <categories>
        <category>计算机网络</category>
        <category>HTTP</category>
      </categories>
      <tags>
        <tag>计算机网络 HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hello</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[消息队列优缺点]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F24%2F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E4%BC%98%E7%BC%BA%E7%82%B9%2F</url>
    <content type="text"><![CDATA[本节思维导图 消息队列的优点消息队列主要有三个优点：解耦、异步和削峰 削峰假设一个业务场景如图所示，A系统分别发送信息给B C D系统，此时系统的耦合性比较高，当需求改变要求不给D系统发送消息，或者增加一个E系统也需要A系统发送数据，那么我们就不得不去修改A系统的代码。除此之外如果其他系统挂了，同样也会影响到A系统，如果引入MQ，那么A系统就只需要把数据放进MQ中，由需要这个数据的系统去订阅这个MQ，这样就可以实现系统解耦。这样A系统不仅不需关系哪个系统需要这个消息，也不需要关心消息发送失败或者超时等情况。 总结：通过MQ，Pub/Sub发布订阅消息模型，A系统就跟其他系统解耦了。 异步业务场景如图所示，用户向A系统发起请求，需要在本地写数据库，还需要在B C D系统写数据库，假设本地写耗时10ms，如下图需要10+20+30+40共100ms。那么这样相对来说比较慢。 但如果引入MQ，假设将消息放入MQ耗时5ms，那么总共需要15ms，极大提高了响应速度。 削峰假设每天0:00-12:00系统每秒并发请求数量只有十几个，但过了12点之后，请求数量猛增到几千个，而且数据库系统是mysql，每秒最多也就执行一千多条SQL语句，这样导致mysql崩溃，但过了高峰期之后并发请求又恢复到了相对比较低的水平，对整个系统又没啥压力了。 引入MQ之后，A系统每秒中只能处理一千个SQL，那就从MQ中取出一千个SQL去处理，这样即使在高峰的时候，A系统也不会崩溃，而在高峰期间MQ可能会有几百万的请求积压在MQ中，但这个短暂的高峰的积压是允许，等高峰期一过，MQ积压的数据就能够迅速被处理。 消息队列的缺点缺点有以下几个： 系统可用性降低引入的外部依赖越多，风险就越高。本来只是调用几个系统的接口就可以了，现在引入MQ之后，如果MQ挂了，整个系统就崩溃了。 系统复杂性提高引入MQ之后，需要考虑很多问题。例如如何保证消息传递的顺序，保证消息没有重复消费和怎么处理消息丢失的情况。 数据一致性问题A系统将数据放到MQ将返回成功了，但如果B系统数据丢失了，那就会造出数据不一致了。 ActiveMQ、RabbitMQ、RocketMQ和kafka有什么优缺点 特性 ActiveMQ RabbitMQ RocketMQ kafka 单机吞吐量 万级，比RocketMQ、kafka低一级 同ActiveMQ 10万级，支撑高吞吐 10万级，高吞吐，一般配合大数据类的系统机型实时数据计算，日志采集等场景 topic数量对吞吐量的影响 topic可以达到几百/几千的级别，这是RocketMQ的优势，在同等机器下，可以支撑大量的topic topic从几十到几百个左右的时候，吞吐量会大幅度下降，kafka尽量保证topic数量不要过多，如果要支撑大规模的topic，需要增加更多的机器资源 时效性 ms级 微秒级，这是RabbitMQ的一大特点，延迟最低 ms级 延迟在ms级以内 可用性 高，基于主从架构实现高可用 同ActiveMQ 非常高，分布式架构 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用 消息可靠性 有较低的概率丢失数据 基本不丢 经过参数优化配置，可以做到0丢失 同RocketMQ 功能支持 MQ领域的功能极其完备 基于erlang开发，并发能力很强，性能极好，延时很低 MQ功能较为完善，还是分布式的，扩展性好 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用 综上，各种对比之后，有如下建议： 一般的业务系统要引入 MQ，最早大家都用 ActiveMQ，但是现在确实大家用的不多了，没经过大规模吞吐量场景的验证，社区也不是很活跃，所以大家还是算了吧，我个人不推荐用这个了； 后来大家开始用 RabbitMQ，但是确实 erlang 语言阻止了大量的 Java 工程师去深入研究和掌控它，对公司而言，几乎处于不可控的状态，但是确实人家是开源的，比较稳定的支持，活跃度也高； 不过现在确实越来越多的公司会去用 RocketMQ，确实很不错，毕竟是阿里出品，但社区可能有突然黄掉的风险（目前 RocketMQ 已捐给 Apache，但 GitHub 上的活跃度其实不算高）对自己公司技术实力有绝对自信的，推荐用 RocketMQ，否则回去老老实实用 RabbitMQ 吧，人家有活跃的开源社区，绝对不会黄。 所以中小型公司，技术实力较为一般，技术挑战不是特别高，用 RabbitMQ 是不错的选择；大型公司，基础架构研发实力较强，用 RocketMQ 是很好的选择。 如果是大数据领域的实时计算、日志采集等场景，用 Kafka 是业内标准的，绝对没问题，社区活跃度很高，绝对不会黄，何况几乎是全世界这个领域的事实性规范。]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的过期策略和内存淘汰机制]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F21%2FRedis%E7%9A%84%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E5%92%8C%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[本节思维导图 ​ redis主要是基于内存来进行高性能、高并发的读写操作的。但既然内存是有限的，例如redis就只能使用10G，你写入了20G。这个时候就需要清理掉10G数据，保留10G数据。那应该保留哪些数据，清除哪些数据，为什么有些数据明明过期了，怎么还占用着内存？这都是由redis的过期策略来决定的。 redis过期策略​ redis的过期策略就是：定期删除 + 惰性删除。 ​ 定期删除，指的是redis默认是每隔100ms就随机抽取一些设置了过期时间的key，检查是否过期，如果过期就删除。 ​ 假设redis里放了10W个key，都设置了过期时间，你每隔几百毫秒就检查全部的key，那redis很有可能就挂了，CPU负载会很高，都消耗在检查过期的key上。注意，这里不是每隔100ms就遍历所有设置过期时间的key，那样就是一场性能灾难。实际上redis是每隔100ms就随机抽取一些key来检查和删除的。 ​ 定期删除可能会导致很多过期的key到了时间并没有被删除掉。这个时候就可以用到惰性删除了。惰性删除是指在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间并且已经过期了，此时就会删除，不会给你返回任何东西。 ​ 但即使是这样，依旧有问题。如果定期删除漏掉了很多过期的key，然后你也没及时去查，也就没走惰性删除。此时依旧有可能大量过期的key堆积在内存里，导致内存耗尽。 ​ 这个时候就需要内存淘汰机制了。 内存淘汰机制​ redis内存淘汰机制有以下几个： noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。这个一般很少用。 allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key，这个是最常用的。 allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。 volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。 volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。 volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。 LRU算法​ 上面的内存淘汰机制中，用到的是LRU算法。什么是LRU算法？LRU算法其实就是上面说的最近最少使用策略。实现LRU算法，大概的思路如下： ​ 维护一个有序单链表，越靠近链表尾部的节点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表： 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的节点，并将其从原来的位置删除，然后再插入到链表的头部。 如果此数据没有在缓存链表中，又可以分为两种情况： 如果此时缓存未满，则将此节点直接插入到链表的头部； 如果此时缓存已满，则链表尾节点删除，将新的数据节点插入链表的头部。 ​ 这就就实现了LRU算法。 ​ 当然我们也可以基于Java现有的数据结构LinkedHashMap手撸一个。LinkHashMap本质上是一个Map与双向链表的结合，比起上述的单链表，效率更高。代码如下： 1234567891011121314151617181920class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int CACHE_SIZE; /** * 传递进来最多能缓存多少数据 * * @param cacheSize 缓存大小 */ public LRUCache(int cacheSize) &#123; // true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老访问的放在尾部。 super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true); CACHE_SIZE = cacheSize; &#125; @Override protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123; // 当 map中的数据量大于指定的缓存个数的时候，就自动删除最老的数据。 return size() &gt; CACHE_SIZE; &#125;&#125;]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的数据结构及其应用场景]]></title>
    <url>%2FCKING.github.io%2F2019%2F07%2F21%2FRedis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF%2F</url>
    <content type="text"><![CDATA[本节思维导图 redis主要有以下几种数据类型： string hash list set sorted set string这是最简单的类型，就是普通的set和get，做简单的KV缓存 1set college gpnu hash这个是类似map的一种结构，一般是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他对象）给缓存在redis里，然后每次读写缓存的时候，就可以操作hash里的某个字段。 1234hset person name bingohset person age 20hset person id 1hget person name 12345person = &#123; "name": "bingo", "age": 20, "id": 1&#125; listlist是有序列表。可以通过list存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的。 还可以通过lrange命令，读取某个闭区间内的元素，可以基于list实现分页查询，基于redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走 12# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。lrange mylist 0 -1 123456lpush mylist 1lpush mylist 2lpush mylist 3 4 5# 1rpop mylist setset是无序集合，自动去重。 直接基于set将系统里需要去重的数据扔进去，自动就去去重了。如果你需要对一些数据进行快速的全局去重，如果是单机系统就可以基于Java的HashSet进行去重，如果你的某个系统部署在多台机器上，就可以基于redis进行全局的set去重。 可以基于set玩交集、并集、差集的操作。比如交集，可以把两个人的粉丝列表整一个交集，看看两人的共同好友是谁。或者把两个大V的粉丝放在两个set中，对两个set做交集。 1234567891011121314151617181920212223242526272829303132#-------操作一个set-------# 添加元素sadd mySet 1# 查看全部元素smembers mySet# 判断是否包含某个值sismember mySet 3# 删除某个/些元素srem mySet 1srem mySet 2 4# 查看元素个数scard mySet# 随机删除一个元素spop mySet#-------操作多个set-------# 将一个set的元素移动到另外一个setsmove yourSet mySet 2# 求两set的交集sinter yourSet mySet# 求两set的并集sunion yourSet mySet# 求在yourSet中而不在mySet中的元素sdiff yourSet mySet sorted setsorted set是排序的set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序 12345678910zadd board 85 zhangsanzadd board 72 lisizadd board 96 wangwuzadd board 63 zhaoliu# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）zrevrange board 0 3# 获取某用户的排名zrank board zhaoliu]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
</search>
