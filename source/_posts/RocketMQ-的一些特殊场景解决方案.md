---
title: RocketMQ 的一些特殊场景解决方案
date: 2020-04-24 14:41:50
tags: 消息队列
categories: 消息队列
---

## RocketMQ 百万消息积压问题

有一个系统，它是由生产者系统和消费者系统两个环节组成的，生产者系统会负责不停地把消息写入 RocketMQ 里去，然后消费者系统就是负责从 RocketMQ 里消费消息。这个系统是有高峰和低谷的，在晚上几个小时的高峰期内，大概会有 100 多万条消息进入 RocketMQ，然后消费者系统从 RocketMQ 里获取到消息之后，会依赖一些 NoSQL 数据库去进行一些业务逻辑的实现。



然后有一天晚上出现了一个问题，消费者系统依赖的 NoSQL 数据库挂掉了，导致消费者系统自己也没法运作，此时就没法继续从 RocketMQ 里消费数据和处理了，消费者系统几乎就处于停滞不动的状态。然后生产者系统在晚上几个小时的高峰期内，往 MQ 里写入了 100 多万的消息，此时都积压在 MQ 里了，没人消费和处理。



针对这种情况，一般来说有几种方案可以快速搞定。如果这些消息你是允许丢失的，那么此时你就可以紧急修改消费者系统的代码，在代码里对所有的消息都获取到就直接丢弃，不做任何的处理，这样可以迅速地让积压在 MQ 里的百万消息被处理掉，只不过处理方式是全部丢弃而已。



但是对很多系统而言，不能简单粗暴地丢弃这些消息，所以最常见的方法，还是先等待消费者系统底层依赖的 NoSQL 数据库先恢复了。恢复之后，就可以根据你的线上 Topic 的 MessageQueue 的数量来看看如何后续处理。



加入你的 Topic 有 20 个 MessageQueue，然后你只有 4 个消费者系统在消费，那么每个消费者系统会从 5 个 MessageQueue 里获取消息。所以此时你仅仅依靠 4 个消费者系统是不够的，毕竟 MQ 了积压了百万消息了。所以此时你可以临时申请 16 台机器多部署 16 个消费者系统的实例，然后 20 个消费者系统同时消费，每个人消费一个 MessageQueue 的消息。此时你消费的速度提高了 5 被，很快积压的百万消息也会被处理掉。



但是这里你同时要考虑到你的消费者系统底层依赖的 NoSQL 数据库必须要能抗住临时增加了 5 倍的读写压力，因为原来就 4 个消费者系统在读写 NoSQL，现在临时变成了 20 个消费者系统了。当你处理完百万积压的消息之后，就可以下线多余的 16 台机器了。



那如果你的 Topic 总共就只有 4 个 MessageQueue，然后你就只有 4 个消费者系统呢？这个时候就没办法扩容消费者系统了，因为你加再多的消费者系统，还是只有 4 个 MessageQueue，没法进行消费。



所以此时往往是临时修改那 4 个消费者系统的代码，让他们获取到消息然后不写入 NoSQL，而是直接把消息写入一个新的 Topic，这个速度是很快的，因为仅仅是读写 MQ 而已。然后新的 Topic 有 20 个 MessageQueue，然后再部署 20 台临时增加的消费者系统，去消费新的 Topic 后写入数据到 NoSQL 里去，这样子也可以迅速地增加消费者系统的并行处理能力，使用一个新的 Topic 来运行更多的消费者并行处理。



## 金融级的系统针对 RocketMQ 集群崩溃设计高可用方案

金融级的系统中如果依赖了 RocketMQ 集群，那么在 RocketMQ 集群彻底崩溃的时候，我们应该如何设计它的高可用方案？比如跟金钱相关的一些系统，它可能需要依赖 MQ 去传递消息，如果你 MQ 崩溃了，可能导致很多跟钱相关的东西就会出问题。



类似的场景有很多，针对这种场景，我们通常会在你发送消息到 MQ 的那个系统中设计高可用的降级方案。**这个降级方案通常的思路是，你需要在你发送消息到 MQ 代码里去 try catch 捕获异常，如果你发送发送消息到 MQ 有异常，此时你需要进行重试。**



如果你发现连续重试了比如超过 3 次还是失败了，说明此时可能就是你的 MQ 集群彻底崩溃了，此时你必须把这条重要消息写入到本地存储中去，可以是数据库，也可以是写入到本地磁盘文件里去，或者是 NoSQL 存储中去。具体要根据你们的具体情况来决定。



之后你要不停地尝试发送消息到 MQ 去，一旦发现 MQ 集群恢复了，你必须有一个后台线程可以把之前持久化存储的消息都查询出来，然后依次按照顺序发送到 MQ 集群里去，这样才能保证你的消息不会因为 MQ 彻底崩溃而丢失。



这里有一个很关键的点，就是你把消息写入存储中暂存时，一定要保证它的顺序，比如按照顺序一条一条的写入本地磁盘文件去暂存消息。而且一旦 MQ 集群故障了，你后续的所有写消息的代码必须严格按照顺序把消息写入到本地磁盘文件去暂存，这个顺序性是要严格保证的。



只要有这个方案在，那么哪怕你的 MQ 集群突然崩溃了，你的系统也是不会丢失消息的，对于一些跟金钱相关的金融系统，广告系统来说，这种高可用的方案设计，是非常有必要的。



## Kafka 到 RocketMQ 的双写 + 双读技术方案，实现无缝迁移

假设你们公司本来线上的 MQ 用的主要是 Kafka，现在要从 Kafka 迁移到 RocketMQ 去，那么这个迁移的过程该怎么做？这里给大家介绍一个 MQ 集群迁移过程中的双写 + 双读技术方案。



简单来说，如果你要做 MQ 集群迁移，是不可能那么简单粗暴的，因为你不可能说在某一个时间点突然之间说把所有的 Producer 系统都停机，然后更新它的代码，接着全部上线，然后所有 Producer 系统都把消息写入到 RocketMQ 去了。



一般来说，首先你要做到双写，也就是说，在你所有的 Producer 系统中，要引入一个双写的代码，让它同时往 Kafka 和 RocketMQ 中去写入消息，然后多写几天，起码双写要持续一周左右，因为 MQ 一般都是实时数据，里面的数据也就最多保留一周。当你的双写持续一周后，你会发现你的 Kafka 和 RocketMQ 里的数据看起来几乎是一模一样，因为 MQ 反正也就保留最近几天的数据，当你双写持续超过一周过后，你会发现 Kafka 和 RocketMQ 里的数据几乎一模一样了



但是光是双写还是不够的，还需要同时进行双读，也就是说在你双写的同时，你所有的 Consumer 系统都需要同时从 Kafka 和 RocketMQ 里获取消息，分别用一模一样的逻辑处理一遍。只不过从 Kafka 里获取到的消息还是走核心逻辑去处理，然后可以落入数据库或者别的存储之类的，但是对月 RocketMQ 里获取到的消息，你可以用一样的逻辑处理，但是不能把处理结果具体的地落入数据库之类的地方



你的 Consumer 系统在同时从 Kafka 到 RocketMQ 进行消息读取的时候，你需要统计每个 MQ 当日读取和处理的消息的数量，这点非常重要，同时对于 RocketMQ 读取到的消息处理之后的结果，可以写入一个临时的存储中。



同时你要观察一段时间，当你发现坚持双写和双读一段时间之后，如果所有的 Consumer 系统通过对比发现，从 Kafka 和 RocketMQ 读取和处理的消息数量一致，同时处理之后得到的结果也是一致的，此时就可以判断说当前 Kafka 和 RocketMQ 里的消息是一致的，而且计算出来的结果也是一致的。



这个时候就可以实施正式的切换了，你可以停机 Producer 系统，再重修修改后上线，全部修改为仅仅写 RocketMQ，这个时候它数据不会丢，因为之前已经双写了一段时间了，然后所有的 Consumer 系统可以全部下线后修改代码再上线，全部基于 RocketMQ 来获取消息，计算和处理，结果写入存储中。



基本上对于类似的一些重要中间件的迁移，往往都会采取双写的方法，双写一段时间，然后观察两个方案的结果都一致了，你再正式下线旧的一套东西